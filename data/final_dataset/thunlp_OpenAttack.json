{"home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo.make_model": [[7, 27], ["MyClassifier", "demo..get_prob().argmax", "numpy.array", "nltk.sentiment.vader.SentimentIntensityAnalyzer", "demo..model.polarity_scores", "ret.append", "nltk.download", "nltk.sentiment.vader.SentimentIntensityAnalyzer", "demo..get_prob", "numpy.array"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["def", "make_model", "(", ")", ":", "\n", "    ", "class", "MyClassifier", "(", "OpenAttack", ".", "Classifier", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "model", "=", "SentimentIntensityAnalyzer", "(", ")", "\n", "", "except", "LookupError", ":", "\n", "                ", "nltk", ".", "download", "(", "'vader_lexicon'", ")", "\n", "self", ".", "model", "=", "SentimentIntensityAnalyzer", "(", ")", "\n", "\n", "", "", "def", "get_pred", "(", "self", ",", "input_", ")", ":", "\n", "            ", "return", "self", ".", "get_prob", "(", "input_", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n", "", "def", "get_prob", "(", "self", ",", "input_", ")", ":", "\n", "            ", "ret", "=", "[", "]", "\n", "for", "sent", "in", "input_", ":", "\n", "                ", "res", "=", "self", ".", "model", ".", "polarity_scores", "(", "sent", ")", "\n", "prob", "=", "(", "res", "[", "\"pos\"", "]", "+", "1e-6", ")", "/", "(", "res", "[", "\"neg\"", "]", "+", "res", "[", "\"pos\"", "]", "+", "1e-6", ")", "\n", "ret", ".", "append", "(", "np", ".", "array", "(", "[", "1", "-", "prob", ",", "prob", "]", ")", ")", "\n", "", "return", "np", ".", "array", "(", "ret", ")", "\n", "", "", "return", "MyClassifier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo.dataset_mapping": [[28, 32], ["None"], "function", ["None"], ["", "def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo.main": [[34, 53], ["print", "OpenAttack.attackers.PWWSAttacker", "print", "demo.make_model", "datasets.load_dataset().map", "print", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset", "OpenAttack.metric.Fluency", "OpenAttack.metric.GrammaticalErrors", "OpenAttack.metric.SemanticSimilarity", "OpenAttack.metric.EditDistance", "OpenAttack.metric.ModificationRate"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.make_model", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "print", "(", "\"New Attacker\"", ")", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", "\n", "\n", "print", "(", "\"Build model\"", ")", "\n", "clsf", "=", "make_model", "(", ")", "\n", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:100]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "\n", "print", "(", "\"Start attack\"", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "clsf", ",", "metrics", "=", "[", "\n", "OpenAttack", ".", "metric", ".", "Fluency", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "GrammaticalErrors", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "SemanticSimilarity", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "EditDistance", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "ModificationRate", "(", ")", "\n", "]", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ",", "progress_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo_chinese.dataset_mapping": [[4, 8], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"review_body\"", "]", ",", "\n", "\"y\"", ":", "x", "[", "\"stars\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo_chinese.main": [[11, 29], ["print", "OpenAttack.attackers.PWWSAttacker", "print", "OpenAttack.loadVictim", "print", "datasets.load_dataset().map", "print", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset", "OpenAttack.metric.Fluency", "OpenAttack.metric.GrammaticalErrors", "OpenAttack.metric.EditDistance", "OpenAttack.metric.ModificationRate"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"New Attacker\"", ")", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", "lang", "=", "\"chinese\"", ")", "\n", "\n", "print", "(", "\"Building model\"", ")", "\n", "clsf", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.AMAZON_ZH\"", ")", "\n", "\n", "print", "(", "\"Loading dataset\"", ")", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"amazon_reviews_multi\"", ",", "'zh'", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "\n", "print", "(", "\"Start attack\"", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "clsf", ",", "metrics", "=", "[", "\n", "OpenAttack", ".", "metric", ".", "Fluency", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "GrammaticalErrors", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "EditDistance", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "ModificationRate", "(", ")", "\n", "]", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ",", "progress_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo_deo.make_model": [[8, 28], ["MyClassifier", "demo_deo..get_prob().argmax", "numpy.array", "nltk.sentiment.vader.SentimentIntensityAnalyzer", "demo_deo..model.polarity_scores", "ret.append", "nltk.download", "nltk.sentiment.vader.SentimentIntensityAnalyzer", "demo_deo..get_prob", "numpy.array"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["def", "make_model", "(", ")", ":", "\n", "    ", "class", "MyClassifier", "(", "OpenAttack", ".", "Classifier", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "model", "=", "SentimentIntensityAnalyzer", "(", ")", "\n", "", "except", "LookupError", ":", "\n", "                ", "nltk", ".", "download", "(", "'vader_lexicon'", ")", "\n", "self", ".", "model", "=", "SentimentIntensityAnalyzer", "(", ")", "\n", "\n", "", "", "def", "get_pred", "(", "self", ",", "input_", ")", ":", "\n", "            ", "return", "self", ".", "get_prob", "(", "input_", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n", "", "def", "get_prob", "(", "self", ",", "input_", ")", ":", "\n", "            ", "ret", "=", "[", "]", "\n", "for", "sent", "in", "input_", ":", "\n", "                ", "res", "=", "self", ".", "model", ".", "polarity_scores", "(", "sent", ")", "\n", "prob", "=", "(", "res", "[", "\"pos\"", "]", "+", "1e-6", ")", "/", "(", "res", "[", "\"neg\"", "]", "+", "res", "[", "\"pos\"", "]", "+", "1e-6", ")", "\n", "ret", ".", "append", "(", "np", ".", "array", "(", "[", "1", "-", "prob", ",", "prob", "]", ")", ")", "\n", "", "return", "np", ".", "array", "(", "ret", ")", "\n", "", "", "return", "MyClassifier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo_deo.dataset_mapping": [[29, 33], ["None"], "function", ["None"], ["", "def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.demo_deo.main": [[35, 57], ["print", "print", "OpenAttack.DataManager.loadVictim", "datasets.load_dataset().map", "print", "OpenAttack.attackers.UATAttacker", "OpenAttack.attackers.UATAttacker.set_triggers", "print", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset", "OpenAttack.metric.Fluency", "OpenAttack.metric.GrammaticalErrors", "OpenAttack.metric.EditDistance", "OpenAttack.metric.ModificationRate"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.set_triggers", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"New Attacker\"", ")", "\n", "#attacker = OpenAttack.attackers.PWWSAttacker()", "\n", "print", "(", "\"Build model\"", ")", "\n", "#clsf = OpenAttack.loadVictim(\"BERT.SST\")", "\n", "clsf", "=", "OpenAttack", ".", "DataManager", ".", "loadVictim", "(", "\"BERT.SST\"", ")", "\n", "#tokenizer = transformers.AutoTokenizer.from_pretrained(\"./data/Victim.BERT.SST\")", "\n", "#model = transformers.AutoModelForSequenceClassification.from_pretrained(\"./data/Victim.BERT.SST\", num_labels=2, output_hidden_states=True)", "\n", "#clsf = OpenAttack.classifiers.TransformersClassifier(model, tokenizer=tokenizer, max_length=100, embedding_layer=model.bert.embeddings.word_embeddings)", "\n", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:100]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "print", "(", "\"New Attacker\"", ")", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "UATAttacker", "(", ")", "\n", "attacker", ".", "set_triggers", "(", "clsf", ",", "dataset", ")", "\n", "print", "(", "\"Start attack\"", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "clsf", ",", "metrics", "=", "[", "\n", "OpenAttack", ".", "metric", ".", "Fluency", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "GrammaticalErrors", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "EditDistance", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "ModificationRate", "(", ")", "\n", "]", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ",", "progress_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses": [[4, 13], ["dir", "issubclass", "ret.append", "OpenAttack.attackers", "OpenAttack.ClassificationAttacker", "OpenAttack.victim.classifiers", "OpenAttack.victim.classifiers.Classifier", "OpenAttack.attack_assist.substitute.word", "OpenAttack.attack_assist.substitute.word.WordSubstitute", "OpenAttack.attack_assist.substitute.char", "OpenAttack.attack_assist.substitute.char.CharSubstitute", "OpenAttack.text_process.tokenizer", "OpenAttack.text_process.tokenizer.Tokenizer", "OpenAttack.text_process.lemmatizer", "OpenAttack.text_process.lemmatizer.Lemmatizer", "OpenAttack.text_process.constituency_parser", "OpenAttack.text_process.constituency_parser.ConstituencyParser"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.tokenizer"], ["def", "getSubClasses", "(", "module", ",", "clss", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "for", "name", "in", "dir", "(", "module", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "if", "issubclass", "(", "module", ".", "__dict__", "[", "name", "]", ",", "clss", ")", ":", "\n", "                ", "ret", ".", "append", "(", "name", ")", "\n", "", "", "except", "TypeError", ":", "\n", "            ", "continue", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getDocMembers": [[14, 22], ["dir", "kw.startswith", "ret.append"], "function", ["None"], ["", "def", "getDocMembers", "(", "clss", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "for", "kw", "in", "dir", "(", "clss", ")", ":", "\n", "        ", "if", "kw", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "continue", "\n", "", "if", "clss", ".", "__dict__", "[", "kw", "]", ".", "__doc__", "is", "not", "None", ":", "\n", "            ", "ret", ".", "append", "(", "kw", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_attacker": [[23, 46], ["build-doc.getSubClasses", "open().write", "open", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses"], ["", "def", "make_attacker", "(", "path", ")", ":", "\n", "    ", "addition_members", "=", "{", "\n", "\"UATAttacker\"", ":", "[", "\"get_triggers\"", "]", ",", "\n", "}", "\n", "opt", "=", "\"===================\\nAttackers API\\n===================\\n\\n\"", "\n", "\n", "opt", "+=", "\"Attacker\\n=============\\n\\n.. autoclass:: OpenAttack.Attacker\\n    :members:\\n\\n\"", "\n", "opt", "+=", "\"-\"", "*", "36", "+", "\"\\n\\n\"", "\n", "\n", "opt", "+=", "\"ClassificationAttacker\\n==============================\\n\\n.. autoclass:: OpenAttack.attackers.ClassificationAttacker\\n    :members:\\n\\n\"", "\n", "opt", "+=", "\"-\"", "*", "36", "+", "\"\\n\\n\"", "\n", "\n", "\n", "for", "name", "in", "getSubClasses", "(", "OpenAttack", ".", "attackers", ",", "OpenAttack", ".", "ClassificationAttacker", ")", ":", "\n", "        ", "if", "name", "==", "\"ClassificationAttacker\"", ":", "\n", "            ", "continue", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.attackers.%s(OpenAttack.attackers.ClassificationAttacker)\\n\"", "%", "name", "\n", "\n", "members", "=", "[", "\"__init__\"", "]", "+", "(", "addition_members", "[", "name", "]", "if", "name", "in", "addition_members", "else", "[", "]", ")", "\n", "opt", "+=", "\"    :members: \"", "+", "(", "\", \"", ".", "join", "(", "members", ")", ")", "+", "\"\\n\\n\"", "\n", "", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_attack_eval": [[47, 51], ["open().write", "open"], "function", ["None"], ["", "def", "make_attack_eval", "(", "path", ")", ":", "\n", "    ", "opt", "=", "\"========================\\nAttackEvals API\\n========================\\n\\n\"", "\n", "opt", "+=", "\"AttackEval\\n----------------\\n\\n.. autoclass:: OpenAttack.AttackEval\\n    :members: __init__, eval, ieval\\n\\n\"", "\n", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_victim": [[52, 73], ["build-doc.getSubClasses", "open().write", "open", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses"], ["", "def", "make_victim", "(", "path", ")", ":", "\n", "    ", "addition_members", "=", "{", "\n", "\"TransformersClassifier\"", ":", "[", "\"to\"", "]", ",", "\n", "}", "\n", "skip_list", "=", "{", "\"Classifier\"", "}", "\n", "\n", "opt", "=", "\"===================\\nVictims API\\n===================\\n\\n\"", "\n", "opt", "+=", "\"Classifier\\n===========================\\n\\n.. autoclass:: OpenAttack.victim.classifiers.Classifier\\n    :members:\\n\\n\"", "\n", "opt", "+=", "\"-\"", "*", "36", "+", "\"\\n\\n\"", "\n", "\n", "for", "name", "in", "getSubClasses", "(", "OpenAttack", ".", "victim", ".", "classifiers", ",", "OpenAttack", ".", "victim", ".", "classifiers", ".", "Classifier", ")", ":", "\n", "        ", "if", "name", "in", "skip_list", ":", "\n", "            ", "continue", "\n", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.classifiers.%s(OpenAttack.Classifier)\\n\"", "%", "name", "\n", "\n", "members", "=", "[", "\"__init__\"", "]", "+", "(", "addition_members", "[", "name", "]", "if", "name", "in", "addition_members", "else", "[", "]", ")", "\n", "opt", "+=", "\"    :members: \"", "+", "(", "\", \"", ".", "join", "(", "members", ")", ")", "+", "\"\\n\\n\"", "\n", "", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_data_manager": [[74, 78], ["open().write", "open"], "function", ["None"], ["", "def", "make_data_manager", "(", "path", ")", ":", "\n", "    ", "opt", "=", "\"===================\\nDataManager API\\n===================\\n\\n.. autoclass:: OpenAttack.DataManager\\n    :members:\"", "\n", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_data": [[79, 115], ["pkgutil.iter_modules", "cats.keys", "[].load_module", "open().write", "hasattr", "name.split", "cats[].append", "len", "open", "[].load_module.module_finder.find_loader", "os.path.join", "len"], "function", ["None"], ["", "def", "make_data", "(", "path", ")", ":", "\n", "    ", "import", "pkgutil", "\n", "cats", "=", "{", "\n", "\n", "}", "\n", "for", "data", "in", "pkgutil", ".", "iter_modules", "(", "OpenAttack", ".", "data", ".", "__path__", ")", ":", "\n", "        ", "data", "=", "data", ".", "module_finder", ".", "find_loader", "(", "data", ".", "name", ")", "[", "0", "]", ".", "load_module", "(", ")", "\n", "if", "hasattr", "(", "data", ",", "\"NAME\"", ")", "and", "(", "data", ".", "NAME", "in", "OpenAttack", ".", "DataManager", ".", "AVAILABLE_DATAS", ")", ":", "\n", "            ", "name", "=", "data", ".", "NAME", "\n", "if", "name", "==", "\"test\"", ":", "\n", "                ", "continue", "\n", "", "cat", "=", "name", ".", "split", "(", "\".\"", ")", "\n", "if", "len", "(", "cat", ")", "==", "1", ":", "\n", "                ", "continue", "\n", "", "name", "=", "\".\"", ".", "join", "(", "cat", "[", "1", ":", "]", ")", "\n", "cat", "=", "cat", "[", "0", "]", "\n", "pack", "=", "data", ".", "__name__", "\n", "\n", "if", "cat", "not", "in", "cats", ":", "\n", "                ", "cats", "[", "cat", "]", "=", "[", "]", "\n", "", "cats", "[", "cat", "]", ".", "append", "(", "{", "\n", "\"name\"", ":", "name", ",", "\n", "\"package\"", ":", "pack", "\n", "}", ")", "\n", "\n", "\n", "\n", "", "", "for", "cat", "in", "cats", ".", "keys", "(", ")", ":", "\n", "        ", "opt", "=", "\"=====================\\n%s\\n=====================\\n\\n\"", "%", "cat", "\n", "opt", "+=", "\".. _label-data-%s:\\n\\n\"", "%", "cat", "\n", "for", "data", "in", "cats", "[", "cat", "]", ":", "\n", "            ", "opt", "+=", "data", "[", "\"name\"", "]", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "data", "[", "\"name\"", "]", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. py:data:: \"", "+", "cat", "+", "\".\"", "+", "data", "[", "\"name\"", "]", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\"    .. automodule:: OpenAttack.data.\"", "+", "data", "[", "\"package\"", "]", "+", "\"\\n\\n\"", "\n", "", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "cat", "+", "\".rst\"", ")", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_metric": [[116, 169], ["dir", "open().write", "isinstance", "hasattr", "issubclass", "open", "metrics.append", "issubclass", "selector.append", "len", "len"], "function", ["None"], ["", "def", "make_metric", "(", "path", ")", ":", "\n", "    ", "opt", "=", "\"==================\\nMetric API\\n==================\\n\\n\"", "\n", "\n", "\n", "metrics", "=", "[", "]", "\n", "selector", "=", "[", "]", "\n", "for", "name", "in", "dir", "(", "OpenAttack", ".", "metric", ")", ":", "\n", "        ", "if", "isinstance", "(", "OpenAttack", ".", "metric", ".", "__dict__", "[", "name", "]", ",", "type", ")", ":", "\n", "            ", "if", "issubclass", "(", "OpenAttack", ".", "metric", ".", "__dict__", "[", "name", "]", ",", "OpenAttack", ".", "metric", ".", "AttackMetric", ")", ":", "\n", "                ", "if", "name", "==", "\"AttackMetric\"", ":", "\n", "                    ", "continue", "\n", "", "metrics", ".", "append", "(", "name", ")", "\n", "", "elif", "issubclass", "(", "OpenAttack", ".", "metric", ".", "__dict__", "[", "name", "]", ",", "OpenAttack", ".", "metric", ".", "MetricSelector", ")", ":", "\n", "                ", "if", "name", "==", "\"MetricSelector\"", ":", "\n", "                    ", "continue", "\n", "", "selector", ".", "append", "(", "name", ")", "\n", "\n", "", "", "", "opt", "+=", "\"\"\"Attacker Metrics\n==================\n\n.. autoclass:: OpenAttack.metric.AttackMetric\n    :members:\n\n\n\"\"\"", "\n", "\n", "for", "name", "in", "metrics", ":", "\n", "        ", "cls", "=", "OpenAttack", ".", "metric", ".", "__dict__", "[", "name", "]", "\n", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.metric.\"", "+", "name", "+", "\"\\n\"", "\n", "if", "hasattr", "(", "cls", ",", "\"calc_score\"", ")", ":", "\n", "            ", "opt", "+=", "\"    :members: __init__, calc_score\"", "+", "\"\\n\"", "\n", "", "else", ":", "\n", "            ", "opt", "+=", "\"    :members: __init__\"", "+", "\"\\n\"", "\n", "", "opt", "+=", "\"    :exclude-members: TAGS\"", "+", "\"\\n\\n\"", "\n", "\n", "", "opt", "+=", "\"\"\"Metrics Selector\n=======================\n\n.. autoclass:: OpenAttack.metric.MetricSelector\n    :members:\n\n\n\"\"\"", "\n", "\n", "for", "name", "in", "selector", ":", "\n", "        ", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.metric.\"", "+", "name", "+", "\"\\n\"", "\n", "opt", "+=", "\"    :members: \"", "+", "\"\\n\"", "\n", "opt", "+=", "\"    :exclude-members: TAGS\"", "+", "\"\\n\\n\"", "\n", "\n", "", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_substitute": [[170, 214], ["build-doc.getSubClasses", "getSubClasses.index", "build-doc.getSubClasses", "open().write", "open", "len", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses"], ["", "def", "make_substitute", "(", "path", ")", ":", "\n", "    ", "opt", "=", "\"======================\\nSubstitutes API\\n======================\\n\\n\"", "\n", "opt", "+=", "\"\"\"\n\nAbstract Classes\n------------------------\n\n.. autoclass:: OpenAttack.attack_assist.substitute.word.WordSubstitute\n    :members: __call__\n\n.. autoclass:: OpenAttack.attack_assist.substitute.char.CharSubstitute\n    :members: __call__\n\n-------------------------------------------------------------------------------\n\n\n\"\"\"", "\n", "subs", "=", "getSubClasses", "(", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "word", ",", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "word", ".", "WordSubstitute", ")", "\n", "embed_based_idx", "=", "subs", ".", "index", "(", "\"EmbedBasedSubstitute\"", ")", "\n", "if", "embed_based_idx", "!=", "-", "1", ":", "\n", "        ", "subs", "[", "0", "]", ",", "subs", "[", "embed_based_idx", "]", "=", "subs", "[", "embed_based_idx", "]", ",", "subs", "[", "0", "]", "\n", "\n", "", "for", "name", "in", "subs", ":", "\n", "        ", "cls", "=", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "word", ".", "__dict__", "[", "name", "]", "\n", "if", "cls", "is", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "word", ".", "WordSubstitute", ":", "\n", "            ", "continue", "\n", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.attack_assist.substitute.word.%s(OpenAttack.attack_assist.substitute.word.WordSubstitute)\\n\"", "%", "name", "\n", "opt", "+=", "\"    :members: __init__\\n\\n\"", "\n", "\n", "", "subs", "=", "getSubClasses", "(", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "char", ",", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "char", ".", "CharSubstitute", ")", "\n", "\n", "for", "name", "in", "subs", ":", "\n", "        ", "cls", "=", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "char", ".", "__dict__", "[", "name", "]", "\n", "if", "cls", "is", "OpenAttack", ".", "attack_assist", ".", "substitute", ".", "char", ".", "CharSubstitute", ":", "\n", "            ", "continue", "\n", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.attack_assist.substitute.char.%s(OpenAttack.attack_assist.substitute.char.CharSubstitute)\\n\"", "%", "name", "\n", "opt", "+=", "\"    :members: __init__\\n\\n\"", "\n", "\n", "", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_text_processor": [[215, 268], ["build-doc.getSubClasses", "build-doc.getSubClasses", "build-doc.getSubClasses", "open().write", "open", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.getSubClasses"], ["", "def", "make_text_processor", "(", "path", ")", ":", "\n", "    ", "opt", "=", "\"========================\\nText Processors API\\n========================\\n\\n\"", "\n", "opt", "+=", "\"Tokenizers\\n============================\\n\\n\"", "\n", "opt", "+=", "\"\"\"\n.. autoclass:: OpenAttack.text_process.tokenizer.Tokenizer\n    :members: tokenize, detokenize\n\n\"\"\"", "\n", "\n", "import", "OpenAttack", ".", "text_process", ".", "tokenizer", "\n", "\n", "for", "name", "in", "getSubClasses", "(", "OpenAttack", ".", "text_process", ".", "tokenizer", ",", "OpenAttack", ".", "text_process", ".", "tokenizer", ".", "Tokenizer", ")", ":", "\n", "        ", "if", "name", "==", "\"Tokenizer\"", ":", "\n", "            ", "continue", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.text_process.tokenizer.%s(OpenAttack.text_process.tokenizer.Tokenizer)\\n\"", "%", "name", "\n", "opt", "+=", "\"    :members:\\n\\n\"", "\n", "\n", "\n", "", "import", "OpenAttack", ".", "text_process", ".", "lemmatizer", "\n", "\n", "opt", "+=", "\"Lemmatizer\\n============================\\n\\n\"", "\n", "opt", "+=", "\"\"\"\n.. autoclass:: OpenAttack.text_process.lemmatizer.Lemmatizer\n    :members: lemmatize, delemmatize\n\n\"\"\"", "\n", "for", "name", "in", "getSubClasses", "(", "OpenAttack", ".", "text_process", ".", "lemmatizer", ",", "OpenAttack", ".", "text_process", ".", "lemmatizer", ".", "Lemmatizer", ")", ":", "\n", "        ", "if", "name", "==", "\"Lemmatizer\"", ":", "\n", "            ", "continue", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.text_process.lemmatizer.%s(OpenAttack.text_process.lemmatizer.Lemmatizer)\\n\"", "%", "name", "\n", "opt", "+=", "\"    :members:\\n\\n\"", "\n", "\n", "\n", "", "import", "OpenAttack", ".", "text_process", ".", "constituency_parser", "\n", "\n", "opt", "+=", "\"ConstituencyParser\\n============================\\n\\n\"", "\n", "opt", "+=", "\"\"\"\n.. autoclass:: OpenAttack.text_process.constituency_parser.ConstituencyParser\n    :members: __call__\n\n\"\"\"", "\n", "for", "name", "in", "getSubClasses", "(", "OpenAttack", ".", "text_process", ".", "constituency_parser", ",", "OpenAttack", ".", "text_process", ".", "constituency_parser", ".", "ConstituencyParser", ")", ":", "\n", "        ", "if", "name", "==", "\"ConstituencyParser\"", ":", "\n", "            ", "continue", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "opt", "+=", "\".. autoclass:: OpenAttack.text_process.constituency_parser.%s(OpenAttack.text_process.constituency_parser.ConstituencyParser)\\n\"", "%", "name", "\n", "opt", "+=", "\"    :members:\\n\\n\"", "\n", "\n", "\n", "", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_utils": [[269, 285], ["OpenAttack.utils.__dir__", "open().write", "name.startswith", "open", "type", "type", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type"], ["", "def", "make_utils", "(", "path", ")", ":", "\n", "    ", "opt", "=", "\"=====================\\nutils API\\n=====================\\n\\n\"", "\n", "for", "name", "in", "OpenAttack", ".", "utils", ".", "__dir__", "(", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "\"__\"", ")", ":", "\n", "            ", "continue", "\n", "", "obj", "=", "OpenAttack", ".", "utils", ".", "__dict__", "[", "name", "]", "\n", "if", "type", "(", "obj", ")", ".", "__name__", "==", "\"module\"", ":", "\n", "            ", "continue", "\n", "", "opt", "+=", "name", "+", "\"\\n\"", "+", "(", "\"-\"", "*", "(", "2", "+", "len", "(", "name", ")", ")", ")", "+", "\"\\n\\n\"", "\n", "if", "type", "(", "obj", ")", ".", "__name__", "==", "\"function\"", ":", "\n", "            ", "opt", "+=", "\".. autofunction:: OpenAttack.utils.\"", "+", "name", "+", "\"\\n\\n\"", "\n", "", "else", ":", "\n", "            ", "opt", "+=", "\".. autoclass:: OpenAttack.utils.\"", "+", "name", "+", "\"\\n\"", "\n", "opt", "+=", "\"    :members: \"", "+", "\"\\n\\n\"", "\n", "", "", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "write", "(", "opt", ")", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.main": [[286, 296], ["build-doc.make_attacker", "build-doc.make_attack_eval", "build-doc.make_victim", "build-doc.make_data_manager", "build-doc.make_data", "build-doc.make_metric", "build-doc.make_substitute", "build-doc.make_text_processor", "build-doc.make_utils", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_attacker", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_attack_eval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_victim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_data_manager", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_data", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_metric", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_text_processor", "home.repos.pwc.inspect_result.thunlp_OpenAttack.None.build-doc.make_utils"], ["", "def", "main", "(", "path", ")", ":", "\n", "    ", "make_attacker", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"attacker.rst\"", ")", ")", "\n", "make_attack_eval", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"attack_eval.rst\"", ")", ")", "\n", "make_victim", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"victim.rst\"", ")", ")", "\n", "make_data_manager", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"data_manager.rst\"", ")", ")", "\n", "make_data", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"..\"", ",", "\"data\"", ")", ")", "\n", "make_metric", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"metric.rst\"", ")", ")", "\n", "make_substitute", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"substitute.rst\"", ")", ")", "\n", "make_text_processor", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"text_processor.rst\"", ")", ")", "\n", "make_utils", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"utils.rst\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_default_text_processor.TestDataManager.test_tokenize": [[7, 18], ["PunctTokenizer", "PunctTokenizer.tokenize", "test_default_text_processor.TestDataManager.assertIsInstance", "test_default_text_processor.TestDataManager.assertGreater", "range", "test_default_text_processor.TestDataManager.assertIsInstance", "len", "len", "test_default_text_processor.TestDataManager.assertEqual", "test_default_text_processor.TestDataManager.assertIsInstance", "test_default_text_processor.TestDataManager.assertIsInstance", "PunctTokenizer.detokenize", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], ["    ", "def", "test_tokenize", "(", "self", ")", ":", "\n", "        ", "from", "OpenAttack", ".", "text_process", ".", "tokenizer", "import", "PunctTokenizer", "\n", "tokenizer", "=", "PunctTokenizer", "(", ")", "\n", "ret", "=", "tokenizer", ".", "tokenize", "(", "\"This is an apple.\"", ")", "\n", "self", ".", "assertIsInstance", "(", "ret", ",", "list", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "ret", ")", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ret", ")", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "len", "(", "ret", "[", "i", "]", ")", ",", "2", ")", "\n", "self", ".", "assertIsInstance", "(", "ret", "[", "i", "]", "[", "0", "]", ",", "str", ")", "\n", "self", ".", "assertIsInstance", "(", "ret", "[", "i", "]", "[", "1", "]", ",", "str", ")", "\n", "", "self", ".", "assertIsInstance", "(", "tokenizer", ".", "detokenize", "(", "ret", ")", ",", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_default_text_processor.TestDataManager.test_lemma": [[19, 34], ["WordnetLemmatimer", "WordnetLemmatimer.delemmatize", "test_default_text_processor.TestDataManager.assertEqual", "WordnetLemmatimer.delemmatize", "test_default_text_processor.TestDataManager.assertEqual", "WordnetLemmatimer.lemmatize", "test_default_text_processor.TestDataManager.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.base.Lemmatizer.delemmatize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.base.Lemmatizer.delemmatize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.base.Lemmatizer.lemmatize"], ["", "def", "test_lemma", "(", "self", ")", ":", "\n", "        ", "from", "OpenAttack", ".", "text_process", ".", "lemmatizer", "import", "WordnetLemmatimer", "\n", "\n", "lemmatizer", "=", "WordnetLemmatimer", "(", ")", "\n", "test_cases", "=", "[", "(", "'There'", ",", "'other'", ")", ",", "(", "'were'", ",", "'verb'", ")", ",", "(", "'apples'", ",", "'noun'", ")", ",", "(", "'.'", ",", "'other'", ")", "]", "\n", "for", "case", "in", "test_cases", ":", "\n", "            ", "ret", "=", "lemmatizer", ".", "lemmatize", "(", "case", "[", "0", "]", ",", "case", "[", "1", "]", ")", "\n", "\n", "self", ".", "assertIsInstance", "(", "ret", ",", "str", ")", "\n", "\n", "", "ret", "=", "lemmatizer", ".", "delemmatize", "(", "\"apples\"", ",", "\"noun\"", ")", "\n", "self", ".", "assertEqual", "(", "ret", ",", "\"apples\"", ")", "\n", "\n", "ret", "=", "lemmatizer", ".", "delemmatize", "(", "\"apple\"", ",", "\"noun\"", ")", "\n", "self", ".", "assertEqual", "(", "ret", ",", "\"apples\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.run_test.main": [[4, 13], ["os.path.dirname", "unittest.defaultTestLoader.discover", "unittest.runner.TextTestRunner", "unittest.runner.TextTestRunner.run", "sys.exit", "os.path.abspath", "len", "len"], "function", ["None"], ["def", "main", "(", "args", ",", ")", ":", "\n", "    ", "import", "unittest", "\n", "import", "os", ",", "sys", "\n", "\n", "TEST_BASE", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "test_cases", "=", "unittest", ".", "defaultTestLoader", ".", "discover", "(", "TEST_BASE", ",", "pattern", "=", "args", ".", "file", ")", "\n", "runner", "=", "unittest", ".", "runner", ".", "TextTestRunner", "(", "verbosity", "=", "args", ".", "verbosity", ")", "\n", "ret", "=", "runner", ".", "run", "(", "test_cases", ")", "\n", "sys", ".", "exit", "(", "len", "(", "ret", ".", "failures", ")", "+", "len", "(", "ret", ".", "errors", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_meta_classifier.MetaClassifier.__init__": [[6, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "last_meta", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_meta_classifier.MetaClassifier.get_pred": [[9, 11], ["test_meta_classifier.MetaClassifier.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["", "def", "get_pred", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "self", ".", "get_prob", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_meta_classifier.MetaClassifier.get_prob": [[12, 14], ["test_meta_classifier.MetaClassifier.get_grad"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad"], ["", "def", "get_prob", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "self", ".", "get_grad", "(", "[", "input_", "]", ",", "[", "0", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_meta_classifier.MetaClassifier.get_grad": [[15, 18], ["numpy.array"], "methods", ["None"], ["", "def", "get_grad", "(", "self", ",", "input_", ",", "labels", ")", ":", "\n", "        ", "self", ".", "last_meta", "=", "self", ".", "context", ".", "input", "\n", "return", "np", ".", "array", "(", "[", "[", "1", ",", "2", ",", "3", "]", "]", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_meta_classifier.TestMetaClassifier.test_get_pred": [[20, 37], ["test_meta_classifier.MetaClassifier", "test_meta_classifier.TestMetaClassifier.assertIsNone", "test_meta_classifier.TestMetaClassifier.assertIsNone", "MetaClassifier.set_context", "test_meta_classifier.MetaClassifier.get_pred", "test_meta_classifier.TestMetaClassifier.assertDictEqual", "MetaClassifier.set_context", "test_meta_classifier.MetaClassifier.get_pred", "test_meta_classifier.TestMetaClassifier.assertDictEqual", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_pred", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_pred", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_pred"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], ["    ", "def", "test_get_pred", "(", "self", ")", ":", "\n", "        ", "clsf", "=", "MetaClassifier", "(", ")", "\n", "self", ".", "assertIsNone", "(", "clsf", ".", "last_meta", ")", "\n", "\n", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_pred", "(", "\"I love apples\"", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_pred", "(", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_pred", "(", "[", "\"I love apples\"", "]", ",", "\"b\"", ",", "\"c\"", ")", "\n", "", "self", ".", "assertIsNone", "(", "clsf", ".", "last_meta", ")", "\n", "clsf", ".", "set_context", "(", "{", "}", ",", "None", ")", "\n", "clsf", ".", "get_pred", "(", "[", "\"I love apples\"", "]", ")", "\n", "self", ".", "assertDictEqual", "(", "clsf", ".", "last_meta", ",", "{", "}", ")", "\n", "clsf", ".", "set_context", "(", "{", "\"THIS\"", ":", "\"that\"", "}", ",", "None", ")", "\n", "clsf", ".", "get_pred", "(", "[", "\"I love apples\"", "]", ")", "\n", "self", ".", "assertDictEqual", "(", "clsf", ".", "last_meta", ",", "{", "\"THIS\"", ":", "\"that\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_meta_classifier.TestMetaClassifier.test_get_prob": [[38, 54], ["test_meta_classifier.MetaClassifier", "test_meta_classifier.TestMetaClassifier.assertIsNone", "test_meta_classifier.TestMetaClassifier.assertIsNone", "MetaClassifier.set_context", "test_meta_classifier.MetaClassifier.get_prob", "test_meta_classifier.TestMetaClassifier.assertDictEqual", "MetaClassifier.set_context", "test_meta_classifier.MetaClassifier.get_prob", "test_meta_classifier.TestMetaClassifier.assertDictEqual", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_prob", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_prob", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["", "def", "test_get_prob", "(", "self", ")", ":", "\n", "        ", "clsf", "=", "MetaClassifier", "(", ")", "\n", "self", ".", "assertIsNone", "(", "clsf", ".", "last_meta", ")", "\n", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_prob", "(", "\"I love apples\"", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_prob", "(", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_prob", "(", "[", "\"I love apples\"", "]", ",", "\"b\"", ",", "\"c\"", ")", "\n", "", "self", ".", "assertIsNone", "(", "clsf", ".", "last_meta", ")", "\n", "clsf", ".", "set_context", "(", "{", "}", ",", "None", ")", "\n", "clsf", ".", "get_prob", "(", "[", "\"I love apples\"", "]", ")", "\n", "self", ".", "assertDictEqual", "(", "clsf", ".", "last_meta", ",", "{", "}", ")", "\n", "clsf", ".", "set_context", "(", "{", "\"THIS\"", ":", "\"that\"", "}", ",", "None", ")", "\n", "clsf", ".", "get_prob", "(", "[", "\"I love apples\"", "]", ")", "\n", "self", ".", "assertDictEqual", "(", "clsf", ".", "last_meta", ",", "{", "\"THIS\"", ":", "\"that\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.test.test_meta_classifier.TestMetaClassifier.test_get_grad": [[55, 73], ["test_meta_classifier.MetaClassifier", "test_meta_classifier.TestMetaClassifier.assertIsNone", "test_meta_classifier.TestMetaClassifier.assertIsNone", "MetaClassifier.set_context", "test_meta_classifier.MetaClassifier.get_grad", "test_meta_classifier.TestMetaClassifier.assertDictEqual", "MetaClassifier.set_context", "test_meta_classifier.MetaClassifier.get_grad", "test_meta_classifier.TestMetaClassifier.assertDictEqual", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_grad", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_grad", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_grad", "test_meta_classifier.TestMetaClassifier.assertRaises", "test_meta_classifier.MetaClassifier.get_grad"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad"], ["", "def", "test_get_grad", "(", "self", ")", ":", "\n", "        ", "clsf", "=", "MetaClassifier", "(", ")", "\n", "self", ".", "assertIsNone", "(", "clsf", ".", "last_meta", ")", "\n", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_grad", "(", "\"I love apples\"", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_grad", "(", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_grad", "(", "[", "\"I love apples\"", "]", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "TypeError", ")", ":", "\n", "            ", "clsf", ".", "get_grad", "(", "[", "\"I love apples\"", "]", ",", "\"b\"", ",", "\"c\"", ",", "\"d\"", ")", "\n", "", "self", ".", "assertIsNone", "(", "clsf", ".", "last_meta", ")", "\n", "clsf", ".", "set_context", "(", "{", "}", ",", "None", ")", "\n", "clsf", ".", "get_grad", "(", "[", "[", "\"I\"", ",", "\"love\"", ",", "\"apples\"", "]", "]", ",", "[", "0", "]", ")", "\n", "self", ".", "assertDictEqual", "(", "clsf", ".", "last_meta", ",", "{", "}", ")", "\n", "clsf", ".", "set_context", "(", "{", "\"THIS\"", ":", "\"that\"", "}", ",", "None", ")", "\n", "clsf", ".", "get_grad", "(", "[", "[", "\"I\"", ",", "\"love\"", ",", "\"apples\"", "]", "]", ",", "[", "0", "]", ")", "\n", "self", ".", "assertDictEqual", "(", "clsf", ".", "last_meta", ",", "{", "\"THIS\"", ":", "\"that\"", "}", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.chinese.dataset_mapping": [[7, 11], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"review_body\"", "]", ",", "\n", "\"y\"", ":", "x", "[", "\"stars\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.chinese.main": [[13, 26], ["print", "OpenAttack.attackers.PWWSAttacker", "print", "OpenAttack.loadVictim().to", "print", "datasets.load_dataset().map", "print", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "OpenAttack.loadVictim", "datasets.load_dataset"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim"], ["", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"New Attacker\"", ")", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", "lang", "=", "\"chinese\"", ")", "\n", "\n", "print", "(", "\"Building model\"", ")", "\n", "victim", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.AMAZON_ZH\"", ")", ".", "to", "(", "\"cuda:0\"", ")", "\n", "\n", "print", "(", "\"Loading dataset\"", ")", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"amazon_reviews_multi\"", ",", "'zh'", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "\n", "print", "(", "\"Start attack\"", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ",", "progress_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_metrics.SentenceLength.after_attack": [[11, 14], ["len", "input[].split"], "methods", ["None"], ["def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "# returns the length of input sentence", "\n", "        ", "return", "len", "(", "input", "[", "\"x\"", "]", ".", "split", "(", "\" \"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_metrics.dataset_mapping": [[15, 19], ["None"], "function", ["None"], ["", "", "def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_metrics.main": [[21, 30], ["OpenAttack.loadVictim", "datasets.load_dataset().map", "OpenAttack.attackers.PWWSAttacker", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset", "custom_metrics.SentenceLength"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "victim", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.SST\"", ")", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ",", "metrics", "=", "[", "\n", "SentenceLength", "(", ")", "\n", "]", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_dataset.main": [[8, 36], ["print", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "OpenAttack.classifiers.TransformersClassifier", "print", "OpenAttack.attackers.PWWSAttacker", "datasets.Dataset.from_dict", "print", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "OpenAttack.metric.EditDistance", "OpenAttack.metric.ModificationRate"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["def", "main", "(", ")", ":", "\n", "# load a fine-tuned sentiment analysis model from Transformers (you can also use our fine-tuned Victim.BERT.SST)", "\n", "    ", "print", "(", "\"Load model\"", ")", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "\"echarlaix/bert-base-uncased-sst2-acc91.1-d37-hybrid\"", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\"echarlaix/bert-base-uncased-sst2-acc91.1-d37-hybrid\"", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "victim", "=", "OpenAttack", ".", "classifiers", ".", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n", "print", "(", "\"New Attacker\"", ")", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", "\n", "\n", "# create your dataset here", "\n", "dataset", "=", "datasets", ".", "Dataset", ".", "from_dict", "(", "{", "\n", "\"x\"", ":", "[", "\n", "\"I hate this movie.\"", ",", "\n", "\"I like this apple.\"", "\n", "]", ",", "\n", "\"y\"", ":", "[", "\n", "0", ",", "# 0 for negative", "\n", "1", ",", "# 1 for positive", "\n", "]", "\n", "}", ")", "\n", "\n", "print", "(", "\"Start attack\"", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ",", "metrics", "=", "[", "\n", "OpenAttack", ".", "metric", ".", "EditDistance", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "ModificationRate", "(", ")", "\n", "]", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_victim.MyClassifier.__init__": [[13, 17], ["nltk.download", "nltk.sentiment.vader.SentimentIntensityAnalyzer"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# nltk.sentiment.vader.SentimentIntensityAnalyzer is a traditional sentiment classification model.", "\n", "        ", "nltk", ".", "download", "(", "'vader_lexicon'", ")", "\n", "self", ".", "model", "=", "SentimentIntensityAnalyzer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_victim.MyClassifier.get_pred": [[18, 20], ["custom_victim.MyClassifier.get_prob().argmax", "custom_victim.MyClassifier.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["", "def", "get_pred", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "self", ".", "get_prob", "(", "input_", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_victim.MyClassifier.get_prob": [[22, 36], ["numpy.array", "custom_victim.MyClassifier.model.polarity_scores", "ret.append", "numpy.array"], "methods", ["None"], ["", "def", "get_prob", "(", "self", ",", "input_", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "sent", "in", "input_", ":", "\n", "# SentimentIntensityAnalyzer calculates scores of \u201cneg\u201d and \u201cpos\u201d for each instance", "\n", "            ", "res", "=", "self", ".", "model", ".", "polarity_scores", "(", "sent", ")", "\n", "\n", "# we use \ud835\udc60\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc52_\ud835\udc5d\ud835\udc5c\ud835\udc60 / (\ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_\ud835\udc5b\ud835\udc52\ud835\udc54 + \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52_\ud835\udc5d\ud835\udc5c\ud835\udc60) to represent the probability of positive sentiment", "\n", "# Adding 10^\u22126 is a trick to avoid dividing by zero.", "\n", "prob", "=", "(", "res", "[", "\"pos\"", "]", "+", "1e-6", ")", "/", "(", "res", "[", "\"neg\"", "]", "+", "res", "[", "\"pos\"", "]", "+", "2e-6", ")", "\n", "\n", "ret", ".", "append", "(", "np", ".", "array", "(", "[", "1", "-", "prob", ",", "prob", "]", ")", ")", "\n", "\n", "# The get_prob method finally returns a np.ndarray of shape (len(input_), 2). See Classifier for detail.", "\n", "", "return", "np", ".", "array", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_victim.dataset_mapping": [[37, 41], ["None"], "function", ["None"], ["", "", "def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_victim.main": [[43, 54], ["datasets.load_dataset().map", "custom_victim.MyClassifier", "OpenAttack.attackers.UATAttacker", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "# load some examples of SST-2 for evaluation", "\n", "    ", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "# choose the costomized classifier as the victim model", "\n", "victim", "=", "MyClassifier", "(", ")", "\n", "# choose PWWS as the attacker and initialize it with default parameters", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "UATAttacker", "(", ")", "\n", "# prepare for attacking", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ")", "\n", "# launch attacks and print attack results ", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.multiprocess_eval.dataset_mapping": [[7, 11], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.multiprocess_eval.main": [[14, 29], ["OpenAttack.loadVictim", "datasets.load_dataset().map", "OpenAttack.attackers.GeneticAttacker", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "victim", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.SST\"", ")", "\n", "# Victim.BiLSTM.SST is a pytorch model which is trained on Dataset.SST. It uses Glove vectors for word representation.", "\n", "# The load operation returns a PytorchClassifier that can be further used for Attacker and AttackEval.", "\n", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "# Dataset.SST.sample is a list of 1k sentences sampled from test dataset of Dataset.SST.", "\n", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "GeneticAttacker", "(", ")", "\n", "# After this step, we\u2019ve initialized a GeneticAttacker and uses the default configuration during attack process.", "\n", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ")", "\n", "# DefaultAttackEval is the default implementation for AttackEval which supports seven basic metrics.", "\n", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ",", "num_workers", "=", "4", ")", "\n", "# Using multiprocessing by specify num_workers", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_attacker.MyAttacker.TAGS": [[12, 16], ["OpenAttack.tags.Tag"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "# returns tags can help OpenAttack to check your parameters automatically", "\n", "        ", "return", "{", "self", ".", "lang_tag", ",", "Tag", "(", "\"get_pred\"", ",", "\"victim\"", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_attacker.MyAttacker.__init__": [[17, 22], ["OpenAttack.utils.get_language", "OpenAttack.text_process.tokenizer.PunctTokenizer"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language"], ["", "def", "__init__", "(", "self", ",", "tokenizer", "=", "None", ")", ":", "\n", "        ", "if", "tokenizer", "is", "None", ":", "\n", "            ", "tokenizer", "=", "PunctTokenizer", "(", ")", "\n", "", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "lang_tag", "=", "OpenAttack", ".", "utils", ".", "get_language", "(", "[", "self", ".", "tokenizer", "]", ")", "\n", "# We add parameter ``processor`` to specify the :py:class:`.TextProcessor` which is used for tokenization and detokenization.", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_attacker.MyAttacker.attack": [[25, 39], ["custom_attacker.MyAttacker.tokenizer.detokenize", "victim.get_pred", "goal.check", "custom_attacker.MyAttacker.swap", "custom_attacker.MyAttacker.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.swap", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "attack", "(", "self", ",", "victim", ",", "input_", ",", "goal", ")", ":", "\n", "# Generate a potential adversarial example", "\n", "        ", "x_new", "=", "self", ".", "tokenizer", ".", "detokenize", "(", "\n", "self", ".", "swap", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "input_", ",", "pos_tagging", "=", "False", ")", ")", "\n", ")", "\n", "\n", "# Get the preidictions of victim classifier", "\n", "y_new", "=", "victim", ".", "get_pred", "(", "[", "x_new", "]", ")", "\n", "\n", "# Check for attack goal", "\n", "if", "goal", ".", "check", "(", "x_new", ",", "y_new", ")", ":", "\n", "            ", "return", "x_new", "\n", "# Failed", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_attacker.MyAttacker.swap": [[40, 46], ["random.shuffle"], "methods", ["None"], ["", "def", "swap", "(", "self", ",", "sentence", ")", ":", "\n", "# Shuffle tokens to generate a potential adversarial example", "\n", "        ", "random", ".", "shuffle", "(", "sentence", ")", "\n", "\n", "# Return the potential adversarial example", "\n", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_attacker.dataset_mapping": [[47, 51], ["None"], "function", ["None"], ["", "", "def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.custom_attacker.main": [[53, 60], ["OpenAttack.loadVictim", "datasets.load_dataset().map", "custom_attacker.MyAttacker", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "victim", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.SST\"", ")", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:10]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "\n", "attacker", "=", "MyAttacker", "(", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.MyClassifier.__init__": [[15, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "vocab", ")", "->", "None", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.MyClassifier.get_prob": [[19, 26], ["torch.no_grad", "adversarial_training.make_batch_tokens", "torch.LongTensor", "adversarial_training.MyClassifier.model().cpu().numpy", "tokenizer.tokenize", "adversarial_training.MyClassifier.model().cpu", "adversarial_training.MyClassifier.model"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.make_batch_tokens", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "get_prob", "(", "self", ",", "sentences", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "token_ids", "=", "make_batch_tokens", "(", "[", "\n", "tokenizer", ".", "tokenize", "(", "sent", ",", "pos_tagging", "=", "False", ")", "for", "sent", "in", "sentences", "\n", "]", ",", "self", ".", "vocab", ")", "\n", "token_ids", "=", "torch", ".", "LongTensor", "(", "token_ids", ")", "\n", "return", "self", ".", "model", "(", "token_ids", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.MyClassifier.get_pred": [[27, 29], ["adversarial_training.MyClassifier.get_prob().argmax", "adversarial_training.MyClassifier.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["", "", "def", "get_pred", "(", "self", ",", "sentences", ")", ":", "\n", "        ", "return", "self", ".", "get_prob", "(", "sentences", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.make_model": [[32, 55], ["TextSentiment", "super().__init__", "nn.EmbeddingBag", "nn.Linear", "nn.Softmax", "adversarial_training..init_weights", "adversarial_training..embedding.weight.data.uniform_", "adversarial_training..fc.weight.data.uniform_", "adversarial_training..fc.bias.data.zero_", "adversarial_training..embedding", "adversarial_training..softmax", "adversarial_training..fc"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], ["", "", "def", "make_model", "(", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    see `tutorial - pytorch <https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html#define-the-model>`__\n    \"\"\"", "\n", "import", "torch", ".", "nn", "as", "nn", "\n", "class", "TextSentiment", "(", "nn", ".", "Module", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embed_dim", "=", "32", ",", "num_class", "=", "2", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "EmbeddingBag", "(", "vocab_size", ",", "embed_dim", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "num_class", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "", "def", "init_weights", "(", "self", ")", ":", "\n", "            ", "initrange", "=", "0.5", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "fc", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "fc", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "text", ")", ":", "\n", "            ", "embedded", "=", "self", ".", "embedding", "(", "text", ",", "None", ")", "\n", "return", "self", ".", "softmax", "(", "self", ".", "fc", "(", "embedded", ")", ")", "\n", "", "", "return", "TextSentiment", "(", "vocab_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.dataset_mapping": [[56, 61], ["tokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "\"tokens\"", ":", "tokenizer", ".", "tokenize", "(", "x", "[", "\"sentence\"", "]", ",", "pos_tagging", "=", "False", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.prepare_data": [[64, 76], ["datasets.load_dataset().map().remove_columns", "datasets.load_dataset().map", "datasets.load_dataset", "len"], "function", ["None"], ["", "def", "prepare_data", "(", ")", ":", "\n", "    ", "vocab", "=", "{", "\n", "\"<UNK>\"", ":", "0", ",", "\n", "\"<PAD>\"", ":", "1", "\n", "}", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", ".", "remove_columns", "(", "[", "\"label\"", ",", "\"sentence\"", ",", "\"tree\"", "]", ")", "\n", "for", "dataset_name", "in", "[", "\"train\"", ",", "\"validation\"", ",", "\"test\"", "]", ":", "\n", "        ", "for", "inst", "in", "dataset", "[", "dataset_name", "]", ":", "\n", "            ", "for", "token", "in", "inst", "[", "\"tokens\"", "]", ":", "\n", "                ", "if", "token", "not", "in", "vocab", ":", "\n", "                    ", "vocab", "[", "token", "]", "=", "len", "(", "vocab", ")", "\n", "", "", "", "", "return", "dataset", "[", "\"train\"", "]", ",", "dataset", "[", "\"validation\"", "]", ",", "dataset", "[", "\"test\"", "]", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.make_batch_tokens": [[77, 90], ["max", "len", "len"], "function", ["None"], ["", "def", "make_batch_tokens", "(", "tokens_list", ",", "vocab", ")", ":", "\n", "    ", "batch_x", "=", "[", "\n", "[", "\n", "vocab", "[", "token", "]", "if", "token", "in", "vocab", "else", "vocab", "[", "\"<UNK>\"", "]", "\n", "for", "token", "in", "tokens", "\n", "]", "for", "tokens", "in", "tokens_list", "\n", "]", "\n", "max_len", "=", "max", "(", "[", "len", "(", "tokens", ")", "for", "tokens", "in", "tokens_list", "]", ")", "\n", "batch_x", "=", "[", "\n", "sentence", "+", "[", "vocab", "[", "\"<PAD>\"", "]", "]", "*", "(", "max_len", "-", "len", "(", "sentence", ")", ")", "\n", "for", "sentence", "in", "batch_x", "\n", "]", "\n", "return", "batch_x", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.make_batch": [[92, 96], ["adversarial_training.make_batch_tokens", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.make_batch_tokens"], ["", "def", "make_batch", "(", "data", ",", "vocab", ")", ":", "\n", "    ", "batch_x", "=", "make_batch_tokens", "(", "data", "[", "\"tokens\"", "]", ",", "vocab", ")", "\n", "batch_y", "=", "data", "[", "\"y\"", "]", "\n", "return", "torch", ".", "LongTensor", "(", "batch_x", ")", ",", "torch", ".", "LongTensor", "(", "batch_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.train_epoch": [[98, 113], ["dataset.shuffle.shuffle", "model.train", "torch.nn.NLLLoss", "torch.optim.Adam", "range", "model.parameters", "len", "adversarial_training.make_batch", "model", "torch.nn.NLLLoss.", "torch.optim.Adam.zero_grad", "criterion.backward", "torch.optim.Adam.step", "criterion.item", "len", "model.log"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.make_batch"], ["", "def", "train_epoch", "(", "model", ",", "dataset", ",", "vocab", ",", "batch_size", "=", "128", ",", "learning_rate", "=", "5e-3", ")", ":", "\n", "    ", "dataset", "=", "dataset", ".", "shuffle", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "criterion", "=", "torch", ".", "nn", ".", "NLLLoss", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ")", "\n", "avg_loss", "=", "0", "\n", "for", "start", "in", "range", "(", "0", ",", "len", "(", "dataset", ")", ",", "batch_size", ")", ":", "\n", "        ", "train_x", ",", "train_y", "=", "make_batch", "(", "dataset", "[", "start", ":", "start", "+", "batch_size", "]", ",", "vocab", ")", "\n", "pred", "=", "model", "(", "train_x", ")", "\n", "loss", "=", "criterion", "(", "pred", ".", "log", "(", ")", ",", "train_y", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "avg_loss", "+=", "loss", ".", "item", "(", ")", "\n", "", "return", "avg_loss", "/", "len", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.eval_classifier_acc": [[114, 119], ["len", "victim.get_pred"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], ["", "def", "eval_classifier_acc", "(", "dataset", ",", "victim", ")", ":", "\n", "    ", "correct", "=", "0", "\n", "for", "inst", "in", "dataset", ":", "\n", "        ", "correct", "+=", "(", "victim", ".", "get_pred", "(", "[", "inst", "[", "\"x\"", "]", "]", ")", "[", "0", "]", "==", "inst", "[", "\"y\"", "]", ")", "\n", "", "return", "correct", "/", "len", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.train_model": [[121, 133], ["range", "model.load_state_dict", "adversarial_training.train_epoch", "adversarial_training.MyClassifier", "adversarial_training.eval_classifier_acc", "print", "model.state_dict"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.train_epoch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.eval_classifier_acc"], ["", "def", "train_model", "(", "model", ",", "data_train", ",", "data_valid", ",", "vocab", ",", "num_epoch", "=", "10", ")", ":", "\n", "    ", "mx_acc", "=", "None", "\n", "mx_model", "=", "None", "\n", "for", "i", "in", "range", "(", "num_epoch", ")", ":", "\n", "        ", "loss", "=", "train_epoch", "(", "model", ",", "data_train", ",", "vocab", ")", "\n", "victim", "=", "MyClassifier", "(", "model", ",", "vocab", ")", "\n", "accuracy", "=", "eval_classifier_acc", "(", "data_valid", ",", "victim", ")", "\n", "print", "(", "\"Epoch %d: loss: %lf, accuracy %lf\"", "%", "(", "i", ",", "loss", ",", "accuracy", ")", ")", "\n", "if", "mx_acc", "is", "None", "or", "mx_acc", "<", "accuracy", ":", "\n", "            ", "mx_model", "=", "model", ".", "state_dict", "(", ")", "\n", "", "", "model", ".", "load_state_dict", "(", "mx_model", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.attack": [[135, 163], ["OpenAttack.attackers.PWWSAttacker", "OpenAttack.AttackEval", "tqdm.tqdm", "print", "datasets.Dataset.from_dict", "len", "len", "OpenAttack.AttackEval.ieval", "len", "len", "len", "adversarial_samples[].append", "adversarial_samples[].append", "adversarial_samples[].append", "tokenizer.tokenize", "classifier.get_pred"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.ieval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], ["", "def", "attack", "(", "classifier", ",", "dataset", ",", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", ")", ":", "\n", "    ", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "\n", "attacker", ",", "\n", "classifier", ",", "\n", ")", "\n", "correct_samples", "=", "[", "\n", "inst", "for", "inst", "in", "dataset", "if", "classifier", ".", "get_pred", "(", "[", "inst", "[", "\"x\"", "]", "]", ")", "[", "0", "]", "==", "inst", "[", "\"y\"", "]", "\n", "]", "\n", "\n", "accuracy", "=", "len", "(", "correct_samples", ")", "/", "len", "(", "dataset", ")", "\n", "\n", "adversarial_samples", "=", "{", "\n", "\"x\"", ":", "[", "]", ",", "\n", "\"y\"", ":", "[", "]", ",", "\n", "\"tokens\"", ":", "[", "]", "\n", "}", "\n", "\n", "for", "result", "in", "tqdm", ".", "tqdm", "(", "attack_eval", ".", "ieval", "(", "correct_samples", ")", ",", "total", "=", "len", "(", "correct_samples", ")", ")", ":", "\n", "        ", "if", "result", "[", "\"success\"", "]", ":", "\n", "            ", "adversarial_samples", "[", "\"x\"", "]", ".", "append", "(", "result", "[", "\"result\"", "]", ")", "\n", "adversarial_samples", "[", "\"y\"", "]", ".", "append", "(", "result", "[", "\"data\"", "]", "[", "\"y\"", "]", ")", "\n", "adversarial_samples", "[", "\"tokens\"", "]", ".", "append", "(", "tokenizer", ".", "tokenize", "(", "result", "[", "\"result\"", "]", ",", "pos_tagging", "=", "False", ")", ")", "\n", "\n", "", "", "attack_success_rate", "=", "len", "(", "adversarial_samples", "[", "\"x\"", "]", ")", "/", "len", "(", "correct_samples", ")", "\n", "\n", "print", "(", "\"Accuracy: %lf%%\\nAttack success rate: %lf%%\"", "%", "(", "accuracy", "*", "100", ",", "attack_success_rate", "*", "100", ")", ")", "\n", "\n", "return", "datasets", ".", "Dataset", ".", "from_dict", "(", "adversarial_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.main": [[164, 199], ["print", "adversarial_training.prepare_data", "adversarial_training.make_model", "print", "adversarial_training.train_model", "print", "adversarial_training.MyClassifier", "adversarial_training.attack", "print", "print", "print", "adversarial_training.train_model", "print", "adversarial_training.attack", "len", "new_dataset[].append", "new_dataset[].append", "new_dataset[].append", "new_dataset[].append", "new_dataset[].append", "new_dataset[].append", "datasets.Dataset.from_dict"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.prepare_data", "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.make_model", "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.train_model", "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.attack", "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.adversarial_training.train_model", "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.attack"], ["", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"Loading data\"", ")", "\n", "train", ",", "valid", ",", "test", ",", "vocab", "=", "prepare_data", "(", ")", "# Load dataset", "\n", "model", "=", "make_model", "(", "len", "(", "vocab", ")", ")", "# Design a victim model", "\n", "\n", "print", "(", "\"Training\"", ")", "\n", "trained_model", "=", "train_model", "(", "model", ",", "train", ",", "valid", ",", "vocab", ")", "# Train the victim model", "\n", "\n", "print", "(", "\"Generating adversarial samples (this step will take dozens of minutes)\"", ")", "\n", "victim", "=", "MyClassifier", "(", "trained_model", ",", "vocab", ")", "# Wrap the victim model", "\n", "adversarial_samples", "=", "attack", "(", "victim", ",", "train", ")", "# Conduct adversarial attacks and generate adversarial examples", "\n", "\n", "print", "(", "\"Adversarially training classifier\"", ")", "\n", "print", "(", "train", ".", "features", ")", "\n", "print", "(", "adversarial_samples", ".", "features", ")", "\n", "\n", "new_dataset", "=", "{", "\n", "\"x\"", ":", "[", "]", ",", "\n", "\"y\"", ":", "[", "]", ",", "\n", "\"tokens\"", ":", "[", "]", "\n", "}", "\n", "for", "it", "in", "train", ":", "\n", "        ", "new_dataset", "[", "\"x\"", "]", ".", "append", "(", "it", "[", "\"x\"", "]", ")", "\n", "new_dataset", "[", "\"y\"", "]", ".", "append", "(", "it", "[", "\"y\"", "]", ")", "\n", "new_dataset", "[", "\"tokens\"", "]", ".", "append", "(", "it", "[", "\"tokens\"", "]", ")", "\n", "\n", "", "for", "it", "in", "adversarial_samples", ":", "\n", "        ", "new_dataset", "[", "\"x\"", "]", ".", "append", "(", "it", "[", "\"x\"", "]", ")", "\n", "new_dataset", "[", "\"y\"", "]", ".", "append", "(", "it", "[", "\"y\"", "]", ")", "\n", "new_dataset", "[", "\"tokens\"", "]", ".", "append", "(", "it", "[", "\"tokens\"", "]", ")", "\n", "\n", "", "finetune_model", "=", "train_model", "(", "trained_model", ",", "datasets", ".", "Dataset", ".", "from_dict", "(", "new_dataset", ")", ",", "valid", ",", "vocab", ")", "# Retrain the classifier with additional adversarial examples", "\n", "\n", "print", "(", "\"Testing enhanced model (this step will take dozens of minutes)\"", ")", "\n", "attack", "(", "victim", ",", "train", ")", "# Re-attack the victim model to measure the effect of adversarial training", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.transformer.dataset_mapping": [[8, 12], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.transformer.main": [[14, 31], ["print", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "OpenAttack.classifiers.TransformersClassifier", "print", "OpenAttack.attackers.PWWSAttacker", "datasets.load_dataset().map", "print", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset", "OpenAttack.metric.EditDistance", "OpenAttack.metric.ModificationRate"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"Load model\"", ")", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "\"echarlaix/bert-base-uncased-sst2-acc91.1-d37-hybrid\"", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\"echarlaix/bert-base-uncased-sst2-acc91.1-d37-hybrid\"", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "victim", "=", "OpenAttack", ".", "classifiers", ".", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n", "print", "(", "\"New Attacker\"", ")", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", "\n", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "\n", "print", "(", "\"Start attack\"", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ",", "metrics", "=", "[", "\n", "OpenAttack", ".", "metric", ".", "EditDistance", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "ModificationRate", "(", ")", "\n", "]", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.nli_attack.NLIWrapper.__init__": [[9, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "OpenAttack", ".", "classifiers", ".", "Classifier", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.nli_attack.NLIWrapper.get_pred": [[12, 14], ["nli_attack.NLIWrapper.get_prob().argmax", "nli_attack.NLIWrapper.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["", "def", "get_pred", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "self", ".", "get_prob", "(", "input_", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.nli_attack.NLIWrapper.get_prob": [[15, 21], ["print", "nli_attack.NLIWrapper.model.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["", "def", "get_prob", "(", "self", ",", "input_", ")", ":", "\n", "        ", "ref", "=", "self", ".", "context", ".", "input", "[", "\"hypothesis\"", "]", "\n", "input_sents", "=", "[", "sent", "+", "\"</s></s>\"", "+", "ref", "for", "sent", "in", "input_", "]", "\n", "print", "(", "input_sents", ")", "\n", "return", "self", ".", "model", ".", "get_prob", "(", "\n", "input_sents", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.nli_attack.dataset_mapping": [[24, 29], ["None"], "function", ["None"], ["", "", "def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"premise\"", "]", ",", "\n", "\"y\"", ":", "x", "[", "\"label\"", "]", ",", "\n", "\"hypothesis\"", ":", "x", "[", "\"hypothesis\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.nli_attack.main": [[31, 49], ["print", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "OpenAttack.classifiers.TransformersClassifier", "nli_attack.NLIWrapper", "print", "OpenAttack.attackers.PWWSAttacker", "datasets.load_dataset().map", "print", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset", "OpenAttack.metric.EditDistance", "OpenAttack.metric.ModificationRate"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"Load model\"", ")", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "\"roberta-large-mnli\"", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\"roberta-large-mnli\"", ",", "output_hidden_states", "=", "False", ")", "\n", "victim", "=", "OpenAttack", ".", "classifiers", ".", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ")", "\n", "victim", "=", "NLIWrapper", "(", "victim", ")", "\n", "\n", "print", "(", "\"New Attacker\"", ")", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", "\n", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"glue\"", ",", "\"mnli\"", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "\n", "print", "(", "\"Start attack\"", ")", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ",", "metrics", "=", "[", "\n", "OpenAttack", ".", "metric", ".", "EditDistance", "(", ")", ",", "\n", "OpenAttack", ".", "metric", ".", "ModificationRate", "(", ")", "\n", "]", ")", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.workflow.dataset_mapping": [[7, 11], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.examples.workflow.main": [[14, 29], ["OpenAttack.loadVictim", "datasets.load_dataset().map", "OpenAttack.attackers.PWWSAttacker", "OpenAttack.AttackEval", "OpenAttack.AttackEval.eval", "datasets.load_dataset"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "victim", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.SST\"", ")", "\n", "# BERT.SST is a pytorch model which is fine-tuned on SST-2. It uses Glove vectors for word representation.", "\n", "# The load operation returns a PytorchClassifier that can be further used for Attacker and AttackEval.", "\n", "\n", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:20]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "# We load the sst-2 dataset using `datasets` package, and map the fields.", "\n", "\n", "attacker", "=", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", "\n", "# After this step, we\u2019ve initialized a PWWSAttacker and uses the default configuration during attack process.", "\n", "\n", "attack_eval", "=", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "victim", ")", "\n", "# Use the default implementation for AttackEval which supports seven basic metrics.", "\n", "\n", "attack_eval", ".", "eval", "(", "dataset", ",", "visualize", "=", "True", ")", "\n", "# Using visualize=True in attack_eval.eval can make it displays a visualized result. This function is really useful for analyzing small datasets.", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.__init__": [[44, 46], ["NotImplementedError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.enable_cdn": [[47, 54], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "enable_cdn", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Enable cdn for all official downloads.\n        \"\"\"", "\n", "\n", "cls", ".", "source", "=", "\"https://cdn.data.thunlp.org/\"", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.disable_cdn": [[55, 61], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "disable_cdn", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Disable cdn for all official downloads.\n        \"\"\"", "\n", "cls", ".", "source", "=", "\"https://data.thunlp.org/\"", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load": [[62, 99], ["exceptions.UnknownDataException", "os.path.exists", "cls.download", "exceptions.DataNotExistException", "exceptions.DataNotExistException"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "data_name", ":", "str", ",", "cached", ":", "bool", "=", "True", ")", "->", "Any", ":", "\n", "        ", "\"\"\"\n        Load data from local storage, and download it automatically if not exists.\n\n        Args:\n            data_name: The name of resource that you want to load. You can find all the available resource names in ``DataManager.AVAILABLE_DATAS``. *Note: all the names are* **CASE-SENSITIVE**.\n            cached: If **cached** is *True*, DataManager will lookup the cache before load it to avoid duplicate disk IO. If **cached** is *False*, DataManager will directly load data from disk. **Default:** *True*.\n        \n        Returns:\n            The object returned by LOAD function of corresponding data.\n\n        Raises:\n            UnknownDataException: For loading an unavailable data. \n            DataNotExistException:  For loading a data that has not been downloaded. This appends when AutoDownload mechanism is disabled.\n\n        \"\"\"", "\n", "\n", "if", "data_name", "not", "in", "cls", ".", "AVAILABLE_DATAS", ":", "\n", "            ", "raise", "UnknownDataException", "(", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cls", ".", "data_path", "[", "data_name", "]", ")", ":", "\n", "            ", "if", "cls", ".", "__auto_download", ":", "\n", "                ", "cls", ".", "download", "(", "data_name", ")", "\n", "", "else", ":", "\n", "                ", "raise", "DataNotExistException", "(", "data_name", ",", "cls", ".", "data_path", "[", "data_name", "]", ")", "\n", "\n", "", "", "if", "not", "cached", ":", "\n", "            ", "return", "cls", ".", "data_loader", "[", "data_name", "]", "(", "cls", ".", "data_path", "[", "data_name", "]", ")", "\n", "", "elif", "cls", ".", "data_reference", "[", "data_name", "]", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "cls", ".", "data_reference", "[", "data_name", "]", "=", "cls", ".", "data_loader", "[", "data_name", "]", "(", "\n", "cls", ".", "data_path", "[", "data_name", "]", "\n", ")", "\n", "", "except", "OSError", ":", "\n", "                ", "raise", "DataNotExistException", "(", "data_name", ",", "cls", ".", "data_path", "[", "data_name", "]", ")", "\n", "", "", "return", "cls", ".", "data_reference", "[", "data_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim": [[101, 107], ["cls.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["", "@", "classmethod", "\n", "def", "loadVictim", "(", "cls", ",", "data_name", ",", "cached", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        This method is equivalent to ``DataManager.load(\"Victim.\" + data_name)``.\n        \"\"\"", "\n", "return", "cls", ".", "load", "(", "\"Victim.\"", "+", "data_name", ",", "cached", "=", "cached", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadTProcess": [[108, 114], ["cls.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["", "@", "classmethod", "\n", "def", "loadTProcess", "(", "cls", ",", "data_name", ",", "cached", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        This method is equivalent to ``DataManager.load(\"TProcess.\" + data_name)``.\n        \"\"\"", "\n", "return", "cls", ".", "load", "(", "\"TProcess.\"", "+", "data_name", ",", "cached", "=", "cached", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadAttackAssist": [[115, 121], ["cls.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["", "@", "classmethod", "\n", "def", "loadAttackAssist", "(", "cls", ",", "data_name", ",", "cached", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        This method is equivalent to ``DataManager.load(\"AttackAssist.\" + data_name)``.\n        \"\"\"", "\n", "return", "cls", ".", "load", "(", "\"AttackAssist.\"", "+", "data_name", ",", "cached", "=", "cached", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.setAutoDownload": [[122, 132], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "setAutoDownload", "(", "cls", ",", "enabled", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        AutoDownload mechanism is enabled by default.\n\n        Args:\n            enabled: Change if DataManager automatically download the data when loading.\n        \n        \"\"\"", "\n", "cls", ".", "__auto_download", "=", "enabled", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.get": [[133, 145], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get", "(", "cls", ",", "data_name", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Args:\n            data_name: The name of data.\n        Returns:\n            Relative path of data.\n\n        \"\"\"", "\n", "if", "data_name", "not", "in", "cls", ".", "AVAILABLE_DATAS", ":", "\n", "            ", "raise", "UnknownDataException", "\n", "", "return", "cls", ".", "data_path", "[", "data_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.set_path": [[146, 171], ["cls.data_path.items", "os.path.join", "os.path.basename"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "set_path", "(", "cls", ",", "path", ":", "str", ",", "data_name", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"Set the path for a specific data or for all data.\n\n        If **data_name** is *None*, all paths will be changed to corresponding file under **path** directory.\n\n        If **data_name** is *not None*, the specific data path will be changed to **path**.\n\n        The default paths for all data are ``./data/<data_name>``, and you can manually change them using this method .\n\n        Args:\n            path: The path to data, or path to the directory where all data is stored.\n            data_name: The name of data. If **data_name** is *None*, all paths will be changed.\n\n\n        \"\"\"", "\n", "if", "data_name", "is", "None", ":", "\n", "            ", "nw_dict", "=", "{", "}", "\n", "for", "kw", ",", "pt", "in", "cls", ".", "data_path", ".", "items", "(", ")", ":", "\n", "                ", "nw_dict", "[", "kw", "]", "=", "os", ".", "path", ".", "join", "(", "path", ",", "os", ".", "path", ".", "basename", "(", "pt", ")", ")", "\n", "", "cls", ".", "data_path", "=", "nw_dict", "\n", "", "else", ":", "\n", "            ", "if", "data_name", "not", "in", "cls", ".", "AVAILABLE_DATAS", ":", "\n", "                ", "raise", "UnknownDataException", "\n", "", "cls", ".", "data_path", "[", "data_name", "]", "=", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download": [[172, 205], ["os.path.dirname", "len", "exceptions.UnknownDataException", "os.path.exists", "os.path.exists", "os.makedirs", "download_func", "inspect.getfullargspec", "download_func"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "download", "(", "cls", ",", "data_name", ":", "str", ",", "path", ":", "Optional", "[", "str", "]", "=", "None", ",", "force", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This method will check if data exists before getting it from \"Data Server\".You can use **force** to skip this step.\n\n        Args:\n            data_name: Name of the data that you want to download.\n            path: Specify a path when before download. Leaves None for download to default **path**.\n            force: Force download the data.\n\n        Raises:\n            UnknownDataException: For downloading an unavailable data.\n\n        \n        \"\"\"", "\n", "if", "data_name", "not", "in", "cls", ".", "AVAILABLE_DATAS", ":", "\n", "            ", "raise", "UnknownDataException", "(", ")", "\n", "", "if", "path", "is", "None", ":", "\n", "            ", "path", "=", "cls", ".", "data_path", "[", "data_name", "]", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "path", ")", "and", "not", "force", ":", "\n", "            ", "return", "True", "\n", "", "download_func", "=", "cls", ".", "data_download", "[", "data_name", "]", "\n", "\n", "parent_dir", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "parent_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "parent_dir", ")", "\n", "\n", "", "num_args", "=", "len", "(", "inspect", ".", "getfullargspec", "(", "download_func", ")", ".", "args", ")", "\n", "if", "num_args", "==", "1", ":", "\n", "            ", "download_func", "(", "path", ")", "\n", "", "elif", "num_args", "==", "2", ":", "\n", "            ", "download_func", "(", "path", ",", "cls", ".", "source", ")", "\n", "", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContext.__init__": [[4, 11], ["time.time"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "invoke_limit", ")", "->", "None", ":", "\n", "        ", "self", ".", "input", "=", "data", "\n", "self", ".", "invoke", "=", "0", "\n", "self", ".", "invoke_limit", "=", "invoke_limit", "\n", "self", ".", "attacker_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "attacker_time_del", "=", "0", "\n", "self", ".", "inference", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContext.attack_time": [[12, 15], ["time.time"], "methods", ["None"], ["", "@", "property", "\n", "def", "attack_time", "(", "self", ")", ":", "\n", "        ", "return", "time", ".", "time", "(", ")", "-", "self", ".", "attacker_start", "-", "self", ".", "attacker_time_del", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContext.__setattr__": [[16, 24], ["hasattr", "super().__setattr__", "getattr", "RuntimeError", "super().__setattr__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__setattr__", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__setattr__"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "value", ")", "->", "None", ":", "\n", "        ", "if", "name", "in", "[", "\"invoke\"", "]", "and", "hasattr", "(", "self", ",", "name", ")", ":", "\n", "            ", "if", "getattr", "(", "self", ",", "name", ")", ">", "value", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Invalid access\"", ")", "\n", "", "else", ":", "\n", "                ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "value", ")", "\n", "", "", "else", ":", "\n", "            ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__init__": [[33, 35], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ctx", ")", "->", "None", ":", "\n", "        ", "self", ".", "__ctx", "=", "ctx", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__setattr__": [[36, 43], ["TypeError", "name.startswith", "super().__setattr__", "setattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__setattr__"], ["", "def", "__setattr__", "(", "self", ",", "name", ":", "str", ",", "value", ")", "->", "None", ":", "\n", "        ", "if", "name", "in", "[", "\"invoke\"", ",", "\"invoke_limit\"", ",", "\"attacker_start\"", ",", "\"attacker_time_del\"", "]", ":", "\n", "            ", "raise", "TypeError", "(", "\"'AttackContext' object does not support item assignment\"", ")", "\n", "", "elif", "name", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "super", "(", ")", ".", "__setattr__", "(", "name", ",", "value", ")", "\n", "", "else", ":", "\n", "            ", "setattr", "(", "self", ".", "__ctx", ",", "name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__getattribute__": [[44, 51], ["AttributeError", "name.startswith", "super().__getattribute__", "getattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__getattribute__"], ["", "", "def", "__getattribute__", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "        ", "if", "name", "in", "[", "\"attacker_start\"", ",", "\"attacker_time_del\"", "]", ":", "\n", "            ", "raise", "AttributeError", "(", "\"'AttackContext' object has no attribute '%s'\"", "%", "name", ")", "\n", "", "elif", "name", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "return", "super", "(", ")", ".", "__getattribute__", "(", "name", ")", "\n", "", "else", ":", "\n", "            ", "return", "getattr", "(", "self", ".", "__ctx", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__delattr__": [[52, 59], ["AttributeError", "name.startswith", "super().__delattr__", "delattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.context.AttackContextShadow.__delattr__"], ["", "", "def", "__delattr__", "(", "self", ",", "name", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "name", "in", "[", "\"invoke\"", ",", "\"invoke_limit\"", ",", "\"attacker_start\"", ",", "\"attacker_time_del\"", ",", "\"attacker_time\"", "]", ":", "\n", "            ", "raise", "AttributeError", "(", "\"%s\"", "%", "name", ")", "\n", "", "elif", "name", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "super", "(", ")", ".", "__delattr__", "(", "name", ")", "\n", "", "else", ":", "\n", "            ", "delattr", "(", "self", ".", "__ctx", ",", "name", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.TAGS": [[18, 21], ["None"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_method_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.__init_subclass__": [[22, 26], ["set", "set", "setattr", "base.invoke_decorator", "getattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.invoke_decorator"], ["", "def", "__init_subclass__", "(", "cls", ",", "invoke_funcs", "=", "[", "]", ",", "tags", "=", "set", "(", ")", ")", ":", "\n", "        ", "for", "func_name", ",", "method", "in", "invoke_funcs", ":", "\n", "            ", "setattr", "(", "cls", ",", "func_name", ",", "invoke_decorator", "(", "getattr", "(", "cls", ",", "func_name", ")", ",", "method", ")", ")", "\n", "", "cls", ".", "_method_tags", "=", "set", "(", "tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.supported_language": [[27, 33], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supported_language", "(", "self", ")", ":", "\n", "        ", "for", "tag", "in", "self", ".", "TAGS", ":", "\n", "            ", "if", "tag", ".", "type", "==", "\"lang\"", ":", "\n", "                ", "return", "tag", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context": [[34, 36], ["context.AttackContext"], "methods", ["None"], ["", "def", "set_context", "(", "self", ",", "data", ",", "invoke_limit", ")", ":", "\n", "        ", "self", ".", "_Victim__context", "=", "AttackContext", "(", "data", ",", "invoke_limit", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.clear_context": [[37, 39], ["None"], "methods", ["None"], ["", "def", "clear_context", "(", "self", ")", ":", "\n", "        ", "self", ".", "_Victim__context", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.context": [[40, 46], ["hasattr", "context.AttackContextShadow"], "methods", ["None"], ["", "@", "property", "\n", "def", "context", "(", "self", ")", "->", "Union", "[", "None", ",", "AttackContextShadow", "]", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"_Victim__context\"", ")", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "AttackContextShadow", "(", "self", ".", "_Victim__context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.record_invoke": [[47, 70], ["hasattr", "func", "time.time", "exceptions.InvokeLimitExceeded", "time.time"], "methods", ["None"], ["", "", "def", "record_invoke", "(", "self", ",", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "hasattr", "(", "self", ",", "\"_Victim__context\"", ")", ":", "\n", "            ", "need_record", "=", "(", "self", ".", "_Victim__context", "is", "not", "None", ")", "and", "(", "not", "self", ".", "_Victim__context", ".", "inference", ")", "\n", "", "else", ":", "\n", "            ", "need_record", "=", "False", "\n", "\n", "", "if", "need_record", ":", "\n", "            ", "self", ".", "_Victim__context", ".", "inference", "=", "True", "\n", "if", "self", ".", "_Victim__context", ".", "invoke_limit", "is", "not", "None", "and", "self", ".", "_Victim__context", ".", "invoke", "+", "cnt", ">", "self", ".", "_Victim__context", ".", "invoke_limit", ":", "\n", "                ", "raise", "InvokeLimitExceeded", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_Victim__context", ".", "invoke", "+=", "cnt", "\n", "", "st", "=", "time", ".", "time", "(", ")", "\n", "\n", "# call original function here", "\n", "", "ret", "=", "func", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "need_record", ":", "\n", "            ", "self", ".", "_Victim__context", ".", "inference", "=", "False", "\n", "self", ".", "_Victim__context", ".", "attacker_time_del", "+=", "time", ".", "time", "(", ")", "-", "st", "\n", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.invoke_decorator": [[9, 16], ["functools.wraps", "method.invoke_count", "base..record_invoke"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetGradient.invoke_count", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.record_invoke"], ["def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "invoke_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.method.VictimMethod.invoke_count": [[4, 6], ["None"], "methods", ["None"], ["    ", "def", "invoke_count", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.method.VictimMethod.method_decorator": [[7, 15], ["functools.wraps", "method.VictimMethod.before_call", "func", "method.VictimMethod.after_call"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetGradient.before_call", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetEmbedding.after_call"], ["", "def", "method_decorator", "(", "self", ",", "func", ")", ":", "\n", "        ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "this", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "self", ".", "before_call", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "ret", "=", "func", "(", "this", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "after_call", "(", "ret", ")", "\n", "return", "ret", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.method.VictimMethod.before_call": [[16, 18], ["None"], "methods", ["None"], ["", "def", "before_call", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.method.VictimMethod.after_call": [[19, 21], ["None"], "methods", ["None"], ["", "def", "after_call", "(", "self", ",", "ret", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetPredict.before_call": [[5, 13], ["enumerate", "isinstance", "TypeError", "len", "ValueError", "isinstance", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type"], ["    ", "def", "before_call", "(", "self", ",", "input_", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "input_", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"get_pred: `input` must be a list of sentences, but got %s\"", "%", "type", "(", "input_", ")", ")", "\n", "", "if", "len", "(", "input_", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"empty `input` list\"", ")", "\n", "", "for", "i", ",", "it", "in", "enumerate", "(", "input_", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "it", ",", "str", ")", ":", "\n", "                ", "raise", "TypeError", "(", "\"get_pred: `input[%d]` must be a list of sentences, but got %s\"", "%", "(", "i", ",", "type", "(", "it", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetPredict.invoke_count": [[14, 16], ["len"], "methods", ["None"], ["", "", "", "def", "invoke_count", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "len", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetProbability.before_call": [[18, 26], ["enumerate", "isinstance", "TypeError", "len", "ValueError", "isinstance", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type"], ["    ", "def", "before_call", "(", "self", ",", "input_", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "input_", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"get_prob: `input` must be a list of sentences, but got %s\"", "%", "type", "(", "input_", ")", ")", "\n", "", "if", "len", "(", "input_", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"empty `input` list\"", ")", "\n", "", "for", "i", ",", "it", "in", "enumerate", "(", "input_", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "it", ",", "str", ")", ":", "\n", "                ", "raise", "TypeError", "(", "\"get_prob: `input[%d]` must be a sentence, but got %s\"", "%", "(", "i", ",", "type", "(", "it", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetProbability.invoke_count": [[27, 29], ["len"], "methods", ["None"], ["", "", "", "def", "invoke_count", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "len", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetGradient.before_call": [[31, 45], ["enumerate", "isinstance", "TypeError", "len", "ValueError", "enumerate", "len", "len", "ValueError", "isinstance", "TypeError", "type", "isinstance", "TypeError", "len", "len", "type", "type"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type"], ["    ", "def", "before_call", "(", "self", ",", "input_", ",", "labels", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "input_", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"get_grad: `input` must be a list of token lists, but got %s\"", "%", "type", "(", "input_", ")", ")", "\n", "", "if", "len", "(", "input_", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"empty `input` list\"", ")", "\n", "", "for", "i", ",", "it", "in", "enumerate", "(", "input_", ")", ":", "\n", "            ", "if", "not", "isinstance", "(", "it", ",", "list", ")", ":", "\n", "                ", "raise", "TypeError", "(", "\"get_grad: `input[%d]` must be a token list, but got %s\"", "%", "(", "i", ",", "type", "(", "it", ")", ")", ")", "\n", "", "for", "j", ",", "token", "in", "enumerate", "(", "it", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "token", ",", "str", ")", ":", "\n", "                    ", "raise", "TypeError", "(", "\"get_grad: `input[%d][%d]` must be a token, but got %s\"", "%", "(", "i", ",", "j", ",", "type", "(", "it", ")", ")", ")", "\n", "\n", "", "", "", "if", "len", "(", "input_", ")", "!=", "len", "(", "labels", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"`input_` and `labels` must be the same length. (%d != %d)\"", "%", "(", "len", "(", "input_", ")", ",", "len", "(", "labels", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetGradient.invoke_count": [[46, 48], ["len"], "methods", ["None"], ["", "", "def", "invoke_count", "(", "self", ",", "input_", ",", "labels", ")", ":", "\n", "        ", "return", "len", "(", "input_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.methods.GetEmbedding.after_call": [[50, 53], ["isinstance", "TypeError"], "methods", ["None"], ["    ", "def", "after_call", "(", "self", ",", "ret", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "ret", ",", "WordEmbedding", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"`get_embedding`: must return a `WordEmbedding` object\"", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.base.Classifier.__init_subclass__": [[21, 32], ["CLASSIFIER_METHODS.keys", "base.Victim.__init_subclass__", "hasattr", "invoke_funcs.append", "tags.append", "setattr", "tags.Tag", "CLASSIFIER_METHODS[].method_decorator", "getattr"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.base.Classifier.__init_subclass__", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.method.VictimMethod.method_decorator"], ["\n", "", "def", "__init_subclass__", "(", "cls", ",", "invoke_funcs", "=", "[", "]", ",", "tags", "=", "set", "(", ")", ")", ":", "\n", "        ", "for", "func_name", ",", "method", "in", "invoke_funcs", ":", "\n", "            ", "setattr", "(", "cls", ",", "func_name", ",", "invoke_decorator", "(", "getattr", "(", "cls", ",", "func_name", ")", ",", "method", ")", ")", "\n", "", "cls", ".", "_method_tags", "=", "set", "(", "tags", ")", "\n", "\n", "", "@", "property", "\n", "def", "supported_language", "(", "self", ")", ":", "\n", "        ", "for", "tag", "in", "self", ".", "TAGS", ":", "\n", "            ", "if", "tag", ".", "type", "==", "\"lang\"", ":", "\n", "                ", "return", "tag", "\n", "", "", "return", "None", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.TAGS": [[12, 17], ["super().TAGS.union"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "__lang_tag", "is", "None", ":", "\n", "            ", "return", "super", "(", ")", ".", "TAGS", "\n", "", "return", "super", "(", ")", ".", "TAGS", ".", "union", "(", "{", "self", ".", "__lang_tag", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.__init__": [[18, 71], ["transformers.TransformersClassifier.to", "embedding_layer.register_forward_hook", "dict", "range", "embedding_layer.weight.detach().cpu().numpy", "utils.language_by_name", "torch.device", "utils.HookCloser", "ValueError", "embedding_layer.weight.detach().cpu", "torch.cuda.is_available", "tokenizer.convert_ids_to_tokens", "embedding_layer.weight.detach"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name"], ["", "def", "__init__", "(", "self", ",", "\n", "model", ":", "transformers", ".", "PreTrainedModel", ",", "\n", "tokenizer", ":", "transformers", ".", "PreTrainedTokenizer", ",", "\n", "embedding_layer", ",", "\n", "device", ":", "torch", ".", "device", "=", "None", ",", "\n", "max_length", ":", "int", "=", "128", ",", "\n", "batch_size", ":", "int", "=", "8", ",", "\n", "lang", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model: Huggingface model for classification.\n            tokenizer: Huggingface tokenizer for classification. **Default:** None\n            embedding_layer: The module of embedding_layer used in transformers models. For example, ``BertModel.bert.embeddings.word_embeddings``. **Default:** None\n            device: Device of pytorch model. **Default:** \"cpu\" if cuda is not available else \"cuda\"\n            max_len: Max length of input tokens. If input token list is too long, it will be truncated. Uses None for no truncation. **Default:** None\n            batch_size: Max batch size of this classifier.\n            lang: Language of this classifier. If is `None` then `TransformersClassifier` will intelligently select the language based on other parameters.\n\n        \"\"\"", "\n", "\n", "self", ".", "model", "=", "model", "\n", "\n", "if", "lang", "is", "not", "None", ":", "\n", "            ", "self", ".", "__lang_tag", "=", "language_by_name", "(", "lang", ")", "\n", "if", "self", ".", "__lang_tag", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown language `%s`\"", "%", "lang", ")", "\n", "", "", "elif", "tokenizer", "is", "not", "None", ":", "\n", "            ", "self", ".", "__lang_tag", "=", "TAG_English", "\n", "", "else", ":", "\n", "            ", "self", ".", "__lang_tag", "=", "TAG_English", "\n", "\n", "", "if", "device", "is", "None", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "self", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "curr_embedding", "=", "None", "\n", "self", ".", "hook", "=", "embedding_layer", ".", "register_forward_hook", "(", "HookCloser", "(", "self", ")", ")", "\n", "self", ".", "embedding_layer", "=", "embedding_layer", "\n", "\n", "self", ".", "word2id", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "tokenizer", ".", "vocab_size", ")", ":", "\n", "            ", "self", ".", "word2id", "[", "tokenizer", ".", "convert_ids_to_tokens", "(", "i", ")", "]", "=", "i", "\n", "", "self", ".", "__tokenizer", "=", "tokenizer", "\n", "\n", "self", ".", "embedding", "=", "embedding_layer", ".", "weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "self", ".", "token_unk", "=", "tokenizer", ".", "unk_token", "\n", "self", ".", "token_unk_id", "=", "tokenizer", ".", "unk_token_id", "\n", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.tokenizer": [[72, 75], ["text_process.tokenizer.TransformersTokenizer"], "methods", ["None"], ["", "@", "property", "\n", "def", "tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "TransformersTokenizer", "(", "self", ".", "__tokenizer", ",", "self", ".", "__lang_tag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to": [[76, 84], ["transformers.TransformersClassifier.model.to"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to"], ["", "def", "to", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            device: Device that moves model to.\n        \"\"\"", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "device", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred": [[85, 87], ["transformers.TransformersClassifier.get_prob().argmax", "transformers.TransformersClassifier.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], ["", "def", "get_pred", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "self", ".", "get_prob", "(", "input_", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob": [[88, 92], ["transformers.TransformersClassifier.get_grad", "transformers.TransformersClassifier.__tokenizer.tokenize", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "get_prob", "(", "self", ",", "input_", ")", ":", "\n", "        ", "return", "self", ".", "get_grad", "(", "[", "\n", "self", ".", "__tokenizer", ".", "tokenize", "(", "sent", ")", "for", "sent", "in", "input_", "\n", "]", ",", "[", "0", "]", "*", "len", "(", "input_", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad": [[93, 96], ["transformers.TransformersClassifier.predict"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.predict"], ["", "def", "get_grad", "(", "self", ",", "input_", ",", "labels", ")", ":", "\n", "        ", "v", "=", "self", ".", "predict", "(", "input_", ",", "labels", ")", "\n", "return", "v", "[", "0", "]", ",", "v", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.predict": [[97, 162], ["numpy.array", "numpy.array", "torch.LongTensor().to", "range", "torch.cat.numpy", "torch.cat.numpy", "len", "max", "transformers.TransformersClassifier.__tokenizer.convert_tokens_to_ids", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "transformers.TransformersClassifier.model", "torch.cat.numpy", "len", "torch.LongTensor", "transformers.TransformersClassifier.hidden_states[].detach().cpu", "torch.nn.functional.softmax", "loss.backward", "transformers.TransformersClassifier.curr_embedding.grad.clone().cpu", "transformers.TransformersClassifier.curr_embedding.grad.zero_", "torch.nn.functional.softmax.detach().cpu", "torch.cat", "torch.nn.functional.softmax", "loss.backward", "torch.cat", "transformers.TransformersClassifier.curr_embedding.grad.zero_", "torch.cat", "torch.from_numpy().long", "torch.from_numpy().long", "len", "transformers.TransformersClassifier.hidden_states[].detach", "transformers.TransformersClassifier.curr_embedding.grad.clone", "torch.nn.functional.softmax.detach", "transformers.TransformersClassifier.hidden_states[].detach().cpu", "transformers.TransformersClassifier.curr_embedding.grad.clone().cpu", "torch.nn.functional.softmax.detach().cpu", "len", "len", "len", "torch.from_numpy", "torch.from_numpy", "transformers.TransformersClassifier.hidden_states[].detach", "transformers.TransformersClassifier.curr_embedding.grad.clone", "torch.nn.functional.softmax.detach"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to"], ["", "def", "predict", "(", "self", ",", "sen_list", ",", "labels", "=", "None", ")", ":", "\n", "        ", "sen_list", "=", "[", "\n", "sen", "[", ":", "self", ".", "max_length", "-", "2", "]", "for", "sen", "in", "sen_list", "\n", "]", "\n", "sent_lens", "=", "[", "len", "(", "sen", ")", "for", "sen", "in", "sen_list", "]", "\n", "batch_len", "=", "max", "(", "sent_lens", ")", "+", "2", "\n", "\n", "attentions", "=", "np", ".", "array", "(", "[", "\n", "[", "1", "]", "*", "(", "len", "(", "sen", ")", "+", "2", ")", "+", "[", "0", "]", "*", "(", "batch_len", "-", "2", "-", "len", "(", "sen", ")", ")", "\n", "for", "sen", "in", "sen_list", "\n", "]", ",", "dtype", "=", "'int64'", ")", "\n", "sen_list", "=", "[", "\n", "self", ".", "__tokenizer", ".", "convert_tokens_to_ids", "(", "sen", ")", "\n", "for", "sen", "in", "sen_list", "\n", "]", "\n", "tokeinzed_sen", "=", "np", ".", "array", "(", "[", "\n", "[", "self", ".", "__tokenizer", ".", "cls_token_id", "]", "+", "sen", "+", "[", "self", ".", "__tokenizer", ".", "sep_token_id", "]", "+", "(", "[", "self", ".", "__tokenizer", ".", "pad_token_id", "]", "*", "(", "batch_len", "-", "2", "-", "len", "(", "sen", ")", ")", ")", "\n", "for", "sen", "in", "sen_list", "\n", "]", ",", "dtype", "=", "'int64'", ")", "\n", "\n", "result", "=", "None", "\n", "result_grad", "=", "None", "\n", "all_hidden_states", "=", "None", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "            ", "labels", "=", "[", "0", "]", "*", "len", "(", "sen_list", ")", "\n", "", "labels", "=", "torch", ".", "LongTensor", "(", "labels", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "(", "len", "(", "sen_list", ")", "+", "self", ".", "batch_size", "-", "1", ")", "//", "self", ".", "batch_size", ")", ":", "\n", "            ", "curr_sen", "=", "tokeinzed_sen", "[", "i", "*", "self", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "self", ".", "batch_size", "]", "\n", "curr_mask", "=", "attentions", "[", "i", "*", "self", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "self", ".", "batch_size", "]", "\n", "\n", "xs", "=", "torch", ".", "from_numpy", "(", "curr_sen", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "masks", "=", "torch", ".", "from_numpy", "(", "curr_mask", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "outputs", "=", "self", ".", "model", "(", "input_ids", "=", "xs", ",", "attention_mask", "=", "masks", ",", "output_hidden_states", "=", "True", ",", "labels", "=", "labels", "[", "i", "*", "self", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "self", ".", "batch_size", "]", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "all_hidden_states", "=", "outputs", ".", "hidden_states", "[", "-", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "loss", "=", "outputs", ".", "loss", "\n", "logits", "=", "outputs", ".", "logits", "\n", "logits", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "loss", "=", "-", "loss", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "result_grad", "=", "self", ".", "curr_embedding", ".", "grad", ".", "clone", "(", ")", ".", "cpu", "(", ")", "\n", "self", ".", "curr_embedding", ".", "grad", ".", "zero_", "(", ")", "\n", "self", ".", "curr_embedding", "=", "None", "\n", "result", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "                ", "all_hidden_states", "=", "torch", ".", "cat", "(", "(", "all_hidden_states", ",", "outputs", ".", "hidden_states", "[", "-", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "dim", "=", "0", ")", "\n", "loss", "=", "outputs", ".", "loss", "\n", "logits", "=", "outputs", ".", "logits", "\n", "logits", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "loss", "=", "-", "loss", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "result_grad", "=", "torch", ".", "cat", "(", "(", "result_grad", ",", "self", ".", "curr_embedding", ".", "grad", ".", "clone", "(", ")", ".", "cpu", "(", ")", ")", ",", "dim", "=", "0", ")", "\n", "self", ".", "curr_embedding", ".", "grad", ".", "zero_", "(", ")", "\n", "self", ".", "curr_embedding", "=", "None", "\n", "\n", "result", "=", "torch", ".", "cat", "(", "(", "result", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ")", "\n", "\n", "", "", "result", "=", "result", ".", "numpy", "(", ")", "\n", "all_hidden_states", "=", "all_hidden_states", ".", "numpy", "(", ")", "\n", "result_grad", "=", "result_grad", ".", "numpy", "(", ")", "[", ":", ",", "1", ":", "-", "1", "]", "\n", "return", "result", ",", "result_grad", ",", "all_hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_hidden_states": [[163, 169], ["transformers.TransformersClassifier.predict"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.predict"], ["", "def", "get_hidden_states", "(", "self", ",", "input_", ",", "labels", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param list input_: A list of sentences of which we want to get the hidden states in the model.\n        :rtype torch.tensor\n        \"\"\"", "\n", "return", "self", ".", "predict", "(", "input_", ",", "labels", ")", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_embedding": [[170, 172], ["attack_assist.word_embedding.WordEmbedding"], "methods", ["None"], ["", "def", "get_embedding", "(", "self", ")", ":", "\n", "        ", "return", "WordEmbedding", "(", "self", ".", "word2id", ",", "self", ".", "embedding", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.char_width": [[15, 23], ["None"], "function", ["None"], ["def", "char_width", "(", "o", ")", ":", "\n", "    ", "global", "widths", "\n", "if", "o", "==", "0xe", "or", "o", "==", "0xf", ":", "\n", "        ", "return", "0", "\n", "", "for", "num", ",", "wid", "in", "widths", ":", "\n", "        ", "if", "o", "<=", "num", ":", "\n", "            ", "return", "wid", "\n", "", "", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len": [[24, 30], ["isinstance", "visualizer.char_width", "ord"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.char_width"], ["", "def", "sent_len", "(", "s", ")", ":", "\n", "    ", "assert", "isinstance", "(", "s", ",", "str", ")", "\n", "ret", "=", "0", "\n", "for", "it", "in", "s", ":", "\n", "        ", "ret", "+=", "char_width", "(", "ord", "(", "it", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.right_bar_print": [[31, 56], ["ret.append", "info.items", "ret.append", "isinstance", "ret.append", "isinstance", "visualizer.sent_len", "isinstance", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len"], ["", "def", "right_bar_print", "(", "info", ",", "key_len", "=", "20", ",", "val_len", "=", "10", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "ret", ".", "append", "(", "\" \"", "*", "(", "key_len", "+", "val_len", ")", ")", "\n", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "        ", "row", "=", "\" %s: \"", "%", "(", "key", "[", ":", "key_len", "-", "3", "]", ")", "\n", "row", "+=", "\" \"", "*", "(", "key_len", "-", "sent_len", "(", "row", ")", ")", "\n", "if", "isinstance", "(", "val", ",", "bool", ")", ":", "\n", "            ", "if", "val", ":", "\n", "                ", "row", "+=", "\" yes\"", "+", "\" \"", "*", "(", "val_len", "-", "4", ")", "\n", "", "else", ":", "\n", "                ", "row", "+=", "\" no\"", "+", "\" \"", "*", "(", "val_len", "-", "3", ")", "\n", "", "", "elif", "isinstance", "(", "val", ",", "int", ")", ":", "\n", "            ", "val_str", "=", "\" %d\"", "%", "val", "\n", "row", "+=", "val_str", "+", "\" \"", "*", "(", "val_len", "-", "sent_len", "(", "val_str", ")", ")", "\n", "", "elif", "isinstance", "(", "val", ",", "float", ")", ":", "\n", "            ", "val_str", "=", "\" %.5g\"", "%", "val", "\n", "if", "sent_len", "(", "val_str", ")", ">", "val_len", ":", "\n", "                ", "val_str", "=", "(", "\" %.7f\"", "%", "val", ")", "[", ":", "val_len", "]", "\n", "", "row", "+=", "val_str", "+", "\" \"", "*", "(", "val_len", "-", "sent_len", "(", "val_str", ")", ")", "\n", "", "else", ":", "\n", "            ", "val_str", "=", "(", "\" %s\"", "%", "val", ")", "[", ":", "val_len", "]", "\n", "row", "+=", "val_str", "+", "\" \"", "*", "(", "val_len", "-", "sent_len", "(", "val_str", ")", ")", "\n", "", "ret", ".", "append", "(", "row", ")", "\n", "", "ret", ".", "append", "(", "\" \"", "*", "(", "key_len", "+", "val_len", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.word_align": [[57, 63], ["visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len"], ["", "def", "word_align", "(", "wordA", ",", "wordB", ")", ":", "\n", "    ", "if", "sent_len", "(", "wordA", ")", "<", "sent_len", "(", "wordB", ")", ":", "\n", "        ", "wordA", "+=", "\" \"", "*", "(", "sent_len", "(", "wordB", ")", "-", "sent_len", "(", "wordA", ")", ")", "\n", "", "else", ":", "\n", "        ", "wordB", "+=", "\" \"", "*", "(", "sent_len", "(", "wordA", ")", "-", "sent_len", "(", "wordB", ")", ")", "\n", "", "return", "wordA", ",", "wordB", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.levenshtein_visual": [[64, 107], ["len", "len", "numpy.zeros", "range", "range", "ret.append", "ret.append", "a[].lower", "b[].lower", "ret.append", "visualizer.word_align", "visualizer.word_align", "ret.append", "visualizer.word_align", "ret.append", "ret.append", "a[].lower", "b[].lower", "visualizer.word_align", "visualizer.word_align", "min"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.word_align", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.word_align", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.word_align", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.word_align", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.word_align"], ["", "def", "levenshtein_visual", "(", "a", ",", "b", ")", ":", "\n", "    ", "la", "=", "len", "(", "a", ")", "\n", "lb", "=", "len", "(", "b", ")", "\n", "f", "=", "np", ".", "zeros", "(", "(", "la", "+", "1", ",", "lb", "+", "1", ")", ",", "dtype", "=", "np", ".", "uint64", ")", "\n", "for", "i", "in", "range", "(", "la", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "lb", "+", "1", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "f", "[", "i", "]", "[", "j", "]", "=", "j", "\n", "", "elif", "j", "==", "0", ":", "\n", "                ", "f", "[", "i", "]", "[", "j", "]", "=", "i", "\n", "", "elif", "a", "[", "i", "-", "1", "]", ".", "lower", "(", ")", "==", "b", "[", "j", "-", "1", "]", ".", "lower", "(", ")", ":", "\n", "                ", "f", "[", "i", "]", "[", "j", "]", "=", "f", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "f", "[", "i", "]", "[", "j", "]", "=", "min", "(", "f", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", ",", "f", "[", "i", "-", "1", "]", "[", "j", "]", ",", "f", "[", "i", "]", "[", "j", "-", "1", "]", ")", "+", "1", "\n", "\n", "", "", "", "p", ",", "q", "=", "la", ",", "lb", "\n", "ret", "=", "[", "]", "\n", "while", "p", ">", "0", "and", "q", ">", "0", ":", "\n", "        ", "if", "a", "[", "p", "-", "1", "]", ".", "lower", "(", ")", "==", "b", "[", "q", "-", "1", "]", ".", "lower", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "(", "a", "[", "p", "-", "1", "]", ",", "b", "[", "q", "-", "1", "]", ")", ")", "\n", "p", "-=", "1", "\n", "q", "-=", "1", "\n", "", "else", ":", "\n", "            ", "if", "f", "[", "p", "]", "[", "q", "]", "==", "f", "[", "p", "-", "1", "]", "[", "q", "-", "1", "]", "+", "1", ":", "\n", "# modify", "\n", "                ", "ret", ".", "append", "(", "word_align", "(", "a", "[", "p", "-", "1", "]", ",", "b", "[", "q", "-", "1", "]", ")", ")", "\n", "p", "-=", "1", "\n", "q", "-=", "1", "\n", "", "elif", "f", "[", "p", "]", "[", "q", "]", "==", "f", "[", "p", "-", "1", "]", "[", "q", "]", "+", "1", ":", "\n", "# remove", "\n", "                ", "ret", ".", "append", "(", "word_align", "(", "a", "[", "p", "-", "1", "]", ",", "\"\"", ")", ")", "\n", "p", "-=", "1", "\n", "", "else", ":", "\n", "                ", "assert", "f", "[", "p", "]", "[", "q", "]", "==", "f", "[", "p", "]", "[", "q", "-", "1", "]", "+", "1", "\n", "ret", ".", "append", "(", "word_align", "(", "\"\"", ",", "b", "[", "q", "-", "1", "]", ")", ")", "\n", "q", "-=", "1", "\n", "", "", "", "while", "p", ">", "0", ":", "\n", "        ", "ret", ".", "append", "(", "word_align", "(", "a", "[", "p", "-", "1", "]", ",", "\"\"", ")", ")", "\n", "p", "-=", "1", "\n", "", "while", "q", ">", "0", ":", "\n", "        ", "ret", ".", "append", "(", "word_align", "(", "\"\"", ",", "b", "[", "q", "-", "1", "]", ")", ")", "\n", "q", "-=", "1", "\n", "", "return", "ret", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.left_bar_print": [[108, 152], ["isinstance", "ret.append", "ret.append", "tokenizer.tokenize", "tokenizer.tokenize", "visualizer.levenshtein_visual", "isinstance", "isinstance", "ret.append", "ret.append", "ret.append", "visualizer.sent_len", "visualizer.sent_len", "ret.append", "ret.append", "ret.append", "y_orig.argmax", "y_adv.argmax", "visualizer.sent_len", "tokenA.lower", "tokenB.lower", "visualizer.sent_len", "tokenA.lower", "tokenB.lower", "y_orig.max", "y_adv.max", "visualizer.sent_len", "visualizer.sent_len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.levenshtein_visual", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len"], ["", "def", "left_bar_print", "(", "x_orig", ",", "y_orig", ",", "x_adv", ",", "y_adv", ",", "max_len", ",", "tokenizer", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "\n", "assert", "isinstance", "(", "y_orig", ",", "int", ")", "==", "isinstance", "(", "y_adv", ",", "int", ")", "\n", "if", "isinstance", "(", "y_orig", ",", "int", ")", ":", "\n", "        ", "head_str", "=", "\"Label: %d --> %d\"", "%", "(", "y_orig", ",", "y_adv", ")", "\n", "", "else", ":", "\n", "        ", "head_str", "=", "\"Label: %d (%.2lf%%) --> %d (%.2lf%%)\"", "%", "(", "y_orig", ".", "argmax", "(", ")", ",", "y_orig", ".", "max", "(", ")", "*", "100", ",", "y_adv", ".", "argmax", "(", ")", ",", "y_adv", ".", "max", "(", ")", "*", "100", ")", "\n", "", "ret", ".", "append", "(", "(", "\"\\033[32m%s\\033[0m\"", "%", "head_str", ")", "+", "\" \"", "*", "(", "max_len", "-", "sent_len", "(", "head_str", ")", ")", ")", "\n", "ret", ".", "append", "(", "\" \"", "*", "max_len", ")", "\n", "\n", "token_orig", "=", "tokenizer", ".", "tokenize", "(", "x_orig", ",", "pos_tagging", "=", "False", ")", "\n", "token_adv", "=", "tokenizer", ".", "tokenize", "(", "x_adv", ",", "pos_tagging", "=", "False", ")", "\n", "pairs", "=", "levenshtein_visual", "(", "token_orig", ",", "token_adv", ")", "\n", "\n", "curr1", "=", "\"\"", "\n", "curr2", "=", "\"\"", "\n", "length", "=", "0", "\n", "for", "tokenA", ",", "tokenB", "in", "pairs", ":", "\n", "        ", "assert", "sent_len", "(", "tokenA", ")", "==", "sent_len", "(", "tokenB", ")", "\n", "if", "length", "+", "sent_len", "(", "tokenA", ")", "+", "1", ">", "max_len", ":", "\n", "            ", "ret", ".", "append", "(", "curr1", "+", "\" \"", "*", "(", "max_len", "-", "length", ")", ")", "\n", "ret", ".", "append", "(", "curr2", "+", "\" \"", "*", "(", "max_len", "-", "length", ")", ")", "\n", "ret", ".", "append", "(", "\" \"", "*", "max_len", ")", "\n", "length", "=", "sent_len", "(", "tokenA", ")", "+", "1", "\n", "if", "tokenA", ".", "lower", "(", ")", "==", "tokenB", ".", "lower", "(", ")", ":", "\n", "                ", "curr1", "=", "tokenA", "+", "\" \"", "\n", "curr2", "=", "tokenB", "+", "\" \"", "\n", "", "else", ":", "\n", "                ", "curr1", "=", "\"\\033[1;31m\"", "+", "tokenA", "+", "\"\\033[0m\"", "+", "\" \"", "\n", "curr2", "=", "\"\\033[1;32m\"", "+", "tokenB", "+", "\"\\033[0m\"", "+", "\" \"", "\n", "", "", "else", ":", "\n", "            ", "length", "+=", "1", "+", "sent_len", "(", "tokenA", ")", "\n", "if", "tokenA", ".", "lower", "(", ")", "==", "tokenB", ".", "lower", "(", ")", ":", "\n", "                ", "curr1", "+=", "tokenA", "+", "\" \"", "\n", "curr2", "+=", "tokenB", "+", "\" \"", "\n", "", "else", ":", "\n", "                ", "curr1", "+=", "\"\\033[1;31m\"", "+", "tokenA", "+", "\"\\033[0m\"", "+", "\" \"", "\n", "curr2", "+=", "\"\\033[1;32m\"", "+", "tokenB", "+", "\"\\033[0m\"", "+", "\" \"", "\n", "", "", "", "if", "length", ">", "0", ":", "\n", "        ", "ret", ".", "append", "(", "curr1", "+", "\" \"", "*", "(", "max_len", "-", "length", ")", ")", "\n", "ret", ".", "append", "(", "curr2", "+", "\" \"", "*", "(", "max_len", "-", "length", ")", ")", "\n", "ret", ".", "append", "(", "\" \"", "*", "max_len", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.left_bar_failed": [[153, 174], ["isinstance", "ret.append", "ret.append", "tokenizer.tokenize", "ret.append", "visualizer.sent_len", "ret.append", "ret.append", "y_orig.argmax", "y_orig.max", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len", "visualizer.sent_len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len"], ["", "def", "left_bar_failed", "(", "x_orig", ",", "y_orig", ",", "max_len", ",", "tokenizer", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "\n", "if", "isinstance", "(", "y_orig", ",", "int", ")", ":", "\n", "        ", "head_str", "=", "\"Label: %d --> Failed!\"", "%", "y_orig", "\n", "", "else", ":", "\n", "        ", "head_str", "=", "\"Label: %d (%.2lf%%) --> Failed!\"", "%", "(", "y_orig", ".", "argmax", "(", ")", ",", "y_orig", ".", "max", "(", ")", "*", "100", ")", "\n", "", "ret", ".", "append", "(", "(", "\"\\033[31m%s\\033[0m\"", "%", "head_str", ")", "+", "\" \"", "*", "(", "max_len", "-", "sent_len", "(", "head_str", ")", ")", ")", "\n", "ret", ".", "append", "(", "\" \"", "*", "max_len", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "x_orig", ",", "pos_tagging", "=", "False", ")", "\n", "curr", "=", "\"\"", "\n", "for", "tk", "in", "tokens", ":", "\n", "        ", "if", "sent_len", "(", "curr", ")", "+", "sent_len", "(", "tk", ")", "+", "1", ">", "max_len", ":", "\n", "            ", "ret", ".", "append", "(", "curr", "+", "\" \"", "*", "(", "max_len", "-", "sent_len", "(", "curr", ")", ")", ")", "\n", "curr", "=", "tk", "+", "\" \"", "\n", "", "else", ":", "\n", "            ", "curr", "+=", "tk", "+", "\" \"", "\n", "", "", "if", "sent_len", "(", "curr", ")", ">", "0", ":", "\n", "        ", "ret", ".", "append", "(", "curr", "+", "\" \"", "*", "(", "max_len", "-", "sent_len", "(", "curr", ")", ")", ")", "\n", "", "ret", ".", "append", "(", "\" \"", "*", "max_len", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.visualizer": [[175, 221], ["stream_writer", "visualizer.right_bar_print", "zip", "visualizer.left_bar_failed", "visualizer.left_bar_print", "len", "len", "len", "len", "stream_writer", "stream_writer", "stream_writer", "stream_writer", "os.get_terminal_size", "len", "len", "left_bar_print.append", "left_bar_print.insert", "left_bar_print.append", "len", "len", "len", "len", "right_bar_print.append", "right_bar_print.insert", "right_bar_print.append", "visualizer.sent_len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.right_bar_print", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.left_bar_failed", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.left_bar_print", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.sent_len"], ["", "def", "visualizer", "(", "idx", ",", "x_orig", ",", "y_orig", ",", "x_adv", ",", "y_adv", ",", "info", ",", "stream_writer", ",", "tokenizer", ",", "key_len", "=", "25", ",", "val_len", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Visualization tools used in :py:class:`.DefaultAttackEval`.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "cols", "=", "os", ".", "get_terminal_size", "(", ")", ".", "columns", "\n", "", "except", "OSError", ":", "\n", "        ", "cols", "=", "80", "\n", "\n", "", "headline", "=", "\"Sample: %d \"", "%", "idx", "\n", "headline", "=", "headline", "+", "(", "\"=\"", "*", "(", "cols", "-", "sent_len", "(", "headline", ")", "-", "1", ")", ")", "+", "\"\\n\"", "\n", "stream_writer", "(", "headline", ")", "\n", "\n", "max_len", "=", "cols", "-", "1", "-", "key_len", "-", "val_len", "\n", "\n", "right", "=", "right_bar_print", "(", "info", ",", "key_len", "=", "key_len", ",", "val_len", "=", "val_len", ")", "\n", "if", "x_adv", "is", "None", ":", "\n", "# Failed", "\n", "        ", "left", "=", "left_bar_failed", "(", "x_orig", ",", "y_orig", ",", "max_len", ",", "tokenizer", ")", "\n", "", "else", ":", "\n", "        ", "left", "=", "left_bar_print", "(", "x_orig", ",", "y_orig", ",", "x_adv", ",", "y_adv", ",", "max_len", ",", "tokenizer", ")", "\n", "\n", "", "if", "len", "(", "left", ")", "<", "len", "(", "right", ")", ":", "\n", "        ", "delta", "=", "len", "(", "right", ")", "-", "len", "(", "left", ")", "\n", "if", "delta", "%", "2", "==", "1", ":", "\n", "            ", "left", ".", "append", "(", "\" \"", "*", "max_len", ")", "\n", "delta", "-=", "1", "\n", "", "while", "delta", ">", "0", ":", "\n", "            ", "delta", "-=", "2", "\n", "left", ".", "insert", "(", "1", ",", "\" \"", "*", "max_len", ")", "\n", "left", ".", "append", "(", "\" \"", "*", "max_len", ")", "\n", "", "", "elif", "len", "(", "right", ")", "<", "len", "(", "left", ")", ":", "\n", "        ", "delta", "=", "len", "(", "left", ")", "-", "len", "(", "right", ")", "\n", "if", "delta", "%", "2", "==", "1", ":", "\n", "            ", "right", ".", "append", "(", "\" \"", "*", "(", "key_len", "+", "val_len", ")", ")", "\n", "delta", "-=", "1", "\n", "", "while", "delta", ">", "0", ":", "\n", "            ", "delta", "-=", "2", "\n", "right", ".", "insert", "(", "0", ",", "\" \"", "*", "(", "key_len", "+", "val_len", ")", ")", "\n", "right", ".", "append", "(", "\" \"", "*", "(", "key_len", "+", "val_len", ")", ")", "\n", "", "", "assert", "len", "(", "left", ")", "==", "len", "(", "right", ")", "\n", "for", "l", ",", "r", "in", "zip", "(", "left", ",", "right", ")", ":", "\n", "        ", "stream_writer", "(", "l", ")", "\n", "stream_writer", "(", "\"|\"", ")", "\n", "stream_writer", "(", "r", ")", "\n", "stream_writer", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.result_visualizer": [[223, 271], ["result.items", "max", "max", "stream_writer", "stream_writer", "stream_writer", "zip", "stream_writer", "left.append", "isinstance", "list", "list", "len", "stream_writer", "os.get_terminal_size", "right.append", "isinstance", "map", "map", "right.append", "isinstance", "len", "len", "len", "right.append", "right.append", "len"], "function", ["None"], ["", "", "def", "result_visualizer", "(", "result", ",", "stream_writer", ")", ":", "\n", "    ", "\"\"\"\n    Visualization tools used in :py:class:`.DefaultAttackEval`.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "cols", "=", "os", ".", "get_terminal_size", "(", ")", ".", "columns", "\n", "", "except", "OSError", ":", "\n", "        ", "cols", "=", "80", "\n", "\n", "", "left", "=", "[", "]", "\n", "right", "=", "[", "]", "\n", "for", "key", ",", "val", "in", "result", ".", "items", "(", ")", ":", "\n", "        ", "left", ".", "append", "(", "\" \"", "+", "key", "+", "\": \"", ")", "\n", "if", "isinstance", "(", "val", ",", "bool", ")", ":", "\n", "            ", "right", ".", "append", "(", "\" \"", "+", "\"yes\"", "if", "val", "else", "\"no\"", ")", "\n", "", "elif", "isinstance", "(", "val", ",", "int", ")", ":", "\n", "            ", "right", ".", "append", "(", "\" %d\"", "%", "val", ")", "\n", "", "elif", "isinstance", "(", "val", ",", "float", ")", ":", "\n", "            ", "right", ".", "append", "(", "\" %.5g\"", "%", "val", ")", "\n", "", "else", ":", "\n", "            ", "right", ".", "append", "(", "\" %s\"", "%", "val", ")", "\n", "", "right", "[", "-", "1", "]", "+=", "\" \"", "\n", "\n", "", "max_left", "=", "max", "(", "list", "(", "map", "(", "len", ",", "left", ")", ")", ")", "\n", "max_right", "=", "max", "(", "list", "(", "map", "(", "len", ",", "right", ")", ")", ")", "\n", "if", "max_left", "+", "max_right", "+", "3", ">", "cols", ":", "\n", "        ", "delta", "=", "max_left", "+", "max_right", "+", "3", "-", "cols", "\n", "if", "delta", "%", "2", "==", "1", ":", "\n", "            ", "delta", "-=", "1", "\n", "max_left", "-=", "1", "\n", "", "max_left", "-=", "delta", "//", "2", "\n", "max_right", "-=", "delta", "//", "2", "\n", "", "total", "=", "max_left", "+", "max_right", "+", "3", "\n", "\n", "title", "=", "\"Summary\"", "\n", "if", "total", "-", "2", "<", "len", "(", "title", ")", ":", "\n", "        ", "title", "=", "title", "[", ":", "total", "-", "2", "]", "\n", "", "offtitle", "=", "(", "(", "total", "-", "len", "(", "title", ")", ")", "//", "2", ")", "-", "1", "\n", "stream_writer", "(", "\"+\"", "+", "(", "\"=\"", "*", "(", "total", "-", "2", ")", ")", "+", "\"+\\n\"", ")", "\n", "stream_writer", "(", "\"|\"", "+", "\" \"", "*", "offtitle", "+", "title", "+", "\" \"", "*", "(", "total", "-", "2", "-", "offtitle", "-", "len", "(", "title", ")", ")", "+", "\"|\"", "+", "\"\\n\"", ")", "\n", "stream_writer", "(", "\"+\"", "+", "(", "\"=\"", "*", "(", "total", "-", "2", ")", ")", "+", "\"+\\n\"", ")", "\n", "for", "l", ",", "r", "in", "zip", "(", "left", ",", "right", ")", ":", "\n", "        ", "l", "=", "l", "[", ":", "max_left", "]", "\n", "r", "=", "r", "[", ":", "max_right", "]", "\n", "l", "+=", "\" \"", "*", "(", "max_left", "-", "len", "(", "l", ")", ")", "\n", "r", "+=", "\" \"", "*", "(", "max_right", "-", "len", "(", "r", ")", ")", "\n", "stream_writer", "(", "\"|\"", "+", "l", "+", "\"|\"", "+", "r", "+", "\"|\"", "+", "\"\\n\"", ")", "\n", "", "stream_writer", "(", "\"+\"", "+", "(", "\"=\"", "*", "(", "total", "-", "2", ")", ")", "+", "\"+\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.zip_downloader.make_zip_downloader": [[7, 57], ["isinstance", "URL.startswith", "zipfile.ZipFile", "os.makedirs", "zipfile.ZipFile.close", "os.remove", "URL.startswith", "URL.startswith", "source.endswith", "os.path.basename", "urllib.request.urlopen", "int", "zipfile.ZipFile.extractall", "open", "ftmp.flush", "zipfile.ZipFile.extract", "tqdm.tqdm", "fin.read", "ftmp.write", "pbar.update", "len", "len"], "function", ["None"], ["def", "make_zip_downloader", "(", "URL", ":", "str", ",", "file_list", "=", "None", ",", "resource_name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function is used to make a zipfile downloader for data.\n    \"\"\"", "\n", "if", "isinstance", "(", "file_list", ",", "str", ")", ":", "\n", "        ", "file_list", "=", "[", "file_list", "]", "\n", "\n", "", "use_source", "=", "not", "(", "URL", ".", "startswith", "(", "\"http://\"", ")", "or", "URL", ".", "startswith", "(", "\"https://\"", ")", ")", "\n", "if", "use_source", "and", "URL", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "URL", "=", "URL", "[", "1", ":", "]", "\n", "\n", "", "def", "DOWNLOAD", "(", "path", ":", "str", ",", "source", ":", "str", ")", ":", "\n", "        ", "if", "not", "source", ".", "endswith", "(", "\"/\"", ")", ":", "\n", "            ", "source", "=", "source", "+", "\"/\"", "\n", "", "if", "use_source", ":", "\n", "            ", "remote_url", "=", "source", "+", "URL", "\n", "", "else", ":", "\n", "            ", "remote_url", "=", "URL", "\n", "\n", "", "if", "resource_name", "is", "None", ":", "\n", "            ", "name", "=", "os", ".", "path", ".", "basename", "(", "path", ")", "\n", "", "else", ":", "\n", "            ", "name", "=", "resource_name", "\n", "\n", "", "with", "urllib", ".", "request", ".", "urlopen", "(", "remote_url", ")", "as", "fin", ":", "\n", "            ", "CHUNK_SIZE", "=", "4", "*", "1024", "\n", "total_length", "=", "int", "(", "fin", ".", "headers", "[", "\"content-length\"", "]", ")", "\n", "with", "open", "(", "path", "+", "\".zip\"", ",", "\"wb\"", ")", "as", "ftmp", ":", "\n", "                ", "with", "tqdm", "(", "total", "=", "total_length", ",", "unit", "=", "\"B\"", ",", "desc", "=", "\"Downloading %s\"", "%", "name", ",", "unit_scale", "=", "True", ")", "as", "pbar", ":", "\n", "                    ", "while", "True", ":", "\n", "                        ", "data", "=", "fin", ".", "read", "(", "CHUNK_SIZE", ")", "\n", "if", "len", "(", "data", ")", "==", "0", ":", "\n", "                            ", "break", "\n", "", "ftmp", ".", "write", "(", "data", ")", "\n", "pbar", ".", "update", "(", "len", "(", "data", ")", ")", "\n", "", "", "ftmp", ".", "flush", "(", ")", "\n", "\n", "", "", "zf", "=", "zipfile", ".", "ZipFile", "(", "path", "+", "\".zip\"", ")", "\n", "\n", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "if", "file_list", "is", "not", "None", ":", "\n", "            ", "for", "file", "in", "file_list", ":", "\n", "                ", "zf", ".", "extract", "(", "file", ",", "path", ")", "\n", "", "", "else", ":", "\n", "            ", "zf", ".", "extractall", "(", "path", ")", "\n", "", "zf", ".", "close", "(", ")", "\n", "os", ".", "remove", "(", "path", "+", "\".zip\"", ")", "\n", "return", "\n", "\n", "", "return", "DOWNLOAD", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.transformers_hook.HookCloser.__init__": [[2, 4], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_wrapper", ")", ":", "\n", "        ", "self", ".", "model_wrapper", "=", "model_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.transformers_hook.HookCloser.__call__": [[5, 8], ["output_.retain_grad"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "module", ",", "input_", ",", "output_", ")", ":", "\n", "        ", "self", ".", "model_wrapper", ".", "curr_embedding", "=", "output_", "\n", "output_", ".", "retain_grad", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.transform_label.update_label": [[2, 18], ["labels_to_labels.items", "dataset.remove_columns.rename_column", "dataset.remove_columns.remove_columns"], "function", ["None"], ["def", "update_label", "(", "dataset", ",", "labels_to_labels", ")", ":", "\n", "    ", "\"\"\"\n    :param datasets dataset: The huggingface datasets you use.\n    :param dict labels_to_labels: map the origin labels to the labels you want.\n\n    :Package Requirements:\n        * **datasets**\n\n    \"\"\"", "\n", "features", "=", "[", "kw", "for", "kw", "in", "dataset", ".", "features", "]", "\n", "for", "kw", "in", "features", ":", "\n", "        ", "if", "kw", "not", "in", "labels_to_labels", ":", "\n", "            ", "dataset", "=", "dataset", ".", "remove_columns", "(", "[", "kw", "]", ")", "\n", "", "", "for", "key", ",", "value", "in", "labels_to_labels", ".", "items", "(", ")", ":", "\n", "        ", "dataset", "=", "dataset", ".", "rename_column", "(", "key", ",", "value", ")", "\n", "", "return", "dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language": [[1, 28], ["lang_tag_cnt.items", "RuntimeError", "len", "RuntimeError", "unsupported_names.append"], "function", ["None"], ["def", "get_language", "(", "obj_list", ")", ":", "\n", "    ", "lang_tag_cnt", "=", "{", "}", "\n", "for", "it", "in", "obj_list", ":", "\n", "        ", "for", "tag", "in", "it", ".", "TAGS", ":", "\n", "            ", "if", "tag", ".", "type", "==", "\"lang\"", ":", "\n", "                ", "if", "tag", "not", "in", "lang_tag_cnt", ":", "\n", "                    ", "lang_tag_cnt", "[", "tag", "]", "=", "0", "\n", "", "lang_tag_cnt", "[", "tag", "]", "+=", "1", "\n", "\n", "# argmax", "\n", "", "", "", "lang_tag", "=", "None", "\n", "for", "tag", ",", "cnt", "in", "lang_tag_cnt", ".", "items", "(", ")", ":", "\n", "        ", "if", "lang_tag", "is", "None", "or", "cnt", ">", "lang_tag_cnt", "[", "lang_tag", "]", ":", "\n", "            ", "lang_tag", "=", "tag", "\n", "\n", "# no language", "\n", "", "", "if", "lang_tag", "is", "None", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"No language support\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "lang_tag_cnt", "[", "lang_tag", "]", "<", "len", "(", "obj_list", ")", ":", "\n", "            ", "unsupported_names", "=", "[", "]", "\n", "for", "it", "in", "obj_list", ":", "\n", "                ", "if", "lang_tag", "not", "in", "it", ".", "TAGS", ":", "\n", "                    ", "unsupported_names", ".", "append", "(", "it", ".", "__class__", ".", "__name__", ")", "\n", "", "", "raise", "RuntimeError", "(", "\"Try to use language `%s`, but %s not support \"", "%", "(", "lang_tag", ",", "unsupported_names", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "lang_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language": [[29, 36], ["len", "RuntimeError", "unsupported_names.append"], "function", ["None"], ["", "", "", "def", "check_language", "(", "obj_list", ",", "lang_tag", ")", ":", "\n", "    ", "unsupported_names", "=", "[", "]", "\n", "for", "it", "in", "obj_list", ":", "\n", "        ", "if", "lang_tag", "not", "in", "it", ".", "TAGS", ":", "\n", "            ", "unsupported_names", ".", "append", "(", "it", ".", "__class__", ".", "__name__", ")", "\n", "", "", "if", "len", "(", "unsupported_names", ")", ">", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"using language `%s`, but %s not support \"", "%", "(", "lang_tag", ",", "unsupported_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name": [[37, 45], ["None"], "function", ["None"], ["", "", "def", "language_by_name", "(", "name", ")", ":", "\n", "    ", "from", ".", ".", "tags", "import", "TAG_ALL_LANGUAGE", ",", "TAG_English", "\n", "if", "name", "is", "None", ":", "\n", "        ", "return", "TAG_English", "\n", "", "for", "tag", "in", "TAG_ALL_LANGUAGE", ":", "\n", "        ", "if", "tag", ".", "name", "==", "name", ":", "\n", "            ", "return", "tag", "\n", "", "", "return", "None", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.semantic.SemanticSimilarity._select": [[7, 11], ["UniversalSentenceEncoder"], "methods", ["None"], ["def", "_select", "(", "self", ",", "lang", ")", ":", "\n", "        ", "if", "lang", ".", "name", "==", "\"english\"", ":", "\n", "            ", "from", ".", ".", "algorithms", ".", "usencoder", "import", "UniversalSentenceEncoder", "\n", "return", "UniversalSentenceEncoder", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.base.MetricSelector.select": [[9, 11], ["base.MetricSelector._select"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.modify.ModificationRate._select"], ["def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.base.MetricSelector._select": [[12, 14], ["NotImplementedError"], "methods", ["None"], ["        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.grammar.GrammaticalErrors._select": [[8, 15], ["LanguageTool", "LanguageToolChinese"], "methods", ["None"], ["def", "_select", "(", "self", ",", "lang", ")", ":", "\n", "        ", "if", "lang", ".", "name", "==", "\"english\"", ":", "\n", "            ", "from", ".", ".", "algorithms", ".", "language_tool", "import", "LanguageTool", "\n", "return", "LanguageTool", "(", ")", "\n", "", "if", "lang", ".", "name", "==", "\"chinese\"", ":", "\n", "            ", "from", ".", ".", "algorithms", ".", "language_tool", "import", "LanguageToolChinese", "\n", "return", "LanguageToolChinese", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.edit_distance.EditDistance._select": [[10, 13], ["Levenshtein", "text_process.tokenizer.get_default_tokenizer"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer"], ["def", "_select", "(", "self", ",", "lang", ")", ":", "\n", "        ", "from", ".", ".", "algorithms", ".", "levenshtein", "import", "Levenshtein", "\n", "return", "Levenshtein", "(", "get_default_tokenizer", "(", "lang", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.fluency.Fluency._select": [[8, 15], ["GPT2LM", "GPT2LMChinese"], "methods", ["None"], ["def", "_select", "(", "self", ",", "lang", ")", ":", "\n", "        ", "if", "lang", ".", "name", "==", "\"english\"", ":", "\n", "            ", "from", ".", ".", "algorithms", ".", "gptlm", "import", "GPT2LM", "\n", "return", "GPT2LM", "(", ")", "\n", "", "if", "lang", ".", "name", "==", "\"chinese\"", ":", "\n", "            ", "from", ".", ".", "algorithms", ".", "gptlm", "import", "GPT2LMChinese", "\n", "return", "GPT2LMChinese", "(", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.modify.ModificationRate._select": [[9, 12], ["Modification", "text_process.tokenizer.get_default_tokenizer"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer"], ["def", "_select", "(", "self", ",", "lang", ")", ":", "\n", "        ", "from", ".", ".", "algorithms", ".", "modification", "import", "Modification", "\n", "return", "Modification", "(", "get_default_tokenizer", "(", "lang", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.gptlm.GPT2LM.__init__": [[11, 23], ["transformers.GPT2TokenizerFast.from_pretrained", "transformers.GPT2LMHeadModel.from_pretrained"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Language Models are Unsupervised Multitask Learners.\n        `[pdf] <https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf>`__\n        `[code] <https://github.com/openai/gpt-2>`__\n\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "self", ".", "tokenizer", "=", "transformers", ".", "GPT2TokenizerFast", ".", "from_pretrained", "(", "\"gpt2\"", ")", "\n", "self", ".", "lm", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "\"gpt2\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.gptlm.GPT2LM.after_attack": [[24, 29], ["gptlm.GPT2LM.tokenizer", "math.exp", "gptlm.GPT2LM.lm"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.tokenizer"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "ipt", "=", "self", ".", "tokenizer", "(", "adversarial_sample", ",", "return_tensors", "=", "\"pt\"", ",", "verbose", "=", "False", ")", "\n", "return", "math", ".", "exp", "(", "self", ".", "lm", "(", "**", "ipt", ",", "labels", "=", "ipt", ".", "input_ids", ")", "[", "0", "]", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.gptlm.GPT2LMChinese.__init__": [[36, 50], ["transformers.BertTokenizerFast.from_pretrained", "transformers.GPT2LMHeadModel.from_pretrained"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Language Models are Unsupervised Multitask Learners.\n        `[pdf] <https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf>`__\n        `[code] <https://github.com/openai/gpt-2>`__\n\n        :Package Requirements:\n            * tensorflow>=2\n        :Language: chinese\n\n        \"\"\"", "\n", "## TODO train a pytorch chinese gpt-2 model", "\n", "self", ".", "tokenizer", "=", "transformers", ".", "BertTokenizerFast", ".", "from_pretrained", "(", "\"mymusise/EasternFantasyNoval\"", ")", "\n", "self", ".", "lm", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "\"mymusise/EasternFantasyNoval\"", ",", "from_tf", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.base.AttackMetric.before_attack": [[9, 11], ["None"], "methods", ["None"], ["def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.base.AttackMetric.after_attack": [[12, 14], ["None"], "methods", ["None"], ["        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.base.AttackMetric.name": [[15, 21], ["hasattr"], "methods", ["None"], ["", "return", "invoke_wrapper", "\n", "\n", "", "class", "Victim", ":", "\n", "    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_method_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.modification.Modification.__init__": [[9, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ":", "Tokenizer", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokenizer: A tokenizer that will be used in this metric. Must be an instance of :py:class:`.Tokenizer`\n\n        \"\"\"", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.modification.Modification.TAGS": [[17, 22], ["hasattr", "set"], "methods", ["None"], ["", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"TAGS\"", ")", ":", "\n", "            ", "return", "self", ".", "tokenizer", ".", "TAGS", "\n", "", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.modification.Modification.calc_score": [[23, 44], ["min", "zip", "len", "len", "abs", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "calc_score", "(", "self", ",", "tokenA", ":", "List", "[", "str", "]", ",", "tokenB", ":", "List", "[", "str", "]", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokenA: The first list of tokens.\n            tokenB: The second list of tokens.\n        Returns:\n            Modification rate.\n\n        Make sure two list have the same length.\n        \"\"\"", "\n", "va", "=", "tokenA", "\n", "vb", "=", "tokenB", "\n", "ret", "=", "0", "\n", "if", "len", "(", "va", ")", "!=", "len", "(", "vb", ")", ":", "\n", "            ", "ret", "=", "abs", "(", "len", "(", "va", ")", "-", "len", "(", "vb", ")", ")", "\n", "", "mn_len", "=", "min", "(", "len", "(", "va", ")", ",", "len", "(", "vb", ")", ")", "\n", "va", ",", "vb", "=", "va", "[", ":", "mn_len", "]", ",", "vb", "[", ":", "mn_len", "]", "\n", "for", "wordA", ",", "wordB", "in", "zip", "(", "va", ",", "vb", ")", ":", "\n", "            ", "if", "wordA", "!=", "wordB", ":", "\n", "                ", "ret", "+=", "1", "\n", "", "", "return", "ret", "/", "len", "(", "va", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.modification.Modification.after_attack": [[45, 48], ["modification.Modification.calc_score", "modification.Modification.tokenizer.tokenize", "modification.Modification.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "calc_score", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "input", "[", "\"x\"", "]", ",", "pos_tagging", "=", "False", ")", ",", "self", ".", "tokenizer", ".", "tokenize", "(", "adversarial_sample", ",", "pos_tagging", "=", "False", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.usencoder.UniversalSentenceEncoder.__init__": [[14, 31], ["hub.load", "data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Universal Sentence Encoder in tensorflow_hub.\n        `[pdf] <https://arxiv.org/pdf/1803.11175>`__\n        `[page] <https://tfhub.dev/google/universal-sentence-encoder/4>`__\n\n        :Data Requirements: :py:data:`.AttackAssist.UniversalSentenceEncoder`\n        :Package Requirements:\n            * **tensorflow** >= 2.0.0\n            * **tensorflow_hub**\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "import", "tensorflow_hub", "as", "hub", "\n", "\n", "self", ".", "embed", "=", "hub", ".", "load", "(", "DataManager", ".", "load", "(", "\"AttackAssist.UniversalSentenceEncoder\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.usencoder.UniversalSentenceEncoder.calc_score": [[32, 44], ["usencoder.UniversalSentenceEncoder.embed().numpy", "ret[].dot", "usencoder.UniversalSentenceEncoder.embed", "numpy.linalg.norm", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.norm", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.norm"], ["", "def", "calc_score", "(", "self", ",", "sentA", ":", "str", ",", "sentB", ":", "str", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Args:\n            sentA: The first sentence.\n            sentB: The second sentence.\n\n        Returns:\n            Cosine distance between two sentences.\n        \n        \"\"\"", "\n", "ret", "=", "self", ".", "embed", "(", "[", "sentA", ",", "sentB", "]", ")", ".", "numpy", "(", ")", "\n", "return", "ret", "[", "0", "]", ".", "dot", "(", "ret", "[", "1", "]", ")", "/", "(", "np", ".", "linalg", ".", "norm", "(", "ret", "[", "0", "]", ")", "*", "np", ".", "linalg", ".", "norm", "(", "ret", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.usencoder.UniversalSentenceEncoder.after_attack": [[45, 48], ["usencoder.UniversalSentenceEncoder.calc_score"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "calc_score", "(", "input", "[", "\"x\"", "]", ",", "adversarial_sample", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.language_tool.LanguageTool.__init__": [[10, 21], ["language_tool_python.LanguageTool"], "methods", ["None"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Use language_tool_python to check grammer.\n\n        :Package Requirements:\n            * language_tool_python\n        :Language: english\n\n        \"\"\"", "\n", "import", "language_tool_python", "\n", "self", ".", "language_tool", "=", "language_tool_python", ".", "LanguageTool", "(", "'en-US'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.language_tool.LanguageTool.after_attack": [[22, 25], ["len", "language_tool.LanguageTool.language_tool.check"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "len", "(", "self", ".", "language_tool", ".", "check", "(", "adversarial_sample", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.language_tool.LanguageToolChinese.__init__": [[31, 42], ["language_tool_python.LanguageTool"], "methods", ["None"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Use language_tool_python to check grammer.\n\n        :Package Requirements:\n            * language_tool_python\n        :Language: chinese\n\n        \"\"\"", "\n", "import", "language_tool_python", "\n", "self", ".", "language_tool", "=", "language_tool_python", ".", "LanguageTool", "(", "'zh-CN'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.language_tool.LanguageToolChinese.after_attack": [[43, 46], ["len", "language_tool.LanguageToolChinese.language_tool.check"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "len", "(", "self", ".", "language_tool", ".", "check", "(", "adversarial_sample", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.bleu.BLEU.__init__": [[7, 20], ["SmoothingFunction"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ":", "Tokenizer", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokenizer: A tokenizer that will be used in this metric. Must be an instance of :py:class:`.Tokenizer`\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "from", "nltk", ".", "translate", ".", "bleu_score", "import", "sentence_bleu", "\n", "from", "nltk", ".", "translate", ".", "bleu_score", "import", "SmoothingFunction", "\n", "self", ".", "smooth", "=", "SmoothingFunction", "(", ")", "\n", "self", ".", "sentence_bleu", "=", "sentence_bleu", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.bleu.BLEU.TAGS": [[21, 27], ["hasattr", "set"], "methods", ["None"], ["", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"TAGS\"", ")", ":", "\n", "            ", "return", "self", ".", "tokenizer", ".", "TAGS", "\n", "", "else", ":", "\n", "            ", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.bleu.BLEU.calc_score": [[28, 41], ["bleu.BLEU.sentence_bleu"], "methods", ["None"], ["", "", "def", "calc_score", "(", "self", ",", "tokenA", ":", "List", "[", "str", "]", ",", "tokenB", ":", "List", "[", "str", "]", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokenA: The first list of tokens.\n            tokenB: The second list of tokens.\n        Retruns:\n            The BLEU score.\n\n        Make sure two list have the same length.\n        \"\"\"", "\n", "ref", "=", "[", "tokenA", "]", "\n", "cand", "=", "tokenB", "\n", "return", "self", ".", "sentence_bleu", "(", "ref", ",", "cand", ",", "smoothing_function", "=", "self", ".", "smooth", ".", "method1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.bleu.BLEU.after_attack": [[42, 47], ["bleu.BLEU.calc_score", "bleu.BLEU.tokenizer.tokenize", "bleu.BLEU.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "calc_score", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "input", "[", "\"x\"", "]", ",", "pos_tagging", "=", "False", ")", ",", "self", ".", "tokenizer", ".", "tokenize", "(", "adversarial_sample", ",", "pos_tagging", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.jaccard_word.JaccardWord.__init__": [[9, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ":", "Tokenizer", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokenizer: A tokenizer that will be used in this metric. Must be an instance of :py:class:`.Tokenizer`\n\n        \"\"\"", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.jaccard_word.JaccardWord.TAGS": [[17, 22], ["hasattr", "set"], "methods", ["None"], ["", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"TAGS\"", ")", ":", "\n", "            ", "return", "self", ".", "tokenizer", ".", "TAGS", "\n", "", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.jaccard_word.JaccardWord.calc_score": [[23, 44], ["jaccard_word.JaccardWord.tokenizer.tokenize", "jaccard_word.JaccardWord.tokenizer.tokenize", "set", "set", "range", "range", "len", "set.add", "len", "set.add", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "calc_score", "(", "self", ",", "sentA", ":", "str", ",", "sentB", ":", "str", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Args:\n            sentA: First sentence.\n            sentB: Second sentence.\n\n        Returns:\n            Jaccard word similarity of two sentences.\n        \n        \"\"\"", "\n", "tokenA", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sentA", ",", "pos_tagging", "=", "False", ")", "\n", "tokenB", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sentB", ",", "pos_tagging", "=", "False", ")", "\n", "\n", "AS", "=", "set", "(", ")", "\n", "BS", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "tokenA", ")", ")", ":", "\n", "            ", "AS", ".", "add", "(", "tokenA", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "tokenB", ")", ")", ":", "\n", "            ", "BS", ".", "add", "(", "tokenB", "[", "i", "]", ")", "\n", "\n", "", "return", "len", "(", "AS", "&", "BS", ")", "/", "len", "(", "AS", "|", "BS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.jaccard_word.JaccardWord.after_attack": [[45, 49], ["jaccard_word.JaccardWord.calc_score"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "calc_score", "(", "input", "[", "\"x\"", "]", ",", "adversarial_sample", ")", "\n", "", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.jaccard_char.JaccardChar.calc_score": [[9, 27], ["set", "set", "range", "range", "len", "set.add", "len", "set.add", "len", "len"], "methods", ["None"], ["def", "calc_score", "(", "self", ",", "senA", ":", "str", ",", "senB", ":", "str", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Args:\n            senA: First sentence.\n            senB: Second sentence.\n\n        Returns:\n            Jaccard char similarity of two sentences.\n        \n        \"\"\"", "\n", "AS", "=", "set", "(", ")", "\n", "BS", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "senA", ")", ")", ":", "\n", "            ", "AS", ".", "add", "(", "senA", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "senB", ")", ")", ":", "\n", "            ", "BS", ".", "add", "(", "senB", "[", "i", "]", ")", "\n", "\n", "", "return", "len", "(", "AS", "&", "BS", ")", "/", "len", "(", "AS", "|", "BS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.jaccard_char.JaccardChar.after_attack": [[28, 32], ["jaccard_char.JaccardChar.calc_score"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "calc_score", "(", "input", "[", "\"x\"", "]", ",", "adversarial_sample", ")", "\n", "", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.levenshtein.Levenshtein.__init__": [[10, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ":", "Tokenizer", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokenizer: A tokenizer that will be used in this metric. Must be an instance of :py:class:`.Tokenizer`\n\n        \"\"\"", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.levenshtein.Levenshtein.TAGS": [[18, 23], ["hasattr", "set"], "methods", ["None"], ["", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"TAGS\"", ")", ":", "\n", "            ", "return", "self", ".", "tokenizer", ".", "TAGS", "\n", "", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.levenshtein.Levenshtein.calc_score": [[24, 48], ["len", "len", "torch.zeros", "range", "[].item", "range", "min"], "methods", ["None"], ["", "def", "calc_score", "(", "self", ",", "a", ":", "List", "[", "str", "]", ",", "b", ":", "List", "[", "str", "]", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Args:\n            a: The first list.\n            b: The second list.\n        Returns:\n            Levenshtein edit distance between two sentences.\n            \n        Both parameters can be str or list, str for char-level edit distance while list for token-level edit distance.\n        \"\"\"", "\n", "la", "=", "len", "(", "a", ")", "\n", "lb", "=", "len", "(", "b", ")", "\n", "f", "=", "torch", ".", "zeros", "(", "la", "+", "1", ",", "lb", "+", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "i", "in", "range", "(", "la", "+", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "lb", "+", "1", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "f", "[", "i", "]", "[", "j", "]", "=", "j", "\n", "", "elif", "j", "==", "0", ":", "\n", "                    ", "f", "[", "i", "]", "[", "j", "]", "=", "i", "\n", "", "elif", "a", "[", "i", "-", "1", "]", "==", "b", "[", "j", "-", "1", "]", ":", "\n", "                    ", "f", "[", "i", "]", "[", "j", "]", "=", "f", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "f", "[", "i", "]", "[", "j", "]", "=", "min", "(", "f", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", ",", "f", "[", "i", "-", "1", "]", "[", "j", "]", ",", "f", "[", "i", "]", "[", "j", "-", "1", "]", ")", "+", "1", "\n", "", "", "", "return", "f", "[", "la", "]", "[", "lb", "]", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.levenshtein.Levenshtein.after_attack": [[49, 52], ["levenshtein.Levenshtein.calc_score", "levenshtein.Levenshtein.tokenizer.tokenize", "levenshtein.Levenshtein.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "calc_score", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "input", "[", "\"x\"", "]", ",", "pos_tagging", "=", "False", ")", ",", "self", ".", "tokenizer", ".", "tokenize", "(", "adversarial_sample", ",", "pos_tagging", "=", "False", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.__init__": [[9, 19], ["SentenceTransformer", "DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :Pakcage Requirements:\n            * sentence_transformers\n        :Language: english\n\n        \"\"\"", "\n", "from", "sentence_transformers", "import", "SentenceTransformer", "\n", "from", "...", "data_manager", "import", "DataManager", "\n", "self", ".", "model", "=", "SentenceTransformer", "(", "DataManager", ".", "load", "(", "\"AttackAssist.SentenceTransformer\"", ")", ",", "device", "=", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score": [[20, 34], ["sentence_sim.SentenceSim.model.encode", "util.pytorch_cos_sim", "util.pytorch_cos_sim.cpu().numpy", "util.pytorch_cos_sim.cpu"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.encode"], ["", "def", "calc_score", "(", "self", ",", "sen1", ":", "str", ",", "sen2", ":", "str", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Args:\n            sen1: The first sentence.\n            sen2: The second sentence.\n        Returns:\n            Sentence similarity.\n            \n        \"\"\"", "\n", "\n", "from", "sentence_transformers", "import", "util", "\n", "emb1", ",", "emb2", "=", "self", ".", "model", ".", "encode", "(", "[", "sen1", ",", "sen2", "]", ",", "show_progress_bar", "=", "False", ")", "\n", "cos_sim", "=", "util", ".", "pytorch_cos_sim", "(", "emb1", ",", "emb2", ")", "\n", "return", "cos_sim", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.after_attack": [[35, 38], ["sentence_sim.SentenceSim.calc_score"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score"], ["", "def", "after_attack", "(", "self", ",", "input", ",", "adversarial_sample", ")", ":", "\n", "        ", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "calc_score", "(", "input", "[", "\"x\"", "]", ",", "adversarial_sample", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__init__": [[18, 76], ["utils.get_language", "utils.language_by_name", "text_process.tokenizer.get_default_tokenizer", "isinstance", "lst.append", "lst.append", "isinstance", "ValueError", "it.select", "attack_eval.AttackEval.metrics.append", "isinstance", "lst.append", "RuntimeError", "attack_eval.AttackEval.metrics.append", "TypeError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.selectors.base.MetricSelector.select"], ["    ", "def", "__init__", "(", "self", ",", "\n", "attacker", ":", "Attacker", ",", "\n", "victim", ":", "Victim", ",", "\n", "language", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "tokenizer", ":", "Optional", "[", "Tokenizer", "]", "=", "None", ",", "\n", "invoke_limit", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "metrics", ":", "List", "[", "Union", "[", "AttackMetric", ",", "MetricSelector", "]", "]", "=", "[", "]", "\n", ")", ":", "\n", "        ", "\"\"\"\n        `AttackEval` is a class used to evaluate attack metrics in OpenAttack.\n\n        Args:\n            attacker: An attacker, must be an instance of :py:class:`.Attacker` .\n            victim: A victim model, must be an instance of :py:class:`.Vicitm` .\n            language: The language used for the evaluation. If is `None` then `AttackEval` will intelligently select the language based on other parameters.\n            tokenizer: A tokenizer used for visualization.\n            invoke_limit: Limit on the number of model invokes.\n            metrics: A list of metrics. Each element must be an instance of :py:class:`.AttackMetric` or :py:class:`.MetricSelector` .\n\n        \"\"\"", "\n", "\n", "if", "language", "is", "None", ":", "\n", "            ", "lst", "=", "[", "attacker", "]", "\n", "if", "tokenizer", "is", "not", "None", ":", "\n", "                ", "lst", ".", "append", "(", "tokenizer", ")", "\n", "", "if", "victim", ".", "supported_language", "is", "not", "None", ":", "\n", "                ", "lst", ".", "append", "(", "victim", ")", "\n", "", "for", "it", "in", "metrics", ":", "\n", "                ", "if", "isinstance", "(", "it", ",", "AttackMetric", ")", ":", "\n", "                    ", "lst", ".", "append", "(", "it", ")", "\n", "\n", "", "", "lang_tag", "=", "get_language", "(", "lst", ")", "\n", "", "else", ":", "\n", "            ", "lang_tag", "=", "language_by_name", "(", "language", ")", "\n", "if", "lang_tag", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unsupported language `%s` in attack eval\"", "%", "language", ")", "\n", "\n", "", "", "self", ".", "_tags", "=", "{", "lang_tag", "}", "\n", "\n", "if", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "tokenizer", "=", "get_default_tokenizer", "(", "lang_tag", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "", "self", ".", "attacker", "=", "attacker", "\n", "self", ".", "victim", "=", "victim", "\n", "self", ".", "metrics", "=", "[", "]", "\n", "for", "it", "in", "metrics", ":", "\n", "            ", "if", "isinstance", "(", "it", ",", "MetricSelector", ")", ":", "\n", "                ", "v", "=", "it", ".", "select", "(", "lang_tag", ")", "\n", "if", "v", "is", "None", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"`%s` does not support language %s\"", "%", "(", "it", ".", "__class__", ".", "__name__", ",", "lang_tag", ".", "name", ")", ")", "\n", "", "self", ".", "metrics", ".", "append", "(", "v", ")", "\n", "", "elif", "isinstance", "(", "it", ",", "AttackMetric", ")", ":", "\n", "                ", "self", ".", "metrics", ".", "append", "(", "it", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\"`metrics` got %s, expect `MetricSelector` or `AttackMetric`\"", "%", "it", ".", "__class__", ".", "__name__", ")", "\n", "", "", "self", ".", "invoke_limit", "=", "invoke_limit", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.TAGS": [[77, 80], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__measure": [[81, 88], ["it.after_attack"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.after_attack"], ["", "def", "__measure", "(", "self", ",", "data", ",", "adversarial_sample", ")", ":", "\n", "        ", "ret", "=", "{", "}", "\n", "for", "it", "in", "self", ".", "metrics", ":", "\n", "            ", "value", "=", "it", ".", "after_attack", "(", "data", ",", "adversarial_sample", ")", "\n", "if", "value", "is", "not", "None", ":", "\n", "                ", "ret", "[", "it", ".", "name", "]", "=", "value", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__iter_dataset": [[90, 98], ["it.before_attack"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.base.AttackMetric.before_attack"], ["", "def", "__iter_dataset", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "for", "data", "in", "dataset", ":", "\n", "            ", "v", "=", "data", "\n", "for", "it", "in", "self", ".", "metrics", ":", "\n", "                ", "ret", "=", "it", ".", "before_attack", "(", "v", ")", "\n", "if", "ret", "is", "not", "None", ":", "\n", "                    ", "v", "=", "ret", "\n", "", "", "yield", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__iter_metrics": [[99, 114], ["attack_eval.AttackEval.__measure"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__measure"], ["", "", "def", "__iter_metrics", "(", "self", ",", "iterable_result", ")", ":", "\n", "        ", "for", "data", ",", "result", "in", "iterable_result", ":", "\n", "            ", "adversarial_sample", ",", "attack_time", ",", "invoke_times", "=", "result", "\n", "ret", "=", "{", "\n", "\"data\"", ":", "data", ",", "\n", "\"success\"", ":", "adversarial_sample", "is", "not", "None", ",", "\n", "\"result\"", ":", "adversarial_sample", ",", "\n", "\"metrics\"", ":", "{", "\n", "\"Running Time\"", ":", "attack_time", ",", "\n", "\"Query Exceeded\"", ":", "self", ".", "invoke_limit", "is", "not", "None", "and", "invoke_times", ">", "self", ".", "invoke_limit", ",", "\n", "\"Victim Model Queries\"", ":", "invoke_times", ",", "\n", "**", "self", ".", "__measure", "(", "data", ",", "adversarial_sample", ")", "\n", "}", "\n", "}", "\n", "yield", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.ieval": [[115, 143], ["multiprocessing.get_context", "attack_eval.AttackEval.__iter_metrics", "multiprocessing.get_context.Pool", "attack_eval.AttackEval.__iter_metrics", "attack_eval.AttackEval.__iter_dataset", "zip", "zip", "attack_eval.AttackEval.ieval.result_iter"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__iter_metrics", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__iter_metrics", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.__iter_dataset"], ["", "", "def", "ieval", "(", "self", ",", "dataset", ":", "Iterable", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "num_workers", ":", "int", "=", "0", ",", "chunk_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "Dict", "[", "str", ",", "Any", "]", ",", "None", ",", "None", "]", ":", "\n", "        ", "\"\"\"\n        Iterable evaluation function of `AttackEval` returns an Iterator of result.\n\n        Args:\n            dataset: An iterable dataset.\n            num_worers: The number of processes running the attack algorithm. Default: 0 (running on the main process).\n            chunk_size: Processing pool trunks size.\n        \n        Yields:\n            A dict contains the result of each input samples.\n\n        \"\"\"", "\n", "\n", "if", "num_workers", ">", "0", ":", "\n", "            ", "ctx", "=", "mp", ".", "get_context", "(", "\"spawn\"", ")", "\n", "if", "chunk_size", "is", "None", ":", "\n", "                ", "chunk_size", "=", "num_workers", "\n", "", "with", "ctx", ".", "Pool", "(", "num_workers", ",", "initializer", "=", "worker_init", ",", "initargs", "=", "(", "self", ".", "attacker", ",", "self", ".", "victim", ",", "self", ".", "invoke_limit", ")", ")", "as", "pool", ":", "\n", "                ", "for", "ret", "in", "self", ".", "__iter_metrics", "(", "zip", "(", "dataset", ",", "pool", ".", "imap", "(", "worker_process", ",", "self", ".", "__iter_dataset", "(", "dataset", ")", ",", "chunksize", "=", "chunk_size", ")", ")", ")", ":", "\n", "                    ", "yield", "ret", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "def", "result_iter", "(", ")", ":", "\n", "                ", "for", "data", "in", "self", ".", "__iter_dataset", "(", "dataset", ")", ":", "\n", "                    ", "yield", "attack_process", "(", "self", ".", "attacker", ",", "self", ".", "victim", ",", "data", ",", "self", ".", "invoke_limit", ")", "\n", "", "", "for", "ret", "in", "self", ".", "__iter_metrics", "(", "zip", "(", "dataset", ",", "result_iter", "(", ")", ")", ")", ":", "\n", "                ", "yield", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval": [[144, 257], ["hasattr", "enumerate", "total_result_cnt.keys", "len", "tqdm.tqdm.tqdm.write", "tqdm.tqdm.tqdm", "attack_eval.AttackEval.ieval", "int", "res[].items", "utils.result_visualizer", "attack_eval.AttackEval.ieval", "float", "Tag", "attack_eval.AttackEval.victim.set_context", "Tag", "attack_eval.AttackEval.victim.set_context", "utils.visualizer", "utils.visualizer", "attack_eval.AttackEval.victim.get_prob", "attack_eval.AttackEval.victim.clear_context", "Tag", "attack_eval.AttackEval.victim.set_context", "int", "int", "RuntimeError", "attack_eval.AttackEval.victim.get_prob", "attack_eval.AttackEval.victim.clear_context", "Tag", "attack_eval.AttackEval.victim.set_context", "int", "RuntimeError", "attack_eval.AttackEval.victim.get_pred", "attack_eval.AttackEval.victim.clear_context", "attack_eval.AttackEval.victim.get_pred", "attack_eval.AttackEval.victim.clear_context"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.ieval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.result_visualizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.ieval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.visualizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.visualizer.visualizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.clear_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.clear_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.clear_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.clear_context"], ["", "", "", "def", "eval", "(", "self", ",", "dataset", ":", "Iterable", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "total_len", ":", "Optional", "[", "int", "]", "=", "None", ",", "visualize", ":", "bool", "=", "False", ",", "progress_bar", ":", "bool", "=", "False", ",", "num_workers", ":", "int", "=", "0", ",", "chunk_size", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Evaluation function of `AttackEval`.\n\n        Args:\n            dataset: An iterable dataset.\n            total_len: Total length of dataset (will be used if dataset doesn't has a `__len__` attribute).\n            visualize: Display a pretty result for each data in the dataset.\n            progress_bar: Display a progress bar if `True`.\n            num_worers: The number of processes running the attack algorithm. Default: 0 (running on the main process).\n            chunk_size: Processing pool trunks size.\n        \n        Returns:\n            A dict of attack evaluation summaries.\n\n        \"\"\"", "\n", "\n", "\n", "if", "hasattr", "(", "dataset", ",", "\"__len__\"", ")", ":", "\n", "            ", "total_len", "=", "len", "(", "dataset", ")", "\n", "\n", "", "def", "tqdm_writer", "(", "x", ")", ":", "\n", "            ", "return", "tqdm", ".", "write", "(", "x", ",", "end", "=", "\"\"", ")", "\n", "\n", "", "if", "progress_bar", ":", "\n", "            ", "result_iterator", "=", "tqdm", "(", "self", ".", "ieval", "(", "dataset", ",", "num_workers", ",", "chunk_size", ")", ",", "total", "=", "total_len", ")", "\n", "", "else", ":", "\n", "            ", "result_iterator", "=", "self", ".", "ieval", "(", "dataset", ",", "num_workers", ",", "chunk_size", ")", "\n", "\n", "", "total_result", "=", "{", "}", "\n", "total_result_cnt", "=", "{", "}", "\n", "total_inst", "=", "0", "\n", "success_inst", "=", "0", "\n", "\n", "# Begin for", "\n", "for", "i", ",", "res", "in", "enumerate", "(", "result_iterator", ")", ":", "\n", "            ", "total_inst", "+=", "1", "\n", "success_inst", "+=", "int", "(", "res", "[", "\"success\"", "]", ")", "\n", "\n", "if", "TAG_Classification", "in", "self", ".", "victim", ".", "TAGS", ":", "\n", "                ", "x_orig", "=", "res", "[", "\"data\"", "]", "[", "\"x\"", "]", "\n", "if", "res", "[", "\"success\"", "]", ":", "\n", "                    ", "x_adv", "=", "res", "[", "\"result\"", "]", "\n", "if", "Tag", "(", "\"get_prob\"", ",", "\"victim\"", ")", "in", "self", ".", "victim", ".", "TAGS", ":", "\n", "                        ", "self", ".", "victim", ".", "set_context", "(", "res", "[", "\"data\"", "]", ",", "None", ")", "\n", "try", ":", "\n", "                            ", "probs", "=", "self", ".", "victim", ".", "get_prob", "(", "[", "x_orig", ",", "x_adv", "]", ")", "\n", "", "finally", ":", "\n", "                            ", "self", ".", "victim", ".", "clear_context", "(", ")", "\n", "", "y_orig", "=", "probs", "[", "0", "]", "\n", "y_adv", "=", "probs", "[", "1", "]", "\n", "", "elif", "Tag", "(", "\"get_pred\"", ",", "\"victim\"", ")", "in", "self", ".", "victim", ".", "TAGS", ":", "\n", "                        ", "self", ".", "victim", ".", "set_context", "(", "res", "[", "\"data\"", "]", ",", "None", ")", "\n", "try", ":", "\n", "                            ", "preds", "=", "self", ".", "victim", ".", "get_pred", "(", "[", "x_orig", ",", "x_adv", "]", ")", "\n", "", "finally", ":", "\n", "                            ", "self", ".", "victim", ".", "clear_context", "(", ")", "\n", "", "y_orig", "=", "int", "(", "preds", "[", "0", "]", ")", "\n", "y_adv", "=", "int", "(", "preds", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\"Invalid victim model\"", ")", "\n", "", "", "else", ":", "\n", "                    ", "y_adv", "=", "None", "\n", "x_adv", "=", "None", "\n", "if", "Tag", "(", "\"get_prob\"", ",", "\"victim\"", ")", "in", "self", ".", "victim", ".", "TAGS", ":", "\n", "                        ", "self", ".", "victim", ".", "set_context", "(", "res", "[", "\"data\"", "]", ",", "None", ")", "\n", "try", ":", "\n", "                            ", "probs", "=", "self", ".", "victim", ".", "get_prob", "(", "[", "x_orig", "]", ")", "\n", "", "finally", ":", "\n", "                            ", "self", ".", "victim", ".", "clear_context", "(", ")", "\n", "", "y_orig", "=", "probs", "[", "0", "]", "\n", "", "elif", "Tag", "(", "\"get_pred\"", ",", "\"victim\"", ")", "in", "self", ".", "victim", ".", "TAGS", ":", "\n", "                        ", "self", ".", "victim", ".", "set_context", "(", "res", "[", "\"data\"", "]", ",", "None", ")", "\n", "try", ":", "\n", "                            ", "preds", "=", "self", ".", "victim", ".", "get_pred", "(", "[", "x_orig", "]", ")", "\n", "", "finally", ":", "\n", "                            ", "self", ".", "victim", ".", "clear_context", "(", ")", "\n", "", "y_orig", "=", "int", "(", "preds", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\"Invalid victim model\"", ")", "\n", "", "", "info", "=", "res", "[", "\"metrics\"", "]", "\n", "info", "[", "\"Succeed\"", "]", "=", "res", "[", "\"success\"", "]", "\n", "if", "visualize", ":", "\n", "                    ", "if", "progress_bar", ":", "\n", "                        ", "visualizer", "(", "i", "+", "1", ",", "x_orig", ",", "y_orig", ",", "x_adv", ",", "y_adv", ",", "info", ",", "tqdm_writer", ",", "self", ".", "tokenizer", ")", "\n", "", "else", ":", "\n", "                        ", "visualizer", "(", "i", "+", "1", ",", "x_orig", ",", "y_orig", ",", "x_adv", ",", "y_adv", ",", "info", ",", "sys", ".", "stdout", ".", "write", ",", "self", ".", "tokenizer", ")", "\n", "", "", "", "for", "kw", ",", "val", "in", "res", "[", "\"metrics\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "val", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "kw", "not", "in", "total_result_cnt", ":", "\n", "                    ", "total_result_cnt", "[", "kw", "]", "=", "0", "\n", "total_result", "[", "kw", "]", "=", "0", "\n", "", "total_result_cnt", "[", "kw", "]", "+=", "1", "\n", "total_result", "[", "kw", "]", "+=", "float", "(", "val", ")", "\n", "# End for", "\n", "\n", "", "", "summary", "=", "{", "}", "\n", "summary", "[", "\"Total Attacked Instances\"", "]", "=", "total_inst", "\n", "summary", "[", "\"Successful Instances\"", "]", "=", "success_inst", "\n", "summary", "[", "\"Attack Success Rate\"", "]", "=", "success_inst", "/", "total_inst", "\n", "for", "kw", "in", "total_result_cnt", ".", "keys", "(", ")", ":", "\n", "            ", "if", "kw", "in", "[", "\"Succeed\"", "]", ":", "\n", "                ", "continue", "\n", "", "if", "kw", "in", "[", "\"Query Exceeded\"", "]", ":", "\n", "                ", "summary", "[", "\"Total \"", "+", "kw", "]", "=", "total_result", "[", "kw", "]", "\n", "", "else", ":", "\n", "                ", "summary", "[", "\"Avg. \"", "+", "kw", "]", "=", "total_result", "[", "kw", "]", "/", "total_result_cnt", "[", "kw", "]", "\n", "\n", "", "", "if", "visualize", ":", "\n", "            ", "result_visualizer", "(", "summary", ",", "sys", ".", "stdout", ".", "write", ")", "\n", "", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.utils.attack_process": [[7, 28], ["victim.set_context", "attacker", "victim.clear_context", "logger.exception"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.set_context", "home.repos.pwc.inspect_result.thunlp_OpenAttack.victim.base.Victim.clear_context"], ["def", "attack_process", "(", "attacker", ",", "victim", ":", "Victim", ",", "data", ",", "limit", ")", ":", "\n", "    ", "victim", ".", "set_context", "(", "data", ",", "limit", ")", "\n", "try", ":", "\n", "        ", "adversarial_sample", "=", "attacker", "(", "victim", ",", "data", ")", "\n", "invoke_times", "=", "victim", ".", "context", ".", "invoke", "\n", "attack_time", "=", "victim", ".", "context", ".", "attack_time", "\n", "", "except", "InvokeLimitExceeded", ":", "\n", "        ", "adversarial_sample", "=", "None", "\n", "invoke_times", "=", "victim", ".", "context", ".", "invoke", "+", "1", "\n", "attack_time", "=", "victim", ".", "context", ".", "attack_time", "\n", "", "except", "KeyboardInterrupt", "as", "e", ":", "\n", "        ", "raise", "e", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", ".", "exception", "(", "\"Exception when evaluate data %s\"", ",", "data", ")", "\n", "adversarial_sample", "=", "None", "\n", "invoke_times", "=", "victim", ".", "context", ".", "invoke", "\n", "attack_time", "=", "victim", ".", "context", ".", "attack_time", "\n", "", "finally", ":", "\n", "        ", "victim", ".", "clear_context", "(", ")", "\n", "\n", "", "return", "adversarial_sample", ",", "attack_time", ",", "invoke_times", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.utils.worker_process": [[30, 36], ["utils.attack_process", "globals", "globals", "globals"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.utils.attack_process"], ["", "def", "worker_process", "(", "data", ")", ":", "\n", "    ", "attacker", "=", "globals", "(", ")", "[", "\"$WORKER_ATTACKER\"", "]", "\n", "victim", "=", "globals", "(", ")", "[", "\"$WORKER_VICTIM\"", "]", "\n", "limit", "=", "globals", "(", ")", "[", "\"$WORKER_INVOKE_LIMIT\"", "]", "\n", "\n", "return", "attack_process", "(", "attacker", ",", "victim", ",", "data", ",", "limit", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.utils.worker_init": [[39, 43], ["globals", "globals", "globals"], "function", ["None"], ["", "def", "worker_init", "(", "attacker", ",", "victim", ",", "limit", ")", ":", "\n", "    ", "globals", "(", ")", "[", "'$WORKER_ATTACKER'", "]", "=", "attacker", "\n", "globals", "(", ")", "[", "'$WORKER_VICTIM'", "]", "=", "victim", "\n", "globals", "(", ")", "[", "'$WORKER_INVOKE_LIMIT'", "]", "=", "limit", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.constituency_parser.base.ConstituencyParser.__call__": [[6, 14], ["base.ConstituencyParser.parse"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.constituency_parser.stanford_parser.StanfordParser.parse"], ["from", ".", "method", "import", "VictimMethod", "\n", "import", "time", "\n", "\n", "def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.constituency_parser.base.ConstituencyParser.parse": [[15, 17], ["NotImplementedError"], "methods", ["None"], ["", "return", "invoke_wrapper", "\n", "\n", "", "class", "Victim", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.constituency_parser.stanford_parser.StanfordParser.__init__": [[16, 18], ["data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "__parser", "=", "DataManager", ".", "load", "(", "\"TProcess.StanfordParser\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.constituency_parser.stanford_parser.StanfordParser.parse": [[19, 21], ["str", "list", "stanford_parser.StanfordParser.__parser"], "methods", ["None"], ["", "def", "parse", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "str", "(", "list", "(", "self", ".", "__parser", "(", "sentence", ")", ")", "[", "0", "]", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.constituency_parser.__init__.get_default_constituency_parser": [[4, 9], ["stanford_parser.StanfordParser", "stanford_parser.StanfordParser"], "function", ["None"], ["# attacker", "\n", "from", ".", "import", "attackers", "\n", "from", ".", "attackers", "import", "Attacker", ",", "ClassificationAttacker", "\n", "\n", "# victim", "\n", "from", ".", "import", "victim", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.base.Lemmatizer.lemmatize": [[6, 15], ["base.Lemmatizer.do_lemmatize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.wordnet_lemmatizer.WordnetLemmatimer.do_lemmatize"], ["from", ".", "method", "import", "VictimMethod", "\n", "import", "time", "\n", "\n", "def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "invoke_wrapper", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.base.Lemmatizer.delemmatize": [[16, 25], ["base.Lemmatizer.do_delemmatize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.wordnet_lemmatizer.WordnetLemmatimer.do_delemmatize"], ["\n", "", "class", "Victim", ":", "\n", "    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_method_tags", "\n", "\n", "", "def", "__init_subclass__", "(", "cls", ",", "invoke_funcs", "=", "[", "]", ",", "tags", "=", "set", "(", ")", ")", ":", "\n", "        ", "for", "func_name", ",", "method", "in", "invoke_funcs", ":", "\n", "            ", "setattr", "(", "cls", ",", "func_name", ",", "invoke_decorator", "(", "getattr", "(", "cls", ",", "func_name", ")", ",", "method", ")", ")", "\n", "", "cls", ".", "_method_tags", "=", "set", "(", "tags", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.base.Lemmatizer.do_lemmatize": [[26, 28], ["NotImplementedError"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "supported_language", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.base.Lemmatizer.do_delemmatize": [[29, 31], ["NotImplementedError"], "methods", ["None"], ["        ", "for", "tag", "in", "self", ".", "TAGS", ":", "\n", "            ", "if", "tag", ".", "type", "==", "\"lang\"", ":", "\n", "                ", "return", "tag", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.wordnet_lemmatizer.WordnetLemmatimer.__init__": [[28, 38], ["data_manager.DataManager.load", "data_manager.DataManager.load", "data_manager.DataManager.load.keys", "old_delema[].items"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "wnc", "=", "DataManager", ".", "load", "(", "\"TProcess.NLTKWordNet\"", ")", "\n", "old_delema", "=", "DataManager", ".", "load", "(", "\"TProcess.NLTKWordNetDelemma\"", ")", "\n", "self", ".", "__delema", "=", "{", "}", "\n", "for", "word", "in", "old_delema", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "__delema", "[", "word", "]", "=", "{", "}", "\n", "for", "kw", ",", "val", "in", "old_delema", "[", "word", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "kw", "[", ":", "2", "]", "in", "_DELEMMA_POS_MAPPING", ":", "\n", "                    ", "pos", "=", "_DELEMMA_POS_MAPPING", "[", "kw", "[", ":", "2", "]", "]", "\n", "self", ".", "__delema", "[", "word", "]", "[", "pos", "]", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.wordnet_lemmatizer.WordnetLemmatimer.do_lemmatize": [[39, 46], ["wordnet_lemmatizer.WordnetLemmatimer.wnc._morphy", "min", "len"], "methods", ["None"], ["", "", "", "", "def", "do_lemmatize", "(", "self", ",", "token", ",", "pos", ")", ":", "\n", "        ", "if", "pos", "not", "in", "POS_MAPPING", ":", "\n", "            ", "return", "token", "\n", "", "pos_in_wordnet", "=", "POS_MAPPING", "[", "pos", "]", "\n", "\n", "lemmas", "=", "self", ".", "wnc", ".", "_morphy", "(", "token", ",", "pos_in_wordnet", ")", "\n", "return", "min", "(", "lemmas", ",", "key", "=", "len", ")", "if", "len", "(", "lemmas", ")", ">", "0", "else", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.wordnet_lemmatizer.WordnetLemmatimer.do_delemmatize": [[48, 52], ["None"], "methods", ["None"], ["", "def", "do_delemmatize", "(", "self", ",", "lemma", ",", "pos", ")", ":", "\n", "        ", "if", "(", "lemma", "in", "self", ".", "__delema", ")", "and", "(", "pos", "in", "self", ".", "__delema", "[", "lemma", "]", ")", ":", "\n", "            ", "return", "self", ".", "__delema", "[", "lemma", "]", "[", "pos", "]", "\n", "", "return", "lemma", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.lemmatizer.__init__.get_default_lemmatizer": [[5, 10], ["wordnet_lemmatizer.WordnetLemmatimer", "wordnet_lemmatizer.WordnetLemmatimer"], "function", ["None"], ["from", ".", "import", "attackers", "\n", "from", ".", "attackers", "import", "Attacker", ",", "ClassificationAttacker", "\n", "\n", "# victim", "\n", "from", ".", "import", "victim", "\n", "from", ".", "victim", "import", "classifiers", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize": [[10, 25], ["base.Tokenizer.do_tokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.punct_tokenizer.PunctTokenizer.do_tokenize"], ["    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "invoke_wrapper", "\n", "\n", "", "class", "Victim", ":", "\n", "    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_method_tags", "\n", "\n", "", "def", "__init_subclass__", "(", "cls", ",", "invoke_funcs", "=", "[", "]", ",", "tags", "=", "set", "(", ")", ")", ":", "\n", "        ", "for", "func_name", ",", "method", "in", "invoke_funcs", ":", "\n", "            ", "setattr", "(", "cls", ",", "func_name", ",", "invoke_decorator", "(", "getattr", "(", "cls", ",", "func_name", ")", ",", "method", ")", ")", "\n", "", "cls", ".", "_method_tags", "=", "set", "(", "tags", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize": [[26, 39], ["base.Tokenizer.do_detokenize", "isinstance", "TypeError", "len", "isinstance"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.punct_tokenizer.PunctTokenizer.do_detokenize"], ["\n", "", "@", "property", "\n", "def", "supported_language", "(", "self", ")", ":", "\n", "        ", "for", "tag", "in", "self", ".", "TAGS", ":", "\n", "            ", "if", "tag", ".", "type", "==", "\"lang\"", ":", "\n", "                ", "return", "tag", "\n", "", "", "return", "None", "\n", "\n", "", "def", "set_context", "(", "self", ",", "data", ",", "invoke_limit", ")", ":", "\n", "        ", "self", ".", "_Victim__context", "=", "AttackContext", "(", "data", ",", "invoke_limit", ")", "\n", "\n", "", "def", "clear_context", "(", "self", ")", ":", "\n", "        ", "self", ".", "_Victim__context", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.do_tokenize": [[41, 43], ["NotImplementedError"], "methods", ["None"], ["def", "context", "(", "self", ")", "->", "Union", "[", "None", ",", "AttackContextShadow", "]", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"_Victim__context\"", ")", ":", "\n", "            ", "return", "None", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.do_detokenize": [[44, 46], ["NotImplementedError"], "methods", ["None"], ["", "else", ":", "\n", "            ", "return", "AttackContextShadow", "(", "self", ".", "_Victim__context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.jieba_tokenizer.JiebaTokenizer.__init__": [[24, 29], ["jieba.initialize"], "methods", ["None"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "import", "jieba", "\n", "import", "jieba", ".", "posseg", "as", "pseg", "\n", "self", ".", "__tokenize", "=", "pseg", ".", "cut", "\n", "jieba", ".", "initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.jieba_tokenizer.JiebaTokenizer.do_tokenize": [[30, 43], ["jieba_tokenizer.JiebaTokenizer.__tokenize", "ret.append", "ret.append"], "methods", ["None"], ["", "def", "do_tokenize", "(", "self", ",", "x", ",", "pos_tagging", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "pair", "in", "self", ".", "__tokenize", "(", "x", ")", ":", "\n", "            ", "if", "pos_tagging", ":", "\n", "                ", "pos", "=", "pair", ".", "flag", "[", "0", "]", "\n", "if", "pos", "in", "_POS_MAPPING", ":", "\n", "                    ", "pos", "=", "_POS_MAPPING", "[", "pos", "]", "\n", "", "else", ":", "\n", "                    ", "pos", "=", "\"other\"", "\n", "", "ret", ".", "append", "(", "(", "pair", ".", "word", ",", "pos", ")", ")", "\n", "", "else", ":", "\n", "                ", "ret", ".", "append", "(", "pair", ".", "word", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.jieba_tokenizer.JiebaTokenizer.do_detokenize": [[44, 46], ["None"], "methods", ["None"], ["", "def", "do_detokenize", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "\"\"", ".", "join", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.transformers_tokenizer.TransformersTokenizer.TAGS": [[15, 18], ["None"], "methods", ["None"], ["", "@", "TAGS", ".", "setter", "\n", "def", "TAGS", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "__lang_tag", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.transformers_tokenizer.TransformersTokenizer.__init__": [[19, 22], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "tokenizer", ":", "transformers", ".", "PreTrainedTokenizerBase", ",", "lang_tag", ")", ":", "\n", "        ", "self", ".", "__tokenizer", "=", "tokenizer", "\n", "self", ".", "__lang_tag", "=", "lang_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.transformers_tokenizer.TransformersTokenizer.do_tokenize": [[23, 27], ["transformers_tokenizer.TransformersTokenizer.__tokenizer.tokenize", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], ["", "def", "do_tokenize", "(", "self", ",", "x", ",", "pos_tagging", ")", ":", "\n", "        ", "if", "pos_tagging", ":", "\n", "            ", "raise", "ValueError", "(", "\"`%s` does not support pos tagging\"", "%", "self", ".", "__class__", ".", "__name__", ")", "\n", "", "return", "self", ".", "__tokenizer", ".", "tokenize", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.transformers_tokenizer.TransformersTokenizer.do_detokenize": [[28, 30], ["transformers_tokenizer.TransformersTokenizer.__tokenizer.convert_tokens_to_string"], "methods", ["None"], ["", "def", "do_detokenize", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "__tokenizer", ".", "convert_tokens_to_string", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.punct_tokenizer.PunctTokenizer.__init__": [[24, 28], ["data_manager.DataManager.load", "data_manager.DataManager.load", "nltk.WordPunctTokenizer"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "sent_tokenizer", "=", "DataManager", ".", "load", "(", "\"TProcess.NLTKSentTokenizer\"", ")", "\n", "self", ".", "word_tokenizer", "=", "nltk", ".", "WordPunctTokenizer", "(", ")", ".", "tokenize", "\n", "self", ".", "pos_tagger", "=", "DataManager", ".", "load", "(", "\"TProcess.NLTKPerceptronPosTagger\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.punct_tokenizer.PunctTokenizer.do_tokenize": [[29, 45], ["punct_tokenizer.PunctTokenizer.sent_tokenizer", "punct_tokenizer.PunctTokenizer.pos_tagger", "tokens.extend", "ret.append", "punct_tokenizer.PunctTokenizer.word_tokenizer"], "methods", ["None"], ["", "def", "do_tokenize", "(", "self", ",", "x", ",", "pos_tagging", "=", "True", ")", ":", "\n", "        ", "sentences", "=", "self", ".", "sent_tokenizer", "(", "x", ")", "\n", "tokens", "=", "[", "]", "\n", "for", "sent", "in", "sentences", ":", "\n", "            ", "tokens", ".", "extend", "(", "self", ".", "word_tokenizer", "(", "sent", ")", ")", "\n", "\n", "", "if", "not", "pos_tagging", ":", "\n", "            ", "return", "tokens", "\n", "", "ret", "=", "[", "]", "\n", "for", "word", ",", "pos", "in", "self", ".", "pos_tagger", "(", "tokens", ")", ":", "\n", "            ", "if", "pos", "[", ":", "2", "]", "in", "_POS_MAPPING", ":", "\n", "                ", "mapped_pos", "=", "_POS_MAPPING", "[", "pos", "[", ":", "2", "]", "]", "\n", "", "else", ":", "\n", "                ", "mapped_pos", "=", "\"other\"", "\n", "", "ret", ".", "append", "(", "(", "word", ",", "mapped_pos", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.punct_tokenizer.PunctTokenizer.do_detokenize": [[46, 48], ["None"], "methods", ["None"], ["", "def", "do_detokenize", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "x", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer": [[6, 13], ["punct_tokenizer.PunctTokenizer", "punct_tokenizer.PunctTokenizer", "jieba_tokenizer.JiebaTokenizer"], "function", ["None"], ["from", ".", "attackers", "import", "Attacker", ",", "ClassificationAttacker", "\n", "\n", "# victim", "\n", "from", ".", "import", "victim", "\n", "from", ".", "victim", "import", "classifiers", "\n", "from", ".", "victim", "import", "Victim", "\n", "from", ".", "victim", ".", "classifiers", "import", "Classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_roberta_imdb.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.word2vec.LOAD": [[17, 22], ["pickle.load", "pickle.load", "WordEmbedding", "open", "open", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "from", "OpenAttack", ".", "attack_assist", "import", "WordEmbedding", "\n", "word2id", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"word2id.pkl\"", ")", ",", "\"rb\"", ")", ")", "\n", "wordvec", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"wordvec.pkl\"", ")", ",", "\"rb\"", ")", ")", "\n", "return", "WordEmbedding", "(", "word2id", ",", "wordvec", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.nltk_wordnet.LOAD": [[16, 19], ["__import__().corpus.WordNetCorpusReader", "__import__"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "wnc", "=", "__import__", "(", "\"nltk\"", ")", ".", "corpus", ".", "WordNetCorpusReader", "(", "path", ",", "None", ")", "\n", "return", "wnc", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.nltk_senttokenizer.LOAD": [[16, 18], ["__import__().data.load", "os.path.join", "__import__"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "return", "__import__", "(", "\"nltk\"", ")", ".", "data", ".", "load", "(", "\"file:\"", "+", "os", ".", "path", ".", "join", "(", "path", ",", "\"english.pickle\"", ")", ")", ".", "tokenize", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.scpn.LOAD": [[17, 21], ["os.path.join"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "flist", "=", "[", "\"scpn.pt\"", ",", "\"parse_generator.pt\"", ",", "\"parse_vocab.pkl\"", ",", "\"bpe.codes\"", ",", "\"vocab.txt\"", ",", "\"ptb_tagset.pkl\"", "]", "\n", "return", "{", "\n", "it", ":", "os", ".", "path", ".", "join", "(", "path", ",", "it", ")", "for", "it", "in", "flist", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_xlnet_sst.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "transformer", ".", "word_embedding", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.fyh_dict.LOAD": [[17, 26], ["open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'tra_dict.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "tra_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'var_dict.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "var_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'hot_dict.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "hot_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "tra_dict", ",", "var_dict", ",", "hot_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.stanford_parser.LOAD": [[18, 25], ["__import__().parse.stanford.StanfordParser", "os.path.join", "os.path.join", "os.path.join", "__import__"], "function", ["None"], ["\n", "", "def", "parse", "(", "self", ",", "sentence", ":", "str", ")", "->", "str", ":", "\n", "        ", "return", "str", "(", "list", "(", "self", ".", "__parser", "(", "sentence", ")", ")", "[", "0", "]", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.translation_models.LOAD": [[21, 26], ["os.path.join"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "flist", "=", "[", "\"english_french_model_acc_71.05_ppl_3.71_e13.pt\"", ",", "\"english_portuguese_model_acc_70.75_ppl_4.32_e13.pt\"", ",", "\n", "\"french_english_model_acc_68.51_ppl_4.43_e13.pt\"", ",", "\"portuguese_english_model_acc_69.93_ppl_5.04_e13.pt\"", "]", "\n", "return", "{", "\n", "it", ":", "os", ".", "path", ".", "join", "(", "path", ",", "it", ")", "for", "it", "in", "flist", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_roberta_ag.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "5", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.chinese_word2vec.LOAD": [[15, 31], ["WordEmbedding", "open", "enumerate", "numpy.stack", "os.path.join", "f.readlines", "line.strip().split", "numpy.array", "np.stack.append", "len", "line.strip", "float"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "from", "OpenAttack", ".", "attack_assist", "import", "WordEmbedding", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"chinese-merge-word-embedding.txt\"", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "id2vec", "=", "[", "]", "\n", "word2id", "=", "{", "}", "\n", "# f.readline()", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "            ", "tmp", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "word", "=", "tmp", "[", "0", "]", "\n", "embed", "=", "np", ".", "array", "(", "[", "float", "(", "x", ")", "for", "x", "in", "tmp", "[", "1", ":", "]", "]", ")", "\n", "if", "len", "(", "embed", ")", "!=", "300", ":", "\n", "                ", "continue", "\n", "", "word2id", "[", "word", "]", "=", "idx", "\n", "id2vec", ".", "append", "(", "embed", ")", "\n", "", "id2vec", "=", "np", ".", "stack", "(", "id2vec", ")", "\n", "", "return", "WordEmbedding", "(", "word2id", ",", "id2vec", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.counter_fit.LOAD": [[18, 33], ["WordEmbedding", "open", "enumerate", "numpy.stack", "os.path.join", "f.readlines", "line.strip().split", "numpy.array", "np.stack.append", "len", "line.strip", "float"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "from", "OpenAttack", ".", "attack_assist", "import", "WordEmbedding", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"counter-fitted-vectors.txt\"", ")", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "id2vec", "=", "[", "]", "\n", "word2id", "=", "{", "}", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "            ", "tmp", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "word", "=", "tmp", "[", "0", "]", "\n", "embed", "=", "np", ".", "array", "(", "[", "float", "(", "x", ")", "for", "x", "in", "tmp", "[", "1", ":", "]", "]", ")", "\n", "if", "len", "(", "embed", ")", "!=", "300", ":", "\n", "                ", "continue", "\n", "", "word2id", "[", "word", "]", "=", "idx", "\n", "id2vec", ".", "append", "(", "embed", ")", "\n", "", "id2vec", "=", "np", ".", "stack", "(", "id2vec", ")", "\n", "", "return", "WordEmbedding", "(", "word2id", ",", "id2vec", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.hownet_substitute_dict.LOAD": [[11, 13], ["os.path.join"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "path", ",", "\"hownet_candidate/hownet_candidate.pkl\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_albert_sst.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "albert", ".", "embeddings", ".", "word_embeddings", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.sgan.to_gpu": [[17, 19], ["None"], "function", ["None"], ["def", "to_gpu", "(", "gpu", ",", "var", ")", ":", "\n", "    ", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.universal_sentence_encoder.LOAD": [[18, 20], ["os.path.join"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "path", ",", "\"usencoder\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_roberta_sst.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_albert_imdb.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "albert", ".", "embeddings", ".", "word_embeddings", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_xlnet_imdb.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "transformer", ".", "word_embedding", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_albert_ag.LOAD": [[18, 24], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "5", ",", "output_hidden_states", "=", "False", ")", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "albert", ".", "embeddings", ".", "word_embeddings", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_xlnet_ag.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "4", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "transformer", ".", "word_embedding", ")", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.glove.LOAD": [[17, 22], ["pickle.load", "numpy.load", "WordEmbedding", "open", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "from", "OpenAttack", ".", "attack_assist", "import", "WordEmbedding", "\n", "word2id", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"word2id.pkl\"", ")", ",", "\"rb\"", ")", ")", "\n", "wordvec", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"wordvec.npy\"", ")", ")", "\n", "return", "WordEmbedding", "(", "word2id", ",", "wordvec", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_bert.LOAD": [[18, 25], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "AutoTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "2", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.hownet.DOWNLOAD": [[14, 18], ["__import__", "__import__.download", "open().write", "open"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download"], ["def", "DOWNLOAD", "(", "path", ")", ":", "\n", "    ", "OpenHowNet", "=", "__import__", "(", "\"OpenHowNet\"", ")", "\n", "OpenHowNet", ".", "download", "(", ")", "\n", "open", "(", "path", ",", "\"w\"", ")", ".", "write", "(", "\"ok\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.hownet.LOAD": [[20, 25], ["open().read", "__import__().HowNetDict", "open", "__import__"], "function", ["None"], ["", "def", "LOAD", "(", "path", ")", ":", "\n", "    ", "if", "open", "(", "path", ",", "\"r\"", ")", ".", "read", "(", ")", "==", "\"ok\"", ":", "\n", "        ", "return", "__import__", "(", "\"OpenHowNet\"", ")", ".", "HowNetDict", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.sentence_transformer.LOAD": [[18, 20], ["os.path.join"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "path", ",", "\"stsb-bert-large\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.__init__.load_data": [[8, 59], ["pkgutil.iter_modules", "pickle.load", "[].load_module", "open", "hasattr", "hasattr", "callable", "hasattr", "ret.append", "source.endswith", "urllib.request.urlopen", "int", "isinstance", "open", "fin.read.module_finder.find_loader", "__init__.load_data.url_downloader"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["# victim", "\n", "from", ".", "import", "victim", "\n", "from", ".", "victim", "import", "classifiers", "\n", "from", ".", "victim", "import", "Victim", "\n", "from", ".", "victim", ".", "classifiers", "import", "Classifier", "\n", "\n", "# metrics", "\n", "from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.stanford_ner.LOAD": [[18, 24], ["__import__().StanfordNERTagger", "__import__", "os.path.join", "os.path.join"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "return", "(", "\n", "__import__", "(", "\"nltk\"", ")", "\n", ".", "StanfordNERTagger", "(", "\n", "model_filename", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"english.muc.7class.distsim.crf.ser.gz\"", ")", ",", "\n", "path_to_jar", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"stanford-ner.jar\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.cilin_dict.LOAD": [[17, 22], ["open", "pickle.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'cilin_dict.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "cilin_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "return", "cilin_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.dces.LOAD": [[21, 36], ["NearestNeighbors", "open", "pickle.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'descs.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "descs", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "from", "sklearn", ".", "neighbors", "import", "NearestNeighbors", "\n", "neigh", "=", "NearestNeighbors", "(", "**", "{", "\n", "'algorithm'", ":", "'auto'", ",", "\n", "'leaf_size'", ":", "30", ",", "\n", "'metric'", ":", "'euclidean'", ",", "\n", "'metric_params'", ":", "None", ",", "\n", "'n_jobs'", ":", "1", ",", "\n", "'n_neighbors'", ":", "5", ",", "\n", "'p'", ":", "2", ",", "\n", "'radius'", ":", "1.0", "\n", "}", ")", "\n", "return", "descs", ",", "neigh", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.victim_bert_amazon_zh.LOAD": [[19, 26], ["transformers.BertTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "TransformersClassifier"], "function", ["None"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "import", "transformers", "\n", "tokenizer", "=", "transformers", ".", "BertTokenizer", ".", "from_pretrained", "(", "path", ")", "\n", "model", "=", "transformers", ".", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "path", ",", "num_labels", "=", "5", ",", "output_hidden_states", "=", "False", ")", "\n", "\n", "from", "OpenAttack", ".", "victim", ".", "classifiers", "import", "TransformersClassifier", "\n", "return", "TransformersClassifier", "(", "model", ",", "tokenizer", ",", "model", ".", "bert", ".", "embeddings", ".", "word_embeddings", ",", "lang", "=", "\"chinese\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.data.nltk_perceptron_pos_tagger.LOAD": [[17, 21], ["__import__().tag.PerceptronTagger", "__import__().tag.PerceptronTagger.load", "os.path.join", "__import__"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "LOAD", "(", "path", ")", ":", "\n", "    ", "ret", "=", "__import__", "(", "\"nltk\"", ")", ".", "tag", ".", "PerceptronTagger", "(", "load", "=", "False", ")", "\n", "ret", ".", "load", "(", "\"file:\"", "+", "os", ".", "path", ".", "join", "(", "path", ",", "\"averaged_perceptron_tagger.pickle\"", ")", ")", "\n", "return", "ret", ".", "tag", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.base.CharSubstitute.__call__": [[4, 17], ["base.CharSubstitute.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], ["from", ".", "context", "import", "AttackContext", ",", "AttackContextShadow", "\n", "from", ".", ".", "exceptions", "import", "InvokeLimitExceeded", "\n", "from", ".", "method", "import", "VictimMethod", "\n", "import", "time", "\n", "\n", "def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "invoke_wrapper", "\n", "\n", "", "class", "Victim", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.base.CharSubstitute.substitute": [[18, 20], ["NotImplementedError"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_method_tags", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.chinese_sim_char.ChineseSimCharSubstitute.__init__": [[11, 25], ["base.CharSubstitute.__init__", "data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ",", "k", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns the chars that is visually similar to the input.\n\n        Args:\n            k: Top-k results to return. If k is `None`, all results will be returned.\n        \n        :Data Requirements: :py:data:`.AttackAssist.SIM`\n        :Language: chinese\n        \n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sim_dict", "=", "DataManager", ".", "load", "(", "\"AttackAssist.SIM\"", ")", "\n", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.chinese_sim_char.ChineseSimCharSubstitute.substitute": [[26, 34], ["ret.append"], "methods", ["None"], ["", "def", "substitute", "(", "self", ",", "char", ":", "str", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "if", "char", "in", "self", ".", "sim_dict", ":", "\n", "            ", "for", "chr", "in", "self", ".", "sim_dict", "[", "char", "]", ":", "\n", "                ", "ret", ".", "append", "(", "(", "chr", ",", "1", ")", ")", "\n", "", "", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "            ", "ret", "=", "ret", "[", ":", "self", ".", "k", "]", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.english_dces.DCESSubstitute.__init__": [[25, 41], ["data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ",", "k", ":", "int", "=", "12", ")", ":", "\n", "        ", "\"\"\"\n        Returns the chars that is visually similar to the input.\n\n        DCES substitute used in :py:class:`.VIPERAttacker`.\n\n        Args:\n            k: Top-k results to return. Default: k = 12\n        \n        :Data Requirements: :py:data:`.AttackAssist.SIM`\n        :Language: english\n        :Package Requirements: * **sklearn**\n\n        \"\"\"", "\n", "self", ".", "descs", ",", "self", ".", "neigh", "=", "DataManager", ".", "load", "(", "\"AttackAssist.DCES\"", ")", "\n", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.english_dces.DCESSubstitute.substitute": [[42, 106], ["english_dces.get_hex_string", "description.split", "numpy.stack", "english_dces.DCESSubstitute.neigh.fit", "[].reshape", "dists.flatten", "list", "english_dces.DCESSubstitute.descs.items", "len", "english_dces.DCESSubstitute.neigh.kneighbors", "english_dces.DCESSubstitute.neigh.kneighbors", "chars.append", "zip", "len", "identifiers.append", "val[].split", "idxs.flatten", "chr", "numpy.array", "int", "numpy.any", "numpy.any", "len", "match_ids.append", "matches.append", "numpy.in1d", "numpy.in1d", "int", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.char.english_dces.get_hex_string"], ["", "def", "substitute", "(", "self", ",", "char", ":", "str", ")", ":", "\n", "        ", "c", "=", "get_hex_string", "(", "char", ")", "\n", "\n", "if", "c", "in", "self", ".", "descs", ":", "\n", "            ", "description", "=", "self", ".", "descs", "[", "c", "]", "[", "\"description\"", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "(", "char", ",", "1", ")", "]", "\n", "\n", "", "tokens", "=", "description", ".", "split", "(", "' '", ")", "\n", "case", "=", "'unknown'", "\n", "identifiers", "=", "[", "]", "\n", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "len", "(", "token", ")", "==", "1", ":", "\n", "                ", "identifiers", ".", "append", "(", "token", ")", "\n", "", "elif", "token", "==", "'SMALL'", ":", "\n", "                ", "case", "=", "'SMALL'", "\n", "", "elif", "token", "==", "'CAPITAL'", ":", "\n", "                ", "case", "=", "'CAPITAL'", "\n", "\n", "", "", "matches", "=", "[", "]", "\n", "match_ids", "=", "[", "]", "\n", "for", "i", "in", "identifiers", ":", "\n", "            ", "for", "idx", ",", "val", "in", "self", ".", "descs", ".", "items", "(", ")", ":", "\n", "                ", "desc_toks", "=", "val", "[", "\"description\"", "]", ".", "split", "(", "' '", ")", "\n", "if", "i", "in", "desc_toks", "and", "not", "np", ".", "any", "(", "np", ".", "in1d", "(", "desc_toks", ",", "disallowed", ")", ")", "and", "not", "np", ".", "any", "(", "np", ".", "in1d", "(", "idx", ",", "disallowed_codes", ")", ")", "and", "not", "int", "(", "idx", ",", "16", ")", ">", "30000", ":", "\n", "\n", "                    ", "desc_toks", "=", "np", ".", "array", "(", "desc_toks", ")", "\n", "case_descriptor", "=", "desc_toks", "[", "(", "desc_toks", "==", "'SMALL'", ")", "|", "(", "desc_toks", "==", "'CAPITAL'", ")", "]", "\n", "\n", "if", "len", "(", "case_descriptor", ")", ">", "1", ":", "\n", "                        ", "case_descriptor", "=", "case_descriptor", "[", "0", "]", "\n", "", "elif", "len", "(", "case_descriptor", ")", "==", "0", ":", "\n", "                        ", "case", "=", "'unknown'", "\n", "\n", "", "if", "case", "==", "'unknown'", "or", "case", "==", "case_descriptor", ":", "\n", "                        ", "match_ids", ".", "append", "(", "idx", ")", "\n", "matches", ".", "append", "(", "val", "[", "\"vec\"", "]", ")", "\n", "\n", "", "", "", "", "if", "len", "(", "matches", ")", "==", "0", ":", "\n", "            ", "return", "[", "(", "char", ",", "1", ")", "]", "\n", "\n", "", "match_vecs", "=", "np", ".", "stack", "(", "matches", ")", "\n", "Y", "=", "match_vecs", "\n", "\n", "self", ".", "neigh", ".", "fit", "(", "Y", ")", "\n", "\n", "X", "=", "self", ".", "descs", "[", "c", "]", "[", "\"vec\"", "]", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "if", "Y", ".", "shape", "[", "0", "]", ">", "self", ".", "k", ":", "\n", "            ", "dists", ",", "idxs", "=", "self", ".", "neigh", ".", "kneighbors", "(", "X", ",", "self", ".", "k", ",", "return_distance", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "dists", ",", "idxs", "=", "self", ".", "neigh", ".", "kneighbors", "(", "X", ",", "Y", ".", "shape", "[", "0", "]", ",", "return_distance", "=", "True", ")", "\n", "", "probs", "=", "dists", ".", "flatten", "(", ")", "\n", "\n", "charcodes", "=", "[", "match_ids", "[", "idx", "]", "for", "idx", "in", "idxs", ".", "flatten", "(", ")", "]", "\n", "\n", "chars", "=", "[", "]", "\n", "for", "charcode", "in", "charcodes", ":", "\n", "            ", "chars", ".", "append", "(", "chr", "(", "int", "(", "charcode", ",", "16", ")", ")", ")", "\n", "", "ret", "=", "list", "(", "zip", "(", "chars", ",", "probs", ")", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.english_dces.get_hex_string": [[18, 20], ["ord"], "function", ["None"], ["def", "get_hex_string", "(", "ch", ")", ":", "\n", "    ", "return", "'{:04x}'", ".", "format", "(", "ord", "(", "ch", ")", ")", ".", "upper", "(", ")", "# Get the hex code of char", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.english_eces.ECESSubstitute.__init__": [[21, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the chars that is visually similar to the input.\n\n        DCES substitute used in :py:class:`.VIPERAttacker`.\n\n        :Data Requirements: :py:data:`.AttackAssist.SIM`\n        :Language: english\n\n        \"\"\"", "\n", "self", ".", "h", "=", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.english_eces.ECESSubstitute.substitute": [[33, 42], ["None"], "methods", ["None"], ["", "def", "substitute", "(", "self", ",", "char", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        :param word: the raw char, threshold: return top k chars.\n        :return: The result is a list of tuples, *(substitute, 1)*.\n        :rtype: list of tuple\n        \"\"\"", "\n", "if", "char", "not", "in", "self", ".", "h", ":", "\n", "            ", "return", "[", "(", "char", ",", "1", ")", "]", "\n", "", "return", "[", "(", "self", ".", "h", "[", "char", "]", ",", "1", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.chinese_fyh_char.ChineseFYHCharSubstitute.__init__": [[11, 26], ["base.CharSubstitute.__init__", "data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ",", "k", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns traditional, variant and Martian characters of the input character.\n\n        Args:\n            k: Top-k results to return. If k is `None`, all results will be returned.\n        \n        :Data Requirements: :py:data:`.AttackAssist.FYH`\n        :Language: chinese\n        \n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tra_dict", ",", "self", ".", "var_dict", ",", "self", ".", "hot_dict", "=", "DataManager", ".", "load", "(", "\"AttackAssist.FYH\"", ")", "\n", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.char.chinese_fyh_char.ChineseFYHCharSubstitute.substitute": [[27, 42], ["set", "fanyihuo_result.union.union.union", "fanyihuo_result.union.union.union", "fanyihuo_result.union.union.union", "ret.append"], "methods", ["None"], ["", "def", "substitute", "(", "self", ",", "char", ":", "str", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "if", "char", "in", "self", ".", "tra_dict", "or", "char", "in", "self", ".", "var_dict", "or", "char", "in", "self", ".", "hot_dict", ":", "\n", "            ", "fanyihuo_result", "=", "set", "(", ")", "\n", "if", "char", "in", "self", ".", "tra_dict", ":", "\n", "                ", "fanyihuo_result", "=", "fanyihuo_result", ".", "union", "(", "self", ".", "tra_dict", "[", "char", "]", ")", "\n", "", "if", "char", "in", "self", ".", "var_dict", ":", "\n", "                ", "fanyihuo_result", "=", "fanyihuo_result", ".", "union", "(", "self", ".", "var_dict", "[", "char", "]", ")", "\n", "", "if", "char", "in", "self", ".", "hot_dict", ":", "\n", "                ", "fanyihuo_result", "=", "fanyihuo_result", ".", "union", "(", "self", ".", "hot_dict", "[", "char", "]", ")", "\n", "", "for", "ch", "in", "fanyihuo_result", ":", "\n", "                ", "ret", ".", "append", "(", "(", "ch", ",", "1", ")", ")", "\n", "", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "                ", "ret", "=", "ret", "[", ":", "self", ".", "k", "]", "\n", "", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_word2vec.Word2VecSubstitute.__init__": [[10, 34], ["data_manager.DataManager.load", "embed_based.EmbedBasedSubstitute.__init__", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], ["def", "__init__", "(", "self", ",", "cosine", "=", "False", ",", "k", "=", "50", ",", "threshold", "=", "0.5", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        English word substitute based on word2vec.\n\n        Args:\n            cosine: If `true` then the cosine distance is used, otherwise the Euclidian distance is used.\n            threshold: Distance threshold. Default: 0.5\n            k: Top-k results to return. If k is `None`, all results will be returned. Default: 50\n            device: A pytocrh device for computing distances. Default: \"cpu\"\n        \n        :Data Requirements: :py:data:`.AttackAssist.GloVe`\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "wordvec", "=", "DataManager", ".", "load", "(", "\"AttackAssist.Word2Vec\"", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "wordvec", ".", "word2id", ",", "\n", "torch", ".", "from_numpy", "(", "wordvec", ".", "embedding", ")", ",", "\n", "cosine", "=", "cosine", ",", "\n", "k", "=", "k", ",", "\n", "threshold", "=", "threshold", ",", "\n", "device", "=", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.base.WordSubstitute.__call__": [[7, 43], ["base.WordSubstitute.substitute", "ret.items", "sorted", "list_ret.append", "len", "exceptions.WordNotInDictionaryException", "exceptions.UnknownPOSException", "base.WordSubstitute.substitute", "max"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], ["import", "time", "\n", "\n", "def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "invoke_wrapper", "\n", "\n", "", "class", "Victim", ":", "\n", "    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_method_tags", "\n", "\n", "", "def", "__init_subclass__", "(", "cls", ",", "invoke_funcs", "=", "[", "]", ",", "tags", "=", "set", "(", ")", ")", ":", "\n", "        ", "for", "func_name", ",", "method", "in", "invoke_funcs", ":", "\n", "            ", "setattr", "(", "cls", ",", "func_name", ",", "invoke_decorator", "(", "getattr", "(", "cls", ",", "func_name", ")", ",", "method", ")", ")", "\n", "", "cls", ".", "_method_tags", "=", "set", "(", "tags", ")", "\n", "\n", "", "@", "property", "\n", "def", "supported_language", "(", "self", ")", ":", "\n", "        ", "for", "tag", "in", "self", ".", "TAGS", ":", "\n", "            ", "if", "tag", ".", "type", "==", "\"lang\"", ":", "\n", "                ", "return", "tag", "\n", "", "", "return", "None", "\n", "\n", "", "def", "set_context", "(", "self", ",", "data", ",", "invoke_limit", ")", ":", "\n", "        ", "self", ".", "_Victim__context", "=", "AttackContext", "(", "data", ",", "invoke_limit", ")", "\n", "\n", "", "def", "clear_context", "(", "self", ")", ":", "\n", "        ", "self", ".", "_Victim__context", "=", "None", "\n", "\n", "", "@", "property", "\n", "def", "context", "(", "self", ")", "->", "Union", "[", "None", ",", "AttackContextShadow", "]", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"_Victim__context\"", ")", ":", "\n", "            ", "return", "None", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.base.WordSubstitute.substitute": [[44, 46], ["NotImplementedError"], "methods", ["None"], ["", "else", ":", "\n", "            ", "return", "AttackContextShadow", "(", "self", ".", "_Victim__context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_cilin.ChineseCiLinSubstitute.__init__": [[10, 24], ["data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ",", "k", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Chinese Sememe-based word substitute based CiLin.\n\n        Args:\n            k: Top-k results to return. If k is `None`, all results will be returned.\n        \n        :Data Requirements: :py:data:`.AttackAssist.CiLin`\n        :Language: chinese\n        \n        \"\"\"", "\n", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "cilin_dict", "=", "DataManager", ".", "load", "(", "\"AttackAssist.CiLin\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_cilin.ChineseCiLinSubstitute.substitute": [[25, 37], ["exceptions.WordNotInDictionaryException", "ret.append"], "methods", ["None"], ["", "def", "substitute", "(", "self", ",", "word", ",", "pos_tag", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "cilin_dict", ":", "\n", "            ", "raise", "WordNotInDictionaryException", "(", ")", "\n", "", "sym_words", "=", "self", ".", "cilin_dict", "[", "word", "]", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "sym_word", "in", "sym_words", ":", "\n", "            ", "ret", ".", "append", "(", "(", "sym_word", ",", "1", ")", ")", "\n", "\n", "", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "            ", "ret", "=", "ret", "[", ":", "self", ".", "k", "]", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_word2vec.ChineseWord2VecSubstitute.__init__": [[11, 35], ["data_manager.DataManager.load", "embed_based.EmbedBasedSubstitute.__init__", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], ["URL", "=", "\"/TAADToolbox/chinese-merge-word-embedding.txt.zip\"", "\n", "DOWNLOAD", "=", "make_zip_downloader", "(", "URL", ",", "\"chinese-merge-word-embedding.txt\"", ")", "\n", "\n", "\n", "def", "LOAD", "(", "path", ")", ":", "\n", "    ", "from", "OpenAttack", ".", "attack_assist", "import", "WordEmbedding", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"chinese-merge-word-embedding.txt\"", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "id2vec", "=", "[", "]", "\n", "word2id", "=", "{", "}", "\n", "# f.readline()", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "            ", "tmp", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "word", "=", "tmp", "[", "0", "]", "\n", "embed", "=", "np", ".", "array", "(", "[", "float", "(", "x", ")", "for", "x", "in", "tmp", "[", "1", ":", "]", "]", ")", "\n", "if", "len", "(", "embed", ")", "!=", "300", ":", "\n", "                ", "continue", "\n", "", "word2id", "[", "word", "]", "=", "idx", "\n", "id2vec", ".", "append", "(", "embed", ")", "\n", "", "id2vec", "=", "np", ".", "stack", "(", "id2vec", ")", "\n", "", "return", "WordEmbedding", "(", "word2id", ",", "id2vec", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_hownet.ChineseHowNetSubstitute.__init__": [[11, 29], ["base.WordSubstitute.__init__", "data_manager.DataManager.load", "chinese_hownet.ChineseHowNetSubstitute.hownet_dict.get_zh_words"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ",", "k", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Chinese Sememe-based word substitute based on OpenHowNet.\n        `[pdf] <https://arxiv.org/pdf/1901.09957.pdf>`__\n\n        Args:\n            k: Top-k results to return. If k is `None`, all results will be returned.\n        \n        :Package Requirements: OpenHowNet\n        :Data Requirements: :py:data:`.AttackAssist.HowNet`\n        :Language: chinese\n        \n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hownet_dict", "=", "DataManager", ".", "load", "(", "\"AttackAssist.HowNet\"", ")", "\n", "self", ".", "zh_word_list", "=", "self", ".", "hownet_dict", ".", "get_zh_words", "(", ")", "\n", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_hownet.ChineseHowNetSubstitute.substitute": [[30, 71], ["chinese_hownet.ChineseHowNetSubstitute.hownet_dict.get_sememes_by_word", "sorted", "len", "exceptions.WordNotInDictionaryException", "set", "chinese_hownet.ChineseHowNetSubstitute.hownet_dict.get", "chinese_hownet.ChineseHowNetSubstitute.hownet_dict.get_sememes_by_word", "set.add", "len", "type", "wd.find", "sorted.append", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.get", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type"], ["", "def", "substitute", "(", "self", ",", "word", ",", "pos", ")", ":", "\n", "# get sememes", "\n", "        ", "word_sememes", "=", "self", ".", "hownet_dict", ".", "get_sememes_by_word", "(", "word", ",", "structured", "=", "False", ",", "lang", "=", "\"zh\"", ",", "merge", "=", "False", ")", "\n", "word_sememe_set", "=", "[", "t", "[", "'sememes'", "]", "for", "t", "in", "word_sememes", "]", "\n", "if", "len", "(", "word_sememes", ")", "==", "0", ":", "\n", "            ", "raise", "WordNotInDictionaryException", "(", ")", "\n", "\n", "# find candidates", "\n", "", "word_candidate", "=", "[", "(", "word", ",", "0", ")", "]", "\n", "for", "wd", "in", "self", ".", "zh_word_list", ":", "\n", "            ", "if", "wd", "==", "word", ":", "\n", "                ", "continue", "\n", "\n", "", "wd_pos", "=", "set", "(", ")", "\n", "for", "a", "in", "self", ".", "hownet_dict", ".", "get", "(", "wd", ")", ":", "\n", "                ", "if", "type", "(", "a", ")", "is", "not", "dict", ":", "\n", "                    ", "continue", "\n", "", "wd_pos", ".", "add", "(", "a", "[", "'en_grammar'", "]", ")", "\n", "", "if", "pos", "not", "in", "wd_pos", ":", "\n", "                ", "continue", "\n", "\n", "# sememe", "\n", "", "wd_sememes", "=", "self", ".", "hownet_dict", ".", "get_sememes_by_word", "(", "wd", ",", "structured", "=", "False", ",", "lang", "=", "\"zh\"", ",", "merge", "=", "False", ")", "\n", "wd_sememe_set", "=", "[", "t", "[", "'sememes'", "]", "for", "t", "in", "wd_sememes", "]", "\n", "if", "len", "(", "wd_sememes", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "common_sememe", "=", "0", "\n", "for", "s1", "in", "word_sememe_set", ":", "\n", "                ", "for", "s2", "in", "wd_sememe_set", ":", "\n", "                    ", "if", "s1", "==", "s2", ":", "\n", "                        ", "common_sememe", "+=", "1", "\n", "\n", "", "", "", "if", "common_sememe", ">", "0", ":", "\n", "                ", "if", "wd", ".", "find", "(", "\" \"", ")", "==", "-", "1", ":", "\n", "                    ", "word_candidate", ".", "append", "(", "(", "wd", ",", "1", "-", "common_sememe", "/", "len", "(", "word_sememe_set", ")", ")", ")", "\n", "\n", "", "", "", "word_candidate", "=", "sorted", "(", "word_candidate", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "            ", "word_candidate", "=", "word_candidate", "[", ":", "self", ".", "k", "]", "\n", "", "return", "word_candidate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_counterfit.CounterFittedSubstitute.__init__": [[10, 35], ["data_manager.DataManager.load", "embed_based.EmbedBasedSubstitute.__init__", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], ["def", "__init__", "(", "self", ",", "cosine", ":", "bool", "=", "False", ",", "k", ":", "int", "=", "50", ",", "threshold", ":", "float", "=", "0.5", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        English word substitute based on Counter-fitting word vectors.\n        `[pdf] <https://www.aclweb.org/anthology/N16-1018.pdf>`__\n\n        Args:\n            cosine: If `true` then the cosine distance is used, otherwise the Euclidian distance is used.\n            threshold: Distance threshold. Default: 0.5\n            k: Top-k results to return. If k is `None`, all results will be returned. Default: 50\n            device: A pytocrh device for computing distances. Default: \"cpu\"\n        \n        :Data Requirements: :py:data:`.AttackAssist.CounterFit`\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "wordvec", "=", "DataManager", ".", "load", "(", "\"AttackAssist.CounterFit\"", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "wordvec", ".", "word2id", ",", "\n", "torch", ".", "from_numpy", "(", "wordvec", ".", "embedding", ")", ",", "\n", "cosine", "=", "cosine", ",", "\n", "k", "=", "k", ",", "\n", "threshold", "=", "threshold", ",", "\n", "device", "=", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_hownet.HowNetSubstitute.__init__": [[12, 28], ["open", "pickle.load", "data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ",", "k", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        English Sememe-based word substitute based on OpenHowNet.\n        `[pdf] <https://arxiv.org/pdf/1901.09957.pdf>`__\n\n        Args:\n            k: Top-k results to return. If k is `None`, all results will be returned.\n        \n        :Data Requirements: :py:data:`.AttackAssist.HownetSubstituteDict`\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "with", "open", "(", "DataManager", ".", "load", "(", "\"AttackAssist.HownetSubstituteDict\"", ")", ",", "'rb'", ")", "as", "fp", ":", "\n", "            ", "self", ".", "dict", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_hownet.HowNetSubstitute.substitute": [[29, 43], ["exceptions.WordNotInDictionaryException", "ret.append"], "methods", ["None"], ["", "def", "substitute", "(", "self", ",", "word", ":", "str", ",", "pos", ":", "str", ")", ":", "\n", "\n", "        ", "if", "word", "not", "in", "self", ".", "dict", "or", "pos", "not", "in", "self", ".", "dict", "[", "word", "]", ":", "\n", "            ", "raise", "WordNotInDictionaryException", "(", ")", "\n", "\n", "", "word_candidate", "=", "self", ".", "dict", "[", "word", "]", "[", "pos", "]", "\n", "\n", "ret", "=", "[", "]", "\n", "for", "wd", "in", "word_candidate", ":", "\n", "            ", "ret", ".", "append", "(", "(", "wd", ",", "1", ")", ")", "\n", "\n", "", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "            ", "ret", "=", "ret", "[", ":", "self", ".", "k", "]", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute": [[16, 23], ["english_wordnet.WordNetSubstitute", "english_wordnet.WordNetSubstitute", "chinese_wordnet.ChineseWordNetSubstitute"], "function", ["None"], ["from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_glove.GloveSubstitute.__init__": [[11, 36], ["data_manager.DataManager.load", "embed_based.EmbedBasedSubstitute.__init__", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], ["def", "__init__", "(", "self", ",", "cosine", "=", "False", ",", "k", "=", "50", ",", "threshold", "=", "0.5", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        English word substitute based on GloVe word vectors.\n        `[pdf] <https://nlp.stanford.edu/pubs/glove.pdf>`__\n\n        Args:\n            cosine: If `true` then the cosine distance is used, otherwise the Euclidian distance is used.\n            threshold: Distance threshold. Default: 0.5\n            k: Top-k results to return. If k is `None`, all results will be returned. Default: 50\n            device: A pytocrh device for computing distances. Default: \"cpu\"\n        \n        :Data Requirements: :py:data:`.AttackAssist.GloVe`\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "wordvec", "=", "DataManager", ".", "load", "(", "\"AttackAssist.GloVe\"", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "wordvec", ".", "word2id", ",", "\n", "torch", ".", "from_numpy", "(", "wordvec", ".", "embedding", ")", ",", "\n", "cosine", "=", "cosine", ",", "\n", "k", "=", "k", ",", "\n", "threshold", "=", "threshold", ",", "\n", "device", "=", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.embed_based.EmbedBasedSubstitute.__init__": [[12, 43], ["embed_based.EmbedBasedSubstitute.embedding.to", "embed_based.EmbedBasedSubstitute.word2id.items", "embed_based.EmbedBasedSubstitute.embedding.norm"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.norm"], ["    ", "def", "__init__", "(", "self", ",", "word2id", ":", "Dict", "[", "str", ",", "int", "]", ",", "embedding", ":", "torch", ".", "Tensor", ",", "cosine", "=", "False", ",", "k", "=", "50", ",", "threshold", "=", "0.5", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Embedding based word substitute.\n\n        Args:\n            word2id: A `dict` maps words to indexes.\n            embedding: A word embedding matrix.\n            cosine: If `true` then the cosine distance is used, otherwise the Euclidian distance is used.\n            threshold: Distance threshold. Default: 0.5\n            k: Top-k results to return. If k is `None`, all results will be returned. Default: 50\n            device: A pytocrh device for computing distances. Default: \"cpu\"\n        \n        \"\"\"", "\n", "\n", "if", "device", "is", "None", ":", "\n", "            ", "device", "=", "\"cpu\"", "\n", "\n", "", "self", ".", "word2id", "=", "word2id", "\n", "self", ".", "embedding", "=", "embedding", "\n", "self", ".", "cosine", "=", "cosine", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "threshold", "=", "threshold", "\n", "\n", "self", ".", "id2word", "=", "{", "\n", "val", ":", "key", "for", "key", ",", "val", "in", "self", ".", "word2id", ".", "items", "(", ")", "\n", "}", "\n", "\n", "if", "cosine", ":", "\n", "            ", "self", ".", "embedding", "=", "self", ".", "embedding", "/", "self", ".", "embedding", ".", "norm", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "self", ".", "embedding", "=", "self", ".", "embedding", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.embed_based.EmbedBasedSubstitute.__call__": [[44, 46], ["embed_based.EmbedBasedSubstitute.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], ["", "def", "__call__", "(", "self", ",", "word", ":", "str", ",", "pos", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "substitute", "(", "word", ",", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.embed_based.EmbedBasedSubstitute.substitute": [[47, 67], ["dis.argsort", "idx[].tolist", "exceptions.WordNotInDictionaryException", "len", "dis[].item"], "methods", ["None"], ["", "def", "substitute", "(", "self", ",", "word", ",", "pos", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2id", ":", "\n", "            ", "raise", "WordNotInDictionaryException", "(", ")", "\n", "", "wdid", "=", "self", ".", "word2id", "[", "word", "]", "\n", "wdvec", "=", "self", ".", "embedding", "[", "wdid", ",", ":", "]", "\n", "if", "self", ".", "cosine", ":", "\n", "            ", "dis", "=", "1", "-", "(", "wdvec", "*", "self", ".", "embedding", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "dis", "=", "(", "wdvec", "-", "self", ".", "embedding", ")", ".", "norm", "(", "dim", "=", "1", ")", "\n", "\n", "", "idx", "=", "dis", ".", "argsort", "(", ")", "\n", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "            ", "idx", "=", "idx", "[", ":", "self", ".", "k", "]", "\n", "\n", "", "threshold_end", "=", "0", "\n", "while", "threshold_end", "<", "len", "(", "idx", ")", "and", "dis", "[", "idx", "[", "threshold_end", "]", "]", "<", "self", ".", "threshold", ":", "\n", "            ", "threshold_end", "+=", "1", "\n", "", "idx", "=", "idx", "[", ":", "threshold_end", "]", ".", "tolist", "(", ")", "\n", "return", "[", "\n", "(", "self", ".", "id2word", "[", "id_", "]", ",", "dis", "[", "id_", "]", ".", "item", "(", ")", ")", "for", "id_", "in", "idx", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_wordnet.WordNetSubstitute.__init__": [[24, 38], ["data_manager.DataManager.load"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["def", "__init__", "(", "self", ",", "k", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        English word substitute based on wordnet.\n\n        Args:\n            k: Top-k results to return. If k is `None`, all results will be returned. Default: 50\n        \n        :Data Requirements: :py:data:`.TProcess.NLTKWordNet`\n        :Language: english\n        \n        \"\"\"", "\n", "\n", "self", ".", "wn", "=", "DataManager", ".", "load", "(", "\"TProcess.NLTKWordNet\"", ")", "\n", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_wordnet.WordNetSubstitute.substitute": [[39, 77], ["english_wordnet.WordNetSubstitute.wn.synsets", "exceptions.WordNotInDictionaryException", "wordnet_synonyms.extend", "synonyms.append", "word.replace().split", "english_wordnet.prefilter", "synonyms_1.append", "ret.append", "synset.lemmas", "wordnet_synonym.name().replace().split", "sss.append", "synonym.lower", "synonym.lower", "word.replace", "wordnet_synonym.name().replace", "wordnet_synonym.name"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_wordnet.prefilter", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.name"], ["", "def", "substitute", "(", "self", ",", "word", ":", "str", ",", "pos", ":", "str", ")", ":", "\n", "        ", "if", "pos", "==", "\"other\"", ":", "\n", "            ", "raise", "WordNotInDictionaryException", "(", ")", "\n", "", "pos_in_wordnet", "=", "{", "\n", "\"adv\"", ":", "\"r\"", ",", "\n", "\"adj\"", ":", "\"a\"", ",", "\n", "\"verb\"", ":", "\"v\"", ",", "\n", "\"noun\"", ":", "\"n\"", "\n", "}", "[", "pos", "]", "\n", "\n", "wordnet_synonyms", "=", "[", "]", "\n", "synsets", "=", "self", ".", "wn", ".", "synsets", "(", "word", ",", "pos", "=", "pos_in_wordnet", ")", "\n", "for", "synset", "in", "synsets", ":", "\n", "            ", "wordnet_synonyms", ".", "extend", "(", "synset", ".", "lemmas", "(", ")", ")", "\n", "", "synonyms", "=", "[", "]", "\n", "for", "wordnet_synonym", "in", "wordnet_synonyms", ":", "\n", "            ", "spacy_synonym", "=", "wordnet_synonym", ".", "name", "(", ")", ".", "replace", "(", "'_'", ",", "' '", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "synonyms", ".", "append", "(", "spacy_synonym", ")", "# original word", "\n", "", "token", "=", "word", ".", "replace", "(", "'_'", ",", "' '", ")", ".", "split", "(", ")", "[", "0", "]", "#TODO:bugs", "\n", "\n", "sss", "=", "[", "]", "\n", "for", "synonym", "in", "synonyms", ":", "\n", "            ", "if", "prefilter", "(", "token", ",", "synonym", ")", ":", "\n", "                ", "sss", ".", "append", "(", "synonym", ")", "\n", "", "", "synonyms", "=", "sss", "[", ":", "]", "\n", "\n", "synonyms_1", "=", "[", "]", "\n", "for", "synonym", "in", "synonyms", ":", "\n", "            ", "if", "synonym", ".", "lower", "(", ")", "in", "synonyms_1", ":", "\n", "                ", "continue", "\n", "", "synonyms_1", ".", "append", "(", "synonym", ".", "lower", "(", ")", ")", "\n", "\n", "", "ret", "=", "[", "]", "\n", "for", "syn", "in", "synonyms_1", ":", "\n", "            ", "ret", ".", "append", "(", "(", "syn", ",", "1", ")", ")", "\n", "", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "            ", "ret", "=", "ret", "[", ":", "self", ".", "k", "]", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.english_wordnet.prefilter": [[8, 18], ["len", "synonym.split"], "function", ["None"], ["def", "prefilter", "(", "token", ",", "synonym", ")", ":", "# \u9884\u8fc7\u6ee4\uff08\u539f\u8bcd\uff0c\u4e00\u4e2a\u5019\u9009\u8bcd", "\n", "    ", "if", "(", "len", "(", "synonym", ".", "split", "(", ")", ")", ">", "2", "or", "(", "# the synonym produced is a phrase", "\n", "synonym", "==", "token", ")", "or", "(", "# the pos of the token synonyms are different", "\n", "token", "==", "'be'", ")", "or", "(", "\n", "token", "==", "'is'", ")", "or", "(", "\n", "token", "==", "'are'", ")", "or", "(", "\n", "token", "==", "'am'", ")", ")", ":", "# token is be", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.__init__": [[11, 23], ["nltk.download", "nltk.download"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.download"], ["def", "__init__", "(", "self", ",", "k", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Chinese word substitute based on wordnet.\n\n        Args:\n            k: Top-k results to return. If k is `None`, all results will be returned. Default: 50\n        \n        :Language: chinese\n        \"\"\"", "\n", "self", ".", "k", "=", "k", "\n", "nltk", ".", "download", "(", "\"wordnet\"", ")", "\n", "nltk", ".", "download", "(", "\"omw\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute": [[24, 45], ["nltk.corpus.wordnet.synsets", "exceptions.WordNotInDictionaryException", "synset.lemma_names", "synonyms.append"], "methods", ["None"], ["", "def", "substitute", "(", "self", ",", "word", ":", "str", ",", "pos", ":", "str", ")", ":", "\n", "        ", "if", "pos", "==", "\"other\"", ":", "\n", "            ", "raise", "WordNotInDictionaryException", "(", ")", "\n", "", "pos_in_wordnet", "=", "{", "\n", "\"adv\"", ":", "\"r\"", ",", "\n", "\"adj\"", ":", "\"a\"", ",", "\n", "\"verb\"", ":", "\"v\"", ",", "\n", "\"noun\"", ":", "\"n\"", "\n", "}", "[", "pos", "]", "\n", "\n", "synonyms", "=", "[", "]", "\n", "for", "synset", "in", "wn", ".", "synsets", "(", "word", ",", "pos", "=", "pos_in_wordnet", ",", "lang", "=", "'cmn'", ")", ":", "\n", "            ", "for", "lemma", "in", "synset", ".", "lemma_names", "(", "'cmn'", ")", ":", "\n", "                ", "if", "lemma", "==", "word", ":", "\n", "                    ", "continue", "\n", "", "synonyms", ".", "append", "(", "(", "lemma", ",", "1", ")", ")", "\n", "\n", "", "", "if", "self", ".", "k", "is", "not", "None", ":", "\n", "            ", "return", "synonyms", "[", ":", "self", ".", "k", "]", "\n", "\n", "", "return", "synonyms", "\n", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word_embedding.__init__.WordEmbedding.__init__": [[6, 9], ["None"], "methods", ["None"], ["from", ".", "attackers", "import", "Attacker", ",", "ClassificationAttacker", "\n", "\n", "# victim", "\n", "from", ".", "import", "victim", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.word_embedding.__init__.WordEmbedding.transform": [[10, 18], ["isinstance"], "methods", ["None"], ["from", ".", "victim", "import", "classifiers", "\n", "from", ".", "victim", "import", "Victim", "\n", "from", ".", "victim", ".", "classifiers", "import", "Classifier", "\n", "\n", "# metrics", "\n", "from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words": [[4, 11], ["None"], "function", ["None"], ["# attacker", "\n", "from", ".", "import", "attackers", "\n", "from", ".", "attackers", "import", "Attacker", ",", "ClassificationAttacker", "\n", "\n", "# victim", "\n", "from", ".", "import", "victim", "\n", "from", ".", "victim", "import", "classifiers", "\n", "from", ".", "victim", "import", "Victim", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.base.AttackGoal.check": [[2, 4], ["NotImplementedError"], "methods", ["None"], ["import", "functools", "\n", "from", "typing", "import", "Union", "\n", "from", ".", "context", "import", "AttackContext", ",", "AttackContextShadow", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.__init__": [[4, 7], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "target", ",", "targeted", ")", ":", "\n", "        ", "self", ".", "target", "=", "target", "\n", "self", ".", "targeted", "=", "targeted", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.is_targeted": [[8, 11], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_targeted", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "targeted", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check": [[12, 17], ["None"], "methods", ["None"], ["", "def", "check", "(", "self", ",", "adversarial_sample", ",", "prediction", ")", ":", "\n", "        ", "if", "self", ".", "targeted", ":", "\n", "            ", "return", "prediction", "==", "self", ".", "target", "\n", "", "else", ":", "\n", "            ", "return", "prediction", "!=", "self", ".", "target", "", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attackers.base.Attacker.__call__": [[14, 16], ["NotImplementedError"], "methods", ["None"], ["\n", "", "return", "invoke_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attackers.base.Attacker._victim_check": [[17, 30], ["RuntimeError", "available_langs.append", "AttributeError"], "methods", ["None"], ["", "class", "Victim", ":", "\n", "    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_method_tags", "\n", "\n", "", "def", "__init_subclass__", "(", "cls", ",", "invoke_funcs", "=", "[", "]", ",", "tags", "=", "set", "(", ")", ")", ":", "\n", "        ", "for", "func_name", ",", "method", "in", "invoke_funcs", ":", "\n", "            ", "setattr", "(", "cls", ",", "func_name", ",", "invoke_decorator", "(", "getattr", "(", "cls", ",", "func_name", ")", ",", "method", ")", ")", "\n", "", "cls", ".", "_method_tags", "=", "set", "(", "tags", ")", "\n", "\n", "", "@", "property", "\n", "def", "supported_language", "(", "self", ")", ":", "\n", "        ", "for", "tag", "in", "self", ".", "TAGS", ":", "\n", "            ", "if", "tag", ".", "type", "==", "\"lang\"", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attackers.base.Attacker.attack": [[31, 33], ["NotImplementedError"], "methods", ["None"], ["                ", "return", "tag", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.attackers.classification.ClassificationAttacker.__call__": [[12, 35], ["classification.ClassificationAttacker._victim_check", "classification.ClassificationAttacker.attack", "isinstance", "TypeError", "Tag", "AttributeError", "AttributeError", "attack_assist.goal.ClassifierGoal", "attack_assist.goal.ClassifierGoal", "victim.get_pred", "victim.get_pred", "attack_assist.goal.ClassifierGoal.check", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attackers.base.Attacker._victim_check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.attack", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check"], ["def", "__call__", "(", "self", ",", "victim", ":", "Classifier", ",", "input_", ":", "Any", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "victim", ",", "Classifier", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"`victim` is an instance of `%s`, but `%s` expected\"", "%", "(", "victim", ".", "__class__", ".", "__name__", ",", "\"Classifier\"", ")", ")", "\n", "", "if", "Tag", "(", "\"get_pred\"", ",", "\"victim\"", ")", "not", "in", "victim", ".", "TAGS", ":", "\n", "            ", "raise", "AttributeError", "(", "\"`%s` needs victim to support `%s` method\"", "%", "(", "self", ".", "__class__", ".", "__name__", ",", "\"get_pred\"", ")", ")", "\n", "", "self", ".", "_victim_check", "(", "victim", ")", "\n", "\n", "if", "TAG_Classification", "not", "in", "victim", ".", "TAGS", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Victim model `%s` must be a classifier\"", "%", "victim", ".", "__class__", ".", "__name__", ")", "\n", "\n", "", "if", "\"target\"", "in", "input_", ":", "\n", "            ", "goal", "=", "ClassifierGoal", "(", "input_", "[", "\"target\"", "]", ",", "targeted", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "origin_x", "=", "victim", ".", "get_pred", "(", "[", "input_", "[", "\"x\"", "]", "]", ")", "[", "0", "]", "\n", "goal", "=", "ClassifierGoal", "(", "origin_x", ",", "targeted", "=", "False", ")", "\n", "\n", "", "adversarial_sample", "=", "self", ".", "attack", "(", "victim", ",", "input_", "[", "\"x\"", "]", ",", "goal", ")", "\n", "\n", "if", "adversarial_sample", "is", "not", "None", ":", "\n", "            ", "y_adv", "=", "victim", ".", "get_pred", "(", "[", "adversarial_sample", "]", ")", "[", "0", "]", "\n", "if", "not", "goal", ".", "check", "(", "adversarial_sample", ",", "y_adv", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Check attacker result failed: result ([%d] %s) expect (%s%d)\"", "%", "(", "y_adv", ",", "adversarial_sample", ",", "\"\"", "if", "goal", ".", "targeted", "else", "\"not \"", ",", "goal", ".", "target", ")", ")", "\n", "", "", "return", "adversarial_sample", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.Sample.__init__": [[99, 114], ["set", "nltk.corpus.stopwords.words"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.Sample.set_mask": [[115, 118], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.Sample.set_new_info": [[119, 122], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.DeepFool.__init__": [[125, 134], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.DeepFool.forward": [[135, 301], ["copy.deepcopy", "copy.deepcopy", "copy.deepcopy.size", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "copy.deepcopy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "copy.deepcopy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "copy.deepcopy.requires_grad_", "copy.deepcopy.forward", "torch.sum().backward", "torch.sum().backward", "torch.sum().backward", "torch.sum().backward", "copy.deepcopy", "torch.div", "torch.div", "torch.div", "torch.div", "copy.deepcopy", "copy.deepcopy.forward", "target.unsqueeze", "target.unsqueeze.size", "torch.where.cuda", "torch.where.cuda", "finish_mask.cuda.cuda.cuda", "finished.cuda.cuda.cuda", "__init__.DeepFool.loops_needed.cuda", "copy.deepcopy.requires_grad_", "copy.deepcopy.forward", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.gather().sum", "torch.gather().sum", "torch.gather().sum", "torch.gather().sum", "torch.gather().sum.backward", "torch.gather().sum.backward", "copy.deepcopy", "range", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.div", "torch.div", "torch.div", "torch.div", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "cur_update_mask.cuda.cuda.bool", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.detach_", "torch.where.detach_", "copy.deepcopy.detach_", "torch.div.detach_", "torch.div.detach_", "copy.deepcopy.detach_", "__init__.DeepFool.norm_dim().unsqueeze", "copy.deepcopy", "copy.deepcopy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.where.cuda", "torch.where.cuda", "torch.where.cuda", "torch.where.cuda", "zero_gradients", "torch.gather().sum", "torch.gather().sum", "torch.gather().sum", "torch.gather().sum", "torch.gather().sum.backward", "torch.gather().sum.backward", "copy.deepcopy", "f_k.squeeze.squeeze.squeeze", "torch.div", "torch.div", "torch.div", "torch.div", "valid_pert_mask.bool.bool.bool", "torch.where", "torch.where", "torch.where", "torch.where", "torch.reshape().float", "torch.reshape().float", "torch.reshape().float", "torch.reshape().float", "valid_w_mask.bool.bool.bool", "torch.where", "torch.where", "torch.where", "torch.where", "torch.clamp().reshape", "torch.clamp().reshape", "torch.clamp().reshape", "torch.clamp().reshape", "__init__.DeepFool.norm_dim().reshape", "cur_update_mask.cuda.cuda.cuda", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "__init__.DeepFool.norm_dim", "copy.deepcopy.forward", "cur_update_mask.cuda.cuda.squeeze", "__init__.DeepFool.norm_dim", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "__init__.DeepFool.norm_dim", "copy.deepcopy.requires_grad_", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "copy.deepcopy.unsqueeze", "I[].unsqueeze", "copy.deepcopy.unsqueeze", "I[].unsqueeze", "k_i.unsqueeze", "copy.deepcopy.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.forward", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.forward", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.forward", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.forward", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.DeepFool.norm_dim": [[302, 310], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "w.size", "torch.stack.append", "torch.stack.append", "tuple", "w[].norm"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.norm"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.WordSaliencyBatch.__init__": [[313, 319], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.WordSaliencyBatch.split_forward": [[320, 334], ["new_word_ids.split", "new_lengths.split", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "__init__.WordSaliencyBatch.model", "torch.cat.append", "torch.cat.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.WordSaliencyBatch.compute_saliency": [[335, 484], ["print", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_cached", "torch.cuda.reset_max_memory_cached", "torch.cuda.reset_max_memory_cached", "torch.cuda.reset_max_memory_cached", "print", "print", "copy.deepcopy", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "word_ids.unsqueeze", "new_word_ids.view.view.repeat", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "diag_mask.cuda.cuda.unsqueeze", "diag_mask.cuda.cuda.repeat().bool", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "new_word_ids.view.view.view", "new_lengths.repeat().view.repeat().view.repeat().view", "torch.argmax.view", "torch.argmax.view", "new_predictions.repeat().view.repeat().view.repeat().view", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "__init__.WordSaliencyBatch.split_forward", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "unk_id.cuda.cuda.cuda", "__init__.WordSaliencyBatch.model", "one_hot_mask.cuda.cuda.cuda", "torch.argmax.unsqueeze", "torch.argmax.unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "diag_mask.cuda.cuda.cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "new_predictions.repeat().view.repeat().view.size", "one_hot_mask.cuda.cuda.cuda", "new_predictions.repeat().view.repeat().view.unsqueeze", "all_true_probs.cuda.cuda.cuda", "torch.masked_select.unsqueeze", "torch.masked_select.unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "diag_mask.cuda.cuda.repeat", "new_lengths.repeat().view.repeat().view.repeat", "new_predictions.repeat().view.repeat().view.repeat", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.cuda.memory_allocated", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "logits.size", "logits.size"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.WordSaliencyBatch.split_forward"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.__init__": [[491, 512], ["set", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "__init__.WordSaliencyBatch", "nltk.corpus.stopwords.words", "__init__.DeepFool", "print"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.select_word_batch": [[513, 551], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "mask.cuda.cuda.bool", "__init__.GreedyAttack.word_saliency.compute_saliency", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "mask.cuda.cuda.cuda", "cur_available.cuda.cuda.cuda", "all_replace_orders.cuda.cuda.cuda"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.WordSaliencyBatch.compute_saliency"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.construct_new_sample_batch2": [[552, 589], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "__init__.GreedyAttack.construct_new_sample2", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "n_new_samples.append", "new_labels.size"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.construct_new_sample2"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.construct_new_sample2": [[590, 637], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "int", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "word_ids.unsqueeze.unsqueeze.unsqueeze", "length.unsqueeze.unsqueeze.unsqueeze", "label.unsqueeze.unsqueeze.unsqueeze", "word_ids[].data.cpu().numpy", "len", "copy.deepcopy", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "word_ids[].data.cpu"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.adv_attack": [[638, 996], ["copy.deepcopy", "word_ids.unsqueeze.unsqueeze.unsqueeze", "word_ids.unsqueeze.unsqueeze.size", "model", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "logits.size", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.arange().unsqueeze().repeat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.stack().transpose.append", "torch.stack().transpose.append", "range", "__init__.GreedyAttack.attack", "intermediate_normals.cuda.cuda.append", "__init__.GreedyAttack.norm_dim", "intermediate_distances.cuda.cuda.append", "copy.deepcopy", "copy.deepcopy", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "one_hot_mask.cuda.cuda.cuda", "torch.argmax.unsqueeze", "torch.argmax.unsqueeze", "finish_mask.bool.bool.cuda", "torch.where.cuda", "torch.where.cuda", "torch.where.cuda", "torch.where.cuda", "torch.where.cuda", "torch.where.cuda", "torch.mul.cuda", "torch.mul.cuda", "torch.where.cuda", "torch.where.cuda", "__init__.GreedyAttack.model.zero_grad", "__init__.GreedyAttack.attack", "intermediate_normals.cuda.cuda.append", "__init__.GreedyAttack.norm_dim", "intermediate_distances.cuda.cuda.append", "__init__.GreedyAttack.select_word_batch", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "__init__.GreedyAttack.construct_new_sample_batch2", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "torch.repeat_interleave", "__init__.GreedyAttack.norm_dim", "__init__.GreedyAttack.cosine_similarity", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.detach_", "torch.where.detach_", "torch.where.detach_", "torch.where.detach_", "torch.where.detach_", "torch.where.detach_", "torch.where.detach_", "torch.where.detach_", "intermediate_projections.cuda.cuda.append", "intermediate_cosines.cuda.cuda.append", "intermediate_update_masks.append", "finish_mask.bool.bool.bool", "final_r_tot.cuda.cuda.cuda", "final_word_ids.cuda.cuda.cuda", "final_predictions.cuda.cuda.cuda", "intermediate_normals.cuda.cuda.cuda", "intermediate_cosines.cuda.cuda.cuda", "intermediate_projections.cuda.cuda.cuda", "intermediate_distances.cuda.cuda.cuda", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "finish_mask.bool.bool.sum", "all_new_word_ids.cuda.cuda.size", "all_new_labels.size", "all_new_word_ids.cuda.cuda.cuda", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "repeats.cuda.cuda.cuda", "__init__.GreedyAttack.attack", "__init__.GreedyAttack.norm_dim", "len", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.max", "torch.max", "torch.max", "torch.max", "selected_indices.cuda.cuda.append", "selected_projections.cuda.cuda.append", "selected_predictions.cuda.cuda.append", "selected_word_ids.cuda.cuda.append", "selected_sent_vecs.cuda.cuda.append", "torch.tensor.append", "torch.tensor.append", "torch.stack.append", "torch.stack.append", "selected_indices.cuda.cuda.cuda", "selected_projections.cuda.cuda.cuda", "selected_predictions.cuda.cuda.cuda", "selected_word_ids.cuda.cuda.cuda", "selected_sent_vecs.cuda.cuda.cuda", "torch.mul.view", "torch.mul.view", "torch.mul.view", "torch.mul.view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "word_ids.unsqueeze.unsqueeze.size", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.min", "torch.min", "torch.min", "torch.min", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.attack", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.attack", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.select_word_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.construct_new_sample_batch2", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.attack", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.norm_dim": [[997, 1005], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "w.size", "torch.stack.append", "torch.stack.append", "tuple", "w[].norm"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.norm"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.TAGS": [[1008, 1011], ["tags.Tag", "tags.Tag"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.__init__": [[1012, 1080], ["DEFAULT_CONFIG.copy", "__init__.GEOAttacker.config.update", "__init__.GEOAttacker.build_vocab", "__init__.GEOAttacker.get_vocab", "__init__.GEOAttacker.construct_synonyms", "__init__.GreedyAttack", "lst.append", "lst.append", "len", "utils.get_language", "utils.language_by_name", "attack_assist.substitute.word.get_default_substitute", "text_process.tokenizer.get_default_tokenizer", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.build_vocab", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.get_vocab", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.construct_synonyms", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.preprocess": [[1081, 1104], ["list", "max", "len", "list", "map", "min", "word_ids.append", "len", "word_ids.append", "len", "words.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "map", "__init__.GEOAttacker.word2id.keys", "__init__.GEOAttacker.tokenizer.tokenize", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.attack": [[1105, 1153], ["x_orig.lower.lower.lower", "list", "len", "__init__.Sample", "set", "__init__.GEOAttacker.create_mask", "__init__.GEOAttacker.inner_attack", "__init__.GEOAttacker.tokenizer.detokenize", "map", "word_ids.append", "len", "word_ids.append", "len", "list.append", "nltk.corpus.stopwords.words", "clsf.get_pred", "clsf.get_pred", "__init__.GEOAttacker.tokenizer.tokenize", "__init__.GEOAttacker.word2id.keys", "word_id.item"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.create_mask", "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.inner_attack", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.create_mask": [[1154, 1178], ["enumerate", "sample.set_mask", "mask.append", "stopwords_mask.append", "mask.append", "word.lower", "stopwords_mask.append", "stopwords_mask.append", "__init__.GEOAttacker.word2id.keys", "len", "mask.append", "mask.append"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.Sample.set_mask"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.get_vocab": [[1179, 1190], ["__init__.GEOAttacker.word2id.items", "print", "vocab.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.construct_synonyms": [[1191, 1229], ["range", "len", "nltk.corpus.wordnet.synsets", "list.append", "list.append", "list", "list", "syn.lemmas", "set", "set", "l.name", "list.append", "list.append", "__init__.GEOAttacker.word2id.keys"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.name"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.build_vocab": [[1230, 1257], ["collections.Counter", "sorted", "sorted.append", "sorted.append", "min", "list", "dict", "__init__.GEOAttacker.tokenizer.tokenize", "collections.Counter.items", "len", "zip", "zip", "word[].lower", "len", "range", "dict.items", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GEOAttacker.inner_attack": [[1265, 1308], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "__init__.GEOAttacker.greedy_attack.adv_attack", "model.cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "word_ids.cuda.cuda.cuda", "stopwords_mask.cuda.cuda.cuda", "mask.cuda.cuda.cuda"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.geometry.__init__.GreedyAttack.adv_attack"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.TAGS": [[17, 20], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.__init__": [[21, 58], ["utils.check_language", "text_process.tokenizer.get_default_tokenizer"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer"], ["# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.attack": [[59, 82], ["__init__.DeepWordBugAttacker.tokenizer.tokenize", "__init__.DeepWordBugAttacker.scorefunc", "numpy.argsort", "__init__.DeepWordBugAttacker.tokenizer.detokenize", "goal.check", "victim.get_pred", "len", "__init__.DeepWordBugAttacker.transform"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.scorefunc", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.transform"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.scorefunc": [[83, 94], ["__init__.DeepWordBugAttacker.replaceone", "__init__.DeepWordBugAttacker.temporal", "__init__.DeepWordBugAttacker.temporaltail", "__init__.DeepWordBugAttacker.combined", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.replaceone", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.temporal", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.temporaltail", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.combined"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.transform": [[95, 102], ["__init__.DeepWordBugAttacker.homoglyph", "__init__.DeepWordBugAttacker.temporal", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.homoglyph", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.temporal"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.replaceone": [[104, 115], ["numpy.zeros", "range", "len", "len", "victim.get_prob", "__init__.DeepWordBugAttacker.tokenizer.detokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.temporal": [[116, 129], ["numpy.zeros", "numpy.zeros", "range", "range", "len", "len", "len", "victim.get_prob", "len", "abs", "__init__.DeepWordBugAttacker.tokenizer.detokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.temporaltail": [[130, 143], ["numpy.zeros", "numpy.zeros", "range", "range", "len", "len", "len", "victim.get_prob", "len", "abs", "__init__.DeepWordBugAttacker.tokenizer.detokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.combined": [[144, 148], ["__init__.DeepWordBugAttacker.temporal", "__init__.DeepWordBugAttacker.temporaltail"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.temporal", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.temporaltail"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.homoglyph": [[150, 158], ["numpy.random.randint", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.swap": [[159, 166], ["len", "numpy.random.randint", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.TAGS": [[15, 18], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.__init__": [[19, 73], ["set", "utils.check_language", "lst.append", "lst.append", "len", "utils.get_language", "utils.language_by_name", "attack_assist.substitute.word.get_default_substitute", "text_process.tokenizer.get_default_tokenizer", "attack_assist.filter_words.get_default_filter_words", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words"], ["from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.attack": [[74, 200], ["sentence.lower", "__init__.PSOAttacker.tokenizer.tokenize", "list", "list", "len", "__init__.PSOAttacker.generate_population", "range", "map", "map", "numpy.sum", "numpy.sum", "numpy.random.uniform", "__init__.PSOAttacker.predict_batch", "range", "__init__.PSOAttacker.predict_batch", "min", "zip", "__init__.PSOAttacker.get_neighbours", "zip", "range", "range", "range", "numpy.argsort", "range", "range", "range", "numpy.argsort", "range", "__init__.PSOAttacker.count_change_ratio", "__init__.PSOAttacker.get_neighbour_num", "range", "range", "range", "numpy.argsort", "numpy.max", "numpy.max", "numpy.argmax", "__init__.PSOAttacker.tokenizer.detokenize", "numpy.min", "numpy.min", "numpy.argmax", "__init__.PSOAttacker.tokenizer.detokenize", "__init__.PSOAttacker.sigmod", "numpy.random.uniform", "__init__.PSOAttacker.turn", "numpy.random.uniform", "__init__.PSOAttacker.turn", "numpy.argsort", "numpy.max", "numpy.max", "numpy.argmax", "__init__.PSOAttacker.tokenizer.detokenize", "numpy.min", "numpy.min", "numpy.argmax", "__init__.PSOAttacker.tokenizer.detokenize", "numpy.random.uniform", "__init__.PSOAttacker.mutate", "new_pop.append", "new_pop.append", "range", "__init__.PSOAttacker.equal", "__init__.PSOAttacker.equal"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.generate_population", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.predict_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.predict_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.get_neighbours", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.count_change_ratio", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.get_neighbour_num", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.sigmod", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.turn", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.turn", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.mutate", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.equal", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.equal"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.predict_batch": [[201, 204], ["numpy.array", "__init__.PSOAttacker.predict"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.predict"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.predict": [[205, 213], ["tuple", "victim.get_prob", "__init__.PSOAttacker.make_batch", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.make_batch"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.do_replace": [[214, 218], ["x_cur.copy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.generate_population": [[220, 230], ["range", "__init__.PSOAttacker.do_replace", "pop.append", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.do_replace"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.turn": [[232, 238], ["copy.deepcopy", "range", "numpy.random.uniform"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.mutate": [[239, 249], ["copy.deepcopy", "numpy.random.choice", "numpy.random.choice", "__init__.PSOAttacker.sum_diff", "numpy.sum", "numpy.random.choice", "len", "numpy.sign"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.sum_diff"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.sum_diff": [[250, 256], ["zip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.norm": [[257, 273], ["numpy.sum", "range", "tn.append", "tn.append", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.get_neighbour_num": [[275, 280], ["len", "__init__.PSOAttacker.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.get_neighbours": [[281, 291], ["list", "map", "__init__.PSOAttacker.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.make_batch": [[293, 295], ["__init__.PSOAttacker.tokenizer.detokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.equal": [[296, 301], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.sigmod": [[302, 304], ["numpy.exp"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.count_change_ratio": [[305, 308], ["float", "float", "numpy.sum", "numpy.array", "numpy.array"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.TAGS": [[16, 24], ["tags.Tag", "ret.add", "ret.add", "tags.Tag", "tags.Tag"], "methods", ["None"], ["from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.__init__": [[25, 79], ["utils.check_language", "set", "lst.append", "lst.append", "len", "utils.get_language", "utils.language_by_name", "attack_assist.substitute.word.get_default_substitute", "text_process.tokenizer.get_default_tokenizer", "attack_assist.filter_words.get_default_filter_words", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words"], ["from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.attack": [[80, 100], ["__init__.TextBuggerAttacker.tokenizer.tokenize", "__init__.TextBuggerAttacker.get_word_importances", "__init__.TextBuggerAttacker.get_w_word_importances", "__init__.TextBuggerAttacker.selectBug", "__init__.TextBuggerAttacker.replaceWithBug", "__init__.TextBuggerAttacker.tokenizer.detokenize", "goal.check", "word.lower", "victim.get_pred"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.get_word_importances", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.get_w_word_importances", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.selectBug", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.replaceWithBug", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.get_word_importances": [[101, 110], ["range", "len", "__init__.TextBuggerAttacker.tokenizer.detokenize", "clsf.get_prob", "sorted", "word_losses.items"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.get_w_word_importances": [[111, 121], ["clsf.get_grad", "numpy.linalg.norm", "len", "RuntimeError", "sorted", "enumerate", "len", "numpy.linalg.norm.tolist"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pso.__init__.PSOAttacker.norm"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.selectBug": [[122, 133], ["__init__.TextBuggerAttacker.generateBugs", "float", "__init__.TextBuggerAttacker.items", "__init__.TextBuggerAttacker.replaceWithBug", "__init__.TextBuggerAttacker.getScore"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.generateBugs", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.replaceWithBug", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.getScore"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.getScore": [[134, 141], ["__init__.TextBuggerAttacker.tokenizer.detokenize", "clsf.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.replaceWithBug": [[142, 144], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.generateBugs": [[145, 155], ["__init__.TextBuggerAttacker.bug_insert", "__init__.TextBuggerAttacker.bug_delete", "__init__.TextBuggerAttacker.bug_swap", "__init__.TextBuggerAttacker.bug_sub_C", "__init__.TextBuggerAttacker.bug_sub_W", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_insert", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_delete", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_swap", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_sub_C", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_sub_W"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_sub_W": [[156, 164], ["__init__.TextBuggerAttacker.substitute", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_insert": [[165, 172], ["random.randint", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_delete": [[173, 178], ["random.randint", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_swap": [[179, 193], ["random.sample", "list", "len", "range", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.bug_sub_C": [[194, 208], ["__init__.TextBuggerAttacker.get_key_neighbors", "random.randint", "list", "len", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.get_key_neighbors"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textbugger.__init__.TextBuggerAttacker.get_key_neighbors": [[209, 233], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.TAGS": [[13, 16], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["\n", "# metrics", "\n", "from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.__init__": [[17, 70], ["set", "utils.check_language", "lst.append", "lst.append", "len", "utils.get_language", "utils.language_by_name", "text_process.tokenizer.get_default_tokenizer", "attack_assist.substitute.word.get_default_substitute", "attack_assist.filter_words.get_default_filter_words", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words"], ["\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.attack": [[72, 140], ["list.lower", "__init__.GeneticAttacker.tokenizer.tokenize", "list", "list", "range", "map", "map", "numpy.sum", "numpy.sum", "__init__.GeneticAttacker.perturb", "victim.get_prob", "numpy.random.choice", "numpy.random.choice", "__init__.GeneticAttacker.get_neighbour_num", "zip", "__init__.GeneticAttacker.get_neighbours", "zip", "range", "__init__.GeneticAttacker.make_batch", "numpy.argmax", "numpy.argmax", "numpy.sum", "numpy.sum", "__init__.GeneticAttacker.crossover", "__init__.GeneticAttacker.perturb", "numpy.argmax", "__init__.GeneticAttacker.tokenizer.detokenize", "numpy.argmax", "__init__.GeneticAttacker.tokenizer.detokenize", "zip"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.perturb", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.get_neighbour_num", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.get_neighbours", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.make_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.crossover", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.perturb", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.get_neighbour_num": [[141, 146], ["len", "__init__.GeneticAttacker.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.get_neighbours": [[147, 157], ["list", "map", "__init__.GeneticAttacker.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.select_best_replacements": [[158, 185], ["new_list.append", "x_cur.copy", "len", "clsf.get_prob", "numpy.max", "new_list.append", "rep_words.append", "__init__.GeneticAttacker.make_batch", "__init__.GeneticAttacker.select_best_replacements.do_replace"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.make_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.do_replace"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.make_batch": [[186, 188], ["__init__.GeneticAttacker.tokenizer.detokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.perturb": [[189, 207], ["len", "range", "__init__.GeneticAttacker.select_best_replacements", "numpy.random.choice", "numpy.sum", "numpy.sign", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.select_best_replacements"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.genetic.__init__.GeneticAttacker.crossover": [[209, 217], ["range", "len", "numpy.random.uniform", "ret.append", "ret.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.Feature.__init__": [[18, 27], ["None"], "methods", ["None"], ["# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker.TAGS": [[29, 32], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker.__init__": [[33, 111], ["transformers.BertTokenizerFast.from_pretrained", "transformers.BertConfig.from_pretrained", "transformers.BertForMaskedLM.from_pretrained().to", "set", "utils.check_language", "metric.UniversalSentenceEncoder", "torch.device", "attack_assist.filter_words.get_default_filter_words", "transformers.BertForMaskedLM.from_pretrained", "torch.cuda.is_available", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words"], ["loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker.attack": [[112, 278], ["sentence.lower", "__init__.Feature", "__init__.BAEAttacker._tokenize", "tokenizer.encode_plus", "torch.tensor", "torch.tensor().unsqueeze().to.size", "torch.Tensor", "orig_probs[].squeeze", "torch.softmax", "torch.softmax.max", "torch.tensor", "[].squeeze", "torch.topk", "__init__.BAEAttacker.get_important_scores", "int", "sorted", "copy.deepcopy", "tokenizer.convert_tokens_to_string", "torch.tensor", "torch.tensor", "victim.get_prob", "len", "enumerate", "enumerate", "len", "tokenizer.convert_tokens_to_ids", "int", "__init__.BAEAttacker.get_substitues", "tokenizer.convert_tokens_to_string", "__init__.BAEAttacker.encoder.calc_score", "tokenizer.encode_plus", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to.size", "[].squeeze", "torch.softmax", "torch.argmax", "goal.check", "Feature.changes.append", "__init__.BAEAttacker.mlm_model", "__init__.BAEAttacker.get_substitues", "data_manager.DataManager.load", "Feature.changes.append", "copy.deepcopy.pop", "torch.tensor.to", "len", "len", "len", "random.random", "temp_replace.insert", "torch.tensor().unsqueeze", "copy.deepcopy.insert", "NotImplementedError", "__init__.BAEAttacker.get_substitues", "__init__.BAEAttacker.get_substitues", "__init__.BAEAttacker.get_substitues", "__init__.BAEAttacker.get_substitues", "data_manager.DataManager.load.", "data_manager.DataManager.load.", "torch.Tensor", "copy.deepcopy.insert", "NotImplementedError", "len", "len", "torch.tensor", "victim.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker._tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_important_scores", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues", "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker._tokenize": [[279, 293], ["seq.replace().lower.replace().lower.replace().lower", "seq.replace().lower.replace().lower.split", "tokenizer.tokenize", "keys.append", "len", "seq.replace().lower.replace().lower.replace", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker._get_masked_insert": [[294, 301], ["max", "range", "len", "masked_words.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker.get_important_scores": [[302, 317], ["__init__.BAEAttacker._get_masked_insert", "torch.Tensor", "torch.softmax", "torch.argmax", "tgt_model.get_prob", "torch.index_select", "torch.softmax.max"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker._get_masked_insert", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker.get_substitues": [[319, 349], ["copy.deepcopy", "tokenizer.convert_tokens_to_ids", "torch.tensor().to", "torch.tensor().to", "model.eval", "tokenizer.convert_ids_to_tokens", "len", "torch.no_grad", "model", "torch.topk", "copy.deepcopy.insert", "NotImplementedError", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bae.__init__.BAEAttacker.get_sim_embed": [[350, 363], ["numpy.load", "open", "line.split", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.TAGS": [[11, 14], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["from", ".", "victim", "import", "Victim", "\n", "from", ".", "victim", ".", "classifiers", "import", "Classifier", "\n", "\n", "# metrics", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.__init__": [[15, 63], ["set", "utils.check_language", "lst.append", "lst.append", "len", "utils.get_language", "utils.language_by_name", "attack_assist.substitute.word.get_default_substitute", "text_process.tokenizer.get_default_tokenizer", "attack_assist.filter_words.get_default_filter_words", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words"], ["from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.attack": [[64, 83], ["sentence.lower", "__init__.HotFlipAttacker.tokenizer.tokenize", "list", "list", "zip", "map", "map", "__init__.HotFlipAttacker.get_neighbours", "__init__.HotFlipAttacker.tokenizer.detokenize", "goal.check", "__init__.HotFlipAttacker.do_replace", "victim.get_pred"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.get_neighbours", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.do_replace", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.do_replace": [[84, 88], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.hotflip.__init__.HotFlipAttacker.get_neighbours": [[89, 94], ["list", "map", "__init__.HotFlipAttacker.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.Feature.__init__": [[16, 25], ["None"], "methods", ["None"], ["from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.TAGS": [[27, 30], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.__init__": [[31, 90], ["transformers.BertTokenizerFast.from_pretrained", "transformers.BertConfig.from_pretrained", "transformers.BertForMaskedLM.from_pretrained().to", "set", "torch.device", "attack_assist.filter_words.get_default_filter_words", "transformers.BertForMaskedLM.from_pretrained", "attack_assist.substitute.word.get_default_substitute", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute"], ["download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.attack": [[91, 196], ["sentence.lower", "__init__.Feature", "__init__.BERTAttacker._tokenize", "tokenizer.encode_plus", "torch.Tensor", "orig_probs[].squeeze", "orig_probs[].squeeze.max", "torch.tensor", "[].squeeze", "torch.topk", "__init__.BERTAttacker.get_important_scores", "int", "sorted", "copy.deepcopy", "tokenizer.convert_tokens_to_string", "torch.tensor", "torch.tensor", "victim.get_prob", "len", "enumerate", "__init__.BERTAttacker.get_substitues", "tokenizer.convert_tokens_to_ids", "int", "tokenizer.convert_tokens_to_string", "tokenizer.encode_plus", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to.size", "[].squeeze", "torch.argmax", "goal.check", "Feature.changes.append", "__init__.BERTAttacker.mlm_model", "__init__.BERTAttacker.substitute", "list", "Feature.changes.append", "torch.tensor.to", "len", "len", "len", "torch.tensor().unsqueeze", "set", "set", "torch.Tensor", "torch.tensor", "victim.get_prob"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker._tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_important_scores", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker._tokenize": [[198, 212], ["seq.replace().lower.replace().lower.replace().lower", "seq.replace().lower.replace().lower.split", "tokenizer.tokenize", "keys.append", "len", "seq.replace().lower.replace().lower.replace", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker._get_masked": [[213, 220], ["max", "range", "len", "masked_words.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_important_scores": [[221, 235], ["__init__.BERTAttacker._get_masked", "torch.Tensor", "torch.argmax", "tgt_model.get_prob", "torch.index_select", "torch.Tensor.max"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker._get_masked", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_bpe_substitues": [[236, 274], ["range", "torch.nn.CrossEntropyLoss", "torch.tensor", "all_substitutes[].to", "all_substitutes[].to.size", "torch.nn.CrossEntropyLoss.", "torch.exp", "torch.sort", "substitutes.size", "mlm_model", "word_predictions.view", "all_substitutes[].to.view", "torch.mean", "tokenizer.convert_tokens_to_string", "final_words.append", "len", "torch.exp.view", "tokenizer._convert_id_to_token", "int", "int", "lev_i.append", "int"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_substitues": [[275, 295], ["substitutes.size", "zip", "__init__.BERTAttacker.append", "__init__.BERTAttacker.get_bpe_substitues", "tokenizer._convert_id_to_token", "int"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_bpe_substitues"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.bert_attack.__init__.BERTAttacker.get_sim_embed": [[296, 309], ["numpy.load", "open", "line.split", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pwws.__init__.PWWSAttacker.TAGS": [[13, 16], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["\n", "# metrics", "\n", "from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pwws.__init__.PWWSAttacker.__init__": [[17, 69], ["utils.check_language", "set", "lst.append", "lst.append", "len", "utils.get_language", "utils.language_by_name", "attack_assist.substitute.word.get_default_substitute", "text_process.tokenizer.get_default_tokenizer", "attack_assist.filter_words.get_default_filter_words", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words"], ["\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pwws.__init__.PWWSAttacker.attack": [[70, 98], ["sentence.lower", "__init__.PWWSAttacker.tokenizer.tokenize", "list", "list", "__init__.PWWSAttacker.get_saliency", "numpy.exp", "sorted", "list.copy", "range", "map", "map", "numpy.exp.sum", "__init__.PWWSAttacker.get_wstar", "len", "__init__.PWWSAttacker.tokenizer.detokenize", "goal.check", "__init__.PWWSAttacker.max", "range", "range", "victim.get_pred", "len", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pwws.__init__.PWWSAttacker.get_saliency", "home.repos.pwc.inspect_result.thunlp_OpenAttack.pwws.__init__.PWWSAttacker.get_wstar", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pwws.__init__.PWWSAttacker.get_saliency": [[101, 115], ["range", "x_hat_raw.append", "len", "x_hat_raw.append", "__init__.PWWSAttacker.tokenizer.detokenize", "clsf.get_prob", "__init__.PWWSAttacker.tokenizer.detokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.pwws.__init__.PWWSAttacker.get_wstar": [[116, 137], ["list", "sents.append", "list", "filter", "len", "sents.append", "__init__.PWWSAttacker.tokenizer.detokenize", "clsf.get_prob", "map", "__init__.PWWSAttacker.tokenizer.detokenize", "__init__.PWWSAttacker.substitute", "res.max", "res.min", "res.argmax", "res.argmin"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.GANAttacker.TAGS": [[22, 25], ["tags.Tag"], "methods", ["None"], ["from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.GANAttacker.__init__": [[26, 63], ["__init__.GANAttacker.gan_gen.cpu", "__init__.GANAttacker.inverter.cpu", "__init__.GANAttacker.autoencoder.eval", "__init__.GANAttacker.autoencoder.cpu", "data_manager.DataManager.load", "data_manager.DataManager.load", "ValueError", "__init__.GANAttacker.word2idx.items"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load"], ["from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.GANAttacker.attack": [[65, 72], ["__init__.GANAttacker.snli_call", "__init__.GANAttacker.sst_call", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.GANAttacker.snli_call", "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.GANAttacker.sst_call"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.GANAttacker.snli_call": [[73, 137], ["hypothesis_orig.strip().lower.strip().lower.strip().split", "min", "__init__.GANAttacker.autoencoder.encode", "__init__.GANAttacker.inverter().data.cpu", "torch.LongTensor", "hypothesis.unsqueeze.unsqueeze.unsqueeze", "hypothesis_orig.strip().lower.strip().lower.strip().lower", "len", "len", "torch.LongTensor", "torch.LongTensor", "__init__.GANAttacker.repeat", "torch.FloatTensor().uniform_", "numpy.array", "__init__.GANAttacker.gan_gen", "range", "range", "hypothesis_orig.strip().lower.strip().lower.strip", "adv_prob.append", "sentences.append", "goal.check", "len", "__init__.get_min", "hypothesis_orig.strip().lower.strip().lower.strip", "len", "len", "__init__.GANAttacker.inverter", "torch.FloatTensor", "numpy.sqrt", "__init__.GANAttacker.autoencoder.generate().data.cpu().numpy", "int", "index_adv.append", "__init__.GANAttacker.repeat.size", "numpy.sum", "torch.FloatTensor().uniform_.cpu().numpy", "clsf.get_pred", "clsf.get_pred", "__init__.GANAttacker.autoencoder.generate().data.cpu", "words.index", "torch.FloatTensor().uniform_.cpu", "__init__.GANAttacker.autoencoder.generate"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.encode", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.get_min", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.GANAttacker.sst_call": [[138, 187], ["hypothesis_orig.strip().lower.strip().lower.strip().split", "min", "__init__.GANAttacker.autoencoder", "torch.max", "max_indices.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu().numpy", "hypothesis_orig.strip().lower.strip().lower.strip().lower", "len", "len", "len", "torch.LongTensor", "torch.LongTensor", "range", "target.check", "hypothesis_orig.strip().lower.strip().lower.strip", "len", "max_indices.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu", "len", "clsf.get_pred", "hypothesis_orig.strip().lower.strip().lower.strip", "len", "len", "words.index", "words.index", "max_indices.view().data.cpu().numpy.view().data.cpu().numpy.view", "__init__.GANAttacker.size"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.gan.__init__.get_min": [[9, 14], ["copy.deepcopy", "numpy.argmin"], "function", ["None"], ["from", ".", "import", "victim", "\n", "from", ".", "victim", "import", "classifiers", "\n", "from", ".", "victim", "import", "Victim", "\n", "from", ".", "victim", ".", "classifiers", "import", "Classifier", "\n", "\n", "# metrics", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.TAGS": [[11, 14], ["tags.Tag"], "methods", ["None"], ["from", ".", "victim", "import", "Victim", "\n", "from", ".", "victim", ".", "classifiers", "import", "Classifier", "\n", "\n", "# metrics", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.__init__": [[15, 53], ["utils.check_language", "lst.append", "len", "utils.get_language", "utils.language_by_name", "text_process.tokenizer.get_default_tokenizer", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer"], ["from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.set_triggers": [[54, 58], ["__init__.UATAttacker.get_triggers"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.get_triggers"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.attack": [[59, 65], ["__init__.UATAttacker.tokenizer.detokenize", "goal.check", "victim.get_pred", "__init__.UATAttacker.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.get_triggers": [[67, 149], ["victim.get_embedding", "range", "tags.Tag", "tags.Tag", "tags.Tag", "tags.Tag", "utils.language_by_name", "text_process.tokenizer.get_default_tokenizer", "[].tolist", "tqdm.tqdm.tqdm", "AttributeError", "ValueError", "word2id.items", "range", "range", "range", "text_process.tokenizer.get_default_tokenizer.tokenize", "list", "__init__.UATAttacker.get_triggers.get_candidates"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_embedding", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.viper.__init__.VIPERAttacker.TAGS": [[21, 24], ["tags.Tag"], "methods", ["None"], ["# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.viper.__init__.VIPERAttacker.__init__": [[25, 61], ["utils.get_language", "attack_assist.substitute.char.DCESSubstitute", "attack_assist.substitute.char.ECESSubstitute", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language"], ["from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.viper.__init__.VIPERAttacker.attack": [[64, 99], ["range", "goal.check", "victim.get_pred", "random.random", "out.append", "random.random", "out.append", "__init__.VIPERAttacker.substitute", "similar_chars.append", "probs.append", "numpy.sum", "len", "numpy.random.choice", "__init__.VIPERAttacker.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.TAGS": [[14, 17], ["tags.Tag", "tags.Tag"], "methods", ["None"], ["# metrics", "\n", "from", ".", "import", "metric", "\n", "from", ".", "metric", "import", "AttackMetric", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.__init__": [[18, 81], ["metric.UniversalSentenceEncoder", "utils.check_language", "set", "lst.append", "lst.append", "len", "utils.get_language", "utils.language_by_name", "attack_assist.substitute.word.get_default_substitute", "text_process.tokenizer.get_default_tokenizer", "attack_assist.filter_words.get_default_filter_words", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words"], ["# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.attack": [[82, 175], ["sentence.lower", "orig_probs.argmax", "orig_probs.max", "__init__.TextFoolerAttacker.tokenizer.tokenize", "list", "list", "len", "victim.get_prob", "numpy.argmax", "sorted", "victim.get_prob", "map", "map", "enumerate", "synonym_words.pop", "victim.get_prob", "numpy.array", "numpy.array", "range", "__init__.TextFoolerAttacker.tokenizer.detokenize", "words_perturb.append", "__init__.TextFoolerAttacker.get_neighbours", "synonyms_all.append", "__init__.TextFoolerAttacker.tokenizer.detokenize", "numpy.argmax", "__init__.TextFoolerAttacker.pos_filter", "numpy.sum", "__init__.TextFoolerAttacker.tokenizer.detokenize", "goal.check", "numpy.min", "numpy.argmin", "numpy.max", "__init__.TextFoolerAttacker.tokenizer.detokenize", "__init__.TextFoolerAttacker.sim_predictor.calc_score", "victim.get_pred", "min", "__init__.TextFoolerAttacker.tokenizer.detokenize", "len", "list", "list", "map", "min", "map", "__init__.TextFoolerAttacker.tokenizer.tokenize", "__init__.TextFoolerAttacker.tokenizer.tokenize", "__init__.TextFoolerAttacker.tokenizer.detokenize", "__init__.TextFoolerAttacker.tokenizer.detokenize", "max"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_prob", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.get_neighbours", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.pos_filter", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.algorithms.sentence_sim.SentenceSim.calc_score", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.get_neighbours": [[177, 190], ["list", "filter", "map", "__init__.TextFoolerAttacker.substitute"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.textfooler.__init__.TextFoolerAttacker.pos_filter": [[192, 196], ["set", "set"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.__init__": [[8, 29], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_nt", ",", "d_hid", ",", "len_voc", ")", ":", "\n", "        ", "super", "(", "ParseNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d_nt", "=", "d_nt", "\n", "self", ".", "d_hid", "=", "d_hid", "\n", "self", ".", "len_voc", "=", "len_voc", "\n", "\n", "self", ".", "trans_embs", "=", "nn", ".", "Embedding", "(", "len_voc", ",", "d_nt", ")", "\n", "\n", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "d_nt", ",", "d_hid", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "LSTM", "(", "d_nt", "+", "d_hid", ",", "d_hid", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "out_dense_1", "=", "nn", ".", "Linear", "(", "d_hid", "*", "2", ",", "d_hid", ")", "\n", "self", ".", "out_dense_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "len_voc", ")", "\n", "self", ".", "out_nonlin", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n", "self", ".", "att_W", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "d_hid", ")", ")", "\n", "self", ".", "att_parse_W", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "d_hid", ")", ")", "\n", "\n", "self", ".", "copy_hid_v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "1", ")", ")", "\n", "self", ".", "copy_att_v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "1", ")", ")", "\n", "self", ".", "copy_inp_v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_nt", "+", "d_hid", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.compute_mask": [[30, 37], ["torch.max", "torch.max", "torch.max", "torch.max", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "lengths.unsqueeze().expand_as", "lengths.size", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "lengths.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "compute_mask", "(", "self", ",", "lengths", ")", ":", "\n", "        ", "device", "=", "lengths", ".", "device", "\n", "max_len", "=", "torch", ".", "max", "(", "lengths", ")", "\n", "range_row", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "device", "=", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "lengths", ".", "size", "(", "0", ")", ",", "max_len", ")", "\n", "mask", "=", "lengths", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "range_row", ")", "\n", "mask", "=", "(", "range_row", "<", "mask", ")", ".", "float", "(", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.masked_softmax": [[38, 43], ["torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax.sum"], "methods", ["None"], ["", "def", "masked_softmax", "(", "self", ",", "vector", ",", "mask", ")", ":", "\n", "        ", "result", "=", "nn", ".", "functional", ".", "softmax", "(", "vector", ",", "dim", "=", "1", ")", "\n", "result", "=", "result", "*", "mask", "\n", "result", "=", "result", "/", "(", "result", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-13", ")", "# avoid dividing zero", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.compute_decoder_attention": [[45, 52], ["models.ParseNet.compute_mask", "hid_previous[].mm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "models.ParseNet.masked_softmax", "hid_previous[].mm.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_mask", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.masked_softmax"], ["", "def", "compute_decoder_attention", "(", "self", ",", "hid_previous", ",", "enc_hids", ",", "in_lens", ")", ":", "\n", "        ", "mask", "=", "self", ".", "compute_mask", "(", "in_lens", ")", "\n", "b_hn", "=", "hid_previous", "[", "0", "]", ".", "mm", "(", "self", ".", "att_W", ")", "\n", "scores", "=", "b_hn", ".", "unsqueeze", "(", "1", ")", "*", "enc_hids", "\n", "scores", "=", "torch", ".", "sum", "(", "scores", ",", "dim", "=", "2", ")", "\n", "scores", "=", "self", ".", "masked_softmax", "(", "scores", ",", "mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.compute_transformation_attention": [[54, 61], ["models.ParseNet.compute_mask", "hid_previous[].mm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "models.ParseNet.masked_softmax", "hid_previous[].mm.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_mask", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.masked_softmax"], ["", "def", "compute_transformation_attention", "(", "self", ",", "hid_previous", ",", "trans_embs", ",", "trans_lens", ")", ":", "\n", "        ", "mask", "=", "self", ".", "compute_mask", "(", "trans_lens", ")", "\n", "b_hn", "=", "hid_previous", "[", "0", "]", ".", "mm", "(", "self", ".", "att_parse_W", ")", "\n", "scores", "=", "b_hn", ".", "unsqueeze", "(", "1", ")", "*", "trans_embs", "\n", "scores", "=", "torch", ".", "sum", "(", "scores", ",", "dim", "=", "2", ")", "\n", "scores", "=", "self", ".", "masked_softmax", "(", "scores", ",", "mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.encode_batch": [[63, 76], ["inputs.size", "models.ParseNet.trans_embs", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "models.ParseNet.encoder", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lens.tolist", "enc_last_hid.squeeze"], "methods", ["None"], ["", "def", "encode_batch", "(", "self", ",", "inputs", ",", "lengths", ")", ":", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "bsz", ",", "max_len", "=", "inputs", ".", "size", "(", ")", "\n", "in_embs", "=", "self", ".", "trans_embs", "(", "inputs", ")", "\n", "lens", ",", "indices", "=", "torch", ".", "sort", "(", "lengths", ",", "0", ",", "True", ")", "\n", "\n", "e_hid_init", "=", "torch", ".", "zeros", "(", "1", ",", "bsz", ",", "self", ".", "d_hid", ",", "device", "=", "device", ")", "\n", "e_cell_init", "=", "torch", ".", "zeros", "(", "1", ",", "bsz", ",", "self", ".", "d_hid", ",", "device", "=", "device", ")", "\n", "all_hids", ",", "(", "enc_last_hid", ",", "_", ")", "=", "self", ".", "encoder", "(", "pack", "(", "in_embs", "[", "indices", "]", ",", "lens", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", ",", "(", "e_hid_init", ",", "e_cell_init", ")", ")", "\n", "_", ",", "_indices", "=", "torch", ".", "sort", "(", "indices", ",", "0", ")", "\n", "all_hids", "=", "unpack", "(", "all_hids", ",", "batch_first", "=", "True", ")", "[", "0", "]", "\n", "\n", "return", "all_hids", "[", "_indices", "]", ",", "enc_last_hid", ".", "squeeze", "(", "0", ")", "[", "_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.decode_step": [[78, 107], ["models.ParseNet.compute_transformation_attention", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.ParseNet.decoder", "models.ParseNet.compute_decoder_attention", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat.squeeze().mm", "torch.cat.squeeze().mm", "torch.sum.mm", "torch.sum.mm", "hn.squeeze().mm", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "models.ParseNet.trans_embs.parameters().__next__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "models.ParseNet.trans_embs", "word_input.view.view.view", "models.ParseNet.unsqueeze", "torch.sum.unsqueeze", "torch.sum.unsqueeze", "models.ParseNet.unsqueeze", "torch.cat.squeeze", "torch.cat.squeeze", "hn.squeeze", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "models.ParseNet.trans_embs.parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_transformation_attention", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_decoder_attention"], ["", "def", "decode_step", "(", "self", ",", "idx", ",", "prev_words", ",", "prev_hid", ",", "prev_cell", ",", "\n", "enc_hids", ",", "trans_embs", ",", "in_sent_lens", ",", "trans_lens", ",", "bsz", ",", "max_len", ")", ":", "\n", "        ", "device", "=", "self", ".", "trans_embs", ".", "parameters", "(", ")", ".", "__next__", "(", ")", ".", "device", "\n", "# initialize with zeros", "\n", "if", "idx", "==", "0", ":", "\n", "            ", "word_input", "=", "torch", ".", "zeros", "(", "bsz", ",", "1", ",", "self", ".", "d_nt", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "            ", "word_input", "=", "self", ".", "trans_embs", "(", "prev_words", ")", "\n", "word_input", "=", "word_input", ".", "view", "(", "bsz", ",", "1", ",", "self", ".", "d_nt", ")", "\n", "\n", "# concatenate w/ transformation embeddings", "\n", "", "trans_weights", "=", "self", ".", "compute_transformation_attention", "(", "prev_hid", ",", "trans_embs", ",", "trans_lens", ")", "\n", "trans_ctx", "=", "torch", ".", "sum", "(", "trans_weights", ".", "unsqueeze", "(", "2", ")", "*", "trans_embs", ",", "dim", "=", "1", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "[", "word_input", ",", "trans_ctx", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "\n", "# feed to decoder lstm", "\n", "_", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "decoder", "(", "decoder_input", ",", "(", "prev_hid", ",", "prev_cell", ")", ")", "\n", "\n", "# compute attention for next time step and att weighted ave of encoder hiddens", "\n", "attn_weights", "=", "self", ".", "compute_decoder_attention", "(", "hn", ",", "enc_hids", ",", "in_sent_lens", ")", "\n", "attn_ctx", "=", "torch", ".", "sum", "(", "attn_weights", ".", "unsqueeze", "(", "2", ")", "*", "enc_hids", ",", "dim", "=", "1", ")", "\n", "\n", "# compute copy prob as function of lotsa shit", "\n", "p_copy", "=", "decoder_input", ".", "squeeze", "(", "1", ")", ".", "mm", "(", "self", ".", "copy_inp_v", ")", "\n", "p_copy", "+=", "attn_ctx", ".", "mm", "(", "self", ".", "copy_att_v", ")", "\n", "p_copy", "+=", "hn", ".", "squeeze", "(", "0", ")", ".", "mm", "(", "self", ".", "copy_hid_v", ")", "\n", "p_copy", "=", "torch", ".", "sigmoid", "(", "p_copy", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "hn", ",", "cn", ",", "attn_weights", ",", "attn_ctx", ",", "p_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.forward": [[108, 110], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.ParseNet.batch_beam_search": [[112, 239], ["inputs.size", "models.ParseNet.encode_batch", "models.ParseNet.encode_batch", "enc_last_hid.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "trim_hids.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "enc_hids.size", "enc_hids.expand", "in_trans_lens.expand", "inputs.expand", "models.ParseNet.decode_step", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.log().squeeze.scatter_add_", "torch.log().squeeze.scatter_add_", "torch.log().squeeze", "torch.log().squeeze", "torch.log().squeeze", "torch.log().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.ParseNet.out_dense_1", "models.ParseNet.out_dense_2", "models.ParseNet.out_nonlin().squeeze", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "trim_hids.size", "trim_hids.size", "trim_hids.unsqueeze().expand().contiguous().view", "out_trimmed_lens.unsqueeze().expand().contiguous().view", "prev_hs.append", "prev_cs.append", "torch.log", "torch.log", "torch.log", "torch.log", "enc_last_hid.unsqueeze.squeeze", "models.ParseNet.out_nonlin", "p_copy.unsqueeze", "len", "hn[].unsqueeze", "cn[].unsqueeze", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "range", "enumerate", "len", "torch.LongTensor().to.append", "torch.LongTensor().to.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "trim_hids.unsqueeze().expand().contiguous", "out_trimmed_lens.unsqueeze().expand().contiguous", "p_copy.unsqueeze", "top_indices[].item", "beam_candidates.append", "ex_hn[].unsqueeze", "ex_cn[].unsqueeze", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "range", "numpy.argsort", "beam_candidates.append", "top_indices[].item", "beam_candidates.append", "trim_hids.unsqueeze().expand", "out_trimmed_lens.unsqueeze().expand", "preds[].item", "trim_hids.unsqueeze", "out_trimmed_lens.unsqueeze", "float", "preds[].cpu().item", "preds[].cpu"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.encode_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.encode_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.decode_step", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to"], ["", "def", "batch_beam_search", "(", "self", ",", "inputs", ",", "out_trimmed", ",", "in_trans_lens", ",", "\n", "out_trimmed_lens", ",", "eos_idx", ",", "beam_size", "=", "5", ",", "max_steps", "=", "250", ")", ":", "\n", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "bsz", ",", "max_len", "=", "inputs", ".", "size", "(", ")", "\n", "\n", "# chop input", "\n", "inputs", "=", "inputs", "[", ":", ",", ":", "in_trans_lens", "[", "0", "]", "]", "\n", "\n", "# encode inputs and trimmed outputs", "\n", "enc_hids", ",", "enc_last_hid", "=", "self", ".", "encode_batch", "(", "inputs", ",", "in_trans_lens", ")", "\n", "trim_hids", ",", "trim_last_hid", "=", "self", ".", "encode_batch", "(", "out_trimmed", ",", "out_trimmed_lens", ")", "\n", "\n", "# initialize decoder hidden to last encoder hidden", "\n", "hn", "=", "enc_last_hid", ".", "unsqueeze", "(", "0", ")", "\n", "cn", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "self", ".", "d_hid", ",", "device", "=", "device", ")", "\n", "\n", "# initialize beams (dictionary of batch_idx: beam params)", "\n", "beam_dict", "=", "{", "}", "\n", "for", "b_idx", "in", "range", "(", "trim_hids", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "beam_dict", "[", "b_idx", "]", "=", "[", "(", "0.0", ",", "hn", ",", "cn", ",", "[", "]", ")", "]", "\n", "", "nsteps", "=", "0", "\n", "\n", "# loop til max_decode, do lstm tick using previous prediction", "\n", "while", "True", ":", "\n", "# set up accumulators for predictions", "\n", "# assumption: all examples have same number of beams at each timestep", "\n", "            ", "prev_words", "=", "[", "]", "\n", "prev_hs", "=", "[", "]", "\n", "prev_cs", "=", "[", "]", "\n", "\n", "for", "b_idx", "in", "beam_dict", ":", "\n", "                ", "beams", "=", "beam_dict", "[", "b_idx", "]", "\n", "# loop over everything in the beam", "\n", "beam_candidates", "=", "[", "]", "\n", "for", "b", "in", "beams", ":", "\n", "                    ", "curr_prob", ",", "prev_h", ",", "prev_c", ",", "seq", "=", "b", "\n", "# start with last word in sequence, if eos end the beam", "\n", "if", "len", "(", "seq", ")", ">", "0", ":", "\n", "                        ", "prev_words", ".", "append", "(", "seq", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "prev_words", "=", "None", "\n", "", "prev_hs", ".", "append", "(", "prev_h", ")", "\n", "prev_cs", ".", "append", "(", "prev_c", ")", "\n", "\n", "\n", "# now batch decoder computations", "\n", "", "", "hs", "=", "torch", ".", "cat", "(", "prev_hs", ",", "dim", "=", "1", ")", "\n", "cs", "=", "torch", ".", "cat", "(", "prev_cs", ",", "dim", "=", "1", ")", "\n", "num_examples", "=", "hs", ".", "size", "(", "1", ")", "\n", "if", "prev_words", "is", "not", "None", ":", "\n", "                ", "prev_words", "=", "torch", ".", "LongTensor", "(", "prev_words", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "if", "num_examples", "!=", "trim_hids", ".", "size", "(", "0", ")", ":", "\n", "                ", "d1", ",", "d2", ",", "d3", "=", "trim_hids", ".", "size", "(", ")", "\n", "rep_factor", "=", "num_examples", "//", "d1", "\n", "curr_out", "=", "trim_hids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "d1", ",", "rep_factor", ",", "d2", ",", "d3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "d2", ",", "d3", ")", "\n", "curr_out_lens", "=", "out_trimmed_lens", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "d1", ",", "rep_factor", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "curr_out", "=", "trim_hids", "\n", "curr_out_lens", "=", "out_trimmed_lens", "\n", "\n", "# expand out inputs and encoder hiddens", "\n", "", "_", ",", "in_len", ",", "hid_d", "=", "enc_hids", ".", "size", "(", ")", "\n", "curr_enc_hids", "=", "enc_hids", ".", "expand", "(", "num_examples", ",", "in_len", ",", "hid_d", ")", "\n", "curr_enc_lens", "=", "in_trans_lens", ".", "expand", "(", "num_examples", ")", "\n", "curr_inputs", "=", "inputs", ".", "expand", "(", "num_examples", ",", "in_trans_lens", "[", "0", "]", ")", "\n", "\n", "# concat prev word emb and prev attn input and feed to decoder lstm", "\n", "hn", ",", "cn", ",", "attn_weights", ",", "attn_ctx", ",", "p_copy", "=", "self", ".", "decode_step", "(", "nsteps", ",", "prev_words", ",", "hs", ",", "cs", ",", "curr_enc_hids", ",", "curr_out", ",", "curr_enc_lens", ",", "curr_out_lens", ",", "num_examples", ",", "max_len", ")", "\n", "\n", "# compute copy attn by scattering attn into vocab space", "\n", "vocab_scores", "=", "torch", ".", "zeros", "(", "num_examples", ",", "self", ".", "len_voc", ",", "device", "=", "device", ")", "\n", "vocab_scores", "=", "vocab_scores", ".", "scatter_add_", "(", "1", ",", "curr_inputs", ",", "attn_weights", ")", "\n", "vocab_scores", "=", "torch", ".", "log", "(", "vocab_scores", "+", "1e-20", ")", ".", "squeeze", "(", ")", "\n", "\n", "# compute prediction over vocab for a single time step", "\n", "pred_inp", "=", "torch", ".", "cat", "(", "[", "hn", ".", "squeeze", "(", "0", ")", ",", "attn_ctx", "]", ",", "dim", "=", "1", ")", "\n", "preds", "=", "self", ".", "out_dense_1", "(", "pred_inp", ")", "\n", "preds", "=", "self", ".", "out_dense_2", "(", "preds", ")", "\n", "preds", "=", "self", ".", "out_nonlin", "(", "preds", ")", ".", "squeeze", "(", ")", "\n", "final_preds", "=", "p_copy", ".", "unsqueeze", "(", "1", ")", "*", "vocab_scores", "+", "(", "1", "-", "p_copy", ".", "unsqueeze", "(", "1", ")", ")", "*", "preds", "\n", "\n", "# now loop over the examples and sort each separately", "\n", "for", "b_idx", "in", "beam_dict", ":", "\n", "                ", "beam_candidates", "=", "[", "]", "\n", "# no words previously predicted", "\n", "if", "num_examples", "==", "len", "(", "beam_dict", ")", ":", "\n", "                    ", "ex_hn", "=", "hn", "[", ":", ",", "b_idx", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "ex_cn", "=", "cn", "[", ":", ",", "b_idx", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "preds", "=", "final_preds", "[", "b_idx", "]", "\n", "_", ",", "top_indices", "=", "torch", ".", "sort", "(", "-", "preds", ")", "\n", "# add top n candidates", "\n", "for", "z", "in", "range", "(", "beam_size", ")", ":", "\n", "                        ", "word_idx", "=", "top_indices", "[", "z", "]", ".", "item", "(", ")", "\n", "beam_candidates", ".", "append", "(", "(", "preds", "[", "word_idx", "]", ".", "item", "(", ")", ",", "ex_hn", ",", "ex_cn", ",", "[", "word_idx", "]", ")", ")", "\n", "", "beam_dict", "[", "b_idx", "]", "=", "beam_candidates", "\n", "", "else", ":", "\n", "                    ", "origin_beams", "=", "beam_dict", "[", "b_idx", "]", "\n", "start", "=", "b_idx", "*", "beam_size", "\n", "end", "=", "(", "b_idx", "+", "1", ")", "*", "beam_size", "\n", "ex_hn", "=", "hn", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "ex_cn", "=", "cn", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "ex_preds", "=", "final_preds", "[", "start", ":", "end", "]", "\n", "\n", "for", "o_idx", ",", "ob", "in", "enumerate", "(", "origin_beams", ")", ":", "\n", "                        ", "curr_prob", ",", "_", ",", "_", ",", "seq", "=", "ob", "\n", "# if one of the beams is already complete, add it to candidates", "\n", "# note: this is inefficient, but whatever", "\n", "if", "seq", "[", "-", "1", "]", "==", "eos_idx", ":", "\n", "                            ", "beam_candidates", ".", "append", "(", "ob", ")", "\n", "\n", "", "preds", "=", "ex_preds", "[", "o_idx", "]", "\n", "curr_hn", "=", "ex_hn", "[", ":", ",", "o_idx", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "curr_cn", "=", "ex_cn", "[", ":", ",", "o_idx", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "_", ",", "top_indices", "=", "torch", ".", "sort", "(", "-", "preds", ")", "\n", "for", "z", "in", "range", "(", "beam_size", ")", ":", "\n", "                            ", "word_idx", "=", "top_indices", "[", "z", "]", ".", "item", "(", ")", "\n", "beam_candidates", ".", "append", "(", "(", "curr_prob", "+", "float", "(", "preds", "[", "word_idx", "]", ".", "cpu", "(", ")", ".", "item", "(", ")", ")", ",", "curr_hn", ",", "curr_cn", ",", "seq", "+", "[", "word_idx", "]", ")", ")", "\n", "\n", "", "", "s_inds", "=", "np", ".", "argsort", "(", "[", "x", "[", "0", "]", "for", "x", "in", "beam_candidates", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "beam_candidates", "=", "[", "beam_candidates", "[", "x", "]", "for", "x", "in", "s_inds", "]", "\n", "beam_dict", "[", "b_idx", "]", "=", "beam_candidates", "[", ":", "beam_size", "]", "\n", "", "", "nsteps", "+=", "1", "\n", "if", "nsteps", ">", "max_steps", ":", "\n", "                ", "break", "\n", "", "", "return", "beam_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.__init__": [[242, 281], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.LogSoftmax", "torch.LogSoftmax", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_word", ",", "d_hid", ",", "d_nt", ",", "d_trans", ",", "\n", "len_voc", ",", "len_trans_voc", ",", "use_input_parse", ")", ":", "\n", "        ", "super", "(", "SCPN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d_word", "=", "d_word", "\n", "self", ".", "d_hid", "=", "d_hid", "\n", "self", ".", "d_trans", "=", "d_trans", "\n", "self", ".", "d_nt", "=", "d_nt", "+", "1", "\n", "self", ".", "len_voc", "=", "len_voc", "\n", "self", ".", "len_trans_voc", "=", "len_trans_voc", "\n", "self", ".", "use_input_parse", "=", "use_input_parse", "\n", "\n", "# embeddings", "\n", "self", ".", "word_embs", "=", "nn", ".", "Embedding", "(", "len_voc", ",", "d_word", ")", "\n", "self", ".", "trans_embs", "=", "nn", ".", "Embedding", "(", "len_trans_voc", ",", "d_nt", ")", "\n", "\n", "# lstms", "\n", "if", "use_input_parse", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "d_word", "+", "d_trans", ",", "d_hid", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "d_word", ",", "d_hid", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "\n", "", "self", ".", "encoder_proj", "=", "nn", ".", "Linear", "(", "d_hid", "*", "2", ",", "d_hid", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "LSTM", "(", "d_word", "+", "d_hid", ",", "d_hid", ",", "num_layers", "=", "2", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "trans_encoder", "=", "nn", ".", "LSTM", "(", "d_nt", ",", "d_trans", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "\n", "# output softmax", "\n", "self", ".", "out_dense_1", "=", "nn", ".", "Linear", "(", "d_hid", "*", "2", ",", "d_hid", ")", "\n", "self", ".", "out_dense_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "len_voc", ")", "\n", "self", ".", "att_nonlin", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "out_nonlin", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n", "# attention params", "\n", "self", ".", "att_parse_proj", "=", "nn", ".", "Linear", "(", "d_trans", ",", "d_hid", ")", "\n", "self", ".", "att_W", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "d_hid", ")", ")", "\n", "self", ".", "att_parse_W", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "d_hid", ")", ")", "\n", "\n", "self", ".", "copy_hid_v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "1", ")", ")", "\n", "self", ".", "copy_att_v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_hid", ",", "1", ")", ")", "\n", "self", ".", "copy_inp_v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_word", "+", "d_hid", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_mask": [[283, 290], ["torch.max", "torch.max", "torch.max", "torch.max", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "lengths.unsqueeze().expand_as", "lengths.size", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "lengths.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "compute_mask", "(", "self", ",", "lengths", ")", ":", "\n", "        ", "device", "=", "lengths", ".", "device", "\n", "max_len", "=", "torch", ".", "max", "(", "lengths", ")", "\n", "range_row", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "device", "=", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "lengths", ".", "size", "(", "0", ")", ",", "max_len", ")", "\n", "mask", "=", "lengths", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "range_row", ")", "\n", "mask", "=", "(", "range_row", "<", "mask", ")", ".", "float", "(", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.masked_softmax": [[292, 297], ["torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.sum", "torch.nn.functional.softmax.sum"], "methods", ["None"], ["", "def", "masked_softmax", "(", "self", ",", "vector", ",", "mask", ")", ":", "\n", "        ", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", ",", "dim", "=", "1", ")", "\n", "result", "=", "result", "*", "mask", "\n", "result", "=", "result", "/", "(", "result", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-13", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_decoder_attention": [[299, 306], ["models.SCPN.compute_mask", "hid_previous.mm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "models.SCPN.masked_softmax", "hid_previous.mm.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_mask", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.masked_softmax"], ["", "def", "compute_decoder_attention", "(", "self", ",", "hid_previous", ",", "enc_hids", ",", "in_lens", ")", ":", "\n", "        ", "mask", "=", "self", ".", "compute_mask", "(", "in_lens", ")", "\n", "b_hn", "=", "hid_previous", ".", "mm", "(", "self", ".", "att_W", ")", "\n", "scores", "=", "b_hn", ".", "unsqueeze", "(", "1", ")", "*", "enc_hids", "\n", "scores", "=", "torch", ".", "sum", "(", "scores", ",", "dim", "=", "2", ")", "\n", "scores", "=", "self", ".", "masked_softmax", "(", "scores", ",", "mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_transformation_attention": [[308, 315], ["models.SCPN.compute_mask", "hid_previous.mm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "models.SCPN.masked_softmax", "hid_previous.mm.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_mask", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.masked_softmax"], ["", "def", "compute_transformation_attention", "(", "self", ",", "hid_previous", ",", "trans_embs", ",", "trans_lens", ")", ":", "\n", "        ", "mask", "=", "self", ".", "compute_mask", "(", "trans_lens", ")", "\n", "b_hn", "=", "hid_previous", ".", "mm", "(", "self", ".", "att_parse_W", ")", "\n", "scores", "=", "b_hn", ".", "unsqueeze", "(", "1", ")", "*", "trans_embs", "\n", "scores", "=", "torch", ".", "sum", "(", "scores", ",", "dim", "=", "2", ")", "\n", "scores", "=", "self", ".", "masked_softmax", "(", "scores", ",", "mask", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.encode_batch": [[317, 338], ["inputs.size", "models.SCPN.word_embs", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "models.SCPN.encoder", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "models.SCPN.encoder_proj().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "models.SCPN.encoder_proj", "lens.tolist", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "models.SCPN.encoder_proj", "trans.unsqueeze().expand", "models.SCPN.view", "trans.unsqueeze"], "methods", ["None"], ["", "def", "encode_batch", "(", "self", ",", "inputs", ",", "trans", ",", "lengths", ")", ":", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "bsz", ",", "max_len", "=", "inputs", ".", "size", "(", ")", "\n", "in_embs", "=", "self", ".", "word_embs", "(", "inputs", ")", "\n", "lens", ",", "indices", "=", "torch", ".", "sort", "(", "lengths", ",", "0", ",", "True", ")", "\n", "\n", "# concat word embs with trans hid", "\n", "if", "self", ".", "use_input_parse", ":", "\n", "            ", "in_embs", "=", "torch", ".", "cat", "(", "[", "in_embs", ",", "trans", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "bsz", ",", "max_len", ",", "self", ".", "d_trans", ")", "]", ",", "dim", "=", "2", ")", "\n", "\n", "", "e_hid_init", "=", "torch", ".", "zeros", "(", "2", ",", "bsz", ",", "self", ".", "d_hid", ",", "device", "=", "device", ")", "\n", "e_cell_init", "=", "torch", ".", "zeros", "(", "2", ",", "bsz", ",", "self", ".", "d_hid", ",", "device", "=", "device", ")", "\n", "all_hids", ",", "(", "enc_last_hid", ",", "_", ")", "=", "self", ".", "encoder", "(", "pack", "(", "in_embs", "[", "indices", "]", ",", "lens", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", ",", "(", "e_hid_init", ",", "e_cell_init", ")", ")", "\n", "_", ",", "_indices", "=", "torch", ".", "sort", "(", "indices", ",", "0", ")", "\n", "all_hids", "=", "unpack", "(", "all_hids", ",", "batch_first", "=", "True", ")", "[", "0", "]", "[", "_indices", "]", "\n", "all_hids", "=", "self", ".", "encoder_proj", "(", "all_hids", ".", "view", "(", "-", "1", ",", "self", ".", "d_hid", "*", "2", ")", ")", ".", "view", "(", "bsz", ",", "max_len", ",", "self", ".", "d_hid", ")", "\n", "\n", "enc_last_hid", "=", "torch", ".", "cat", "(", "[", "enc_last_hid", "[", "0", "]", ",", "enc_last_hid", "[", "1", "]", "]", ",", "dim", "=", "1", ")", "\n", "enc_last_hid", "=", "self", ".", "encoder_proj", "(", "enc_last_hid", ")", "[", "_indices", "]", "\n", "\n", "return", "all_hids", ",", "enc_last_hid", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.encode_transformations": [[340, 356], ["trans.size", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "models.SCPN.trans_embs", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "models.SCPN.trans_encoder", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "lens.tolist", "enc_last_hid.squeeze", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence"], "methods", ["None"], ["", "def", "encode_transformations", "(", "self", ",", "trans", ",", "lengths", ",", "return_last", "=", "True", ")", ":", "\n", "        ", "device", "=", "trans", ".", "device", "\n", "bsz", ",", "_", "=", "trans", ".", "size", "(", ")", "\n", "\n", "lens", ",", "indices", "=", "torch", ".", "sort", "(", "lengths", ",", "0", ",", "True", ")", "\n", "in_embs", "=", "self", ".", "trans_embs", "(", "trans", ")", "\n", "t_hid_init", "=", "torch", ".", "zeros", "(", "1", ",", "bsz", ",", "self", ".", "d_trans", ",", "device", "=", "device", ")", "\n", "t_cell_init", "=", "torch", ".", "zeros", "(", "1", ",", "bsz", ",", "self", ".", "d_trans", ",", "device", "=", "device", ")", "\n", "all_hids", ",", "(", "enc_last_hid", ",", "_", ")", "=", "self", ".", "trans_encoder", "(", "pack", "(", "in_embs", "[", "indices", "]", ",", "lens", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", ",", "(", "t_hid_init", ",", "t_cell_init", ")", ")", "\n", "_", ",", "_indices", "=", "torch", ".", "sort", "(", "indices", ",", "0", ")", "\n", "\n", "if", "return_last", ":", "\n", "            ", "return", "enc_last_hid", ".", "squeeze", "(", "0", ")", "[", "_indices", "]", "\n", "", "else", ":", "\n", "            ", "all_hids", "=", "unpack", "(", "all_hids", ",", "batch_first", "=", "True", ")", "[", "0", "]", "\n", "return", "all_hids", "[", "_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.decode_step": [[358, 388], ["models.SCPN.compute_transformation_attention", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.SCPN.decoder", "models.SCPN.compute_decoder_attention", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat.squeeze().mm", "torch.cat.squeeze().mm", "torch.sum.mm", "torch.sum.mm", "hn[].mm", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "torch.sigmoid().squeeze", "models.SCPN.word_embs.parameters().__next__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "models.SCPN.word_embs", "word_input.view.view.view", "models.SCPN.unsqueeze", "torch.sum.unsqueeze", "torch.sum.unsqueeze", "models.SCPN.unsqueeze", "torch.cat.squeeze", "torch.cat.squeeze", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "models.SCPN.word_embs.parameters"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_transformation_attention", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.compute_decoder_attention"], ["", "", "def", "decode_step", "(", "self", ",", "idx", ",", "prev_words", ",", "prev_hid", ",", "prev_cell", ",", "\n", "enc_hids", ",", "trans_embs", ",", "in_sent_lens", ",", "trans_lens", ",", "bsz", ",", "max_len", ")", ":", "\n", "        ", "device", "=", "self", ".", "word_embs", ".", "parameters", "(", ")", ".", "__next__", "(", ")", ".", "device", "\n", "\n", "# initialize with zeros", "\n", "if", "idx", "==", "0", ":", "\n", "            ", "word_input", "=", "torch", ".", "zeros", "(", "bsz", ",", "1", ",", "self", ".", "d_word", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "            ", "word_input", "=", "self", ".", "word_embs", "(", "prev_words", ")", "\n", "word_input", "=", "word_input", ".", "view", "(", "bsz", ",", "1", ",", "self", ".", "d_word", ")", "\n", "\n", "# concatenate w/ transformation embeddings", "\n", "", "trans_weights", "=", "self", ".", "compute_transformation_attention", "(", "prev_hid", "[", "1", "]", ",", "trans_embs", ",", "trans_lens", ")", "\n", "trans_ctx", "=", "torch", ".", "sum", "(", "trans_weights", ".", "unsqueeze", "(", "2", ")", "*", "trans_embs", ",", "dim", "=", "1", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "[", "word_input", ",", "trans_ctx", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "\n", "# feed to decoder lstm", "\n", "_", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "decoder", "(", "decoder_input", ",", "(", "prev_hid", ",", "prev_cell", ")", ")", "\n", "\n", "# compute attention for next time step and att weighted ave of encoder hiddens", "\n", "attn_weights", "=", "self", ".", "compute_decoder_attention", "(", "hn", "[", "1", "]", ",", "enc_hids", ",", "in_sent_lens", ")", "\n", "attn_ctx", "=", "torch", ".", "sum", "(", "attn_weights", ".", "unsqueeze", "(", "2", ")", "*", "enc_hids", ",", "dim", "=", "1", ")", "\n", "\n", "# compute copy prob as function of lotsa shit", "\n", "p_copy", "=", "decoder_input", ".", "squeeze", "(", "1", ")", ".", "mm", "(", "self", ".", "copy_inp_v", ")", "\n", "p_copy", "+=", "attn_ctx", ".", "mm", "(", "self", ".", "copy_att_v", ")", "\n", "p_copy", "+=", "hn", "[", "1", "]", ".", "mm", "(", "self", ".", "copy_hid_v", ")", "\n", "p_copy", "=", "torch", ".", "sigmoid", "(", "p_copy", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "hn", ",", "cn", ",", "attn_weights", ",", "attn_ctx", ",", "p_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.forward": [[389, 391], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.batch_beam_search": [[393, 526], ["inputs.size", "models.SCPN.encode_transformations", "models.SCPN.att_parse_proj", "models.SCPN.encode_batch", "enc_last_hid.unsqueeze().expand().contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "out_trans.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "enc_hids.size", "enc_hids.expand", "in_sent_lens.expand", "inputs.expand", "models.SCPN.decode_step", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.log().squeeze.scatter_add_", "torch.log().squeeze.scatter_add_", "torch.log().squeeze", "torch.log().squeeze", "torch.log().squeeze", "torch.log().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.SCPN.out_dense_1", "models.SCPN.out_dense_2", "models.SCPN.out_nonlin().squeeze", "enc_last_hid.unsqueeze().expand", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "models.SCPN.size", "models.SCPN.size", "models.SCPN.unsqueeze().expand().contiguous().view", "out_trans_lens.unsqueeze().expand().contiguous().view", "prev_hs.append", "prev_cs.append", "torch.log", "torch.log", "torch.log", "torch.log", "models.SCPN.out_nonlin", "p_copy.unsqueeze", "len", "hn[].unsqueeze", "cn[].unsqueeze", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "range", "enumerate", "enc_last_hid.unsqueeze", "len", "torch.LongTensor().to.append", "torch.LongTensor().to.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "models.SCPN.unsqueeze().expand().contiguous", "out_trans_lens.unsqueeze().expand().contiguous", "p_copy.unsqueeze", "top_indices[].item", "beam_candidates.append", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "range", "numpy.argsort", "beam_candidates.append", "top_indices[].item", "beam_candidates.append", "models.SCPN.unsqueeze().expand", "out_trans_lens.unsqueeze().expand", "preds[].item", "curr_hn.unsqueeze", "curr_cn.unsqueeze", "models.SCPN.unsqueeze", "out_trans_lens.unsqueeze", "float", "preds[].cpu().item", "preds[].cpu"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.encode_transformations", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.encode_batch", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.decode_step", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to"], ["", "def", "batch_beam_search", "(", "self", ",", "inputs", ",", "out_trans", ",", "in_sent_lens", ",", "out_trans_lens", ",", "eos_idx", ",", "beam_size", "=", "5", ",", "max_steps", "=", "70", ")", ":", "\n", "        ", "device", "=", "inputs", ".", "device", "\n", "bsz", ",", "max_len", "=", "inputs", ".", "size", "(", ")", "\n", "\n", "# chop input", "\n", "inputs", "=", "inputs", "[", ":", ",", ":", "in_sent_lens", "[", "0", "]", "]", "\n", "\n", "# encode transformations", "\n", "out_trans_hids", "=", "self", ".", "encode_transformations", "(", "out_trans", ",", "out_trans_lens", ",", "return_last", "=", "False", ")", "\n", "out_trans_hids", "=", "self", ".", "att_parse_proj", "(", "out_trans_hids", ")", "\n", "\n", "# encode input sentence", "\n", "enc_hids", ",", "enc_last_hid", "=", "self", ".", "encode_batch", "(", "inputs", ",", "None", ",", "in_sent_lens", ")", "\n", "\n", "# initialize decoder hidden to last encoder hidden", "\n", "hn", "=", "enc_last_hid", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "2", ",", "bsz", ",", "self", ".", "d_hid", ")", ".", "contiguous", "(", ")", "\n", "cn", "=", "torch", ".", "zeros", "(", "2", ",", "1", ",", "self", ".", "d_hid", ",", "device", "=", "device", ")", "\n", "\n", "# initialize beams (dictionary of batch_idx: beam params)", "\n", "beam_dict", "=", "{", "}", "\n", "for", "b_idx", "in", "range", "(", "out_trans", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "beam_dict", "[", "b_idx", "]", "=", "[", "(", "0.0", ",", "hn", ",", "cn", ",", "[", "]", ")", "]", "\n", "", "nsteps", "=", "0", "\n", "\n", "while", "True", ":", "\n", "# set up accumulators for predictions", "\n", "# assumption: all examples have same number of beams at each timestep", "\n", "            ", "prev_words", "=", "[", "]", "\n", "prev_hs", "=", "[", "]", "\n", "prev_cs", "=", "[", "]", "\n", "\n", "for", "b_idx", "in", "beam_dict", ":", "\n", "                ", "beams", "=", "beam_dict", "[", "b_idx", "]", "\n", "\n", "# loop over everything in the beam", "\n", "beam_candidates", "=", "[", "]", "\n", "for", "b", "in", "beams", ":", "\n", "                    ", "curr_prob", ",", "prev_h", ",", "prev_c", ",", "seq", "=", "b", "\n", "\n", "# start with last word in sequence, if eos end the beam", "\n", "if", "len", "(", "seq", ")", ">", "0", ":", "\n", "                        ", "prev_words", ".", "append", "(", "seq", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "prev_words", "=", "None", "\n", "\n", "", "prev_hs", ".", "append", "(", "prev_h", ")", "\n", "prev_cs", ".", "append", "(", "prev_c", ")", "\n", "\n", "# now batch decoder computations", "\n", "", "", "hs", "=", "torch", ".", "cat", "(", "prev_hs", ",", "dim", "=", "1", ")", "\n", "cs", "=", "torch", ".", "cat", "(", "prev_cs", ",", "dim", "=", "1", ")", "\n", "num_examples", "=", "hs", ".", "size", "(", "1", ")", "\n", "\n", "if", "prev_words", "is", "not", "None", ":", "\n", "                ", "prev_words", "=", "torch", ".", "LongTensor", "(", "prev_words", ")", ".", "to", "(", "device", ")", "\n", "\n", "# expand out parse states if necessary", "\n", "", "if", "num_examples", "!=", "out_trans_hids", ".", "size", "(", "0", ")", ":", "\n", "                ", "d1", ",", "d2", ",", "d3", "=", "out_trans_hids", ".", "size", "(", ")", "\n", "rep_factor", "=", "num_examples", "//", "d1", "\n", "curr_out", "=", "out_trans_hids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "d1", ",", "rep_factor", ",", "d2", ",", "d3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "d2", ",", "d3", ")", "\n", "curr_out_lens", "=", "out_trans_lens", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "d1", ",", "rep_factor", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "curr_out", "=", "out_trans_hids", "\n", "curr_out_lens", "=", "out_trans_lens", "\n", "\n", "# expand out inputs and encoder hiddens", "\n", "", "_", ",", "in_len", ",", "hid_d", "=", "enc_hids", ".", "size", "(", ")", "\n", "curr_enc_hids", "=", "enc_hids", ".", "expand", "(", "num_examples", ",", "in_len", ",", "hid_d", ")", "\n", "curr_enc_lens", "=", "in_sent_lens", ".", "expand", "(", "num_examples", ")", "\n", "curr_inputs", "=", "inputs", ".", "expand", "(", "num_examples", ",", "in_sent_lens", "[", "0", "]", ")", "\n", "\n", "# concat prev word emb and prev attn input and feed to decoder lstm", "\n", "hn", ",", "cn", ",", "attn_weights", ",", "attn_ctx", ",", "p_copy", "=", "self", ".", "decode_step", "(", "nsteps", ",", "prev_words", ",", "hs", ",", "cs", ",", "curr_enc_hids", ",", "curr_out", ",", "curr_enc_lens", ",", "curr_out_lens", ",", "num_examples", ",", "max_len", ")", "\n", "\n", "# compute copy attn by scattering attn into vocab space", "\n", "vocab_scores", "=", "torch", ".", "zeros", "(", "num_examples", ",", "self", ".", "len_voc", ",", "device", "=", "device", ")", "\n", "vocab_scores", "=", "vocab_scores", ".", "scatter_add_", "(", "1", ",", "curr_inputs", ",", "attn_weights", ")", "\n", "vocab_scores", "=", "torch", ".", "log", "(", "vocab_scores", "+", "1e-20", ")", ".", "squeeze", "(", ")", "\n", "\n", "# compute prediction over vocab for a single time step", "\n", "pred_inp", "=", "torch", ".", "cat", "(", "[", "hn", "[", "1", "]", ",", "attn_ctx", "]", ",", "dim", "=", "1", ")", "\n", "\n", "preds", "=", "self", ".", "out_dense_1", "(", "pred_inp", ")", "\n", "preds", "=", "self", ".", "out_dense_2", "(", "preds", ")", "\n", "preds", "=", "self", ".", "out_nonlin", "(", "preds", ")", ".", "squeeze", "(", ")", "\n", "final_preds", "=", "p_copy", ".", "unsqueeze", "(", "1", ")", "*", "vocab_scores", "+", "(", "1", "-", "p_copy", ".", "unsqueeze", "(", "1", ")", ")", "*", "preds", "\n", "\n", "# now loop over the examples and sort each separately", "\n", "for", "b_idx", "in", "beam_dict", ":", "\n", "                ", "beam_candidates", "=", "[", "]", "\n", "\n", "# no words previously predicted", "\n", "if", "num_examples", "==", "len", "(", "beam_dict", ")", ":", "\n", "                    ", "ex_hn", "=", "hn", "[", ":", ",", "b_idx", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "ex_cn", "=", "cn", "[", ":", ",", "b_idx", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "preds", "=", "final_preds", "[", "b_idx", "]", "\n", "_", ",", "top_indices", "=", "torch", ".", "sort", "(", "-", "preds", ")", "\n", "# add top n candidates", "\n", "for", "z", "in", "range", "(", "beam_size", ")", ":", "\n", "                        ", "word_idx", "=", "top_indices", "[", "z", "]", ".", "item", "(", ")", "\n", "beam_candidates", ".", "append", "(", "(", "preds", "[", "word_idx", "]", ".", "item", "(", ")", ",", "ex_hn", ",", "ex_cn", ",", "[", "word_idx", "]", ")", ")", "\n", "beam_dict", "[", "b_idx", "]", "=", "beam_candidates", "\n", "", "", "else", ":", "\n", "                    ", "origin_beams", "=", "beam_dict", "[", "b_idx", "]", "\n", "start", "=", "b_idx", "*", "beam_size", "\n", "end", "=", "(", "b_idx", "+", "1", ")", "*", "beam_size", "\n", "ex_hn", "=", "hn", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "ex_cn", "=", "cn", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "ex_preds", "=", "final_preds", "[", "start", ":", "end", "]", "\n", "\n", "for", "o_idx", ",", "ob", "in", "enumerate", "(", "origin_beams", ")", ":", "\n", "                        ", "curr_prob", ",", "_", ",", "_", ",", "seq", "=", "ob", "\n", "# if one of the beams is already complete, add it to candidates", "\n", "if", "seq", "[", "-", "1", "]", "==", "eos_idx", ":", "\n", "                            ", "beam_candidates", ".", "append", "(", "ob", ")", "\n", "\n", "", "preds", "=", "ex_preds", "[", "o_idx", "]", "\n", "curr_hn", "=", "ex_hn", "[", ":", ",", "o_idx", ",", ":", "]", "\n", "curr_cn", "=", "ex_cn", "[", ":", ",", "o_idx", ",", ":", "]", "\n", "_", ",", "top_indices", "=", "torch", ".", "sort", "(", "-", "preds", ")", "\n", "for", "z", "in", "range", "(", "beam_size", ")", ":", "\n", "                            ", "word_idx", "=", "top_indices", "[", "z", "]", ".", "item", "(", ")", "\n", "beam_candidates", ".", "append", "(", "(", "curr_prob", "+", "float", "(", "preds", "[", "word_idx", "]", ".", "cpu", "(", ")", ".", "item", "(", ")", ")", ",", "curr_hn", ".", "unsqueeze", "(", "1", ")", ",", "curr_cn", ".", "unsqueeze", "(", "1", ")", ",", "seq", "+", "[", "word_idx", "]", ")", ")", "\n", "", "", "s_inds", "=", "np", ".", "argsort", "(", "[", "x", "[", "0", "]", "for", "x", "in", "beam_candidates", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "beam_candidates", "=", "[", "beam_candidates", "[", "x", "]", "for", "x", "in", "s_inds", "]", "\n", "beam_dict", "[", "b_idx", "]", "=", "beam_candidates", "[", ":", "beam_size", "]", "\n", "\n", "", "", "nsteps", "+=", "1", "\n", "if", "nsteps", ">", "max_steps", ":", "\n", "                ", "break", "\n", "", "", "return", "beam_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.BPE.__init__": [[19, 43], ["codes.readline", "codes.readline.startswith", "dict", "dict", "tuple", "codes.seek", "tuple", "item.split", "int", "reversed", "subword.BPE.bpe_codes.items", "re.sub().split", "list", "enumerate", "re.sub", "codes.readline.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "codes", ",", "separator", "=", "'@@'", ",", "vocab", "=", "None", ",", "glossaries", "=", "None", ")", ":", "\n", "\n", "# check version information", "\n", "        ", "firstline", "=", "codes", ".", "readline", "(", ")", "\n", "if", "firstline", ".", "startswith", "(", "'#version:'", ")", ":", "\n", "            ", "self", ".", "version", "=", "tuple", "(", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "sub", "(", "r'(\\.0+)*$'", ",", "''", ",", "firstline", ".", "split", "(", ")", "[", "-", "1", "]", ")", ".", "split", "(", "\".\"", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "version", "=", "(", "0", ",", "1", ")", "\n", "codes", ".", "seek", "(", "0", ")", "\n", "\n", "", "self", ".", "bpe_codes", "=", "[", "tuple", "(", "item", ".", "split", "(", ")", ")", "for", "item", "in", "codes", "]", "\n", "\n", "# some hacking to deal with duplicates (only consider first instance)", "\n", "self", ".", "bpe_codes", "=", "dict", "(", "[", "(", "code", ",", "i", ")", "for", "(", "i", ",", "code", ")", "in", "reversed", "(", "list", "(", "enumerate", "(", "self", ".", "bpe_codes", ")", ")", ")", "]", ")", "\n", "\n", "self", ".", "bpe_codes_reverse", "=", "dict", "(", "[", "(", "pair", "[", "0", "]", "+", "pair", "[", "1", "]", ",", "pair", ")", "for", "pair", ",", "i", "in", "self", ".", "bpe_codes", ".", "items", "(", ")", "]", ")", "\n", "\n", "self", ".", "separator", "=", "separator", "\n", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "glossaries", "=", "glossaries", "if", "glossaries", "else", "[", "]", "\n", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.BPE.segment": [[44, 63], ["sentence.split", "output.append", "output.append", "subword.BPE._isolate_glossaries", "subword.encode"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.BPE._isolate_glossaries", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.encode"], ["", "def", "segment", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "\"\"\"segment single sentence (whitespace-tokenized string) with BPE encoding\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "word", "in", "sentence", ".", "split", "(", ")", ":", "\n", "            ", "new_word", "=", "[", "out", "for", "segment", "in", "self", ".", "_isolate_glossaries", "(", "word", ")", "\n", "for", "out", "in", "encode", "(", "segment", ",", "\n", "self", ".", "bpe_codes", ",", "\n", "self", ".", "bpe_codes_reverse", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "separator", ",", "\n", "self", ".", "version", ",", "\n", "self", ".", "cache", ",", "\n", "self", ".", "glossaries", ")", "]", "\n", "\n", "for", "item", "in", "new_word", "[", ":", "-", "1", "]", ":", "\n", "                ", "output", ".", "append", "(", "item", "+", "self", ".", "separator", ")", "\n", "", "output", ".", "append", "(", "new_word", "[", "-", "1", "]", ")", "\n", "\n", "", "return", "' '", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.BPE._isolate_glossaries": [[64, 70], ["subword.isolate_glossary"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.isolate_glossary"], ["", "def", "_isolate_glossaries", "(", "self", ",", "word", ")", ":", "\n", "        ", "word_segments", "=", "[", "word", "]", "\n", "for", "gloss", "in", "self", ".", "glossaries", ":", "\n", "            ", "word_segments", "=", "[", "out_segments", "for", "segment", "in", "word_segments", "\n", "for", "out_segments", "in", "isolate_glossary", "(", "segment", ",", "gloss", ")", "]", "\n", "", "return", "word_segments", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.get_pairs": [[72, 83], ["set", "set.add"], "function", ["None"], ["", "", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.encode": [[84, 147], ["subword.get_pairs", "min", "tuple", "word[].endswith", "subword.check_vocab_and_split", "tuple", "len", "len", "subword.get_pairs", "tuple", "check_vocab_and_split.index", "tuple.extend", "tuple.append", "tuple.append", "bpe_codes.get", "tuple.extend", "word[].replace", "float", "len"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.get_pairs", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.check_vocab_and_split", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.get_pairs", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.get"], ["", "def", "encode", "(", "orig", ",", "bpe_codes", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ",", "version", ",", "cache", ",", "glossaries", "=", "None", ")", ":", "\n", "    ", "\"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\n    \"\"\"", "\n", "\n", "if", "orig", "in", "cache", ":", "\n", "        ", "return", "cache", "[", "orig", "]", "\n", "\n", "", "if", "orig", "in", "glossaries", ":", "\n", "        ", "cache", "[", "orig", "]", "=", "(", "orig", ",", ")", "\n", "return", "(", "orig", ",", ")", "\n", "\n", "", "if", "version", "==", "(", "0", ",", "1", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "orig", ")", "+", "(", "'</w>'", ",", ")", "\n", "", "elif", "version", "==", "(", "0", ",", "2", ")", ":", "# more consistent handling of word-final segments", "\n", "        ", "word", "=", "tuple", "(", "orig", "[", ":", "-", "1", "]", ")", "+", "(", "orig", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "        ", "return", "orig", "\n", "\n", "", "while", "True", ":", "\n", "        ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "bpe_codes", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "bpe_codes", ":", "\n", "            ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "# don't print end-of-word symbols", "\n", "", "", "if", "word", "[", "-", "1", "]", "==", "'</w>'", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "\n", "", "elif", "word", "[", "-", "1", "]", ".", "endswith", "(", "'</w>'", ")", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "+", "(", "word", "[", "-", "1", "]", ".", "replace", "(", "'</w>'", ",", "''", ")", ",", ")", "\n", "\n", "", "if", "vocab", ":", "\n", "        ", "word", "=", "check_vocab_and_split", "(", "word", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ")", "\n", "\n", "", "cache", "[", "orig", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.recursive_split": [[148, 174], ["subword.recursive_split", "subword.recursive_split"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.recursive_split", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.recursive_split"], ["", "def", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", "=", "False", ")", ":", "\n", "    ", "\"\"\"Recursively split segment into smaller units (by reversing BPE merges)\n    until all units are either in-vocabulary, or cannot be split futher.\"\"\"", "\n", "\n", "try", ":", "\n", "        ", "if", "final", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "+", "'</w>'", "]", "\n", "right", "=", "right", "[", ":", "-", "4", "]", "\n", "", "else", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "]", "\n", "", "", "except", ":", "\n", "#sys.stderr.write('cannot split {0} further.\\n'.format(segment))", "\n", "        ", "yield", "segment", "\n", "return", "\n", "\n", "", "if", "left", "+", "separator", "in", "vocab", ":", "\n", "        ", "yield", "left", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "left", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "            ", "yield", "item", "\n", "\n", "", "", "if", "(", "final", "and", "right", "in", "vocab", ")", "or", "(", "not", "final", "and", "right", "+", "separator", "in", "vocab", ")", ":", "\n", "        ", "yield", "right", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "right", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", ")", ":", "\n", "            ", "yield", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.check_vocab_and_split": [[175, 198], ["out.append", "subword.recursive_split", "out.append", "subword.recursive_split", "out.append", "out.append"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.recursive_split", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.recursive_split"], ["", "", "", "def", "check_vocab_and_split", "(", "orig", ",", "bpe_codes", ",", "vocab", ",", "separator", ")", ":", "\n", "    ", "\"\"\"Check for each segment in word if it is in-vocabulary,\n    and segment OOV segments into smaller units by reversing the BPE merge operations\"\"\"", "\n", "\n", "out", "=", "[", "]", "\n", "\n", "for", "segment", "in", "orig", "[", ":", "-", "1", "]", ":", "\n", "        ", "if", "segment", "+", "separator", "in", "vocab", ":", "\n", "            ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "            ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "                ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "segment", "=", "orig", "[", "-", "1", "]", "\n", "if", "segment", "in", "vocab", ":", "\n", "        ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "        ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "True", ")", ":", "\n", "            ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.read_vocabulary": [[200, 213], ["set", "line.split", "int", "set.add"], "function", ["None"], ["", "def", "read_vocabulary", "(", "vocab_file", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"read vocabulary file produced by get_vocab.py, and filter according to frequency threshold.\n    \"\"\"", "\n", "\n", "vocabulary", "=", "set", "(", ")", "\n", "\n", "for", "line", "in", "vocab_file", ":", "\n", "        ", "word", ",", "freq", "=", "line", ".", "split", "(", ")", "\n", "freq", "=", "int", "(", "freq", ")", "\n", "if", "threshold", "==", "None", "or", "freq", ">=", "threshold", ":", "\n", "            ", "vocabulary", ".", "add", "(", "word", ")", "\n", "\n", "", "", "return", "vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.isolate_glossary": [[214, 229], ["word.split", "segment.strip", "splits[].strip"], "function", ["None"], ["", "def", "isolate_glossary", "(", "word", ",", "glossary", ")", ":", "\n", "    ", "\"\"\"\n    Isolate a glossary present inside a word.\n\n    Returns a list of subwords. In which all 'glossary' glossaries are isolated \n\n    For example, if 'USA' is the glossary and '1934USABUSA' the word, the return value is:\n        ['1934', 'USA', 'B', 'USA']\n    \"\"\"", "\n", "if", "word", "==", "glossary", "or", "glossary", "not", "in", "word", ":", "\n", "        ", "return", "[", "word", "]", "\n", "", "else", ":", "\n", "        ", "splits", "=", "word", ".", "split", "(", "glossary", ")", "\n", "segments", "=", "[", "segment", ".", "strip", "(", ")", "for", "split", "in", "splits", "[", ":", "-", "1", "]", "for", "segment", "in", "[", "split", ",", "glossary", "]", "if", "segment", "!=", "''", "]", "\n", "return", "segments", "+", "[", "splits", "[", "-", "1", "]", ".", "strip", "(", ")", "]", "if", "splits", "[", "-", "1", "]", "!=", "''", "else", "segments", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.__init__.SCPNAttacker.TAGS": [[44, 47], ["tags.Tag"], "methods", ["None"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.__init__.SCPNAttacker.__init__": [[48, 147], ["utils.check_language", "data_manager.DataManager.load", "torch.load", "torch.load", "pickle.load", "open", "open", "pickle.load", "dict", "models.SCPN", "__init__.SCPNAttacker.net.load_state_dict", "__init__.SCPNAttacker.net.to().eval", "models.ParseNet", "__init__.SCPNAttacker.parse_net.load_state_dict", "__init__.SCPNAttacker.parse_net.to().eval", "subword.read_vocabulary", "subword.BPE", "torch.cuda.is_available", "torch.device", "text_process.tokenizer.get_default_tokenizer", "text_process.constituency_parser.get_default_constituency_parser", "open", "open", "len", "len", "torch.device", "torch.device", "len", "__init__.SCPNAttacker.net.to", "__init__.SCPNAttacker.parse_net.to", "__init__.SCPNAttacker.parse_gen_voc.items"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.load", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.read_vocabulary", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.constituency_parser.__init__.get_default_constituency_parser", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.__init__.SCPNAttacker.gen_paraphrase": [[148, 205], ["numpy.zeros", "enumerate", "torch.from_numpy().long().to", "torch.LongTensor().to", "__init__.SCPNAttacker.bpe.segment().split", "__init__.SCPNAttacker.append", "torch.LongTensor().to", "torch.LongTensor().to", "__init__.SCPNAttacker.parser", "parse_tree.split.split.split", "range", "torch.LongTensor().to", "torch.LongTensor().to", "__init__.SCPNAttacker.parse_net.batch_beam_search", "numpy.zeros", "enumerate", "torch.from_numpy().long().to", "torch.LongTensor().to", "__init__.SCPNAttacker.net.batch_beam_search", "len", "__init__.SCPNAttacker.tokenizer.tokenize", "torch.LongTensor().to.unsqueeze", "seq_lens.append", "seqs.append", "torch.LongTensor().to.unsqueeze", "ret.append", "x.split", "len", "max", "torch.from_numpy().long", "torch.LongTensor", "__init__.SCPNAttacker.bpe.segment", "torch.LongTensor", "torch.LongTensor", "len", "torch.LongTensor", "torch.LongTensor", "len", "len", "max", "torch.from_numpy().long", "torch.LongTensor", "__init__.reverse_bpe", "templates[].split", "ssent.lower", "gen_sent.split", "torch.from_numpy", "len", "len", "torch.from_numpy", "parse_tree.split.split.replace().split", "parse_tree.split.split.replace"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.batch_beam_search", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.models.SCPN.batch_beam_search", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.subword.BPE.segment", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.__init__.reverse_bpe"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.__init__.SCPNAttacker.attack": [[206, 217], ["victim.get_pred", "enumerate", "__init__.SCPNAttacker.gen_paraphrase", "goal.check"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.__init__.SCPNAttacker.gen_paraphrase", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.scpn.__init__.reverse_bpe": [[28, 40], ["w.endswith", "w.replace", "x.append", "x.append"], "function", ["None"], ["# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.TAGS": [[12, 15], ["tags.Tag", "tags.Tag", "tags.Tag"], "methods", ["None"], ["from", ".", "victim", ".", "classifiers", "import", "Classifier", "\n", "\n", "# metrics", "\n", "from", ".", "import", "metric", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.__init__": [[16, 74], ["set", "utils.check_language", "utils.get_language", "utils.get_language", "attack_assist.substitute.word.get_default_substitute", "text_process.tokenizer.get_default_tokenizer", "attack_assist.filter_words.get_default_filter_words", "utils.get_language", "utils.language_by_name", "ValueError"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.check_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.__init__.get_default_substitute", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.__init__.get_default_tokenizer", "home.repos.pwc.inspect_result.thunlp_OpenAttack.filter_words.__init__.get_default_filter_words", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.get_language", "home.repos.pwc.inspect_result.thunlp_OpenAttack.utils.auto_lang.language_by_name"], ["from", ".", "metric", "import", "AttackMetric", "\n", "\n", "# attack_eval", "\n", "from", ".", "attack_eval", "import", "AttackEval", "\n", "\n", "# attack_assist", "\n", "from", ".", "attack_assist", "import", "goal", ",", "substitute", ",", "word_embedding", ",", "filter_words", "\n", "\n", "# exception", "\n", "from", ".", "import", "exceptions", "\n", "from", ".", "exception", "import", "AttackException", "\n", "\n", "# utils", "\n", "from", ".", "import", "utils", "\n", "\n", "download", "=", "DataManager", ".", "download", "\n", "load", "=", "DataManager", ".", "load", "\n", "loadAttackAssist", "=", "DataManager", ".", "loadAttackAssist", "\n", "loadVictim", "=", "DataManager", ".", "loadVictim", "\n", "loadTProcess", "=", "DataManager", ".", "loadTProcess", "\n", "\n", "from", ".", "version", "import", "VERSION", "as", "__version__", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.fd.__init__.FDAttacker.attack": [[75, 128], ["x_orig.lower.lower.lower", "__init__.FDAttacker.tokenizer.tokenize", "victim.get_embedding", "range", "__init__.FDAttacker.tokenizer.detokenize", "goal.check", "victim.get_grad", "numpy.sign", "victim.get_pred", "numpy.random.choice", "list", "RuntimeError", "numpy.sign", "numpy.abs().sum", "len", "list", "filter", "len", "len", "len", "map", "victim.get_embedding.transform", "victim.get_embedding.transform", "numpy.abs", "__init__.FDAttacker.substitute", "len"], "methods", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.tokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_embedding", "home.repos.pwc.inspect_result.thunlp_OpenAttack.tokenizer.base.Tokenizer.detokenize", "home.repos.pwc.inspect_result.thunlp_OpenAttack.goal.classifier_goal.ClassifierGoal.check", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_grad", "home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.get_pred", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.transform", "home.repos.pwc.inspect_result.thunlp_OpenAttack.deepwordbug.__init__.DeepWordBugAttacker.transform", "home.repos.pwc.inspect_result.thunlp_OpenAttack.word.chinese_wordnet.ChineseWordNetSubstitute.substitute"], []], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__init__": [[2, 5], ["None"], "methods", ["None"], ["import", "functools", "\n", "from", "typing", "import", "Union", "\n", "from", ".", "context", "import", "AttackContext", ",", "AttackContextShadow", "\n", "from", ".", ".", "exceptions", "import", "InvokeLimitExceeded", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.type": [[6, 9], ["None"], "methods", ["None"], ["from", ".", "method", "import", "VictimMethod", "\n", "import", "time", "\n", "\n", "def", "invoke_decorator", "(", "func", ",", "method", ":", "VictimMethod", ")", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.name": [[10, 13], ["None"], "methods", ["None"], ["    ", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "invoke_wrapper", "(", "self", ":", "Victim", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cnt", "=", "method", ".", "invoke_count", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "self", ".", "record_invoke", "(", "cnt", ",", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__str__": [[14, 16], ["None"], "methods", ["None"], ["\n", "", "return", "invoke_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__eq__": [[17, 19], ["str().lower", "str().lower", "str", "str"], "methods", ["None"], ["", "class", "Victim", ":", "\n", "    ", "@", "property", "\n", "def", "TAGS", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__hash__": [[20, 22], ["hash", "str"], "methods", ["None"], ["        ", "return", "self", ".", "_method_tags", "\n", "\n", "", "def", "__init_subclass__", "(", "cls", ",", "invoke_funcs", "=", "[", "]", ",", "tags", "=", "set", "(", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.tags.base.Tag.__repr__": [[23, 25], ["str"], "methods", ["None"], ["        ", "for", "func_name", ",", "method", "in", "invoke_funcs", ":", "\n", "            ", "setattr", "(", "cls", ",", "func_name", ",", "invoke_decorator", "(", "getattr", "(", "cls", ",", "func_name", ")", ",", "method", ")", ")", "\n", "", "cls", ".", "_method_tags", "=", "set", "(", "tags", ")", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_chinese_default.dataset_mapping": [[10, 14], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"review_body\"", "]", ",", "\n", "\"y\"", ":", "x", "[", "\"stars\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_chinese_default.main": [[16, 37], ["datasets.load_dataset().map", "OpenAttack.loadVictim().to", "attackers_chinese.get_attackers_on_chinese", "multiprocessing.get_start_method", "multiprocessing.set_start_method", "print", "datasets.load_dataset", "OpenAttack.loadVictim", "time.perf_counter", "print", "OpenAttack.AttackEval().eval", "print", "print", "time.perf_counter", "OpenAttack.AttackEval"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.attackers_chinese.get_attackers_on_chinese", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "multiprocessing", "\n", "if", "multiprocessing", ".", "get_start_method", "(", ")", "!=", "\"spawn\"", ":", "\n", "        ", "multiprocessing", ".", "set_start_method", "(", "\"spawn\"", ",", "force", "=", "True", ")", "\n", "", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"amazon_reviews_multi\"", ",", "'zh'", ",", "split", "=", "\"train[:5]\"", ")", ".", "map", "(", "dataset_mapping", ")", "\n", "\n", "clsf", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.AMAZON_ZH\"", ")", ".", "to", "(", "\"cuda:0\"", ")", "\n", "attackers", "=", "get_attackers_on_chinese", "(", "dataset", ",", "clsf", ")", "\n", "\n", "for", "attacker", "in", "attackers", ":", "\n", "        ", "print", "(", "attacker", ".", "__class__", ".", "__name__", ")", "\n", "try", ":", "\n", "            ", "st", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "\n", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "clsf", ",", "language", "=", "\"chinese\"", ")", ".", "eval", "(", "dataset", ",", "progress_bar", "=", "True", ")", ",", "\n", "time", ".", "perf_counter", "(", ")", "-", "st", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "e", "\n", "print", "(", "e", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_chinese_multi_process.dataset_mapping": [[10, 14], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"review_body\"", "]", ",", "\n", "\"y\"", ":", "x", "[", "\"stars\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_chinese_multi_process.main": [[16, 36], ["datasets.load_dataset().map", "OpenAttack.loadVictim().to", "attackers_chinese.get_attackers_on_chinese", "multiprocessing.get_start_method", "multiprocessing.set_start_method", "print", "datasets.load_dataset", "OpenAttack.loadVictim", "time.perf_counter", "print", "OpenAttack.AttackEval().eval", "print", "print", "time.perf_counter", "OpenAttack.AttackEval"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.attackers_chinese.get_attackers_on_chinese", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "multiprocessing", "\n", "if", "multiprocessing", ".", "get_start_method", "(", ")", "!=", "\"spawn\"", ":", "\n", "        ", "multiprocessing", ".", "set_start_method", "(", "\"spawn\"", ",", "force", "=", "True", ")", "\n", "", "dataset", "=", "datasets", ".", "load_dataset", "(", "'amazon_reviews_multi'", ",", "'zh'", ",", "split", "=", "\"train[:100]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "clsf", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.AMAZON_ZH\"", ")", ".", "to", "(", "\"cuda:0\"", ")", "\n", "attackers", "=", "get_attackers_on_chinese", "(", "dataset", ",", "clsf", ")", "\n", "\n", "for", "attacker", "in", "attackers", ":", "\n", "        ", "print", "(", "attacker", ".", "__class__", ".", "__name__", ")", "\n", "try", ":", "\n", "            ", "st", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "\n", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "clsf", ",", "language", "=", "\"chinese\"", ")", ".", "eval", "(", "dataset", ",", "num_workers", "=", "2", ",", "progress_bar", "=", "False", ")", ",", "\n", "time", ".", "perf_counter", "(", ")", "-", "st", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "e", "\n", "print", "(", "e", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.attackers.get_attackers": [[8, 33], ["OpenAttack.attackers.UATAttacker.get_triggers", "print", "OpenAttack.attackers.FDAttacker", "OpenAttack.attackers.UATAttacker", "OpenAttack.attackers.TextBuggerAttacker", "OpenAttack.attackers.TextFoolerAttacker", "OpenAttack.attackers.VIPERAttacker", "OpenAttack.attackers.DeepWordBugAttacker", "OpenAttack.attackers.GANAttacker", "OpenAttack.attackers.GeneticAttacker", "OpenAttack.attackers.HotFlipAttacker", "OpenAttack.attackers.PWWSAttacker", "OpenAttack.attackers.SCPNAttacker", "OpenAttack.attackers.PSOAttacker", "OpenAttack.attackers.BAEAttacker", "OpenAttack.attackers.BERTAttacker"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.get_triggers"], ["def", "get_attackers", "(", "dataset", ",", "clsf", ")", ":", "\n", "\n", "# rules = OpenAttack.attackers.SEAAttacker.get_rules(clsf, dataset)", "\n", "\n", "    ", "triggers", "=", "OpenAttack", ".", "attackers", ".", "UATAttacker", ".", "get_triggers", "(", "clsf", ",", "dataset", ",", "clsf", ".", "tokenizer", ")", "\n", "print", "(", "triggers", ")", "\n", "\n", "attackers", "=", "[", "\n", "OpenAttack", ".", "attackers", ".", "FDAttacker", "(", "token_unk", "=", "clsf", ".", "token_unk", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "UATAttacker", "(", "triggers", "=", "triggers", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "TextBuggerAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "TextFoolerAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "VIPERAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "DeepWordBugAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "GANAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "GeneticAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "HotFlipAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "SCPNAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "PSOAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "BAEAttacker", "(", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "BERTAttacker", "(", ")", "\n", "]", "\n", "\n", "return", "attackers", "\n", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_multi_process.dataset_mapping": [[11, 15], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_multi_process.main": [[17, 40], ["datasets.load_dataset().map", "OpenAttack.loadVictim().to", "attackers.get_attackers", "multiprocessing.get_start_method", "multiprocessing.set_start_method", "print", "wrapper.TimeCalcClsf", "datasets.load_dataset", "OpenAttack.loadVictim", "time.perf_counter", "print", "OpenAttack.attack_evals.DefaultAttackEval().eval", "print", "print", "time.perf_counter", "OpenAttack.attack_evals.DefaultAttackEval"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.classifiers.transformers.TransformersClassifier.to", "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.attackers.get_attackers", "home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "multiprocessing", "\n", "if", "multiprocessing", ".", "get_start_method", "(", ")", "!=", "\"spawn\"", ":", "\n", "        ", "multiprocessing", ".", "set_start_method", "(", "\"spawn\"", ",", "force", "=", "True", ")", "\n", "", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:100]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "clsf", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.SST\"", ")", ".", "to", "(", "\"cuda:0\"", ")", "\n", "\n", "attackers", "=", "get_attackers", "(", "dataset", ",", "clsf", ")", "\n", "\n", "for", "attacker", "in", "attackers", ":", "\n", "        ", "print", "(", "attacker", ".", "__class__", ".", "__name__", ")", "\n", "time_clsf", "=", "TimeCalcClsf", "(", "clsf", ")", "\n", "try", ":", "\n", "            ", "st", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "\n", "OpenAttack", ".", "attack_evals", ".", "DefaultAttackEval", "(", "attacker", ",", "time_clsf", ",", "num_process", "=", "2", ")", ".", "eval", "(", "dataset", ",", "progress_bar", "=", "True", ")", ",", "\n", "time_clsf", ".", "total_time", ",", "\n", "time", ".", "perf_counter", "(", ")", "-", "st", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "e", "\n", "print", "(", "e", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.attackers_chinese.get_attackers_on_chinese": [[9, 22], ["OpenAttack.attackers.UATAttacker.get_triggers", "OpenAttack.attackers.FDAttacker", "OpenAttack.attackers.UATAttacker", "OpenAttack.attackers.TextBuggerAttacker", "OpenAttack.attackers.GeneticAttacker", "OpenAttack.attackers.PWWSAttacker", "OpenAttack.attackers.PSOAttacker"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.uat.__init__.UATAttacker.get_triggers"], ["def", "get_attackers_on_chinese", "(", "dataset", ",", "clsf", ")", ":", "\n", "\n", "    ", "triggers", "=", "OpenAttack", ".", "attackers", ".", "UATAttacker", ".", "get_triggers", "(", "clsf", ",", "dataset", ",", "clsf", ".", "tokenizer", ")", "\n", "\n", "attackers", "=", "[", "\n", "OpenAttack", ".", "attackers", ".", "FDAttacker", "(", "token_unk", "=", "clsf", ".", "token_unk", ",", "lang", "=", "\"chinese\"", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "UATAttacker", "(", "triggers", "=", "triggers", ",", "lang", "=", "\"chinese\"", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "TextBuggerAttacker", "(", "lang", "=", "\"chinese\"", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "GeneticAttacker", "(", "lang", "=", "\"chinese\"", ",", "filter_words", "=", "[", "\"\u7684\"", ",", "\"\u4e86\"", ",", "\"\u7740\"", "]", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "PWWSAttacker", "(", "lang", "=", "\"chinese\"", ")", ",", "\n", "OpenAttack", ".", "attackers", ".", "PSOAttacker", "(", "lang", "=", "\"chinese\"", ")", "\n", "]", "\n", "return", "attackers", "", "", ""]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_default.dataset_mapping": [[10, 14], ["None"], "function", ["None"], ["def", "dataset_mapping", "(", "x", ")", ":", "\n", "    ", "return", "{", "\n", "\"x\"", ":", "x", "[", "\"sentence\"", "]", ",", "\n", "\"y\"", ":", "1", "if", "x", "[", "\"label\"", "]", ">", "0.5", "else", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.test_default.main": [[16, 35], ["datasets.load_dataset().map", "OpenAttack.loadVictim", "attackers.get_attackers", "multiprocessing.get_start_method", "multiprocessing.set_start_method", "print", "datasets.load_dataset", "print", "OpenAttack.AttackEval().eval", "print", "print", "OpenAttack.AttackEval"], "function", ["home.repos.pwc.inspect_result.thunlp_OpenAttack.OpenAttack.data_manager.DataManager.loadVictim", "home.repos.pwc.inspect_result.thunlp_OpenAttack.slow_tests.attackers.get_attackers", "home.repos.pwc.inspect_result.thunlp_OpenAttack.attack_eval.attack_eval.AttackEval.eval"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "multiprocessing", "\n", "if", "multiprocessing", ".", "get_start_method", "(", ")", "!=", "\"spawn\"", ":", "\n", "        ", "multiprocessing", ".", "set_start_method", "(", "\"spawn\"", ",", "force", "=", "True", ")", "\n", "", "dataset", "=", "datasets", ".", "load_dataset", "(", "\"sst\"", ",", "split", "=", "\"train[:100]\"", ")", ".", "map", "(", "function", "=", "dataset_mapping", ")", "\n", "clsf", "=", "OpenAttack", ".", "loadVictim", "(", "\"BERT.SST\"", ")", "# .to(\"cuda:0\")", "\n", "\n", "attackers", "=", "get_attackers", "(", "dataset", ",", "clsf", ")", "\n", "\n", "for", "attacker", "in", "attackers", ":", "\n", "        ", "print", "(", "attacker", ".", "__class__", ".", "__name__", ")", "\n", "try", ":", "\n", "            ", "print", "(", "\n", "OpenAttack", ".", "AttackEval", "(", "attacker", ",", "clsf", ")", ".", "eval", "(", "dataset", ",", "progress_bar", "=", "True", ")", ",", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "e", "\n", "print", "(", "e", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n"]]}