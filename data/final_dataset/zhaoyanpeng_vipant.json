{"home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train._distributed_worker": [[17, 36], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.barrier", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.new_group", "torch.device", "torch.device", "torch.device", "main_func", "torch.init_process_group", "range", "logging.getLogger", "logging.getLogger.error"], "function", ["None"], ["def", "_distributed_worker", "(", "local_rank", ",", "main_func", ",", "cfg", ",", "ddp", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"CUDA is not available\"", "\n", "global_rank", "=", "0", "+", "local_rank", "\n", "try", ":", "\n", "        ", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "\"NCCL\"", ",", "\n", "init_method", "=", "cfg", ".", "dist_url", ",", "\n", "world_size", "=", "cfg", ".", "num_gpus", ",", "\n", "rank", "=", "global_rank", ",", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "error", "(", "\"Process group URL: {}\"", ".", "format", "(", "cfg", ".", "dist_url", ")", ")", "\n", "raise", "e", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "pg", "=", "dist", ".", "new_group", "(", "range", "(", "cfg", ".", "num_gpus", ")", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ",", "local_rank", ")", "\n", "main_func", "(", "cfg", ",", "local_rank", ",", "ddp", ",", "pg", ",", "device", ",", "DDPMonitor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.main": [[38, 64], ["cvap.util.seed_all_rng", "cvap.util.setup_logger", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "cvap.util.setup_logger.info", "isinstance", "manager.learn", "omegaconf.OmegaConf.to_yaml", "cvap.util.setup_logger.info", "open", "manager", "eval"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.seed_all_rng", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.setup_logger", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.learn"], ["", "def", "main", "(", "cfg", ",", "rank", ",", "ddp", ",", "pg", ",", "device", ",", "manager", ")", ":", "\n", "    ", "cfg", ".", "rank", "=", "rank", "\n", "seed_all_rng", "(", "cfg", ".", "seed", ")", "# + rank)", "\n", "\n", "output_dir", "=", "f\"{cfg.alias_root}/{cfg.model_name}\"", "\n", "logger", "=", "setup_logger", "(", "\n", "output_dir", "=", "output_dir", ",", "rank", "=", "rank", ",", "output", "=", "output_dir", ",", "\n", ")", "\n", "\n", "if", "cfg", ".", "verbose", "or", "not", "cfg", ".", "eval", ":", "\n", "        ", "cfg_str", "=", "OmegaConf", ".", "to_yaml", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "f\"\\n\\n{cfg_str}\"", ")", "\n", "", "if", "cfg", ".", "blockprint", ":", "\n", "# https://stackoverflow.com/a/8391735", "\n", "        ", "sys", ".", "stdout", "=", "open", "(", "os", ".", "devnull", ",", "'w'", ")", "\n", "\n", "", "ngpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "logger", ".", "info", "(", "\"World size: {}; rank: {}\"", ".", "format", "(", "ngpu", ",", "rank", ")", ")", "\n", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "if", "isinstance", "(", "manager", ",", "str", ")", ":", "\n", "        ", "monitor", "=", "eval", "(", "manager", ")", "(", "cfg", ",", "logger", ".", "info", ",", "device", ")", "\n", "", "else", ":", "\n", "        ", "monitor", "=", "manager", "(", "cfg", ",", "logger", ".", "info", ",", "device", ")", "\n", "", "monitor", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train": [[66, 86], ["hydra.main", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "train.main", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "train.main", "torch.spawn", "torch.device", "torch.device", "torch.device", "torch.destroy_process_group"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.main", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.main", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.main"], ["", "@", "hydra", ".", "main", "(", "config_path", "=", "\"configs\"", ",", "config_name", "=", "\"default\"", ")", "\n", "def", "train", "(", "cfg", ":", "DictConfig", ")", "->", "None", ":", "\n", "    ", "if", "cfg", ".", "mode", "==", "\"dp\"", ":", "\n", "        ", "cfg", ".", "rank", "=", "0", "\n", "torch", ".", "cuda", ".", "set_device", "(", "0", ")", "\n", "main", "(", "cfg", ",", "0", ",", "False", ",", "False", ",", "torch", ".", "device", "(", "'cuda'", ",", "0", ")", ",", "cfg", ".", "monitor", ")", "\n", "", "elif", "cfg", ".", "mode", "==", "\"ddp\"", ":", "\n", "        ", "try", ":", "\n", "            ", "mp", ".", "spawn", "(", "\n", "_distributed_worker", ",", "\n", "nprocs", "=", "cfg", ".", "num_gpus", ",", "\n", "args", "=", "(", "main", ",", "cfg", ",", "False", ")", ",", "\n", "daemon", "=", "False", ",", "\n", ")", "\n", "", "except", "KeyboardInterrupt", "as", "e", ":", "\n", "            ", "dist", ".", "destroy_process_group", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "cfg", ".", "rank", "=", "0", "\n", "torch", ".", "cuda", ".", "set_device", "(", "0", ")", "\n", "main", "(", "cfg", ",", "0", ",", "False", ",", "False", ",", "torch", ".", "device", "(", "'cuda'", ",", "0", ")", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.__init__": [[25, 42], ["dict", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "params", ",", "lr", ",", "\n", "weight_decay", "=", "0", ",", "\n", "momentum", "=", "0.9", ",", "\n", "eta", "=", "0.001", ",", "\n", "weight_decay_filter", "=", "None", ",", "\n", "lars_adaptation_filter", "=", "None", "\n", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "momentum", "=", "momentum", ",", "\n", "eta", "=", "eta", ",", "\n", "weight_decay_filter", "=", "weight_decay_filter", ",", "\n", "lars_adaptation_filter", "=", "lars_adaptation_filter", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step": [[43, 73], ["torch.no_grad", "mu.mul_().add_", "p.add_", "dp.mul.mul.add", "torch.norm", "torch.norm", "torch.ones_like", "torch.where", "dp.mul.mul.mul", "torch.zeros_like", "torch.where", "mu.mul_"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ")", ":", "\n", "        ", "for", "g", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "g", "[", "'params'", "]", ":", "\n", "                ", "dp", "=", "p", ".", "grad", "\n", "if", "dp", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "g", "[", "'weight_decay_filter'", "]", "is", "None", "or", "not", "g", "[", "'weight_decay_filter'", "]", "(", "p", ")", ":", "\n", "                    ", "dp", "=", "dp", ".", "add", "(", "p", ",", "alpha", "=", "g", "[", "'weight_decay'", "]", ")", "\n", "\n", "", "if", "g", "[", "'lars_adaptation_filter'", "]", "is", "None", "or", "not", "g", "[", "'lars_adaptation_filter'", "]", "(", "p", ")", ":", "\n", "                    ", "param_norm", "=", "torch", ".", "norm", "(", "p", ")", "\n", "update_norm", "=", "torch", ".", "norm", "(", "dp", ")", "\n", "one", "=", "torch", ".", "ones_like", "(", "param_norm", ")", "\n", "q", "=", "torch", ".", "where", "(", "\n", "param_norm", ">", "0.", ",", "torch", ".", "where", "(", "\n", "update_norm", ">", "0", ",", "\n", "(", "g", "[", "'eta'", "]", "*", "param_norm", "/", "update_norm", ")", ",", "one", "\n", ")", ",", "one", "\n", ")", "\n", "dp", "=", "dp", ".", "mul", "(", "q", ")", "\n", "\n", "", "param_state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "'mu'", "not", "in", "param_state", ":", "\n", "                    ", "param_state", "[", "'mu'", "]", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "", "mu", "=", "param_state", "[", "'mu'", "]", "\n", "mu", ".", "mul_", "(", "g", "[", "'momentum'", "]", ")", ".", "add_", "(", "dp", ")", "\n", "\n", "p", ".", "add_", "(", "mu", ",", "alpha", "=", "-", "g", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.exclude_bias_or_norm": [[6, 8], ["None"], "function", ["None"], ["def", "exclude_bias_or_norm", "(", "p", ")", ":", "\n", "    ", "return", "p", ".", "ndim", "<", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.adjust_learning_rate": [[9, 23], ["int", "len", "len", "math.cos"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "cfg", ",", "optimizer", ",", "dataloader", ",", "step", ")", ":", "\n", "    ", "max_steps", "=", "cfg", ".", "epochs", "*", "len", "(", "dataloader", ")", "\n", "warmup_steps", "=", "int", "(", "cfg", ".", "warmup_epoch", "*", "len", "(", "dataloader", ")", ")", "\n", "base_lr", "=", "cfg", ".", "batch_size", "/", "256", "\n", "if", "step", "<", "warmup_steps", ":", "\n", "        ", "lr", "=", "base_lr", "*", "step", "/", "warmup_steps", "\n", "", "else", ":", "\n", "        ", "step", "-=", "warmup_steps", "\n", "max_steps", "-=", "warmup_steps", "\n", "q", "=", "0.5", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "step", "/", "max_steps", ")", ")", "\n", "end_lr", "=", "base_lr", "*", "0.001", "\n", "lr", "=", "base_lr", "*", "q", "+", "end_lr", "*", "(", "1", "-", "q", ")", "\n", "", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr", "*", "cfg", ".", "lr_weight", "\n", "optimizer", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", "=", "lr", "*", "cfg", ".", "lr_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.vit.VisualTransformer.__init__": [[9, 49], ["torch.nn.Module.__init__", "isinstance", "isinstance", "list", "list", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Parameter", "torch.nn.Parameter", "isinstance", "torch.nn.Parameter", "torch.nn.Parameter", "clip.LayerNorm", "Transformer", "clip.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_resolution", ":", "int", ",", "\n", "patch_size", ":", "int", ",", "\n", "width", ":", "int", ",", "\n", "layers", ":", "int", ",", "\n", "heads", ":", "int", ",", "\n", "output_dim", ":", "int", ",", "\n", "in_channels", "=", "3", ",", "\n", "stride", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_resolution", "=", "input_resolution", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "stride", "=", "stride", "or", "patch_size", "\n", "if", "isinstance", "(", "stride", ",", "int", ")", ":", "\n", "            ", "stride", "=", "[", "stride", "]", "*", "2", "\n", "", "if", "isinstance", "(", "patch_size", ",", "int", ")", ":", "\n", "            ", "patch_size", "=", "[", "patch_size", "]", "*", "2", "\n", "", "stride", "=", "list", "(", "stride", ")", "\n", "patch_size", "=", "list", "(", "patch_size", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "width", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n", "scale", "=", "width", "**", "-", "0.5", "\n", "self", ".", "class_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ")", ")", "\n", "if", "isinstance", "(", "input_resolution", ",", "int", ")", ":", "\n", "            ", "positions", "=", "(", "input_resolution", "//", "patch_size", "[", "0", "]", ")", "**", "2", "+", "1", "\n", "", "else", ":", "\n", "            ", "row_stride", ",", "col_stride", "=", "stride", "[", ":", "2", "]", "\n", "nrow", "=", "(", "input_resolution", "[", "0", "]", "-", "patch_size", "[", "0", "]", ")", "//", "row_stride", "+", "1", "\n", "ncol", "=", "(", "input_resolution", "[", "1", "]", "-", "patch_size", "[", "1", "]", ")", "//", "col_stride", "+", "1", "\n", "positions", "=", "nrow", "*", "ncol", "+", "1", "\n", "self", ".", "position_resolution", "=", "(", "nrow", ",", "ncol", ")", "\n", "", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "positions", ",", "width", ")", ")", "\n", "self", ".", "ln_pre", "=", "LayerNorm", "(", "width", ")", "\n", "\n", "self", ".", "transformer", "=", "Transformer", "(", "width", ",", "layers", ",", "heads", ")", "\n", "\n", "self", ".", "ln_post", "=", "LayerNorm", "(", "width", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ",", "output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.vit.VisualTransformer.dtype": [[50, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv1", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.vit.VisualTransformer.forward": [[54, 82], ["vit.VisualTransformer.type", "vit.VisualTransformer.reshape", "vit.VisualTransformer.permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "vit.VisualTransformer.ln_pre", "vit.VisualTransformer.permute", "vit.VisualTransformer.transformer", "vit.VisualTransformer.permute", "vit.VisualTransformer.ln_post", "vit.VisualTransformer.conv1.weight.mean", "torch.conv2d", "torch.conv2d", "vit.VisualTransformer.conv1", "vit.VisualTransformer.positional_embedding.to", "vit.VisualTransformer.class_embedding.to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "require_feature", ":", "bool", "=", "False", ")", ":", "\n", "        ", "x", "=", "x", ".", "type", "(", "self", ".", "dtype", ")", "\n", "if", "x", ".", "shape", "[", "1", "]", "!=", "self", ".", "conv1", ".", "weight", ".", "shape", "[", "1", "]", ":", "# interpolate weight", "\n", "            ", "conv1_weight", "=", "self", ".", "conv1", ".", "weight", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "conv1_weight", ",", "bias", "=", "self", ".", "conv1", ".", "bias", ",", "stride", "=", "self", ".", "conv1", ".", "stride", "\n", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "# shape = [*, width, grid, grid]", "\n", "", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "# shape = [*, width, grid ** 2]", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# shape = [*, grid ** 2, width]", "\n", "x", "=", "torch", ".", "cat", "(", "[", "self", ".", "class_embedding", ".", "to", "(", "x", ".", "dtype", ")", "+", "torch", ".", "zeros", "(", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ",", "x", "]", ",", "dim", "=", "1", ")", "# shape = [*, grid ** 2 + 1, width]", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", ".", "to", "(", "x", ".", "dtype", ")", "\n", "x", "=", "self", ".", "ln_pre", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# NLD -> LND", "\n", "x", "=", "self", ".", "transformer", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# LND -> NLD", "\n", "\n", "x", "=", "x_feature", "=", "self", ".", "ln_post", "(", "x", ")", "\n", "\n", "if", "self", ".", "proj", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "0", ",", ":", "]", "@", "self", ".", "proj", "\n", "\n", "", "if", "require_feature", ":", "\n", "            ", "return", "x", ",", "x_feature", "[", ":", ",", "1", ":", "]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.MetaEncoder.__init__": [[21, 25], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "position_resolution", "=", "None", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.MetaEncoder.hp": [[30, 33], ["None"], "methods", ["None"], ["", "@", "hp", ".", "setter", "\n", "def", "hp", "(", "self", ",", "hp", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.Miscellanea.__init__": [[37, 49], ["val.MetaEncoder.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "numpy.prod", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "position_resolution", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "position_resolution", "is", "not", "None", ":", "\n", "            ", "width", "=", "position_resolution", "[", "-", "1", "]", "\n", "self", ".", "position_resolution", "=", "position_resolution", "[", ":", "-", "1", "]", "\n", "positions", "=", "np", ".", "prod", "(", "self", ".", "position_resolution", ")", "+", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "position_resolution", "=", "None", "\n", "width", ",", "positions", "=", "0", ",", "0", "\n", "", "scale", "=", "width", "**", "-", "0.5", "if", "width", ">", "0", "else", "0", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "positions", ",", "width", ")", ")", "\n", "self", ".", "class_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ")", ")", "#None # `<s>` as the class ", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.Miscellanea.initialize_parameters": [[50, 52], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.AddonEncoder.__init__": [[57, 59], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.AddonEncoder.forward": [[60, 62], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.CLIPMisc.__init__": [[67, 70], ["val.Miscellanea.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "position_resolution", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "position_resolution", "=", "position_resolution", ",", "**", "kwargs", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.CLIPMisc.replace_modules": [[71, 75], ["None"], "methods", ["None"], ["", "def", "replace_modules", "(", "self", ",", "reference", ",", "keep_hp", "=", "False", ")", ":", "\n", "        ", "self", ".", "positional_embedding", ",", "self", ".", "class_embedding", "=", "reference", ".", "positional_embedding", ",", "reference", ".", "class_embedding", "\n", "if", "not", "keep_hp", ":", "\n", "            ", "self", ".", "position_resolution", "=", "reference", ".", "position_resolution", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.CLIPMisc.hp": [[80, 83], ["None"], "methods", ["None"], ["", "@", "hp", ".", "setter", "\n", "def", "hp", "(", "self", ",", "hp", ")", ":", "\n", "        ", "(", "self", ".", "position_resolution", ",", ")", "=", "hp", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.CLIPMisc.pos_embedding": [[84, 89], ["val.interp_clip_vp_embedding"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_clip_vp_embedding"], ["", "@", "property", "\n", "def", "pos_embedding", "(", "self", ")", ":", "\n", "        ", "positional_embedding", "=", "interp_clip_vp_embedding", "(", "self", ".", "positional_embedding", ",", "self", ".", "position_resolution", ")", "\n", "#print(f\"{self.positional_embedding.shape} {self.position_resolution} {positional_embedding.shape}\")", "\n", "return", "positional_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.CLIPMisc.cls_embedding": [[90, 93], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "cls_embedding", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "class_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.GPTPreEncoder.__init__": [[96, 101], ["val.MetaEncoder.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "val.GPTPreEncoder.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "512", ",", "ctx_len", "=", "77", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "position_resolution", "=", "(", "ctx_len", ",", "width", ")", "\n", "self", ".", "token_embedding", "=", "nn", ".", "Embedding", "(", "cfg", ".", "vocab_size", ",", "width", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.GPTPreEncoder.initialize_parameters": [[102, 104], ["torch.nn.init.normal_", "torch.nn.init.normal_"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "token_embedding", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.GPTPreEncoder.dtype": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token_embedding", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.GPTPreEncoder.forward": [[109, 123], ["val.GPTPreEncoder.argmax", "val.GPTPreEncoder.token_embedding().type", "positional_embedding.type", "val.GPTPreEncoder.token_embedding"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "positional_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "class_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "# take features from the eot embedding (eot_token is the highest number in each sequence)", "\n", "# saved for the post encoder", "\n", "        ", "self", ".", "mask", "=", "x", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "x", "=", "self", ".", "token_embedding", "(", "x", ")", ".", "type", "(", "self", ".", "dtype", ")", "# [batch_size, n_ctx, d_model]", "\n", "positional_embedding", "=", "positional_embedding", "[", ":", "x", ".", "shape", "[", "1", "]", "]", "\n", "x", "=", "x", "+", "positional_embedding", ".", "type", "(", "self", ".", "dtype", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.GPTPostEncoder.__init__": [[126, 132], ["val.MetaEncoder.__init__", "clip.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "val.GPTPostEncoder.initialize_parameters", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "512", ",", "embed_dim", "=", "512", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "scale", "=", "width", "**", "-", "0.5", "\n", "self", ".", "ln", "=", "LayerNorm", "(", "width", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ",", "embed_dim", ")", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.GPTPostEncoder.initialize_parameters": [[133, 135], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.GPTPostEncoder.forward": [[136, 147], ["val.GPTPostEncoder.ln().type", "val.GPTPostEncoder.ln", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "positional_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "class_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "mask", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "dtype", "=", "x", ".", "dtype", "\n", "x", "=", "self", ".", "ln", "(", "x", ")", ".", "type", "(", "dtype", ")", "\n", "# x.shape = [batch_size, n_ctx, transformer.width]", "\n", "x", "=", "x", "[", "torch", ".", "arange", "(", "x", ".", "shape", "[", "0", "]", ")", ",", "mask", "]", "@", "self", ".", "proj", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPreEncoder.__init__": [[194, 206], ["val.MetaEncoder.__init__", "val._vit_position_resolution", "torch.nn.Conv2d", "torch.nn.Conv2d", "clip.LayerNorm", "val.ViTPreEncoder.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val._vit_position_resolution", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "768", ",", "resolution", "=", "224", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", ",", "_", ",", "self", ".", "position_resolution", "=", "_vit_position_resolution", "(", "\n", "resolution", ",", "cfg", ".", "patch_size", ",", "cfg", ".", "stride", "\n", ")", "\n", "self", ".", "position_resolution", "+=", "(", "width", ",", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "cfg", ".", "in_channels", ",", "out_channels", "=", "width", ",", "kernel_size", "=", "cfg", ".", "patch_size", ",", "stride", "=", "self", ".", "stride", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "patch_size", "=", "self", ".", "conv1", ".", "weight", ".", "shape", "[", "-", "2", ":", "]", "\n", "self", ".", "ln", "=", "LayerNorm", "(", "width", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPreEncoder.initialize_parameters": [[207, 209], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPreEncoder.replace_modules": [[210, 215], ["None"], "methods", ["None"], ["", "def", "replace_modules", "(", "self", ",", "reference", ",", "keep_hp", "=", "False", ")", ":", "\n", "        ", "self", ".", "conv1", ",", "self", ".", "ln", "=", "reference", ".", "conv1", ",", "reference", ".", "ln", "\n", "if", "not", "keep_hp", ":", "\n", "            ", "self", ".", "stride", ",", "self", ".", "patch_size", ",", "self", ".", "position_resolution", "=", "reference", ".", "stride", ",", "reference", ".", "patch_size", ",", "reference", ".", "position_resolution", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPreEncoder.hp": [[220, 223], ["None"], "methods", ["None"], ["", "@", "hp", ".", "setter", "\n", "def", "hp", "(", "self", ",", "hp", ")", ":", "\n", "        ", "(", "self", ".", "stride", ",", "self", ".", "patch_size", ",", "self", ".", "position_resolution", ")", "=", "hp", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPreEncoder.dtype": [[224, 227], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv1", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPreEncoder.forward": [[228, 260], ["val.ViTPreEncoder.type", "val.ViTPreEncoder.reshape", "val.ViTPreEncoder.permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "val.ViTPreEncoder.ln", "val.ViTPreEncoder.dim", "val.interp_conv_weight_spatial", "torch.conv2d", "torch.conv2d", "val.ViTPreEncoder.conv1", "positional_embedding[].to", "val.ViTPreEncoder.dim", "interp_conv_weight_spatial.mean", "val.interp_conv_weight_channel", "class_embedding.to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_conv_weight_spatial", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_conv_weight_channel"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "positional_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "class_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "assert", "x", ".", "dim", "(", ")", "==", "4", ",", "f\"expect 4d `x` but get x.dim == {x.dim()}\"", "\n", "x", "=", "x", ".", "type", "(", "self", ".", "dtype", ")", "\n", "if", "x", ".", "shape", "[", "1", "]", "!=", "3", ":", "# interpolate weight", "\n", "            ", "use_mean", "=", "True", "\n", "conv1_weight", "=", "interp_conv_weight_spatial", "(", "self", ".", "conv1", ".", "weight", ",", "self", ".", "patch_size", ")", "\n", "#print(f\"{self.conv1.weight.shape}, {conv1_weight.shape}, {self.patch_size}, {self.conv1.stride}, {self.stride}\")", "\n", "if", "x", ".", "shape", "[", "1", "]", "!=", "conv1_weight", ".", "shape", "[", "1", "]", ":", "# channel", "\n", "                ", "conv1_weight", "=", "(", "\n", "conv1_weight", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "if", "use_mean", "else", "\n", "interp_conv_weight_channel", "(", "conv1_weight", ",", "x", ".", "shape", ")", "\n", ")", "\n", "", "x", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "conv1_weight", ",", "bias", "=", "self", ".", "conv1", ".", "bias", ",", "stride", "=", "self", ".", "stride", "\n", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "# shape = [*, width, grid, grid]", "\n", "#print(f\"{self.conv1.weight.shape}, {self.patch_size}, {self.conv1.stride}, {self.stride}\")", "\n", "", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "# shape = [*, width, grid ** 2]", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# shape = [*, grid ** 2, width]", "\n", "x", "=", "torch", ".", "cat", "(", "[", "\n", "class_embedding", ".", "to", "(", "x", ".", "dtype", ")", "+", "torch", ".", "zeros", "(", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ",", "x", "\n", "]", ",", "dim", "=", "1", ")", "# shape = [*, grid ** 2 + 1, width]", "\n", "#print(f\"C {x.shape}, {positional_embedding.shape}, {self.position_resolution}\")", "\n", "x", "=", "x", "+", "positional_embedding", "[", ":", "x", ".", "shape", "[", "1", "]", "]", ".", "to", "(", "x", ".", "dtype", ")", "\n", "x", "=", "self", ".", "ln", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPostEncoder.__init__": [[263, 269], ["val.MetaEncoder.__init__", "clip.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "val.ViTPostEncoder.initialize_parameters", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "768", ",", "embed_dim", "=", "512", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "scale", "=", "width", "**", "-", "0.5", "\n", "self", ".", "ln", "=", "LayerNorm", "(", "width", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ",", "embed_dim", ")", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPostEncoder.initialize_parameters": [[270, 272], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ViTPostEncoder.forward": [[273, 291], ["val.ViTPostEncoder.ln", "val.ViTPostEncoder.ln", "feature.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "positional_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "class_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "position_resolution", ":", "list", "=", "None", ",", "\n", "require_feature", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "if", "require_feature", ":", "# Transformer encoder-decoder model", "\n", "            ", "x", "=", "self", ".", "ln", "(", "x", ")", "\n", "feature", "=", "x", "[", ":", ",", "1", ":", "]", "\n", "N", ",", "_", ",", "D", "=", "feature", ".", "shape", "\n", "nrow", ",", "ncol", "=", "position_resolution", "\n", "feature", "=", "feature", ".", "view", "(", "N", ",", "nrow", ",", "ncol", ",", "D", ")", "\n", "return", "x", "[", ":", ",", "0", ",", ":", "]", "@", "self", ".", "proj", ",", "feature", "\n", "", "x", "=", "self", ".", "ln", "(", "x", "[", ":", ",", "0", ",", ":", "]", ")", "\n", "x", "=", "x", "@", "self", ".", "proj", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPreEncoder.__init__": [[312, 324], ["val.MetaEncoder.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "val.ResNetPreEncoder.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "64", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# the 3-layer stem", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "cfg", ".", "in_channels", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "width", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPreEncoder.initialize_parameters": [[325, 327], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPreEncoder.dtype": [[328, 331], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv1", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPreEncoder.forward": [[332, 356], ["val.ResNetPreEncoder.type", "val.ResNetPreEncoder.relu", "val.ResNetPreEncoder.avgpool", "val.ResNetPreEncoder.dim", "torch.conv2d", "torch.conv2d", "val.ResNetPreEncoder.conv1", "val.ResNetPreEncoder.bn1", "val.ResNetPreEncoder.relu", "val.ResNetPreEncoder.dim", "val.ResNetPreEncoder.conv1.weight.mean", "val.interp_conv_weight_channel", "bn", "conv"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_conv_weight_channel"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "positional_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "class_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "assert", "x", ".", "dim", "(", ")", "==", "4", ",", "f\"expect 4d `x` but get x.dim == {x.dim()}\"", "\n", "x", "=", "x", ".", "type", "(", "self", ".", "dtype", ")", "\n", "if", "x", ".", "shape", "[", "1", "]", "!=", "3", ":", "# interpolate weight", "\n", "            ", "use_mean", "=", "True", "\n", "conv1_weight", "=", "(", "\n", "self", ".", "conv1", ".", "weight", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "if", "use_mean", "else", "\n", "interp_conv_weight_channel", "(", "self", ".", "conv1", ".", "weight", ",", "x", ".", "shape", ")", "\n", ")", "\n", "x", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "conv1_weight", ",", "bias", "=", "self", ".", "conv1", ".", "bias", ",", "stride", "=", "self", ".", "conv1", ".", "stride", ",", "padding", "=", "self", ".", "conv1", ".", "padding", "\n", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "# shape = [*, width, grid, grid]", "\n", "", "x", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "for", "conv", ",", "bn", "in", "[", "(", "self", ".", "conv2", ",", "self", ".", "bn2", ")", ",", "(", "self", ".", "conv3", ",", "self", ".", "bn3", ")", "]", ":", "\n", "            ", "x", "=", "self", ".", "relu", "(", "bn", "(", "conv", "(", "x", ")", ")", ")", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPostEncoder.__init__": [[359, 372], ["val.MetaEncoder.__init__", "val._resnet_position_resolution", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "val.ResNetPostEncoder.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val._resnet_position_resolution", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "64", ",", "embed_dim", "=", "None", ",", "resolution", "=", "224", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "width", "=", "width", "*", "32", "# the ResNet feature dimension", "\n", "self", ".", "num_heads", "=", "width", "//", "64", "\n", "\n", "_", ",", "_", ",", "self", ".", "position_resolution", "=", "_resnet_position_resolution", "(", "resolution", ")", "\n", "self", ".", "position_resolution", "+=", "(", "width", ",", ")", "\n", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "width", ",", "width", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "width", ",", "width", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "width", ",", "width", ")", "\n", "self", ".", "c_proj", "=", "nn", ".", "Linear", "(", "width", ",", "embed_dim", "or", "width", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPostEncoder.initialize_parameters": [[373, 379], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "std", "=", "self", ".", "c_proj", ".", "in_features", "**", "-", "0.5", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "q_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "k_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "v_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "c_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPostEncoder.replace_modules": [[380, 386], ["None"], "methods", ["None"], ["", "def", "replace_modules", "(", "self", ",", "reference", ",", "keep_hp", "=", "False", ")", ":", "\n", "        ", "self", ".", "k_proj", ",", "self", ".", "q_proj", ",", "self", ".", "v_proj", ",", "self", ".", "c_proj", "=", "(", "\n", "reference", ".", "k_proj", ",", "reference", ".", "q_proj", ",", "reference", ".", "v_proj", ",", "reference", ".", "c_proj", "\n", ")", "\n", "if", "not", "keep_hp", ":", "\n", "            ", "self", ".", "position_resolution", "=", "reference", ".", "position_resolution", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPostEncoder.hp": [[391, 394], ["None"], "methods", ["None"], ["", "@", "hp", ".", "setter", "\n", "def", "hp", "(", "self", ",", "hp", ")", ":", "\n", "        ", "(", "self", ".", "position_resolution", ",", ")", "=", "hp", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetPostEncoder.forward": [[395, 425], ["torch.cat.reshape().permute", "torch.cat.reshape().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "positional_embedding[].to", "torch.cat.reshape", "torch.cat.reshape", "torch.cat.mean", "torch.cat.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ":", "torch", ".", "Tensor", ",", "\n", "positional_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "class_embedding", ":", "torch", ".", "Tensor", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# NCHW -> (HW)NC", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ",", "x", "]", ",", "dim", "=", "0", ")", "# (HW+1)NC", "\n", "#print(f\"C {x.shape}, {positional_embedding.shape}, {self.position_resolution}\")", "\n", "x", "=", "x", "+", "positional_embedding", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "None", ",", ":", "]", ".", "to", "(", "x", ".", "dtype", ")", "# (HW+1)NC", "\n", "x", ",", "_", "=", "F", ".", "multi_head_attention_forward", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "\n", "embed_dim_to_check", "=", "x", ".", "shape", "[", "-", "1", "]", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ",", "\n", "in_proj_weight", "=", "None", ",", "\n", "in_proj_bias", "=", "torch", ".", "cat", "(", "[", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", "]", ")", ",", "\n", "bias_k", "=", "None", ",", "\n", "bias_v", "=", "None", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "dropout_p", "=", "0", ",", "\n", "out_proj_weight", "=", "self", ".", "c_proj", ".", "weight", ",", "\n", "out_proj_bias", "=", "self", ".", "c_proj", ".", "bias", ",", "\n", "use_separate_proj_weight", "=", "True", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "need_weights", "=", "False", "\n", ")", "\n", "return", "x", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetBackbone.__init__": [[428, 441], ["val.MetaEncoder.__init__", "val.ResNetBackbone._make_layer", "val.ResNetBackbone._make_layer", "val.ResNetBackbone._make_layer", "val.ResNetBackbone._make_layer", "val.ResNetBackbone.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "64", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch_first", "=", "True", "\n", "layers", "=", "cfg", ".", "layers", "\n", "\n", "# residual layers", "\n", "self", ".", "_inplanes", "=", "width", "# this is a *mutable* variable used during construction", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "width", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "width", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "width", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "width", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetBackbone._make_layer": [[442, 450], ["range", "torch.nn.Sequential", "torch.nn.Sequential", "clip.Bottleneck", "layers.append", "clip.Bottleneck"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "layers", "=", "[", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ",", "stride", ")", "]", "\n", "\n", "self", ".", "_inplanes", "=", "planes", "*", "Bottleneck", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetBackbone.initialize_parameters": [[451, 456], ["resnet_block.named_parameters", "name.endswith", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "for", "resnet_block", "in", "[", "self", ".", "layer1", ",", "self", ".", "layer2", ",", "self", ".", "layer3", ",", "self", ".", "layer4", "]", ":", "\n", "            ", "for", "name", ",", "param", "in", "resnet_block", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "name", ".", "endswith", "(", "\"bn3.weight\"", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetBackbone.dtype": [[457, 460], ["None"], "methods", ["None"], ["", "", "", "", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv1", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResNetBackbone.forward": [[461, 467], ["val.ResNetBackbone.layer1", "val.ResNetBackbone.layer2", "val.ResNetBackbone.layer3", "val.ResNetBackbone.layer4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.TransformerBackbone.__init__": [[470, 482], ["val.MetaEncoder.__init__", "val.TransformerBackbone.build_attention_mask", "torch.nn.Sequential", "torch.nn.Sequential", "val.ResidualAttentionBlock", "range"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.build_attention_mask"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "width", "=", "512", ",", "ctx_len", "=", "77", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch_first", "=", "False", "\n", "self", ".", "ctx_len", "=", "ctx_len", "\n", "heads", "=", "width", "//", "64", "\n", "\n", "attn_mask", "=", "self", ".", "build_attention_mask", "(", ")", "\n", "\n", "self", ".", "resblocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "ResidualAttentionBlock", "(", "\n", "width", ",", "heads", ",", "attn_mask", ",", "cfg", ".", "skip_attn_mask", "\n", ")", "for", "_", "in", "range", "(", "cfg", ".", "layers", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.TransformerBackbone.build_attention_mask": [[484, 492], ["torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.fill_", "torch.empty.fill_", "torch.empty.triu_", "torch.empty.triu_", "float"], "methods", ["None"], ["", "def", "build_attention_mask", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "ctx_len", "is", "None", ":", "\n", "            ", "return", "None", "\n", "# pytorch uses additive attention mask; fill with -inf", "\n", "", "mask", "=", "torch", ".", "empty", "(", "self", ".", "ctx_len", ",", "self", ".", "ctx_len", ")", "\n", "mask", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "mask", ".", "triu_", "(", "1", ")", "# zero out the lower diagonal", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.TransformerBackbone.forward": [[493, 495], ["val.TransformerBackbone.resblocks"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "resblocks", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResidualAttentionBlock.__init__": [[497, 510], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "clip.LayerNorm", "torch.nn.Sequential", "torch.nn.Sequential", "clip.LayerNorm", "collections.OrderedDict", "torch.nn.Linear", "torch.nn.Linear", "clip.QuickGELU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ":", "int", ",", "n_head", ":", "int", ",", "attn_mask", ":", "torch", ".", "Tensor", "=", "None", ",", "skip_attn_mask", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "n_head", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"c_fc\"", ",", "nn", ".", "Linear", "(", "d_model", ",", "d_model", "*", "4", ")", ")", ",", "\n", "(", "\"gelu\"", ",", "QuickGELU", "(", ")", ")", ",", "\n", "(", "\"c_proj\"", ",", "nn", ".", "Linear", "(", "d_model", "*", "4", ",", "d_model", ")", ")", "\n", "]", ")", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "skip_attn_mask", "=", "skip_attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResidualAttentionBlock.attention": [[511, 518], ["val.ResidualAttentionBlock.attn_mask.to", "val.ResidualAttentionBlock.attn"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "if", "not", "self", ".", "skip_attn_mask", "and", "self", ".", "attn_mask", "is", "not", "None", ":", "\n", "            ", "self", ".", "attn_mask", "=", "self", ".", "attn_mask", ".", "to", "(", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "attn_mask", "=", "self", ".", "attn_mask", "[", ":", "x", ".", "shape", "[", "0", "]", ",", ":", "x", ".", "shape", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "return", "self", ".", "attn", "(", "x", ",", "x", ",", "x", ",", "need_weights", "=", "False", ",", "attn_mask", "=", "attn_mask", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.ResidualAttentionBlock.forward": [[519, 523], ["val.ResidualAttentionBlock.attention", "val.ResidualAttentionBlock.mlp", "val.ResidualAttentionBlock.ln_1", "val.ResidualAttentionBlock.ln_2"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ResidualAttentionBlock.attention"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "attention", "(", "self", ".", "ln_1", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.build_encoder_module": [[17, 19], ["ENCODER_MODULES_REGISTRY.get"], "function", ["None"], ["def", "build_encoder_module", "(", "cfg", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "ENCODER_MODULES_REGISTRY", ".", "get", "(", "cfg", ".", "name", ")", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val._vit_position_resolution": [[148, 168], ["isinstance", "list", "isinstance", "list", "isinstance"], "function", ["None"], ["", "", "def", "_vit_position_resolution", "(", "input_resolution", ",", "patch_size", ",", "stride", ")", ":", "\n", "    ", "stride", "=", "stride", "or", "patch_size", "\n", "if", "isinstance", "(", "stride", ",", "int", ")", ":", "\n", "        ", "stride", "=", "[", "stride", "]", "*", "2", "\n", "", "stride", "=", "list", "(", "stride", ")", "\n", "if", "isinstance", "(", "patch_size", ",", "int", ")", ":", "\n", "        ", "patch_size", "=", "[", "patch_size", "]", "*", "2", "\n", "", "patch_size", "=", "list", "(", "patch_size", ")", "\n", "\n", "if", "isinstance", "(", "input_resolution", ",", "int", ")", ":", "\n", "        ", "nrow", "=", "ncol", "=", "input_resolution", "//", "patch_size", "[", "0", "]", "\n", "positions", "=", "nrow", "**", "2", "+", "1", "# ", "\n", "position_resolution", "=", "(", "nrow", ",", "ncol", ")", "\n", "", "else", ":", "\n", "        ", "row_stride", ",", "col_stride", "=", "stride", "[", ":", "2", "]", "\n", "nrow", "=", "(", "input_resolution", "[", "0", "]", "-", "patch_size", "[", "0", "]", ")", "//", "row_stride", "+", "1", "\n", "ncol", "=", "(", "input_resolution", "[", "1", "]", "-", "patch_size", "[", "1", "]", ")", "//", "col_stride", "+", "1", "\n", "positions", "=", "nrow", "*", "ncol", "+", "1", "\n", "position_resolution", "=", "(", "nrow", ",", "ncol", ")", "\n", "", "return", "stride", ",", "positions", ",", "position_resolution", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_conv_weight_channel": [[169, 181], ["conv_weight.permute.permute", "torch.interpolate", "conv_weight.permute.permute"], "function", ["None"], ["", "def", "interp_conv_weight_channel", "(", "conv_weight", ",", "input_shape", ")", ":", "\n", "    ", "if", "conv_weight", ".", "shape", "[", "1", "]", "!=", "input_shape", "[", "1", "]", ":", "\n", "        ", "input_shape", "=", "(", "conv_weight", ".", "shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ")", "\n", "conv_weight", "=", "conv_weight", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "conv_weight", "=", "F", ".", "interpolate", "(", "\n", "conv_weight", ",", "\n", "input_shape", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n", "conv_weight", "=", "conv_weight", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "", "return", "conv_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_conv_weight_spatial": [[182, 191], ["torch.interpolate"], "function", ["None"], ["", "def", "interp_conv_weight_spatial", "(", "conv_weight", ",", "patch_shape", ")", ":", "\n", "    ", "if", "conv_weight", ".", "shape", "[", "-", "2", ":", "]", "!=", "patch_shape", ":", "\n", "        ", "conv_weight", "=", "F", ".", "interpolate", "(", "\n", "conv_weight", ",", "\n", "patch_shape", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n", "", "return", "conv_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val._resnet_position_resolution": [[292, 309], ["isinstance", "list", "isinstance"], "function", ["None"], ["", "", "def", "_resnet_position_resolution", "(", "input_resolution", ",", "patch_size", "=", "32", ",", "stride", "=", "None", ")", ":", "\n", "    ", "stride", "=", "stride", "or", "patch_size", "\n", "if", "isinstance", "(", "stride", ",", "int", ")", ":", "\n", "        ", "stride", "=", "[", "stride", "]", "*", "2", "\n", "", "stride", "=", "list", "(", "stride", ")", "\n", "\n", "if", "isinstance", "(", "input_resolution", ",", "int", ")", ":", "\n", "        ", "nrow", "=", "ncol", "=", "input_resolution", "//", "patch_size", "\n", "positions", "=", "nrow", "**", "2", "+", "1", "# ", "\n", "position_resolution", "=", "(", "nrow", ",", "ncol", ")", "\n", "", "else", ":", "\n", "        ", "row_stride", ",", "col_stride", "=", "stride", "[", ":", "2", "]", "\n", "nrow", "=", "(", "input_resolution", "[", "0", "]", "-", "0", ")", "//", "row_stride", "\n", "ncol", "=", "(", "input_resolution", "[", "1", "]", "-", "0", ")", "//", "col_stride", "\n", "positions", "=", "nrow", "*", "ncol", "+", "1", "\n", "position_resolution", "=", "(", "nrow", ",", "ncol", ")", "\n", "", "return", "stride", ",", "positions", ",", "position_resolution", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_clip_vp_embedding": [[524, 557], ["numpy.prod", "old_pos_emb[].reshape().permute", "int", "torch.interpolate().permute().flatten", "torch.cat", "torch.cat", "numpy.sqrt", "old_pos_emb[].reshape", "torch.interpolate().permute", "torch.cat.view", "torch.interpolate"], "function", ["None"], ["", "", "def", "interp_clip_vp_embedding", "(", "old_pos_emb", ",", "pos_resolution", ",", "old_pos_resolution", "=", "None", ",", "bop", "=", "1", ")", ":", "\n", "    ", "\"\"\" vp: stands for `visual positional`\n        bop: start position of the postional embeddings\n        old_pos_emb: (H x W + 1, D)\n    \"\"\"", "\n", "num_pos", ",", "pos_dim", "=", "old_pos_emb", ".", "shape", "[", "-", "2", ":", "]", "\n", "num_pos_required", "=", "np", ".", "prod", "(", "pos_resolution", ")", "\n", "# TODO assumed old_pos_emb comes from vision pos, but it can come from audio pos", "\n", "# if these two kinds do not share, we do not need to interp the input pos.", "\n", "# FIXME adhoc: the condition of not sharing may be wrong.", "\n", "if", "num_pos_required", "+", "1", "==", "num_pos", ":", "\n", "        ", "return", "old_pos_emb", "\n", "", "if", "old_pos_resolution", "is", "None", ":", "\n", "# old_pos_emb must be vision pos if sharing pos between vision and audio", "\n", "        ", "h", "=", "w", "=", "int", "(", "np", ".", "sqrt", "(", "num_pos", "-", "bop", ")", ")", "\n", "", "else", ":", "# should have fixed the TODO", "\n", "        ", "h", ",", "w", "=", "old_pos_resolution", "\n", "", "ptensor", "=", "old_pos_emb", "[", "bop", ":", "]", ".", "reshape", "(", "\n", "-", "1", ",", "h", ",", "w", ",", "pos_dim", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "if", "ptensor", ".", "shape", "[", "-", "2", ":", "]", "!=", "pos_resolution", ":", "\n", "        ", "new_pos_emb", "=", "F", ".", "interpolate", "(", "\n", "ptensor", ",", "\n", "pos_resolution", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "1", ",", "2", ")", "\n", "new_pos_emb", "=", "torch", ".", "cat", "(", "(", "\n", "old_pos_emb", "[", ":", "bop", "]", ",", "new_pos_emb", ".", "view", "(", "-", "1", ",", "pos_dim", ")", "\n", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "# do nothing", "\n", "        ", "new_pos_emb", "=", "old_pos_emb", "\n", "", "return", "new_pos_emb", "\n", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.resnet.AttentionPool2d.__init__": [[8, 16], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "positions", ":", "int", ",", "embed_dim", ":", "int", ",", "num_heads", ":", "int", ",", "output_dim", ":", "int", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "positions", ",", "embed_dim", ")", "/", "embed_dim", "**", "0.5", ")", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "c_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "output_dim", "or", "embed_dim", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.resnet.AttentionPool2d.forward": [[17, 42], ["torch.cat.reshape().permute", "torch.cat.reshape().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "resnet.AttentionPool2d.positional_embedding[].to", "torch.cat.reshape", "torch.cat.reshape", "torch.cat.mean", "torch.cat.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# NCHW -> (HW)NC", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ",", "x", "]", ",", "dim", "=", "0", ")", "# (HW+1)NC", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", "[", ":", ",", "None", ",", ":", "]", ".", "to", "(", "x", ".", "dtype", ")", "# (HW+1)NC", "\n", "x", ",", "_", "=", "F", ".", "multi_head_attention_forward", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "\n", "embed_dim_to_check", "=", "x", ".", "shape", "[", "-", "1", "]", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ",", "\n", "in_proj_weight", "=", "None", ",", "\n", "in_proj_bias", "=", "torch", ".", "cat", "(", "[", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", "]", ")", ",", "\n", "bias_k", "=", "None", ",", "\n", "bias_v", "=", "None", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "dropout_p", "=", "0", ",", "\n", "out_proj_weight", "=", "self", ".", "c_proj", ".", "weight", ",", "\n", "out_proj_bias", "=", "self", ".", "c_proj", ".", "bias", ",", "\n", "use_separate_proj_weight", "=", "True", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "need_weights", "=", "False", "\n", ")", "\n", "\n", "return", "x", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.resnet.ModifiedResNet.__init__": [[51, 84], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "resnet.ModifiedResNet._make_layer", "resnet.ModifiedResNet._make_layer", "resnet.ModifiedResNet._make_layer", "resnet.ModifiedResNet._make_layer", "isinstance", "resnet.AttentionPool2d", "resnet.ModifiedResNet.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["def", "__init__", "(", "self", ",", "layers", ",", "output_dim", ",", "heads", ",", "input_resolution", "=", "224", ",", "width", "=", "64", ",", "in_channels", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "input_resolution", "=", "input_resolution", "\n", "\n", "# the 3-layer stem", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "width", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "# residual layers", "\n", "self", ".", "_inplanes", "=", "width", "# this is a *mutable* variable used during construction", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "width", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "width", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "width", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "width", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n", "if", "isinstance", "(", "input_resolution", ",", "int", ")", ":", "\n", "            ", "positions", "=", "(", "input_resolution", "//", "32", ")", "**", "2", "+", "1", "\n", "", "else", ":", "\n", "            ", "nrow", "=", "(", "input_resolution", "[", "0", "]", "-", "0", ")", "//", "32", "\n", "ncol", "=", "(", "input_resolution", "[", "1", "]", "-", "0", ")", "//", "32", "\n", "positions", "=", "nrow", "*", "ncol", "+", "1", "\n", "self", ".", "position_resolution", "=", "(", "nrow", ",", "ncol", ")", "\n", "\n", "", "embed_dim", "=", "width", "*", "32", "# the ResNet feature dimension", "\n", "self", ".", "attnpool", "=", "AttentionPool2d", "(", "positions", ",", "embed_dim", ",", "heads", ",", "output_dim", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.resnet.ModifiedResNet._make_layer": [[85, 93], ["range", "torch.nn.Sequential", "torch.nn.Sequential", "clip.Bottleneck", "layers.append", "clip.Bottleneck"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "layers", "=", "[", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ",", "stride", ")", "]", "\n", "\n", "self", ".", "_inplanes", "=", "planes", "*", "Bottleneck", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.resnet.ModifiedResNet.initialize_parameters": [[94, 105], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "resnet_block.named_parameters", "name.endswith", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "std", "=", "self", ".", "attnpool", ".", "c_proj", ".", "in_features", "**", "-", "0.5", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "q_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "k_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "v_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "c_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "\n", "for", "resnet_block", "in", "[", "self", ".", "layer1", ",", "self", ".", "layer2", ",", "self", ".", "layer3", ",", "self", ".", "layer4", "]", ":", "\n", "            ", "for", "name", ",", "param", "in", "resnet_block", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "name", ".", "endswith", "(", "\"bn3.weight\"", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.resnet.ModifiedResNet.dtype": [[106, 109], ["None"], "methods", ["None"], ["", "", "", "", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv1", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.resnet.ModifiedResNet.forward": [[110, 126], ["resnet.ModifiedResNet.type", "resnet.ModifiedResNet.forward.stem"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "def", "stem", "(", "x", ")", ":", "\n", "            ", "for", "conv", ",", "bn", "in", "[", "(", "self", ".", "conv1", ",", "self", ".", "bn1", ")", ",", "(", "self", ".", "conv2", ",", "self", ".", "bn2", ")", ",", "(", "self", ".", "conv3", ",", "self", ".", "bn3", ")", "]", ":", "\n", "                ", "x", "=", "self", ".", "relu", "(", "bn", "(", "conv", "(", "x", ")", ")", ")", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "return", "x", "\n", "\n", "", "x", "=", "x", ".", "type", "(", "self", ".", "dtype", ")", "\n", "x", "=", "stem", "(", "x", ")", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "x", "=", "self", ".", "attnpool", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.PatchEmbed.__init__": [[13, 39], ["torch.Module.__init__", "isinstance", "list", "list", "isinstance", "list", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "timm.models.layers.to_2tuple", "timm.models.layers.to_2tuple", "norm_layer", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["def", "__init__", "(", "\n", "self", ",", "img_size", "=", "224", ",", "patch_size", "=", "16", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "norm_layer", "=", "None", ",", "flatten", "=", "True", ",", "stride", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "patch_size", ",", "dict", ")", ":", "# hack", "\n", "            ", "patch_size", ",", "stride", "=", "patch_size", "[", "\"patch_size\"", "]", ",", "patch_size", "[", "\"stride\"", "]", "\n", "", "img_size", "=", "list", "(", "to_2tuple", "(", "img_size", ")", ")", "\n", "patch_size", "=", "list", "(", "to_2tuple", "(", "patch_size", ")", ")", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "stride", "=", "stride", "or", "patch_size", "\n", "if", "isinstance", "(", "stride", ",", "int", ")", ":", "\n", "            ", "stride", "=", "[", "stride", "]", "*", "2", "\n", "", "stride", "=", "list", "(", "stride", ")", "\n", "\n", "row_stride", ",", "col_stride", "=", "stride", "[", ":", "2", "]", "\n", "nrow", "=", "(", "img_size", "[", "0", "]", "-", "patch_size", "[", "0", "]", ")", "//", "row_stride", "+", "1", "\n", "ncol", "=", "(", "img_size", "[", "1", "]", "-", "patch_size", "[", "1", "]", ")", "//", "col_stride", "+", "1", "\n", "\n", "self", ".", "grid_size", "=", "(", "nrow", ",", "ncol", ")", "\n", "self", ".", "num_patches", "=", "self", ".", "grid_size", "[", "0", "]", "*", "self", ".", "grid_size", "[", "1", "]", "\n", "self", ".", "flatten", "=", "flatten", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "stride", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.PatchEmbed.forward": [[40, 55], ["deit.PatchEmbed.norm", "deit.PatchEmbed.proj.weight.mean", "torch.conv2d", "torch.conv2d", "torch.conv2d", "deit.PatchEmbed.proj", "x.flatten().transpose.flatten().transpose.flatten().transpose", "x.flatten().transpose.flatten().transpose.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "assert", "H", "==", "self", ".", "img_size", "[", "0", "]", "and", "W", "==", "self", ".", "img_size", "[", "1", "]", ",", "f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"", "\n", "if", "x", ".", "shape", "[", "1", "]", "!=", "self", ".", "proj", ".", "weight", ".", "shape", "[", "1", "]", ":", "# interpolate weight", "\n", "            ", "conv1_weight", "=", "self", ".", "proj", ".", "weight", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "conv1_weight", ",", "bias", "=", "self", ".", "proj", ".", "bias", ",", "stride", "=", "self", ".", "proj", ".", "stride", "\n", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "", "if", "self", ".", "flatten", ":", "\n", "            ", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "# BCHW -> BNC", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.DistilledVisionTransformer.__init__": [[57, 70], ["timm.models.vision_transformer.VisionTransformer.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "timm.models.layers.trunc_normal_", "timm.models.layers.trunc_normal_", "deit.DistilledVisionTransformer.head_dist.apply", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "output_dim", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dist_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "self", ".", "embed_dim", ")", ")", "\n", "num_patches", "=", "self", ".", "patch_embed", ".", "num_patches", "\n", "self", ".", "pos_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "num_patches", "+", "2", ",", "self", ".", "embed_dim", ")", ")", "\n", "self", ".", "head_dist", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "num_classes", ")", "if", "self", ".", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "dist_token", ",", "std", "=", ".02", ")", "\n", "trunc_normal_", "(", "self", ".", "pos_embed", ",", "std", "=", ".02", ")", "\n", "self", ".", "head_dist", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n", "scale", "=", "self", ".", "embed_dim", "**", "-", "0.5", "\n", "self", ".", "proj", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "self", ".", "embed_dim", ",", "output_dim", ")", ")", "if", "output_dim", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.DistilledVisionTransformer.forward_features": [[71, 96], ["deit.DistilledVisionTransformer.patch_embed", "deit.DistilledVisionTransformer.cls_token.expand", "deit.DistilledVisionTransformer.dist_token.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "deit.DistilledVisionTransformer.pos_drop", "deit.DistilledVisionTransformer.norm", "blk", "deit.DistilledVisionTransformer.pre_logits"], "methods", ["None"], ["", "def", "forward_features", "(", "self", ",", "x", ")", ":", "\n", "# taken from https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py", "\n", "# with slight modifications to add the dist_token", "\n", "        ", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "\n", "cls_tokens", "=", "self", ".", "cls_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "# stole cls_tokens impl from Phil Wang, thanks", "\n", "dist_token", "=", "self", ".", "dist_token", ".", "expand", "(", "B", ",", "-", "1", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "dist_token", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "\n", "x", "=", "x", "+", "self", ".", "pos_embed", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "x", "=", "blk", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "# non-linear operator because of Tanh activation function, it might be desired because we want to use", "\n", "# classification head as the head for contrastive learning ", "\n", "# still, we only want a simple projection layer", "\n", "if", "self", ".", "proj", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", "2", "]", "@", "self", ".", "proj", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "pre_logits", "(", "x", ")", "\n", "", "return", "x", "[", ":", ",", "0", "]", ",", "x", "[", ":", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.DistilledVisionTransformer.forward": [[97, 106], ["deit.DistilledVisionTransformer.forward_features", "deit.DistilledVisionTransformer.head", "deit.DistilledVisionTransformer.head_dist"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.DistilledVisionTransformer.forward_features"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", ",", "x_dist", "=", "self", ".", "forward_features", "(", "x", ")", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "x_dist", "=", "self", ".", "head_dist", "(", "x_dist", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "x", ",", "x_dist", "\n", "", "else", ":", "\n", "# during inference, return the average of both classifier predictions", "\n", "            ", "return", "(", "x", "+", "x_dist", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.__init__.DummyHead.__init__": [[22, 25], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "pass", "\n", "", "def", "from_pretrained", "(", "self", ",", "state_dict", ",", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.__init__.DummyHead.from_pretrained": [[25, 27], ["None"], "methods", ["None"], ["", "def", "from_pretrained", "(", "self", ",", "state_dict", ",", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.__init__.DummyHead.copy_state_dict": [[27, 29], ["None"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "return", "{", "}", ",", "{", "}", "\n", "", "def", "replace_modules", "(", "self", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.__init__.DummyHead.replace_modules": [[29, 31], ["None"], "methods", ["None"], ["", "def", "replace_modules", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "[", "]", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.__init__.DummyHead.forward": [[31, 33], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "None", "\n", "", "", "IMAGE_HEADS_REGISTRY", ".", "register", "(", "DummyHead", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.ResidualAttentionBlock.__init__": [[12, 24], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "clip.LayerNorm", "torch.nn.Sequential", "torch.nn.Sequential", "clip.LayerNorm", "collections.OrderedDict", "torch.nn.Linear", "torch.nn.Linear", "clip.QuickGELU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ":", "int", ",", "n_head", ":", "int", ",", "attn_mask", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "n_head", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"c_fc\"", ",", "nn", ".", "Linear", "(", "d_model", ",", "d_model", "*", "4", ")", ")", ",", "\n", "(", "\"gelu\"", ",", "QuickGELU", "(", ")", ")", ",", "\n", "(", "\"c_proj\"", ",", "nn", ".", "Linear", "(", "d_model", "*", "4", ",", "d_model", ")", ")", "\n", "]", ")", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.ResidualAttentionBlock.attention": [[25, 32], ["transformer.ResidualAttentionBlock.attn_mask.to", "transformer.ResidualAttentionBlock.attn"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "if", "self", ".", "attn_mask", "is", "not", "None", ":", "\n", "            ", "self", ".", "attn_mask", "=", "self", ".", "attn_mask", ".", "to", "(", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "attn_mask", "=", "self", ".", "attn_mask", "[", ":", "x", ".", "shape", "[", "0", "]", ",", ":", "x", ".", "shape", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "return", "self", ".", "attn", "(", "x", ",", "x", ",", "x", ",", "need_weights", "=", "False", ",", "attn_mask", "=", "attn_mask", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.ResidualAttentionBlock.forward": [[33, 37], ["transformer.ResidualAttentionBlock.attention", "transformer.ResidualAttentionBlock.mlp", "transformer.ResidualAttentionBlock.ln_1", "transformer.ResidualAttentionBlock.ln_2"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ResidualAttentionBlock.attention"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "attention", "(", "self", ".", "ln_1", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.GeneralResidualAttentionBlock.__init__": [[39, 56], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "clip.LayerNorm", "torch.nn.Sequential", "torch.nn.Sequential", "clip.LayerNorm", "collections.OrderedDict", "clip.LayerNorm", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "clip.QuickGELU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ":", "int", ",", "n_head", ":", "int", ",", "attn_mask", ":", "torch", ".", "Tensor", "=", "None", ",", "require_inter_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "n_head", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"c_fc\"", ",", "nn", ".", "Linear", "(", "d_model", ",", "d_model", "*", "4", ")", ")", ",", "\n", "(", "\"gelu\"", ",", "QuickGELU", "(", ")", ")", ",", "\n", "(", "\"c_proj\"", ",", "nn", ".", "Linear", "(", "d_model", "*", "4", ",", "d_model", ")", ")", "\n", "]", ")", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "\n", "self", ".", "require_inter_attn", "=", "require_inter_attn", "\n", "if", "self", ".", "require_inter_attn", ":", "\n", "            ", "self", ".", "attn_inter_ln", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "attn_inter", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "n_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.GeneralResidualAttentionBlock.attention": [[57, 64], ["transformer.GeneralResidualAttentionBlock.attn_mask.to", "transformer.GeneralResidualAttentionBlock.attn"], "methods", ["None"], ["", "", "def", "attention", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "if", "self", ".", "attn_mask", "is", "not", "None", ":", "\n", "            ", "self", ".", "attn_mask", "=", "self", ".", "attn_mask", ".", "to", "(", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "attn_mask", "=", "self", ".", "attn_mask", "[", ":", "x", ".", "shape", "[", "0", "]", ",", ":", "x", ".", "shape", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "return", "self", ".", "attn", "(", "x", ",", "x", ",", "x", ",", "need_weights", "=", "False", ",", "attn_mask", "=", "attn_mask", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.GeneralResidualAttentionBlock.forward": [[65, 76], ["isinstance", "transformer.GeneralResidualAttentionBlock.attention", "transformer.GeneralResidualAttentionBlock.attn_inter_ln", "transformer.GeneralResidualAttentionBlock.mlp", "transformer.GeneralResidualAttentionBlock.ln_1", "transformer.GeneralResidualAttentionBlock.ln_2", "transformer.GeneralResidualAttentionBlock.attn_inter"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ResidualAttentionBlock.attention"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "            ", "x", ",", "memory", "=", "x", "\n", "", "else", ":", "\n", "            ", "memory", "=", "None", "\n", "", "x", "=", "x", "+", "self", ".", "attention", "(", "self", ".", "ln_1", "(", "x", ")", ")", "\n", "if", "self", ".", "require_inter_attn", ":", "\n", "            ", "x", "=", "self", ".", "attn_inter_ln", "(", "x", ")", "\n", "x", "=", "x", "+", "self", ".", "attn_inter", "(", "x", ",", "memory", ",", "memory", ",", "need_weights", "=", "False", ")", "[", "0", "]", "\n", "", "x", "=", "x", "+", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "return", "x", ",", "memory", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.Transformer.__init__": [[78, 87], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "transformer.GeneralResidualAttentionBlock", "range"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "width", ":", "int", ",", "layers", ":", "int", ",", "heads", ":", "int", ",", "attn_mask", ":", "torch", ".", "Tensor", "=", "None", ",", "require_inter_attn", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "resblocks", "=", "nn", ".", "Sequential", "(", "*", "[", "\n", "#ResidualAttentionBlock(width, heads, attn_mask) for _ in range(layers)", "\n", "GeneralResidualAttentionBlock", "(", "width", ",", "heads", ",", "attn_mask", ",", "require_inter_attn", ")", "for", "_", "in", "range", "(", "layers", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.transformer.Transformer.forward": [[89, 92], ["transformer.Transformer.resblocks"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "memory", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "#return self.resblocks(x)", "\n", "        ", "return", "self", ".", "resblocks", "(", "(", "x", ",", "memory", ")", ")", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.txt.TextualTransformer.__init__": [[15, 43], ["torch.nn.Module.__init__", "Transformer", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "clip.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "txt.TextualTransformer.initialize_parameters", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "txt.TextualTransformer.build_attention_mask"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.build_attention_mask"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "width", ":", "int", ",", "\n", "layers", ":", "int", ",", "\n", "heads", ":", "int", ",", "\n", "ctx_len", ":", "int", ",", "\n", "vocab_size", ":", "int", ",", "\n", "output_dim", ":", "int", ",", "\n", "require_inter_attn", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ctx_len", "=", "ctx_len", "\n", "self", ".", "transformer", "=", "Transformer", "(", "\n", "width", "=", "width", ",", "\n", "layers", "=", "layers", ",", "\n", "heads", "=", "heads", ",", "\n", "attn_mask", "=", "self", ".", "build_attention_mask", "(", ")", ",", "\n", "require_inter_attn", "=", "require_inter_attn", ",", "\n", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "token_embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "width", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "ctx_len", ",", "width", ")", ")", "\n", "self", ".", "ln_final", "=", "LayerNorm", "(", "width", ")", "\n", "\n", "self", ".", "text_projection", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "width", ",", "output_dim", ")", ")", "\n", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.txt.TextualTransformer.initialize_parameters": [[44, 59], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "token_embedding", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "positional_embedding", ",", "std", "=", "0.01", ")", "\n", "\n", "proj_std", "=", "(", "self", ".", "transformer", ".", "width", "**", "-", "0.5", ")", "*", "(", "(", "2", "*", "self", ".", "transformer", ".", "layers", ")", "**", "-", "0.5", ")", "\n", "attn_std", "=", "self", ".", "transformer", ".", "width", "**", "-", "0.5", "\n", "fc_std", "=", "(", "2", "*", "self", ".", "transformer", ".", "width", ")", "**", "-", "0.5", "\n", "for", "block", "in", "self", ".", "transformer", ".", "resblocks", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "block", ".", "attn", ".", "in_proj_weight", ",", "std", "=", "attn_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "attn", ".", "out_proj", ".", "weight", ",", "std", "=", "proj_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "mlp", ".", "c_fc", ".", "weight", ",", "std", "=", "fc_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "mlp", ".", "c_proj", ".", "weight", ",", "std", "=", "proj_std", ")", "\n", "\n", "", "if", "self", ".", "text_projection", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "text_projection", ",", "std", "=", "self", ".", "transformer", ".", "width", "**", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.txt.TextualTransformer.build_attention_mask": [[60, 67], ["torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.fill_", "torch.empty.fill_", "torch.empty.triu_", "torch.empty.triu_", "float"], "methods", ["None"], ["", "", "def", "build_attention_mask", "(", "self", ")", ":", "\n", "# lazily create causal attention mask, with full attention between the vision tokens", "\n", "# pytorch uses additive attention mask; fill with -inf", "\n", "        ", "mask", "=", "torch", ".", "empty", "(", "self", ".", "ctx_len", ",", "self", ".", "ctx_len", ")", "\n", "mask", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "mask", ".", "triu_", "(", "1", ")", "# zero out the lower diagonal", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.txt.TextualTransformer.dtype": [[68, 71], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token_embedding", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.txt.TextualTransformer.forward": [[72, 91], ["txt.TextualTransformer.token_embedding().type", "txt.TextualTransformer.permute", "txt.TextualTransformer.transformer", "txt.TextualTransformer.permute", "txt.TextualTransformer.ln_final().type", "positional_embedding.type", "txt.TextualTransformer.token_embedding", "txt.TextualTransformer.ln_final", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "text.argmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "text", ",", "positional_embedding", "=", "None", ",", "memory", "=", "None", ",", "require_feature", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "token_embedding", "(", "text", ")", ".", "type", "(", "self", ".", "dtype", ")", "# [batch_size, n_ctx, d_model]", "\n", "\n", "positional_embedding", "=", "positional_embedding", "or", "self", ".", "positional_embedding", "\n", "positional_embedding", "=", "positional_embedding", "[", ":", "x", ".", "shape", "[", "1", "]", "]", "\n", "x", "=", "x", "+", "positional_embedding", ".", "type", "(", "self", ".", "dtype", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# NLD -> LND", "\n", "x", "=", "self", ".", "transformer", "(", "x", ",", "memory", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# LND -> NLD", "\n", "x", "=", "x_feature", "=", "self", ".", "ln_final", "(", "x", ")", ".", "type", "(", "self", ".", "dtype", ")", "\n", "\n", "# x.shape = [batch_size, n_ctx, transformer.width]", "\n", "# take features from the eot embedding (eot_token is the highest number in each sequence)", "\n", "x", "=", "x", "[", "torch", ".", "arange", "(", "x", ".", "shape", "[", "0", "]", ")", ",", "text", ".", "argmax", "(", "dim", "=", "-", "1", ")", "]", "@", "self", ".", "text_projection", "\n", "\n", "if", "require_feature", ":", "\n", "            ", "return", "x", ",", "x_feature", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveCLIPAudioHead.__init__": [[138, 161], ["torch.nn.Module.__init__", "isinstance", "ModifiedResNet", "VisualTransformer", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "cfg", ".", "layers", ",", "(", "tuple", ",", "list", ",", "ListConfig", ")", ")", ":", "\n", "            ", "heads", "=", "cfg", ".", "width", "*", "32", "//", "64", "\n", "self", ".", "encoder", "=", "ModifiedResNet", "(", "\n", "in_channels", "=", "getattr", "(", "cfg", ",", "\"in_channel\"", ",", "1", ")", ",", "\n", "input_resolution", "=", "cfg", ".", "resolution", ",", "\n", "output_dim", "=", "cfg", ".", "embed_dim", ",", "\n", "layers", "=", "cfg", ".", "layers", ",", "\n", "width", "=", "cfg", ".", "width", ",", "\n", "heads", "=", "heads", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "heads", "=", "cfg", ".", "width", "//", "64", "\n", "self", ".", "encoder", "=", "VisualTransformer", "(", "\n", "in_channels", "=", "getattr", "(", "cfg", ",", "\"in_channel\"", ",", "1", ")", ",", "\n", "stride", "=", "cfg", ".", "stride", ",", "\n", "input_resolution", "=", "cfg", ".", "resolution", ",", "\n", "output_dim", "=", "cfg", ".", "embed_dim", ",", "\n", "patch_size", "=", "cfg", ".", "patch_size", ",", "\n", "layers", "=", "cfg", ".", "layers", ",", "\n", "width", "=", "cfg", ".", "width", ",", "\n", "heads", "=", "heads", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveCLIPAudioHead.from_pretrained": [[163, 186], ["[].startswith", "audio_head.NaiveCLIPAudioHead.encoder.state_dict", "audio_head.position_resolution", "audio_head.load_pos_embedding", "audio_head.NaiveCLIPAudioHead.encoder.load_state_dict", "collections.OrderedDict", "state_dict.items", "isinstance", "re.sub", "state_dict.items", "list", "state_dict.keys"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.position_resolution", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.load_pos_embedding"], ["", "", "def", "from_pretrained", "(", "self", ",", "state_dict", ",", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "(", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "[", "0", "]", ")", ".", "startswith", "(", "\"encoder.\"", ")", ":", "\n", "            ", "audio_head_sd_new", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "k", "=", "re", ".", "sub", "(", "\"^encoder\\.\"", ",", "\"\"", ",", "k", ")", "\n", "audio_head_sd_new", "[", "k", "]", "=", "v", "\n", "", "state_dict", "=", "audio_head_sd_new", "\n", "", "excluded", "=", "[", "\"positional_embedding\"", ",", "\"attnpool.positional_embedding\"", "]", "\n", "new_dict", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", "\n", "old_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "k", "not", "in", "excluded", "}", "\n", "# interpolate positional embedding", "\n", "key", "=", "(", "\"attnpool.positional_embedding\"", "\n", "if", "isinstance", "(", "self", ".", "encoder", ",", "ModifiedResNet", ")", "else", "\"positional_embedding\"", "\n", ")", "\n", "new_pos_shape", "=", "self", ".", "encoder", ".", "position_resolution", "\n", "old_pos_shape", "=", "position_resolution", "(", "\n", "cfg", ".", "model", ".", "audio", ".", "resolution", ",", "cfg", ".", "model", ".", "audio", ".", "patch_size", ",", "cfg", ".", "model", ".", "audio", ".", "stride", "\n", ")", "# nrow always indicates the time dimenstion", "\n", "n_o", ",", "o_n", "=", "load_pos_embedding", "(", "\n", "state_dict", ",", "old_dict", ",", "new_dict", ",", "key", ",", "1", ",", "old_pos_shape", ",", "new_pos_shape", "\n", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "new_dict", ")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveCLIPAudioHead.copy_state_dict": [[187, 206], ["audio_head.NaiveCLIPAudioHead.encoder.state_dict", "audio_head.interp_conv_weight", "audio_head.interp_pos_embedding", "audio_head.NaiveCLIPAudioHead.encoder.load_state_dict", "interp_conv_weight.mean", "isinstance", "state_dict.items"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.interp_conv_weight", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.interp_pos_embedding"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "excluded", "=", "[", "\"conv1.weight\"", ",", "\"positional_embedding\"", ",", "\"attnpool.positional_embedding\"", "]", "\n", "new_dict", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", "\n", "old_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "k", "not", "in", "excluded", "}", "\n", "# conv1: 3 channels -> 1 channel", "\n", "conv_key", "=", "\"conv1.weight\"", "\n", "old_conv_weight", "=", "interp_conv_weight", "(", "state_dict", ",", "new_dict", ",", "conv_key", ")", "\n", "old_dict", "[", "conv_key", "]", "=", "(", "old_conv_weight", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "new_dict", "[", "conv_key", "]", ".", "shape", "[", "1", "]", "!=", "old_conv_weight", ".", "shape", "[", "1", "]", "else", "old_conv_weight", "\n", ")", "\n", "# interpolate positional embedding", "\n", "key", "=", "(", "\"attnpool.positional_embedding\"", "\n", "if", "isinstance", "(", "self", ".", "encoder", ",", "ModifiedResNet", ")", "else", "\"positional_embedding\"", "\n", ")", "\n", "n_o", ",", "o_n", "=", "interp_pos_embedding", "(", "\n", "state_dict", ",", "old_dict", ",", "new_dict", ",", "key", ",", "1", ",", "self", ".", "encoder", ".", "position_resolution", "\n", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "new_dict", ")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveCLIPAudioHead.forward": [[207, 213], ["audio_head.NaiveCLIPAudioHead.encoder", "kwargs.get", "audio_head.NaiveCLIPAudioHead.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "audios", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "z", "=", "self", ".", "encoder", "(", "audios", ")", "\n", "if", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "z", "=", "z", "/", "z", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} audio --{kwargs.get('normalized', False)}\")", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveDeiTAudioHead.__init__": [[216, 235], ["torch.nn.Module.__init__", "DistilledVisionTransformer", "getattr", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "heads", "=", "cfg", ".", "width", "//", "64", "\n", "self", ".", "encoder", "=", "DistilledVisionTransformer", "(", "\n", "img_size", "=", "cfg", ".", "resolution", ",", "\n", "# hack and has to be used with the customized `PatchEmbed`", "\n", "patch_size", "=", "{", "\"patch_size\"", ":", "cfg", ".", "patch_size", ",", "\"stride\"", ":", "cfg", ".", "stride", "}", ",", "\n", "representation_size", "=", "False", ",", "\n", "output_dim", "=", "cfg", ".", "embed_dim", ",", "\n", "embed_dim", "=", "cfg", ".", "width", ",", "\n", "depth", "=", "cfg", ".", "layers", ",", "\n", "num_heads", "=", "heads", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "in_chans", "=", "getattr", "(", "cfg", ",", "\"in_channel\"", ",", "1", ")", ",", "\n", "num_classes", "=", "-", "1", ",", "\n", "embed_layer", "=", "PatchEmbed", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveDeiTAudioHead.from_pretrained": [[237, 258], ["[].startswith", "audio_head.NaiveDeiTAudioHead.encoder.state_dict", "audio_head.position_resolution", "audio_head.load_pos_embedding", "audio_head.NaiveDeiTAudioHead.encoder.load_state_dict", "collections.OrderedDict", "state_dict.items", "re.sub", "state_dict.items", "list", "state_dict.keys"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.position_resolution", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.load_pos_embedding"], ["", "def", "from_pretrained", "(", "self", ",", "state_dict", ",", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "(", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "[", "0", "]", ")", ".", "startswith", "(", "\"encoder.\"", ")", ":", "\n", "            ", "audio_head_sd_new", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "k", "=", "re", ".", "sub", "(", "\"^encoder\\.\"", ",", "\"\"", ",", "k", ")", "\n", "audio_head_sd_new", "[", "k", "]", "=", "v", "\n", "", "state_dict", "=", "audio_head_sd_new", "\n", "", "excluded", "=", "[", "\"pos_embed\"", "]", "\n", "new_dict", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", "\n", "old_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "k", "not", "in", "excluded", "}", "\n", "# interpolate positional embedding", "\n", "key", "=", "\"pos_embed\"", "\n", "new_pos_shape", "=", "self", ".", "encoder", ".", "patch_embed", ".", "grid_size", "\n", "old_pos_shape", "=", "position_resolution", "(", "\n", "cfg", ".", "model", ".", "audio", ".", "resolution", ",", "cfg", ".", "model", ".", "audio", ".", "patch_size", ",", "cfg", ".", "model", ".", "audio", ".", "stride", "\n", ")", "# nrow always indicates the time dimenstion", "\n", "n_o", ",", "o_n", "=", "load_pos_embedding", "(", "\n", "state_dict", ",", "old_dict", ",", "new_dict", ",", "key", ",", "2", ",", "old_pos_shape", ",", "new_pos_shape", "\n", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "new_dict", ")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveDeiTAudioHead.copy_state_dict": [[259, 276], ["audio_head.NaiveDeiTAudioHead.encoder.state_dict", "audio_head.interp_conv_weight", "audio_head.interp_pos_embedding", "audio_head.NaiveDeiTAudioHead.encoder.load_state_dict", "interp_conv_weight.mean", "state_dict.items"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.interp_conv_weight", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.interp_pos_embedding"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "excluded", "=", "[", "\"patch_embed.proj.weight\"", ",", "\"pos_embed\"", "]", "\n", "new_dict", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", "\n", "old_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "k", "not", "in", "excluded", "and", "k", "in", "new_dict", "}", "\n", "# conv1: 3 channels -> 1 channel", "\n", "conv_key", "=", "\"patch_embed.proj.weight\"", "\n", "old_conv_weight", "=", "interp_conv_weight", "(", "state_dict", ",", "new_dict", ",", "conv_key", ")", "\n", "old_dict", "[", "conv_key", "]", "=", "(", "old_conv_weight", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "new_dict", "[", "conv_key", "]", ".", "shape", "[", "1", "]", "!=", "old_conv_weight", ".", "shape", "[", "1", "]", "else", "old_conv_weight", "\n", ")", "\n", "# interpolate positional embedding", "\n", "key", "=", "\"pos_embed\"", "\n", "n_o", ",", "o_n", "=", "interp_pos_embedding", "(", "\n", "state_dict", ",", "old_dict", ",", "new_dict", ",", "key", ",", "2", ",", "self", ".", "encoder", ".", "patch_embed", ".", "grid_size", "\n", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "new_dict", ")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.NaiveDeiTAudioHead.forward": [[277, 284], ["audio_head.NaiveDeiTAudioHead.encoder.forward_features", "kwargs.get", "z.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.DistilledVisionTransformer.forward_features"], ["", "def", "forward", "(", "self", ",", "audios", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cls_z", ",", "distilled_z", "=", "self", ".", "encoder", ".", "forward_features", "(", "audios", ")", "\n", "z", "=", "(", "cls_z", "+", "distilled_z", ")", "/", "2", "\n", "if", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "z", "=", "z", "/", "z", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} image --{kwargs.get('normalized', False)}\")", "\n", "", "return", "z", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head": [[25, 27], ["AUDIO_HEADS_REGISTRY.get"], "function", ["None"], ["def", "build_audio_head", "(", "cfg", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "AUDIO_HEADS_REGISTRY", ".", "get", "(", "cfg", ".", "name", ")", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.position_resolution": [[28, 41], ["list", "list", "isinstance", "list", "timm.models.layers.to_2tuple", "timm.models.layers.to_2tuple"], "function", ["None"], ["", "def", "position_resolution", "(", "input_resolution", ",", "patch_size", ",", "stride", ")", ":", "\n", "    ", "input_resolution", "=", "list", "(", "to_2tuple", "(", "input_resolution", ")", ")", "\n", "patch_size", "=", "list", "(", "to_2tuple", "(", "patch_size", ")", ")", "\n", "\n", "stride", "=", "stride", "or", "patch_size", "\n", "if", "isinstance", "(", "stride", ",", "int", ")", ":", "\n", "        ", "stride", "=", "[", "stride", "]", "*", "2", "\n", "", "stride", "=", "list", "(", "stride", ")", "\n", "\n", "row_stride", ",", "col_stride", "=", "stride", "[", ":", "2", "]", "\n", "nrow", "=", "(", "input_resolution", "[", "0", "]", "-", "patch_size", "[", "0", "]", ")", "//", "row_stride", "+", "1", "\n", "ncol", "=", "(", "input_resolution", "[", "1", "]", "-", "patch_size", "[", "1", "]", ")", "//", "col_stride", "+", "1", "\n", "return", "nrow", ",", "ncol", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.interp_conv_weight": [[42, 53], ["torch.interpolate"], "function", ["None"], ["", "def", "interp_conv_weight", "(", "old_dict", ",", "new_dict", ",", "key", ")", ":", "\n", "    ", "old_conv_weight", "=", "old_dict", "[", "key", "]", "\n", "new_conv_weight", "=", "new_dict", "[", "key", "]", "\n", "if", "new_conv_weight", ".", "shape", "[", "2", ":", "]", "!=", "old_conv_weight", ".", "shape", "[", "2", ":", "]", ":", "\n", "        ", "old_conv_weight", "=", "F", ".", "interpolate", "(", "\n", "old_conv_weight", ",", "\n", "new_conv_weight", ".", "shape", "[", "2", ":", "]", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n", "", "return", "old_conv_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.interp_pos_embedding": [[54, 88], ["int", "old_pos_emb[].reshape().permute", "torch.interpolate().permute().flatten", "torch.cat", "torch.cat", "set", "set", "new_dict.update", "old_pos_emb.squeeze.dim", "old_pos_emb.squeeze.squeeze", "numpy.sqrt", "torch.cat.unsqueeze", "new_dict.keys", "old_dict.keys", "old_pos_emb[].reshape", "torch.interpolate().permute", "torch.cat.view", "torch.interpolate"], "function", ["None"], ["", "def", "interp_pos_embedding", "(", "state_dict", ",", "old_dict", ",", "new_dict", ",", "key", ",", "bop", ",", "pos_resolution", ")", ":", "\n", "    ", "\"\"\"bop: start position of the postional embeddings\"\"\"", "\n", "add_leading_dim", "=", "False", "\n", "old_pos_emb", "=", "state_dict", "[", "key", "]", "\n", "if", "old_pos_emb", ".", "dim", "(", ")", "==", "3", ":", "# ensure of rank-2 tensor", "\n", "        ", "assert", "old_pos_emb", ".", "shape", "[", "0", "]", "==", "1", "\n", "old_pos_emb", "=", "old_pos_emb", ".", "squeeze", "(", "0", ")", "\n", "add_leading_dim", "=", "True", "\n", "", "num_pos", ",", "pos_dim", "=", "old_pos_emb", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "num_pos", "=", "int", "(", "np", ".", "sqrt", "(", "num_pos", "-", "bop", ")", ")", "\n", "ptensor", "=", "old_pos_emb", "[", "bop", ":", "]", ".", "reshape", "(", "\n", "-", "1", ",", "num_pos", ",", "num_pos", ",", "pos_dim", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "new_pos_emb", "=", "F", ".", "interpolate", "(", "\n", "ptensor", ",", "\n", "pos_resolution", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "1", ",", "2", ")", "\n", "new_pos_emb", "=", "torch", ".", "cat", "(", "(", "\n", "old_pos_emb", "[", ":", "bop", "]", ",", "new_pos_emb", ".", "view", "(", "-", "1", ",", "pos_dim", ")", "\n", ")", ",", "dim", "=", "0", ")", "\n", "new_pos_emb", "=", "new_pos_emb", ".", "unsqueeze", "(", "0", ")", "if", "add_leading_dim", "else", "new_pos_emb", "\n", "old_dict", "[", "key", "]", "=", "new_pos_emb", "\n", "\n", "new_keys", "=", "set", "(", "new_dict", ".", "keys", "(", ")", ")", "\n", "old_keys", "=", "set", "(", "old_dict", ".", "keys", "(", ")", ")", "\n", "new_dict", ".", "update", "(", "old_dict", ")", "\n", "n_o", "=", "new_keys", "-", "old_keys", "\n", "o_n", "=", "old_keys", "-", "new_keys", "\n", "#print(f\"{n_o}\\n{o_n}\")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.load_pos_embedding": [[89, 135], ["numpy.prod", "set", "set", "new_dict.update", "old_pos_emb.squeeze.dim", "old_pos_emb.squeeze.squeeze", "torch.cat.unsqueeze", "new_dict.keys", "old_dict.keys", "old_pos_emb[].reshape().permute", "torch.interpolate().permute().flatten", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "old_pos_emb[].reshape", "torch.interpolate().permute", "torch.cat.view", "torch.interpolate"], "function", ["None"], ["", "def", "load_pos_embedding", "(", "\n", "state_dict", ",", "old_dict", ",", "new_dict", ",", "key", ",", "bop", ",", "old_pos_shape", ",", "new_pos_shape", ",", "use_slice", "=", "True", "\n", ")", ":", "\n", "    ", "add_leading_dim", "=", "False", "\n", "old_pos_emb", "=", "state_dict", "[", "key", "]", "\n", "if", "old_pos_emb", ".", "dim", "(", ")", "==", "3", ":", "# ensure of rank-2 tensor", "\n", "        ", "assert", "old_pos_emb", ".", "shape", "[", "0", "]", "==", "1", "\n", "old_pos_emb", "=", "old_pos_emb", ".", "squeeze", "(", "0", ")", "\n", "add_leading_dim", "=", "True", "\n", "", "num_pos", ",", "pos_dim", "=", "old_pos_emb", ".", "shape", "[", "-", "2", ":", "]", "\n", "num_pos_required", "=", "np", ".", "prod", "(", "new_pos_shape", ")", "\n", "\n", "if", "new_pos_shape", "==", "old_pos_shape", ":", "\n", "        ", "new_pos_emb", "=", "old_pos_emb", "# do nothing", "\n", "", "elif", "use_slice", "and", "new_pos_shape", "[", "-", "1", "]", "==", "old_pos_shape", "[", "-", "1", "]", "and", "num_pos_required", "+", "bop", "<=", "num_pos", ":", "\n", "        ", "extra", "=", "old_pos_shape", "[", "-", "2", "]", "-", "new_pos_shape", "[", "-", "2", "]", "\n", "if", "extra", "==", "0", ":", "\n", "            ", "new_pos_emb", "=", "old_pos_emb", "[", ":", "num_pos_required", "+", "bop", "]", "# first k time steps", "\n", "", "else", ":", "\n", "            ", "start", "=", "6", "# [0, extra]", "\n", "start", "=", "start", "*", "old_pos_shape", "[", "-", "1", "]", "+", "bop", "\n", "new_pos_emb", "=", "torch", ".", "cat", "(", "(", "\n", "old_pos_emb", "[", ":", "bop", "]", ",", "old_pos_emb", "[", "start", ":", "start", "+", "num_pos_required", "]", "\n", ")", ",", "0", ")", "\n", "", "", "else", ":", "# interpolate", "\n", "        ", "shape", "=", "(", "-", "1", ",", ")", "+", "old_pos_shape", "+", "(", "pos_dim", ",", ")", "\n", "ptensor", "=", "old_pos_emb", "[", "bop", ":", "]", ".", "reshape", "(", "shape", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "new_pos_emb", "=", "F", ".", "interpolate", "(", "\n", "ptensor", ",", "\n", "new_pos_shape", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "1", ",", "2", ")", "\n", "new_pos_emb", "=", "torch", ".", "cat", "(", "(", "\n", "old_pos_emb", "[", ":", "bop", "]", ",", "new_pos_emb", ".", "view", "(", "-", "1", ",", "pos_dim", ")", "\n", ")", ",", "dim", "=", "0", ")", "\n", "", "new_pos_emb", "=", "new_pos_emb", ".", "unsqueeze", "(", "0", ")", "if", "add_leading_dim", "else", "new_pos_emb", "\n", "old_dict", "[", "key", "]", "=", "new_pos_emb", "\n", "\n", "new_keys", "=", "set", "(", "new_dict", ".", "keys", "(", ")", ")", "\n", "old_keys", "=", "set", "(", "old_dict", ".", "keys", "(", ")", ")", "\n", "new_dict", ".", "update", "(", "old_dict", ")", "\n", "n_o", "=", "new_keys", "-", "old_keys", "\n", "o_n", "=", "old_keys", "-", "new_keys", "\n", "#print(f\"{n_o}\\n{o_n}\")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.TextHead.__init__": [[24, 33], ["torch.nn.Module.__init__", "TextualTransformer"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "TextualTransformer", "(", "\n", "width", "=", "cfg", ".", "width", ",", "\n", "layers", "=", "cfg", ".", "layers", ",", "\n", "heads", "=", "cfg", ".", "heads", ",", "\n", "ctx_len", "=", "cfg", ".", "ctx_len", ",", "\n", "vocab_size", "=", "cfg", ".", "vocab_size", ",", "\n", "output_dim", "=", "cfg", ".", "embed_dim", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.TextHead.copy_state_dict": [[35, 38], ["text_head.TextHead.encoder.load_state_dict"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "{", "}", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.TextHead.forward": [[39, 46], ["kwargs.get", "text_head.TextHead.encoder", "kwargs.get", "text_head.TextHead.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "positional_embedding", "=", "kwargs", ".", "get", "(", "\"positional_embedding\"", ",", "None", ")", "\n", "z", "=", "self", ".", "encoder", "(", "text", ",", "positional_embedding", "=", "positional_embedding", ")", "\n", "if", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "z", "=", "z", "/", "z", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} image --{kwargs.get('normalized', False)}\")", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.SeqGenerationHead.__init__": [[49, 66], ["torch.nn.Module.__init__", "TextualTransformer", "clip.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "TextualTransformer", "(", "\n", "width", "=", "cfg", ".", "width", ",", "\n", "layers", "=", "cfg", ".", "layers", ",", "\n", "heads", "=", "cfg", ".", "heads", ",", "\n", "ctx_len", "=", "cfg", ".", "ctx_len", ",", "\n", "vocab_size", "=", "cfg", ".", "vocab_size", ",", "\n", "output_dim", "=", "cfg", ".", "embed_dim", ",", "\n", "require_inter_attn", "=", "True", ",", "\n", ")", "\n", "width", "=", "cfg", ".", "width", "\n", "scale", "=", "width", "**", "-", "0.5", "\n", "self", ".", "mem_ln", "=", "LayerNorm", "(", "width", ")", "\n", "self", ".", "to_txt", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "cfg", ".", "mem_width", ",", "cfg", ".", "width", ")", ")", "\n", "self", ".", "predictor", "=", "nn", ".", "Linear", "(", "width", ",", "self", ".", "encoder", ".", "vocab_size", ",", "bias", "=", "cfg", ".", "bias", ")", "\n", "self", ".", "max_len_dec", "=", "cfg", ".", "max_len_dec", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.SeqGenerationHead.copy_state_dict": [[67, 79], ["text_head.SeqGenerationHead.encoder.state_dict", "set", "set", "text_head.SeqGenerationHead.update", "text_head.SeqGenerationHead.encoder.load_state_dict", "text_head.SeqGenerationHead.keys", "old_dict.keys", "state_dict.items"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "excluded", "=", "[", "]", "\n", "new_dict", "=", "self", ".", "encoder", ".", "state_dict", "(", ")", "\n", "old_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "k", "not", "in", "excluded", "}", "\n", "new_keys", "=", "set", "(", "new_dict", ".", "keys", "(", ")", ")", "\n", "old_keys", "=", "set", "(", "old_dict", ".", "keys", "(", ")", ")", "\n", "new_dict", ".", "update", "(", "old_dict", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "new_dict", ")", "\n", "n_o", "=", "new_keys", "-", "old_keys", "\n", "o_n", "=", "old_keys", "-", "new_keys", "\n", "#print(f\"{n_o}\\n{o_n}\")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.SeqGenerationHead.infer": [[80, 108], ["list", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "text_head.SeqGenerationHead.scatter", "torch.cat.append", "torch.cat.append", "text_head.SeqGenerationHead.encoder", "text_head.SeqGenerationHead.predictor", "torch.cat.append", "torch.cat.append", "text_head.SeqGenerationHead.argmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all_ctx[].unsqueeze", "torch.cat.size", "torch.cat.size"], "methods", ["None"], ["", "def", "infer", "(", "self", ",", "x", ",", "positional_embedding", ",", "memory", ")", ":", "\n", "        ", "beg_len", "=", "0", "\n", "max_len", "=", "self", ".", "max_len_dec", "-", "beg_len", "\n", "logits", "=", "list", "(", ")", "\n", "indice", "=", "torch", ".", "arange", "(", "0", ",", "x", ".", "shape", "[", "0", "]", ",", "5", ",", "device", "=", "x", ".", "device", ")", "\n", "x", "=", "x", "[", "indice", "]", "\n", "if", "beg_len", ">", "0", ":", "# gold prefix and fake logits", "\n", "            ", "all_ctx", "=", "x", "[", ":", ",", ":", "beg_len", "+", "1", "]", "\n", "logit", "=", "torch", ".", "zeros", "(", "(", "\n", "all_ctx", ".", "size", "(", "0", ")", ",", "beg_len", ",", "self", ".", "encoder", ".", "vocab_size", "\n", ")", ",", "device", "=", "x", ".", "device", ")", "\n", "logit", "=", "logit", ".", "scatter", "(", "2", ",", "all_ctx", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "-", "1", ")", ",", "10", ")", "\n", "logits", ".", "append", "(", "logit", ")", "\n", "", "else", ":", "# the start symbol", "\n", "            ", "all_ctx", "=", "x", "[", ":", ",", ":", "1", "]", "\n", "\n", "", "for", "istep", "in", "range", "(", "beg_len", ",", "max_len", ")", ":", "\n", "            ", "_", ",", "features", "=", "self", ".", "encoder", "(", "\n", "all_ctx", ",", "positional_embedding", "=", "positional_embedding", ",", "memory", "=", "memory", ",", "require_feature", "=", "True", "\n", ")", "\n", "logit", "=", "self", ".", "predictor", "(", "features", "[", ":", ",", "-", "1", ":", "]", ")", "\n", "logits", ".", "append", "(", "logit", ")", "\n", "\n", "new_ctx", "=", "logit", ".", "argmax", "(", "dim", "=", "-", "1", ")", "\n", "all_ctx", "=", "torch", ".", "cat", "(", "(", "all_ctx", ",", "new_ctx", ")", ",", "1", ")", "\n", "\n", "", "logits", "=", "torch", ".", "cat", "(", "logits", ",", "dim", "=", "1", ")", "\n", "return", "x", ",", "logits", ",", "all_ctx", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.SeqGenerationHead.forward": [[109, 130], ["text_head.SeqGenerationHead.mem_ln().permute", "kwargs.get", "text_head.SeqGenerationHead.encoder", "text_head.SeqGenerationHead.predictor", "kwargs.get", "text_head.SeqGenerationHead.mean", "text_head.SeqGenerationHead.mean", "text_head.SeqGenerationHead.infer", "text_head.SeqGenerationHead.mem_ln", "z.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "text", ",", "audio", ",", "time_first", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# layer-normed audio: (N, nrow, ncol, D)", "\n", "        ", "audio", "=", "audio", "@", "self", ".", "to_txt", "# project to the textual space", "\n", "audio", "=", "audio", ".", "mean", "(", "2", ")", "if", "time_first", "else", "audio", ".", "mean", "(", "1", ")", "\n", "audio", "=", "self", ".", "mem_ln", "(", "audio", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# NLD -> LND", "\n", "# text conditional on audio", "\n", "positional_embedding", "=", "kwargs", ".", "get", "(", "\"positional_embedding\"", ",", "None", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "infer", "(", "text", ",", "positional_embedding", ",", "audio", ")", "\n", "\n", "", "z", ",", "features", "=", "self", ".", "encoder", "(", "\n", "text", ",", "positional_embedding", "=", "positional_embedding", ",", "memory", "=", "audio", ",", "require_feature", "=", "True", "\n", ")", "\n", "logits", "=", "self", ".", "predictor", "(", "features", ")", "# compute cross-entropy loss", "\n", "logits", "=", "logits", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "if", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "z", "=", "z", "/", "z", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} image --{kwargs.get('normalized', False)}\")", "\n", "", "return", "z", ",", "logits", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head": [[19, 21], ["TEXT_HEADS_REGISTRY.get"], "function", ["None"], ["def", "build_text_head", "(", "cfg", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "TEXT_HEADS_REGISTRY", ".", "get", "(", "cfg", ".", "name", ")", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.ImageHead.__init__": [[27, 47], ["torch.nn.Module.__init__", "isinstance", "ModifiedResNet", "VisualTransformer"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "cfg", ".", "layers", ",", "(", "tuple", ",", "list", ",", "ListConfig", ")", ")", ":", "\n", "            ", "heads", "=", "cfg", ".", "width", "*", "32", "//", "64", "\n", "self", ".", "encoder", "=", "ModifiedResNet", "(", "\n", "input_resolution", "=", "cfg", ".", "resolution", ",", "\n", "output_dim", "=", "cfg", ".", "embed_dim", ",", "\n", "layers", "=", "cfg", ".", "layers", ",", "\n", "width", "=", "cfg", ".", "width", ",", "\n", "heads", "=", "heads", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "heads", "=", "cfg", ".", "width", "//", "64", "\n", "self", ".", "encoder", "=", "VisualTransformer", "(", "\n", "input_resolution", "=", "cfg", ".", "resolution", ",", "\n", "output_dim", "=", "cfg", ".", "embed_dim", ",", "\n", "patch_size", "=", "cfg", ".", "patch_size", ",", "\n", "layers", "=", "cfg", ".", "layers", ",", "\n", "width", "=", "cfg", ".", "width", ",", "\n", "heads", "=", "heads", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.ImageHead.copy_state_dict": [[49, 51], ["image_head.ImageHead.encoder.load_state_dict"], "methods", ["None"], ["", "", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.ImageHead.forward": [[52, 58], ["image_head.ImageHead.encoder", "kwargs.get", "image_head.ImageHead.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "z", "=", "self", ".", "encoder", "(", "images", ")", "\n", "if", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "z", "=", "z", "/", "z", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} image --{kwargs.get('normalized', False)}\")", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.DeiTImageHead.__init__": [[61, 75], ["torch.nn.Module.__init__", "DistilledVisionTransformer", "partial"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "heads", "=", "cfg", ".", "width", "//", "64", "\n", "self", ".", "encoder", "=", "DistilledVisionTransformer", "(", "\n", "img_size", "=", "cfg", ".", "resolution", ",", "\n", "patch_size", "=", "cfg", ".", "patch_size", ",", "\n", "representation_size", "=", "cfg", ".", "embed_dim", ",", "\n", "embed_dim", "=", "cfg", ".", "width", ",", "\n", "depth", "=", "cfg", ".", "layers", ",", "\n", "num_heads", "=", "heads", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "norm_layer", "=", "partial", "(", "nn", ".", "LayerNorm", ",", "eps", "=", "1e-6", ")", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.DeiTImageHead.copy_state_dict": [[77, 79], ["image_head.DeiTImageHead.encoder.load_state_dict"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.DeiTImageHead.forward": [[80, 87], ["image_head.DeiTImageHead.encoder.forward_features", "kwargs.get", "z.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.deit.DistilledVisionTransformer.forward_features"], ["", "def", "forward", "(", "self", ",", "images", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cls_z", ",", "distilled_z", "=", "self", ".", "encoder", ".", "forward_features", "(", "images", ")", "\n", "z", "=", "(", "cls_z", "+", "distilled_z", ")", "/", "2", "\n", "if", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "z", "=", "z", "/", "z", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} image --{kwargs.get('normalized', False)}\")", "\n", "", "return", "z", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head": [[22, 24], ["IMAGE_HEADS_REGISTRY.get"], "function", ["None"], ["def", "build_image_head", "(", "cfg", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "IMAGE_HEADS_REGISTRY", ".", "get", "(", "cfg", ".", "name", ")", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.__init__": [[26, 67], ["torch.nn.Module.__init__", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.update", "build_encoder_module", "build_encoder_module", "build_encoder_module", "build_encoder_module", "build_encoder_module", "kwargs.update", "build_encoder_module"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.build_encoder_module", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.build_encoder_module", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.build_encoder_module", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.build_encoder_module", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.build_encoder_module", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.build_encoder_module"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "keep_hp", "=", "kwargs", ".", "pop", "(", "\"keep_hp\"", ",", "False", ")", "\n", "reference", "=", "kwargs", ".", "pop", "(", "\"reference\"", ",", "None", ")", "\n", "shared_modules", "=", "kwargs", ".", "pop", "(", "\"shared_modules\"", ",", "[", "]", ")", "\n", "kwargs", ".", "update", "(", "{", "\n", "\"width\"", ":", "cfg", ".", "width", ",", "\"embed_dim\"", ":", "cfg", ".", "embed_dim", ",", "\n", "\"ctx_len\"", ":", "cfg", ".", "ctx_len", ",", "\"resolution\"", ":", "cfg", ".", "resolution", "\n", "}", ")", "# shared hyperparameters", "\n", "\n", "self", ".", "encoder", "=", "(", "\n", "build_encoder_module", "(", "cfg", ".", "encoder", ",", "**", "kwargs", ")", "\n", "#if \"encoder\" not in shared_modules else reference.encoder ", "\n", ")", "# backbone", "\n", "self", ".", "pre_encoder", "=", "(", "\n", "build_encoder_module", "(", "cfg", ".", "pre_encoder", ",", "**", "kwargs", ")", "\n", "#if \"pre_encoder\" not in shared_modules else reference.pre_encoder ", "\n", ")", "\n", "self", ".", "post_encoder", "=", "(", "\n", "build_encoder_module", "(", "cfg", ".", "post_encoder", ",", "**", "kwargs", ")", "\n", "#if \"post_encoder\" not in shared_modules else reference.post_encoder ", "\n", ")", "\n", "\n", "self", ".", "pre_encoder_addon", "=", "build_encoder_module", "(", "\n", "cfg", ".", "pre_encoder_addon", ",", "**", "kwargs", "\n", ")", "# in-between `pre_encoder` & `encoder`", "\n", "self", ".", "post_encoder_addon", "=", "build_encoder_module", "(", "\n", "cfg", ".", "post_encoder_addon", ",", "**", "kwargs", "\n", ")", "# in-between `encoder` & `post_encoder`", "\n", "\n", "# have to build all modules to get `position_resolution`, even though ", "\n", "# we will probably replace all the modules by those of the `reference` ", "\n", "position_resolution", "=", "(", "\n", "self", ".", "pre_encoder", ".", "position_resolution", "or", "self", ".", "encoder", ".", "position_resolution", "or", "self", ".", "post_encoder", ".", "position_resolution", "\n", ")", "\n", "kwargs", ".", "update", "(", "{", "\n", "\"position_resolution\"", ":", "position_resolution", "\n", "}", ")", "\n", "self", ".", "misc", "=", "build_encoder_module", "(", "cfg", ".", "misc", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.replace_modules": [[71, 97], ["list", "list.append", "eval", "eval", "hasattr", "len", "eval.replace_modules", "eval", "exec", "eval", "exec"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.replace_modules"], ["", "def", "replace_modules", "(", "self", ",", "shared_modules", "=", "[", "]", ",", "reference", "=", "None", ",", "keep_hp", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" keep_hp: keep selected hyperparameters\n        \"\"\"", "\n", "if", "len", "(", "shared_modules", ")", "<", "1", "or", "reference", "is", "None", ":", "\n", "            ", "return", "[", "]", "\n", "", "module_list", "=", "[", "\"encoder\"", ",", "\"pre_encoder\"", ",", "\"post_encoder\"", ",", "\"misc\"", "]", "\n", "ref_modules", "=", "list", "(", ")", "\n", "for", "module", "in", "module_list", ":", "\n", "            ", "if", "module", "not", "in", "shared_modules", ":", "\n", "                ", "continue", "\n", "", "ref_modules", ".", "append", "(", "module", ")", "\n", "self_module", "=", "eval", "(", "f\"self.{module}\"", ")", "\n", "refr_module", "=", "eval", "(", "f\"reference.{module}\"", ")", "\n", "#print(f\"RP A {module} {self_module.hp} {refr_module.hp} {self_module == refr_module}\")", "\n", "if", "hasattr", "(", "self_module", ",", "\"replace_modules\"", ")", ":", "\n", "                ", "self_module", ".", "replace_modules", "(", "refr_module", ",", "keep_hp", "=", "keep_hp", ")", "\n", "new_self_module", "=", "eval", "(", "f\"self.{module}\"", ")", "\n", "#print(f\"RP B {module} {self_module.hp} {refr_module.hp} {self_module == refr_module} {new_self_module == refr_module}\")", "\n", "", "else", ":", "# via reference, not recommended", "\n", "                ", "hp", "=", "self_module", ".", "hp", "\n", "exec", "(", "f\"self.{module} = reference.{module}\"", ")", "# modified via reference", "\n", "if", "keep_hp", ":", "\n", "                    ", "exec", "(", "f\"self.{module}.hp = {hp}\"", ")", "# so the `reference` is modified", "\n", "", "new_self_module", "=", "eval", "(", "f\"self.{module}\"", ")", "\n", "#print(f\"RP C {module} {self_module.hp} {refr_module.hp} {self_module == refr_module} {new_self_module == refr_module}\")", "\n", "", "", "return", "ref_modules", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.forward": [[98, 121], ["kwargs.update", "clip_head.MetaHead.pre_encoder", "clip_head.MetaHead.pre_encoder_addon", "clip_head.MetaHead.encoder", "clip_head.MetaHead.post_encoder_addon", "clip_head.MetaHead.post_encoder", "kwargs.get", "clip_head.MetaHead.permute", "clip_head.MetaHead.permute", "clip_head.MetaHead.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", ".", "update", "(", "{", "\n", "\"positional_embedding\"", ":", "self", ".", "misc", ".", "pos_embedding", ",", "\n", "\"class_embedding\"", ":", "self", ".", "misc", ".", "cls_embedding", ",", "\n", "\"position_resolution\"", ":", "self", ".", "misc", ".", "position_resolution", "\n", "}", ")", "\n", "x", "=", "self", ".", "pre_encoder", "(", "x", ",", "**", "kwargs", ")", "# (N, L, D)", "\n", "x", "=", "self", ".", "pre_encoder_addon", "(", "x", ",", "**", "kwargs", ")", "# (N, L, D)", "\n", "\n", "# TODO assumed 3d `x`", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "if", "not", "self", ".", "encoder", ".", "batch_first", "else", "x", "# (N, L, D) -> (L, N, D)", "\n", "x", "=", "self", ".", "encoder", "(", "x", ",", "**", "kwargs", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "if", "not", "self", ".", "encoder", ".", "batch_first", "else", "x", "# (L, N, D) -> (N, L, D)", "\n", "\n", "mask", "=", "self", ".", "pre_encoder", ".", "mask", "#or self.encoder.mask # text) postion of cls token; audio/image) ?", "\n", "\n", "x", "=", "self", ".", "post_encoder_addon", "(", "x", ",", "**", "kwargs", ")", "\n", "x", "=", "self", ".", "post_encoder", "(", "x", ",", "mask", "=", "mask", ",", "**", "kwargs", ")", "\n", "\n", "if", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "x", "=", "x", "/", "x", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} x --{kwargs.get('normalized', False)}\")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPImageHead.__init__": [[123, 125], ["clip_head.MetaHead.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPImageHead.copy_state_dict": [[126, 167], ["clip_head.CLIPImageHead.state_dict", "set", "set", "clip_head.CLIPImageHead.update", "clip_head.CLIPImageHead.load_state_dict", "collections.OrderedDict", "state_dict.items", "collections.OrderedDict", "state_dict.items", "collections.OrderedDict.pop", "clip_head.CLIPImageHead.keys", "collections.OrderedDict.keys", "re.match", "re.match", "pos_key.rsplit", "re.sub", "re.sub", "re.sub", "re.sub"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "not", "self", ".", "encoder", ".", "batch_first", ":", "# TransformerBackbone", "\n", "            ", "pre_keys", "=", "{", "\"conv1.weight\"", "}", "\n", "post_keys", "=", "{", "\"proj\"", "}", "\n", "misc_keys", "=", "{", "\"positional_embedding\"", ",", "\"class_embedding\"", "}", "\n", "old_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "pre_keys", ":", "\n", "                    ", "k", "=", "f\"pre_encoder.{k}\"", "\n", "", "elif", "k", "in", "post_keys", ":", "\n", "                    ", "k", "=", "f\"post_encoder.{k}\"", "\n", "", "elif", "k", "in", "misc_keys", ":", "\n", "                    ", "k", "=", "f\"misc.{k}\"", "\n", "", "else", ":", "\n", "#k = re.sub(\"^ln_\\w+\\.\", \"ln.\", k)", "\n", "                    ", "k", "=", "re", ".", "sub", "(", "\"^transformer\\.\"", ",", "\"encoder.\"", ",", "k", ")", "\n", "k", "=", "re", ".", "sub", "(", "\"^ln_pre\\.\"", ",", "\"pre_encoder.ln.\"", ",", "k", ")", "\n", "k", "=", "re", ".", "sub", "(", "\"^ln_post\\.\"", ",", "\"post_encoder.ln.\"", ",", "k", ")", "\n", "", "old_dict", "[", "k", "]", "=", "v", "\n", "", "", "else", ":", "# ResNetBackbone", "\n", "            ", "old_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "re", ".", "match", "(", "\"layer\\d+\\.\"", ",", "k", ")", ":", "\n", "                    ", "k", "=", "f\"encoder.{k}\"", "\n", "", "elif", "re", ".", "match", "(", "\"attnpool\\.\"", ",", "k", ")", ":", "\n", "                    ", "k", "=", "re", ".", "sub", "(", "\"^attnpool\\.\"", ",", "\"post_encoder.\"", ",", "k", ")", "\n", "", "else", ":", "\n", "                    ", "k", "=", "f\"pre_encoder.{k}\"", "\n", "", "old_dict", "[", "k", "]", "=", "v", "\n", "", "pos_key", "=", "\"post_encoder.positional_embedding\"", "\n", "new_key", "=", "\"misc.\"", "+", "pos_key", ".", "rsplit", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "old_dict", "[", "new_key", "]", "=", "old_dict", ".", "pop", "(", "pos_key", ")", "\n", "", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "new_keys", "=", "set", "(", "new_dict", ".", "keys", "(", ")", ")", "\n", "old_keys", "=", "set", "(", "old_dict", ".", "keys", "(", ")", ")", "\n", "new_dict", ".", "update", "(", "old_dict", ")", "\n", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "n_o", "=", "new_keys", "-", "old_keys", "\n", "o_n", "=", "old_keys", "-", "new_keys", "\n", "#print(f\"{n_o}\\n{o_n}\")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.__init__": [[169, 171], ["clip_head.MetaHead.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained": [[172, 192], ["clip_head.CLIPAudioHead.state_dict", "audio_head.position_resolution", "audio_head.load_pos_embedding", "clip_head.CLIPAudioHead.load_state_dict", "interp_clip_vp_embedding", "state_dict.items", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.position_resolution", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.load_pos_embedding", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_clip_vp_embedding"], ["", "def", "from_pretrained", "(", "self", ",", "state_dict", ",", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "excluded", "=", "[", "\"misc.positional_embedding\"", "]", "\n", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "old_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "k", "not", "in", "excluded", "}", "\n", "# interpolate positional embedding", "\n", "key", "=", "\"misc.positional_embedding\"", "\n", "new_pos_shape", "=", "self", ".", "misc", ".", "position_resolution", "\n", "old_pos_shape", "=", "position_resolution", "(", "\n", "cfg", ".", "model", ".", "audio", ".", "resolution", ",", "cfg", ".", "model", ".", "audio", ".", "pre_encoder", ".", "patch_size", ",", "cfg", ".", "model", ".", "audio", ".", "pre_encoder", ".", "stride", "\n", ")", "# nrow always indicates the time dimenstion", "\n", "#print(new_dict[key].shape, state_dict[key].shape, new_pos_shape, old_pos_shape)", "\n", "if", "state_dict", "[", "key", "]", ".", "shape", "[", "0", "]", "in", "{", "50", ",", "197", "}", ":", "# from vision encoder TODO could be wrong", "\n", "            ", "state_dict", "[", "key", "]", "=", "interp_clip_vp_embedding", "(", "\n", "state_dict", ".", "pop", "(", "key", ")", ",", "old_pos_shape", "\n", ")", "# pos embed inherited from vision encoder", "\n", "", "n_o", ",", "o_n", "=", "load_pos_embedding", "(", "\n", "state_dict", ",", "old_dict", ",", "new_dict", ",", "key", ",", "1", ",", "old_pos_shape", ",", "new_pos_shape", "\n", ")", "\n", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.copy_state_dict": [[193, 248], ["clip_head.CLIPAudioHead.state_dict", "interp_conv_weight_spatial", "set", "set", "clip_head.CLIPAudioHead.update", "clip_head.CLIPAudioHead.load_state_dict", "collections.OrderedDict", "state_dict.items", "interp_clip_vp_embedding", "collections.OrderedDict", "state_dict.items", "interp_clip_vp_embedding", "interp_conv_weight_spatial.mean", "clip_head.CLIPAudioHead.keys", "collections.OrderedDict.keys", "collections.OrderedDict.pop", "re.match", "collections.OrderedDict.pop", "re.match", "pos_key.rsplit", "re.sub", "re.sub", "re.sub", "re.sub"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_conv_weight_spatial", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_clip_vp_embedding", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.val.interp_clip_vp_embedding"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "not", "self", ".", "encoder", ".", "batch_first", ":", "# TransformerBackbone", "\n", "            ", "pre_keys", "=", "{", "\"conv1.weight\"", "}", "\n", "post_keys", "=", "{", "\"proj\"", "}", "\n", "misc_keys", "=", "{", "\"positional_embedding\"", ",", "\"class_embedding\"", "}", "\n", "old_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "pre_keys", ":", "\n", "                    ", "k", "=", "f\"pre_encoder.{k}\"", "\n", "", "elif", "k", "in", "post_keys", ":", "\n", "                    ", "k", "=", "f\"post_encoder.{k}\"", "\n", "", "elif", "k", "in", "misc_keys", ":", "\n", "                    ", "k", "=", "f\"misc.{k}\"", "\n", "", "else", ":", "\n", "#k = re.sub(\"^ln_\\w+\\.\", \"ln.\", k)", "\n", "                    ", "k", "=", "re", ".", "sub", "(", "\"^transformer\\.\"", ",", "\"encoder.\"", ",", "k", ")", "\n", "k", "=", "re", ".", "sub", "(", "\"^ln_pre\\.\"", ",", "\"pre_encoder.ln.\"", ",", "k", ")", "\n", "k", "=", "re", ".", "sub", "(", "\"^ln_post\\.\"", ",", "\"post_encoder.ln.\"", ",", "k", ")", "\n", "", "old_dict", "[", "k", "]", "=", "v", "\n", "# interpolation", "\n", "", "pos_key", "=", "\"misc.positional_embedding\"", "\n", "old_dict", "[", "pos_key", "]", "=", "interp_clip_vp_embedding", "(", "\n", "old_dict", ".", "pop", "(", "pos_key", ")", ",", "self", ".", "misc", ".", "position_resolution", "\n", ")", "\n", "", "else", ":", "# ResNetBackbone", "\n", "            ", "old_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "re", ".", "match", "(", "\"layer\\d+\\.\"", ",", "k", ")", ":", "\n", "                    ", "k", "=", "f\"encoder.{k}\"", "\n", "", "elif", "re", ".", "match", "(", "\"attnpool\\.\"", ",", "k", ")", ":", "\n", "                    ", "k", "=", "re", ".", "sub", "(", "\"^attnpool\\.\"", ",", "\"post_encoder.\"", ",", "k", ")", "\n", "", "else", ":", "\n", "                    ", "k", "=", "f\"pre_encoder.{k}\"", "\n", "", "old_dict", "[", "k", "]", "=", "v", "\n", "# interpolation", "\n", "", "pos_key", "=", "\"post_encoder.positional_embedding\"", "\n", "new_key", "=", "\"misc.\"", "+", "pos_key", ".", "rsplit", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "old_dict", "[", "new_key", "]", "=", "interp_clip_vp_embedding", "(", "\n", "old_dict", ".", "pop", "(", "pos_key", ")", ",", "self", ".", "misc", ".", "position_resolution", "\n", ")", "\n", "# take care of conv1", "\n", "", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "conv_key", "=", "\"pre_encoder.conv1.weight\"", "\n", "conv_weight", "=", "interp_conv_weight_spatial", "(", "old_dict", "[", "conv_key", "]", ",", "new_dict", "[", "conv_key", "]", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "use_mean", "=", "new_dict", "[", "conv_key", "]", ".", "shape", "[", "1", "]", "!=", "1", "\n", "old_dict", "[", "conv_key", "]", "=", "conv_weight", "if", "use_mean", "else", "conv_weight", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "# update", "\n", "new_keys", "=", "set", "(", "new_dict", ".", "keys", "(", ")", ")", "\n", "old_keys", "=", "set", "(", "old_dict", ".", "keys", "(", ")", ")", "\n", "new_dict", ".", "update", "(", "old_dict", ")", "\n", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "n_o", "=", "new_keys", "-", "old_keys", "\n", "o_n", "=", "old_keys", "-", "new_keys", "\n", "#print(f\"{n_o}\\n{o_n}\")", "\n", "return", "n_o", ",", "o_n", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPTextHead.__init__": [[250, 253], ["clip_head.MetaHead.__init__", "clip_head.CLIPTextHead.initialize_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPTextHead.initialize_parameters": [[254, 256], ["None"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "#nn.init.normal_(self.positional_embedding, std=0.01)", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPTextHead.copy_state_dict": [[257, 293], ["collections.OrderedDict", "state_dict.items", "clip_head.CLIPTextHead.state_dict", "set", "set", "clip_head.CLIPTextHead.update", "clip_head.CLIPTextHead.load_state_dict", "collections.OrderedDict.pop", "clip_head.CLIPTextHead.keys", "collections.OrderedDict.keys", "collections.OrderedDict.pop", "re.sub", "re.sub", "re.sub"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "pre_keys", "=", "{", "\"token_embedding.weight\"", "}", "\n", "post_keys", "=", "{", "}", "\n", "misc_keys", "=", "{", "\"positional_embedding\"", "}", "\n", "old_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "pre_keys", ":", "\n", "                ", "k", "=", "f\"pre_encoder.{k}\"", "\n", "", "elif", "k", "in", "post_keys", ":", "\n", "                ", "k", "=", "f\"post_encoder.{k}\"", "\n", "", "elif", "k", "in", "misc_keys", ":", "\n", "                ", "k", "=", "f\"misc.{k}\"", "\n", "", "else", ":", "\n", "#k = re.sub(\"^ln_\\w+\\.\", \"ln.\", k)", "\n", "                ", "k", "=", "re", ".", "sub", "(", "\"^transformer\\.\"", ",", "\"encoder.\"", ",", "k", ")", "\n", "k", "=", "re", ".", "sub", "(", "\"^ln_final\\.\"", ",", "\"post_encoder.ln.\"", ",", "k", ")", "\n", "k", "=", "re", ".", "sub", "(", "\"^text_projection\"", ",", "\"post_encoder.proj\"", ",", "k", ")", "\n", "", "old_dict", "[", "k", "]", "=", "v", "\n", "", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "# TODO better via interpolation", "\n", "pos_key", "=", "\"misc.positional_embedding\"", "\n", "old_num", "=", "old_dict", "[", "pos_key", "]", ".", "shape", "[", "0", "]", "\n", "new_num", "=", "new_dict", "[", "pos_key", "]", ".", "shape", "[", "0", "]", "\n", "if", "old_num", ">=", "new_num", ":", "\n", "            ", "old_dict", "[", "pos_key", "]", "=", "old_dict", ".", "pop", "(", "pos_key", ")", "[", ":", "new_num", "]", "\n", "", "else", ":", "\n", "            ", "new_dict", "[", "pos_key", "]", "[", ":", "old_num", "]", "=", "old_dict", ".", "pop", "(", "pos_key", ")", "\n", "old_dict", "[", "pos_key", "]", "=", "new_dict", "[", "pos_key", "]", "# unnecessary", "\n", "", "new_keys", "=", "set", "(", "new_dict", ".", "keys", "(", ")", ")", "\n", "old_keys", "=", "set", "(", "old_dict", ".", "keys", "(", ")", ")", "\n", "new_dict", ".", "update", "(", "old_dict", ")", "\n", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "n_o", "=", "new_keys", "-", "old_keys", "\n", "o_n", "=", "old_keys", "-", "new_keys", "\n", "#print(f\"{n_o}\\n{o_n}\")", "\n", "return", "n_o", ",", "o_n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.__init__": [[26, 30], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reduce", "=", "False", "\n", "self", ".", "normalized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.copy_state_dict": [[31, 33], ["None"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.infer": [[34, 47], ["loss_head.LossHead.x1s.append", "loss_head.LossHead.x2s.append", "kwargs.get", "kwargs.get", "loss_head.LossHead.ids.extend", "hasattr", "hasattr", "hasattr", "x1.norm", "x2.norm"], "methods", ["None"], ["", "def", "infer", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"x1s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x2s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"ids\"", ")", ":", "\n", "            ", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "# normalized features", "\n", "", "if", "not", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "x1", "=", "x1", "/", "x1", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x2", "=", "x2", "/", "x2", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "self", ".", "x1s", ".", "append", "(", "x1", ")", "\n", "self", ".", "x2s", ".", "append", "(", "x2", ")", "\n", "names", "=", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "\n", "if", "names", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", ".", "extend", "(", "names", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead._gold_cluster": [[48, 66], ["collections.defaultdict", "collections.defaultdict", "open", "enumerate", "list", "list.sort", "print", "json.loads", "sample_by_classname[].append", "collections.defaultdict.items", "print", "len", "len", "len"], "methods", ["None"], ["", "def", "_gold_cluster", "(", "self", ",", "gold_file", ",", "nsample", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "sample_by_classname", "=", "defaultdict", "(", "list", ")", "\n", "classname_by_sample", "=", "defaultdict", "(", "str", ")", "\n", "with", "open", "(", "gold_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "iline", "+", "1", ">", "nsample", ":", "\n", "                    ", "break", "\n", "", "key", "=", "\" \"", ".", "join", "(", "record", "[", "\"labels\"", "]", ")", "\n", "sample_by_classname", "[", "key", "]", ".", "append", "(", "record", "[", "\"id\"", "]", ")", "\n", "classname_by_sample", "[", "record", "[", "\"id\"", "]", "]", "=", "key", "\n", "", "", "if", "verbose", ":", "\n", "            ", "items", "=", "list", "(", "sample_by_classname", ".", "items", "(", ")", ")", "\n", "items", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "len", "(", "x", "[", "1", "]", ")", ")", "\n", "for", "k", ",", "v", "in", "items", ":", "\n", "                ", "print", "(", "k", ",", "len", "(", "v", ")", ")", "\n", "", "print", "(", "f\"total {len(sample_by_classname)} groups\"", ")", "\n", "", "return", "sample_by_classname", ",", "classname_by_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.retrieval_metrics": [[67, 78], ["ranks.median", "ranks.mean", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "retrieval_metrics", "(", "ranks", ",", "nsample", "=", "None", ",", "msg", "=", "\"\"", ")", ":", "\n", "        ", "nsample", "=", "nsample", "or", "ranks", ".", "shape", "[", "0", "]", "\n", "R1", "=", "torch", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "R5", "=", "torch", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "R10", "=", "torch", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "R50", "=", "torch", ".", "where", "(", "ranks", "<", "50", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "MED", "=", "ranks", ".", "median", "(", ")", "+", "1", "\n", "AVG", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "msg", "=", "f\"{msg}: R@1 {R1:2.2f} R5 {R5:2.2f} R10 {R10:2.2f} R50 {R50:2.2f} MED {MED:2.2f} AVG {AVG:2.2f}\"", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.retrieval_eval": [[79, 108], ["x12.argsort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "loss_head.LossHead.retrieval_metrics", "x21.argsort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "loss_head.LossHead.retrieval_metrics", "x2s.t", "range", "x1s.t", "range", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.retrieval_metrics", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.retrieval_metrics"], ["", "@", "staticmethod", "\n", "def", "retrieval_eval", "(", "x1s", ",", "x2s", ",", "k", "=", "5", ")", ":", "\n", "# assume x1s.shape[0] * k == x2s.shape[0]", "\n", "# x1 -> x2", "\n", "        ", "x12", "=", "x1s", "@", "x2s", ".", "t", "(", ")", "\n", "nsample", "=", "x1s", ".", "shape", "[", "0", "]", "\n", "ind_12", "=", "x12", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "ranks", "=", "torch", ".", "zeros", "(", "nsample", ",", "device", "=", "x1s", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "nsample", ")", ":", "\n", "            ", "rank", "=", "1e9", "\n", "inds", "=", "ind_12", "[", "i", ":", "i", "+", "1", "]", "\n", "for", "j", "in", "range", "(", "i", "*", "k", ",", "i", "*", "k", "+", "k", ")", ":", "\n", "                ", "rank_j", "=", "torch", ".", "where", "(", "inds", "==", "j", ")", "[", "1", "]", "[", "0", "]", "\n", "if", "rank_j", "<", "rank", ":", "\n", "                    ", "rank", "=", "rank_j", "\n", "", "", "ranks", "[", "i", "]", "=", "rank", "\n", "", "msg_12", "=", "LossHead", ".", "retrieval_metrics", "(", "ranks", ",", "msg", "=", "\"A->T\"", ")", "\n", "\n", "# x2 -> x1", "\n", "x21", "=", "x2s", "@", "x1s", ".", "t", "(", ")", "\n", "nsample", "=", "x1s", ".", "shape", "[", "0", "]", "\n", "ind_21", "=", "x21", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "ranks", "=", "torch", ".", "zeros", "(", "nsample", "*", "k", ",", "device", "=", "x1s", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "nsample", ")", ":", "\n", "            ", "inds", "=", "ind_21", "[", "i", "*", "k", ":", "i", "*", "k", "+", "k", "]", "\n", "for", "j", "in", "range", "(", "k", ")", ":", "\n", "                ", "ranks", "[", "i", "*", "k", "+", "j", "]", "=", "torch", ".", "where", "(", "inds", "[", "j", ":", "j", "+", "1", "]", "==", "i", ")", "[", "1", "]", "[", "0", "]", "\n", "", "", "msg_21", "=", "LossHead", ".", "retrieval_metrics", "(", "ranks", ",", "msg", "=", "\"T->A\"", ")", "\n", "return", "f\"{msg_12}\\n{msg_21}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead.report": [[109, 245], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "x12.argsort", "x21.argsort", "torch.cat.size", "torch.cat.size", "torch.cat.size", "loss_head.LossHead._gold_cluster", "loss_head.LossHead.report.topk_overlap"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.LossHead._gold_cluster"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "x1s", "=", "torch", ".", "cat", "(", "self", ".", "x1s", ")", "\n", "x2s", "=", "torch", ".", "cat", "(", "self", ".", "x2s", ")", "\n", "if", "x1s", ".", "shape", "[", "0", "]", "==", "x2s", ".", "shape", "[", "0", "]", ":", "\n", "            ", "nsample", "=", "x1s", ".", "shape", "[", "0", "]", "\n", "labels", "=", "torch", ".", "arange", "(", "nsample", ",", "device", "=", "x1s", ".", "device", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# x1 -> x2", "\n", "x12", "=", "x1s", "@", "x2s", ".", "t", "(", ")", "\n", "ind_12", "=", "x12", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "r12", "=", "torch", ".", "where", "(", "ind_12", "==", "labels", ")", "[", "1", "]", "\n", "\n", "t12_1", "=", "torch", ".", "where", "(", "r12", "<", "1", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "t12_5", "=", "torch", ".", "where", "(", "r12", "<", "5", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "\n", "p_12", "=", "f\"I->A: t1 = {t12_1:2.2f} t5 = {t12_5:2.2f}\"", "\n", "\n", "# x2 -> x1", "\n", "x21", "=", "x2s", "@", "x1s", ".", "t", "(", ")", "\n", "ind_21", "=", "x21", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "r21", "=", "torch", ".", "where", "(", "ind_21", "==", "labels", ")", "[", "1", "]", "\n", "\n", "t21_1", "=", "torch", ".", "where", "(", "r21", "<", "1", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "t21_5", "=", "torch", ".", "where", "(", "r21", "<", "5", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "nsample", "*", "100.", "\n", "\n", "p_21", "=", "f\"A->I: t1 = {t21_1:2.2f} t5 = {t21_5:2.2f}\"", "\n", "ref_metric", "=", "\"\"", "\n", "", "elif", "x1s", ".", "shape", "[", "0", "]", "*", "5", "==", "x2s", ".", "shape", "[", "0", "]", ":", "\n", "# x1 -> x2: 1 v 5 ", "\n", "            ", "nsample", "=", "x2s", ".", "shape", "[", "0", "]", "\n", "labels", "=", "torch", ".", "arange", "(", "nsample", ",", "device", "=", "x2s", ".", "device", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "x12", "=", "x1s", "@", "x2s", ".", "t", "(", ")", "\n", "ind_12", "=", "x12", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "ind_12", "=", "ind_12", ".", "repeat_interleave", "(", "5", ",", "dim", "=", "0", ")", "\n", "r12", "=", "torch", ".", "where", "(", "ind_12", "==", "labels", ")", "[", "1", "]", "\n", "\n", "r12", "=", "r12", ".", "reshape", "(", "-", "1", ",", "5", ")", "# 1 x 5", "\n", "\n", "t12_1", "=", "(", "r12", "<", "1", ")", ".", "sum", "(", "-", "1", ")", ".", "sum", "(", ")", "/", "(", "1", "*", "r12", ".", "shape", "[", "0", "]", ")", "*", "100.", "# P@1 ", "\n", "t12_5", "=", "(", "r12", "<", "5", ")", ".", "sum", "(", "-", "1", ")", ".", "sum", "(", ")", "/", "(", "5", "*", "r12", ".", "shape", "[", "0", "]", ")", "*", "100.", "# R@5 == P@5 ", "\n", "\n", "mean", "=", "r12", ".", "min", "(", "-", "1", ")", "[", "0", "]", ".", "float", "(", ")", ".", "mean", "(", ")", "+", "1", "\n", "\n", "p_12", "=", "f\"A->T: t1 = {t12_1:2.2f} t5 = {t12_5:2.2f} mR = {mean:2.2f}\"", "\n", "\n", "# x2 -> x1: 5 v 1", "\n", "nsample", "=", "x1s", ".", "shape", "[", "0", "]", "\n", "labels", "=", "torch", ".", "arange", "(", "nsample", ",", "device", "=", "x1s", ".", "device", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "labels", "=", "labels", ".", "repeat", "(", "1", ",", "5", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "x21", "=", "x2s", "@", "x1s", ".", "t", "(", ")", "\n", "ind_21", "=", "x21", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "r21", "=", "torch", ".", "where", "(", "ind_21", "==", "labels", ")", "[", "1", "]", "\n", "\n", "t21_1", "=", "torch", ".", "where", "(", "r21", "<", "1", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "r21", ".", "shape", "[", "0", "]", "*", "100.", "# P@1 ", "\n", "t21_5", "=", "torch", ".", "where", "(", "r21", "<", "5", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "/", "r21", ".", "shape", "[", "0", "]", "*", "100.", "# R@5 ", "\n", "\n", "mean", "=", "r21", ".", "float", "(", ")", ".", "mean", "(", ")", "+", "1", "\n", "\n", "p_21", "=", "f\"T->A: t1 = {t21_1:2.2f} t5 = {t21_5:2.2f} mR = {mean:2.2f}\"", "\n", "ref_metric", "=", "self", ".", "retrieval_eval", "(", "x1s", ",", "x2s", ")", "\n", "gold_file", "=", "None", "\n", "", "else", ":", "\n", "            ", "p_12", ",", "p_21", "=", "f\"{x1s.shape}x{x2s.shape}\"", ",", "\"-\"", "\n", "ref_metric", "=", "\"\"", "\n", "gold_file", "=", "None", "\n", "\n", "# stats per class", "\n", "", "if", "gold_file", "is", "not", "None", ":", "\n", "            ", "nsample", "=", "x1s", ".", "size", "(", "0", ")", "\n", "sample_by_classname", ",", "classname_by_sample", "=", "self", ".", "_gold_cluster", "(", "gold_file", ",", "nsample", ",", "verbose", "=", "False", ")", "\n", "\n", "def", "topk_overlap", "(", "x", ",", "k", "=", "1", ")", ":", "\n", "                ", "\"\"\" x has to be a 2d matrix: (sample_idx, sorted_sample_idx)\n                \"\"\"", "\n", "indice", "=", "x", "[", ":", ",", ":", "k", "]", "\n", "stats", "=", "defaultdict", "(", "dict", ")", "# {cls_name: {sample: num_correct}} ", "\n", "for", "idx", ",", "neighbors", "in", "enumerate", "(", "indice", ")", ":", "\n", "                    ", "sample", "=", "self", ".", "ids", "[", "idx", "]", "\n", "classname", "=", "classname_by_sample", "[", "sample", "]", "\n", "true_neighbors", "=", "sample_by_classname", "[", "classname", "]", "\n", "sample_stat", "=", "stats", ".", "get", "(", "classname", ",", "{", "}", ")", "\n", "this_stat", "=", "sample_stat", ".", "get", "(", "sample", ",", "[", "0", "]", "*", "2", ")", "\n", "for", "neighbor", "in", "neighbors", ":", "\n", "                        ", "neighbor_sample", "=", "self", ".", "ids", "[", "neighbor", "]", "\n", "if", "neighbor_sample", "in", "true_neighbors", ":", "\n", "                            ", "this_stat", "[", "0", "]", "+=", "1", "\n", "", "", "sample_stat", "[", "sample", "]", "=", "this_stat", "\n", "stats", "[", "classname", "]", "=", "sample_stat", "\n", "", "return", "stats", "\n", "\n", "", "def", "pnr", "(", "stats", ",", "k", "=", "1", ",", "msg", "=", "\"\"", ")", ":", "\n", "                ", "\"\"\" P: relevant & retrieved / retrieved\n                    R: relevant & retrieved / relevant \n                \"\"\"", "\n", "p", ",", "r", "=", "0.", ",", "0.", "# overall", "\n", "p_cls", ",", "r_cls", "=", "0.", ",", "0.", "# in-class", "\n", "pnr_by_class", "=", "defaultdict", "(", "list", ")", "\n", "nclass", "=", "len", "(", "sample_by_classname", ")", "\n", "for", "classname", ",", "class_stats", "in", "stats", ".", "items", "(", ")", ":", "\n", "                    ", "pnr_cls", "=", "pnr_by_class", ".", "get", "(", "classname", ",", "[", "0", "]", "*", "3", ")", "\n", "nrelevant", "=", "len", "(", "sample_by_classname", "[", "classname", "]", ")", "\n", "for", "sample", ",", "sample_stats", "in", "class_stats", ".", "items", "(", ")", ":", "\n", "                        ", "tp", "=", "sample_stats", "[", "0", "]", "\n", "this_p", "=", "tp", "/", "k", "\n", "this_r", "=", "tp", "/", "nrelevant", "\n", "p", "+=", "this_p", "\n", "r", "+=", "this_r", "\n", "pnr_cls", "[", "0", "]", "+=", "this_p", "\n", "pnr_cls", "[", "1", "]", "+=", "this_r", "\n", "", "pnr_cls", "[", "0", "]", "/=", "nrelevant", "\n", "pnr_cls", "[", "1", "]", "/=", "nrelevant", "\n", "pnr_by_class", "[", "classname", "]", "=", "pnr_cls", "\n", "p_cls", "+=", "pnr_cls", "[", "0", "]", "\n", "r_cls", "+=", "pnr_cls", "[", "1", "]", "\n", "", "p", "=", "(", "p", "/", "nsample", ")", "*", "100", "\n", "r", "=", "(", "r", "/", "nsample", ")", "*", "100", "\n", "p_cls", "=", "(", "p_cls", "/", "nclass", ")", "*", "100", "\n", "r_cls", "=", "(", "r_cls", "/", "nclass", ")", "*", "100", "\n", "return", "f\"{msg}: P@{k} {p:2.2f} R@{k} {r:2.2f} mAP {p_cls:2.2f} mAR {r_cls:2.2f}\"", "\n", "\n", "# x1 -> x2", "\n", "", "stats_12", "=", "topk_overlap", "(", "ind_12", ",", "k", "=", "1", ")", "\n", "msg_12", "=", "pnr", "(", "stats_12", ",", "k", "=", "1", ",", "msg", "=", "\"I->A\"", ")", "\n", "\n", "# x2 -> x1", "\n", "stats_21", "=", "topk_overlap", "(", "ind_21", ",", "k", "=", "1", ")", "\n", "msg_21", "=", "pnr", "(", "stats_21", ",", "k", "=", "1", ",", "msg", "=", "\"A->I\"", ")", "\n", "", "else", ":", "\n", "            ", "msg_12", "=", "msg_21", "=", "\"\"", "\n", "\n", "", "del", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "\n", "msg", "=", "\"\"", "if", "msg_12", "==", "msg_21", "==", "\"\"", "else", "f\"\\n{msg_12} {msg_21}\\n\"", "\n", "ref", "=", "\"\"", "if", "ref_metric", "==", "\"\"", "else", "f\"\\nREFERENCE\\n{ref_metric}\"", "\n", "report", "=", "f\"{msg}{p_12} {p_21} @ {x1s.shape[0]}{ref}\"", "\n", "return", "report", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.CELossHead.__init__": [[248, 257], ["loss_head.LossHead.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logit_scale", "=", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "if", "cfg", ".", "scaling", "else", "\n", "torch", ".", "ones", "(", "[", "]", ",", "requires_grad", "=", "False", ")", "*", "np", ".", "log", "(", "1", "/", "1", ")", "\n", ")", "\n", "self", ".", "scale_max", "=", "cfg", ".", "scale_max", "or", "float", "(", "\"inf\"", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "reduce", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.CELossHead.copy_state_dict": [[258, 264], ["loss_head.CELossHead.state_dict", "loss_head.CELossHead.load_state_dict", "loss_head.CELossHead.update"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "key", "=", "\"logit_scale\"", "\n", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "if", "key", "in", "new_dict", "and", "key", "in", "state_dict", ":", "\n", "            ", "new_dict", ".", "update", "(", "{", "key", ":", "state_dict", "[", "key", "]", "}", ")", "\n", "", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.CELossHead.forward": [[265, 285], ["loss_head.CELossHead.logit_scale.exp().clamp", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "loss_head.CELossHead.loss_fn", "loss_head.CELossHead.loss_fn", "kwargs.get", "x2.t", "x1.t", "loss_head.CELossHead.infer", "x1.norm", "x2.norm", "loss_head.CELossHead.logit_scale.exp", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "# normalized features", "\n", "", "if", "not", "kwargs", ".", "get", "(", "\"normalized\"", ",", "False", ")", ":", "\n", "            ", "x1", "=", "x1", "/", "x1", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x2", "=", "x2", "/", "x2", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "#print(f\"{threading.current_thread().ident} loss --{kwargs.get('normalized', False)}\")", "\n", "# cosine similarity as logits", "\n", "", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", ".", "clamp", "(", "max", "=", "self", ".", "scale_max", ")", "\n", "logits_per_x1", "=", "logit_scale", "*", "x1", "@", "x2", ".", "t", "(", ")", "\n", "logits_per_x2", "=", "logit_scale", "*", "x2", "@", "x1", ".", "t", "(", ")", "\n", "# cross entropy loss ", "\n", "labels", "=", "torch", ".", "arange", "(", "x1", ".", "shape", "[", "0", "]", ",", "device", "=", "x1", ".", "device", ")", "\n", "loss_mean_x1", "=", "self", ".", "loss_fn", "(", "logits_per_x1", ",", "labels", ")", "\n", "loss_mean_x2", "=", "self", ".", "loss_fn", "(", "logits_per_x2", ",", "labels", ")", "\n", "loss", "=", "loss_mean_x1", "+", "loss_mean_x2", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.__init__": [[289, 305], ["loss_head.LossHead.__init__", "list", "range", "list.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "list", "list.extend", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalized", "=", "False", "\n", "layers", "=", "list", "(", ")", "\n", "sizes", "=", "[", "cfg", ".", "embed_dim", "]", "+", "list", "(", "cfg", ".", "layers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "sizes", ")", "-", "2", ")", ":", "\n", "            ", "layers", ".", "extend", "(", "[", "\n", "nn", ".", "Linear", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "sizes", "[", "i", "+", "1", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "]", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sizes", "[", "-", "2", "]", ",", "sizes", "[", "-", "1", "]", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "sizes", "[", "-", "1", "]", ",", "affine", "=", "False", ")", "\n", "self", ".", "lambd_off", "=", "cfg", ".", "lambd_off", "\n", "self", ".", "reduce", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn": [[306, 313], ["torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "c.masked_select().pow_().sum", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "c.masked_select().pow_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "c.masked_select", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "c.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "loss_fn", "(", "c", ")", ":", "\n", "        ", "on_diag", "=", "torch", ".", "diagonal", "(", "c", ")", ".", "add_", "(", "-", "1", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "\n", "off_diag", "=", "c", ".", "masked_select", "(", "# more memory-efficient?", "\n", "~", "torch", ".", "eye", "(", "c", ".", "size", "(", "-", "1", ")", ",", "device", "=", "c", ".", "device", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "\n", "return", "on_diag", ",", "off_diag", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.forward": [[314, 329], ["loss_head.BarlowLossHead.linear", "loss_head.BarlowLossHead.linear", "c.div_", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "loss_head.BarlowLossHead.loss_fn", "loss_head.BarlowLossHead.bn", "loss_head.BarlowLossHead.size", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "loss_head.BarlowLossHead.infer", "loss_head.BarlowLossHead.bn", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "", "x1", "=", "self", ".", "linear", "(", "x1", ")", "\n", "x2", "=", "self", ".", "linear", "(", "x2", ")", "\n", "# empirical cross-correlation matrix", "\n", "c", "=", "self", ".", "bn", "(", "x1", ")", ".", "T", "@", "self", ".", "bn", "(", "x2", ")", "\n", "c", ".", "div_", "(", "x1", ".", "size", "(", "0", ")", ")", "\n", "if", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "c", ")", "\n", "", "on_diag", ",", "off_diag", "=", "self", ".", "loss_fn", "(", "c", ")", "\n", "loss", "=", "on_diag", "+", "self", ".", "lambd_off", "*", "off_diag", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.ClassificationHead.__init__": [[332, 344], ["loss_head.LossHead.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "clip.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalized", "=", "False", "\n", "assert", "\"output_dim\"", "in", "kwargs", ",", "f\"`the label number` is not found in `kwargs`\"", "\n", "nlabel", "=", "kwargs", "[", "\"output_dim\"", "]", "\n", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "\n", "LayerNorm", "(", "cfg", ".", "embed_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "cfg", ".", "embed_dim", ",", "nlabel", ")", "\n", ")", "\n", "self", ".", "logit_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "reduce", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.ClassificationHead.copy_state_dict": [[345, 350], ["loss_head.ClassificationHead.state_dict", "loss_head.ClassificationHead.update", "loss_head.ClassificationHead.load_state_dict", "state_dict.items"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "old_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "if", "k", "in", "new_dict", "}", "\n", "new_dict", ".", "update", "(", "old_dict", ")", "\n", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.ClassificationHead.infer": [[351, 364], ["loss_head.ClassificationHead.audios.append", "loss_head.ClassificationHead.linear", "loss_head.ClassificationHead.argmax", "loss_head.ClassificationHead.x1s.append", "loss_head.ClassificationHead.x2s.append", "kwargs.get", "loss_head.ClassificationHead.ids.extend", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["", "def", "infer", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"audios\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x1s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x2s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"ids\"", ")", ":", "\n", "            ", "self", ".", "audios", ",", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "", "self", ".", "audios", ".", "append", "(", "x1", ")", "\n", "logits_per_x1", "=", "self", ".", "linear", "(", "x1", ")", "\n", "predictions", "=", "logits_per_x1", ".", "argmax", "(", "-", "1", ")", "\n", "self", ".", "x1s", ".", "append", "(", "predictions", ")", "\n", "self", ".", "x2s", ".", "append", "(", "x2", ")", "\n", "names", "=", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "\n", "if", "names", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", ".", "extend", "(", "names", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.ClassificationHead.report": [[365, 408], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "kwargs.get", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "x12.argsort", "kwargs.get", "isinstance", "kwargs.get.t", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.norm", "torch.cat.norm", "torch.cat.norm", "kwargs.get.norm", "torch.tensor().view.flatten().tolist", "torch.tensor().view.flatten().tolist", "torch.tensor().view.flatten().tolist", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().view.flatten", "torch.tensor().view.flatten", "torch.tensor().view.flatten"], "methods", ["None"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "x1s", "=", "torch", ".", "cat", "(", "self", ".", "x1s", ")", "\n", "x2s", "=", "torch", ".", "cat", "(", "self", ".", "x2s", ")", "\n", "nsample", "=", "len", "(", "x1s", ")", "\n", "precision", "=", "(", "x1s", "==", "x2s", ")", ".", "sum", "(", ")", "/", "nsample", "*", "100.", "\n", "\n", "# zero-shot classification", "\n", "text", "=", "kwargs", ".", "get", "(", "\"text\"", ",", "None", ")", "\n", "if", "text", "is", "not", "None", ":", "\n", "            ", "audios", "=", "torch", ".", "cat", "(", "self", ".", "audios", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "self", ".", "x2s", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "if", "False", "and", "not", "self", ".", "normalized", ":", "\n", "                ", "audios", "=", "audios", "/", "audios", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "text", "=", "text", "/", "text", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "# audio -> label ", "\n", "", "x12", "=", "audios", "@", "text", ".", "t", "(", ")", "\n", "ind_12", "=", "x12", ".", "argsort", "(", "descending", "=", "True", ")", "\n", "\n", "# top-1 prediction", "\n", "predictions", "=", "ind_12", "[", ":", ",", ":", "1", "]", "\n", "label_map", "=", "kwargs", ".", "get", "(", "\"label_map\"", ",", "None", ")", "\n", "if", "isinstance", "(", "label_map", ",", "dict", ")", ":", "\n", "                ", "mapped_predictions", "=", "[", "\n", "label_map", "[", "x", "]", "for", "x", "in", "predictions", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "]", "\n", "predictions", "=", "torch", ".", "tensor", "(", "\n", "mapped_predictions", ",", "device", "=", "predictions", ".", "device", "\n", ")", ".", "view", "(", "predictions", ".", "shape", ")", "\n", "\n", "", "t12_1", "=", "(", "predictions", "==", "labels", ")", ".", "sum", "(", ")", "/", "x1s", ".", "shape", "[", "0", "]", "*", "100.", "\n", "\n", "#r12 = torch.where(ind_12 == labels)[1]", "\n", "#t12_1 = (r12 < 1).sum() / r12.shape[0] * 100.", "\n", "\n", "precision", "=", "t12_1", "\n", "", "else", ":", "\n", "            ", "pass", "#text = \"\"", "\n", "\n", "", "del", "self", ".", "audios", ",", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "\n", "report", "=", "(", "\n", "f\"A->T: p1 = {precision:2.2f} @ {nsample}\"", "\n", ")", "\n", "return", "report", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.ClassificationHead.forward": [[409, 420], ["loss_head.ClassificationHead.logit_scale.exp", "loss_head.ClassificationHead.loss_fn", "loss_head.ClassificationHead.linear", "loss_head.ClassificationHead.infer", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" x1 is the input features and x2 is the label\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_x1", "=", "logit_scale", "*", "self", ".", "linear", "(", "x1", ")", "\n", "loss_mean_x1", "=", "self", ".", "loss_fn", "(", "logits_per_x1", ",", "x2", ")", "\n", "return", "loss_mean_x1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VALCELossHead.__init__": [[423, 436], ["loss_head.LossHead.__init__", "loss_head.CELossHead", "loss_head.VALCELossHead._total_loss.update", "loss_head.CELossHead", "loss_head.VALCELossHead._total_loss.update", "loss_head.CELossHead", "loss_head.VALCELossHead._total_loss.update"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_head_va", "=", "self", ".", "loss_head_lv", "=", "self", ".", "loss_head_al", "=", "None", "\n", "self", ".", "_total_loss", "=", "{", "}", "# record loss", "\n", "if", "cfg", ".", "va", ":", "\n", "            ", "self", ".", "loss_head_va", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"va\"", ":", "0.", "}", ")", "\n", "", "if", "cfg", ".", "lv", ":", "\n", "            ", "self", ".", "loss_head_lv", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"lv\"", ":", "0.", "}", ")", "\n", "", "if", "cfg", ".", "al", ":", "\n", "            ", "self", ".", "loss_head_al", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"al\"", ":", "0.", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VALCELossHead.copy_state_dict": [[437, 439], ["None"], "methods", ["None"], ["", "", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VALCELossHead.infer": [[440, 452], ["loss_head.VALCELossHead.loss_head_va.infer", "loss_head.VALCELossHead.loss_head_lv.infer", "loss_head.VALCELossHead.loss_head_al.infer"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "infer", "(", "self", ",", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss_va", "=", "loss_lv", "=", "loss_al", "=", "0.", "\n", "if", "x1", "is", "not", "None", "and", "x2", "is", "not", "None", "and", "self", ".", "loss_head_va", "is", "not", "None", ":", "\n", "            ", "loss_va", "=", "self", ".", "loss_head_va", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "x1", "is", "not", "None", "and", "x3", "is", "not", "None", "and", "self", ".", "loss_head_lv", "is", "not", "None", ":", "\n", "            ", "loss_lv", "=", "self", ".", "loss_head_lv", ".", "infer", "(", "x1", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "x2", "is", "not", "None", "and", "x3", "is", "not", "None", "and", "self", ".", "loss_head_al", "is", "not", "None", ":", "\n", "            ", "loss_al", "=", "self", ".", "loss_head_al", ".", "infer", "(", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "loss_va", "=", "loss_va", "or", "0.", "\n", "loss_lv", "=", "loss_lv", "or", "0.", "\n", "loss_al", "=", "loss_al", "or", "0.", "\n", "return", "loss_va", "+", "loss_lv", "+", "loss_al", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VALCELossHead.stats": [[453, 458], ["loss_head.VALCELossHead._total_loss.items"], "methods", ["None"], ["", "def", "stats", "(", "self", ",", "nstep", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "msg", "=", "\" \"", ".", "join", "(", "[", "\n", "f\"{k} {v / nstep:.3f}\"", "for", "k", ",", "v", "in", "self", ".", "_total_loss", ".", "items", "(", ")", "\n", "]", ")", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VALCELossHead.report": [[459, 474], ["list", "list.append", "list.append", "list.append", "loss_head.VALCELossHead.loss_head_va.report", "loss_head.VALCELossHead.loss_head_lv.report", "loss_head.VALCELossHead.loss_head_al.report"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "report_list", "=", "list", "(", ")", "\n", "if", "self", ".", "loss_head_va", "is", "not", "None", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"VA: \"", "+", "self", ".", "loss_head_va", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "if", "self", ".", "loss_head_lv", "is", "not", "None", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"LV: \"", "+", "self", ".", "loss_head_lv", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "if", "self", ".", "loss_head_al", "is", "not", "None", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"AL: \"", "+", "self", ".", "loss_head_al", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "return", "\"\\n\"", "+", "\"\\n\"", ".", "join", "(", "report_list", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VALCELossHead.forward": [[475, 496], ["loss_head.VALCELossHead.loss_head_va", "loss_head.VALCELossHead.detach", "loss_head.VALCELossHead.loss_head_lv", "loss_head.VALCELossHead.detach", "loss_head.VALCELossHead.loss_head_al", "loss_head.VALCELossHead.detach", "loss_head.VALCELossHead.infer", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" v: x1; a: x2; l: x3\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "\n", "", "loss_va", "=", "loss_lv", "=", "loss_al", "=", "0.", "\n", "if", "x1", "is", "not", "None", "and", "x2", "is", "not", "None", "and", "self", ".", "loss_head_va", "is", "not", "None", ":", "\n", "            ", "loss_va", "=", "self", ".", "loss_head_va", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"va\"", "]", "+=", "loss_va", ".", "detach", "(", ")", "\n", "", "if", "x1", "is", "not", "None", "and", "x3", "is", "not", "None", "and", "self", ".", "loss_head_lv", "is", "not", "None", ":", "\n", "            ", "loss_lv", "=", "self", ".", "loss_head_lv", "(", "x1", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"lv\"", "]", "+=", "loss_lv", ".", "detach", "(", ")", "\n", "", "if", "x2", "is", "not", "None", "and", "x3", "is", "not", "None", "and", "self", ".", "loss_head_al", "is", "not", "None", ":", "\n", "            ", "loss_al", "=", "self", ".", "loss_head_al", "(", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"al\"", "]", "+=", "loss_al", ".", "detach", "(", ")", "\n", "\n", "", "loss", "=", "loss_va", "+", "loss_lv", "+", "loss_al", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VACELossHead.__init__": [[499, 519], ["loss_head.LossHead.__init__", "loss_head.CELossHead", "loss_head.VACELossHead._total_loss.update", "loss_head.CELossHead", "loss_head.VACELossHead._total_loss.update", "loss_head.CELossHead", "loss_head.VACELossHead._total_loss.update", "loss_head.CELossHead", "loss_head.VACELossHead._total_loss.update", "loss_head.CELossHead", "loss_head.VACELossHead._total_loss.update"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_head_vp", "=", "self", ".", "loss_head_ap", "=", "self", ".", "loss_head_va", "=", "self", ".", "loss_head_vv", "=", "self", ".", "loss_head_aa", "=", "None", "\n", "self", ".", "_total_loss", "=", "{", "}", "# record loss", "\n", "if", "cfg", ".", "vp", ":", "# vision -> prime (`gold` image features)", "\n", "            ", "self", ".", "loss_head_vp", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"vp\"", ":", "0.", "}", ")", "\n", "", "if", "cfg", ".", "ap", ":", "# audio  -> prime (`gold` image features)", "\n", "            ", "self", ".", "loss_head_ap", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"ap\"", ":", "0.", "}", ")", "\n", "", "if", "cfg", ".", "va", ":", "# vision -> audio", "\n", "            ", "self", ".", "loss_head_va", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"va\"", ":", "0.", "}", ")", "\n", "", "if", "cfg", ".", "vv", ":", "# vision -> vision", "\n", "            ", "self", ".", "loss_head_vv", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"vv\"", ":", "0.", "}", ")", "\n", "", "if", "cfg", ".", "aa", ":", "# audio  -> audio", "\n", "            ", "self", ".", "loss_head_aa", "=", "CELossHead", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"aa\"", ":", "0.", "}", ")", "\n", "", "self", ".", "vp_w", ",", "self", ".", "ap_w", ",", "self", ".", "va_w", ",", "self", ".", "vv_w", ",", "self", ".", "aa_w", "=", "cfg", ".", "vp_w", ",", "cfg", ".", "ap_w", ",", "cfg", ".", "va_w", ",", "cfg", ".", "vv_w", ",", "cfg", ".", "aa_w", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VACELossHead.copy_state_dict": [[520, 522], ["None"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VACELossHead.infer": [[523, 541], ["loss_head.VACELossHead.loss_head_vp.infer", "loss_head.VACELossHead.loss_head_ap.infer", "loss_head.VACELossHead.loss_head_va.infer", "loss_head.VACELossHead.loss_head_vv.infer", "loss_head.VACELossHead.loss_head_aa.infer"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "infer", "(", "self", ",", "images", ",", "images_v1", ",", "audios_v1", ",", "images_v2", "=", "None", ",", "audios_v2", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss_vp", "=", "loss_ap", "=", "loss_va", "=", "loss_vv", "=", "loss_aa", "=", "0.", "\n", "if", "images", "is", "not", "None", "and", "images_v1", "is", "not", "None", "and", "self", ".", "loss_head_vp", "is", "not", "None", ":", "\n", "            ", "loss_vp", "=", "self", ".", "loss_head_vp", ".", "infer", "(", "images_v1", ",", "images", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "images", "is", "not", "None", "and", "audios_v1", "is", "not", "None", "and", "self", ".", "loss_head_ap", "is", "not", "None", ":", "\n", "            ", "loss_ap", "=", "self", ".", "loss_head_ap", ".", "infer", "(", "audios_v1", ",", "images", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "images_v1", "is", "not", "None", "and", "audios_v1", "is", "not", "None", "and", "self", ".", "loss_head_va", "is", "not", "None", ":", "\n", "            ", "loss_va", "=", "self", ".", "loss_head_va", ".", "infer", "(", "images_v1", ",", "audios_v1", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "images_v1", "is", "not", "None", "and", "images_v2", "is", "not", "None", "and", "self", ".", "loss_head_vv", "is", "not", "None", ":", "\n", "            ", "loss_vv", "=", "self", ".", "loss_head_vv", ".", "infer", "(", "images_v1", ",", "images_v2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "audios_v1", "is", "not", "None", "and", "audios_v2", "is", "not", "None", "and", "self", ".", "loss_head_aa", "is", "not", "None", ":", "\n", "            ", "loss_aa", "=", "self", ".", "loss_head_aa", ".", "infer", "(", "audios_v1", ",", "audios_v2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "loss_vp", "=", "loss_vp", "or", "0.", "\n", "loss_ap", "=", "loss_ap", "or", "0.", "\n", "loss_va", "=", "loss_va", "or", "0.", "\n", "loss_vv", "=", "loss_vv", "or", "0.", "\n", "loss_aa", "=", "loss_aa", "or", "0.", "\n", "return", "loss_vp", "+", "loss_ap", "+", "loss_va", "+", "loss_vv", "+", "loss_aa", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VACELossHead.stats": [[542, 547], ["loss_head.VACELossHead._total_loss.items"], "methods", ["None"], ["", "def", "stats", "(", "self", ",", "nstep", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "msg", "=", "\" \"", ".", "join", "(", "[", "\n", "f\"{k} {v / nstep:.3f}\"", "for", "k", ",", "v", "in", "self", ".", "_total_loss", ".", "items", "(", ")", "\n", "]", ")", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VACELossHead.report": [[548, 571], ["list", "hasattr", "list.append", "hasattr", "list.append", "hasattr", "list.append", "hasattr", "list.append", "hasattr", "list.append", "loss_head.VACELossHead.loss_head_vp.report", "loss_head.VACELossHead.loss_head_ap.report", "loss_head.VACELossHead.loss_head_va.report", "loss_head.VACELossHead.loss_head_vv.report", "loss_head.VACELossHead.loss_head_aa.report"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "report_list", "=", "list", "(", ")", "\n", "if", "self", ".", "loss_head_vp", "is", "not", "None", "and", "hasattr", "(", "self", ".", "loss_head_vp", ",", "\"x1s\"", ")", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"VP: \"", "+", "self", ".", "loss_head_vp", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "if", "self", ".", "loss_head_ap", "is", "not", "None", "and", "hasattr", "(", "self", ".", "loss_head_ap", ",", "\"x1s\"", ")", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"AP: \"", "+", "self", ".", "loss_head_ap", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "if", "self", ".", "loss_head_va", "is", "not", "None", "and", "hasattr", "(", "self", ".", "loss_head_va", ",", "\"x1s\"", ")", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"VA: \"", "+", "self", ".", "loss_head_va", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "if", "self", ".", "loss_head_vv", "is", "not", "None", "and", "hasattr", "(", "self", ".", "loss_head_vv", ",", "\"x1s\"", ")", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"VV: \"", "+", "self", ".", "loss_head_vv", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "if", "self", ".", "loss_head_aa", "is", "not", "None", "and", "hasattr", "(", "self", ".", "loss_head_aa", ",", "\"x1s\"", ")", ":", "\n", "            ", "report_list", ".", "append", "(", "\n", "\"AA: \"", "+", "self", ".", "loss_head_aa", ".", "report", "(", "gold_file", ")", "\n", ")", "\n", "", "return", "\"\\n\"", "+", "\"\\n\"", ".", "join", "(", "report_list", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.VACELossHead.forward": [[572, 599], ["loss_head.VACELossHead.loss_head_vp", "loss_head.VACELossHead.detach", "loss_head.VACELossHead.loss_head_ap", "loss_head.VACELossHead.detach", "loss_head.VACELossHead.loss_head_va", "loss_head.VACELossHead.detach", "loss_head.VACELossHead.loss_head_vv", "loss_head.VACELossHead.detach", "loss_head.VACELossHead.loss_head_aa", "loss_head.VACELossHead.detach", "loss_head.VACELossHead.infer", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "images", ",", "images_v1", ",", "audios_v1", ",", "images_v2", "=", "None", ",", "audios_v2", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "\n", "images", ",", "images_v1", ",", "audios_v1", ",", "images_v2", "=", "images_v2", ",", "audios_v2", "=", "audios_v2", ",", "*", "args", ",", "**", "kwargs", "\n", ")", "\n", "", "return", "None", "\n", "\n", "", "loss_vp", "=", "loss_ap", "=", "loss_va", "=", "loss_vv", "=", "loss_aa", "=", "0.", "\n", "if", "images", "is", "not", "None", "and", "images_v1", "is", "not", "None", "and", "self", ".", "loss_head_vp", "is", "not", "None", ":", "\n", "            ", "loss_vp", "=", "self", ".", "loss_head_vp", "(", "images_v1", ",", "images", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"vp\"", "]", "+=", "loss_vp", ".", "detach", "(", ")", "\n", "", "if", "images", "is", "not", "None", "and", "audios_v1", "is", "not", "None", "and", "self", ".", "loss_head_ap", "is", "not", "None", ":", "\n", "            ", "loss_ap", "=", "self", ".", "loss_head_ap", "(", "audios_v1", ",", "images", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"ap\"", "]", "+=", "loss_ap", ".", "detach", "(", ")", "\n", "", "if", "images_v1", "is", "not", "None", "and", "audios_v1", "is", "not", "None", "and", "self", ".", "loss_head_va", "is", "not", "None", ":", "\n", "            ", "loss_va", "=", "self", ".", "loss_head_va", "(", "images_v1", ",", "audios_v1", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"va\"", "]", "+=", "loss_va", ".", "detach", "(", ")", "\n", "", "if", "images_v1", "is", "not", "None", "and", "images_v2", "is", "not", "None", "and", "self", ".", "loss_head_vv", "is", "not", "None", ":", "\n", "            ", "loss_vv", "=", "self", ".", "loss_head_vv", "(", "images_v1", ",", "images_v2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"vv\"", "]", "+=", "loss_vv", ".", "detach", "(", ")", "\n", "", "if", "audios_v1", "is", "not", "None", "and", "audios_v2", "is", "not", "None", "and", "self", ".", "loss_head_aa", "is", "not", "None", ":", "\n", "            ", "loss_aa", "=", "self", ".", "loss_head_aa", "(", "audios_v1", ",", "audios_v2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"aa\"", "]", "+=", "loss_aa", ".", "detach", "(", ")", "\n", "\n", "", "loss", "=", "self", ".", "vp_w", "*", "loss_vp", "+", "self", ".", "ap_w", "*", "loss_ap", "+", "self", ".", "va_w", "*", "loss_va", "+", "self", ".", "vv_w", "*", "loss_vv", "+", "self", ".", "aa_w", "*", "loss_aa", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowCELossHead.__init__": [[603, 610], ["loss_head.LossHead.__init__", "loss_head.build_loss_head", "loss_head.build_loss_head"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalized", "=", "False", "\n", "self", ".", "loss_ce", "=", "build_loss_head", "(", "cfg", ".", "ce", ",", "**", "kwargs", ")", "\n", "self", ".", "loss_barlow", "=", "build_loss_head", "(", "cfg", ".", "barlow", ",", "**", "kwargs", ")", "\n", "self", ".", "lambd_barlow", "=", "cfg", ".", "lambd_barlow", "\n", "self", ".", "reduce", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowCELossHead.report": [[611, 613], ["loss_head.BarlowCELossHead.loss_ce.report"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "loss_ce", ".", "report", "(", "gold_file", "=", "gold_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowCELossHead.forward": [[614, 623], ["loss_head.BarlowCELossHead.loss_ce", "loss_head.BarlowCELossHead.loss_barlow", "loss_head.BarlowCELossHead.loss_ce.infer", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "loss_ce", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "", "loss_ce", "=", "self", ".", "loss_ce", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "loss_barlow", "=", "self", ".", "loss_barlow", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "loss", "=", "loss_ce", "+", "self", ".", "lambd_barlow", "*", "loss_barlow", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head": [[22, 24], ["LOSS_HEADS_REGISTRY.get"], "function", ["None"], ["def", "build_loss_head", "(", "cfg", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "LOSS_HEADS_REGISTRY", ".", "get", "(", "cfg", ".", "name", ")", "(", "cfg", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCELossHead.__init__": [[30, 54], ["loss_head.LossHead.__init__", "list", "range", "list.extend", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "list.extend", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "list", "len", "clip.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log", "clip.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalized", "=", "False", "\n", "assert", "\"output_dim\"", "in", "kwargs", ",", "f\"`the label number` is not found in `kwargs`\"", "\n", "nlabel", "=", "kwargs", "[", "\"output_dim\"", "]", "\n", "layers", "=", "list", "(", ")", "\n", "embed_dim", "=", "cfg", ".", "embed_dim", "or", "cfg", ".", "width", "\n", "sizes", "=", "[", "embed_dim", "]", "+", "list", "(", "cfg", ".", "layers", ")", "+", "[", "nlabel", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sizes", ")", "-", "2", ")", ":", "\n", "            ", "layers", ".", "extend", "(", "[", "\n", "LayerNorm", "(", "sizes", "[", "i", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ")", ",", "\n", "]", ")", "\n", "", "layers", ".", "extend", "(", "[", "\n", "LayerNorm", "(", "sizes", "[", "-", "2", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "sizes", "[", "-", "2", "]", ",", "sizes", "[", "-", "1", "]", ",", "bias", "=", "cfg", ".", "bias", ")", "\n", "]", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "logit_scale", "=", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "if", "cfg", ".", "scaling", "else", "\n", "torch", ".", "ones", "(", "[", "]", ",", "requires_grad", "=", "False", ")", "*", "np", ".", "log", "(", "1", "/", "1", ")", "\n", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "self", ".", "reduce", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCELossHead.copy_state_dict": [[55, 60], ["loss_more.BCELossHead.state_dict", "loss_more.BCELossHead.update", "loss_more.BCELossHead.load_state_dict"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "key", "=", "\"logit_scale\"", "\n", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "new_dict", ".", "update", "(", "{", "key", ":", "state_dict", "[", "key", "]", "}", ")", "\n", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCELossHead.infer": [[61, 76], ["loss_more.BCELossHead.audios.append", "loss_more.BCELossHead.logit_scale.exp", "loss_more.BCELossHead.loss_fn", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "loss_more.BCELossHead.x1s.append", "loss_more.BCELossHead.x2s.append", "kwargs.get", "loss_more.BCELossHead.linear", "x2.float", "loss_more.BCELossHead.ids.extend", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn"], ["", "def", "infer", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"audios\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x1s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x2s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"ids\"", ")", ":", "\n", "            ", "self", ".", "audios", ",", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "", "self", ".", "audios", ".", "append", "(", "x1", ")", "\n", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_x1", "=", "logit_scale", "*", "self", ".", "linear", "(", "x1", ")", "\n", "loss_mean_x1", "=", "self", ".", "loss_fn", "(", "logits_per_x1", ",", "x2", ".", "float", "(", ")", ")", "\n", "predictions", "=", "torch", ".", "sigmoid", "(", "logits_per_x1", ")", "\n", "self", ".", "x1s", ".", "append", "(", "predictions", ")", "\n", "self", ".", "x2s", ".", "append", "(", "x2", ")", "\n", "names", "=", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "\n", "if", "names", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", ".", "extend", "(", "names", ")", "\n", "", "return", "loss_mean_x1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCELossHead.zero_shot": [[77, 85], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "loss_more.BCELossHead.report", "text.t", "torch.cat.norm", "torch.cat.norm", "torch.cat.norm", "text.norm", "x1s.cpu().numpy", "x1s.cpu"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "zero_shot", "(", "self", ",", "text", ",", "gold_file", ")", ":", "\n", "        ", "audios", "=", "torch", ".", "cat", "(", "self", ".", "audios", ")", "\n", "if", "True", "and", "not", "self", ".", "normalized", ":", "\n", "            ", "audios", "=", "audios", "/", "audios", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "text", "=", "text", "/", "text", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "# audio -> label", "\n", "", "x1s", "=", "audios", "@", "text", ".", "t", "(", ")", "\n", "return", "self", ".", "report", "(", "gold_file", "=", "gold_file", ",", "text", "=", "None", ",", "x1s", "=", "x1s", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCELossHead.report": [[86, 132], ["kwargs.get", "sklearn.metrics.average_precision_score", "sklearn.metrics.average_precision_score", "sklearn.metrics.average_precision_score", "range", "loss_more.BCELossHead.zero_shot", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "sklearn.metrics.average_precision_score", "math.isnan", "sklearn.metrics.precision_recall_curve", "ap_list.append", "auc_list.append", "precisions.append", "recalls.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "sklearn.metrics.roc_auc_score", "len", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.zero_shot"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "x1s", "=", "None", ",", "x2s", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# zero-shot classification", "\n", "        ", "text", "=", "kwargs", ".", "get", "(", "\"text\"", ",", "None", ")", "\n", "if", "text", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "zero_shot", "(", "text", ",", "gold_file", ")", "\n", "# supervised classification", "\n", "", "x1s", "=", "torch", ".", "cat", "(", "self", ".", "x1s", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "if", "x1s", "is", "None", "else", "x1s", "\n", "x2s", "=", "torch", ".", "cat", "(", "self", ".", "x2s", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "if", "x2s", "is", "None", "else", "x2s", "\n", "nsample", ",", "nlabel", "=", "x1s", ".", "shape", "[", ":", "2", "]", "\n", "\n", "ap_micro", "=", "metrics", ".", "average_precision_score", "(", "x2s", ",", "x1s", ",", "average", "=", "'micro'", ")", "\n", "ap_macro", "=", "metrics", ".", "average_precision_score", "(", "x2s", ",", "x1s", ",", "average", "=", "'macro'", ")", "\n", "ap_weighted", "=", "metrics", ".", "average_precision_score", "(", "x2s", ",", "x1s", ",", "average", "=", "'weighted'", ")", "\n", "\n", "# multi-label classification metrics", "\n", "has_err", "=", "False", "\n", "ap_list", ",", "auc_list", ",", "precisions", ",", "recalls", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "k", "in", "range", "(", "nlabel", ")", ":", "# unnecessary (from AST)", "\n", "            ", "y_true", ",", "y_score", "=", "x2s", "[", ":", ",", "k", "]", ",", "x1s", "[", ":", ",", "k", "]", "\n", "ap", "=", "metrics", ".", "average_precision_score", "(", "y_true", ",", "y_score", ",", "average", "=", "None", ")", "\n", "if", "math", ".", "isnan", "(", "ap", ")", ":", "\n", "                ", "ap", "=", "0.", "\n", "has_err", "=", "True", "\n", "", "try", ":", "\n", "                ", "auc", "=", "metrics", ".", "roc_auc_score", "(", "y_true", ",", "y_score", ",", "average", "=", "None", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "auc", "=", "0.", "# auc may not be used a valid metric for this task", "\n", "has_err", "=", "True", "\n", "", "p", ",", "r", ",", "_", "=", "metrics", ".", "precision_recall_curve", "(", "y_true", ",", "y_score", ")", "\n", "mid", "=", "len", "(", "p", ")", "//", "2", "\n", "ap_list", ".", "append", "(", "ap", ")", "\n", "auc_list", ".", "append", "(", "auc", ")", "\n", "precisions", ".", "append", "(", "p", "[", "mid", "]", ")", "\n", "recalls", ".", "append", "(", "r", "[", "mid", "]", ")", "\n", "", "mean_ap", "=", "np", ".", "mean", "(", "ap_list", ")", "*", "100.", "\n", "mean_auc", "=", "np", ".", "mean", "(", "auc_list", ")", "*", "100.", "\n", "mean_p", "=", "np", ".", "mean", "(", "precisions", ")", "*", "100.", "\n", "mean_r", "=", "np", ".", "mean", "(", "recalls", ")", "*", "100.", "\n", "text", "=", "(", "\n", "f\"Err({has_err}) mAP = {mean_ap:2.2f} mAUC = {mean_auc:2.2f} mP = {mean_p:2.2f} mR = {mean_r:2.2f}\"", "\n", ")", "\n", "\n", "del", "self", ".", "audios", ",", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "\n", "common", "=", "f\"Mac-AP = {ap_macro:2.2f} Mic-AP = {ap_micro:2.2f} wAP = {ap_weighted:2.2f}\"", "\n", "report", "=", "f\"{common} {text} @ {nsample}\"", "\n", "return", "report", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCELossHead.forward": [[133, 144], ["loss_more.BCELossHead.logit_scale.exp", "loss_more.BCELossHead.loss_fn", "loss_more.BCELossHead.linear", "x2.float", "loss_more.BCELossHead.infer", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" x1 is the input features and x2 is the label\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_x1", "=", "logit_scale", "*", "self", ".", "linear", "(", "x1", ")", "\n", "loss_mean_x1", "=", "self", ".", "loss_fn", "(", "logits_per_x1", ",", "x2", ".", "float", "(", ")", ")", "\n", "return", "loss_mean_x1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCHingeLossHead.__init__": [[146, 149], ["loss_more.BCELossHead.__init__", "torch.nn.MultiLabelMarginLoss", "torch.nn.MultiLabelMarginLoss", "torch.nn.MultiLabelMarginLoss"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "MultiLabelMarginLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCHingeLossHead.convert_label": [[150, 167], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.append", "torch.stack.append", "torch.stack.append", "label[].nonzero", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lid.new_zeros().fill_", "lid.new_zeros", "len"], "methods", ["None"], ["", "def", "convert_label", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\" label: binary matrix\n        \"\"\"", "\n", "#sequences = []", "\n", "#for i in range(len(label)):", "\n", "#    lid = label[i].nonzero(as_tuple=True)[0]", "\n", "#    sequences.append(lid)", "\n", "#sequences = pad_sequence(sequences, batch_first=True, padding_value=-1)", "\n", "sequences", "=", "[", "]", "\n", "bsize", ",", "length", "=", "label", ".", "shape", "\n", "for", "i", "in", "range", "(", "bsize", ")", ":", "\n", "            ", "lid", "=", "label", "[", "i", "]", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "[", "0", "]", "\n", "sequences", ".", "append", "(", "torch", ".", "cat", "(", "\n", "(", "lid", ",", "lid", ".", "new_zeros", "(", "length", "-", "len", "(", "lid", ")", ")", ".", "fill_", "(", "-", "1", ")", ")", "\n", ")", ")", "\n", "", "sequences", "=", "torch", ".", "stack", "(", "sequences", ",", "0", ")", "\n", "return", "sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCHingeLossHead.infer": [[168, 185], ["loss_more.BCHingeLossHead.audios.append", "loss_more.BCHingeLossHead.logit_scale.exp", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "loss_more.BCHingeLossHead.convert_label", "loss_more.BCHingeLossHead.loss_fn", "loss_more.BCHingeLossHead.x1s.append", "loss_more.BCHingeLossHead.x2s.append", "kwargs.get", "loss_more.BCHingeLossHead.linear", "loss_more.BCHingeLossHead.ids.extend", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCHingeLossHead.convert_label", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn"], ["", "def", "infer", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"audios\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x1s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x2s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"ids\"", ")", ":", "\n", "            ", "self", ".", "audios", ",", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "", "self", ".", "audios", ".", "append", "(", "x1", ")", "\n", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_x1", "=", "logit_scale", "*", "self", ".", "linear", "(", "x1", ")", "\n", "logits_per_x1", "=", "torch", ".", "sigmoid", "(", "logits_per_x1", ")", "\n", "label", "=", "self", ".", "convert_label", "(", "x2", ")", "\n", "loss_mean_x1", "=", "self", ".", "loss_fn", "(", "logits_per_x1", ",", "label", ")", "\n", "predictions", "=", "logits_per_x1", "#torch.sigmoid(logits_per_x1)", "\n", "self", ".", "x1s", ".", "append", "(", "predictions", ")", "\n", "self", ".", "x2s", ".", "append", "(", "x2", ")", "\n", "names", "=", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "\n", "if", "names", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", ".", "extend", "(", "names", ")", "\n", "", "return", "loss_mean_x1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCHingeLossHead.forward": [[186, 199], ["loss_more.BCHingeLossHead.logit_scale.exp", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "loss_more.BCHingeLossHead.convert_label", "loss_more.BCHingeLossHead.loss_fn", "loss_more.BCHingeLossHead.linear", "loss_more.BCHingeLossHead.infer", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.BCHingeLossHead.convert_label", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" x1 is the input features and x2 is the label\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_x1", "=", "logit_scale", "*", "self", ".", "linear", "(", "x1", ")", "\n", "logits_per_x1", "=", "torch", ".", "sigmoid", "(", "logits_per_x1", ")", "\n", "label", "=", "self", ".", "convert_label", "(", "x2", ")", "\n", "loss_mean_x1", "=", "self", ".", "loss_fn", "(", "logits_per_x1", ",", "label", ")", "\n", "return", "loss_mean_x1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.ImagineAndClassifyLossHead.__init__": [[203, 232], ["loss_head.LossHead.__init__", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "loss_head.build_loss_head", "loss_more.ImagineAndClassifyLossHead._total_loss.update", "loss_head.build_loss_head", "loss_more.ImagineAndClassifyLossHead._total_loss.update", "len", "list", "range", "list.extend", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "list", "list.extend", "len", "clip.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "clip.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_ce", "=", "self", ".", "loss_bce", "=", "None", "\n", "self", ".", "normalized", "=", "False", "\n", "self", ".", "_total_loss", "=", "{", "}", "\n", "if", "cfg", ".", "ce", ".", "alive", ":", "\n", "            ", "self", ".", "loss_ce", "=", "build_loss_head", "(", "cfg", ".", "ce", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"ce\"", ":", "0.", "}", ")", "\n", "", "if", "cfg", ".", "bce", ".", "alive", ":", "\n", "            ", "self", ".", "loss_bce", "=", "build_loss_head", "(", "cfg", ".", "bce", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", ".", "update", "(", "{", "\"bce\"", ":", "0.", "}", ")", "\n", "", "self", ".", "lambd_ce", "=", "cfg", ".", "lambd_ce", "\n", "self", ".", "reduce", "=", "True", "\n", "# audio -> vision", "\n", "self", ".", "a2v", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "len", "(", "cfg", ".", "layers", ")", ">", "0", ":", "\n", "            ", "layers", "=", "list", "(", ")", "\n", "embed_dim", "=", "cfg", ".", "bce", ".", "embed_dim", "or", "cfg", ".", "bce", ".", "width", "\n", "sizes", "=", "[", "embed_dim", "]", "+", "list", "(", "cfg", ".", "layers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "sizes", ")", "-", "2", ")", ":", "\n", "                ", "layers", ".", "extend", "(", "[", "\n", "LayerNorm", "(", "sizes", "[", "i", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ")", ",", "\n", "]", ")", "\n", "", "layers", ".", "extend", "(", "[", "\n", "LayerNorm", "(", "sizes", "[", "-", "2", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "sizes", "[", "-", "2", "]", ",", "sizes", "[", "-", "1", "]", ",", "bias", "=", "cfg", ".", "bias", ")", "\n", "]", ")", "\n", "self", ".", "a2v", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.ImagineAndClassifyLossHead.stats": [[233, 238], ["loss_more.ImagineAndClassifyLossHead._total_loss.items"], "methods", ["None"], ["", "", "def", "stats", "(", "self", ",", "nstep", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "msg", "=", "\" \"", ".", "join", "(", "[", "\n", "f\"{k} {v / nstep:.3f}\"", "for", "k", ",", "v", "in", "self", ".", "_total_loss", ".", "items", "(", ")", "\n", "]", ")", "\n", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.ImagineAndClassifyLossHead.report": [[239, 246], ["hasattr", "hasattr", "loss_more.ImagineAndClassifyLossHead.loss_ce.report", "loss_more.ImagineAndClassifyLossHead.loss_bce.report"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "report_ce", "=", "report_bce", "=", "\"\"", "\n", "if", "self", ".", "loss_ce", "is", "not", "None", "and", "hasattr", "(", "self", ".", "loss_ce", ",", "\"x1s\"", ")", "and", "hasattr", "(", "self", ".", "loss_ce", ",", "\"x2s\"", ")", ":", "\n", "            ", "report_ce", "=", "self", ".", "loss_ce", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "if", "self", ".", "loss_bce", "is", "not", "None", ":", "\n", "            ", "report_bce", "=", "self", ".", "loss_bce", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "return", "f\"{report_ce}\\n{report_bce}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.ImagineAndClassifyLossHead.infer": [[247, 256], ["loss_more.ImagineAndClassifyLossHead.loss_ce.infer", "loss_more.ImagineAndClassifyLossHead.loss_bce.infer", "loss_more.ImagineAndClassifyLossHead.a2v"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "infer", "(", "self", ",", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss_ce", "=", "loss_bce", "=", "0.", "\n", "if", "self", ".", "loss_ce", "is", "not", "None", "and", "x3", "is", "not", "None", ":", "\n", "            ", "loss_ce", "=", "self", ".", "loss_ce", ".", "infer", "(", "self", ".", "a2v", "(", "x1", ")", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "if", "self", ".", "loss_bce", "is", "not", "None", ":", "\n", "            ", "loss_bce", "=", "self", ".", "loss_bce", ".", "infer", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "loss_ce", "=", "loss_ce", "or", "0.", "\n", "loss_bce", "=", "loss_bce", "or", "0.", "\n", "return", "loss_ce", "+", "loss_bce", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.ImagineAndClassifyLossHead.forward": [[257, 275], ["loss_more.ImagineAndClassifyLossHead.loss_ce", "loss_more.ImagineAndClassifyLossHead.detach", "loss_more.ImagineAndClassifyLossHead.loss_bce", "loss_more.ImagineAndClassifyLossHead.detach", "loss_more.ImagineAndClassifyLossHead.infer", "loss_more.ImagineAndClassifyLossHead.a2v", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "*", "args", ",", "x3", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" x1 is (audio) features, x2 is (audio) labels, and x3 is mirror (image) features\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "\n", "", "loss_ce", "=", "loss_bce", "=", "0.", "\n", "if", "self", ".", "loss_ce", "is", "not", "None", "and", "x3", "is", "not", "None", ":", "\n", "            ", "loss_ce", "=", "self", ".", "loss_ce", "(", "self", ".", "a2v", "(", "x1", ")", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"ce\"", "]", "+=", "loss_ce", ".", "detach", "(", ")", "\n", "", "if", "self", ".", "loss_bce", "is", "not", "None", ":", "\n", "            ", "loss_bce", "=", "self", ".", "loss_bce", "(", "x1", ",", "x2", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_total_loss", "[", "\"bce\"", "]", "+=", "loss_bce", ".", "detach", "(", ")", "\n", "\n", "", "loss", "=", "self", ".", "lambd_ce", "*", "loss_ce", "+", "loss_bce", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.__init__": [[277, 288], ["loss_head.LossHead.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logit_scale", "=", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "if", "cfg", ".", "scaling", "else", "\n", "torch", ".", "ones", "(", "[", "]", ",", "requires_grad", "=", "False", ")", "*", "np", ".", "log", "(", "1", "/", "1", ")", "\n", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "0", ")", "\n", "self", ".", "max_len_dec", "=", "cfg", ".", "max_len_dec", "\n", "self", ".", "sot_token", "=", "\"<|startoftext|>\"", "\n", "self", ".", "eot_token", "=", "\"<|endoftext|>\"", "\n", "self", ".", "reduce", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict": [[289, 295], ["loss_more.LMLossHead.state_dict", "loss_more.LMLossHead.load_state_dict", "loss_more.LMLossHead.update"], "methods", ["None"], ["", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "key", "=", "\"logit_scale\"", "\n", "new_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "if", "key", "in", "new_dict", "and", "key", "in", "state_dict", ":", "\n", "            ", "new_dict", ".", "update", "(", "{", "key", ":", "state_dict", "[", "key", "]", "}", ")", "\n", "", "self", ".", "load_state_dict", "(", "new_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.infer": [[296, 316], ["kwargs.get", "x3.cpu().tolist", "enumerate", "loss_more.LMLossHead.ids.extend", "clip._tokenizer.decode", "x.replace.replace.replace", "x.replace.replace.find", "loss_more.LMLossHead.x1s.append", "hasattr", "hasattr", "hasattr", "x3.cpu", "x.replace.replace.strip().split", "x.replace.replace.strip"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.decode"], ["", "def", "infer", "(", "self", ",", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"x1s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"x2s\"", ")", "or", "not", "hasattr", "(", "self", ",", "\"ids\"", ")", ":", "\n", "            ", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "", "names", "=", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "\n", "if", "names", "is", "not", "None", ":", "\n", "            ", "self", ".", "ids", ".", "extend", "(", "names", ")", "\n", "", "predictions", "=", "x3", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "for", "isample", ",", "x", "in", "enumerate", "(", "predictions", ")", ":", "\n", "            ", "x", "=", "_tokenizer", ".", "decode", "(", "x", ")", "\n", "x", "=", "x", ".", "replace", "(", "self", ".", "sot_token", ",", "\"\"", ")", "\n", "eot_pos", "=", "x", ".", "find", "(", "self", ".", "eot_token", ")", "\n", "if", "eot_pos", ">", "0", ":", "\n", "                ", "x", "=", "x", "[", ":", "eot_pos", "]", "\n", "", "x", "=", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "[", ":", "self", ".", "max_len_dec", "]", "\n", "x", "=", "\" \"", ".", "join", "(", "x", ")", "\n", "self", ".", "x1s", ".", "append", "(", "{", "\n", "\"file_name\"", ":", "names", "[", "isample", "]", ",", "\n", "\"caption_predicted\"", ":", "x", ",", "\n", "}", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.is_json": [[317, 327], ["open", "next", "json.loads", "isinstance"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_json", "(", "gold_file", ")", ":", "\n", "        ", "with", "open", "(", "gold_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "line", "=", "next", "(", "fr", ")", "\n", "try", ":", "\n", "                ", "line", "=", "json", ".", "loads", "(", "line", ")", "\n", "is_json", "=", "isinstance", "(", "line", ",", "dict", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "is_json", "=", "False", "\n", "", "", "return", "is_json", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.report": [[328, 372], ["list", "len", "loss_more.LMLossHead.is_json", "set", "set", "set", "set", "ac_metric", "ac_metric.items", "open", "csv.DictReader", "enumerate", "open", "enumerate", "msg.append", "list.append", "json.loads", "list.append", "enumerate"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.is_json"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "assert", "gold_file", "is", "not", "None", ",", "f\"please provide the right gold file: `{gold_file}`.\"", "\n", "references", "=", "list", "(", ")", "\n", "nsample", "=", "len", "(", "self", ".", "x1s", ")", "\n", "\n", "# csv (Clotho) or json (AudioCaps)", "\n", "if", "not", "self", ".", "is_json", "(", "gold_file", ")", ":", "\n", "            ", "with", "open", "(", "gold_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "                ", "fr", "=", "csv", ".", "DictReader", "(", "fr", ")", "\n", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                    ", "references", ".", "append", "(", "line", ")", "\n", "if", "iline", "+", "1", ">=", "nsample", ":", "\n", "                        ", "break", "\n", "", "", "", "", "else", ":", "\n", "            ", "with", "open", "(", "gold_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "                ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                    ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "item", "=", "{", "\n", "f\"caption_{i + 1}\"", ":", "caption", "for", "i", ",", "caption", "in", "enumerate", "(", "record", "[", "\"captions\"", "]", ")", "\n", "}", "\n", "item", "[", "\"file_name\"", "]", "=", "record", "[", "\"id\"", "]", "\n", "references", ".", "append", "(", "item", ")", "\n", "if", "iline", "+", "1", ">=", "nsample", ":", "\n", "                        ", "break", "\n", "\n", "", "", "", "", "key", "=", "\"file_name\"", "\n", "ref_keys", "=", "[", "r", "[", "key", "]", "for", "r", "in", "references", "]", "\n", "ret_keys", "=", "[", "r", "[", "key", "]", "for", "r", "in", "self", ".", "x1s", "]", "\n", "f_t", "=", "set", "(", "ref_keys", ")", "-", "set", "(", "ret_keys", ")", "\n", "t_f", "=", "set", "(", "ret_keys", ")", "-", "set", "(", "ref_keys", ")", "\n", "#print(f\"{f_t}\\n{t_f}\")", "\n", "\n", "try", ":", "\n", "            ", "msg", "=", "[", "]", "\n", "results", "=", "ac_metric", "(", "self", ".", "x1s", ",", "references", ")", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "                ", "msg", ".", "append", "(", "f\"{k}: {v['score']:.3f}\"", ")", "\n", "", "msg", "=", "\" \"", ".", "join", "(", "msg", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "msg", "=", "f\"failed to evaluate the model: {e}\"", "\n", "\n", "", "del", "self", ".", "x1s", ",", "self", ".", "x2s", ",", "self", ".", "ids", "\n", "report", "=", "f\"{msg}\"", "\n", "return", "report", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.forward": [[373, 388], ["x1.reshape.reshape.reshape", "loss_more.LMLossHead.logit_scale.exp", "x2.reshape", "loss_more.LMLossHead.loss_fn", "loss_more.LMLossHead.infer", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.BarlowLossHead.loss_fn", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# x1: logits; x2: word seqs; predictions", "\n", "        ", "if", "not", "self", ".", "training", ":", "\n", "            ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "                ", "return", "self", ".", "infer", "(", "x1", ",", "x2", ",", "x3", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "None", "\n", "# cosine similarity as logits", "\n", "", "x1", "=", "x1", ".", "reshape", "(", "-", "1", ",", "x1", ".", "shape", "[", "-", "1", "]", ")", "\n", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_x1", "=", "logit_scale", "*", "x1", "\n", "# cross entropy loss", "\n", "labels", "=", "x2", ".", "reshape", "(", "-", "1", ")", "\n", "loss_mean_x1", "=", "self", ".", "loss_fn", "(", "logits_per_x1", ",", "labels", ")", "\n", "loss", "=", "loss_mean_x1", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.__init__": [[29, 33], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CVALP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.forward": [[34, 63], ["kwargs.get", "cvalp.CVALP.loss_head", "kwargs.get", "list", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "list", "images.norm", "text.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ",", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "image_features", "=", "audio_features", "=", "text_features", "=", "None", "\n", "dummy_image", "=", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "==", "[", "1", ",", "1", ",", "1", "]", "\n", "if", "images", "is", "not", "None", "and", "self", ".", "image_head", "is", "not", "None", "and", "not", "dummy_image", ":", "\n", "            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "elif", "images", "is", "not", "None", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", "and", "not", "dummy_image", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "# dummy images will be ignored", "\n", "", "if", "audios", "is", "not", "None", "and", "self", ".", "audio_head", "is", "not", "None", ":", "\n", "            ", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "dummy_text", "=", "list", "(", "text", ".", "shape", "[", "1", ":", "]", ")", "==", "[", "1", "]", "if", "text", "is", "not", "None", "else", "True", "\n", "if", "text", "is", "not", "None", "and", "self", ".", "text_head", "is", "not", "None", "and", "not", "dummy_text", ":", "\n", "            ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "elif", "text", "is", "not", "None", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", "and", "not", "dummy_text", ":", "\n", "                ", "text", "=", "text", "/", "text", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "text_features", "=", "text", "# dummy text will be ignored", "\n", "", "loss", "=", "self", ".", "loss_head", "(", "image_features", ",", "audio_features", ",", "text_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.encode_image": [[64, 69], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_image", "(", "self", ",", "image", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "image_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.encode_audio": [[70, 75], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_audio", "(", "self", ",", "audio", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "audio_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.encode_text": [[76, 81], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.collect_audio_state_dict": [[82, 84], ["cvalp.CVALP.collect_state_dict"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.collect_state_dict"], ["", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "collect_state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.collect_state_dict": [[85, 93], ["cvalp.CVALP.audio_head.state_dict", "cvalp.CVALP.loss_head.state_dict", "cvalp.CVALP.image_head.state_dict", "collections.OrderedDict", "cvalp.CVALP.text_head.state_dict", "collections.OrderedDict"], "methods", ["None"], ["", "def", "collect_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "(", "self", ".", "image_head", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "image_head", "is", "not", "None", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "else", "OrderedDict", "(", ")", ")", ",", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "text_head", "is", "not", "None", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "else", "OrderedDict", "(", ")", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.report": [[95, 102], ["cvalp.CVALP.loss_head.report", "hasattr", "cvalp.CVALP.loss_head.stats", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.ImagineAndClassifyLossHead.stats"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "stats", "(", "**", "kwargs", ")", "if", "hasattr", "(", "self", ".", "loss_head", ",", "\"stats\"", ")", "else", "\"\"", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP.build": [[103, 129], ["dict", "load_checkpoint", "load_clip", "module.build_image_head", "cvalp.CVALP.image_head.copy_state_dict", "module.build_audio_head", "cvalp.CVALP.audio_head.load_state_dict", "module.build_text_head", "cvalp.CVALP.text_head.copy_state_dict", "module.build_loss_head", "cvalp.CVALP.loss_head.load_state_dict", "cvalp.CVALP.cuda", "cvalp.CVALP.cuda", "cvalp.CVALP._build_siamese_backbone", "cvalp.CVALP._build_separate_backbone"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.siamese_va.CVASP._build_siamese_backbone", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP._build_separate_backbone"], ["", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "\n", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "\n", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "self", ".", "loss_head", ".", "load_state_dict", "(", "loss_head_sd", ")", "\n", "\n", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "running", ".", "siamese", ".", "alive", ":", "\n", "                ", "tunable_params", "=", "self", ".", "_build_siamese_backbone", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "                ", "tunable_params", "=", "self", ".", "_build_separate_backbone", "(", "**", "kwargs", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP._build_siamese_backbone": [[130, 216], ["load_checkpoint", "load_clip", "module.build_image_head", "set", "module.build_audio_head", "cvalp.CVALP.audio_head.replace_modules", "cvalp.CVALP.echo", "set", "kwargs.update", "module.build_text_head", "cvalp.CVALP.text_head.replace_modules", "cvalp.CVALP.echo", "module.build_loss_head", "cvalp.CVALP.image_head.copy_state_dict", "cvalp.CVALP.echo", "cvalp.CVALP.echo", "cvalp.CVALP.echo", "tunable_params.update", "tunable_params.update", "cvalp.CVALP.echo", "tunable_params.update", "cvalp.CVALP.audio_head.from_pretrained", "cvalp.CVALP.echo", "cvalp.CVALP.text_head.copy_state_dict", "cvalp.CVALP.echo", "cvalp.CVALP.text_head.copy_state_dict", "cvalp.CVALP.echo", "len", "cvalp.CVALP.loss_head.named_parameters", "tunable_params.update", "cvalp.CVALP.echo", "cvalp.CVALP.echo", "len", "cvalp.CVALP.audio_head.copy_state_dict", "cvalp.CVALP.echo", "cvalp.CVALP.echo", "cvalp.CVALP.text_head.state_dict", "len", "len", "len", "cvalp.CVALP.image_head.named_parameters", "cvalp.CVALP.audio_head.named_parameters", "cvalp.CVALP.text_head.named_parameters", "len", "cvalp.CVALP.image_head.named_parameters", "re.match", "re.match", "re.match"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.replace_modules", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.replace_modules", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "def", "_build_siamese_backbone", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# try pre-trained model!", "\n", "        ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "# image_head's parameters as the reference", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize image encoder from `image_head`{msg}.\"", ")", "\n", "", "if", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", "or", "not", "self", ".", "cfg", ".", "running", ".", "imagine", ":", "\n", "            ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "", "scfg", "=", "self", ".", "cfg", ".", "running", ".", "siamese", "\n", "\n", "# shared modules with audio_head", "\n", "amodules", "=", "set", "(", "scfg", ".", "amodules", ")", "\n", "kwargs", "=", "{", "\n", "\"shared_modules\"", ":", "amodules", ",", "\"reference\"", ":", "self", ".", "image_head", ",", "\"keep_hp\"", ":", "scfg", ".", "keep_hp", "\n", "}", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ",", "**", "kwargs", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "            ", "if", "local_cfg", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `image_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "audio_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"A: audio_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "\n", "# shared modules with text_head ", "\n", "lmodules", "=", "set", "(", "scfg", ".", "lmodules", ")", "\n", "kwargs", ".", "update", "(", "{", "\"shared_modules\"", ":", "lmodules", "}", ")", "\n", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ",", "**", "kwargs", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_scratch", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_text", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `image_head`{msg}.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "text_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"T:  text_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "if", "self", ".", "cfg", ".", "running", ".", "text_emb", "is", "not", "None", "or", "len", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "text_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory text encoder.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "shared_modules", "=", "amodules", "|", "lmodules", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "shared_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "!=", "\"\"", "and", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# shared parameters must be tunable", "\n", "self", ".", "echo", "(", "f\"Freeze image encoder (excl. shared modules: {shared_modules}).\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "amodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "else", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "lmodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "return", "tunable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvalp.CVALP._build_separate_backbone": [[217, 268], ["load_clip", "module.build_image_head", "module.build_audio_head", "module.build_text_head", "module.build_loss_head", "cvalp.CVALP.image_head.copy_state_dict", "cvalp.CVALP.echo", "cvalp.CVALP.echo", "cvalp.CVALP.audio_head.copy_state_dict", "cvalp.CVALP.echo", "cvalp.CVALP.text_head.copy_state_dict", "cvalp.CVALP.echo", "len", "cvalp.CVALP.echo", "tunable_params.update", "tunable_params.update", "cvalp.CVALP.echo", "tunable_params.update", "cvalp.CVALP.text_head.state_dict", "cvalp.CVALP.loss_head.named_parameters", "cvalp.CVALP.echo", "cvalp.CVALP.echo", "len", "len", "len", "cvalp.CVALP.image_head.named_parameters", "cvalp.CVALP.audio_head.named_parameters", "cvalp.CVALP.text_head.named_parameters"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "def", "_build_separate_backbone", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize image encoder from `image_head`{msg}.\"", ")", "\n", "", "if", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", ":", "\n", "            ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `image_head`{msg}.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "", "if", "len", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "text_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory text encoder.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze image encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "return", "tunable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.esc50_clf.ESClassifier.__init__": [[30, 34], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "ESClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.esc50_clf.ESClassifier.forward": [[35, 44], ["kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "esc50_clf.ESClassifier.loss_head", "kwargs.get"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "audios", ",", "labels", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "audio_features", ",", "labels", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.esc50_clf.ESClassifier.encode_text": [[45, 50], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.esc50_clf.ESClassifier.collect_audio_state_dict": [[51, 55], ["esc50_clf.ESClassifier.audio_head.state_dict", "esc50_clf.ESClassifier.loss_head.state_dict"], "methods", ["None"], ["", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.esc50_clf.ESClassifier.report": [[57, 62], ["esc50_clf.ESClassifier.loss_head.report", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.esc50_clf.ESClassifier.build": [[63, 129], ["dict", "load_checkpoint", "load_clip", "module.build_audio_head", "module.build_text_head", "esc50_clf.ESClassifier.text_head.copy_state_dict", "esc50_clf.ESClassifier.echo", "module.build_loss_head", "esc50_clf.ESClassifier.cuda", "load_checkpoint", "load_clip", "load_meme", "module.build_audio_head", "module.build_loss_head", "esc50_clf.ESClassifier.cuda", "esc50_clf.ESClassifier.audio_head.from_pretrained", "esc50_clf.ESClassifier.echo", "esc50_clf.ESClassifier.audio_head.copy_state_dict", "esc50_clf.ESClassifier.echo", "esc50_clf.ESClassifier.loss_head.copy_state_dict", "set", "dict.update", "esc50_clf.ESClassifier.echo", "esc50_clf.ESClassifier.echo", "len", "esc50_clf.ESClassifier.audio_head.from_pretrained", "esc50_clf.ESClassifier.echo", "esc50_clf.ESClassifier.loss_head.named_parameters", "len", "esc50_clf.ESClassifier.echo", "esc50_clf.ESClassifier.echo", "esc50_clf.ESClassifier.audio_head.copy_state_dict", "esc50_clf.ESClassifier.audio_head.copy_state_dict", "esc50_clf.ESClassifier.audio_head.named_parameters", "len", "re.match"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_meme", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "audio_head_sd", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `image_head`.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "if", "loss_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "loss_head", ".", "copy_state_dict", "(", "loss_head_sd", ")", "#", "\n", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "model", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "# TODO better to use `from_pretrained()`", "\n", "                    ", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "                ", "excl_modules", "=", "set", "(", "self", ".", "cfg", ".", "running", ".", "excl_modules", ".", "amodules", ")", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "excl_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out excluded parameters", "\n", "self", ".", "echo", "(", "f\"Tune audio encoder (excl. {excl_modules}).\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.siamese_va.CVASP.__init__": [[30, 32], ["cvalp.CVALP.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CVASP", ",", "self", ")", ".", "__init__", "(", "cfg", ",", "echo", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.siamese_va.CVASP.forward": [[33, 67], ["kwargs.get", "siamese_va.CVASP.loss_head", "kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "list", "images.norm"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "images", ",", "images_v1", ",", "audios_v1", ",", "\n", "text_v1", "=", "None", ",", "images_v2", "=", "None", ",", "audios_v2", "=", "None", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "image_features", "=", "image_features_v1", "=", "image_features_v2", "=", "audio_features_v1", "=", "text_features", "=", "None", "\n", "if", "images", "is", "not", "None", ":", "# pre-computed unnormalized features", "\n", "            ", "dummy_image", "=", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "==", "[", "1", ",", "1", ",", "1", "]", "\n", "if", "self", ".", "loss_head", ".", "normalized", "and", "not", "dummy_image", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "# dummy images will be ignored", "\n", "", "if", "images_v1", "is", "not", "None", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "image_features_v1", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images_v1", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "if", "images_v2", "is", "not", "None", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "image_features_v2", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images_v2", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "if", "audios_v1", "is", "not", "None", "and", "self", ".", "audio_head", "is", "not", "None", ":", "\n", "            ", "audio_features_v1", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios_v1", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "if", "text_v1", "is", "not", "None", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text_v1", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "loss", "=", "self", ".", "loss_head", "(", "\n", "image_features", ",", "image_features_v1", ",", "audio_features_v1", ",", "\n", "images_v2", "=", "image_features_v2", ",", "audios_v2", "=", "image_features_v2", ",", "**", "kwargs", "\n", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.siamese_va.CVASP._build_siamese_backbone": [[68, 154], ["load_checkpoint", "load_clip", "module.build_image_head", "set", "module.build_audio_head", "siamese_va.CVASP.audio_head.replace_modules", "siamese_va.CVASP.echo", "set", "kwargs.update", "module.build_text_head", "siamese_va.CVASP.text_head.replace_modules", "siamese_va.CVASP.echo", "module.build_loss_head", "siamese_va.CVASP.image_head.copy_state_dict", "siamese_va.CVASP.echo", "siamese_va.CVASP.echo", "len", "siamese_va.CVASP.echo", "tunable_params.update", "tunable_params.update", "siamese_va.CVASP.echo", "tunable_params.update", "siamese_va.CVASP.audio_head.from_pretrained", "siamese_va.CVASP.echo", "siamese_va.CVASP.text_head.copy_state_dict", "siamese_va.CVASP.echo", "siamese_va.CVASP.text_head.copy_state_dict", "siamese_va.CVASP.echo", "siamese_va.CVASP.text_head.state_dict", "siamese_va.CVASP.loss_head.named_parameters", "tunable_params.update", "siamese_va.CVASP.echo", "siamese_va.CVASP.echo", "len", "siamese_va.CVASP.audio_head.copy_state_dict", "siamese_va.CVASP.echo", "siamese_va.CVASP.echo", "len", "len", "len", "siamese_va.CVASP.image_head.named_parameters", "siamese_va.CVASP.audio_head.named_parameters", "siamese_va.CVASP.text_head.named_parameters", "len", "siamese_va.CVASP.image_head.named_parameters", "re.match", "re.match", "re.match"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.replace_modules", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.MetaHead.replace_modules", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "def", "_build_siamese_backbone", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# try pre-trained model!", "\n", "        ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "# image_head's parameters as the reference", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize image encoder from `image_head`{msg}.\"", ")", "\n", "", "if", "False", "and", "(", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", "or", "not", "self", ".", "cfg", ".", "running", ".", "imagine", ")", ":", "\n", "            ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "", "scfg", "=", "self", ".", "cfg", ".", "running", ".", "siamese", "\n", "\n", "# shared modules with audio_head", "\n", "amodules", "=", "set", "(", "scfg", ".", "amodules", ")", "\n", "kwargs", "=", "{", "\n", "\"shared_modules\"", ":", "amodules", ",", "\"reference\"", ":", "self", ".", "image_head", ",", "\"keep_hp\"", ":", "scfg", ".", "keep_hp", "\n", "}", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ",", "**", "kwargs", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "            ", "if", "local_cfg", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `image_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "audio_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"A: audio_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "\n", "# shared modules with text_head ", "\n", "lmodules", "=", "set", "(", "scfg", ".", "lmodules", ")", "\n", "kwargs", ".", "update", "(", "{", "\"shared_modules\"", ":", "lmodules", "}", ")", "\n", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ",", "**", "kwargs", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_scratch", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_text", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `image_head`{msg}.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "text_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"T:  text_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "if", "len", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "text_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory text encoder.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "shared_modules", "=", "amodules", "|", "lmodules", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "shared_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "!=", "\"\"", "and", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# shared parameters must be tunable", "\n", "self", ".", "echo", "(", "f\"Freeze image encoder (excl. shared modules: {shared_modules}).\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "amodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "else", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "lmodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "return", "tunable_params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvap.CVAP.__init__": [[19, 23], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CVAP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvap.CVAP.forward": [[24, 41], ["kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "cvap.CVAP.loss_head", "kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "images.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ",", "audios", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "if", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "else", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "\n", "", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "image_features", ",", "audio_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvap.CVAP.collect_audio_state_dict": [[42, 46], ["cvap.CVAP.audio_head.state_dict", "cvap.CVAP.loss_head.state_dict"], "methods", ["None"], ["", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvap.CVAP.collect_state_dict": [[48, 53], ["cvap.CVAP.image_head.state_dict", "cvap.CVAP.audio_head.state_dict", "cvap.CVAP.loss_head.state_dict"], "methods", ["None"], ["", "def", "collect_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "image_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvap.CVAP.report": [[55, 60], ["cvap.CVAP.loss_head.report", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.cvap.CVAP.build": [[61, 129], ["dict", "load_checkpoint", "load_clip", "module.build_image_head", "cvap.CVAP.image_head.copy_state_dict", "module.build_audio_head", "cvap.CVAP.audio_head.load_state_dict", "module.build_loss_head", "cvap.CVAP.loss_head.load_state_dict", "cvap.CVAP.cuda", "load_checkpoint", "load_clip", "load_meme", "module.build_image_head", "module.build_audio_head", "module.build_loss_head", "dict.update", "cvap.CVAP.cuda", "cvap.CVAP.image_head.copy_state_dict", "cvap.CVAP.echo", "cvap.CVAP.echo", "cvap.CVAP.loss_head.copy_state_dict", "dict.update", "cvap.CVAP.audio_head.load_state_dict", "cvap.CVAP.echo", "cvap.CVAP.audio_head.named_parameters", "cvap.CVAP.echo", "cvap.CVAP.echo", "cvap.CVAP.echo", "cvap.CVAP.loss_head.named_parameters", "cvap.CVAP.audio_head.copy_state_dict", "cvap.CVAP.audio_head.copy_state_dict", "cvap.CVAP.image_head.named_parameters", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_meme", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "", "def", "build", "(", "self", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "local_cfg", ".", "model", ".", "audio", ")", "\n", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "local_cfg", ".", "model", ".", "loss", ")", "\n", "self", ".", "loss_head", ".", "load_state_dict", "(", "loss_head_sd", ")", "\n", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "model", "=", "load_clip", "(", "local_cfg", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "if", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "# TODO better to use `from_pretrained()`", "\n", "                    ", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "extra_sd", "=", "{", "\"logit_scale\"", ":", "model", ".", "logit_scale", "}", "\n", "self", ".", "loss_head", ".", "copy_state_dict", "(", "extra_sd", ")", "\n", "\n", "", "tunable_params", "=", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze image encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint": [[10, 31], ["omegaconf.OmegaConf.to_yaml", "len", "torch.load", "echo", "echo", "echo", "ValueError"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["def", "load_checkpoint", "(", "cfg", ",", "echo", ")", ":", "\n", "    ", "model_file", "=", "f\"{cfg.model_root}/{cfg.model_name}/{cfg.model_file}\"", "\n", "try", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "model_file", ",", "map_location", "=", "\"cpu\"", ")", "\n", "echo", "(", "f\"Loading from {model_file}\"", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "echo", "(", "f\"Failed to load the checkpoint `{model_file}`\"", ")", "\n", "return", "(", "None", ",", ")", "*", "5", "\n", "", "local_cfg", "=", "checkpoint", "[", "\"cfg\"", "]", "\n", "local_str", "=", "OmegaConf", ".", "to_yaml", "(", "local_cfg", ")", "\n", "if", "cfg", ".", "verbose", ":", "\n", "        ", "echo", "(", "f\"Old configs:\\n\\n{local_str}\"", ")", "\n", "", "nmodule", "=", "len", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "if", "nmodule", "==", "2", ":", "\n", "        ", "audio_head_sd", ",", "loss_head_sd", "=", "checkpoint", "[", "\"model\"", "]", "\n", "return", "local_cfg", ",", "None", ",", "audio_head_sd", ",", "None", ",", "loss_head_sd", "\n", "", "elif", "nmodule", "==", "4", ":", "\n", "        ", "image_head_sd", ",", "audio_head_sd", ",", "text_head_sd", ",", "loss_head_sd", "=", "checkpoint", "[", "\"model\"", "]", "\n", "return", "local_cfg", ",", "image_head_sd", ",", "audio_head_sd", ",", "text_head_sd", ",", "loss_head_sd", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't know how to parse the checkpoint: # module is {nmodule}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip": [[32, 51], ["clip.load", "collections.OrderedDict", "model.state_dict().items", "model.visual.state_dict", "echo", "model.state_dict", "k.startswith"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "", "def", "load_clip", "(", "local_cfg", ",", "cfg", ",", "echo", ")", ":", "\n", "    ", "try", ":", "# try image / text backbone", "\n", "        ", "rcfg", "=", "cfg", ".", "running", "\n", "model", ",", "_", "=", "load", "(", "\n", "rcfg", ".", "clip_model_name", ",", "rcfg", ".", "clip_model_root", ",", "device", "=", "\"cpu\"", ",", "jit", "=", "False", "\n", ")", "\n", "image_head_sd", "=", "model", ".", "visual", ".", "state_dict", "(", ")", "if", "local_cfg", "is", "None", "else", "None", "\n", "text_head_sd", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "\"visual\"", ")", "or", "k", "==", "\"logit_scale\"", ":", "\n", "                ", "continue", "\n", "#k = re.sub(\"^transformer\\.\", \"encoder.\", k)", "\n", "", "text_head_sd", "[", "k", "]", "=", "v", "\n", "", "from_scratch", "=", "False", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "echo", "(", "f\"Will learn from scratch because: {e}\"", ")", "\n", "model", "=", "image_head_sd", "=", "text_head_sd", "=", "None", "\n", "from_scratch", "=", "True", "\n", "", "return", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_meme": [[52, 64], ["torch.hub.load", "torch.hub.load.state_dict", "getattr", "echo"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "load_meme", "(", "cfg", ",", "echo", ")", ":", "\n", "    ", "try", ":", "# try image / text backbone", "\n", "        ", "acfg", "=", "cfg", ".", "model", ".", "audio", "\n", "model", "=", "torch", ".", "hub", ".", "load", "(", "acfg", ".", "meme_path", ",", "acfg", ".", "meme_name", ",", "pretrained", "=", "True", ")", "\n", "image_head_sd", "=", "model", ".", "state_dict", "(", ")", "\n", "with_meme", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "meme_name", "=", "getattr", "(", "acfg", ",", "\"meme_name\"", ",", "None", ")", "\n", "echo", "(", "f\"Failed to load the meme `{meme_name}` because: {e}\"", ")", "\n", "image_head_sd", "=", "None", "\n", "with_meme", "=", "False", "\n", "", "return", "with_meme", ",", "image_head_sd", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.extract_model_file": [[65, 78], ["list", "open", "echo", "re.search", "list.append", "re.search.groups"], "function", ["None"], ["", "def", "extract_model_file", "(", "cfg", ",", "echo", ")", ":", "\n", "    ", "model_files", "=", "list", "(", ")", "\n", "log_file", "=", "f\"{cfg.model_root}/{cfg.model_name}/{cfg.model_file}\"", "\n", "try", ":", "\n", "        ", "pattern", "=", "'.?Saving the checkpoint to.*\\/([0-9]+\\.pth)'", "\n", "with", "open", "(", "log_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "line", "in", "fr", ":", "\n", "                ", "ret", "=", "re", ".", "search", "(", "pattern", ",", "line", ")", "\n", "if", "ret", "is", "not", "None", ":", "\n", "                    ", "model_files", ".", "append", "(", "ret", ".", "groups", "(", "0", ")", "[", "0", "]", ")", "\n", "", "", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "echo", "(", "f\"Failed to extract model files from `{log_file}`\"", ")", "\n", "", "return", "model_files", "\n", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clvp.CLVP.__init__": [[20, 24], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CLVP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clvp.CLVP.forward": [[25, 30], ["kwargs.get", "clvp.CLVP.forward_retrieval", "ValueError"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.forward_retrieval"], ["", "def", "forward", "(", "self", ",", "images", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "\"retrieval\"", ",", "False", ")", ":", "# if it is a retrieval task", "\n", "            ", "return", "self", ".", "forward_retrieval", "(", "images", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only support retrieval.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clvp.CLVP.forward_retrieval": [[31, 50], ["kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "clvp.CLVP.loss_head", "kwargs.get", "list", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "images.norm"], "methods", ["None"], ["", "", "def", "forward_retrieval", "(", "self", ",", "images", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel`", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "image_features", "=", "audio_features", "=", "text_features", "=", "None", "\n", "dummy_image", "=", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "==", "[", "1", ",", "1", ",", "1", "]", "\n", "if", "images", "is", "not", "None", "and", "self", ".", "image_head", "is", "not", "None", "and", "not", "dummy_image", ":", "\n", "            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "elif", "images", "is", "not", "None", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", "and", "not", "dummy_image", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "# dummy images will be ignored", "\n", "", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "image_features", ",", "text_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clvp.CLVP.collect_audio_state_dict": [[51, 53], ["dict"], "methods", ["None"], ["", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "dict", "(", ")", ",", ")", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clvp.CLVP.collect_state_dict": [[54, 56], ["dict"], "methods", ["None"], ["", "def", "collect_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "dict", "(", ")", ",", ")", "*", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clvp.CLVP.report": [[57, 62], ["clvp.CLVP.loss_head.report", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clvp.CLVP.build": [[63, 91], ["dict", "load_checkpoint", "load_clip", "module.build_image_head", "module.build_text_head", "clvp.CLVP.text_head.copy_state_dict", "clvp.CLVP.echo", "module.build_loss_head", "clvp.CLVP.cuda", "ValueError", "clvp.CLVP.image_head.copy_state_dict", "clvp.CLVP.echo", "clvp.CLVP.echo", "clvp.CLVP.loss_head.copy_state_dict", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "# image_head's parameters as the reference", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize image encoder from `image_head`{msg}.\"", ")", "\n", "", "if", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", "or", "not", "self", ".", "cfg", ".", "running", ".", "imagine", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "if", "loss_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "loss_head", ".", "copy_state_dict", "(", "loss_head_sd", ")", "#", "\n", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Not implemented yet.\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.__init__.build_main_model": [[25, 27], ["VAL_MODELS_REGISTRY.get"], "function", ["None"], ["", "def", "from_pretrained", "(", "self", ",", "state_dict", ",", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.__init__": [[29, 33], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "ASClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.forward": [[34, 52], ["kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "audioset_clf.ASClassifier.loss_head", "kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "list", "images.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ",", "audios", ",", "labels", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "if", "self", ".", "image_head", "is", "not", "None", "and", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "!=", "[", "1", ",", "1", ",", "1", "]", ":", "\n", "            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "else", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "\n", "\n", "", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "audio_features", ",", "labels", ",", "x3", "=", "image_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.encode_image": [[53, 58], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_image", "(", "self", ",", "images", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "image_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.encode_audio": [[59, 64], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_audio", "(", "self", ",", "audios", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "audio_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.encode_text": [[65, 70], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.collect_audio_state_dict": [[71, 75], ["audioset_clf.ASClassifier.audio_head.state_dict", "audioset_clf.ASClassifier.loss_head.state_dict"], "methods", ["None"], ["", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.report": [[77, 84], ["audioset_clf.ASClassifier.loss_head.report", "hasattr", "audioset_clf.ASClassifier.loss_head.stats", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.ImagineAndClassifyLossHead.stats"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "stats", "(", "**", "kwargs", ")", "if", "hasattr", "(", "self", ".", "loss_head", ",", "\"stats\"", ")", "else", "\"\"", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.build": [[85, 175], ["dict", "load_checkpoint", "load_clip", "module.build_image_head", "module.build_audio_head", "module.build_text_head", "audioset_clf.ASClassifier.text_head.copy_state_dict", "audioset_clf.ASClassifier.echo", "module.build_loss_head", "audioset_clf.ASClassifier.cuda", "load_checkpoint", "load_clip", "load_meme", "module.build_image_head", "module.build_audio_head", "module.build_loss_head", "audioset_clf.ASClassifier.cuda", "audioset_clf.ASClassifier.image_head.copy_state_dict", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.audio_head.from_pretrained", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.audio_head.copy_state_dict", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.loss_head.load_state_dict", "audioset_clf.ASClassifier.image_head.copy_state_dict", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.echo", "dict.update", "set", "dict.update", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.echo", "len", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.audio_head.load_state_dict", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.loss_head.named_parameters", "audioset_clf.ASClassifier.echo", "len", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.echo", "audioset_clf.ASClassifier.audio_head.copy_state_dict", "audioset_clf.ASClassifier.audio_head.copy_state_dict", "audioset_clf.ASClassifier.image_head.named_parameters", "audioset_clf.ASClassifier.audio_head.named_parameters", "len", "re.match"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_meme", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.image_head.build_image_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "self", ".", "cfg", ".", "running", ".", "imagine", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "audio_head_sd", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `image_head`.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "try", ":", "\n", "                ", "self", ".", "loss_head", ".", "load_state_dict", "(", "loss_head_sd", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "self", ".", "echo", "(", "f\"Failed to load `loss_head` (expected in zero-shot mode) because: {e}\"", ")", "\n", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "model", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", "and", "image_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "running", ".", "imagine", "or", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "# TODO better to use `from_pretrained()`", "\n", "                    ", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze image encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "                ", "excl_modules", "=", "set", "(", "self", ".", "cfg", ".", "running", ".", "excl_modules", ".", "amodules", ")", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "excl_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out excluded parameters", "\n", "self", ".", "echo", "(", "f\"Tune audio encoder (excl. {excl_modules}).\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.__init__": [[20, 24], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CLAP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.forward": [[25, 41], ["kwargs.get", "kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "clap.CLAP.loss_head", "clap.CLAP.forward_retrieval", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.forward_retrieval"], ["", "def", "forward", "(", "self", ",", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "\"retrieval\"", ",", "False", ")", ":", "# if it is a retrieval task", "\n", "            ", "return", "self", ".", "forward_retrieval", "(", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel`", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "False", ",", "\"require_feature\"", ":", "True", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "_", ",", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "time_first", "=", "True", "#self.audio_head.time_first", "\n", "text_input", "=", "(", "text", ",", "audio_features", ",", "time_first", ")", "\n", "_", ",", "logits", ",", "predictions", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text_input", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "logits", ",", "text", "[", ":", ",", "1", ":", "]", ",", "predictions", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.forward_retrieval": [[42, 54], ["kwargs.get", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "clap.CLAP.loss_head", "kwargs.get"], "methods", ["None"], ["", "def", "forward_retrieval", "(", "self", ",", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel`", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "audio_features", ",", "text_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.encode_text": [[55, 60], ["torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel"], "methods", ["None"], ["", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.collect_audio_state_dict": [[61, 65], ["clap.CLAP.audio_head.state_dict", "clap.CLAP.loss_head.state_dict"], "methods", ["None"], ["", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.collect_state_dict": [[67, 72], ["clap.CLAP.audio_head.state_dict", "clap.CLAP.text_head.state_dict", "clap.CLAP.loss_head.state_dict"], "methods", ["None"], ["", "def", "collect_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "text_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report": [[74, 79], ["clap.CLAP.loss_head.report", "torch.is_initialized", "torch.is_initialized", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report"], ["", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build": [[80, 158], ["dict", "load_checkpoint", "load_clip", "module.build_audio_head", "module.build_text_head", "clap.CLAP.text_head.copy_state_dict", "clap.CLAP.echo", "module.build_loss_head", "clap.CLAP.cuda", "load_checkpoint", "load_clip", "load_meme", "module.build_audio_head", "module.build_text_head", "module.build_loss_head", "dict.update", "clap.CLAP.cuda", "clap.CLAP.audio_head.from_pretrained", "clap.CLAP.echo", "clap.CLAP.audio_head.copy_state_dict", "clap.CLAP.echo", "clap.CLAP.loss_head.copy_state_dict", "clap.CLAP.text_head.copy_state_dict", "clap.CLAP.echo", "clap.CLAP.loss_head.copy_state_dict", "dict.update", "dict.update", "len", "clap.CLAP.audio_head.from_pretrained", "clap.CLAP.echo", "clap.CLAP.echo", "clap.CLAP.echo", "len", "clap.CLAP.echo", "clap.CLAP.echo", "clap.CLAP.loss_head.named_parameters", "clap.CLAP.audio_head.copy_state_dict", "clap.CLAP.audio_head.copy_state_dict", "clap.CLAP.audio_head.named_parameters", "clap.CLAP.text_head.named_parameters", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_checkpoint", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_clip", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.load_meme", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.audio_head.build_audio_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.text_head.build_text_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_head.build_loss_head", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.encoder.clip_head.CLIPAudioHead.from_pretrained", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.decoder.loss_more.LMLossHead.copy_state_dict"], ["", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "audio_head_sd", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `image_head`.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "if", "loss_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "loss_head", ".", "copy_state_dict", "(", "loss_head_sd", ")", "#", "\n", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "model", "=", "load_clip", "(", "local_cfg", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "#cfg = local_cfg if local_cfg is not None else self.cfg", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ",", "**", "kwargs", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "                    ", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "\n", "if", "not", "from_scratch", ":", "\n", "                ", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize text encoder from `text_head`.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "extra_sd", "=", "{", "\"logit_scale\"", ":", "model", ".", "logit_scale", "}", "\n", "self", ".", "loss_head", ".", "copy_state_dict", "(", "extra_sd", ")", "\n", "\n", "", "tunable_params", ".", "update", "(", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "audio_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.AverageMeter.__init__": [[50, 52], ["__init__.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.AverageMeter.reset"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.AverageMeter.reset": [[53, 55], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.AverageMeter.__call__": [[56, 59], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.AverageMeter.average": [[60, 63], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.seed_all_rng": [[8, 12], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], [")", "\n", "# deprecated API", "\n", "from", ".", "deit", "import", "PatchEmbed", ",", "DistilledVisionTransformer", "\n", "from", ".", "vit", "import", "VisualTransformer", "\n", "from", ".", "txt", "import", "TextualTransformer", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.setup_logger": [[13, 38], ["logging.getLogger", "logging.getLogger.setLevel", "logging.Formatter", "os.path.exists", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.info", "logging.getLogger.info", "torch.barrier", "os.path.join", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "os.makedirs"], "function", ["None"], ["from", ".", "resnet", "import", "ModifiedResNet", "\n", "# optimizer", "\n", "from", ".", "lars", "import", "*", "\n", "# encoder heads", "\n", "from", ".", "encoder", "import", "*", "\n", "from", ".", "decoder", "import", "*", "\n", "# dummy heads", "\n", "import", "torch", "\n", "class", "DummyHead", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "pass", "\n", "", "def", "from_pretrained", "(", "self", ",", "state_dict", ",", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "", "def", "copy_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "return", "{", "}", ",", "{", "}", "\n", "", "def", "replace_modules", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "[", "]", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "None", "\n", "", "", "IMAGE_HEADS_REGISTRY", ".", "register", "(", "DummyHead", ")", "\n", "AUDIO_HEADS_REGISTRY", ".", "register", "(", "DummyHead", ")", "\n", "TEXT_HEADS_REGISTRY", ".", "register", "(", "DummyHead", ")", "\n", "LOSS_HEADS_REGISTRY", ".", "register", "(", "DummyHead", ")", "\n", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel": [[39, 45], ["list", "sum", "model.parameters", "p.numel", "p.data_ptr"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.detect_nan": [[46, 48], ["torch.isnan().any", "torch.isnan().any", "torch.isinf().any", "torch.isinf().any", "torch.isnan", "torch.isnan", "torch.isinf", "torch.isinf"], "function", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.AudioTextDatasetSrc.__init__": [[26, 47], ["list", "enumerate", "len", "audio.make_transform", "audio_text.AudioTextDatasetSrc.dataset.append"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_list", ",", "train", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "list", "(", ")", "\n", "for", "iline", ",", "record", "in", "enumerate", "(", "data_list", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                ", "break", "\n", "", "", "self", ".", "audio_norms", "=", "cfg", ".", "audio", ".", "norms", "\n", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "aclip_key", "=", "\"clip\"", "if", "\"clip\"", "in", "self", ".", "dataset", "[", "0", "]", "else", "\"aclip\"", "\n", "acfg", "=", "cfg", ".", "audio", "\n", "self", ".", "transform_audio", ",", "self", ".", "transform_fbank", "=", "make_transform", "(", "acfg", ")", "\n", "self", ".", "kaldi_params", "=", "{", "\n", "\"htk_compat\"", ":", "True", ",", "\n", "\"use_energy\"", ":", "False", ",", "\n", "\"window_type\"", ":", "'hanning'", ",", "\n", "\"num_mel_bins\"", ":", "acfg", ".", "num_mel_bins", ",", "\n", "\"dither\"", ":", "0.0", ",", "\n", "\"frame_shift\"", ":", "10", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.AudioTextDatasetSrc._shuffle": [[49, 51], ["None"], "methods", ["None"], ["", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.AudioTextDatasetSrc._audio2numpy_cst": [[52, 69], ["np.pad._extract_kaldi_spectrogram", "numpy.pad"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform._extract_kaldi_spectrogram"], ["", "def", "_audio2numpy_cst", "(", "self", ",", "aclip_file", ")", ":", "\n", "        ", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "_extract_kaldi_spectrogram", "(", "\n", "aclip_file", ",", "\n", "self", ".", "kaldi_params", ",", "\n", "train", "=", "self", ".", "train", ",", "\n", "max_audio_len", "=", "max_audio_len", ",", "\n", "zero_mean_wf", "=", "self", ".", "cfg", ".", "audio", ".", "zero_mean_wf", ",", "\n", "transform_audio", "=", "(", "\n", "self", ".", "transform_audio", "if", "self", ".", "train", "and", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "else", "None", "\n", ")", "\n", ")", "# (..., time, freq)", "\n", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.AudioTextDatasetSrc.__getitem__": [[70, 101], ["audio_text.AudioTextDatasetSrc._audio2numpy_cst", "audio_text.AudioTextDatasetSrc.transform_fbank", "len", "len", "numpy.random.choice", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_cst"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "akey", "=", "self", ".", "aclip_key", "\n", "name", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"id\"", "]", "\n", "sub_dir", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"dir\"", "]", "\n", "label_str", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_str\"", "]", "\n", "label_int", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_int_bpe\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "akey", "]", "[", "0", "]", "\n", "\n", "sub_dir", "=", "\"\"", "if", "len", "(", "sub_dir", ")", "==", "0", "else", "f\"{sub_dir}/\"", "\n", "aclip", "=", "aclip", "if", "aclip", "==", "name", "else", "f\"{akey}/{name}.{aclip}\"", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{aclip}\"", "\n", "\n", "audio", "=", "self", ".", "_audio2numpy_cst", "(", "aclip_file", ")", "\n", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "len", "(", "self", ".", "audio_norms", ")", "==", "2", ":", "\n", "            ", "mean", ",", "std", "=", "self", ".", "audio_norms", "\n", "audio", "=", "(", "audio", "-", "mean", ")", "/", "std", "\n", "\n", "#if self.train and self.transform_fbank is not None:", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "label_int", ")", ",", "1", ")", "[", "0", "]", "\n", "text", "=", "label_int", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "text", "=", "label_int", "\n", "\n", "", "audio", "=", "audio", "[", "None", "]", "\n", "item", "=", "{", "\"audio\"", ":", "audio", ",", "\"text\"", ":", "text", ",", "\"name\"", ":", "name", "}", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.AudioTextDatasetSrc.__len__": [[102, 104], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.AudioTextCollator.__init__": [[106, 110], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", ":", "\n", "# RuntimeError: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned", "\n", "# when pin_memory is true, the collator has to return CPU tensors", "\n", "        ", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.AudioTextCollator.__call__": [[111, 137], ["isinstance", "isinstance", "numpy.array", "numpy.concatenate", "record.get", "set().union", "list", "ValueError", "list", "itertools.chain.from_iterable", "itertools.zip_longest", "set", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "records", ")", ":", "\n", "        ", "union", "=", "{", "\n", "k", ":", "[", "record", ".", "get", "(", "k", ")", "for", "record", "in", "records", "]", "for", "k", "in", "set", "(", ")", ".", "union", "(", "*", "records", ")", "\n", "}", "\n", "name", "=", "union", "[", "\"name\"", "]", "\n", "text_list", "=", "union", "[", "\"text\"", "]", "\n", "if", "isinstance", "(", "text_list", "[", "0", "]", "[", "0", "]", ",", "int", ")", ":", "# train", "\n", "            ", "pass", "\n", "\"\"\" https://stackoverflow.com/a/43149308\n            lengths = [len(x) for x in text_list]\n            max_len = max(lengths)\n            text = np.zeros((len(text_list), max_len), int)\n            mask = np.arange(max_len) < np.array(lengths)[:, None]\n            text[mask] = np.concatenate(text_list)\n            \"\"\"", "\n", "", "elif", "isinstance", "(", "text_list", "[", "0", "]", "[", "0", "]", ",", "list", ")", ":", "# test", "\n", "            ", "text_list", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "text_list", ")", ")", "\n", "#name = list(itertools.chain.from_iterable(name))", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"unrecognized `{type(text_list[0][0])}`\"", ")", "\n", "# https://stackoverflow.com/a/38619333", "\n", "", "text", "=", "np", ".", "array", "(", "list", "(", "itertools", ".", "zip_longest", "(", "*", "text_list", ",", "fillvalue", "=", "0", ")", ")", ")", ".", "T", "\n", "return", "(", "\n", "np", ".", "concatenate", "(", "union", "[", "\"audio\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "text", ",", "\n", "name", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_dataloader": [[139, 168], ["torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "isinstance", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataset_cls", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "eval", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "collator_cls"], "function", ["None"], ["", "", "def", "build_dataloader", "(", "cfg", ",", "data_list", ",", "dataset_cls", ",", "shuffle", "=", "True", ",", "train", "=", "True", ",", "collator_cls", "=", "AudioTextCollator", ")", ":", "\n", "    ", "ddp_mode", "=", "torch", ".", "distributed", ".", "is_initialized", "(", ")", "\n", "rcfg", "=", "cfg", ".", "running", "\n", "if", "isinstance", "(", "dataset_cls", ",", "str", ")", ":", "\n", "        ", "dataset", "=", "eval", "(", "dataset_cls", ")", "(", "rcfg", ",", "data_list", ",", "train", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "dataset_cls", "(", "rcfg", ",", "data_list", ",", "train", ")", "\n", "", "if", "ddp_mode", ":", "\n", "        ", "assert", "self", ".", "cfg", ".", "optimizer", ".", "batch_size", "%", "self", ".", "cfg", ".", "num_gpus", "==", "0", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "dataset", ",", "shuffle", "=", "shuffle", "\n", ")", "\n", "per_device_batch_size", "=", "cfg", ".", "optimizer", ".", "batch_size", "//", "cfg", ".", "num_gpus", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "(", "\n", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "dataset", ")", "if", "shuffle", "else", "\n", "torch", ".", "utils", ".", "data", ".", "SequentialSampler", "(", "dataset", ")", "\n", ")", "\n", "per_device_batch_size", "=", "cfg", ".", "optimizer", ".", "batch_size", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "per_device_batch_size", ",", "\n", "collate_fn", "=", "collator_cls", "(", ")", ",", "\n", "num_workers", "=", "(", "0", "if", "ddp_mode", "else", "cfg", ".", "num_proc", ")", ",", "\n", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "drop_last", "=", "(", "True", "if", "ddp_mode", "else", "False", ")", ",", "\n", ")", "\n", "return", "sampler", ",", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_clotho_data_list": [[169, 195], ["os.path.isfile", "cfg.prompt.strip", "list", "data_name.rsplit", "open", "csv.DictReader", "enumerate", "len", "clip.tokenize", "list.append", "range"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize"], ["", "def", "build_clotho_data_list", "(", "cfg", ",", "data_name", ")", ":", "\n", "    ", "fold", "=", "data_name", ".", "rsplit", "(", "\"_\"", ",", "1", ")", "[", "-", "1", "]", "# {development, validation, evaluation} ", "\n", "data_path", "=", "f\"{cfg.data_root}/{data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "prompt", "=", "cfg", ".", "prompt", ".", "strip", "(", ")", "\n", "prompt", "=", "\"\"", "if", "len", "(", "prompt", ")", "==", "0", "else", "f\"{prompt} \"", "\n", "dataset", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "        ", "meta", "=", "csv", ".", "DictReader", "(", "fr", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "meta", ")", ":", "\n", "            ", "filename", "=", "row", "[", "\"file_name\"", "]", "\n", "captions", "=", "[", "prompt", "+", "row", "[", "f\"caption_{icap}\"", "]", "for", "icap", "in", "range", "(", "1", ",", "6", ")", "]", "\n", "label_int_bpe", "=", "tokenize", "(", "captions", ",", "as_list", "=", "True", ")", "\n", "item", "=", "{", "\n", "\"id\"", ":", "filename", ",", "\n", "\"dir\"", ":", "fold", ",", "\n", "\"aclip\"", ":", "[", "filename", "]", ",", "\n", "\"label_int_bpe\"", ":", "label_int_bpe", ",", "\n", "\"label_int_w2v\"", ":", "[", "]", ",", "\n", "\"label_str\"", ":", "captions", "\n", "}", "\n", "dataset", ".", "append", "(", "item", ")", "\n", "if", "i", ">", "10", ":", "\n", "                ", "pass", "#break", "\n", "#print(dataset)", "\n", "", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_audiocaps_data_list": [[196, 216], ["os.path.isfile", "cfg.prompt.strip", "list", "open", "enumerate", "print", "len", "json.loads", "clip.tokenize", "list.append"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize"], ["", "def", "build_audiocaps_data_list", "(", "cfg", ",", "data_name", ")", ":", "\n", "    ", "data_path", "=", "f\"{cfg.data_root}/{data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "prompt", "=", "cfg", ".", "prompt", ".", "strip", "(", ")", "\n", "prompt", "=", "\"\"", "if", "len", "(", "prompt", ")", "==", "0", "else", "f\"{prompt} \"", "\n", "dataset", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "        ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "            ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "captions", "=", "[", "prompt", "+", "caption", "for", "caption", "in", "record", "[", "\"captions\"", "]", "]", "\n", "record", "[", "\"label_int_w2v\"", "]", "=", "[", "]", "\n", "record", "[", "\"label_int_bpe\"", "]", "=", "tokenize", "(", "\n", "captions", ",", "as_list", "=", "True", "\n", ")", "# add bpe captions", "\n", "record", "[", "\"label_str\"", "]", "=", "captions", "\n", "dataset", ".", "append", "(", "record", ")", "\n", "if", "iline", ">", "10", ":", "\n", "                ", "pass", "#break", "\n", "", "", "print", "(", "dataset", "[", ":", "2", "]", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_dataloader_clotho": [[217, 224], ["data_name.split", "list", "audio_text.build_dataloader", "audio_text.build_clotho_data_list", "list.extend"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_clotho_data_list"], ["", "def", "build_dataloader_clotho", "(", "cfg", ",", "data_name", ",", "shuffle", "=", "True", ",", "train", "=", "True", ")", ":", "\n", "    ", "name_list", "=", "data_name", ".", "split", "(", "\",\"", ")", "\n", "dataset", "=", "list", "(", ")", "\n", "for", "name", "in", "name_list", ":", "\n", "        ", "subset", "=", "build_clotho_data_list", "(", "cfg", ".", "running", ",", "name", ")", "\n", "dataset", ".", "extend", "(", "subset", ")", "\n", "", "return", "build_dataloader", "(", "cfg", ",", "dataset", ",", "AudioTextDatasetSrc", ",", "shuffle", "=", "shuffle", ",", "train", "=", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_dataloader_audiocaps": [[225, 232], ["data_name.split", "list", "audio_text.build_dataloader", "audio_text.build_audiocaps_data_list", "list.extend"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_audiocaps_data_list"], ["", "def", "build_dataloader_audiocaps", "(", "cfg", ",", "data_name", ",", "shuffle", "=", "True", ",", "train", "=", "True", ")", ":", "\n", "    ", "name_list", "=", "data_name", ".", "split", "(", "\",\"", ")", "\n", "dataset", "=", "list", "(", ")", "\n", "for", "name", "in", "name_list", ":", "\n", "        ", "subset", "=", "build_audiocaps_data_list", "(", "cfg", ".", "running", ",", "name", ")", "\n", "dataset", ".", "extend", "(", "subset", ")", "\n", "", "return", "build_dataloader", "(", "cfg", ",", "dataset", ",", "AudioTextDatasetSrc", ",", "shuffle", "=", "shuffle", ",", "train", "=", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_audio_text_dataloader": [[233, 246], ["data_name.startswith", "audio_text.build_dataloader_clotho", "data_name.startswith", "audio_text.build_dataloader_audiocaps", "ValueError"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_dataloader_clotho", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.build_dataloader_audiocaps"], ["", "def", "build_audio_text_dataloader", "(", "cfg", ",", "data_name", ",", "*", "args", ",", "shuffle", "=", "True", ",", "train", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "data_name", ".", "startswith", "(", "\"clotho\"", ")", ":", "\n", "        ", "return", "build_dataloader_clotho", "(", "\n", "cfg", ",", "data_name", ",", "shuffle", "=", "shuffle", ",", "train", "=", "train", "\n", ")", "\n", "", "elif", "data_name", ".", "startswith", "(", "\"audiocaps\"", ")", ":", "\n", "#from .audioset import build_audioset_dataloader", "\n", "#return build_audioset_dataloader(cfg, data_name, dict(), shuffle=shuffle, train=train)", "\n", "        ", "return", "build_dataloader_audiocaps", "(", "\n", "cfg", ",", "data_name", ",", "shuffle", "=", "shuffle", ",", "train", "=", "train", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognized dataset `{data_name}`.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDatasetSrc.__init__": [[31, 62], ["list", "enumerate", "len", "audio.make_transform", "esc50.ImageAudioDatasetSrc.dataset.append"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_list", ",", "train", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "list", "(", ")", "\n", "for", "iline", ",", "record", "in", "enumerate", "(", "data_list", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                ", "break", "\n", "", "", "self", ".", "audio_norms", "=", "cfg", ".", "audio", ".", "norms", "\n", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "acfg", "=", "cfg", ".", "audio", "\n", "self", ".", "transform_audio", ",", "self", ".", "transform_fbank", "=", "make_transform", "(", "acfg", ")", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "zero_mean_wf", ":", "\n", "            ", "self", ".", "kaldi_params", "=", "{", "\n", "\"use_log_fbank\"", ":", "acfg", ".", "use_log_fbank", ",", "\n", "\"frame_length\"", ":", "acfg", ".", "frame_length", ",", "\n", "\"frame_shift\"", ":", "acfg", ".", "frame_shift", ",", "\n", "\"window_type\"", ":", "acfg", ".", "window_type", ",", "\n", "\"num_mel_bins\"", ":", "acfg", ".", "num_mel_bins", ",", "\n", "\"high_freq\"", ":", "acfg", ".", "high_freq", ",", "\n", "\"low_freq\"", ":", "acfg", ".", "low_freq", ",", "\n", "}", "# old configs", "\n", "", "else", ":", "\n", "            ", "self", ".", "kaldi_params", "=", "{", "\n", "\"htk_compat\"", ":", "True", ",", "\n", "\"use_energy\"", ":", "False", ",", "\n", "\"window_type\"", ":", "'hanning'", ",", "\n", "\"num_mel_bins\"", ":", "acfg", ".", "num_mel_bins", ",", "\n", "\"dither\"", ":", "0.0", ",", "\n", "\"frame_shift\"", ":", "10", "\n", "}", "# new configs", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDatasetSrc._shuffle": [[64, 66], ["None"], "methods", ["None"], ["", "", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDatasetSrc.__getitem__": [[67, 109], ["esc50.ImageAudioDatasetSrc._extract_kaldi_spectrogram", "numpy.pad", "esc50.ImageAudioDatasetSrc.transform_fbank", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform._extract_kaldi_spectrogram"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "label_str", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_str\"", "]", "\n", "label_int", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_int\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"aclip\"", "]", "\n", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{aclip}\"", "\n", "\n", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "_extract_kaldi_spectrogram", "(", "\n", "aclip_file", ",", "\n", "self", ".", "kaldi_params", ",", "\n", "train", "=", "self", ".", "train", ",", "\n", "max_audio_len", "=", "max_audio_len", ",", "\n", "zero_mean_wf", "=", "self", ".", "cfg", ".", "audio", ".", "zero_mean_wf", ",", "\n", "tile_audio", "=", "False", ",", "#self.cfg.audio.tile_audio,", "\n", "transform_audio", "=", "(", "\n", "self", ".", "transform_audio", "if", "self", ".", "train", "and", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "else", "None", "\n", ")", "\n", ")", "# (..., time, freq)", "\n", "\n", "npad", "=", "self", ".", "cfg", ".", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "# always pad to the right", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "\n", "", "\"\"\"\n        if self.cfg.audio.tile_audio and max_audio_len > audio.shape[0]:\n            ntile = int(np.ceil(max_audio_len / audio.shape[0]))\n            audio = np.tile(audio, (ntile, 1))[:max_audio_len]\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "len", "(", "self", ".", "audio_norms", ")", "==", "2", ":", "\n", "            ", "mean", ",", "std", "=", "self", ".", "audio_norms", "\n", "audio", "=", "(", "audio", "-", "mean", ")", "/", "std", "\n", "\n", "#if self.train and self.transform_fbank is not None:", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "\n", "", "audio", "=", "audio", "[", "None", "]", "\n", "\n", "item", "=", "{", "\"audio\"", ":", "audio", ",", "\"label_int\"", ":", "label_int", ",", "\"label_str\"", ":", "label_str", "}", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDatasetSrc.__len__": [[110, 112], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioCollator.__init__": [[114, 118], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", ":", "\n", "# RuntimeError: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned", "\n", "# when pin_memory is true, the collator has to return CPU tensors", "\n", "        ", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioCollator.__call__": [[119, 127], ["numpy.concatenate", "numpy.array", "record.get", "set().union", "set"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "records", ")", ":", "\n", "        ", "union", "=", "{", "\n", "k", ":", "[", "record", ".", "get", "(", "k", ")", "for", "record", "in", "records", "]", "for", "k", "in", "set", "(", ")", ".", "union", "(", "*", "records", ")", "\n", "}", "\n", "return", "(", "\n", "np", ".", "concatenate", "(", "union", "[", "\"audio\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "array", "(", "union", "[", "\"label_int\"", "]", ")", ",", "\n", "union", "[", "\"label_str\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDataset4Mreserve.__init__": [[132, 141], ["list", "enumerate", "len", "esc50.ImageAudioDataset4Mreserve.dataset.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_list", ",", "train", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "list", "(", ")", "\n", "for", "iline", ",", "record", "in", "enumerate", "(", "data_list", ")", ":", "\n", "            ", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                ", "break", "\n", "", "", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDataset4Mreserve._shuffle": [[142, 144], ["None"], "methods", ["None"], ["", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDataset4Mreserve.__getitem__": [[145, 178], ["numpy.array", "video_to_segments", "copy.deepcopy", "video_to_segments.insert", "preprocess_video", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "label_str", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_str\"", "]", "\n", "label_int", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_int\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"aclip\"", "]", "\n", "audio", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{aclip}\"", "\n", "acfg", "=", "self", ".", "cfg", ".", "audio", "\n", "\n", "video_segments", "=", "video_to_segments", "(", "\n", "aclip_file", ",", "\n", "end_trim", "=", "acfg", ".", "end_trim", ",", "\n", "segment_gap", "=", "acfg", ".", "segment_gap", ",", "\n", "pad_segment", "=", "acfg", ".", "pad_segment", ",", "\n", "min_duration", "=", "acfg", ".", "min_duration", ",", "\n", "time_interval", "=", "acfg", ".", "time_interval", ",", "\n", "tile_length", "=", "acfg", ".", "tile_length", ",", "\n", ")", "\n", "\n", "video_segments", "=", "video_segments", "[", ":", "7", "]", "\n", "dummy_segment", "=", "copy", ".", "deepcopy", "(", "video_segments", "[", "0", "]", ")", "\n", "video_segments", ".", "insert", "(", "0", ",", "dummy_segment", ")", "\n", "\n", "video_segments", "[", "0", "]", "[", "'text'", "]", "=", "f'{self.cfg.text}'", "\n", "video_segments", "[", "0", "]", "[", "'use_text_as_input'", "]", "=", "True", "\n", "for", "seg", "in", "video_segments", "[", "1", ":", "]", ":", "\n", "            ", "seg", "[", "'use_text_as_input'", "]", "=", "False", "\n", "", "assert", "len", "(", "video_segments", ")", ">=", "2", ",", "f\"Require at least 2 video segments.\"", "\n", "\n", "video_pre", "=", "preprocess_video", "(", "video_segments", ",", "output_grid_size", "=", "acfg", ".", "grid_size", ",", "verbose", "=", "acfg", ".", "verbose", ")", "\n", "\n", "item", "=", "{", "\"video\"", ":", "video_pre", ",", "\"audio\"", ":", "audio", ",", "\"label_int\"", ":", "label_int", ",", "\"label_str\"", ":", "label_str", "}", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioDataset4Mreserve.__len__": [[179, 181], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.ImageAudioCollator4Mreserve.__call__": [[183, 192], ["numpy.concatenate", "numpy.array", "record.get", "set().union", "set"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "records", ")", ":", "\n", "        ", "union", "=", "{", "\n", "k", ":", "[", "record", ".", "get", "(", "k", ")", "for", "record", "in", "records", "]", "for", "k", "in", "set", "(", ")", ".", "union", "(", "*", "records", ")", "\n", "}", "\n", "return", "(", "\n", "np", ".", "concatenate", "(", "union", "[", "\"audio\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "array", "(", "union", "[", "\"label_int\"", "]", ")", ",", "\n", "union", "[", "\"label_str\"", "]", ",", "\n", "union", "[", "\"video\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader": [[194, 223], ["torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "esc50.ImageAudioDatasetSrc", "esc50.ImageAudioDataset4Mreserve", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "esc50.ImageAudioCollator4Mreserve", "esc50.ImageAudioCollator"], "function", ["None"], ["", "", "def", "build_dataloader", "(", "cfg", ",", "data_list", ",", "shuffle", "=", "True", ",", "train", "=", "True", ",", "mreserve", "=", "False", ")", ":", "\n", "    ", "ddp_mode", "=", "torch", ".", "distributed", ".", "is_initialized", "(", ")", "\n", "rcfg", "=", "cfg", ".", "running", "\n", "dataset", "=", "(", "\n", "ImageAudioDatasetSrc", "(", "rcfg", ",", "data_list", ",", "train", ")", "if", "not", "mreserve", "\n", "else", "ImageAudioDataset4Mreserve", "(", "rcfg", ",", "data_list", ",", "train", ")", "\n", ")", "\n", "if", "ddp_mode", ":", "\n", "        ", "assert", "self", ".", "cfg", ".", "optimizer", ".", "batch_size", "%", "self", ".", "cfg", ".", "num_gpus", "==", "0", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "dataset", ",", "shuffle", "=", "shuffle", "\n", ")", "\n", "per_device_batch_size", "=", "cfg", ".", "optimizer", ".", "batch_size", "//", "cfg", ".", "num_gpus", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "(", "\n", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "dataset", ")", "if", "shuffle", "else", "\n", "torch", ".", "utils", ".", "data", ".", "SequentialSampler", "(", "dataset", ")", "\n", ")", "\n", "per_device_batch_size", "=", "rcfg", ".", "batch_size", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "per_device_batch_size", ",", "\n", "collate_fn", "=", "(", "ImageAudioCollator4Mreserve", "(", ")", "if", "mreserve", "else", "ImageAudioCollator", "(", ")", ")", ",", "\n", "num_workers", "=", "(", "0", "if", "ddp_mode", "else", "cfg", ".", "num_proc", ")", ",", "\n", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "drop_last", "=", "(", "True", "if", "ddp_mode", "else", "False", ")", ",", "\n", ")", "\n", "return", "sampler", ",", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_esc50": [[224, 277], ["os.path.isfile", "numpy.loadtxt", "dict", "enumerate", "tuple", "range", "print", "clip.tokenize", "folds[].append", "range", "copy.deepcopy", "os.path.isfile", "rcfg.prompt.strip", "json.load", "list", "numpy.array", "range", "int", "train_list.extend", "open", "itertools.chain.from_iterable", "re.sub", "len", "list", "int", "copy.deepcopy", "lid2str[].replace", "range", "range", "range", "len", "len", "len", "range", "itertools.zip_longest", "esc50.build_dataloader", "esc50.build_dataloader", "len", "len", "len", "lid2str[].replace", "len", "int"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader"], ["", "def", "build_dataloader_list_esc50", "(", "cfg", ",", "mreserve", "=", "False", ")", ":", "\n", "    ", "rcfg", "=", "cfg", ".", "running", "\n", "data_path", "=", "f\"{rcfg.data_root}/meta/{rcfg.data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "meta", "=", "np", ".", "loadtxt", "(", "data_path", ",", "delimiter", "=", "\",\"", ",", "dtype", "=", "\"str\"", ",", "skiprows", "=", "1", ")", "\n", "nfold", "=", "5", "\n", "folds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "nfold", ")", "]", "\n", "lid2str", "=", "dict", "(", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "meta", ")", ":", "\n", "        ", "filename", ",", "fold", ",", "target", ",", "category", ",", "_", ",", "_", ",", "_", "=", "row", "\n", "item", "=", "{", "\n", "\"aclip\"", ":", "f\"audio/{filename}\"", ",", "\n", "\"label_int\"", ":", "int", "(", "target", ")", ",", "\n", "\"label_str\"", ":", "category", "\n", "}", "\n", "folds", "[", "int", "(", "fold", ")", "-", "1", "]", ".", "append", "(", "item", ")", "\n", "lid2str", "[", "int", "(", "target", ")", "]", "=", "category", "\n", "\n", "", "loader_tuple", "=", "tuple", "(", ")", "\n", "for", "i", "in", "range", "(", "nfold", ")", ":", "\n", "        ", "train_list", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "nfold", ")", ":", "\n", "            ", "if", "j", "==", "i", ":", "\n", "                ", "continue", "\n", "", "train_list", ".", "extend", "(", "copy", ".", "deepcopy", "(", "folds", "[", "j", "]", ")", ")", "\n", "", "eval_list", "=", "copy", ".", "deepcopy", "(", "folds", "[", "i", "]", ")", "\n", "# print(len(train_list), len(eval_list), len(train_list) + len(eval_list))", "\n", "# lazy loading ", "\n", "loader_tuple", "+=", "(", "(", "\n", "lambda", "data_list", "=", "train_list", ":", "build_dataloader", "(", "cfg", ",", "data_list", ",", "mreserve", "=", "mreserve", ")", ",", "\n", "lambda", "data_list", "=", "eval_list", ":", "build_dataloader", "(", "cfg", ",", "data_list", ",", "shuffle", "=", "False", ",", "train", "=", "False", ",", "mreserve", "=", "mreserve", ")", "\n", ")", ",", ")", "\n", "\n", "", "label_path", "=", "f\"{rcfg.data_root}/meta/{rcfg.prompt}.json\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "label_path", ")", ":", "\n", "        ", "prompt", "=", "rcfg", ".", "prompt", ".", "strip", "(", ")", "\n", "prompt", "=", "\"\"", "if", "prompt", "==", "\"\"", "else", "prompt", "+", "\" \"", "\n", "lid2int", "=", "[", "prompt", "+", "lid2str", "[", "i", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "]", "\n", "label_map", "=", "{", "i", ":", "i", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "}", "\n", "", "else", ":", "\n", "        ", "topk", "=", "4", "\n", "label_map", "=", "json", ".", "load", "(", "open", "(", "label_path", ",", "\"r\"", ")", ")", "\n", "text_list", "=", "[", "\n", "label_map", "[", "lid2str", "[", "i", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "]", "[", ":", "topk", "]", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "\n", "]", "\n", "lid2int", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "text_list", ")", ")", "\n", "lid2int", "=", "[", "re", ".", "sub", "(", "\"^a photo of\"", ",", "\"the sound of\"", ",", "text", ")", "for", "text", "in", "lid2int", "]", "\n", "assert", "len", "(", "lid2int", ")", "==", "len", "(", "text_list", ")", "*", "topk", ",", "f\"unbalanced label mapping: {len(text_list)}x{topk} -> {len(lid2int)}\"", "\n", "label_map", "=", "{", "i", ":", "i", "//", "topk", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", "*", "topk", ")", "}", "\n", "", "print", "(", "lid2int", ")", "\n", "lid2int", "=", "tokenize", "(", "lid2int", ",", "as_list", "=", "True", ")", "\n", "lid2int", "=", "np", ".", "array", "(", "list", "(", "itertools", ".", "zip_longest", "(", "*", "lid2int", ",", "fillvalue", "=", "0", ")", ")", ")", ".", "T", "\n", "return", "loader_tuple", ",", "lid2str", ",", "lid2int", ",", "label_map", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_us8k": [[278, 325], ["os.path.isfile", "numpy.loadtxt", "dict", "enumerate", "tuple", "range", "print", "clip.tokenize", "folds[].append", "range", "copy.deepcopy", "os.path.isfile", "rcfg.prompt.strip", "numpy.array", "range", "int", "train_list.extend", "lid2str[].replace", "list", "int", "copy.deepcopy", "lid2str[].replace", "range", "range", "range", "itertools.zip_longest", "esc50.build_dataloader", "esc50.build_dataloader", "len", "len", "len", "int"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader"], ["", "def", "build_dataloader_list_us8k", "(", "cfg", ",", "mreserve", "=", "False", ")", ":", "\n", "    ", "rcfg", "=", "cfg", ".", "running", "\n", "data_path", "=", "f\"{rcfg.data_root}/metadata/{rcfg.data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "meta", "=", "np", ".", "loadtxt", "(", "data_path", ",", "delimiter", "=", "\",\"", ",", "dtype", "=", "\"str\"", ",", "skiprows", "=", "1", ")", "\n", "nfold", "=", "10", "\n", "folds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "nfold", ")", "]", "\n", "lid2str", "=", "dict", "(", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "meta", ")", ":", "\n", "        ", "filename", ",", "_", ",", "_", ",", "_", ",", "_", ",", "fold", ",", "target", ",", "category", "=", "row", "\n", "item", "=", "{", "\n", "\"aclip\"", ":", "f\"audio/fold{fold}/{filename}\"", ",", "\n", "\"label_int\"", ":", "int", "(", "target", ")", ",", "\n", "\"label_str\"", ":", "category", "\n", "}", "\n", "folds", "[", "int", "(", "fold", ")", "-", "1", "]", ".", "append", "(", "item", ")", "\n", "lid2str", "[", "int", "(", "target", ")", "]", "=", "category", "\n", "\n", "", "loader_tuple", "=", "tuple", "(", ")", "\n", "for", "i", "in", "range", "(", "nfold", ")", ":", "\n", "        ", "train_list", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "nfold", ")", ":", "\n", "            ", "if", "j", "==", "i", ":", "\n", "                ", "continue", "\n", "", "train_list", ".", "extend", "(", "copy", ".", "deepcopy", "(", "folds", "[", "j", "]", ")", ")", "\n", "", "eval_list", "=", "copy", ".", "deepcopy", "(", "folds", "[", "i", "]", ")", "\n", "# print(len(train_list), len(eval_list), len(train_list) + len(eval_list))", "\n", "# lazy loading ", "\n", "loader_tuple", "+=", "(", "(", "\n", "lambda", "data_list", "=", "train_list", ":", "build_dataloader", "(", "cfg", ",", "data_list", ",", "mreserve", "=", "mreserve", ")", ",", "\n", "lambda", "data_list", "=", "eval_list", ":", "build_dataloader", "(", "cfg", ",", "data_list", ",", "shuffle", "=", "False", ",", "train", "=", "False", ",", "mreserve", "=", "mreserve", ")", "\n", ")", ",", ")", "\n", "\n", "", "label_path", "=", "f\"{rcfg.data_root}/meta/{rcfg.prompt}.json\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "label_path", ")", ":", "\n", "        ", "prompt", "=", "rcfg", ".", "prompt", ".", "strip", "(", ")", "\n", "prompt", "=", "\"\"", "if", "prompt", "==", "\"\"", "else", "prompt", "+", "\" \"", "\n", "lid2int", "=", "[", "prompt", "+", "lid2str", "[", "i", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "]", "\n", "#lid2int = [lid2str[i].replace(\"_\", \" \") + \" \" + prompt for i in range(len(lid2str))]", "\n", "label_map", "=", "{", "i", ":", "i", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "}", "\n", "", "else", ":", "\n", "        ", "lid2int", "=", "[", "lid2str", "[", "i", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "]", "\n", "pass", "\n", "", "print", "(", "lid2int", ")", "\n", "lid2int", "=", "tokenize", "(", "lid2int", ",", "as_list", "=", "True", ")", "\n", "lid2int", "=", "np", ".", "array", "(", "list", "(", "itertools", ".", "zip_longest", "(", "*", "lid2int", ",", "fillvalue", "=", "0", ")", ")", ")", ".", "T", "\n", "return", "loader_tuple", ",", "lid2str", ",", "lid2int", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_audioset": [[326, 376], ["os.path.isfile", "build_label_map", "build_label_map.items", "enumerate", "list", "len", "len", "build_label_map.items", "checksum.append", "open", "enumerate", "json.loads", "set", "set", "list.append", "set.add", "set.add", "list", "esc50.build_dataloader", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader"], ["", "def", "build_dataloader_list_audioset", "(", "cfg", ",", "mreserve", "=", "False", ")", ":", "\n", "    ", "rcfg", "=", "cfg", ".", "running", "\n", "data_path", "=", "f\"{rcfg.data_root}/{rcfg.eval_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "from", ".", ".", "import", "build_audioset_label_map", "as", "build_label_map", "\n", "label_map", "=", "build_label_map", "(", "rcfg", ".", "data_root", ",", "label_map", "=", "rcfg", ".", "label_map", ",", "prompt", "=", "\"\"", ")", "\n", "lid2int", "=", "[", "0", "]", "*", "len", "(", "label_map", ")", "\n", "lid2str", "=", "[", "0", "]", "*", "len", "(", "label_map", ")", "\n", "for", "k", ",", "v", "in", "label_map", ".", "items", "(", ")", ":", "\n", "        ", "lid2int", "[", "v", "[", "0", "]", "]", "=", "v", "[", "2", "]", "\n", "lid2str", "[", "v", "[", "0", "]", "]", "=", "v", "[", "1", "]", "\n", "", "checksum", "=", "[", "]", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "label_map", ".", "items", "(", ")", ")", ":", "\n", "        ", "checksum", ".", "append", "(", "v", "[", "-", "1", "]", "==", "lid2int", "[", "v", "[", "0", "]", "]", ")", "\n", "if", "i", "<", "600", "and", "rcfg", ".", "zero_shot", ":", "\n", "            ", "pass", "#print(k, v)", "\n", "#print(all(checksum))", "\n", "\n", "", "", "eval_list", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "        ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "            ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "name", "=", "record", "[", "\"id\"", "]", "\n", "sub_dir", "=", "record", "[", "\"dir\"", "]", "\n", "sub_dir", "=", "\"\"", "if", "len", "(", "sub_dir", ")", "==", "0", "else", "f\"{sub_dir}/\"", "\n", "akey", "=", "\"clip\"", "if", "\"clip\"", "in", "record", "else", "\"aclip\"", "\n", "aclip", "=", "record", "[", "akey", "]", "[", "0", "]", "\n", "\n", "label_int_set", "=", "set", "(", ")", "\n", "label_str_set", "=", "set", "(", ")", "\n", "for", "category", "in", "record", "[", "\"labels\"", "]", ":", "\n", "                ", "label_str_set", ".", "add", "(", "label_map", "[", "category", "]", "[", "1", "]", ")", "\n", "label_int_set", ".", "add", "(", "label_map", "[", "category", "]", "[", "0", "]", ")", "\n", "\n", "", "label_int", "=", "[", "1", "if", "i", "in", "label_int_set", "else", "0", "for", "i", "in", "range", "(", "len", "(", "label_map", ")", ")", "]", "\n", "label_str", "=", "\"<O>\"", ".", "join", "(", "list", "(", "label_str_set", ")", ")", "\n", "\n", "item", "=", "{", "\n", "\"aclip\"", ":", "f\"{sub_dir}{akey}/{name}.{aclip}\"", ",", "\n", "\"label_int\"", ":", "label_int", ",", "\n", "\"label_str\"", ":", "label_str", ",", "\n", "}", "\n", "eval_list", ".", "append", "(", "item", ")", "\n", "\n", "", "", "loader_tuple", "=", "(", "(", "\n", "lambda", ":", "None", ",", "\n", "lambda", "data_list", "=", "eval_list", ":", "build_dataloader", "(", "cfg", ",", "data_list", ",", "shuffle", "=", "False", ",", "train", "=", "False", ",", "mreserve", "=", "mreserve", ")", "\n", ")", ",", ")", "\n", "\n", "return", "loader_tuple", ",", "lid2str", ",", "lid2int", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_voxceleb2": [[377, 447], ["os.path.isfile", "collections.defaultdict", "dict", "dict", "dict", "clip.tokenize", "open", "open", "os.path.isfile", "rcfg.prompt.strip", "numpy.array", "json.loads", "min", "numpy.random.choice", "json.loads", "dict.setdefault", "dict.setdefault", "dict.setdefault", "lid2str[].replace", "list", "list", "len", "len", "samples_by_vid[].append", "len", "copy.deepcopy", "split.append", "esc50.build_dataloader", "lid2str[].replace", "range", "range", "range", "itertools.zip_longest", "json.loads.items", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader"], ["", "def", "build_dataloader_list_voxceleb2", "(", "cfg", ",", "mreserve", "=", "False", ")", ":", "\n", "    ", "rcfg", "=", "cfg", ".", "running", "\n", "data_path", "=", "f\"{rcfg.data_root}/{rcfg.data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "# load all data indice", "\n", "list_file", "=", "f\"{rcfg.data_root}/{rcfg.data_name}_list.csv\"", "\n", "nsample_per_vid", "=", "rcfg", ".", "nsample_per_vid", "\n", "samples_by_vid", "=", "defaultdict", "(", "list", ")", "\n", "with", "open", "(", "list_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "        ", "for", "record", "in", "fr", ":", "\n", "            ", "record", "=", "json", ".", "loads", "(", "record", ")", "\n", "k", ",", "v", "=", "list", "(", "record", ".", "items", "(", ")", ")", "[", "0", "]", "\n", "nsample", "=", "min", "(", "nsample_per_vid", ",", "len", "(", "v", ")", ")", "\n", "indice", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "v", ")", ",", "nsample", ",", "replace", "=", "False", ")", "\n", "samples", "=", "[", "v", "[", "idx", "]", "for", "idx", "in", "indice", "]", "\n", "for", "a", ",", "b", "in", "samples", ":", "\n", "                ", "samples_by_vid", "[", "k", "]", ".", "append", "(", "f\"{b}/{a}\"", ")", "\n", "# create splits", "\n", "", "", "", "lid2str", "=", "dict", "(", ")", "\n", "str2lid", "=", "dict", "(", ")", "# label space", "\n", "lid2face", "=", "dict", "(", ")", "\n", "splits", "=", "{", "\"dev\"", ":", "[", "]", ",", "\"test\"", ":", "[", "]", "}", "\n", "dev_fold", ",", "test_fold", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "        ", "for", "record", "in", "fr", ":", "\n", "            ", "record", "=", "json", ".", "loads", "(", "record", ")", "\n", "split_id", "=", "record", "[", "\"split\"", "]", "\n", "if", "split_id", "==", "\"dev\"", ":", "\n", "                ", "continue", "\n", "", "name", "=", "record", "[", "\"name\"", "]", "\n", "vox_id", "=", "record", "[", "\"vox_id\"", "]", "\n", "split", "=", "splits", "[", "split_id", "]", "\n", "\n", "face", "=", "f'{record[\"vgg_split\"]}/{record[\"vgg_id\"]}/{record[\"face\"]}'", "\n", "face_file", "=", "f\"{rcfg.data_root}/vggface2/{face}\"", "\n", "\n", "lid_int", "=", "str2lid", ".", "setdefault", "(", "name", ",", "len", "(", "str2lid", ")", ")", "\n", "lid_str", "=", "lid2str", ".", "setdefault", "(", "lid_int", ",", "name", ")", "\n", "lid2face", ".", "setdefault", "(", "lid_int", ",", "face_file", ")", "\n", "\n", "#print(lid_int, len(samples_by_vid[vox_id]), vox_id, lid_str)", "\n", "for", "sample", "in", "samples_by_vid", "[", "vox_id", "]", ":", "\n", "                ", "acopy", "=", "copy", ".", "deepcopy", "(", "record", ")", "\n", "acopy", "[", "\"aclip\"", "]", "=", "f\"mp4/{vox_id}/{sample[:-3]}mp4\"", "\n", "acopy", "[", "\"aclip\"", "]", "=", "f\"aac/{vox_id}/{sample}\"", "\n", "acopy", "[", "\"label_int\"", "]", "=", "lid_int", "\n", "acopy", "[", "\"label_str\"", "]", "=", "lid_str", "\n", "split", ".", "append", "(", "acopy", ")", "\n", "\n", "", "", "", "loader_tuple", "=", "(", "(", "\n", "lambda", ":", "None", ",", "\n", "lambda", "data_list", "=", "splits", "[", "\"test\"", "]", ":", "build_dataloader", "(", "cfg", ",", "data_list", ",", "shuffle", "=", "False", ",", "train", "=", "False", ",", "mreserve", "=", "mreserve", ")", "\n", ")", ",", ")", "\n", "\n", "label_path", "=", "f\"{rcfg.data_root}/meta/{rcfg.prompt}.json\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "label_path", ")", ":", "\n", "        ", "prompt", "=", "rcfg", ".", "prompt", ".", "strip", "(", ")", "\n", "prompt", "=", "\"\"", "if", "prompt", "==", "\"\"", "else", "prompt", "+", "\" \"", "\n", "lid2int", "=", "[", "prompt", "+", "lid2str", "[", "i", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "]", "\n", "#lid2int = [lid2str[i].replace(\"_\", \" \") + \" \" + prompt for i in range(len(lid2str))]", "\n", "label_map", "=", "{", "i", ":", "i", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "}", "\n", "", "else", ":", "\n", "        ", "lid2int", "=", "[", "lid2str", "[", "i", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "i", "in", "range", "(", "len", "(", "lid2str", ")", ")", "]", "\n", "pass", "\n", "#print(lid2str)", "\n", "#print(lid2face, len(lid2face))", "\n", "#print(lid2int, len(lid2int), len(splits[\"test\"]))", "\n", "", "lid2int", "=", "tokenize", "(", "lid2int", ",", "as_list", "=", "True", ")", "\n", "lid2int", "=", "np", ".", "array", "(", "list", "(", "itertools", ".", "zip_longest", "(", "*", "lid2int", ",", "fillvalue", "=", "0", ")", ")", ")", ".", "T", "\n", "return", "loader_tuple", ",", "lid2str", ",", "lid2int", ",", "lid2face", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_xfold_dataloader_list": [[448, 459], ["esc50.build_dataloader_list_esc50", "esc50.build_dataloader_list_us8k", "esc50.build_dataloader_list_audioset", "esc50.build_dataloader_list_voxceleb2", "ValueError"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_esc50", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_us8k", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_audioset", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader_list_voxceleb2"], ["", "def", "build_xfold_dataloader_list", "(", "cfg", ",", "mreserve", "=", "False", ")", ":", "\n", "    ", "if", "cfg", ".", "running", ".", "data_name", "==", "\"esc50\"", ":", "\n", "        ", "return", "build_dataloader_list_esc50", "(", "cfg", ",", "mreserve", "=", "mreserve", ")", "\n", "", "elif", "cfg", ".", "running", ".", "data_name", "==", "\"UrbanSound8K\"", ":", "\n", "        ", "return", "build_dataloader_list_us8k", "(", "cfg", ",", "mreserve", "=", "mreserve", ")", "\n", "", "elif", "cfg", ".", "running", ".", "data_name", "==", "\"audioset\"", ":", "\n", "        ", "return", "build_dataloader_list_audioset", "(", "cfg", ",", "mreserve", "=", "mreserve", ")", "\n", "", "elif", "cfg", ".", "running", ".", "data_name", "==", "\"voxceleb2\"", ":", "\n", "        ", "return", "build_dataloader_list_voxceleb2", "(", "cfg", ",", "mreserve", "=", "mreserve", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognized dataset `{cfg.running.data_name}`.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_filter_set": [[32, 59], ["filter_set.split", "set", "open", "json.load", "set", "json.load.items", "int", "set", "json.loads.strip", "set.add", "open", "set.update", "open", "json.loads", "set", "set.update", "list", "json.loads.items"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["def", "build_filter_set", "(", "data_root", ",", "filter_set", ")", ":", "\n", "    ", "try", ":", "# filters can be None", "\n", "        ", "name", ",", "topk", "=", "filter_set", ".", "split", "(", "\",\"", ")", "\n", "filter_file", "=", "f\"{data_root}/{name}\"", "\n", "if", "filter_file", "[", "-", "3", ":", "]", "==", "\"csv\"", ":", "\n", "            ", "samples", "=", "set", "(", ")", "\n", "with", "open", "(", "filter_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "                ", "for", "line", "in", "fr", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "samples", ".", "add", "(", "line", ")", "\n", "", "", "", "elif", "filter_file", "[", "-", "1", "]", "==", "\"k\"", ":", "\n", "            ", "samples_per_label", "=", "json", ".", "load", "(", "open", "(", "filter_file", ",", "\"r\"", ")", ")", "\n", "samples", "=", "set", "(", ")", "\n", "for", "k", ",", "v", "in", "samples_per_label", ".", "items", "(", ")", ":", "\n", "                ", "samples", ".", "update", "(", "v", ")", "\n", "", "", "else", ":", "\n", "            ", "topk", "=", "int", "(", "topk", ")", "\n", "samples", "=", "set", "(", ")", "\n", "with", "open", "(", "filter_file", ",", "\"r\"", ")", "as", "fr", ":", "\n", "                ", "for", "line", "in", "fr", ":", "\n", "                    ", "line", "=", "json", ".", "loads", "(", "line", ")", "\n", "k", ",", "v", "=", "list", "(", "line", ".", "items", "(", ")", ")", "[", "0", "]", "\n", "new_samples", "=", "set", "(", "[", "name", "for", "name", ",", "_", "in", "v", "[", ":", "topk", "]", "]", "+", "[", "k", "]", ")", "\n", "samples", ".", "update", "(", "new_samples", ")", "\n", "", "", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "samples", "=", "None", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.collect_ytid": [[60, 75], ["collections.defaultdict", "list", "open", "range", "enumerate", "collections.defaultdict.keys", "next", "row.split.split", "ids[].append", "row[].strip", "row[].strip", "row[].strip().split", "row[].strip", "row[].strip"], "function", ["None"], ["", "def", "collect_ytid", "(", "csv_root", ",", "csv_list", ")", ":", "\n", "    ", "ids", "=", "defaultdict", "(", "list", ")", "\n", "nrow", "=", "0", "\n", "for", "fname", "in", "csv_list", ":", "\n", "        ", "ifile", "=", "f\"{csv_root}/{fname}.csv\"", "\n", "with", "open", "(", "ifile", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "_", "in", "range", "(", "3", ")", ":", "\n", "                ", "next", "(", "fr", ")", "\n", "", "for", "irow", ",", "row", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "row", "=", "row", ".", "split", "(", "\", \"", ")", "\n", "ids", "[", "row", "[", "0", "]", ".", "strip", "(", ")", "]", ".", "append", "(", "\n", "(", "row", "[", "1", "]", ".", "strip", "(", ")", ",", "row", "[", "2", "]", ".", "strip", "(", ")", ",", "row", "[", "3", "]", ".", "strip", "(", "'\" \\n'", ")", ".", "split", "(", "\",\"", ")", ")", "\n", ")", "\n", "nrow", "+=", "1", "\n", "", "", "", "return", "list", "(", "ids", ".", "keys", "(", ")", ")", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_audioset_label_map": [[76, 107], ["label_map.split", "list", "json.load", "clip.tokenize", "audioset_hub.collect_ytid", "set", "os.path.isfile", "os.path.isfile", "open", "list.append", "itertools.chain.from_iterable", "prompt.strip", "prompt.strip", "enumerate", "range", "len", "item[].lower", "ytid_dict.items"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.collect_ytid"], ["", "def", "build_audioset_label_map", "(", "data_root", ",", "label_map", "=", "\"ontology,eval_segments\"", ",", "prompt", "=", "\"\"", ")", ":", "\n", "    ", "file_list", "=", "label_map", ".", "split", "(", "\",\"", ")", "\n", "ontology", ",", "label_files", "=", "file_list", "[", "0", "]", ",", "file_list", "[", "1", ":", "]", "\n", "label_path", "=", "f\"{data_root}/{ontology}.json\"", "\n", "label_real", "=", "f\"{data_root}/{label_files[0]}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "label_path", ")", "and", "os", ".", "path", ".", "isfile", "(", "label_real", ")", ",", "(", "\n", "\"please specify a valid `ontology` file (ontology) and `eval` file (eval_segments).\"", "\n", ")", "\n", "category_list", "=", "list", "(", ")", "\n", "ontology", "=", "json", ".", "load", "(", "open", "(", "label_path", ",", "\"r\"", ")", ")", "\n", "prompt", "=", "\"\"", "if", "prompt", ".", "strip", "(", ")", "==", "\"\"", "else", "prompt", ".", "strip", "(", ")", "+", "\" \"", "\n", "for", "item", "in", "ontology", ":", "\n", "        ", "category", "=", "item", "[", "\"id\"", "]", "\n", "category_list", ".", "append", "(", "\n", "(", "category", ",", "prompt", "+", "item", "[", "\"name\"", "]", ".", "lower", "(", ")", ")", "\n", ")", "\n", "", "text_list", "=", "[", "item", "[", "1", "]", "for", "item", "in", "category_list", "]", "\n", "label_int", "=", "tokenize", "(", "text_list", ",", "as_list", "=", "True", ")", "\n", "category_list", "=", "[", "item", "+", "(", "label_int", "[", "i", "]", ",", ")", "for", "i", ",", "item", "in", "enumerate", "(", "category_list", ")", "]", "\n", "#label_map = {category_list[i][0]: (i, category_list[i][1], label_int[i]) for i in range(len(category_list))}", "\n", "\n", "_", ",", "ytid_dict", "=", "collect_ytid", "(", "data_root", ",", "label_files", ")", "\n", "\n", "label_set", "=", "set", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "\n", "v", "[", "0", "]", "[", "2", "]", "for", "_", ",", "v", "in", "ytid_dict", ".", "items", "(", ")", "\n", ")", ")", "\n", "category_list", "=", "[", "item", "for", "item", "in", "category_list", "if", "item", "[", "0", "]", "in", "label_set", "]", "\n", "label_map", "=", "{", "category_list", "[", "i", "]", "[", "0", "]", ":", "(", "i", ",", ")", "+", "category_list", "[", "i", "]", "[", "1", ":", "]", "for", "i", "in", "range", "(", "len", "(", "category_list", ")", ")", "}", "\n", "#print(text_list, len(label_set))", "\n", "#print(label_map, len(label_map))", "\n", "return", "label_map", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_audioset_dataloader": [[108, 144], ["torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "data_name.startswith", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_name.startswith", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "audioset_cls.AudiosetSrc", "audioset_cls.AudiosetNpz", "audioset_clf.AudiosetDatasetNpz", "data_name.startswith", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "audioset_clf.ImageAudioCollator", "audiocaps.AudioCapDatasetSrc", "ValueError"], "function", ["None"], ["", "def", "build_audioset_dataloader", "(", "cfg", ",", "data_name", ",", "label_map", ",", "shuffle", "=", "True", ",", "train", "=", "True", ",", "external_text", "=", "None", ",", "filters", "=", "None", ")", ":", "\n", "    ", "ddp_mode", "=", "torch", ".", "distributed", ".", "is_initialized", "(", ")", "\n", "rcfg", "=", "cfg", ".", "running", "\n", "if", "data_name", ".", "startswith", "(", "\"src\"", ")", ":", "\n", "        ", "if", "not", "rcfg", ".", "force_npz", ":", "\n", "            ", "dataset", "=", "AudiosetSrc", "(", "rcfg", ",", "data_name", ",", "train", ",", "label_map", ",", "False", ",", "external_text", "=", "external_text", ",", "filter_set", "=", "filters", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "AudiosetNpz", "(", "rcfg", ",", "data_name", ",", "train", ",", "label_map", ",", "False", ",", "external_text", "=", "external_text", ")", "\n", "", "", "elif", "data_name", ".", "startswith", "(", "\"npz\"", ")", ":", "\n", "        ", "dataset", "=", "AudiosetDatasetNpz", "(", "rcfg", ",", "data_name", ",", "train", ",", "label_map", ",", "False", ")", "\n", "", "elif", "data_name", ".", "startswith", "(", "\"audiocaps\"", ")", ":", "# audio captioning", "\n", "        ", "dataset", "=", "AudioCapDatasetSrc", "(", "rcfg", ",", "data_name", ",", "train", ",", "label_map", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognized data file `{data_name}`.\"", ")", "\n", "", "if", "ddp_mode", ":", "\n", "        ", "assert", "cfg", ".", "optimizer", ".", "batch_size", "%", "cfg", ".", "num_gpus", "==", "0", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "dataset", ",", "shuffle", "=", "shuffle", "\n", ")", "\n", "per_device_batch_size", "=", "cfg", ".", "optimizer", ".", "batch_size", "//", "cfg", ".", "num_gpus", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "(", "\n", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "dataset", ")", "if", "shuffle", "else", "\n", "torch", ".", "utils", ".", "data", ".", "SequentialSampler", "(", "dataset", ")", "\n", ")", "\n", "per_device_batch_size", "=", "cfg", ".", "optimizer", ".", "batch_size", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "per_device_batch_size", ",", "\n", "collate_fn", "=", "ImageAudioCollator", "(", ")", ",", "\n", "num_workers", "=", "(", "0", "if", "ddp_mode", "else", "cfg", ".", "num_proc", ")", ",", "\n", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "drop_last", "=", "(", "True", "if", "ddp_mode", "else", "False", ")", ",", "\n", ")", "\n", "return", "sampler", ",", "dataloader", "\n", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetNpz.__init__": [[30, 50], ["os.path.isfile", "list", "len", "audio.make_transform", "open", "enumerate", "int", "numpy.random.permutation", "json.loads", "image_audio.ImageAudioDatasetNpz.dataset.append", "numpy.random.permutation", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_name", ",", "train", ")", ":", "\n", "        ", "data_path", "=", "f\"{cfg.data_root}/{data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "self", ".", "dataset", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                    ", "break", "\n", "", "", "", "if", "train", "and", "cfg", ".", "train_samples", ">", "0.", "and", "cfg", ".", "train_samples", "<", "1.", ":", "\n", "            ", "k", "=", "int", "(", "len", "(", "self", ".", "dataset", ")", "*", "cfg", ".", "train_samples", ")", "\n", "#self.dataset = np.random.choice(self.dataset, k, replace=False)", "\n", "shuffled_indice", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "self", ".", "dataset", "=", "[", "self", ".", "dataset", "[", "i", "]", "for", "i", "in", "shuffled_indice", "[", ":", "k", "]", "]", "\n", "", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "transform_audio", ",", "self", ".", "transform_fbank", "=", "make_transform", "(", "cfg", ".", "audio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetNpz._shuffle": [[51, 53], ["None"], "methods", ["None"], ["", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetNpz.__getitem__": [[54, 86], ["numpy.load", "len", "numpy.load", "image_audio.ImageAudioDatasetNpz.transform_fbank", "numpy.pad", "len", "numpy.random.choice", "int", "len", "len", "numpy.ceil", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "name", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"id\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"aclip\"", "]", "\n", "frame", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"frame\"", "]", "\n", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{aclip}\"", "\n", "frame_file", "=", "f\"{self.cfg.data_root}/{frame}\"", "\n", "\n", "images", "=", "np", ".", "load", "(", "frame_file", ")", "\n", "images", "=", "[", "images", "[", "key", "]", "for", "key", "in", "images", ".", "files", "if", "len", "(", "images", "[", "key", "]", ")", "!=", "0", "]", "\n", "assert", "len", "(", "images", ")", "!=", "0", ",", "f\"no frame exist: |images| = {len(images)}\"", "\n", "if", "self", ".", "train", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "idx", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "", "image", "=", "images", "[", "idx", "]", "\n", "\n", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "np", ".", "load", "(", "aclip_file", ")", "[", "\"flag\"", "]", "# (..., time, freq): `flag' is used as the key accidentally", "\n", "\n", "if", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "\n", "", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "\n", "", "image", "=", "image", "[", "None", "]", "\n", "audio", "=", "audio", "[", "None", "]", "\n", "\n", "item", "=", "{", "\"image\"", ":", "image", ",", "\"audio\"", ":", "audio", ",", "\"name\"", ":", "name", "}", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetNpz.__len__": [[87, 89], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc.__init__": [[93, 126], ["os.path.isfile", "list", "len", "image.make_clip_image_transform", "audio.make_transform", "open", "enumerate", "int", "numpy.random.permutation", "json.loads", "image_audio.ImageAudioDatasetSrc.dataset.append", "numpy.random.permutation", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.make_clip_image_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_name", ",", "train", ")", ":", "\n", "        ", "data_path", "=", "f\"{cfg.data_root}/{data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "self", ".", "dataset", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                    ", "break", "\n", "", "", "", "if", "train", "and", "cfg", ".", "train_samples", ">", "0.", "and", "cfg", ".", "train_samples", "<", "1.", ":", "\n", "            ", "k", "=", "int", "(", "len", "(", "self", ".", "dataset", ")", "*", "cfg", ".", "train_samples", ")", "\n", "#self.dataset = np.random.choice(self.dataset, k, replace=False)", "\n", "shuffled_indice", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "self", ".", "dataset", "=", "[", "self", ".", "dataset", "[", "i", "]", "for", "i", "in", "shuffled_indice", "[", ":", "k", "]", "]", "\n", "", "self", ".", "audio_norms", "=", "cfg", ".", "audio", ".", "norms", "\n", "# compatible with AudioSet and Balanced AudioSet", "\n", "self", ".", "aclip_key", "=", "\"clip\"", "if", "\"clip\"", "in", "self", ".", "dataset", "[", "0", "]", "else", "\"aclip\"", "\n", "self", ".", "frame_key", "=", "cfg", ".", "frame_key", "\n", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "acfg", "=", "cfg", ".", "audio", "\n", "self", ".", "transform_image", "=", "make_image_transform", "(", "cfg", ".", "resolution", ")", "\n", "self", ".", "transform_audio", ",", "self", ".", "transform_fbank", "=", "make_transform", "(", "acfg", ")", "\n", "self", ".", "kaldi_params", "=", "{", "\n", "\"htk_compat\"", ":", "True", ",", "\n", "\"use_energy\"", ":", "False", ",", "\n", "\"window_type\"", ":", "'hanning'", ",", "\n", "\"num_mel_bins\"", ":", "acfg", ".", "num_mel_bins", ",", "\n", "\"dither\"", ":", "0.0", ",", "\n", "\"frame_shift\"", ":", "10", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc._shuffle": [[128, 130], ["None"], "methods", ["None"], ["", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc._process_item": [[131, 152], ["isinstance", "len", "numpy.random.choice", "int", "len", "numpy.ceil", "images[].rsplit", "len"], "methods", ["None"], ["", "def", "_process_item", "(", "self", ",", "index", ")", ":", "\n", "        ", "akey", "=", "self", ".", "aclip_key", "\n", "fkey", "=", "self", ".", "frame_key", "\n", "sub_dir", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"dir\"", "]", "\n", "name", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"id\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "akey", "]", "[", "0", "]", "\n", "frame", "=", "images", "=", "self", ".", "dataset", "[", "index", "]", "[", "fkey", "]", "\n", "\n", "sub_dir", "=", "\"\"", "if", "len", "(", "sub_dir", ")", "==", "0", "else", "f\"{sub_dir}/\"", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{akey}/{name}.{aclip}\"", "\n", "\n", "frame_emb_file", "=", "None", "\n", "if", "isinstance", "(", "frame", ",", "str", ")", ":", "\n", "            ", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{frame}\"", "\n", "", "else", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{images[idx]}\"", "\n", "if", "self", ".", "cfg", ".", "frame_emb", "is", "not", "None", ":", "\n", "                ", "frame_emb_file", "=", "f\"{self.cfg.data_root}/{self.cfg.frame_emb}/{name}.{images[idx].rsplit('.', 1)[0]}.npz\"", "\n", "\n", "", "", "return", "name", ",", "aclip_file", ",", "frame_file", ",", "frame_emb_file", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc._image2embed": [[153, 160], ["numpy.load", "numpy.random.rand().astype", "warnings.warn", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2embed", "(", "self", ",", "fname", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "image", "=", "np", ".", "load", "(", "fname", ")", "[", "\"v\"", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "image", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "cfg", ".", "embed_dim", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc._image2numpy": [[161, 182], ["numpy.array", "fname.endswith", "numpy.load", "PIL.Image.open", "image_audio.ImageAudioDatasetSrc.transform_image().cpu().numpy", "PIL.Image.fromarray", "warnings.warn", "image_audio.ImageAudioDatasetSrc.transform_image().cpu().numpy", "numpy.random.choice", "int", "image_audio.ImageAudioDatasetSrc.transform_image().cpu", "image_audio.ImageAudioDatasetSrc.transform_image().cpu", "len", "len", "numpy.ceil", "image_audio.ImageAudioDatasetSrc.transform_image", "numpy.random.rand", "image_audio.ImageAudioDatasetSrc.transform_image", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2numpy", "(", "self", ",", "fname", ")", ":", "\n", "        ", "if", "fname", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "fname", ".", "endswith", "(", "\".npz\"", ")", ":", "\n", "                    ", "images", "=", "np", ".", "load", "(", "fname", ")", "\n", "images", "=", "[", "images", "[", "key", "]", "for", "key", "in", "images", ".", "files", "if", "len", "(", "images", "[", "key", "]", ")", "!=", "0", "]", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "image", "=", "images", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "image", "=", "PILImage", ".", "open", "(", "fname", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "h", "=", "w", "=", "self", ".", "cfg", ".", "resolution", "\n", "image", "=", "PILImage", ".", "fromarray", "(", "\n", "(", "np", ".", "random", ".", "rand", "(", "h", ",", "w", ",", "3", ")", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "image", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc._audio2numpy": [[183, 208], ["image_audio.ImageAudioDatasetSrc._extract_kaldi_spectrogram", "numpy.pad", "image_audio.ImageAudioDatasetSrc.transform_fbank", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform._extract_kaldi_spectrogram"], ["", "def", "_audio2numpy", "(", "self", ",", "aclip_file", ")", ":", "\n", "        ", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "_extract_kaldi_spectrogram", "(", "\n", "aclip_file", ",", "\n", "self", ".", "kaldi_params", ",", "\n", "train", "=", "self", ".", "train", ",", "\n", "max_audio_len", "=", "max_audio_len", ",", "\n", "zero_mean_wf", "=", "self", ".", "cfg", ".", "audio", ".", "zero_mean_wf", ",", "\n", "transform_audio", "=", "(", "\n", "self", ".", "transform_audio", "if", "self", ".", "train", "and", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "else", "None", "\n", ")", "\n", ")", "# (..., time, freq)", "\n", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "len", "(", "self", ".", "audio_norms", ")", "==", "2", ":", "\n", "            ", "mean", ",", "std", "=", "self", ".", "audio_norms", "\n", "audio", "=", "(", "audio", "-", "mean", ")", "/", "std", "\n", "\n", "#if self.train and self.transform_fbank is not None:", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc.__getitem__": [[209, 220], ["image_audio.ImageAudioDatasetSrc._process_item", "image_audio.ImageAudioDatasetSrc._audio2numpy", "image_audio.ImageAudioDatasetSrc._image2embed", "image_audio.ImageAudioDatasetSrc._image2numpy"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSiameseSrc._audio2numpy", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2embed", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2numpy"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "name", ",", "aclip_file", ",", "frame_file", ",", "frame_emb_file", "=", "self", ".", "_process_item", "(", "index", ")", "\n", "\n", "# higher priority for pre-computed frame embeddings", "\n", "image", "=", "self", ".", "_image2embed", "(", "frame_emb_file", ")", "if", "frame_emb_file", "is", "not", "None", "else", "self", ".", "_image2numpy", "(", "frame_file", ")", "\n", "audio", "=", "self", ".", "_audio2numpy", "(", "aclip_file", ")", "\n", "\n", "image", "=", "image", "[", "None", "]", "\n", "audio", "=", "audio", "[", "None", "]", "\n", "item", "=", "{", "\"image\"", ":", "image", ",", "\"audio\"", ":", "audio", ",", "\"name\"", ":", "name", "}", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSrc.__len__": [[221, 223], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSiameseSrc.__init__": [[228, 240], ["image_audio.ImageAudioDatasetSrc.__init__", "image.BarlowImageTransform", "audio.FbankTransform"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_name", ",", "train", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ".", "running", ",", "data_name", ",", "train", ")", "\n", "self", ".", "lcfg", "=", "cfg", ".", "model", ".", "loss", "\n", "assert", "self", ".", "cfg", ".", "frame_emb", "is", "not", "None", ",", "f\"`frame_emb` is None\"", "\n", "if", "not", "cfg", ".", "running", ".", "clip_tf", ":", "\n", "            ", "from", ".", "image", "import", "BarlowImageTransform", "as", "ImageTransform", "\n", "", "else", ":", "# use `CLIPImageTransform` to generate multi-view images", "\n", "            ", "from", ".", "image", "import", "CLIPImageTransform", "as", "ImageTransform", "\n", "from", ".", "image", "import", "AuthenticCLIPImageTransform", "as", "ImageTransform", "\n", "", "self", ".", "transform_image", "=", "ImageTransform", "(", "self", ".", "cfg", ".", "resolution", ")", "\n", "self", ".", "transform_audio", "=", "None", "\n", "self", ".", "transform_fbank", "=", "FbankTransform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSiameseSrc._image2numpy": [[241, 255], ["image_audio.ImageAudioDatasetSiameseSrc.transform_image", "PIL.Image.open", "PIL.Image.fromarray", "warnings.warn", "numpy.array", "numpy.random.rand"], "methods", ["None"], ["", "def", "_image2numpy", "(", "self", ",", "fname", ")", ":", "\n", "        ", "if", "fname", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "image", "=", "PILImage", ".", "open", "(", "fname", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "h", "=", "w", "=", "self", ".", "cfg", ".", "resolution", "\n", "image", "=", "PILImage", ".", "fromarray", "(", "\n", "(", "np", ".", "random", ".", "rand", "(", "h", ",", "w", ",", "3", ")", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "", "images", "=", "self", ".", "transform_image", "(", "image", ",", "self", ".", "lcfg", ".", "vv", ",", "self", ".", "train", ")", "\n", "", "else", ":", "\n", "            ", "images", "=", "(", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", ",", ")", "*", "2", "\n", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSiameseSrc._audio2numpy": [[256, 286], ["np.pad._extract_kaldi_spectrogram", "image_audio.ImageAudioDatasetSiameseSrc.transform_fbank", "numpy.pad"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform._extract_kaldi_spectrogram"], ["", "def", "_audio2numpy", "(", "self", ",", "aclip_file", ")", ":", "\n", "        ", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "_extract_kaldi_spectrogram", "(", "\n", "aclip_file", ",", "\n", "self", ".", "kaldi_params", ",", "\n", "train", "=", "self", ".", "train", ",", "\n", "max_audio_len", "=", "max_audio_len", ",", "\n", "zero_mean_wf", "=", "self", ".", "cfg", ".", "audio", ".", "zero_mean_wf", ",", "\n", "transform_audio", "=", "(", "\n", "self", ".", "transform_audio", "if", "self", ".", "train", "and", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "else", "None", "\n", ")", "\n", ")", "# (..., time, freq)", "\n", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "\n", "", "\"\"\"\n        if not self.cfg.audio.eval_norms and len(self.audio_norms) == 2:\n            mean, std = self.audio_norms\n            audio = (audio - mean) / std\n\n        #if self.train and self.transform_fbank is not None:\n        if not self.cfg.audio.eval_norms and self.train and self.transform_fbank is not None:\n            audio = self.transform_fbank(audio)\n        return audio[None], np.array([[[1]]])\n        \"\"\"", "\n", "\n", "audios", "=", "self", ".", "transform_fbank", "(", "audio", ",", "self", ".", "lcfg", ".", "aa", ",", "self", ".", "train", ")", "\n", "return", "audios", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSiameseSrc.__getitem__": [[287, 306], ["image_audio.ImageAudioDatasetSiameseSrc._process_item", "tuple", "tuple", "image_audio.ImageAudioDatasetSiameseSrc._image2embed", "numpy.array", "image_audio.ImageAudioDatasetSiameseSrc._image2numpy", "image_audio.ImageAudioDatasetSiameseSrc._audio2numpy"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2embed", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2numpy", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioDatasetSiameseSrc._audio2numpy"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "name", ",", "aclip_file", ",", "frame_file", ",", "frame_emb_file", "=", "self", ".", "_process_item", "(", "index", ")", "\n", "\n", "image", "=", "self", ".", "_image2embed", "(", "frame_emb_file", ")", "if", "self", ".", "lcfg", ".", "vp", "or", "self", ".", "lcfg", ".", "ap", "else", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "images", "=", "tuple", "(", "x", "[", "None", "]", "for", "x", "in", "self", ".", "_image2numpy", "(", "frame_file", ")", ")", "\n", "audios", "=", "tuple", "(", "x", "[", "None", "]", "for", "x", "in", "self", ".", "_audio2numpy", "(", "aclip_file", ")", ")", "\n", "\n", "#image = np.array([[[1]]])", "\n", "#images = (self._image2numpy(frame_file), np.array([[[1]]]))", "\n", "#images = tuple(x[None] for x in images)", "\n", "#audios = (self._audio2numpy(aclip_file)[None], np.array([[[1]]]))", "\n", "#audios = tuple(x[None] for x in audios)", "\n", "\n", "item", "=", "{", "\n", "\"image\"", ":", "image", "[", "None", "]", ",", "\"name\"", ":", "name", ",", "\n", "\"image_v1\"", ":", "images", "[", "0", "]", ",", "\"image_v2\"", ":", "images", "[", "1", "]", ",", "\n", "\"audio_v1\"", ":", "audios", "[", "0", "]", ",", "\"audio_v2\"", ":", "audios", "[", "1", "]", "\n", "}", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioCollator.__init__": [[308, 312], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", ":", "\n", "# RuntimeError: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned", "\n", "# when pin_memory is true, the collator has to return CPU tensors", "\n", "        ", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.ImageAudioCollator.__call__": [[313, 331], ["record.get", "set().union", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "set"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "records", ")", ":", "\n", "        ", "union", "=", "{", "\n", "k", ":", "[", "record", ".", "get", "(", "k", ")", "for", "record", "in", "records", "]", "for", "k", "in", "set", "(", ")", ".", "union", "(", "*", "records", ")", "\n", "}", "\n", "if", "\"image_v1\"", "in", "union", ":", "\n", "            ", "return", "(", "\n", "np", ".", "concatenate", "(", "union", "[", "\"image\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "concatenate", "(", "union", "[", "\"image_v1\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "concatenate", "(", "union", "[", "\"image_v2\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "concatenate", "(", "union", "[", "\"audio_v1\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "concatenate", "(", "union", "[", "\"audio_v2\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "union", "[", "\"name\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "\n", "np", ".", "concatenate", "(", "union", "[", "\"image\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "concatenate", "(", "union", "[", "\"audio\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "union", "[", "\"name\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.build_image_audio_dataloader": [[333, 376], ["torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "rcfg.data_root.startswith", "data_name.startswith", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_name.startswith", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "ValueError", "ValueError", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "image_audio.ImageAudioCollator", "getattr", "image_audio.ImageAudioDatasetSrc", "image_audio.ImageAudioDatasetSiameseSrc", "image_audio.ImageAudioDatasetNpz", "ValueError"], "function", ["None"], ["", "", "", "def", "build_image_audio_dataloader", "(", "cfg", ",", "data_name", ",", "shuffle", "=", "True", ",", "train", "=", "True", ")", ":", "\n", "    ", "ddp_mode", "=", "torch", ".", "distributed", ".", "is_initialized", "(", ")", "\n", "rcfg", "=", "cfg", ".", "running", "\n", "from_gs", "=", "rcfg", ".", "data_root", ".", "startswith", "(", "\"gs://\"", ")", "\n", "if", "data_name", ".", "startswith", "(", "\"src\"", ")", ":", "\n", "        ", "if", "not", "from_gs", ":", "\n", "            ", "if", "not", "getattr", "(", "rcfg", ",", "\"multi_view\"", ",", "False", ")", ":", "\n", "                ", "dataset", "=", "ImageAudioDatasetSrc", "(", "rcfg", ",", "data_name", ",", "train", ")", "\n", "", "else", ":", "\n", "                ", "dataset", "=", "ImageAudioDatasetSiameseSrc", "(", "cfg", ",", "data_name", ",", "train", ")", "\n", "", "", "else", ":", "\n", "#dataset = ImageAudioDatasetSrcGS(rcfg, data_name, train)", "\n", "            ", "raise", "ValueError", "(", "f\"unrecognized dataset `{data_name}`.\"", ")", "\n", "", "", "elif", "data_name", ".", "startswith", "(", "\"npz\"", ")", ":", "\n", "        ", "if", "not", "from_gs", ":", "\n", "            ", "dataset", "=", "ImageAudioDatasetNpz", "(", "rcfg", ",", "data_name", ",", "train", ")", "\n", "", "else", ":", "\n", "#dataset = ImageAudioDatasetNpzGS(rcfg, data_name, train)", "\n", "            ", "raise", "ValueError", "(", "f\"unrecognized dataset `{data_name}`.\"", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognized dataset `{data_name}`.\"", ")", "\n", "", "if", "ddp_mode", ":", "\n", "        ", "assert", "cfg", ".", "optimizer", ".", "batch_size", "%", "cfg", ".", "num_gpus", "==", "0", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "dataset", ",", "shuffle", "=", "shuffle", "\n", ")", "\n", "per_device_batch_size", "=", "cfg", ".", "optimizer", ".", "batch_size", "//", "cfg", ".", "num_gpus", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "(", "\n", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "dataset", ")", "if", "shuffle", "else", "\n", "torch", ".", "utils", ".", "data", ".", "SequentialSampler", "(", "dataset", ")", "\n", ")", "\n", "per_device_batch_size", "=", "cfg", ".", "optimizer", ".", "batch_size", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "per_device_batch_size", ",", "\n", "collate_fn", "=", "ImageAudioCollator", "(", ")", ",", "\n", "num_workers", "=", "(", "0", "if", "ddp_mode", "else", "cfg", ".", "num_proc", ")", ",", "\n", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "drop_last", "=", "(", "True", "if", "ddp_mode", "else", "False", ")", ",", "\n", ")", "\n", "return", "sampler", ",", "dataloader", "\n", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc.__init__": [[36, 76], ["os.path.isfile", "len", "numpy.zeros", "list", "len", "getattr", "image.make_clip_image_transform", "audio.make_transform", "open", "enumerate", "int", "numpy.random.permutation", "json.loads", "clip.tokenize", "audiocaps.AudioCapDatasetSrc.dataset.append", "numpy.random.permutation", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.make_clip_image_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_name", ",", "train", ",", "label_map", ")", ":", "\n", "        ", "data_path", "=", "f\"{cfg.data_root}/{data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "self", ".", "label_map", "=", "label_map", "\n", "self", ".", "num_label", "=", "len", "(", "label_map", ")", "\n", "label_counts", "=", "np", ".", "zeros", "(", "self", ".", "num_label", ")", "\n", "self", ".", "dataset", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "record", "[", "\"captions_bpe\"", "]", "=", "tokenize", "(", "\n", "record", "[", "\"captions\"", "]", ",", "as_list", "=", "True", "\n", ")", "# add bpe captions", "\n", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                    ", "break", "\n", "", "", "", "if", "train", "and", "cfg", ".", "train_samples", ">", "0.", "and", "cfg", ".", "train_samples", "<", "1.", ":", "\n", "            ", "k", "=", "int", "(", "len", "(", "self", ".", "dataset", ")", "*", "cfg", ".", "train_samples", ")", "\n", "#self.dataset = np.random.choice(self.dataset, k, replace=False)", "\n", "shuffled_indice", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "self", ".", "dataset", "=", "[", "self", ".", "dataset", "[", "i", "]", "for", "i", "in", "shuffled_indice", "[", ":", "k", "]", "]", "\n", "", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "self", ".", "audio_norms", "=", "cfg", ".", "audio", ".", "norms", "\n", "self", ".", "aclip_key", "=", "\"clip\"", "if", "\"clip\"", "in", "self", ".", "dataset", "[", "0", "]", "else", "\"aclip\"", "\n", "self", ".", "frame_key", "=", "cfg", ".", "frame_key", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "rnd_cap", "=", "getattr", "(", "cfg", ",", "\"rnd_cap\"", ",", "False", ")", "# random AL fine-tuning baseline", "\n", "\n", "acfg", "=", "cfg", ".", "audio", "\n", "self", ".", "transform_image", "=", "make_image_transform", "(", "cfg", ".", "resolution", ")", "\n", "self", ".", "transform_audio", ",", "self", ".", "transform_fbank", "=", "make_transform", "(", "acfg", ")", "\n", "self", ".", "kaldi_params", "=", "{", "\n", "\"htk_compat\"", ":", "True", ",", "\n", "\"use_energy\"", ":", "False", ",", "\n", "\"window_type\"", ":", "'hanning'", ",", "\n", "\"num_mel_bins\"", ":", "acfg", ".", "num_mel_bins", ",", "\n", "\"dither\"", ":", "0.0", ",", "\n", "\"frame_shift\"", ":", "10", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc._shuffle": [[78, 80], ["None"], "methods", ["None"], ["", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc._process_item": [[81, 116], ["isinstance", "len", "numpy.random.randint", "numpy.random.choice", "len", "numpy.random.choice", "int", "len", "numpy.ceil", "images[].rsplit", "len"], "methods", ["None"], ["", "def", "_process_item", "(", "self", ",", "index", ")", ":", "\n", "        ", "akey", "=", "self", ".", "aclip_key", "\n", "fkey", "=", "self", ".", "frame_key", "\n", "sub_dir", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"dir\"", "]", "\n", "name", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"id\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "akey", "]", "[", "0", "]", "\n", "frame", "=", "images", "=", "self", ".", "dataset", "[", "index", "]", "[", "fkey", "]", "\n", "categories", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"labels\"", "]", "\n", "\n", "sub_dir", "=", "\"\"", "if", "len", "(", "sub_dir", ")", "==", "0", "else", "f\"{sub_dir}/\"", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{akey}/{name}.{aclip}\"", "\n", "\n", "frame_file", "=", "frame_emb_file", "=", "None", "\n", "if", "self", ".", "cfg", ".", "imagine", ":", "\n", "            ", "if", "isinstance", "(", "frame", ",", "str", ")", ":", "\n", "                ", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{frame}\"", "\n", "", "else", ":", "\n", "                ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{images[idx]}\"", "\n", "if", "self", ".", "cfg", ".", "frame_emb", "is", "not", "None", ":", "\n", "                    ", "frame_emb_file", "=", "f\"{self.cfg.data_root}/{self.cfg.frame_emb}/{name}.{images[idx].rsplit('.', 1)[0]}.npz\"", "\n", "\n", "", "", "", "label", "=", "[", "0", "]", "\n", "captions_bpe", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"captions_bpe\"", "]", "\n", "if", "self", ".", "train", ":", "\n", "            ", "if", "self", ".", "rnd_cap", ":", "# random baseline", "\n", "                ", "rnd_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "length", ")", "\n", "captions_bpe", "=", "self", ".", "dataset", "[", "rnd_idx", "]", "[", "\"captions_bpe\"", "]", "\n", "", "icp", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "captions_bpe", ")", ",", "1", ")", "[", "0", "]", "\n", "text_bpe", "=", "captions_bpe", "[", "icp", "]", "\n", "", "else", ":", "\n", "            ", "text_bpe", "=", "captions_bpe", "\n", "\n", "", "item", "=", "{", "\"text\"", ":", "text_bpe", ",", "\"name\"", ":", "name", "}", "\n", "return", "item", ",", "label", ",", "aclip_file", ",", "frame_file", ",", "frame_emb_file", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc._image2embed": [[117, 124], ["numpy.load", "numpy.random.rand().astype", "warnings.warn", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2embed", "(", "self", ",", "fname", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "image", "=", "np", ".", "load", "(", "fname", ")", "[", "\"v\"", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "image", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "cfg", ".", "embed_dim", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc._image2numpy": [[125, 146], ["numpy.array", "fname.endswith", "numpy.load", "PIL.Image.open", "audiocaps.AudioCapDatasetSrc.transform_image().cpu().numpy", "PIL.Image.fromarray", "warnings.warn", "audiocaps.AudioCapDatasetSrc.transform_image().cpu().numpy", "numpy.random.choice", "int", "audiocaps.AudioCapDatasetSrc.transform_image().cpu", "audiocaps.AudioCapDatasetSrc.transform_image().cpu", "len", "len", "numpy.ceil", "audiocaps.AudioCapDatasetSrc.transform_image", "numpy.random.rand", "audiocaps.AudioCapDatasetSrc.transform_image", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2numpy", "(", "self", ",", "fname", ")", ":", "\n", "        ", "if", "fname", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "fname", ".", "endswith", "(", "\".npz\"", ")", ":", "\n", "                    ", "images", "=", "np", ".", "load", "(", "fname", ")", "\n", "images", "=", "[", "images", "[", "key", "]", "for", "key", "in", "images", ".", "files", "if", "len", "(", "images", "[", "key", "]", ")", "!=", "0", "]", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "image", "=", "images", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "image", "=", "PILImage", ".", "open", "(", "fname", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "h", "=", "w", "=", "self", ".", "cfg", ".", "resolution", "\n", "image", "=", "PILImage", ".", "fromarray", "(", "\n", "(", "np", ".", "random", ".", "rand", "(", "h", ",", "w", ",", "3", ")", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "image", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc._audio2numpy_clf": [[147, 188], ["torchaudio.load", "torchaudio.compliance.kaldi.fbank", "wf.mean", "sampler.randint", "audiocaps.AudioCapDatasetSrc._process_item", "torchaudio.load", "numpy.random.beta", "label.tolist.tolist.tolist", "torch.pad", "torch.pad", "torch.pad", "sampler.random", "torch.pad.mean", "torch.pad", "torch.pad", "torch.pad", "wf_mixed.mean", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_audio2numpy_clf", "(", "self", ",", "aclip_file", ",", "label", ")", ":", "\n", "        ", "wf", ",", "sr", "=", "torchaudio", ".", "load", "(", "aclip_file", ")", "\n", "wf", "=", "wf", "[", ":", "1", "]", "#wf.mean(0, keepdim=True)", "\n", "wf", "=", "wf", "-", "wf", ".", "mean", "(", ")", "\n", "\n", "sampler", "=", "np", ".", "random", "if", "self", ".", "cfg", ".", "np_rnd", "else", "random", "\n", "\n", "#if self.train and sampler.random() < self.cfg.mixup_rate:", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "sampler", ".", "random", "(", ")", "<", "self", ".", "cfg", ".", "mixup_rate", ":", "\n", "            ", "idx_mix", "=", "sampler", ".", "randint", "(", "0", ",", "self", ".", "length", "if", "self", ".", "cfg", ".", "np_rnd", "else", "self", ".", "length", "-", "1", ")", "\n", "_", ",", "label_mix", ",", "aclip_file", ",", "_", ",", "_", "=", "self", ".", "_process_item", "(", "idx_mix", ")", "\n", "wf_mix", ",", "_", "=", "torchaudio", ".", "load", "(", "aclip_file", ")", "\n", "wf_mix", "=", "wf_mix", "[", ":", "1", "]", "#wf_mix.mean(0, keepdim=True)", "\n", "wf_mix", "=", "wf_mix", "-", "wf_mix", ".", "mean", "(", ")", "\n", "\n", "wf_len", "=", "wf", ".", "shape", "[", "1", "]", "\n", "wf_mix", "=", "wf_mix", "[", ":", ",", ":", "wf_len", "]", "\n", "npad", "=", "wf_len", "-", "wf_mix", ".", "shape", "[", "1", "]", "\n", "if", "npad", ">", "0", ":", "\n", "                ", "wf_mix", "=", "F", ".", "pad", "(", "wf_mix", ",", "(", "0", ",", "npad", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0.", ")", "\n", "\n", "", "lambd", "=", "np", ".", "random", ".", "beta", "(", "10", ",", "10", ")", "# sample lambda from beta distribtion", "\n", "wf_mixed", "=", "lambd", "*", "wf", "+", "(", "1", "-", "lambd", ")", "*", "wf_mix", "\n", "wf_mixed", "=", "wf_mixed", "-", "wf_mixed", ".", "mean", "(", ")", "\n", "wf", "=", "wf_mixed", "\n", "\n", "label", "=", "lambd", "*", "np", ".", "array", "(", "label", ")", "+", "(", "1", "-", "lambd", ")", "*", "np", ".", "array", "(", "label_mix", ")", "\n", "label", "=", "label", ".", "tolist", "(", ")", "\n", "\n", "", "audio", "=", "torchaudio", ".", "compliance", ".", "kaldi", ".", "fbank", "(", "\n", "wf", ",", "\n", "sample_frequency", "=", "sr", ",", "\n", "**", "self", ".", "kaldi_params", "\n", ")", "\n", "\n", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "audio", "[", ":", "max_audio_len", "]", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "F", ".", "pad", "(", "audio", ",", "(", "0", ",", "0", ",", "0", ",", "npad", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0.", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc._audio2numpy_cst": [[189, 206], ["np.pad._extract_kaldi_spectrogram", "numpy.pad"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform._extract_kaldi_spectrogram"], ["", "def", "_audio2numpy_cst", "(", "self", ",", "aclip_file", ")", ":", "\n", "        ", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "_extract_kaldi_spectrogram", "(", "\n", "aclip_file", ",", "\n", "self", ".", "kaldi_params", ",", "\n", "train", "=", "self", ".", "train", ",", "\n", "max_audio_len", "=", "max_audio_len", ",", "\n", "zero_mean_wf", "=", "self", ".", "cfg", ".", "audio", ".", "zero_mean_wf", ",", "\n", "transform_audio", "=", "(", "\n", "self", ".", "transform_audio", "if", "self", ".", "train", "and", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "else", "None", "\n", ")", "\n", ")", "# (..., time, freq)", "\n", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc.__getitem__": [[207, 230], ["audiocaps.AudioCapDatasetSrc._process_item", "item.update", "audiocaps.AudioCapDatasetSrc._image2embed", "audiocaps.AudioCapDatasetSrc._image2numpy", "audiocaps.AudioCapDatasetSrc._audio2numpy_clf", "audiocaps.AudioCapDatasetSrc._audio2numpy_cst", "audiocaps.AudioCapDatasetSrc.transform_fbank", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2embed", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2numpy", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_clf", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_cst"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", ",", "label", ",", "aclip_file", ",", "frame_file", ",", "frame_emb_file", "=", "self", ".", "_process_item", "(", "index", ")", "\n", "\n", "# higher priority for pre-computed frame embeddings", "\n", "image", "=", "(", "self", ".", "_image2embed", "(", "frame_emb_file", ")", "\n", "if", "frame_emb_file", "is", "not", "None", "and", "self", ".", "cfg", ".", "imagine", "else", "self", ".", "_image2numpy", "(", "frame_file", ")", "\n", ")", "\n", "audio", "=", "(", "self", ".", "_audio2numpy_clf", "(", "aclip_file", ",", "label", ")", "\n", "if", "self", ".", "cfg", ".", "clf", "else", "self", ".", "_audio2numpy_cst", "(", "aclip_file", ")", "\n", ")", "\n", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "len", "(", "self", ".", "audio_norms", ")", "==", "2", ":", "\n", "            ", "mean", ",", "std", "=", "self", ".", "audio_norms", "\n", "audio", "=", "(", "audio", "-", "mean", ")", "/", "std", "\n", "\n", "#if self.train and self.transform_fbank is not None:", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "\n", "", "image", "=", "image", "[", "None", "]", "\n", "audio", "=", "audio", "[", "None", "]", "\n", "item", ".", "update", "(", "{", "\"image\"", ":", "image", ",", "\"audio\"", ":", "audio", ",", "\"label\"", ":", "label", "}", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audiocaps.AudioCapDatasetSrc.__len__": [[231, 233], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.ImageTextDatasetSrc.__init__": [[32, 36], ["audio_text.AudioTextDatasetSrc.__init__", "image.make_clip_image_transform"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.make_clip_image_transform"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_list", ",", "train", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "data_list", ",", "train", ")", "\n", "self", ".", "frame_key", "=", "cfg", ".", "frame_key", "\n", "self", ".", "transform_image", "=", "make_image_transform", "(", "cfg", ".", "resolution", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.ImageTextDatasetSrc._image2embed": [[37, 44], ["numpy.load", "numpy.random.rand().astype", "warnings.warn", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2embed", "(", "self", ",", "fname", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "image", "=", "np", ".", "load", "(", "fname", ")", "[", "\"v\"", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "image", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "cfg", ".", "embed_dim", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.ImageTextDatasetSrc._image2numpy": [[45, 66], ["numpy.array", "fname.endswith", "numpy.load", "PIL.Image.open", "image_text.ImageTextDatasetSrc.transform_image().cpu().numpy", "PIL.Image.fromarray", "warnings.warn", "image_text.ImageTextDatasetSrc.transform_image().cpu().numpy", "numpy.random.choice", "int", "image_text.ImageTextDatasetSrc.transform_image().cpu", "image_text.ImageTextDatasetSrc.transform_image().cpu", "len", "len", "numpy.ceil", "image_text.ImageTextDatasetSrc.transform_image", "numpy.random.rand", "image_text.ImageTextDatasetSrc.transform_image", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2numpy", "(", "self", ",", "fname", ")", ":", "\n", "        ", "if", "fname", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "fname", ".", "endswith", "(", "\".npz\"", ")", ":", "\n", "                    ", "images", "=", "np", ".", "load", "(", "fname", ")", "\n", "images", "=", "[", "images", "[", "key", "]", "for", "key", "in", "images", ".", "files", "if", "len", "(", "images", "[", "key", "]", ")", "!=", "0", "]", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "image", "=", "images", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "image", "=", "PILImage", ".", "open", "(", "fname", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "h", "=", "w", "=", "self", ".", "cfg", ".", "resolution", "\n", "image", "=", "PILImage", ".", "fromarray", "(", "\n", "(", "np", ".", "random", ".", "rand", "(", "h", ",", "w", ",", "3", ")", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "image", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.ImageTextDatasetSrc.__getitem__": [[67, 114], ["isinstance", "image_text.ImageTextDatasetSrc._audio2numpy_cst", "image_text.ImageTextDatasetSrc._image2embed", "image_text.ImageTextDatasetSrc._image2numpy", "image_text.ImageTextDatasetSrc.transform_fbank", "len", "len", "numpy.random.choice", "numpy.random.choice", "int", "len", "len", "numpy.ceil", "images[].rsplit", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_cst", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2embed", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2numpy"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "akey", "=", "self", ".", "aclip_key", "\n", "fkey", "=", "self", ".", "frame_key", "\n", "name", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"id\"", "]", "\n", "sub_dir", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"dir\"", "]", "\n", "label_str", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_str\"", "]", "\n", "label_int", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"label_int_bpe\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "akey", "]", "[", "0", "]", "\n", "frame", "=", "images", "=", "self", ".", "dataset", "[", "index", "]", "[", "fkey", "]", "\n", "\n", "sub_dir", "=", "\"\"", "if", "len", "(", "sub_dir", ")", "==", "0", "else", "f\"{sub_dir}/\"", "\n", "aclip", "=", "aclip", "if", "aclip", "==", "name", "else", "f\"{akey}/{name}.{aclip}\"", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{aclip}\"", "\n", "\n", "# image", "\n", "frame_emb_file", "=", "None", "\n", "if", "isinstance", "(", "frame", ",", "str", ")", ":", "\n", "            ", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{frame}\"", "\n", "", "else", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{images[idx]}\"", "\n", "if", "self", ".", "cfg", ".", "frame_emb", "is", "not", "None", ":", "\n", "                ", "frame_emb_file", "=", "f\"{self.cfg.data_root}/{self.cfg.frame_emb}/{name}.{images[idx].rsplit('.', 1)[0]}.npz\"", "\n", "# higher priority for pre-computed frame embeddings", "\n", "", "", "image", "=", "self", ".", "_image2embed", "(", "frame_emb_file", ")", "if", "frame_emb_file", "is", "not", "None", "else", "self", ".", "_image2numpy", "(", "frame_file", ")", "\n", "\n", "# audio", "\n", "audio", "=", "self", ".", "_audio2numpy_cst", "(", "aclip_file", ")", "\n", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "len", "(", "self", ".", "audio_norms", ")", "==", "2", ":", "\n", "            ", "mean", ",", "std", "=", "self", ".", "audio_norms", "\n", "audio", "=", "(", "audio", "-", "mean", ")", "/", "std", "\n", "\n", "#if self.train and self.transform_fbank is not None:", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "label_int", ")", ",", "1", ")", "[", "0", "]", "\n", "text", "=", "label_int", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "text", "=", "label_int", "\n", "\n", "", "audio", "=", "audio", "[", "None", "]", "\n", "image", "=", "image", "[", "None", "]", "\n", "item", "=", "{", "\"image\"", ":", "image", ",", "\"audio\"", ":", "audio", ",", "\"text\"", ":", "text", ",", "\"name\"", ":", "name", "}", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.ImageTextDatasetSrc.__len__": [[115, 117], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.ImageTextCollator.__init__": [[119, 123], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", ":", "\n", "# RuntimeError: cannot pin 'torch.cuda.FloatTensor' only dense CPU tensors can be pinned", "\n", "# when pin_memory is true, the collator has to return CPU tensors", "\n", "        ", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.ImageTextCollator.__call__": [[124, 150], ["isinstance", "isinstance", "numpy.array", "numpy.concatenate", "record.get", "set().union", "list", "ValueError", "list", "itertools.chain.from_iterable", "itertools.zip_longest", "set", "type"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "records", ")", ":", "\n", "        ", "union", "=", "{", "\n", "k", ":", "[", "record", ".", "get", "(", "k", ")", "for", "record", "in", "records", "]", "for", "k", "in", "set", "(", ")", ".", "union", "(", "*", "records", ")", "\n", "}", "\n", "name", "=", "union", "[", "\"name\"", "]", "\n", "text_list", "=", "union", "[", "\"text\"", "]", "\n", "if", "isinstance", "(", "text_list", "[", "0", "]", "[", "0", "]", ",", "int", ")", ":", "# train", "\n", "            ", "pass", "\n", "\"\"\" https://stackoverflow.com/a/43149308\n            lengths = [len(x) for x in text_list]\n            max_len = max(lengths)\n            text = np.zeros((len(text_list), max_len), int)\n            mask = np.arange(max_len) < np.array(lengths)[:, None]\n            text[mask] = np.concatenate(text_list)\n            \"\"\"", "\n", "", "elif", "isinstance", "(", "text_list", "[", "0", "]", "[", "0", "]", ",", "list", ")", ":", "# test", "\n", "            ", "text_list", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "text_list", ")", ")", "\n", "#name = list(itertools.chain.from_iterable(name))", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"unrecognized `{type(text_list[0][0])}`\"", ")", "\n", "# https://stackoverflow.com/a/38619333", "\n", "", "text", "=", "np", ".", "array", "(", "list", "(", "itertools", ".", "zip_longest", "(", "*", "text_list", ",", "fillvalue", "=", "0", ")", ")", ")", ".", "T", "\n", "return", "(", "\n", "np", ".", "concatenate", "(", "union", "[", "\"image\"", "]", ",", "axis", "=", "0", ")", ",", "\n", "text", ",", "\n", "name", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.build_dataloader_audiocaps": [[152, 159], ["data_name.split", "list", "audio_text.build_dataloader", "audio_text.build_audiocaps_data_list", "list.extend"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audio_text.build_audiocaps_data_list"], ["", "", "def", "build_dataloader_audiocaps", "(", "cfg", ",", "data_name", ",", "shuffle", "=", "True", ",", "train", "=", "True", ")", ":", "\n", "    ", "name_list", "=", "data_name", ".", "split", "(", "\",\"", ")", "\n", "dataset", "=", "list", "(", ")", "\n", "for", "name", "in", "name_list", ":", "\n", "        ", "subset", "=", "build_audiocaps_data_list", "(", "cfg", ".", "running", ",", "name", ")", "\n", "dataset", ".", "extend", "(", "subset", ")", "\n", "", "return", "build_dataloader", "(", "cfg", ",", "dataset", ",", "ImageTextDatasetSrc", ",", "shuffle", "=", "shuffle", ",", "train", "=", "train", ",", "collator_cls", "=", "ImageTextCollator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.build_image_text_dataloader": [[160, 167], ["data_name.startswith", "image_text.build_dataloader_audiocaps", "ValueError"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_text.build_dataloader_audiocaps"], ["", "def", "build_image_text_dataloader", "(", "cfg", ",", "data_name", ",", "*", "args", ",", "shuffle", "=", "True", ",", "train", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "data_name", ".", "startswith", "(", "\"audiocaps\"", ")", ":", "# can only do w/ AudioCaps", "\n", "        ", "return", "build_dataloader_audiocaps", "(", "\n", "cfg", ",", "data_name", ",", "shuffle", "=", "shuffle", ",", "train", "=", "train", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognized dataset `{data_name}`.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetNpz.__init__": [[63, 104], ["os.path.isfile", "len", "numpy.zeros", "list", "len", "image.make_clip_image_transform", "audio.make_transform", "open", "enumerate", "audioset_cls.print_label_dist", "numpy.zeros", "enumerate", "json.loads", "audioset_cls.AudiosetNpz.dataset.append", "re.sub().strip", "audioset_cls.AudiosetNpz._cat_label", "label_map.items", "re.sub"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.make_clip_image_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.print_label_dist", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._cat_label"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_name", ",", "train", ",", "label_map", ",", "weighted", ")", ":", "\n", "        ", "data_path", "=", "f\"{cfg.data_root}/{data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "label_map", "=", "label_map", "\n", "self", ".", "num_label", "=", "len", "(", "label_map", ")", "\n", "label_counts", "=", "np", ".", "zeros", "(", "self", ".", "num_label", ")", "\n", "self", ".", "dataset", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "cfg", ".", "cat_label", ":", "\n", "                    ", "self", ".", "_cat_label", "(", "record", ")", "\n", "", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                    ", "break", "\n", "", "if", "weighted", ":", "# save label distribution", "\n", "                    ", "for", "category", "in", "record", "[", "\"labels\"", "]", ":", "\n", "                        ", "label_counts", "[", "\n", "self", ".", "label_map", "[", "category", "]", "[", "0", "]", "\n", "]", "+=", "1", "\n", "", "", "", "", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "if", "weighted", ":", "# compute sample weight", "\n", "            ", "lid2label", "=", "{", "v", "[", "0", "]", ":", "re", ".", "sub", "(", "f\"^{cfg.prompt}\"", ",", "\"\"", ",", "v", "[", "1", "]", ")", ".", "strip", "(", ")", "for", "_", ",", "v", "in", "label_map", ".", "items", "(", ")", "}", "\n", "print_label_dist", "(", "cfg", ",", "print", ",", "label_counts", ",", "lid2label", ",", "ncol", "=", "18", ")", "\n", "self", ".", "sample_weights", "=", "np", ".", "zeros", "(", "self", ".", "length", ")", "\n", "label_counts", "=", "1000.0", "/", "(", "label_counts", "+", "1.", ")", "\n", "for", "i", ",", "record", "in", "enumerate", "(", "self", ".", "dataset", ")", ":", "\n", "                ", "for", "category", "in", "record", "[", "\"labels\"", "]", ":", "\n", "                    ", "self", ".", "sample_weights", "[", "i", "]", "+=", "label_counts", "[", "\n", "self", ".", "label_map", "[", "category", "]", "[", "0", "]", "\n", "]", "\n", "", "", "", "self", ".", "audio_norms", "=", "cfg", ".", "audio", ".", "norms", "\n", "# compatible with AudioSet and Balanced AudioSet", "\n", "self", ".", "aclip_key", "=", "\"aclip_128\"", "\n", "self", ".", "frame_key", "=", "\"frame_224\"", "\n", "self", ".", "train", "=", "train", "\n", "\n", "acfg", "=", "cfg", ".", "audio", "\n", "self", ".", "transform_image", "=", "make_image_transform", "(", "cfg", ".", "resolution", ")", "\n", "self", ".", "transform_audio", ",", "self", ".", "transform_fbank", "=", "make_transform", "(", "acfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetNpz._shuffle": [[105, 107], ["None"], "methods", ["None"], ["", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetNpz._cat_label": [[108, 117], ["clip.tokenize", "re.sub().strip", "re.sub"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize"], ["", "def", "_cat_label", "(", "self", ",", "record", ")", ":", "\n", "        ", "categories", "=", "record", "[", "\"labels\"", "]", "\n", "label_text", "=", "[", "re", ".", "sub", "(", "\n", "f\"^{self.cfg.prompt}\"", ",", "\"\"", ",", "self", ".", "label_map", "[", "category", "]", "[", "1", "]", "\n", ")", ".", "strip", "(", ")", "for", "category", "in", "categories", "]", "\n", "label_text", "=", "self", ".", "cfg", ".", "prompt", "+", "\" \"", "+", "\", \"", ".", "join", "(", "label_text", ")", "\n", "record", "[", "\"captions\"", "]", "=", "[", "label_text", "]", "\n", "record", "[", "\"captions_bpe\"", "]", "=", "tokenize", "(", "\n", "record", "[", "\"captions\"", "]", ",", "as_list", "=", "True", "\n", ")", "# add bpe captions", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetNpz._image2numpy": [[119, 136], ["numpy.array", "numpy.load", "PIL.Image.fromarray", "warnings.warn", "audioset_cls.AudiosetNpz.transform_image().cpu().numpy", "numpy.random.choice", "int", "len", "len", "numpy.ceil", "audioset_cls.AudiosetNpz.transform_image().cpu", "len", "numpy.random.rand", "audioset_cls.AudiosetNpz.transform_image"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2numpy", "(", "self", ",", "fname", ")", ":", "\n", "        ", "if", "fname", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "images", "=", "np", ".", "load", "(", "fname", ")", "\n", "images", "=", "[", "images", "[", "key", "]", "for", "key", "in", "images", ".", "files", "if", "len", "(", "images", "[", "key", "]", ")", "!=", "0", "]", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "image", "=", "images", "[", "idx", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "h", "=", "w", "=", "self", ".", "cfg", ".", "resolution", "\n", "image", "=", "PILImage", ".", "fromarray", "(", "\n", "(", "np", ".", "random", ".", "rand", "(", "h", ",", "w", ",", "3", ")", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "image", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetNpz._process_item": [[137, 165], ["set", "len", "range", "numpy.random.choice", "len"], "methods", ["None"], ["", "def", "_process_item", "(", "self", ",", "index", ")", ":", "\n", "        ", "akey", "=", "self", ".", "aclip_key", "\n", "fkey", "=", "self", ".", "frame_key", "\n", "sub_dir", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"dir\"", "]", "\n", "name", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"id\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "akey", "]", "\n", "frame", "=", "images", "=", "self", ".", "dataset", "[", "index", "]", "[", "fkey", "]", "\n", "categories", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"labels\"", "]", "\n", "\n", "sub_dir", "=", "\"\"", "if", "len", "(", "sub_dir", ")", "==", "0", "else", "f\"{sub_dir}/\"", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{akey}/{name}.{aclip}\"", "\n", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{frame}\"", "if", "self", ".", "cfg", ".", "imagine", "else", "None", "\n", "\n", "if", "not", "self", ".", "cfg", ".", "clf", ":", "# dummy", "\n", "            ", "if", "self", ".", "cfg", ".", "cat_label", ":", "\n", "                ", "record", "=", "self", ".", "dataset", "[", "index", "]", "\n", "label", ",", "text", ",", "text_int", "=", "0", ",", "record", "[", "\"captions\"", "]", "[", "0", "]", ",", "record", "[", "\"captions_bpe\"", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "ict", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "categories", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "0", "\n", "category", "=", "categories", "[", "ict", "]", "\n", "label", ",", "text", ",", "text_int", "=", "self", ".", "label_map", "[", "category", "]", "\n", "", "", "else", ":", "# classification task", "\n", "            ", "label_set", "=", "set", "(", "[", "self", ".", "label_map", "[", "category", "]", "[", "0", "]", "for", "category", "in", "categories", "]", ")", "\n", "label", "=", "[", "1", "if", "i", "in", "label_set", "else", "0", "for", "i", "in", "range", "(", "self", ".", "num_label", ")", "]", "\n", "text_int", "=", "[", "0", "]", "# TODO concatenate all text pieces", "\n", "\n", "", "item", "=", "{", "\"text\"", ":", "text_int", ",", "\"name\"", ":", "name", "}", "\n", "return", "item", ",", "label", ",", "aclip_file", ",", "frame_file", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetNpz.__getitem__": [[166, 189], ["audioset_cls.AudiosetNpz._process_item", "audioset_cls.AudiosetNpz._image2numpy", "item.update", "numpy.load", "numpy.pad", "audioset_cls.AudiosetNpz.transform_fbank", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2numpy", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", ",", "label", ",", "aclip_file", ",", "frame_file", "=", "self", ".", "_process_item", "(", "index", ")", "\n", "\n", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "np", ".", "load", "(", "aclip_file", ")", "[", "\"flag\"", "]", "# (..., time, freq): `flag' is used as the key accidentally", "\n", "image", "=", "self", ".", "_image2numpy", "(", "frame_file", ")", "\n", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "len", "(", "self", ".", "audio_norms", ")", "==", "2", ":", "\n", "            ", "mean", ",", "std", "=", "self", ".", "audio_norms", "\n", "audio", "=", "(", "audio", "-", "mean", ")", "/", "std", "\n", "\n", "#if self.train and self.transform_fbank is not None:", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "\n", "", "image", "=", "image", "[", "None", "]", "\n", "audio", "=", "audio", "[", "None", "]", "\n", "item", ".", "update", "(", "{", "\"image\"", ":", "image", ",", "\"audio\"", ":", "audio", ",", "\"label\"", ":", "label", "}", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetNpz.__len__": [[190, 192], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc.__init__": [[196, 248], ["os.path.isfile", "len", "numpy.zeros", "list", "len", "image.make_clip_image_transform", "audio.make_transform", "open", "enumerate", "audioset_cls.print_label_dist", "numpy.zeros", "enumerate", "json.loads", "audioset_cls.AudiosetSrc.dataset.append", "re.sub().strip", "audioset_cls.AudiosetSrc._add_text", "label_map.items", "audioset_cls.AudiosetSrc._cat_label", "re.sub"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.make_clip_image_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.print_label_dist", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._add_text", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._cat_label"], ["def", "__init__", "(", "self", ",", "cfg", ",", "data_name", ",", "train", ",", "label_map", ",", "weighted", ",", "filter_set", "=", "None", ",", "external_text", "=", "None", ")", ":", "\n", "        ", "data_path", "=", "f\"{cfg.data_root}/{data_name}.csv\"", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "data_path", ")", ",", "f\"{data_path} is not a file.\"", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "label_map", "=", "label_map", "\n", "self", ".", "num_label", "=", "len", "(", "label_map", ")", "\n", "label_counts", "=", "np", ".", "zeros", "(", "self", ".", "num_label", ")", "\n", "self", ".", "dataset", "=", "list", "(", ")", "\n", "with", "open", "(", "data_path", ",", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "iline", ",", "line", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "filter_set", "is", "not", "None", "and", "record", "[", "\"id\"", "]", "not", "in", "filter_set", ":", "\n", "                    ", "continue", "# let us skip this sample", "\n", "", "if", "external_text", "is", "not", "None", ":", "\n", "                    ", "self", ".", "_add_text", "(", "record", ",", "external_text", ")", "\n", "", "elif", "cfg", ".", "cat_label", ":", "\n", "                    ", "self", ".", "_cat_label", "(", "record", ")", "\n", "", "self", ".", "dataset", ".", "append", "(", "record", ")", "\n", "if", "not", "train", "and", "iline", "+", "1", "==", "cfg", ".", "eval_samples", ":", "\n", "                    ", "break", "\n", "", "if", "weighted", ":", "# save label distribution", "\n", "                    ", "for", "category", "in", "record", "[", "\"labels\"", "]", ":", "\n", "                        ", "label_counts", "[", "\n", "self", ".", "label_map", "[", "category", "]", "[", "0", "]", "\n", "]", "+=", "1", "\n", "", "", "", "", "self", ".", "length", "=", "len", "(", "self", ".", "dataset", ")", "\n", "if", "weighted", ":", "# compute sample weight", "\n", "            ", "lid2label", "=", "{", "v", "[", "0", "]", ":", "re", ".", "sub", "(", "f\"^{cfg.prompt}\"", ",", "\"\"", ",", "v", "[", "1", "]", ")", ".", "strip", "(", ")", "for", "_", ",", "v", "in", "label_map", ".", "items", "(", ")", "}", "\n", "print_label_dist", "(", "cfg", ",", "print", ",", "label_counts", ",", "lid2label", ",", "ncol", "=", "18", ")", "\n", "self", ".", "sample_weights", "=", "np", ".", "zeros", "(", "self", ".", "length", ")", "\n", "label_counts", "=", "1000.0", "/", "(", "label_counts", "+", "1.", ")", "\n", "for", "i", ",", "record", "in", "enumerate", "(", "self", ".", "dataset", ")", ":", "\n", "                ", "for", "category", "in", "record", "[", "\"labels\"", "]", ":", "\n", "                    ", "self", ".", "sample_weights", "[", "i", "]", "+=", "label_counts", "[", "\n", "self", ".", "label_map", "[", "category", "]", "[", "0", "]", "\n", "]", "\n", "", "", "", "self", ".", "audio_norms", "=", "cfg", ".", "audio", ".", "norms", "\n", "# compatible with AudioSet and Balanced AudioSet", "\n", "self", ".", "aclip_key", "=", "\"clip\"", "if", "\"clip\"", "in", "self", ".", "dataset", "[", "0", "]", "else", "\"aclip\"", "\n", "self", ".", "frame_key", "=", "cfg", ".", "frame_key", "\n", "self", ".", "train", "=", "train", "\n", "\n", "acfg", "=", "cfg", ".", "audio", "\n", "self", ".", "transform_image", "=", "make_image_transform", "(", "cfg", ".", "resolution", ")", "\n", "self", ".", "transform_audio", ",", "self", ".", "transform_fbank", "=", "make_transform", "(", "acfg", ")", "\n", "self", ".", "kaldi_params", "=", "{", "\n", "\"htk_compat\"", ":", "True", ",", "\n", "\"use_energy\"", ":", "False", ",", "\n", "\"window_type\"", ":", "'hanning'", ",", "\n", "\"num_mel_bins\"", ":", "acfg", ".", "num_mel_bins", ",", "\n", "\"dither\"", ":", "0.0", ",", "\n", "\"frame_shift\"", ":", "10", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._shuffle": [[250, 252], ["None"], "methods", ["None"], ["", "def", "_shuffle", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._add_text": [[253, 256], ["external_text.get"], "methods", ["None"], ["", "def", "_add_text", "(", "self", ",", "record", ",", "external_text", ")", ":", "\n", "        ", "record", "[", "\"captions\"", "]", "=", "external_text", ".", "get", "(", "\n", "record", "[", "\"id\"", "]", ",", "[", "-", "1", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._cat_label": [[258, 267], ["clip.tokenize", "re.sub().strip", "re.sub"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize"], ["", "def", "_cat_label", "(", "self", ",", "record", ")", ":", "\n", "        ", "categories", "=", "record", "[", "\"labels\"", "]", "\n", "label_text", "=", "[", "re", ".", "sub", "(", "\n", "f\"^{self.cfg.prompt}\"", ",", "\"\"", ",", "self", ".", "label_map", "[", "category", "]", "[", "1", "]", "\n", ")", ".", "strip", "(", ")", "for", "category", "in", "categories", "]", "\n", "label_text", "=", "self", ".", "cfg", ".", "prompt", "+", "\" \"", "+", "\", \"", ".", "join", "(", "label_text", ")", "\n", "record", "[", "\"captions\"", "]", "=", "[", "label_text", "]", "\n", "record", "[", "\"captions_bpe\"", "]", "=", "tokenize", "(", "\n", "record", "[", "\"captions\"", "]", ",", "as_list", "=", "True", "\n", ")", "# add bpe captions", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item": [[269, 311], ["isinstance", "set", "len", "range", "numpy.random.choice", "int", "numpy.random.choice", "len", "numpy.ceil", "len", "numpy.random.choice", "images[].rsplit", "len", "len"], "methods", ["None"], ["", "def", "_process_item", "(", "self", ",", "index", ")", ":", "\n", "        ", "akey", "=", "self", ".", "aclip_key", "\n", "fkey", "=", "self", ".", "frame_key", "\n", "sub_dir", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"dir\"", "]", "\n", "name", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"id\"", "]", "\n", "aclip", "=", "self", ".", "dataset", "[", "index", "]", "[", "akey", "]", "[", "0", "]", "\n", "frame", "=", "images", "=", "self", ".", "dataset", "[", "index", "]", "[", "fkey", "]", "\n", "categories", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"labels\"", "]", "\n", "\n", "sub_dir", "=", "\"\"", "if", "len", "(", "sub_dir", ")", "==", "0", "else", "f\"{sub_dir}/\"", "\n", "aclip_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{akey}/{name}.{aclip}\"", "\n", "\n", "frame_file", "=", "frame_emb_file", "=", "None", "\n", "if", "self", ".", "cfg", ".", "imagine", ":", "\n", "            ", "if", "isinstance", "(", "frame", ",", "str", ")", ":", "\n", "                ", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{frame}\"", "\n", "", "else", ":", "\n", "                ", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "frame_file", "=", "f\"{self.cfg.data_root}/{sub_dir}{fkey}/{name}.{images[idx]}\"", "\n", "if", "self", ".", "cfg", ".", "frame_emb", "is", "not", "None", ":", "\n", "                    ", "frame_emb_file", "=", "f\"{self.cfg.data_root}/{self.cfg.frame_emb}/{name}.{images[idx].rsplit('.', 1)[0]}.npz\"", "\n", "\n", "", "", "", "if", "not", "self", ".", "cfg", ".", "clf", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "text_emb", "is", "not", "None", ":", "\n", "                ", "caption_indice", "=", "self", ".", "dataset", "[", "index", "]", "[", "\"captions\"", "]", "# list of caption id", "\n", "ict", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "caption_indice", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "0", "\n", "label", ",", "text", ",", "text_int", "=", "0", ",", "\"\"", ",", "caption_indice", "[", "ict", "]", "\n", "text_int", "=", "f\"{self.cfg.data_root}/caption/{self.cfg.text_emb}/{text_int}.npz\"", "\n", "", "elif", "self", ".", "cfg", ".", "cat_label", ":", "\n", "                ", "record", "=", "self", ".", "dataset", "[", "index", "]", "\n", "label", ",", "text", ",", "text_int", "=", "0", ",", "record", "[", "\"captions\"", "]", "[", "0", "]", ",", "record", "[", "\"captions_bpe\"", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "ict", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "categories", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "0", "\n", "category", "=", "categories", "[", "ict", "]", "\n", "label", ",", "text", ",", "text_int", "=", "self", ".", "label_map", "[", "category", "]", "\n", "", "", "else", ":", "# classification task", "\n", "            ", "label_set", "=", "set", "(", "[", "self", ".", "label_map", "[", "category", "]", "[", "0", "]", "for", "category", "in", "categories", "]", ")", "\n", "label", "=", "[", "1", "if", "i", "in", "label_set", "else", "0", "for", "i", "in", "range", "(", "self", ".", "num_label", ")", "]", "\n", "text_int", "=", "[", "0", "]", "# TODO concatenate all text pieces", "\n", "\n", "", "item", "=", "{", "\"text\"", ":", "text_int", ",", "\"name\"", ":", "name", "}", "\n", "return", "item", ",", "label", ",", "aclip_file", ",", "frame_file", ",", "frame_emb_file", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc.blocking_io": [[312, 319], ["numpy.load", "numpy.random.rand().astype", "warnings.warn", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "blocking_io", "(", "self", ",", "fname", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "image", "=", "np", ".", "load", "(", "fname", ")", "[", "\"v\"", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "image", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "cfg", ".", "embed_dim", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._text2embed": [[332, 343], ["numpy.load", "numpy.random.rand().astype", "warnings.warn", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_text2embed", "(", "self", ",", "fname", ")", ":", "\n", "#print(self._text2embed.cache_info())", "\n", "# cache does not work in multi-thread model (e.g., worker > 0)", "\n", "# see https://discuss.pytorch.org/t/dataloader-re-initialize-dataset-after-each-iteration/32658", "\n", "# and https://discuss.pytorch.org/t/dataloader-resets-dataset-state/27960", "\n", "        ", "try", ":", "\n", "            ", "image", "=", "np", ".", "load", "(", "fname", ")", "[", "\"v\"", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "image", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "cfg", ".", "embed_dim", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2embed": [[344, 351], ["numpy.load", "numpy.random.rand().astype", "warnings.warn", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2embed", "(", "self", ",", "fname", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "image", "=", "np", ".", "load", "(", "fname", ")", "[", "\"v\"", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "image", "=", "np", ".", "random", ".", "rand", "(", "self", ".", "cfg", ".", "embed_dim", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2numpy": [[352, 373], ["numpy.array", "fname.endswith", "numpy.load", "PIL.Image.open", "audioset_cls.AudiosetSrc.transform_image().cpu().numpy", "PIL.Image.fromarray", "warnings.warn", "audioset_cls.AudiosetSrc.transform_image().cpu().numpy", "numpy.random.choice", "int", "audioset_cls.AudiosetSrc.transform_image().cpu", "audioset_cls.AudiosetSrc.transform_image().cpu", "len", "len", "numpy.ceil", "audioset_cls.AudiosetSrc.transform_image", "numpy.random.rand", "audioset_cls.AudiosetSrc.transform_image", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_image2numpy", "(", "self", ",", "fname", ")", ":", "\n", "        ", "if", "fname", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "fname", ".", "endswith", "(", "\".npz\"", ")", ":", "\n", "                    ", "images", "=", "np", ".", "load", "(", "fname", ")", "\n", "images", "=", "[", "images", "[", "key", "]", "for", "key", "in", "images", ".", "files", "if", "len", "(", "images", "[", "key", "]", ")", "!=", "0", "]", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "images", ")", ",", "1", ")", "[", "0", "]", "if", "self", ".", "train", "else", "int", "(", "np", ".", "ceil", "(", "len", "(", "images", ")", "/", "2", ")", ")", "-", "1", "\n", "image", "=", "images", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "image", "=", "PILImage", ".", "open", "(", "fname", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "h", "=", "w", "=", "self", ".", "cfg", ".", "resolution", "\n", "image", "=", "PILImage", ".", "fromarray", "(", "\n", "(", "np", ".", "random", ".", "rand", "(", "h", ",", "w", ",", "3", ")", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", ")", "\n", "warnings", ".", "warn", "(", "f\"use random image instead because `{e}` {fname}.\"", ")", "\n", "image", "=", "self", ".", "transform_image", "(", "image", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "image", "=", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_clf": [[374, 415], ["torchaudio.load", "torchaudio.compliance.kaldi.fbank", "wf.mean", "sampler.randint", "audioset_cls.AudiosetSrc._process_item", "torchaudio.load", "numpy.random.beta", "label.tolist.tolist.tolist", "torch.pad", "torch.pad", "torch.pad", "sampler.random", "torch.pad.mean", "torch.pad", "torch.pad", "torch.pad", "wf_mixed.mean", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], ["", "def", "_audio2numpy_clf", "(", "self", ",", "aclip_file", ",", "label", ")", ":", "\n", "        ", "wf", ",", "sr", "=", "torchaudio", ".", "load", "(", "aclip_file", ")", "\n", "wf", "=", "wf", "[", ":", "1", "]", "#wf.mean(0, keepdim=True)", "\n", "wf", "=", "wf", "-", "wf", ".", "mean", "(", ")", "\n", "\n", "sampler", "=", "np", ".", "random", "if", "self", ".", "cfg", ".", "np_rnd", "else", "random", "\n", "\n", "#if self.train and sampler.random() < self.cfg.mixup_rate:", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "sampler", ".", "random", "(", ")", "<", "self", ".", "cfg", ".", "mixup_rate", ":", "\n", "            ", "idx_mix", "=", "sampler", ".", "randint", "(", "0", ",", "self", ".", "length", "if", "self", ".", "cfg", ".", "np_rnd", "else", "self", ".", "length", "-", "1", ")", "\n", "_", ",", "label_mix", ",", "aclip_file", ",", "_", ",", "_", "=", "self", ".", "_process_item", "(", "idx_mix", ")", "\n", "wf_mix", ",", "_", "=", "torchaudio", ".", "load", "(", "aclip_file", ")", "\n", "wf_mix", "=", "wf_mix", "[", ":", "1", "]", "#wf_mix.mean(0, keepdim=True)", "\n", "wf_mix", "=", "wf_mix", "-", "wf_mix", ".", "mean", "(", ")", "\n", "\n", "wf_len", "=", "wf", ".", "shape", "[", "1", "]", "\n", "wf_mix", "=", "wf_mix", "[", ":", ",", ":", "wf_len", "]", "\n", "npad", "=", "wf_len", "-", "wf_mix", ".", "shape", "[", "1", "]", "\n", "if", "npad", ">", "0", ":", "\n", "                ", "wf_mix", "=", "F", ".", "pad", "(", "wf_mix", ",", "(", "0", ",", "npad", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0.", ")", "\n", "\n", "", "lambd", "=", "np", ".", "random", ".", "beta", "(", "10", ",", "10", ")", "# sample lambda from beta distribtion", "\n", "wf_mixed", "=", "lambd", "*", "wf", "+", "(", "1", "-", "lambd", ")", "*", "wf_mix", "\n", "wf_mixed", "=", "wf_mixed", "-", "wf_mixed", ".", "mean", "(", ")", "\n", "wf", "=", "wf_mixed", "\n", "\n", "label", "=", "lambd", "*", "np", ".", "array", "(", "label", ")", "+", "(", "1", "-", "lambd", ")", "*", "np", ".", "array", "(", "label_mix", ")", "\n", "label", "=", "label", ".", "tolist", "(", ")", "\n", "\n", "", "audio", "=", "torchaudio", ".", "compliance", ".", "kaldi", ".", "fbank", "(", "\n", "wf", ",", "\n", "sample_frequency", "=", "sr", ",", "\n", "**", "self", ".", "kaldi_params", "\n", ")", "\n", "\n", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "audio", "[", ":", "max_audio_len", "]", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "F", ".", "pad", "(", "audio", ",", "(", "0", ",", "0", ",", "0", ",", "npad", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0.", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_cst": [[416, 433], ["np.pad._extract_kaldi_spectrogram", "numpy.pad"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform._extract_kaldi_spectrogram"], ["", "def", "_audio2numpy_cst", "(", "self", ",", "aclip_file", ")", ":", "\n", "        ", "max_audio_len", "=", "self", ".", "cfg", ".", "max_audio_len", "\n", "audio", "=", "_extract_kaldi_spectrogram", "(", "\n", "aclip_file", ",", "\n", "self", ".", "kaldi_params", ",", "\n", "train", "=", "self", ".", "train", ",", "\n", "max_audio_len", "=", "max_audio_len", ",", "\n", "zero_mean_wf", "=", "self", ".", "cfg", ".", "audio", ".", "zero_mean_wf", ",", "\n", "transform_audio", "=", "(", "\n", "self", ".", "transform_audio", "if", "self", ".", "train", "and", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "else", "None", "\n", ")", "\n", ")", "# (..., time, freq)", "\n", "\n", "npad", "=", "max_audio_len", "-", "audio", ".", "shape", "[", "0", "]", "\n", "if", "npad", ">", "0", ":", "\n", "            ", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "npad", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"constant\"", ",", "constant_values", "=", "(", "0.", ",", "0.", ")", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc.__getitem__": [[434, 463], ["audioset_cls.AudiosetSrc._process_item", "item.update", "isinstance", "text.endswith", "audioset_cls.AudiosetSrc._image2embed", "audioset_cls.AudiosetSrc._image2numpy", "audioset_cls.AudiosetSrc._audio2numpy_clf", "audioset_cls.AudiosetSrc._audio2numpy_cst", "audioset_cls.AudiosetSrc.transform_fbank", "audioset_cls.AudiosetSrc._text2embed", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._process_item", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2embed", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._image2numpy", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_clf", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._audio2numpy_cst", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc._text2embed"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", ",", "label", ",", "aclip_file", ",", "frame_file", ",", "frame_emb_file", "=", "self", ".", "_process_item", "(", "index", ")", "\n", "\n", "text", "=", "item", "[", "\"text\"", "]", "# pre-computed text embeddings", "\n", "if", "isinstance", "(", "text", ",", "str", ")", "and", "text", ".", "endswith", "(", "\"npz\"", ")", ":", "\n", "#item[\"text\"] = asyncio.get_event_loop().run_until_complete(self._async_text2embed(text))[None]", "\n", "#item[\"text\"] = asyncio.run(self._async_text2embed(text))[None]", "\n", "            ", "item", "[", "\"text\"", "]", "=", "self", ".", "_text2embed", "(", "text", ")", "[", "None", "]", "\n", "\n", "# higher priority for pre-computed frame embeddings", "\n", "", "image", "=", "(", "self", ".", "_image2embed", "(", "frame_emb_file", ")", "\n", "if", "frame_emb_file", "is", "not", "None", "and", "self", ".", "cfg", ".", "imagine", "else", "self", ".", "_image2numpy", "(", "frame_file", ")", "\n", ")", "\n", "audio", "=", "(", "self", ".", "_audio2numpy_clf", "(", "aclip_file", ",", "label", ")", "\n", "if", "self", ".", "cfg", ".", "clf", "else", "self", ".", "_audio2numpy_cst", "(", "aclip_file", ")", "\n", ")", "\n", "\n", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "len", "(", "self", ".", "audio_norms", ")", "==", "2", ":", "\n", "            ", "mean", ",", "std", "=", "self", ".", "audio_norms", "\n", "audio", "=", "(", "audio", "-", "mean", ")", "/", "std", "\n", "\n", "#if self.train and self.transform_fbank is not None:", "\n", "", "if", "not", "self", ".", "cfg", ".", "audio", ".", "eval_norms", "and", "self", ".", "train", "and", "self", ".", "transform_fbank", "is", "not", "None", ":", "\n", "            ", "audio", "=", "self", ".", "transform_fbank", "(", "audio", ")", "\n", "\n", "", "image", "=", "image", "[", "None", "]", "\n", "audio", "=", "audio", "[", "None", "]", "\n", "item", ".", "update", "(", "{", "\"image\"", ":", "image", ",", "\"audio\"", ":", "audio", ",", "\"label\"", ":", "label", "}", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.AudiosetSrc.__len__": [[464, 466], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.print_label_dist": [[39, 59], ["list", "sum", "itertools.zip_longest.extend", "itertools.zip_longest", "tabulate.tabulate", "termcolor.colored", "echo", "itertools.chain", "len", "len", "len", "range", "audioset_cls.print_label_dist.short_name"], "function", ["None"], ["def", "print_label_dist", "(", "cfg", ",", "echo", ",", "label_counts", ",", "label_map", ",", "ncol", "=", "30", ")", ":", "\n", "    ", "def", "short_name", "(", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ")", ">", "15", ":", "\n", "            ", "return", "x", "[", ":", "13", "]", "+", "\"..\"", "\n", "", "return", "x", "\n", "", "data", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "\n", "[", "short_name", "(", "label_map", "[", "i", "]", ")", ",", "int", "(", "v", ")", "]", "for", "i", ",", "v", "in", "enumerate", "(", "label_counts", ")", "\n", "]", ")", ")", "\n", "total_num_instances", "=", "sum", "(", "data", "[", "1", ":", ":", "2", "]", ")", "\n", "data", ".", "extend", "(", "[", "None", "]", "*", "(", "ncol", "-", "(", "len", "(", "data", ")", "%", "ncol", ")", ")", ")", "\n", "data", "=", "itertools", ".", "zip_longest", "(", "*", "[", "data", "[", "i", ":", ":", "ncol", "]", "for", "i", "in", "range", "(", "ncol", ")", "]", ")", "\n", "table", "=", "tabulate", "(", "\n", "data", ",", "\n", "headers", "=", "[", "\"category\"", ",", "\"#\"", "]", "*", "(", "ncol", "//", "2", ")", ",", "\n", "tablefmt", "=", "\"pipe\"", ",", "\n", "numalign", "=", "\"right\"", ",", "\n", "stralign", "=", "\"center\"", ",", "\n", ")", "\n", "msg", "=", "colored", "(", "table", ",", "\"cyan\"", ")", "\n", "echo", "(", "f\"Distribution of instances among all {len(label_map)} categories:\\n{msg}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.AudiosetDatasetNpz.__init__": [[30, 64], ["os.path.isfile", "len", "numpy.zeros", "list", "len", "audio.make_transform", "open", "enumerate", "audioset_cls.print_label_dist", "numpy.zeros", "enumerate", "json.loads", "audioset_clf.AudiosetDatasetNpz.dataset.append", "re.sub().strip", "label_map.items", "re.sub"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_cls.print_label_dist"], ["        ", "super", "(", "ASClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n", "", "def", "forward", "(", "self", ",", "images", ",", "audios", ",", "labels", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "if", "self", ".", "image_head", "is", "not", "None", "and", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "!=", "[", "1", ",", "1", ",", "1", "]", ":", "\n", "            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "else", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "\n", "\n", "", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "audio_features", ",", "labels", ",", "x3", "=", "image_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n", "", "def", "encode_image", "(", "self", ",", "images", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "image_features", "\n", "\n", "", "def", "encode_audio", "(", "self", ",", "audios", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "audio_features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.AudiosetDatasetNpz._shuffle": [[65, 67], ["None"], "methods", ["None"], ["", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.AudiosetDatasetNpz.__getitem__": [[68, 118], ["numpy.load", "len", "numpy.load", "audioset_clf.AudiosetDatasetNpz.transform_fbank", "numpy.pad", "set", "len", "numpy.random.choice", "numpy.random.choice", "int", "numpy.max", "len", "len", "len", "len", "numpy.ceil", "numpy.abs", "range", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load"], [")", "\n", "return", "text_features", "\n", "\n", "", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "stats", "(", "**", "kwargs", ")", "if", "hasattr", "(", "self", ".", "loss_head", ",", "\"stats\"", ")", "else", "\"\"", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n", "", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "self", ".", "cfg", ".", "running", ".", "imagine", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "audio_head_sd", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `image_head`.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "try", ":", "\n", "                ", "self", ".", "loss_head", ".", "load_state_dict", "(", "loss_head_sd", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "self", ".", "echo", "(", "f\"Failed to load `loss_head` (expected in zero-shot mode) because: {e}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.AudiosetDatasetNpz.__len__": [[119, 121], ["None"], "methods", ["None"], ["", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.ImageAudioCollator.__init__": [[123, 127], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "model", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.ImageAudioCollator.__call__": [[128, 152], ["isinstance", "numpy.concatenate", "isinstance", "numpy.concatenate", "numpy.concatenate", "record.get", "set().union", "numpy.array", "isinstance", "numpy.array", "list", "ValueError", "list", "set", "itertools.chain.from_iterable", "itertools.zip_longest", "type"], "methods", ["None"], ["self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", "and", "image_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "running", ".", "imagine", "or", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "# TODO better to use `from_pretrained()`", "\n", "                    ", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.build_audioset_clf_dataloader": [[154, 195], ["torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "data_name.startswith", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_name.startswith", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "audioset_cls.AudiosetSrc", "audioset_cls.AudiosetNpz", "audioset_clf.AudiosetDatasetNpz", "audioset_cls.AudiosetSrc", "torch.utils.data.WeightedRandomSampler", "torch.utils.data.WeightedRandomSampler", "torch.utils.data.WeightedRandomSampler", "audioset_clf.ImageAudioCollator", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "torch.utils.data.SequentialSampler", "len"], "function", ["None"], ["", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze image encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "                ", "excl_modules", "=", "set", "(", "self", ".", "cfg", ".", "running", ".", "excl_modules", ".", "amodules", ")", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "excl_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out excluded parameters", "\n", "self", ".", "echo", "(", "f\"Tune audio encoder (excl. {excl_modules}).\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.ToTensorKeepdim.__call__": [[62, 67], ["isinstance", "super().__call__", "super().__call__.squeeze_"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.BarlowImageTransform.__call__"], ["    ", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "super", "(", "ToTensorKeepdim", ",", "self", ")", ".", "__call__", "(", "x", "[", "...", ",", "None", "]", ")", "\n", "return", "x", ".", "squeeze_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.AbstractTransform.__call__": [[69, 72], ["None"], "methods", ["None"], ["    ", "@", "abc", ".", "abstractmethod", "\n", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "pass", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.AbstractTransform.__repr__": [[72, 74], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomFlip.__init__": [[76, 79], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "RandomFlip", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomFlip.random_flip": [[80, 89], ["x.flip.flip.dim", "x[].flip", "torch.rand", "torch.rand", "x.flip.flip.flip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_flip", "(", "x", ",", "p", ")", ":", "\n", "        ", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "flip_mask", "=", "torch", ".", "rand", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ")", "<=", "p", "\n", "x", "[", "flip_mask", "]", "=", "x", "[", "flip_mask", "]", ".", "flip", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "if", "torch", ".", "rand", "(", "1", ")", "<=", "p", ":", "\n", "                ", "x", "=", "x", ".", "flip", "(", "-", "1", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomFlip.__call__": [[90, 92], ["transform.RandomFlip.random_flip"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomFlip.random_flip"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_flip", "(", "x", ",", "self", ".", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomScale.__init__": [[94, 98], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.5", ",", "keep_len", "=", "False", ")", ":", "\n", "        ", "super", "(", "RandomScale", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "keep_len", "=", "keep_len", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomScale.random_scale": [[99, 112], ["numpy.power", "int", "torch.arange().div_", "torch.arange().div_.clone().type", "torch.min", "numpy.random.uniform", "torch.full_like", "torch.arange().div_.clone().type.type", "transform.RandomCrop.random_crop", "torch.arange", "torch.arange().div_.clone", "torch.arange().div_.type"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomCrop.random_crop"], ["", "@", "staticmethod", "\n", "def", "random_scale", "(", "x", ",", "scale", ",", "keep_len", ")", ":", "\n", "        ", "scaling", "=", "np", ".", "power", "(", "scale", ",", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ")", ")", "\n", "output_len", "=", "int", "(", "x", ".", "shape", "[", "-", "1", "]", "*", "scaling", ")", "\n", "base", "=", "torch", ".", "arange", "(", "output_len", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "div_", "(", "scaling", ")", "\n", "\n", "ref1", "=", "base", ".", "clone", "(", ")", ".", "type", "(", "torch", ".", "int64", ")", "\n", "ref2", "=", "torch", ".", "min", "(", "ref1", "+", "1", ",", "torch", ".", "full_like", "(", "ref1", ",", "x", ".", "shape", "[", "-", "1", "]", "-", "1", ",", "dtype", "=", "torch", ".", "int64", ")", ")", "\n", "r", "=", "base", "-", "ref1", ".", "type", "(", "base", ".", "type", "(", ")", ")", "\n", "scaled_x", "=", "(", "1", "-", "r", ")", "*", "x", "[", "...", ",", "ref1", "]", "+", "r", "*", "x", "[", "...", ",", "ref2", "]", "\n", "if", "keep_len", ":", "\n", "            ", "scaled_x", "=", "RandomCrop", ".", "random_crop", "(", "scaled_x", ",", "x", ".", "shape", "[", "-", "1", "]", ",", "True", ")", "# keep the same length", "\n", "", "return", "scaled_x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomScale.__call__": [[113, 115], ["transform.RandomScale.random_scale"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomScale.random_scale"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_scale", "(", "x", ",", "self", ".", "scale", ",", "self", ".", "keep_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomCrop.__init__": [[117, 121], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_len", "=", "44100", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", "RandomCrop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_len", "=", "output_len", "\n", "self", ".", "train", "=", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomCrop.random_crop": [[122, 142], ["cropped_x.float().std", "cropped_x.float().std", "numpy.random.randint", "int", "x.float().std", "round", "cropped_x.float", "cropped_x.float", "x.float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_crop", "(", "x", ",", "output_len", ",", "train", ")", ":", "\n", "        ", "if", "x", ".", "shape", "[", "-", "1", "]", "<=", "output_len", ":", "\n", "            ", "return", "x", "\n", "", "if", "train", ":", "\n", "            ", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "x", ".", "shape", "[", "-", "1", "]", "-", "output_len", ")", "\n", "", "else", ":", "# center", "\n", "            ", "left", "=", "int", "(", "round", "(", "0.5", "*", "(", "x", ".", "shape", "[", "-", "1", "]", "-", "output_len", ")", ")", ")", "\n", "\n", "", "old_std", "=", "x", ".", "float", "(", ")", ".", "std", "(", ")", "*", "0.5", "\n", "cropped_x", "=", "x", "[", "...", ",", "left", ":", "left", "+", "output_len", "]", "\n", "\n", "new_std", "=", "cropped_x", ".", "float", "(", ")", ".", "std", "(", ")", "\n", "if", "new_std", "<", "old_std", ":", "\n", "            ", "cropped_x", "=", "x", "[", "...", ",", ":", "output_len", "]", "\n", "\n", "", "out_std", "=", "cropped_x", ".", "float", "(", ")", ".", "std", "(", ")", "\n", "if", "old_std", ">", "new_std", ">", "out_std", ":", "\n", "            ", "cropped_x", "=", "x", "[", "...", ",", "-", "output_len", ":", "]", "\n", "", "return", "cropped_x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomCrop.__call__": [[143, 145], ["transform.RandomCrop.random_crop"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomCrop.random_crop"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_crop", "(", "x", ",", "self", ".", "output_len", ",", "self", ".", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomPad.__init__": [[147, 152], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_len", "=", "88200", ",", "train", "=", "True", ",", "padding_value", "=", "None", ")", ":", "\n", "        ", "super", "(", "RandomPad", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_len", "=", "output_len", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "padding_value", "=", "padding_value", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomPad.random_pad": [[153, 174], ["torch.cat", "numpy.random.randint", "int", "x[].float().mean().to", "x[].float().mean().to", "round", "torch.zeros().fill_", "torch.zeros().fill_", "x[].float().mean", "x[].float().mean", "torch.zeros", "torch.zeros", "x[].float", "x[].float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_pad", "(", "x", ",", "output_len", ",", "train", ",", "padding_value", "=", "None", ")", ":", "\n", "        ", "if", "x", ".", "shape", "[", "-", "1", "]", ">=", "output_len", ":", "\n", "            ", "return", "x", "\n", "", "if", "train", ":", "\n", "            ", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "output_len", "-", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "# center", "\n", "            ", "left", "=", "int", "(", "round", "(", "0.5", "*", "(", "output_len", "-", "x", ".", "shape", "[", "-", "1", "]", ")", ")", ")", "\n", "\n", "", "right", "=", "output_len", "-", "(", "left", "+", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "padding_value", "is", "not", "None", ":", "\n", "            ", "pad_value_left", "=", "pad_value_right", "=", "padding_value", "\n", "", "else", ":", "# mean over channel? ", "\n", "            ", "pad_value_left", "=", "x", "[", "...", ",", "0", "]", ".", "float", "(", ")", ".", "mean", "(", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "pad_value_right", "=", "x", "[", "...", ",", "-", "1", "]", ".", "float", "(", ")", ".", "mean", "(", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "", "padded_x", "=", "torch", ".", "cat", "(", "(", "\n", "torch", ".", "zeros", "(", "x", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "left", ",", ")", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ".", "fill_", "(", "pad_value_left", ")", ",", "\n", "x", ",", "\n", "torch", ".", "zeros", "(", "x", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "right", ",", ")", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ".", "fill_", "(", "pad_value_right", ")", "\n", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "padded_x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomPad.__call__": [[175, 177], ["transform.RandomPad.random_pad"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomPad.random_pad"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_pad", "(", "x", ",", "self", ".", "output_len", ",", "self", ".", "train", ",", "self", ".", "padding_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomNoise.__init__": [[179, 184], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "snr_min_db", "=", "10.0", ",", "snr_max_db", "=", "120.0", ",", "p", "=", "0.25", ")", ":", "\n", "        ", "super", "(", "RandomNoise", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "snr_min_db", "=", "snr_min_db", "\n", "self", ".", "snr_max_db", "=", "snr_max_db", "\n", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomNoise.random_noise": [[185, 200], ["torch.mean", "torch.normal", "numpy.random.rand", "torch.log10", "numpy.random.rand", "noise_watts.item"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_noise", "(", "x", ",", "snr_min_db", ",", "snr_max_db", ",", "p", ")", ":", "\n", "        ", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "p", ":", "\n", "            ", "return", "x", "\n", "", "target_snr", "=", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "snr_max_db", "-", "snr_min_db", "+", "1.0", ")", "+", "snr_min_db", "\n", "\n", "x_watts", "=", "torch", ".", "mean", "(", "x", "**", "2", ",", "dim", "=", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "x_db", "=", "10", "*", "torch", ".", "log10", "(", "x_watts", ")", "\n", "\n", "noise_db", "=", "x_db", "-", "target_snr", "\n", "noise_watts", "=", "10", "**", "(", "noise_db", "/", "10", ")", "+", "1e-7", "\n", "noise", "=", "torch", ".", "normal", "(", "0.0", ",", "noise_watts", ".", "item", "(", ")", "**", "0.5", ",", "x", ".", "shape", ")", "\n", "\n", "noise_x", "=", "x", "+", "noise", "\n", "return", "noise_x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomNoise.__call__": [[201, 203], ["transform.RandomNoise.random_noise"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.SimpleRandomNoise.random_noise"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_noise", "(", "x", ",", "self", ".", "snr_min_db", ",", "self", ".", "snr_max_db", ",", "self", ".", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.SimpleRandomNoise.__init__": [[205, 210], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "10.0", ",", "shift", "=", "10", ",", "p", "=", "0.25", ")", ":", "\n", "        ", "super", "(", "SimpleRandomNoise", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "shift", "=", "shift", "\n", "self", ".", "p", "=", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.SimpleRandomNoise.random_noise": [[211, 219], ["torch.roll", "numpy.random.rand", "numpy.random.randint", "torch.rand", "numpy.random.rand"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_noise", "(", "x", ",", "scale", ",", "shift", ",", "p", ")", ":", "\n", "# expect a 2d tensor", "\n", "        ", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "p", ":", "\n", "            ", "return", "x", "\n", "", "noise_x", "=", "x", "+", "torch", ".", "rand", "(", "x", ".", "shape", ")", "*", "np", ".", "random", ".", "rand", "(", ")", "/", "scale", "\n", "noise_x", "=", "torch", ".", "roll", "(", "noise_x", ",", "np", ".", "random", ".", "randint", "(", "-", "shift", ",", "shift", ")", ",", "-", "1", ")", "\n", "return", "noise_x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.SimpleRandomNoise.__call__": [[220, 222], ["transform.SimpleRandomNoise.random_noise"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.SimpleRandomNoise.random_noise"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_noise", "(", "x", ",", "self", ".", "scale", ",", "self", ".", "shift", ",", "self", ".", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.FbankTransform.__init__": [[224, 249], ["torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.ToTensor", "torchvision.Normalize", "torchaudio.transforms.FrequencyMasking", "torchaudio.transforms.TimeMasking", "torchvision.ToTensor", "torchvision.Normalize", "torchaudio.transforms.FrequencyMasking", "torchaudio.transforms.TimeMasking", "torchvision.ToTensor", "torchvision.Normalize", "x.transpose", "x.transpose"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "lambda", "x", ":", "x", ".", "T", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "-", "4.93839311", "]", ",", "std", "=", "[", "5.75751113", "]", "\n", ")", ",", "\n", "FrequencyMasking", "(", "48", ")", ",", "\n", "TimeMasking", "(", "300", ")", ",", "\n", "lambda", "x", ":", "x", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "]", ")", "\n", "self", ".", "transform_prime", "=", "transforms", ".", "Compose", "(", "[", "\n", "lambda", "x", ":", "x", ".", "T", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "-", "4.93839311", "]", ",", "std", "=", "[", "5.75751113", "]", "\n", ")", ",", "\n", "FrequencyMasking", "(", "32", ")", ",", "\n", "TimeMasking", "(", "200", ")", ",", "\n", "lambda", "x", ":", "x", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "]", ")", "\n", "self", ".", "transform_eval", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "-", "4.93839311", "]", ",", "std", "=", "[", "5.75751113", "]", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.FbankTransform.__call__": [[252, 259], ["transform.FbankTransform.transform_prime", "transform.FbankTransform.transform_eval", "numpy.array", "transform.FbankTransform.transform", "numpy.array"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ",", "both", ",", "train", ")", ":", "\n", "        ", "if", "not", "train", ":", "\n", "            ", "return", "self", ".", "transform_eval", "(", "x", ")", ",", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "y1", "=", "self", ".", "transform_prime", "(", "x", ")", "\n", "y2", "=", "self", ".", "transform", "(", "x", ")", "if", "both", "else", "np", ".", "array", "(", "[", "[", "[", "1", "]", "]", "]", ")", "\n", "return", "y1", ",", "y2", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform._extract_kaldi_spectrogram": [[12, 36], ["torchaudio.load", "int", "transform.RandomCrop.random_crop", "torchaudio.compliance.kaldi.fbank", "torchaudio.compliance.kaldi.fbank.numpy", "transform_audio.mean", "int", "transform_audio", "int", "numpy.ceil", "torch.tile", "transform_audio.mean"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.RandomCrop.random_crop"], ["def", "_extract_kaldi_spectrogram", "(", "\n", "filename", ",", "params", ",", "train", "=", "True", ",", "mean_channel", "=", "False", ",", "zero_mean_wf", "=", "False", ",", "max_audio_len", "=", "1000", ",", "transform_audio", "=", "None", ",", "tile_audio", "=", "False", ",", "\n", ")", ":", "\n", "    ", "waveform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "filename", ")", "\n", "if", "mean_channel", ":", "# mean along channel # TODO else branch should take a specific channel", "\n", "        ", "waveform", "=", "waveform", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "", "desired_len", "=", "int", "(", "(", "max_audio_len", "/", "100", ")", "*", "sample_rate", ")", "\n", "if", "tile_audio", "and", "desired_len", ">", "waveform", ".", "shape", "[", "-", "1", "]", ":", "\n", "        ", "ntile", "=", "int", "(", "np", ".", "ceil", "(", "desired_len", "/", "waveform", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "waveform", "=", "torch", ".", "tile", "(", "waveform", ",", "(", "1", ",", "ntile", ")", ")", "[", ":", "desired_len", "]", "\n", "", "if", "transform_audio", "is", "not", "None", ":", "\n", "        ", "waveform", "=", "transform_audio", "(", "waveform", ")", "\n", "", "waveform", "=", "RandomCrop", ".", "random_crop", "(", "\n", "waveform", ",", "int", "(", "(", "max_audio_len", "/", "100", "+", "0.05", ")", "*", "sample_rate", ")", ",", "train", "=", "train", "\n", ")", "# divided by 100 because kaldi has a frame shift of 10, additional 0.05s", "\n", "if", "zero_mean_wf", ":", "# TODO should extract the 1st channel before the mean", "\n", "        ", "waveform", "=", "waveform", "-", "waveform", ".", "mean", "(", ")", "\n", "", "fbank_feat", "=", "torchaudio", ".", "compliance", ".", "kaldi", ".", "fbank", "(", "\n", "waveform", ",", "\n", "sample_frequency", "=", "sample_rate", ",", "\n", "**", "params", ",", "\n", ")", "\n", "fbank_feat", "=", "fbank_feat", "[", ":", "max_audio_len", "]", "\n", "return", "fbank_feat", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.audio.transform.make_transform": [[37, 60], ["list", "list", "isinstance", "len", "torchvision.transforms.Compose", "isinstance", "len", "torchvision.transforms.Compose", "list.append", "list.append", "list.append", "list.append", "eval", "eval", "eval", "eval", "transform.ToTensorKeepdim"], "function", ["None"], ["", "def", "make_transform", "(", "cfg", ")", ":", "\n", "    ", "transform_fbank", "=", "transform_audio", "=", "None", "\n", "if", "cfg", ".", "transform_audio", ":", "\n", "        ", "tfm_list", "=", "list", "(", ")", "\n", "for", "name", ",", "params", "in", "cfg", ".", "audio_transforms", ":", "\n", "            ", "if", "isinstance", "(", "params", ",", "DictConfig", ")", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "**", "params", ")", ")", "\n", "", "else", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "*", "params", ")", ")", "\n", "", "", "if", "len", "(", "tfm_list", ")", ">", "0", ":", "\n", "            ", "transform_audio", "=", "Compose", "(", "tfm_list", ")", "\n", "", "", "if", "cfg", ".", "transform_fbank", ":", "\n", "        ", "tfm_list", "=", "list", "(", ")", "\n", "for", "name", ",", "params", "in", "cfg", ".", "fbank_transforms", ":", "\n", "            ", "if", "isinstance", "(", "params", ",", "DictConfig", ")", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "**", "params", ")", ")", "\n", "", "else", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "*", "params", ")", ")", "\n", "", "", "if", "len", "(", "tfm_list", ")", ">", "0", ":", "\n", "            ", "tfm_list", "=", "[", "lambda", "x", ":", "x", ".", "T", ",", "ToTensorKeepdim", "(", ")", "]", "+", "tfm_list", "+", "[", "lambda", "x", ":", "x", ".", "T", "]", "\n", "transform_fbank", "=", "Compose", "(", "tfm_list", ")", "\n", "#print(transform_audio, transform_fbank)", "\n", "", "", "return", "transform_audio", ",", "transform_fbank", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.GaussianBlur.__init__": [[21, 23], ["None"], "methods", ["None"], ["waveform", "=", "torch", ".", "tile", "(", "waveform", ",", "(", "1", ",", "ntile", ")", ")", "[", ":", "desired_len", "]", "\n", "", "if", "transform_audio", "is", "not", "None", ":", "\n", "        ", "waveform", "=", "transform_audio", "(", "waveform", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.GaussianBlur.__call__": [[24, 30], ["random.random", "image.filter", "PIL.ImageFilter.GaussianBlur", "random.random"], "methods", ["None"], ["", "waveform", "=", "RandomCrop", ".", "random_crop", "(", "\n", "waveform", ",", "int", "(", "(", "max_audio_len", "/", "100", "+", "0.05", ")", "*", "sample_rate", ")", ",", "train", "=", "train", "\n", ")", "# divided by 100 because kaldi has a frame shift of 10, additional 0.05s", "\n", "if", "zero_mean_wf", ":", "# TODO should extract the 1st channel before the mean", "\n", "        ", "waveform", "=", "waveform", "-", "waveform", ".", "mean", "(", ")", "\n", "", "fbank_feat", "=", "torchaudio", ".", "compliance", ".", "kaldi", ".", "fbank", "(", "\n", "waveform", ",", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.Solarization.__init__": [[32, 34], ["None"], "methods", ["None"], ["**", "params", ",", "\n", ")", "\n", "fbank_feat", "=", "fbank_feat", "[", ":", "max_audio_len", "]", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.Solarization.__call__": [[35, 40], ["random.random", "PIL.ImageOps.solarize"], "methods", ["None"], ["return", "fbank_feat", ".", "numpy", "(", ")", "\n", "\n", "", "def", "make_transform", "(", "cfg", ")", ":", "\n", "    ", "transform_fbank", "=", "transform_audio", "=", "None", "\n", "if", "cfg", ".", "transform_audio", ":", "\n", "        ", "tfm_list", "=", "list", "(", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.SharedImageTransform.__init__": [[42, 54], ["torchvision.Compose", "torchvision.Compose", "torchvision.RandomResizedCrop", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.RandomHorizontalFlip", "torchvision.RandomApply", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomGrayscale", "torchvision.ColorJitter", "torchvision.ColorJitter"], "methods", ["None"], ["            ", "if", "isinstance", "(", "params", ",", "DictConfig", ")", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "**", "params", ")", ")", "\n", "", "else", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "*", "params", ")", ")", "\n", "", "", "if", "len", "(", "tfm_list", ")", ">", "0", ":", "\n", "            ", "transform_audio", "=", "Compose", "(", "tfm_list", ")", "\n", "", "", "if", "cfg", ".", "transform_fbank", ":", "\n", "        ", "tfm_list", "=", "list", "(", ")", "\n", "for", "name", ",", "params", "in", "cfg", ".", "fbank_transforms", ":", "\n", "            ", "if", "isinstance", "(", "params", ",", "DictConfig", ")", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "**", "params", ")", ")", "\n", "", "else", ":", "\n", "                ", "tfm_list", ".", "append", "(", "eval", "(", "name", ")", "(", "*", "params", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.SharedImageTransform.__call__": [[56, 58], ["transform.SharedImageTransform.transform"], "methods", ["None"], ["            ", "tfm_list", "=", "[", "lambda", "x", ":", "x", ".", "T", ",", "ToTensorKeepdim", "(", ")", "]", "+", "tfm_list", "+", "[", "lambda", "x", ":", "x", ".", "T", "]", "\n", "transform_fbank", "=", "Compose", "(", "tfm_list", ")", "\n", "#print(transform_audio, transform_fbank)", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.SecretImageTransform.__init__": [[60, 68], ["torchvision.Compose", "torchvision.Compose", "transform.GaussianBlur", "transform.Solarization", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize"], "methods", ["None"], ["\n", "", "class", "ToTensorKeepdim", "(", "ToTensor", ")", ":", "\n", "    ", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "x", "\n", "", "x", "=", "super", "(", "ToTensorKeepdim", ",", "self", ")", ".", "__call__", "(", "x", "[", "...", ",", "None", "]", ")", "\n", "return", "x", ".", "squeeze_", "(", "0", ")", "\n", "\n", "", "", "class", "AbstractTransform", "(", "abc", ".", "ABC", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.SecretImageTransform.__call__": [[70, 72], ["transform.SecretImageTransform.transform"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "pass", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.AuthenticCLIPImageTransform.__init__": [[74, 88], ["torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Resize", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.CenterCrop", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Resize", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.CenterCrop", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize"], "methods", ["None"], ["\n", "", "", "class", "RandomFlip", "(", "AbstractTransform", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "RandomFlip", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "p", "\n", "\n", "", "@", "staticmethod", "\n", "def", "random_flip", "(", "x", ",", "p", ")", ":", "\n", "        ", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "flip_mask", "=", "torch", ".", "rand", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ")", "<=", "p", "\n", "x", "[", "flip_mask", "]", "=", "x", "[", "flip_mask", "]", ".", "flip", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "if", "torch", ".", "rand", "(", "1", ")", "<=", "p", ":", "\n", "                ", "x", "=", "x", ".", "flip", "(", "-", "1", ")", "\n", "", "", "return", "x", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.AuthenticCLIPImageTransform.__call__": [[89, 97], ["x.convert.convert.convert", "transform.AuthenticCLIPImageTransform.transform_prime", "transform.AuthenticCLIPImageTransform.transform_eval", "numpy.array", "transform.AuthenticCLIPImageTransform.transform", "numpy.array"], "methods", ["None"], ["\n", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_flip", "(", "x", ",", "self", ".", "p", ")", "\n", "\n", "", "", "class", "RandomScale", "(", "AbstractTransform", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.5", ",", "keep_len", "=", "False", ")", ":", "\n", "        ", "super", "(", "RandomScale", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "keep_len", "=", "keep_len", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.CLIPImageTransform.__init__": [[99, 135], ["torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Resize", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.CenterCrop", "torchvision.RandomHorizontalFlip", "torchvision.RandomHorizontalFlip", "torchvision.RandomApply", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomGrayscale", "transform.GaussianBlur", "transform.Solarization", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Resize", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.CenterCrop", "torchvision.RandomHorizontalFlip", "torchvision.RandomHorizontalFlip", "torchvision.RandomApply", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomGrayscale", "transform.GaussianBlur", "transform.Solarization", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Resize", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.CenterCrop", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.ColorJitter", "torchvision.ColorJitter", "torchvision.ColorJitter", "torchvision.ColorJitter"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_scale", "(", "x", ",", "scale", ",", "keep_len", ")", ":", "\n", "        ", "scaling", "=", "np", ".", "power", "(", "scale", ",", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ")", ")", "\n", "output_len", "=", "int", "(", "x", ".", "shape", "[", "-", "1", "]", "*", "scaling", ")", "\n", "base", "=", "torch", ".", "arange", "(", "output_len", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "div_", "(", "scaling", ")", "\n", "\n", "ref1", "=", "base", ".", "clone", "(", ")", ".", "type", "(", "torch", ".", "int64", ")", "\n", "ref2", "=", "torch", ".", "min", "(", "ref1", "+", "1", ",", "torch", ".", "full_like", "(", "ref1", ",", "x", ".", "shape", "[", "-", "1", "]", "-", "1", ",", "dtype", "=", "torch", ".", "int64", ")", ")", "\n", "r", "=", "base", "-", "ref1", ".", "type", "(", "base", ".", "type", "(", ")", ")", "\n", "scaled_x", "=", "(", "1", "-", "r", ")", "*", "x", "[", "...", ",", "ref1", "]", "+", "r", "*", "x", "[", "...", ",", "ref2", "]", "\n", "if", "keep_len", ":", "\n", "            ", "scaled_x", "=", "RandomCrop", ".", "random_crop", "(", "scaled_x", ",", "x", ".", "shape", "[", "-", "1", "]", ",", "True", ")", "# keep the same length", "\n", "", "return", "scaled_x", "\n", "\n", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_scale", "(", "x", ",", "self", ".", "scale", ",", "self", ".", "keep_len", ")", "\n", "\n", "", "", "class", "RandomCrop", "(", "AbstractTransform", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "output_len", "=", "44100", ",", "train", "=", "True", ")", ":", "\n", "        ", "super", "(", "RandomCrop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_len", "=", "output_len", "\n", "self", ".", "train", "=", "train", "\n", "\n", "", "@", "staticmethod", "\n", "def", "random_crop", "(", "x", ",", "output_len", ",", "train", ")", ":", "\n", "        ", "if", "x", ".", "shape", "[", "-", "1", "]", "<=", "output_len", ":", "\n", "            ", "return", "x", "\n", "", "if", "train", ":", "\n", "            ", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "x", ".", "shape", "[", "-", "1", "]", "-", "output_len", ")", "\n", "", "else", ":", "# center", "\n", "            ", "left", "=", "int", "(", "round", "(", "0.5", "*", "(", "x", ".", "shape", "[", "-", "1", "]", "-", "output_len", ")", ")", ")", "\n", "\n", "", "old_std", "=", "x", ".", "float", "(", ")", ".", "std", "(", ")", "*", "0.5", "\n", "cropped_x", "=", "x", "[", "...", ",", "left", ":", "left", "+", "output_len", "]", "\n", "\n", "new_std", "=", "cropped_x", ".", "float", "(", ")", ".", "std", "(", ")", "\n", "if", "new_std", "<", "old_std", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.CLIPImageTransform.__call__": [[137, 145], ["x.convert.convert.convert", "transform.CLIPImageTransform.transform_prime", "transform.CLIPImageTransform.transform_eval", "numpy.array", "transform.CLIPImageTransform.transform", "numpy.array"], "methods", ["None"], ["\n", "", "out_std", "=", "cropped_x", ".", "float", "(", ")", ".", "std", "(", ")", "\n", "if", "old_std", ">", "new_std", ">", "out_std", ":", "\n", "            ", "cropped_x", "=", "x", "[", "...", ",", "-", "output_len", ":", "]", "\n", "", "return", "cropped_x", "\n", "\n", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_crop", "(", "x", ",", "self", ".", "output_len", ",", "self", ".", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.BarlowImageTransform.__init__": [[147, 191], ["torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.RandomResizedCrop", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.RandomHorizontalFlip", "torchvision.RandomApply", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomGrayscale", "transform.GaussianBlur", "transform.Solarization", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.RandomResizedCrop", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.RandomHorizontalFlip", "torchvision.RandomApply", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomGrayscale", "transform.GaussianBlur", "transform.Solarization", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.Resize", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.CenterCrop", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Normalize", "torchvision.ColorJitter", "torchvision.ColorJitter", "torchvision.ColorJitter", "torchvision.ColorJitter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "output_len", "=", "88200", ",", "train", "=", "True", ",", "padding_value", "=", "None", ")", ":", "\n", "        ", "super", "(", "RandomPad", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_len", "=", "output_len", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "padding_value", "=", "padding_value", "\n", "\n", "", "@", "staticmethod", "\n", "def", "random_pad", "(", "x", ",", "output_len", ",", "train", ",", "padding_value", "=", "None", ")", ":", "\n", "        ", "if", "x", ".", "shape", "[", "-", "1", "]", ">=", "output_len", ":", "\n", "            ", "return", "x", "\n", "", "if", "train", ":", "\n", "            ", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "output_len", "-", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "# center", "\n", "            ", "left", "=", "int", "(", "round", "(", "0.5", "*", "(", "output_len", "-", "x", ".", "shape", "[", "-", "1", "]", ")", ")", ")", "\n", "\n", "", "right", "=", "output_len", "-", "(", "left", "+", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "padding_value", "is", "not", "None", ":", "\n", "            ", "pad_value_left", "=", "pad_value_right", "=", "padding_value", "\n", "", "else", ":", "# mean over channel? ", "\n", "            ", "pad_value_left", "=", "x", "[", "...", ",", "0", "]", ".", "float", "(", ")", ".", "mean", "(", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "pad_value_right", "=", "x", "[", "...", ",", "-", "1", "]", ".", "float", "(", ")", ".", "mean", "(", ")", ".", "to", "(", "x", ".", "dtype", ")", "\n", "", "padded_x", "=", "torch", ".", "cat", "(", "(", "\n", "torch", ".", "zeros", "(", "x", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "left", ",", ")", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ".", "fill_", "(", "pad_value_left", ")", ",", "\n", "x", ",", "\n", "torch", ".", "zeros", "(", "x", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "right", ",", ")", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ".", "fill_", "(", "pad_value_right", ")", "\n", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "padded_x", "\n", "\n", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "random_pad", "(", "x", ",", "self", ".", "output_len", ",", "self", ".", "train", ",", "self", ".", "padding_value", ")", "\n", "\n", "", "", "class", "RandomNoise", "(", "AbstractTransform", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "snr_min_db", "=", "10.0", ",", "snr_max_db", "=", "120.0", ",", "p", "=", "0.25", ")", ":", "\n", "        ", "super", "(", "RandomNoise", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "snr_min_db", "=", "snr_min_db", "\n", "self", ".", "snr_max_db", "=", "snr_max_db", "\n", "self", ".", "p", "=", "p", "\n", "\n", "", "@", "staticmethod", "\n", "def", "random_noise", "(", "x", ",", "snr_min_db", ",", "snr_max_db", ",", "p", ")", ":", "\n", "        ", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "p", ":", "\n", "            ", "return", "x", "\n", "", "target_snr", "=", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "snr_max_db", "-", "snr_min_db", "+", "1.0", ")", "+", "snr_min_db", "\n", "\n", "x_watts", "=", "torch", ".", "mean", "(", "x", "**", "2", ",", "dim", "=", "(", "-", "1", ",", "-", "2", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.BarlowImageTransform.__call__": [[193, 201], ["x.convert.convert.convert", "transform.BarlowImageTransform.transform_prime", "transform.BarlowImageTransform.transform_eval", "numpy.array", "transform.BarlowImageTransform.transform", "numpy.array"], "methods", ["None"], ["\n", "noise_db", "=", "x_db", "-", "target_snr", "\n", "noise_watts", "=", "10", "**", "(", "noise_db", "/", "10", ")", "+", "1e-7", "\n", "noise", "=", "torch", ".", "normal", "(", "0.0", ",", "noise_watts", ".", "item", "(", ")", "**", "0.5", ",", "x", ".", "shape", ")", "\n", "\n", "noise_x", "=", "x", "+", "noise", "\n", "return", "noise_x", "\n", "\n", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.image.transform.make_clip_image_transform": [[11, 18], ["torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "image.convert"], "function", ["None"], ["\n", "def", "_extract_kaldi_spectrogram", "(", "\n", "filename", ",", "params", ",", "train", "=", "True", ",", "mean_channel", "=", "False", ",", "zero_mean_wf", "=", "False", ",", "max_audio_len", "=", "1000", ",", "transform_audio", "=", "None", ",", "tile_audio", "=", "False", ",", "\n", ")", ":", "\n", "    ", "waveform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "filename", ")", "\n", "if", "mean_channel", ":", "# mean along channel # TODO else branch should take a specific channel", "\n", "        ", "waveform", "=", "waveform", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "", "desired_len", "=", "int", "(", "(", "max_audio_len", "/", "100", ")", "*", "sample_rate", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.__init__": [[24, 40], ["object.__init__", "cvalp.Monitor.build_data", "model.CVALP.CVALP", "model.CVALP.CVALP.build", "cvalp.Monitor.model.train", "cvalp.Monitor.build_optimizer", "cvalp.Monitor.eval_norms", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.build_data", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.build_optimizer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.eval_norms"], ["from", ".", "import", "(", "\n", "load_checkpoint", ",", "load_clip", ",", "load_meme", "\n", ")", "\n", "\n", "class", "CVALP", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CVALP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n", "", "def", "forward", "(", "self", ",", "images", ",", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "image_features", "=", "audio_features", "=", "text_features", "=", "None", "\n", "dummy_image", "=", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "==", "[", "1", ",", "1", ",", "1", "]", "\n", "if", "images", "is", "not", "None", "and", "self", ".", "image_head", "is", "not", "None", "and", "not", "dummy_image", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.eval_norms": [[41, 64], ["cvalp.Monitor.echo", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "enumerate", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "cvalp.Monitor.echo", "list", "list", "cvalp.Monitor.make_batch", "audios.mean", "som_list.append", "sos_list.append", "cvalp.Monitor.echo", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "std.cpu().tolist", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "std.cpu"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], ["            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "elif", "images", "is", "not", "None", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", "and", "not", "dummy_image", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "# dummy images will be ignored", "\n", "", "if", "audios", "is", "not", "None", "and", "self", ".", "audio_head", "is", "not", "None", ":", "\n", "            ", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "dummy_text", "=", "list", "(", "text", ".", "shape", "[", "1", ":", "]", ")", "==", "[", "1", "]", "if", "text", "is", "not", "None", "else", "True", "\n", "if", "text", "is", "not", "None", "and", "self", ".", "text_head", "is", "not", "None", "and", "not", "dummy_text", ":", "\n", "            ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "elif", "text", "is", "not", "None", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", "and", "not", "dummy_text", ":", "\n", "                ", "text", "=", "text", "/", "text", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "text_features", "=", "text", "# dummy text will be ignored", "\n", "", "loss", "=", "self", ".", "loss_head", "(", "image_features", ",", "audio_features", ",", "text_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n", "", "def", "encode_image", "(", "self", ",", "image", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.build_data": [[65, 105], ["data.build_filter_set", "data.build_audioset_label_map", "cvalp.Monitor.echo", "data.build_audioset_dataloader", "cvalp.Monitor.echo", "len", "os.path.isfile", "json.load", "cvalp.Monitor.echo", "data.build_audioset_dataloader", "cvalp.Monitor.echo", "data.build_audioset_dataloader", "cvalp.Monitor.echo", "open", "os.path.isdir", "os.path.isfile", "os.path.isdir", "os.path.isfile", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_filter_set", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_audioset_label_map", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_audioset_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_audioset_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_audioset_dataloader"], ["        ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "image_features", "\n", "\n", "", "def", "encode_audio", "(", "self", ",", "audio", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "audio_features", "\n", "\n", "", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n", "\n", "", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "collect_state_dict", "(", ")", "\n", "\n", "", "def", "collect_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "(", "self", ".", "image_head", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "image_head", "is", "not", "None", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "else", "OrderedDict", "(", ")", ")", ",", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "text_head", "is", "not", "None", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "else", "OrderedDict", "(", ")", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "stats", "(", "**", "kwargs", ")", "if", "hasattr", "(", "self", ".", "loss_head", ",", "\"stats\"", ")", "else", "\"\"", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n", "", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.learn": [[106, 131], ["cvalp.Monitor.echo", "time.time", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "range", "cvalp.Monitor.echo", "isinstance", "cvalp.Monitor.epoch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cvalp.Monitor.infer", "cvalp.Monitor.echo", "cvalp.Monitor.dataloader.sampler.set_epoch"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.epoch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "\n", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "\n", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "self", ".", "loss_head", ".", "load_state_dict", "(", "loss_head_sd", ")", "\n", "\n", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "running", ".", "siamese", ".", "alive", ":", "\n", "                ", "tunable_params", "=", "self", ".", "_build_siamese_backbone", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "                ", "tunable_params", "=", "self", ".", "_build_separate_backbone", "(", "**", "kwargs", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n", "", "def", "_build_siamese_backbone", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# try pre-trained model!", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.make_batch": [[136, 155], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.interpolate.dim", "list"], "methods", ["None"], ["self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize image encoder from `image_head`{msg}.\"", ")", "\n", "", "if", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", "or", "not", "self", ".", "cfg", ".", "running", ".", "imagine", ":", "\n", "            ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "", "scfg", "=", "self", ".", "cfg", ".", "running", ".", "siamese", "\n", "\n", "# shared modules with audio_head", "\n", "amodules", "=", "set", "(", "scfg", ".", "amodules", ")", "\n", "kwargs", "=", "{", "\n", "\"shared_modules\"", ":", "amodules", ",", "\"reference\"", ":", "self", ".", "image_head", ",", "\"keep_hp\"", ":", "scfg", ".", "keep_hp", "\n", "}", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ",", "**", "kwargs", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "            ", "if", "local_cfg", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.timeit": [[156, 171], ["time_dict.items", "cvalp.Monitor.echo", "time.time", "time.time", "time_dict[].append", "numpy.mean", "report.strip"], "methods", ["None"], ["self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `image_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "audio_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"A: audio_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "\n", "# shared modules with text_head ", "\n", "lmodules", "=", "set", "(", "scfg", ".", "lmodules", ")", "\n", "kwargs", ".", "update", "(", "{", "\"shared_modules\"", ":", "lmodules", "}", ")", "\n", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ",", "**", "kwargs", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_scratch", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_text", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.epoch": [[172, 273], ["collections.defaultdict", "cvalp.Monitor.timeit", "max", "enumerate", "cvalp.Monitor.timeit", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "cvalp.Monitor.make_batch", "cvalp.Monitor.timeit", "cvalp.Monitor.optimizer.zero_grad", "cvalp.Monitor.scaler.scale().backward", "cvalp.Monitor.scaler.step", "cvalp.Monitor.scaler.update", "cvalp.Monitor.timeit", "cvalp.Monitor.detach", "cvalp.Monitor.timeit", "cvalp.Monitor.scheduler.step", "range", "module.adjust_learning_rate", "cvalp.Monitor.echo", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "cvalp.Monitor.model", "cvalp.Monitor.scheduler.step", "isinstance", "print", "cvalp.Monitor.model.named_parameters", "cvalp.Monitor.model.report", "cvalp.Monitor.echo", "len", "cvalp.Monitor.scaler.scale", "cvalp.Monitor.model.train", "cvalp.Monitor.model.train", "cvalp.Monitor.echo", "cvalp.Monitor.model.train", "cvalp.Monitor.model.train", "cvalp.Monitor.echo", "cvalp.Monitor.save", "cvalp.Monitor.scheduler.get_last_lr", "print", "sum().item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cvalp.Monitor.infer", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cvalp.Monitor.infer", "cvalp.Monitor.scheduler.get_last_lr", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "len", "sum", "time.time", "p.grad.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.adjust_learning_rate", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `image_head`{msg}.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "text_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"T:  text_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "if", "self", ".", "cfg", ".", "running", ".", "text_emb", "is", "not", "None", "or", "len", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "text_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory text encoder.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "shared_modules", "=", "amodules", "|", "lmodules", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "shared_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "!=", "\"\"", "and", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# shared parameters must be tunable", "\n", "self", ".", "echo", "(", "f\"Freeze image encoder (excl. shared modules: {shared_modules}).\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "amodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "else", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "lmodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "return", "tunable_params", "\n", "\n", "", "def", "_build_separate_backbone", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize image encoder from `image_head`{msg}.\"", ")", "\n", "", "if", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", ":", "\n", "            ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `image_head`{msg}.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "", "if", "len", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "text_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory text encoder.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze image encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "return", "tunable_params", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.infer": [[274, 301], ["float", "isinstance", "max", "time.time", "enumerate", "cvalp.Monitor.echo", "model.report", "len", "dataloader.sampler.set_epoch", "cvalp.Monitor.make_batch", "cvalp.Monitor.model", "isinstance", "range", "len", "cvalp.Monitor.echo", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.save": [[302, 310], ["cvalp.Monitor.echo", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "model.collect_audio_state_dict"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.collect_audio_state_dict"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvalp.Monitor.build_optimizer": [[311, 349], ["list", "tunable_params.items", "isinstance", "cvalp.Monitor.model.named_parameters", "cvalp.Monitor.echo", "cvalp.Monitor.echo", "cvalp.Monitor.model.named_parameters", "tunable_params.values", "module.LARS", "re.sub", "getattr", "getattr", "cvalp.Monitor.echo", "util.numel", "util.numel", "v.size"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.__init__": [[25, 42], ["object.__init__", "esc50_clf.Monitor.build_data", "model.build_main_model.build_main_model", "model.build_main_model.build_main_model.build", "esc50_clf.Monitor.model.train", "esc50_clf.Monitor.build_optimizer", "cfg.model_file.endswith", "esc50_clf.Monitor.model.train", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.build_data", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.__init__.build_main_model", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.build_optimizer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train"], ["load_checkpoint", ",", "load_clip", ",", "load_meme", "\n", ")", "\n", "\n", "\n", "class", "ESClassifier", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "ESClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n", "", "def", "forward", "(", "self", ",", "audios", ",", "labels", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "audio_features", ",", "labels", ",", "**", "kwargs", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.reinitialize": [[43, 53], ["esc50_clf.Monitor.echo", "model.build_main_model.build_main_model", "len", "model.build_main_model.build_main_model.build", "esc50_clf.Monitor.model.train", "esc50_clf.Monitor.build_optimizer", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.__init__.build_main_model", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.build_optimizer"], ["return", "loss", "\n", "\n", "", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n", "\n", "", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.build_data": [[54, 57], ["data.build_xfold_dataloader_list", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_xfold_dataloader_list"], ["self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.learn": [[58, 103], ["list", "enumerate", "esc50_clf.Monitor.summary_report", "esc50_clf.Monitor.echo", "dataloader_fn", "evalloader_fn", "esc50_clf.Monitor.echo", "time.time", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "list", "range", "list.append", "esc50_clf.Monitor.reinitialize", "esc50_clf.Monitor.echo", "esc50_clf.Monitor.cfg.model_file.endswith", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "esc50_clf.Monitor.infer", "esc50_clf.Monitor.echo", "isinstance", "esc50_clf.Monitor.epoch", "esc50_clf.Monitor.echo", "esc50_clf.Monitor.dataloader.sampler.set_epoch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "esc50_clf.Monitor.repeated_zero_shot", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "esc50_clf.Monitor.standard_zero_shot"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.summary_report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.reinitialize", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.epoch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.repeated_zero_shot", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.standard_zero_shot"], ["        ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n", "", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "audio_head_sd", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `image_head`.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "if", "loss_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "loss_head", ".", "copy_state_dict", "(", "loss_head_sd", ")", "#", "\n", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "model", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "# TODO better to use `from_pretrained()`", "\n", "                    ", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.summary_report": [[104, 121], ["numpy.array", "esc50_clf.Monitor.echo", "esc50_clf.Monitor.echo", "numpy.array.sum", "np.array.sum.argmax", "esc50_clf.Monitor.echo", "numpy.array.argmax", "numpy.array.max", "esc50_clf.Monitor.echo", "best_precisions.mean", "best_precisions.std", "np.array.max.mean", "np.array.max.std"], "methods", ["None"], ["                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "                ", "excl_modules", "=", "set", "(", "self", ".", "cfg", ".", "running", ".", "excl_modules", ".", "amodules", ")", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "excl_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.make_batch": [[122, 133], ["torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out excluded parameters", "\n", "self", ".", "echo", "(", "f\"Tune audio encoder (excl. {excl_modules}).\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.timeit": [[134, 149], ["time_dict.items", "esc50_clf.Monitor.echo", "time.time", "time.time", "time_dict[].append", "numpy.mean", "report.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.epoch": [[150, 239], ["collections.defaultdict", "esc50_clf.Monitor.timeit", "max", "enumerate", "esc50_clf.Monitor.timeit", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.get_world_size", "torch.get_world_size", "esc50_clf.Monitor.make_batch", "esc50_clf.Monitor.timeit", "esc50_clf.Monitor.optimizer.zero_grad", "esc50_clf.Monitor.scaler.scale().backward", "esc50_clf.Monitor.scaler.step", "esc50_clf.Monitor.scaler.update", "esc50_clf.Monitor.timeit", "esc50_clf.Monitor.detach", "esc50_clf.Monitor.timeit", "esc50_clf.Monitor.scheduler.step", "range", "module.adjust_learning_rate", "esc50_clf.Monitor.echo", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "esc50_clf.Monitor.model", "esc50_clf.Monitor.scheduler.step", "isinstance", "print", "esc50_clf.Monitor.model.named_parameters", "esc50_clf.Monitor.echo", "len", "esc50_clf.Monitor.scaler.scale", "esc50_clf.Monitor.model.train", "esc50_clf.Monitor.model.train", "re.search", "float", "esc50_clf.Monitor.report_by_epoch.append", "esc50_clf.Monitor.echo", "esc50_clf.Monitor.scheduler.get_last_lr", "print", "sum().item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "esc50_clf.Monitor.infer", "float.group", "esc50_clf.Monitor.scheduler.get_last_lr", "torch.get_world_size", "torch.get_world_size", "len", "sum", "time.time", "p.grad.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.adjust_learning_rate", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.infer": [[240, 259], ["float", "isinstance", "time.time", "enumerate", "esc50_clf.Monitor.echo", "model.report", "len", "dataloader.sampler.set_epoch", "esc50_clf.Monitor.make_batch", "esc50_clf.Monitor.model", "isinstance", "range", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.zero_shot": [[260, 293], ["float", "list", "esc50_clf.Monitor.model.encode_text", "enumerate", "numpy.array", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "evalloader_fn", "isinstance", "time.time", "enumerate", "esc50_clf.Monitor.echo", "model.report", "esc50_clf.Monitor.echo", "re.search", "float", "list.append", "numpy.array.mean", "numpy.array.std", "range", "len", "dataloader.sampler.set_epoch", "esc50_clf.Monitor.make_batch", "esc50_clf.Monitor.model", "isinstance", "float.group", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.standard_zero_shot": [[294, 326], ["float", "list", "esc50_clf.Monitor.model.encode_text", "enumerate", "model.report", "esc50_clf.Monitor.echo", "re.search", "float", "list.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "evalloader_fn", "isinstance", "time.time", "enumerate", "esc50_clf.Monitor.echo", "isinstance", "float.group", "range", "len", "dataloader.sampler.set_epoch", "esc50_clf.Monitor.make_batch", "esc50_clf.Monitor.model", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.repeated_zero_shot": [[327, 338], ["esc50_clf.Monitor.echo", "model.extract_model_file", "len", "esc50_clf.Monitor.model.build", "esc50_clf.Monitor.model.train", "esc50_clf.Monitor.standard_zero_shot", "esc50_clf.Monitor.echo"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.extract_model_file", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.standard_zero_shot"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.save": [[339, 347], ["esc50_clf.Monitor.echo", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "model.collect_audio_state_dict"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.collect_audio_state_dict"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.esc50_clf.Monitor.build_optimizer": [[348, 386], ["list", "tunable_params.items", "isinstance", "esc50_clf.Monitor.model.named_parameters", "esc50_clf.Monitor.echo", "esc50_clf.Monitor.echo", "esc50_clf.Monitor.model.named_parameters", "tunable_params.values", "module.LARS", "re.sub", "getattr", "getattr", "esc50_clf.Monitor.echo", "util.numel", "util.numel", "v.size"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.siamese_va.Monitor.__init__": [[20, 22], ["siamese_va.Monitor.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["\n", "from", ".", "cvalp", "import", "CVALP", "\n", "from", ".", ".", "module", "import", "(", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.siamese_va.Monitor.make_batch": [[23, 63], ["siamese_va.Monitor.make_batch.scale_images"], "methods", ["None"], ["build_image_head", ",", "build_audio_head", ",", "build_text_head", ",", "build_loss_head", "\n", ")", "\n", "from", ".", "import", "(", "\n", "load_checkpoint", ",", "load_clip", ",", "load_meme", "\n", ")", "\n", "\n", "class", "CVASP", "(", "CVALP", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CVASP", ",", "self", ")", ".", "__init__", "(", "cfg", ",", "echo", ")", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "images", ",", "images_v1", ",", "audios_v1", ",", "\n", "text_v1", "=", "None", ",", "images_v2", "=", "None", ",", "audios_v2", "=", "None", ",", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "image_features", "=", "image_features_v1", "=", "image_features_v2", "=", "audio_features_v1", "=", "text_features", "=", "None", "\n", "if", "images", "is", "not", "None", ":", "# pre-computed unnormalized features", "\n", "            ", "dummy_image", "=", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "==", "[", "1", ",", "1", ",", "1", "]", "\n", "if", "self", ".", "loss_head", ".", "normalized", "and", "not", "dummy_image", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "# dummy images will be ignored", "\n", "", "if", "images_v1", "is", "not", "None", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "image_features_v1", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images_v1", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "if", "images_v2", "is", "not", "None", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "image_features_v2", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images_v2", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "if", "audios_v1", "is", "not", "None", "and", "self", ".", "audio_head", "is", "not", "None", ":", "\n", "            ", "audio_features_v1", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios_v1", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "if", "text_v1", "is", "not", "None", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text_v1", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "loss", "=", "self", ".", "loss_head", "(", "\n", "image_features", ",", "image_features_v1", ",", "audio_features_v1", ",", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.siamese_va.Monitor.epoch": [[64, 153], ["collections.defaultdict", "siamese_va.Monitor.timeit", "max", "enumerate", "siamese_va.Monitor.timeit", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "siamese_va.Monitor.make_batch", "siamese_va.Monitor.timeit", "siamese_va.Monitor.optimizer.zero_grad", "siamese_va.Monitor.scaler.scale().backward", "siamese_va.Monitor.scaler.step", "siamese_va.Monitor.scaler.update", "siamese_va.Monitor.timeit", "siamese_va.Monitor.detach", "siamese_va.Monitor.timeit", "siamese_va.Monitor.scheduler.step", "range", "module.adjust_learning_rate", "siamese_va.Monitor.echo", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "siamese_va.Monitor.model", "siamese_va.Monitor.scheduler.step", "isinstance", "print", "siamese_va.Monitor.model.named_parameters", "siamese_va.Monitor.model.report", "siamese_va.Monitor.echo", "len", "siamese_va.Monitor.scaler.scale", "siamese_va.Monitor.model.train", "siamese_va.Monitor.model.train", "siamese_va.Monitor.echo", "siamese_va.Monitor.save", "siamese_va.Monitor.scheduler.get_last_lr", "print", "sum().item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "siamese_va.Monitor.infer", "siamese_va.Monitor.scheduler.get_last_lr", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "len", "sum", "time.time", "p.grad.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.adjust_learning_rate", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["images_v2", "=", "image_features_v2", ",", "audios_v2", "=", "image_features_v2", ",", "**", "kwargs", "\n", ")", "\n", "return", "loss", "\n", "\n", "", "def", "_build_siamese_backbone", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# try pre-trained model!", "\n", "        ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "# image_head's parameters as the reference", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "            ", "n_o", ",", "o_n", "=", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize image encoder from `image_head`{msg}.\"", ")", "\n", "", "if", "False", "and", "(", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", "or", "not", "self", ".", "cfg", ".", "running", ".", "imagine", ")", ":", "\n", "            ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "", "scfg", "=", "self", ".", "cfg", ".", "running", ".", "siamese", "\n", "\n", "# shared modules with audio_head", "\n", "amodules", "=", "set", "(", "scfg", ".", "amodules", ")", "\n", "kwargs", "=", "{", "\n", "\"shared_modules\"", ":", "amodules", ",", "\"reference\"", ":", "self", ".", "image_head", ",", "\"keep_hp\"", ":", "scfg", ".", "keep_hp", "\n", "}", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ",", "**", "kwargs", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "            ", "if", "local_cfg", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `image_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "audio_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"A: audio_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "\n", "# shared modules with text_head ", "\n", "lmodules", "=", "set", "(", "scfg", ".", "lmodules", ")", "\n", "kwargs", ".", "update", "(", "{", "\"shared_modules\"", ":", "lmodules", "}", ")", "\n", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ",", "**", "kwargs", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_scratch", ":", "\n", "            ", "if", "self", ".", "cfg", ".", "model", ".", "text", ".", "from_text", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `image_head`{msg}.\"", ")", "\n", "", "", "ref_modules", "=", "self", ".", "text_head", ".", "replace_modules", "(", "**", "kwargs", ")", "\n", "self", ".", "echo", "(", "f\"T:  text_head.modules referring to image_head.modules: {ref_modules}.\"", ")", "\n", "if", "len", "(", "self", ".", "text_head", ".", "state_dict", "(", ")", ")", "==", "0", ":", "\n", "            ", "self", ".", "text_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory text encoder.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "shared_modules", "=", "amodules", "|", "lmodules", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "shared_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "!=", "\"\"", "and", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# shared parameters must be tunable", "\n", "self", ".", "echo", "(", "f\"Freeze image encoder (excl. shared modules: {shared_modules}).\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "amodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "else", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", "and", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "lmodules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out shared parameters", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "return", "tunable_params", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.siamese_va.Monitor.infer": [[154, 181], ["float", "isinstance", "max", "time.time", "enumerate", "siamese_va.Monitor.echo", "model.report", "len", "dataloader.sampler.set_epoch", "siamese_va.Monitor.make_batch", "siamese_va.Monitor.model", "isinstance", "range", "len", "siamese_va.Monitor.echo", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], ["", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.__init__": [[22, 42], ["object.__init__", "cvap.Monitor.build_data", "model.build_main_model.build_main_model", "model.build_main_model.build_main_model.build", "cvap.Monitor.model.train", "cvap.Monitor.build_optimizer", "cvap.Monitor.eval_norms", "cfg.model_file.endswith", "cvap.Monitor.model.train", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.build_data", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.__init__.build_main_model", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.build_optimizer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.eval_norms", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train"], ["self", ".", "echo", "=", "echo", "\n", "\n", "", "def", "forward", "(", "self", ",", "images", ",", "audios", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "if", "self", ".", "image_head", "is", "not", "None", ":", "\n", "            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "else", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "\n", "", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "image_features", ",", "audio_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n", "", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.eval_norms": [[43, 66], ["cvap.Monitor.echo", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "enumerate", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "cvap.Monitor.echo", "list", "list", "cvap.Monitor.make_batch", "audios.mean", "som_list.append", "sos_list.append", "cvap.Monitor.echo", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "std.cpu().tolist", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "std.cpu"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], ["        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "collect_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "image_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n", "", "", "def", "build", "(", "self", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.build_data": [[67, 88], ["data.build_image_audio_dataloader", "len", "cvap.Monitor.echo", "os.path.isdir", "os.path.isfile", "data.build_image_audio_dataloader", "cvap.Monitor.echo", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.build_image_audio_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.image_audio.build_image_audio_dataloader"], ["self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "local_cfg", ".", "model", ".", "audio", ")", "\n", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "local_cfg", ".", "model", ".", "loss", ")", "\n", "self", ".", "loss_head", ".", "load_state_dict", "(", "loss_head_sd", ")", "\n", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "model", "=", "load_clip", "(", "local_cfg", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "if", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.learn": [[89, 112], ["cvap.Monitor.echo", "time.time", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "range", "cvap.Monitor.echo", "isinstance", "cvap.Monitor.epoch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cvap.Monitor.infer", "cvap.Monitor.echo", "cvap.Monitor.dataloader.sampler.set_epoch"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.epoch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "# TODO better to use `from_pretrained()`", "\n", "                    ", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "extra_sd", "=", "{", "\"logit_scale\"", ":", "model", ".", "logit_scale", "}", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.make_batch": [[113, 143], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.interpolate.cuda", "torch.tensor().unsqueeze.cuda", "torch.tensor().unsqueeze.cuda", "torch.tensor().unsqueeze.cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.interpolate", "torch.interpolate", "torch.interpolate", "numpy.concatenate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.interpolate.dim", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.concatenate"], "methods", ["None"], ["self", ".", "loss_head", ".", "copy_state_dict", "(", "extra_sd", ")", "\n", "\n", "", "tunable_params", "=", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze image encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.timeit": [[144, 159], ["time_dict.items", "cvap.Monitor.echo", "time.time", "time.time", "time_dict[].append", "numpy.mean", "report.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.epoch": [[160, 245], ["collections.defaultdict", "cvap.Monitor.timeit", "max", "enumerate", "cvap.Monitor.timeit", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "cvap.Monitor.make_batch", "cvap.Monitor.timeit", "cvap.Monitor.optimizer.zero_grad", "cvap.Monitor.scaler.scale().backward", "cvap.Monitor.scaler.step", "cvap.Monitor.scaler.update", "cvap.Monitor.timeit", "cvap.Monitor.detach", "cvap.Monitor.timeit", "cvap.Monitor.scheduler.step", "range", "module.adjust_learning_rate", "cvap.Monitor.echo", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "cvap.Monitor.model", "cvap.Monitor.scheduler.step", "isinstance", "print", "cvap.Monitor.model.named_parameters", "cvap.Monitor.echo", "len", "cvap.Monitor.scaler.scale", "cvap.Monitor.model.train", "cvap.Monitor.model.train", "cvap.Monitor.echo", "cvap.Monitor.save", "cvap.Monitor.scheduler.get_last_lr", "print", "sum().item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cvap.Monitor.infer", "cvap.Monitor.scheduler.get_last_lr", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "len", "sum", "time.time", "p.grad.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.adjust_learning_rate", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.infer": [[246, 273], ["float", "isinstance", "max", "time.time", "enumerate", "cvap.Monitor.echo", "model.report", "len", "dataloader.sampler.set_epoch", "cvap.Monitor.make_batch", "cvap.Monitor.model", "isinstance", "range", "len", "cvap.Monitor.echo", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.save": [[274, 282], ["cvap.Monitor.echo", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "model.collect_audio_state_dict"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.collect_audio_state_dict"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.cvap.Monitor.build_optimizer": [[283, 321], ["list", "tunable_params.items", "isinstance", "cvap.Monitor.model.named_parameters", "cvap.Monitor.echo", "cvap.Monitor.echo", "cvap.Monitor.model.named_parameters", "tunable_params.values", "module.LARS", "re.sub", "getattr", "getattr", "cvap.Monitor.echo", "util.numel", "util.numel", "v.size"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.__init__": [[26, 46], ["object.__init__", "audioset_clf.Monitor.build_data", "model.ASClassifier.ASClassifier", "model.ASClassifier.ASClassifier.build", "audioset_clf.Monitor.model.train", "audioset_clf.Monitor.build_optimizer", "audioset_clf.Monitor.eval_norms", "cfg.model_file.endswith", "audioset_clf.Monitor.model.train", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.build_data", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.build_optimizer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.eval_norms", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train"], [")", "\n", "\n", "class", "ASClassifier", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "ASClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "echo", "=", "echo", "\n", "\n", "", "def", "forward", "(", "self", ",", "images", ",", "audios", ",", "labels", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel` ", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "if", "self", ".", "image_head", "is", "not", "None", "and", "list", "(", "images", ".", "shape", "[", "1", ":", "]", ")", "!=", "[", "1", ",", "1", ",", "1", "]", ":", "\n", "            ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "", "else", ":", "# pre-computed unnormalized features", "\n", "            ", "if", "self", ".", "loss_head", ".", "normalized", ":", "\n", "                ", "images", "=", "images", "/", "images", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "image_features", "=", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.eval_norms": [[47, 69], ["audioset_clf.Monitor.echo", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "enumerate", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "audioset_clf.Monitor.echo", "list", "list", "audioset_clf.Monitor.make_batch", "audios.mean", "som_list.append", "sos_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "std.cpu().tolist", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "std.cpu"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], ["", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "audio_features", ",", "labels", ",", "x3", "=", "image_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n", "", "def", "encode_image", "(", "self", ",", "images", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "image_features", "=", "data_parallel", "(", "\n", "self", ".", "image_head", ",", "images", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "image_features", "\n", "\n", "", "def", "encode_audio", "(", "self", ",", "audios", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "audio_features", "\n", "\n", "", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.encode_audios": [[70, 99], ["audioset_clf.Monitor.echo", "time.time", "enumerate", "audioset_clf.Monitor.echo", "os.path.exists", "os.makedirs", "enumerate", "audioset_clf.Monitor.make_batch", "audioset_clf.Monitor.model.encode_audio", "audio_features.cpu().numpy.cpu().numpy.cpu().numpy", "audioset_clf.Monitor.encode_audios.save_npz"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.audioset_clf.ASClassifier.encode_audio"], ["\n", "", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "report", "(", "self", ",", "gold_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "stats", "(", "**", "kwargs", ")", "if", "hasattr", "(", "self", ".", "loss_head", ",", "\"stats\"", ")", "else", "\"\"", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"\"", "\n", "\n", "", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "self", ".", "cfg", ".", "running", ".", "imagine", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.build_data": [[100, 146], ["data.build_audioset_label_map", "data.build_audioset_label_map.items", "enumerate", "data.build_filter_set", "audioset_clf.Monitor.echo", "data.build_audioset_clf_dataloader", "audioset_clf.Monitor.echo", "len", "len", "data.build_audioset_label_map.items", "checksum.append", "audioset_clf.Monitor.echo", "data.build_audioset_clf_dataloader", "audioset_clf.Monitor.echo", "data.build_audioset_clf_dataloader", "audioset_clf.Monitor.echo", "print", "os.path.isdir", "os.path.isfile", "os.path.isdir", "os.path.isfile", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_audioset_label_map", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_hub.build_filter_set", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.build_audioset_clf_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.build_audioset_clf_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.audioset_clf.build_audioset_clf_dataloader"], ["if", "audio_head_sd", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `image_head`.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "try", ":", "\n", "                ", "self", ".", "loss_head", ".", "load_state_dict", "(", "loss_head_sd", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "self", ".", "echo", "(", "f\"Failed to load `loss_head` (expected in zero-shot mode) because: {e}\"", ")", "\n", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "_", ",", "model", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "image_head", "=", "build_image_head", "(", "self", ".", "cfg", ".", "model", ".", "image", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "from_scratch", "and", "image_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "image_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize image encoder from `image_head`.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "running", ".", "imagine", "or", "self", ".", "cfg", ".", "running", ".", "frame_emb", "is", "not", "None", ":", "\n", "                ", "self", ".", "image_head", "=", "None", "\n", "self", ".", "echo", "(", "\"Destory image encoder.\"", ")", "\n", "\n", "", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "# TODO better to use `from_pretrained()`", "\n", "                    ", "self", ".", "audio_head", ".", "load_state_dict", "(", "audio_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.learn": [[147, 191], ["audioset_clf.Monitor.echo", "util.AverageMeter", "time.time", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "range", "audioset_clf.Monitor.echo", "isinstance", "audioset_clf.Monitor.epoch", "audioset_clf.Monitor.echo", "audioset_clf.Monitor.cfg.model_file.endswith", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audioset_clf.Monitor.infer", "audioset_clf.Monitor.echo", "audioset_clf.Monitor.dataloader.sampler.set_epoch", "audioset_clf.Monitor.echo", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audioset_clf.Monitor.repeated_zero_shot", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audioset_clf.Monitor.zero_shot"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.epoch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.repeated_zero_shot", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.zero_shot"], ["                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "tunable_params", "=", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "image", ".", "freeze", "and", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"image_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "image_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "image_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze image encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "                ", "excl_modules", "=", "set", "(", "self", ".", "cfg", ".", "running", ".", "excl_modules", ".", "amodules", ")", "\n", "pattern", "=", "\"|\"", ".", "join", "(", "[", "f\"^{m}\\.\"", "for", "m", "in", "excl_modules", "]", ")", "\n", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "if", "pattern", "==", "\"\"", "or", "not", "re", ".", "match", "(", "pattern", ",", "k", ")", "}", ")", "# filter out excluded parameters", "\n", "self", ".", "echo", "(", "f\"Tune audio encoder (excl. {excl_modules}).\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.make_batch": [[192, 211], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.interpolate.dim", "list"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit": [[212, 227], ["time_dict.items", "audioset_clf.Monitor.echo", "time.time", "time.time", "time_dict[].append", "numpy.mean", "report.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.epoch": [[228, 333], ["collections.defaultdict", "audioset_clf.Monitor.timeit", "max", "enumerate", "audioset_clf.Monitor.ast_loss.reset", "audioset_clf.Monitor.timeit", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "audioset_clf.Monitor.make_batch", "audioset_clf.Monitor.timeit", "audioset_clf.Monitor.optimizer.zero_grad", "audioset_clf.Monitor.scaler.scale().backward", "audioset_clf.Monitor.scaler.step", "audioset_clf.Monitor.scaler.update", "audioset_clf.Monitor.timeit", "audioset_clf.Monitor.detach", "audioset_clf.Monitor.ast_loss", "audioset_clf.Monitor.timeit", "audioset_clf.Monitor.scheduler.step", "range", "module.adjust_learning_rate", "audioset_clf.Monitor.echo", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "audioset_clf.Monitor.model", "audioset_clf.Monitor.scheduler.get_last_lr", "audioset_clf.Monitor.scheduler.step", "isinstance", "print", "audioset_clf.Monitor.model.named_parameters", "audioset_clf.Monitor.detach", "audioset_clf.Monitor.model.report", "audioset_clf.Monitor.echo", "len", "audioset_clf.Monitor.scaler.scale", "isinstance", "audioset_clf.Monitor.model.train", "audioset_clf.Monitor.model.train", "audioset_clf.Monitor.echo", "audioset_clf.Monitor.model.train", "audioset_clf.Monitor.model.train", "audioset_clf.Monitor.echo", "audioset_clf.Monitor.save", "audioset_clf.Monitor.scheduler.get_last_lr", "print", "sum().item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audioset_clf.Monitor.infer", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "audioset_clf.Monitor.infer", "audioset_clf.Monitor.scheduler.get_last_lr", "audioset_clf.Monitor.scheduler.get_last_lr", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "len", "sum", "time.time", "p.grad.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.AverageMeter.reset", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.adjust_learning_rate", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.infer": [[334, 361], ["float", "isinstance", "max", "time.time", "enumerate", "audioset_clf.Monitor.echo", "model.report", "len", "dataloader.sampler.set_epoch", "audioset_clf.Monitor.make_batch", "audioset_clf.Monitor.model", "isinstance", "range", "len", "audioset_clf.Monitor.echo", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.encode_text": [[362, 376], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "audioset_clf.Monitor.model.encode_text", "text.append", "numpy.array", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "list", "itertools.zip_longest"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_text"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.zero_shot": [[377, 405], ["float", "isinstance", "max", "audioset_clf.Monitor.encode_text", "time.time", "enumerate", "audioset_clf.Monitor.echo", "model.report", "len", "dataloader.sampler.set_epoch", "audioset_clf.Monitor.make_batch", "audioset_clf.Monitor.model", "isinstance", "range", "len", "audioset_clf.Monitor.echo", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.repeated_zero_shot": [[406, 419], ["audioset_clf.Monitor.echo", "model.extract_model_file", "len", "audioset_clf.Monitor.model.build", "audioset_clf.Monitor.model.train", "audioset_clf.Monitor.zero_shot", "audioset_clf.Monitor.echo"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.extract_model_file", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.zero_shot"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save": [[420, 428], ["audioset_clf.Monitor.echo", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "model.collect_audio_state_dict"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.collect_audio_state_dict"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.build_optimizer": [[429, 467], ["list", "tunable_params.items", "isinstance", "audioset_clf.Monitor.model.named_parameters", "audioset_clf.Monitor.echo", "audioset_clf.Monitor.echo", "audioset_clf.Monitor.model.named_parameters", "tunable_params.values", "module.LARS", "re.sub", "getattr", "getattr", "audioset_clf.Monitor.echo", "util.numel", "util.numel", "v.size"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.util.__init__.numel"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.__init__": [[20, 22], ["clap.Monitor.__init__"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "echo", ")", ":", "\n", "        ", "super", "(", "CLAP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.eval_norms": [[23, 45], ["clap.Monitor.echo", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "enumerate", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "clap.Monitor.echo", "list", "list", "clap.Monitor.make_batch", "audios.mean", "som_list.append", "sos_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "torch.cat().mean.cpu().tolist", "std.cpu().tolist", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "torch.cat().mean.cpu", "std.cpu"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], ["self", ".", "echo", "=", "echo", "\n", "\n", "", "def", "forward", "(", "self", ",", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "\"retrieval\"", ",", "False", ")", ":", "# if it is a retrieval task", "\n", "            ", "return", "self", ".", "forward_retrieval", "(", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel`", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "False", ",", "\"require_feature\"", ":", "True", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n", "_", ",", "audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "time_first", "=", "True", "#self.audio_head.time_first", "\n", "text_input", "=", "(", "text", ",", "audio_features", ",", "time_first", ")", "\n", "_", ",", "logits", ",", "predictions", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text_input", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "logits", ",", "text", "[", ":", ",", "1", ":", "]", ",", "predictions", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n", "", "def", "forward_retrieval", "(", "self", ",", "audios", ",", "text", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "device_ids", "=", "kwargs", ".", "get", "(", "\"device_ids\"", ",", "[", "0", "]", ")", "\n", "# how to asynchronize the two `data_parallel`", "\n", "kwargs", "=", "{", "\"normalized\"", ":", "self", ".", "loss_head", ".", "normalized", ",", "\"names\"", ":", "kwargs", ".", "get", "(", "\"names\"", ",", "None", ")", "}", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.encode_text": [[46, 77], ["rcfg.clip_model_name.lower", "clap.Monitor.echo", "time.time", "enumerate", "clap.Monitor.echo", "os.path.exists", "os.makedirs", "int", "enumerate", "clap.Monitor.make_batch", "clap.Monitor.model.encode_text", "text_features.cpu().numpy.cpu().numpy.cpu().numpy", "clap.Monitor.encode_text.save_npz"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_text"], ["audio_features", "=", "data_parallel", "(", "\n", "self", ".", "audio_head", ",", "audios", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "loss", "=", "self", ".", "loss_head", "(", "audio_features", ",", "text_features", ",", "**", "kwargs", ")", "\n", "return", "loss", "\n", "\n", "", "def", "encode_text", "(", "self", ",", "text", ",", "*", "args", ",", "device_ids", "=", "[", "0", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "text_features", "=", "data_parallel", "(", "\n", "self", ".", "text_head", ",", "text", ",", "device_ids", "=", "device_ids", ",", "module_kwargs", "=", "kwargs", "\n", ")", "\n", "return", "text_features", "\n", "\n", "", "def", "collect_audio_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "collect_state_dict", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "audio_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "text_head", ".", "state_dict", "(", ")", ",", "\n", "self", ".", "loss_head", ".", "state_dict", "(", ")", ",", "\n", ")", "\n", "\n", "", "def", "report", "(", "self", ",", "gold_file", "=", "None", ")", ":", "\n", "        ", "if", "not", "dist", ".", "is_initialized", "(", ")", "or", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "loss_head", ".", "report", "(", "gold_file", "=", "gold_file", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.build_data": [[78, 115], ["build_dataloader", "len", "clap.Monitor.echo", "os.path.isdir", "os.path.isfile", "build_dataloader", "clap.Monitor.echo", "os.path.isdir", "os.path.isfile", "build_dataloader", "clap.Monitor.echo", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.data.esc50.build_dataloader"], ["            ", "return", "\"\"", "\n", "\n", "", "", "def", "build", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "tunable_params", "=", "dict", "(", ")", "\n", "if", "self", ".", "cfg", ".", "eval", ":", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "_", "=", "load_clip", "(", "None", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ")", "\n", "if", "audio_head_sd", "is", "not", "None", ":", "\n", "                ", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from `audio_head`{msg}.\"", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `image_head`.\"", ")", "\n", "\n", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "#", "\n", "n_o", ",", "o_n", "=", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "msg", "=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize text encoder from `text_head`{msg}.\"", ")", "\n", "\n", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ",", "**", "kwargs", ")", "\n", "if", "loss_head_sd", "is", "not", "None", ":", "\n", "                ", "self", ".", "loss_head", ".", "copy_state_dict", "(", "loss_head_sd", ")", "#", "\n", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "else", ":", "\n", "# try pre-trained model!", "\n", "            ", "local_cfg", ",", "_", ",", "audio_head_sd", ",", "_", ",", "loss_head_sd", "=", "load_checkpoint", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try clip! TODO do we always have to load CLIP?", "\n", "from_scratch", ",", "image_head_sd", ",", "text_head_sd", ",", "model", "=", "load_clip", "(", "local_cfg", ",", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "# try meme!", "\n", "with_meme", ",", "meme_image_head_sd", "=", "load_meme", "(", "self", ".", "cfg", ",", "self", ".", "echo", ")", "\n", "\n", "#cfg = local_cfg if local_cfg is not None else self.cfg", "\n", "self", ".", "audio_head", "=", "build_audio_head", "(", "self", ".", "cfg", ".", "model", ".", "audio", ",", "**", "kwargs", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.learn": [[116, 148], ["clap.Monitor.echo", "time.time", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "torch.cuda.amp.GradScaler", "range", "clap.Monitor.echo", "clap.Monitor.cfg.model_file.endswith", "isinstance", "clap.Monitor.epoch", "clap.Monitor.dataloader.sampler.set_epoch", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "clap.Monitor.repeated_retrieval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "clap.Monitor.infer", "clap.Monitor.echo"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.epoch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.repeated_retrieval", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], ["                ", "if", "local_cfg", "is", "not", "None", ":", "\n", "                    ", "self", ".", "audio_head", ".", "from_pretrained", "(", "audio_head_sd", ",", "local_cfg", ")", "\n", "self", ".", "echo", "(", "\"Initialize audio encoder from `audio_head`.\"", ")", "\n", "", "elif", "not", "from_scratch", ":", "\n", "                    ", "if", "with_meme", ":", "# higher priority", "\n", "                        ", "msg", "=", "\" `meme_image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "meme_image_head_sd", ")", "\n", "", "else", ":", "\n", "                        ", "msg", "=", "\" `image_head`\"", "\n", "n_o", ",", "o_n", "=", "self", ".", "audio_head", ".", "copy_state_dict", "(", "image_head_sd", ")", "\n", "", "msg", "+=", "f\" except {n_o}\"", "if", "len", "(", "n_o", ")", ">", "0", "else", "\"\"", "\n", "self", ".", "echo", "(", "f\"Initialize audio encoder from{msg}.\"", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "echo", "(", "\"Have to learn from scratch.\"", ")", "\n", "\n", "", "", "self", ".", "text_head", "=", "build_text_head", "(", "self", ".", "cfg", ".", "model", ".", "text", ")", "\n", "if", "not", "from_scratch", ":", "\n", "                ", "self", ".", "text_head", ".", "copy_state_dict", "(", "text_head_sd", ")", "\n", "self", ".", "echo", "(", "\"Initialize text encoder from `text_head`.\"", ")", "\n", "\n", "", "self", ".", "loss_head", "=", "build_loss_head", "(", "self", ".", "cfg", ".", "model", ".", "loss", ")", "\n", "if", "not", "from_scratch", "and", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "from_scratch", ":", "\n", "                ", "extra_sd", "=", "{", "\"logit_scale\"", ":", "model", ".", "logit_scale", "}", "\n", "self", ".", "loss_head", ".", "copy_state_dict", "(", "extra_sd", ")", "\n", "\n", "", "tunable_params", ".", "update", "(", "{", "\n", "f\"loss_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "loss_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "if", "not", "self", ".", "cfg", ".", "model", ".", "audio", ".", "freeze", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"audio_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "audio_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "audio_head", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch": [[149, 175], ["len", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "ValueError", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["                ", "self", ".", "echo", "(", "\"Freeze audio encoder.\"", ")", "\n", "", "if", "not", "self", ".", "cfg", ".", "model", ".", "text", ".", "freeze", ":", "\n", "                ", "tunable_params", ".", "update", "(", "{", "\n", "f\"text_head.{k}\"", ":", "v", "for", "k", ",", "v", "in", "self", ".", "text_head", ".", "named_parameters", "(", ")", "\n", "}", ")", "\n", "", "elif", "self", ".", "text_head", "is", "not", "None", ":", "\n", "                ", "self", ".", "echo", "(", "\"Freeze text encoder.\"", ")", "\n", "", "self", ".", "cuda", "(", "self", ".", "cfg", ".", "rank", ")", "\n", "", "return", "tunable_params", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.epoch": [[176, 273], ["collections.defaultdict", "clap.Monitor.timeit", "max", "enumerate", "clap.Monitor.timeit", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.distributed.is_initialized", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "clap.Monitor.make_batch", "clap.Monitor.timeit", "clap.Monitor.optimizer.zero_grad", "clap.Monitor.scaler.scale().backward", "clap.Monitor.scaler.step", "clap.Monitor.scaler.update", "clap.Monitor.timeit", "clap.Monitor.detach", "clap.Monitor.timeit", "clap.Monitor.scheduler.step", "range", "module.adjust_learning_rate", "clap.Monitor.echo", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "clap.Monitor.model", "clap.Monitor.scheduler.step", "isinstance", "print", "clap.Monitor.model.named_parameters", "clap.Monitor.echo", "len", "clap.Monitor.scaler.scale", "clap.Monitor.model.train", "clap.Monitor.model.train", "clap.Monitor.echo", "clap.Monitor.model.train", "clap.Monitor.model.train", "clap.Monitor.echo", "clap.Monitor.save", "clap.Monitor.scheduler.get_last_lr", "print", "sum().item", "clap.Monitor.detach", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "clap.Monitor.infer", "clap.Monitor.detach", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "clap.Monitor.infer", "clap.Monitor.scheduler.get_last_lr", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "len", "sum", "time.time", "p.grad.norm"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.timeit", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.adjust_learning_rate", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.module.lars.LARS.step", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.audioset_clf.Monitor.save", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer": [[274, 301], ["float", "isinstance", "max", "time.time", "enumerate", "clap.Monitor.echo", "model.report", "len", "dataloader.sampler.set_epoch", "clap.Monitor.make_batch", "clap.Monitor.model", "isinstance", "range", "len", "clap.Monitor.echo", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.report", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.make_batch"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.repeated_retrieval": [[302, 312], ["clap.Monitor.echo", "model.extract_model_file", "clap.Monitor.model.build", "clap.Monitor.model.train", "clap.Monitor.infer", "clap.Monitor.echo"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.helper.extract_model_file", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.model.clap.CLAP.build", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.None.train.train", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.monitor.clap.Monitor.infer"], []], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.__init__": [[63, 79], ["simple_tokenizer.default_bpe", "simple_tokenizer.bytes_to_unicode", "gzip.open().read().decode().split", "list", "list.extend", "dict", "dict", "regex.compile", "tuple", "bytes_to_unicode().values", "list.append", "zip", "zip", "simple_tokenizer.SimpleTokenizer.byte_encoder.items", "gzip.open().read().decode", "merge.split", "range", "simple_tokenizer.SimpleTokenizer.encoder.items", "range", "simple_tokenizer.bytes_to_unicode", "len", "len", "gzip.open().read", "gzip.open"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.default_bpe", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.bytes_to_unicode", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.decode", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.bytes_to_unicode"], ["    ", "def", "__init__", "(", "self", ",", "bpe_path", ":", "str", "=", "default_bpe", "(", ")", ")", ":", "\n", "        ", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "gzip", ".", "open", "(", "bpe_path", ")", ".", "read", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "'\\n'", ")", "\n", "merges", "=", "merges", "[", "1", ":", "49152", "-", "256", "-", "2", "+", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "vocab", "=", "list", "(", "bytes_to_unicode", "(", ")", ".", "values", "(", ")", ")", "\n", "vocab", "=", "vocab", "+", "[", "v", "+", "'</w>'", "for", "v", "in", "vocab", "]", "\n", "for", "merge", "in", "merges", ":", "\n", "            ", "vocab", ".", "append", "(", "''", ".", "join", "(", "merge", ")", ")", "\n", "", "vocab", ".", "extend", "(", "[", "'<|startoftext|>'", ",", "'<|endoftext|>'", "]", ")", "\n", "self", ".", "encoder", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "'<|startoftext|>'", ":", "'<|startoftext|>'", ",", "'<|endoftext|>'", ":", "'<|endoftext|>'", "}", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\"", ",", "re", ".", "IGNORECASE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.bpe": [[80, 120], ["simple_tokenizer.get_pairs", "tuple", "min", "tuple", "len", "len", "simple_tokenizer.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "simple_tokenizer.SimpleTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.get_pairs", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.encode": [[121, 128], ["whitespace_clean().lower", "regex.findall", "bpe_tokens.extend", "simple_tokenizer.whitespace_clean", "simple_tokenizer.basic_clean", "token.encode", "simple_tokenizer.SimpleTokenizer.bpe().split", "simple_tokenizer.SimpleTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.whitespace_clean", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.basic_clean", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.encode", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.bpe"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "text", "=", "whitespace_clean", "(", "basic_clean", "(", "text", ")", ")", ".", "lower", "(", ")", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "bpe_tokens", ".", "extend", "(", "self", ".", "encoder", "[", "bpe_token", "]", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.decode": [[129, 133], ["bytearray().decode().replace", "bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "text", "=", "''", ".", "join", "(", "[", "self", ".", "decoder", "[", "token", "]", "for", "token", "in", "tokens", "]", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "\"replace\"", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", "\n", "return", "text", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.default_bpe": [[10, 13], ["functools.lru_cache", "os.path.join", "os.path.dirname", "os.path.abspath"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "default_bpe", "(", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "\"bpe_simple_vocab_16e6.txt.gz\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.bytes_to_unicode": [[15, 36], ["functools.lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "bs", "=", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.get_pairs": [[38, 48], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.basic_clean": [[50, 54], ["ftfy.fix_text", "html.unescape", "html.unescape.strip", "html.unescape"], "function", ["None"], ["", "def", "basic_clean", "(", "text", ")", ":", "\n", "    ", "text", "=", "ftfy", ".", "fix_text", "(", "text", ")", "\n", "text", "=", "html", ".", "unescape", "(", "html", ".", "unescape", "(", "text", ")", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.whitespace_clean": [[56, 60], ["regex.sub", "text.strip.strip"], "function", ["None"], ["", "def", "whitespace_clean", "(", "text", ")", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "text", ")", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip._download": [[28, 58], ["os.path.expanduser", "os.makedirs", "os.path.basename", "os.path.join", "os.path.isfile", "url.split", "os.path.exists", "RuntimeError", "urllib.request.urlopen", "open", "hashlib.sha256().hexdigest", "RuntimeError", "os.path.isfile", "hashlib.sha256().hexdigest", "warnings.warn", "tqdm.tqdm", "source.read", "output.write", "loop.update", "hashlib.sha256", "hashlib.sha256", "int", "len", "open().read", "open().read", "source.info().get", "open", "open", "source.info"], "function", ["None"], ["def", "_download", "(", "url", ":", "str", ",", "root", ":", "str", "=", "os", ".", "path", ".", "expanduser", "(", "\"~/.cache/clip\"", ")", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "root", ",", "exist_ok", "=", "True", ")", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "\n", "expected_sha256", "=", "url", ".", "split", "(", "\"/\"", ")", "[", "-", "2", "]", "\n", "download_target", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "download_target", ")", "and", "not", "os", ".", "path", ".", "isfile", "(", "download_target", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"{download_target} exists and is not a regular file\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "download_target", ")", ":", "\n", "        ", "if", "hashlib", ".", "sha256", "(", "open", "(", "download_target", ",", "\"rb\"", ")", ".", "read", "(", ")", ")", ".", "hexdigest", "(", ")", "==", "expected_sha256", ":", "\n", "            ", "return", "download_target", "\n", "", "else", ":", "\n", "            ", "warnings", ".", "warn", "(", "f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\"", ")", "\n", "\n", "", "", "with", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "as", "source", ",", "open", "(", "download_target", ",", "\"wb\"", ")", "as", "output", ":", "\n", "        ", "with", "tqdm", "(", "total", "=", "int", "(", "source", ".", "info", "(", ")", ".", "get", "(", "\"Content-Length\"", ")", ")", ",", "ncols", "=", "80", ",", "unit", "=", "'iB'", ",", "unit_scale", "=", "True", ")", "as", "loop", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "buffer", "=", "source", ".", "read", "(", "8192", ")", "\n", "if", "not", "buffer", ":", "\n", "                    ", "break", "\n", "\n", "", "output", ".", "write", "(", "buffer", ")", "\n", "loop", ".", "update", "(", "len", "(", "buffer", ")", ")", "\n", "\n", "", "", "", "if", "hashlib", ".", "sha256", "(", "open", "(", "download_target", ",", "\"rb\"", ")", ".", "read", "(", ")", ")", ".", "hexdigest", "(", ")", "!=", "expected_sha256", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Model has been downloaded but the SHA256 checksum does not not match\"", ")", "\n", "\n", "", "return", "download_target", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip._transform": [[60, 67], ["torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "image.convert"], "function", ["None"], ["", "def", "_transform", "(", "n_px", ")", ":", "\n", "    ", "return", "Compose", "(", "[", "\n", "Resize", "(", "n_px", ",", "interpolation", "=", "InterpolationMode", ".", "BICUBIC", ")", ",", "\n", "CenterCrop", "(", "n_px", ")", ",", "\n", "lambda", "image", ":", "image", ".", "convert", "(", "\"RGB\"", ")", ",", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "(", "0.48145466", ",", "0.4578275", ",", "0.40821073", ")", ",", "(", "0.26862954", ",", "0.26130258", ",", "0.27577711", ")", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.available_models": [[70, 73], ["list", "_MODELS.keys"], "function", ["None"], ["", "def", "available_models", "(", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"Returns the names of available CLIP models\"\"\"", "\n", "return", "list", "(", "_MODELS", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.load": [[75, 169], ["os.path.expanduser", "torch.jit.trace", "build_model().to.apply", "torch.cuda.is_available", "clip._download", "os.path.isfile", "torch.jit.load().eval", "model.build_model().to", "hasattr", "str", "torch.jit.trace", "float_input.node", "build_model().to.apply", "clip.load.patch_float"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip._download"], ["", "def", "load", "(", "\n", "name", ":", "str", ",", "\n", "root", ":", "str", "=", "os", ".", "path", ".", "expanduser", "(", "\"~/.cache/clip\"", ")", ",", "\n", "device", ":", "Union", "[", "str", ",", "torch", ".", "device", "]", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "jit", "=", "True", "\n", ")", ":", "\n", "    ", "\"\"\"Load a CLIP model\n\n    Parameters\n    ----------\n    name : str\n        A model name listed by `clip.available_models()`, or the path to a model checkpoint containing the state_dict\n\n    device : Union[str, torch.device]\n        The device to put the loaded model\n\n    jit : bool\n        Whether to load the optimized JIT model (default) or more hackable non-JIT model.\n\n    Returns\n    -------\n    model : torch.nn.Module\n        The CLIP model\n\n    preprocess : Callable[[PIL.Image], torch.Tensor]\n        A torchvision transform that converts a PIL image into a tensor that the returned model can take as its input\n    \"\"\"", "\n", "if", "name", "in", "_MODELS", ":", "\n", "        ", "model_path", "=", "_download", "(", "_MODELS", "[", "name", "]", ",", "root", "=", "root", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "name", ")", ":", "\n", "        ", "model_path", "=", "name", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Model {name} not found; available models = {available_models()}\"", ")", "\n", "\n", "", "try", ":", "\n", "# loading JIT archive", "\n", "        ", "model", "=", "torch", ".", "jit", ".", "load", "(", "model_path", ",", "map_location", "=", "device", "if", "jit", "else", "\"cpu\"", ")", ".", "eval", "(", ")", "\n", "state_dict", "=", "None", "\n", "", "except", "RuntimeError", ":", "\n", "# loading saved state dict", "\n", "        ", "if", "jit", ":", "\n", "            ", "warnings", ".", "warn", "(", "f\"File {model_path} is not a JIT archive. Loading as a state dict instead\"", ")", "\n", "jit", "=", "False", "\n", "", "state_dict", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "", "if", "not", "jit", ":", "\n", "        ", "model", "=", "build_model", "(", "state_dict", "or", "model", ".", "state_dict", "(", ")", ")", ".", "to", "(", "device", ")", "\n", "if", "str", "(", "device", ")", "==", "\"cpu\"", ":", "\n", "            ", "model", ".", "float", "(", ")", "\n", "", "return", "model", ",", "_transform", "(", "model", ".", "visual", ".", "input_resolution", ")", "\n", "\n", "# patch the device names", "\n", "", "device_holder", "=", "torch", ".", "jit", ".", "trace", "(", "lambda", ":", "torch", ".", "ones", "(", "[", "]", ")", ".", "to", "(", "torch", ".", "device", "(", "device", ")", ")", ",", "example_inputs", "=", "[", "]", ")", "\n", "device_node", "=", "[", "n", "for", "n", "in", "device_holder", ".", "graph", ".", "findAllNodes", "(", "\"prim::Constant\"", ")", "if", "\"Device\"", "in", "repr", "(", "n", ")", "]", "[", "-", "1", "]", "\n", "\n", "def", "patch_device", "(", "module", ")", ":", "\n", "        ", "graphs", "=", "[", "module", ".", "graph", "]", "if", "hasattr", "(", "module", ",", "\"graph\"", ")", "else", "[", "]", "\n", "if", "hasattr", "(", "module", ",", "\"forward1\"", ")", ":", "\n", "            ", "graphs", ".", "append", "(", "module", ".", "forward1", ".", "graph", ")", "\n", "\n", "", "for", "graph", "in", "graphs", ":", "\n", "            ", "for", "node", "in", "graph", ".", "findAllNodes", "(", "\"prim::Constant\"", ")", ":", "\n", "                ", "if", "\"value\"", "in", "node", ".", "attributeNames", "(", ")", "and", "str", "(", "node", "[", "\"value\"", "]", ")", ".", "startswith", "(", "\"cuda\"", ")", ":", "\n", "                    ", "node", ".", "copyAttributes", "(", "device_node", ")", "\n", "\n", "", "", "", "", "model", ".", "apply", "(", "patch_device", ")", "\n", "#patch_device(model.encode_image)", "\n", "#patch_device(model.encode_text)", "\n", "\n", "# patch dtype to float32 on CPU", "\n", "if", "str", "(", "device", ")", "==", "\"cpu\"", ":", "\n", "        ", "float_holder", "=", "torch", ".", "jit", ".", "trace", "(", "lambda", ":", "torch", ".", "ones", "(", "[", "]", ")", ".", "float", "(", ")", ",", "example_inputs", "=", "[", "]", ")", "\n", "float_input", "=", "list", "(", "float_holder", ".", "graph", ".", "findNode", "(", "\"aten::to\"", ")", ".", "inputs", "(", ")", ")", "[", "1", "]", "\n", "float_node", "=", "float_input", ".", "node", "(", ")", "\n", "\n", "def", "patch_float", "(", "module", ")", ":", "\n", "            ", "graphs", "=", "[", "module", ".", "graph", "]", "if", "hasattr", "(", "module", ",", "\"graph\"", ")", "else", "[", "]", "\n", "if", "hasattr", "(", "module", ",", "\"forward1\"", ")", ":", "\n", "                ", "graphs", ".", "append", "(", "module", ".", "forward1", ".", "graph", ")", "\n", "\n", "", "for", "graph", "in", "graphs", ":", "\n", "                ", "for", "node", "in", "graph", ".", "findAllNodes", "(", "\"aten::to\"", ")", ":", "\n", "                    ", "inputs", "=", "list", "(", "node", ".", "inputs", "(", ")", ")", "\n", "for", "i", "in", "[", "1", ",", "2", "]", ":", "# dtype can be the second or third argument to aten::to()", "\n", "                        ", "if", "inputs", "[", "i", "]", ".", "node", "(", ")", "[", "\"value\"", "]", "==", "5", ":", "\n", "                            ", "inputs", "[", "i", "]", ".", "node", "(", ")", ".", "copyAttributes", "(", "float_node", ")", "\n", "\n", "", "", "", "", "", "model", ".", "apply", "(", "patch_float", ")", "\n", "patch_float", "(", "model", ".", "encode_image", ")", "\n", "patch_float", "(", "model", ".", "encode_text", ")", "\n", "\n", "model", ".", "float", "(", ")", "\n", "\n", "", "return", "model", ",", "_transform", "(", "model", ".", "input_resolution", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.clip.tokenize": [[171, 207], ["isinstance", "torch.zeros", "enumerate", "len", "torch.tensor", "len", "_tokenizer.encode", "RuntimeError", "len"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.simple_tokenizer.SimpleTokenizer.encode"], ["", "def", "tokenize", "(", "texts", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ",", "context_length", ":", "int", "=", "77", ",", "as_list", "=", "False", ",", "truncate", ":", "bool", "=", "False", ")", "->", "torch", ".", "LongTensor", ":", "\n", "    ", "\"\"\"\n    Returns the tokenized representation of given input string(s)\n\n    Parameters\n    ----------\n    texts : Union[str, List[str]]\n        An input string or a list of input strings to tokenize\n\n    context_length : int\n        The context length to use; all CLIP models use 77 as the context length\n\n    Returns\n    -------\n    A two-dimensional tensor containing the resulting tokens, shape = [number of input strings, context_length]\n    \"\"\"", "\n", "if", "isinstance", "(", "texts", ",", "str", ")", ":", "\n", "        ", "texts", "=", "[", "texts", "]", "\n", "\n", "", "sot_token", "=", "_tokenizer", ".", "encoder", "[", "\"<|startoftext|>\"", "]", "\n", "eot_token", "=", "_tokenizer", ".", "encoder", "[", "\"<|endoftext|>\"", "]", "\n", "all_tokens", "=", "[", "[", "sot_token", "]", "+", "_tokenizer", ".", "encode", "(", "text", ")", "+", "[", "eot_token", "]", "for", "text", "in", "texts", "]", "\n", "if", "as_list", ":", "\n", "        ", "return", "all_tokens", "\n", "", "result", "=", "torch", ".", "zeros", "(", "len", "(", "all_tokens", ")", ",", "context_length", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "for", "i", ",", "tokens", "in", "enumerate", "(", "all_tokens", ")", ":", "\n", "        ", "if", "len", "(", "tokens", ")", ">", "context_length", ":", "\n", "            ", "if", "truncate", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "context_length", "]", "\n", "tokens", "[", "-", "1", "]", "=", "eot_token", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "f\"Input {texts[i]} is too long for context length {context_length}\"", ")", "\n", "", "", "result", "[", "i", ",", ":", "len", "(", "tokens", ")", "]", "=", "torch", ".", "tensor", "(", "tokens", ")", "\n", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.Bottleneck.__init__": [[14, 39], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Sequential", "torch.nn.Sequential", "collections.OrderedDict", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# all conv layers have stride 1. an avgpool is performed after the second convolution when stride > 1", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "stride", ")", "if", "stride", ">", "1", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "None", "\n", "self", ".", "stride", "=", "stride", "\n", "\n", "if", "stride", ">", "1", "or", "inplanes", "!=", "planes", "*", "Bottleneck", ".", "expansion", ":", "\n", "# downsampling layer is prepended with an avgpool, and the subsequent convolution has stride 1", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"-1\"", ",", "nn", ".", "AvgPool2d", "(", "stride", ")", ")", ",", "\n", "(", "\"0\"", ",", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", "*", "self", ".", "expansion", ",", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "\"1\"", ",", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", ")", "\n", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.Bottleneck.forward": [[41, 55], ["model.Bottleneck.relu", "model.Bottleneck.relu", "model.Bottleneck.avgpool", "model.Bottleneck.bn3", "model.Bottleneck.relu", "model.Bottleneck.bn1", "model.Bottleneck.bn2", "model.Bottleneck.conv3", "model.Bottleneck.downsample", "model.Bottleneck.conv1", "model.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "avgpool", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.AttentionPool2d.__init__": [[58, 66], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "spacial_dim", ":", "int", ",", "embed_dim", ":", "int", ",", "num_heads", ":", "int", ",", "output_dim", ":", "int", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "spacial_dim", "**", "2", "+", "1", ",", "embed_dim", ")", "/", "embed_dim", "**", "0.5", ")", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "c_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "output_dim", "or", "embed_dim", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.AttentionPool2d.forward": [[67, 92], ["torch.cat.reshape().permute", "torch.cat.reshape().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "model.AttentionPool2d.positional_embedding[].to", "torch.cat.reshape", "torch.cat.reshape", "torch.cat.mean", "torch.cat.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# NCHW -> (HW)NC", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ",", "x", "]", ",", "dim", "=", "0", ")", "# (HW+1)NC", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", "[", ":", ",", "None", ",", ":", "]", ".", "to", "(", "x", ".", "dtype", ")", "# (HW+1)NC", "\n", "x", ",", "_", "=", "F", ".", "multi_head_attention_forward", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "\n", "embed_dim_to_check", "=", "x", ".", "shape", "[", "-", "1", "]", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ",", "\n", "in_proj_weight", "=", "None", ",", "\n", "in_proj_bias", "=", "torch", ".", "cat", "(", "[", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", "]", ")", ",", "\n", "bias_k", "=", "None", ",", "\n", "bias_v", "=", "None", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "dropout_p", "=", "0", ",", "\n", "out_proj_weight", "=", "self", ".", "c_proj", ".", "weight", ",", "\n", "out_proj_bias", "=", "self", ".", "c_proj", ".", "bias", ",", "\n", "use_separate_proj_weight", "=", "True", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "need_weights", "=", "False", "\n", ")", "\n", "\n", "return", "x", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet.__init__": [[102, 126], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "model.ModifiedResNet._make_layer", "model.ModifiedResNet._make_layer", "model.ModifiedResNet._make_layer", "model.ModifiedResNet._make_layer", "model.AttentionPool2d"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer"], ["def", "__init__", "(", "self", ",", "layers", ",", "output_dim", ",", "heads", ",", "input_resolution", "=", "224", ",", "width", "=", "64", ",", "in_channels", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "input_resolution", "=", "input_resolution", "\n", "\n", "# the 3-layer stem", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "width", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "2", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "# residual layers", "\n", "self", ".", "_inplanes", "=", "width", "# this is a *mutable* variable used during construction", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "width", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "width", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "width", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "width", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n", "embed_dim", "=", "width", "*", "32", "# the ResNet feature dimension", "\n", "self", ".", "attnpool", "=", "AttentionPool2d", "(", "input_resolution", "//", "32", ",", "embed_dim", ",", "heads", ",", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet._make_layer": [[127, 135], ["range", "torch.nn.Sequential", "torch.nn.Sequential", "model.Bottleneck", "layers.append", "model.Bottleneck"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "layers", "=", "[", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ",", "stride", ")", "]", "\n", "\n", "self", ".", "_inplanes", "=", "planes", "*", "Bottleneck", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ModifiedResNet.forward": [[136, 152], ["model.ModifiedResNet.type", "model.ModifiedResNet.forward.stem"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "def", "stem", "(", "x", ")", ":", "\n", "            ", "for", "conv", ",", "bn", "in", "[", "(", "self", ".", "conv1", ",", "self", ".", "bn1", ")", ",", "(", "self", ".", "conv2", ",", "self", ".", "bn2", ")", ",", "(", "self", ".", "conv3", ",", "self", ".", "bn3", ")", "]", ":", "\n", "                ", "x", "=", "self", ".", "relu", "(", "bn", "(", "conv", "(", "x", ")", ")", ")", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "return", "x", "\n", "\n", "", "x", "=", "x", ".", "type", "(", "self", ".", "conv1", ".", "weight", ".", "dtype", ")", "\n", "x", "=", "stem", "(", "x", ")", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "x", "=", "self", ".", "attnpool", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.LayerNorm.forward": [[157, 161], ["super().forward", "super().forward.type", "x.type"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.forward"], ["def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "orig_type", "=", "x", ".", "dtype", "\n", "ret", "=", "super", "(", ")", ".", "forward", "(", "x", ".", "type", "(", "torch", ".", "float32", ")", ")", "\n", "return", "ret", ".", "type", "(", "orig_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.QuickGELU.forward": [[164, 166], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "sigmoid", "(", "1.702", "*", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ResidualAttentionBlock.__init__": [[169, 181], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "model.LayerNorm", "torch.nn.Sequential", "torch.nn.Sequential", "model.LayerNorm", "collections.OrderedDict", "torch.nn.Linear", "torch.nn.Linear", "model.QuickGELU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ":", "int", ",", "n_head", ":", "int", ",", "attn_mask", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "n_head", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"c_fc\"", ",", "nn", ".", "Linear", "(", "d_model", ",", "d_model", "*", "4", ")", ")", ",", "\n", "(", "\"gelu\"", ",", "QuickGELU", "(", ")", ")", ",", "\n", "(", "\"c_proj\"", ",", "nn", ".", "Linear", "(", "d_model", "*", "4", ",", "d_model", ")", ")", "\n", "]", ")", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ResidualAttentionBlock.attention": [[182, 185], ["model.ResidualAttentionBlock.attn_mask.to", "model.ResidualAttentionBlock.attn"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "self", ".", "attn_mask", "=", "self", ".", "attn_mask", ".", "to", "(", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "if", "self", ".", "attn_mask", "is", "not", "None", "else", "None", "\n", "return", "self", ".", "attn", "(", "x", ",", "x", ",", "x", ",", "need_weights", "=", "False", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ResidualAttentionBlock.forward": [[186, 190], ["model.ResidualAttentionBlock.attention", "model.ResidualAttentionBlock.mlp", "model.ResidualAttentionBlock.ln_1", "model.ResidualAttentionBlock.ln_2"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.ResidualAttentionBlock.attention"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "attention", "(", "self", ".", "ln_1", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.Transformer.__init__": [[193, 198], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "model.ResidualAttentionBlock", "range"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "width", ":", "int", ",", "layers", ":", "int", ",", "heads", ":", "int", ",", "attn_mask", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "resblocks", "=", "nn", ".", "Sequential", "(", "*", "[", "ResidualAttentionBlock", "(", "width", ",", "heads", ",", "attn_mask", ")", "for", "_", "in", "range", "(", "layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.Transformer.forward": [[199, 201], ["model.Transformer.resblocks"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "self", ".", "resblocks", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.VisualTransformer.__init__": [[204, 219], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "model.LayerNorm", "model.Transformer", "model.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_resolution", ":", "int", ",", "patch_size", ":", "int", ",", "width", ":", "int", ",", "layers", ":", "int", ",", "heads", ":", "int", ",", "output_dim", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_resolution", "=", "input_resolution", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "3", ",", "out_channels", "=", "width", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ",", "bias", "=", "False", ")", "\n", "\n", "scale", "=", "width", "**", "-", "0.5", "\n", "self", ".", "class_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ")", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "(", "input_resolution", "//", "patch_size", ")", "**", "2", "+", "1", ",", "width", ")", ")", "\n", "self", ".", "ln_pre", "=", "LayerNorm", "(", "width", ")", "\n", "\n", "self", ".", "transformer", "=", "Transformer", "(", "width", ",", "layers", ",", "heads", ")", "\n", "\n", "self", ".", "ln_post", "=", "LayerNorm", "(", "width", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ",", "output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.VisualTransformer.forward": [[220, 238], ["model.VisualTransformer.conv1", "model.VisualTransformer.reshape", "model.VisualTransformer.permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.VisualTransformer.ln_pre", "model.VisualTransformer.permute", "model.VisualTransformer.transformer", "model.VisualTransformer.permute", "model.VisualTransformer.ln_post", "model.VisualTransformer.positional_embedding.to", "model.VisualTransformer.class_embedding.to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "# shape = [*, width, grid, grid]", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "# shape = [*, width, grid ** 2]", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# shape = [*, grid ** 2, width]", "\n", "x", "=", "torch", ".", "cat", "(", "[", "self", ".", "class_embedding", ".", "to", "(", "x", ".", "dtype", ")", "+", "torch", ".", "zeros", "(", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ",", "x", "]", ",", "dim", "=", "1", ")", "# shape = [*, grid ** 2 + 1, width]", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", ".", "to", "(", "x", ".", "dtype", ")", "\n", "x", "=", "self", ".", "ln_pre", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# NLD -> LND", "\n", "x", "=", "self", ".", "transformer", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# LND -> NLD", "\n", "\n", "x", "=", "self", ".", "ln_post", "(", "x", "[", ":", ",", "0", ",", ":", "]", ")", "\n", "\n", "if", "self", ".", "proj", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "@", "self", ".", "proj", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__": [[241, 295], ["torch.nn.Module.__init__", "isinstance", "model.Transformer", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "model.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "model.CLIP.initialize_parameters", "model.ModifiedResNet", "model.VisualTransformer", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "model.CLIP.build_attention_mask", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.__init__", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.build_attention_mask"], ["    ", "def", "__init__", "(", "self", ",", "\n", "embed_dim", ":", "int", ",", "\n", "# vision", "\n", "image_resolution", ":", "int", ",", "\n", "vision_layers", ":", "Union", "[", "Tuple", "[", "int", ",", "int", ",", "int", ",", "int", "]", ",", "int", "]", ",", "\n", "vision_width", ":", "int", ",", "\n", "vision_patch_size", ":", "int", ",", "\n", "# text", "\n", "context_length", ":", "int", ",", "\n", "vocab_size", ":", "int", ",", "\n", "transformer_width", ":", "int", ",", "\n", "transformer_heads", ":", "int", ",", "\n", "transformer_layers", ":", "int", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "context_length", "=", "context_length", "\n", "\n", "if", "isinstance", "(", "vision_layers", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "vision_heads", "=", "vision_width", "*", "32", "//", "64", "\n", "self", ".", "visual", "=", "ModifiedResNet", "(", "\n", "layers", "=", "vision_layers", ",", "\n", "output_dim", "=", "embed_dim", ",", "\n", "heads", "=", "vision_heads", ",", "\n", "input_resolution", "=", "image_resolution", ",", "\n", "width", "=", "vision_width", "\n", ")", "\n", "", "else", ":", "\n", "            ", "vision_heads", "=", "vision_width", "//", "64", "\n", "self", ".", "visual", "=", "VisualTransformer", "(", "\n", "input_resolution", "=", "image_resolution", ",", "\n", "patch_size", "=", "vision_patch_size", ",", "\n", "width", "=", "vision_width", ",", "\n", "layers", "=", "vision_layers", ",", "\n", "heads", "=", "vision_heads", ",", "\n", "output_dim", "=", "embed_dim", "\n", ")", "\n", "\n", "", "self", ".", "transformer", "=", "Transformer", "(", "\n", "width", "=", "transformer_width", ",", "\n", "layers", "=", "transformer_layers", ",", "\n", "heads", "=", "transformer_heads", ",", "\n", "attn_mask", "=", "self", ".", "build_attention_mask", "(", ")", "\n", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "token_embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "transformer_width", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "self", ".", "context_length", ",", "transformer_width", ")", ")", "\n", "self", ".", "ln_final", "=", "LayerNorm", "(", "transformer_width", ")", "\n", "\n", "self", ".", "text_projection", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "transformer_width", ",", "embed_dim", ")", ")", "\n", "self", ".", "logit_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "\n", "\n", "self", ".", "initialize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.initialize_parameters": [[296, 324], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "isinstance", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "resnet_block.named_parameters", "name.endswith", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "initialize_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "token_embedding", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "positional_embedding", ",", "std", "=", "0.01", ")", "\n", "\n", "if", "isinstance", "(", "self", ".", "visual", ",", "ModifiedResNet", ")", ":", "\n", "            ", "if", "self", ".", "visual", ".", "attnpool", "is", "not", "None", ":", "\n", "                ", "std", "=", "self", ".", "visual", ".", "attnpool", ".", "c_proj", ".", "in_features", "**", "-", "0.5", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "visual", ".", "attnpool", ".", "q_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "visual", ".", "attnpool", ".", "k_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "visual", ".", "attnpool", ".", "v_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "visual", ".", "attnpool", ".", "c_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "\n", "", "for", "resnet_block", "in", "[", "self", ".", "visual", ".", "layer1", ",", "self", ".", "visual", ".", "layer2", ",", "self", ".", "visual", ".", "layer3", ",", "self", ".", "visual", ".", "layer4", "]", ":", "\n", "                ", "for", "name", ",", "param", "in", "resnet_block", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "name", ".", "endswith", "(", "\"bn3.weight\"", ")", ":", "\n", "                        ", "nn", ".", "init", ".", "zeros_", "(", "param", ")", "\n", "\n", "", "", "", "", "proj_std", "=", "(", "self", ".", "transformer", ".", "width", "**", "-", "0.5", ")", "*", "(", "(", "2", "*", "self", ".", "transformer", ".", "layers", ")", "**", "-", "0.5", ")", "\n", "attn_std", "=", "self", ".", "transformer", ".", "width", "**", "-", "0.5", "\n", "fc_std", "=", "(", "2", "*", "self", ".", "transformer", ".", "width", ")", "**", "-", "0.5", "\n", "for", "block", "in", "self", ".", "transformer", ".", "resblocks", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "block", ".", "attn", ".", "in_proj_weight", ",", "std", "=", "attn_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "attn", ".", "out_proj", ".", "weight", ",", "std", "=", "proj_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "mlp", ".", "c_fc", ".", "weight", ",", "std", "=", "fc_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "mlp", ".", "c_proj", ".", "weight", ",", "std", "=", "proj_std", ")", "\n", "\n", "", "if", "self", ".", "text_projection", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "text_projection", ",", "std", "=", "self", ".", "transformer", ".", "width", "**", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.build_attention_mask": [[325, 332], ["torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.fill_", "torch.empty.fill_", "torch.empty.triu_", "torch.empty.triu_", "float"], "methods", ["None"], ["", "", "def", "build_attention_mask", "(", "self", ")", ":", "\n", "# lazily create causal attention mask, with full attention between the vision tokens", "\n", "# pytorch uses additive attention mask; fill with -inf", "\n", "        ", "mask", "=", "torch", ".", "empty", "(", "self", ".", "context_length", ",", "self", ".", "context_length", ")", "\n", "mask", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "mask", ".", "triu_", "(", "1", ")", "# zero out the lower diagonal", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.dtype": [[333, 336], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "visual", ".", "conv1", ".", "weight", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_image": [[337, 339], ["model.CLIP.visual", "image.type"], "methods", ["None"], ["", "def", "encode_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "return", "self", ".", "visual", "(", "image", ".", "type", "(", "self", ".", "dtype", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_text": [[340, 354], ["model.CLIP.token_embedding().type", "model.CLIP.permute", "model.CLIP.transformer", "model.CLIP.permute", "model.CLIP.ln_final().type", "model.CLIP.positional_embedding.type", "model.CLIP.token_embedding", "model.CLIP.ln_final", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "text.argmax"], "methods", ["None"], ["", "def", "encode_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "x", "=", "self", ".", "token_embedding", "(", "text", ")", ".", "type", "(", "self", ".", "dtype", ")", "# [batch_size, n_ctx, d_model]", "\n", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", ".", "type", "(", "self", ".", "dtype", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# NLD -> LND", "\n", "x", "=", "self", ".", "transformer", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# LND -> NLD", "\n", "x", "=", "self", ".", "ln_final", "(", "x", ")", ".", "type", "(", "self", ".", "dtype", ")", "\n", "\n", "# x.shape = [batch_size, n_ctx, transformer.width]", "\n", "# take features from the eot embedding (eot_token is the highest number in each sequence)", "\n", "x", "=", "x", "[", "torch", ".", "arange", "(", "x", ".", "shape", "[", "0", "]", ")", ",", "text", ".", "argmax", "(", "dim", "=", "-", "1", ")", "]", "@", "self", ".", "text_projection", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.forward": [[355, 370], ["model.CLIP.encode_image", "model.CLIP.encode_text", "model.CLIP.logit_scale.exp", "model.CLIP.norm", "model.CLIP.norm", "model.CLIP.t", "model.CLIP.t"], "methods", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_image", "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.CLIP.encode_text"], ["", "def", "forward", "(", "self", ",", "image", ",", "text", ")", ":", "\n", "        ", "image_features", "=", "self", ".", "encode_image", "(", "image", ")", "\n", "text_features", "=", "self", ".", "encode_text", "(", "text", ")", "\n", "\n", "# normalized features", "\n", "image_features", "=", "image_features", "/", "image_features", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "text_features", "=", "text_features", "/", "text_features", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# cosine similarity as logits", "\n", "logit_scale", "=", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "logits_per_image", "=", "logit_scale", "*", "image_features", "@", "text_features", ".", "t", "(", ")", "\n", "logits_per_text", "=", "logit_scale", "*", "text_features", "@", "image_features", ".", "t", "(", ")", "\n", "\n", "# shape = [global_batch_size, global_batch_size]", "\n", "return", "logits_per_image", ",", "logits_per_text", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.convert_weights": [[372, 394], ["model.apply", "isinstance", "isinstance", "l.weight.data.half", "hasattr", "l.bias.data.half", "getattr", "getattr", "getattr.data.half", "getattr.data.half"], "function", ["None"], ["", "", "def", "convert_weights", "(", "model", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Convert applicable model parameters to fp16\"\"\"", "\n", "\n", "def", "_convert_weights_to_fp16", "(", "l", ")", ":", "\n", "        ", "if", "isinstance", "(", "l", ",", "(", "nn", ".", "Conv1d", ",", "nn", ".", "Conv2d", ",", "nn", ".", "Linear", ")", ")", ":", "\n", "            ", "l", ".", "weight", ".", "data", "=", "l", ".", "weight", ".", "data", ".", "half", "(", ")", "\n", "if", "l", ".", "bias", "is", "not", "None", ":", "\n", "                ", "l", ".", "bias", ".", "data", "=", "l", ".", "bias", ".", "data", ".", "half", "(", ")", "\n", "\n", "", "", "if", "isinstance", "(", "l", ",", "nn", ".", "MultiheadAttention", ")", ":", "\n", "            ", "for", "attr", "in", "[", "*", "[", "f\"{s}_proj_weight\"", "for", "s", "in", "[", "\"in\"", ",", "\"q\"", ",", "\"k\"", ",", "\"v\"", "]", "]", ",", "\"in_proj_bias\"", ",", "\"bias_k\"", ",", "\"bias_v\"", "]", ":", "\n", "                ", "tensor", "=", "getattr", "(", "l", ",", "attr", ")", "\n", "if", "tensor", "is", "not", "None", ":", "\n", "                    ", "tensor", ".", "data", "=", "tensor", ".", "data", ".", "half", "(", ")", "\n", "\n", "", "", "", "for", "name", "in", "[", "\"text_projection\"", ",", "\"proj\"", "]", ":", "\n", "            ", "if", "hasattr", "(", "l", ",", "name", ")", ":", "\n", "                ", "attr", "=", "getattr", "(", "l", ",", "name", ")", "\n", "if", "attr", "is", "not", "None", ":", "\n", "                    ", "attr", ".", "data", "=", "attr", ".", "data", ".", "half", "(", ")", "\n", "\n", "", "", "", "", "model", ".", "apply", "(", "_convert_weights_to_fp16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.build_model": [[396, 434], ["len", "model.CLIP", "model.convert_weights", "CLIP.load_state_dict", "CLIP.eval", "len", "round", "tuple", "round", "set", "len", "set", "state_dict.keys", "k.split", "k.startswith", "k.startswith", "k.endswith", "k.split", "k.startswith"], "function", ["home.repos.pwc.inspect_result.zhaoyanpeng_vipant.clip.model.convert_weights"], ["", "def", "build_model", "(", "state_dict", ":", "dict", ")", ":", "\n", "    ", "vit", "=", "\"visual.proj\"", "in", "state_dict", "\n", "\n", "if", "vit", ":", "\n", "        ", "vision_width", "=", "state_dict", "[", "\"visual.conv1.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "vision_layers", "=", "len", "(", "[", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "if", "k", ".", "startswith", "(", "\"visual.\"", ")", "and", "k", ".", "endswith", "(", "\".attn.in_proj_weight\"", ")", "]", ")", "\n", "vision_patch_size", "=", "state_dict", "[", "\"visual.conv1.weight\"", "]", ".", "shape", "[", "-", "1", "]", "\n", "grid_size", "=", "round", "(", "(", "state_dict", "[", "\"visual.positional_embedding\"", "]", ".", "shape", "[", "0", "]", "-", "1", ")", "**", "0.5", ")", "\n", "image_resolution", "=", "vision_patch_size", "*", "grid_size", "\n", "", "else", ":", "\n", "        ", "counts", ":", "list", "=", "[", "len", "(", "set", "(", "k", ".", "split", "(", "\".\"", ")", "[", "2", "]", "for", "k", "in", "state_dict", "if", "k", ".", "startswith", "(", "f\"visual.layer{b}\"", ")", ")", ")", "for", "b", "in", "[", "1", ",", "2", ",", "3", ",", "4", "]", "]", "\n", "vision_layers", "=", "tuple", "(", "counts", ")", "\n", "vision_width", "=", "state_dict", "[", "\"visual.layer1.0.conv1.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "output_width", "=", "round", "(", "(", "state_dict", "[", "\"visual.attnpool.positional_embedding\"", "]", ".", "shape", "[", "0", "]", "-", "1", ")", "**", "0.5", ")", "\n", "vision_patch_size", "=", "None", "\n", "assert", "output_width", "**", "2", "+", "1", "==", "state_dict", "[", "\"visual.attnpool.positional_embedding\"", "]", ".", "shape", "[", "0", "]", "\n", "image_resolution", "=", "output_width", "*", "32", "\n", "\n", "", "embed_dim", "=", "state_dict", "[", "\"text_projection\"", "]", ".", "shape", "[", "1", "]", "\n", "context_length", "=", "state_dict", "[", "\"positional_embedding\"", "]", ".", "shape", "[", "0", "]", "\n", "vocab_size", "=", "state_dict", "[", "\"token_embedding.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "transformer_width", "=", "state_dict", "[", "\"ln_final.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "transformer_heads", "=", "transformer_width", "//", "64", "\n", "transformer_layers", "=", "len", "(", "set", "(", "k", ".", "split", "(", "\".\"", ")", "[", "2", "]", "for", "k", "in", "state_dict", "if", "k", ".", "startswith", "(", "f\"transformer.resblocks\"", ")", ")", ")", "\n", "\n", "model", "=", "CLIP", "(", "\n", "embed_dim", ",", "\n", "image_resolution", ",", "vision_layers", ",", "vision_width", ",", "vision_patch_size", ",", "\n", "context_length", ",", "vocab_size", ",", "transformer_width", ",", "transformer_heads", ",", "transformer_layers", "\n", ")", "\n", "\n", "for", "key", "in", "[", "\"input_resolution\"", ",", "\"context_length\"", ",", "\"vocab_size\"", "]", ":", "\n", "        ", "if", "key", "in", "state_dict", ":", "\n", "            ", "del", "state_dict", "[", "key", "]", "\n", "\n", "", "", "convert_weights", "(", "model", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "model", ".", "eval", "(", ")", "\n", "", ""]]}