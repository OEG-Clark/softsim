{"home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaep.recall_f1": [[123, 138], ["len", "range", "metric.f1_metric", "len", "len", "len", "sum", "len", "preds.append", "len", "len", "score.index", "max"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.f1_metric"], ["", "def", "recall_f1", "(", "scores", ",", "knowledges", ",", "responses", ")", ":", "\n", "    ", "count", "=", "[", "len", "(", "k", ")", "for", "k", "in", "knowledges", "]", "\n", "# all equals to the numbert of context", "\n", "assert", "len", "(", "knowledges", ")", "==", "len", "(", "responses", ")", "\n", "# all equals to the total number of knowledge sentences in every case", "\n", "assert", "sum", "(", "count", ")", "==", "len", "(", "scores", ")", "\n", "n", "=", "len", "(", "knowledges", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "len", "(", "knowledges", "[", "i", "]", ")", "]", "\n", "scores", "=", "scores", "[", "len", "(", "knowledges", "[", "i", "]", ")", ":", "]", "\n", "knowledge", "=", "knowledges", "[", "i", "]", "\n", "pred", "=", "knowledge", "[", "score", ".", "index", "(", "max", "(", "score", ")", ")", "]", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "return", "f1_metric", "(", "preds", ",", "responses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaep.recall_metric": [[140, 168], ["range", "open", "json.load", "open", "json.load", "len", "numpy.array().sum", "len", "len", "len", "numpy.argsort", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "recall_metric", "(", "scores", ")", ":", "\n", "    ", "r1", ",", "r2", ",", "r5", ",", "r10", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "#count_path=r'/home/futc/cmudog/'+'train'+'_knowledge_count.json'", "\n", "#label_path=r'/home/futc/cmudog/'+'train'+'_label_index.json'", "\n", "with", "open", "(", "args", ".", "count_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "knowledge_count", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "args", ".", "label_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "label", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "assert", "len", "(", "scores", ")", "==", "np", ".", "array", "(", "knowledge_count", ")", ".", "sum", "(", ")", "\n", "assert", "len", "(", "knowledge_count", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "knowledge_count", ")", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "knowledge_count", "[", "i", "]", "]", "\n", "scores", "=", "scores", "[", "knowledge_count", "[", "i", "]", ":", "]", "\n", "order", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "gold", "=", "label", "[", "i", "]", "\n", "#gold=0 if correct_first else label[i]", "\n", "if", "gold", "in", "order", "[", ":", "1", "]", ":", "\n", "            ", "r1", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "2", "]", ":", "\n", "            ", "r2", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "5", "]", ":", "\n", "            ", "r5", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "10", "]", ":", "\n", "            ", "r10", "+=", "1", "\n", "\n", "", "", "return", "r1", "/", "len", "(", "knowledge_count", ")", ",", "r2", "/", "len", "(", "knowledge_count", ")", ",", "r5", "/", "len", "(", "knowledge_count", ")", ",", "r10", "/", "len", "(", "knowledge_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaep.train_step": [[245, 283], ["semip_model.eval", "priorp_model.train", "range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "priorp_optimizer.step", "priorp_scheduler.step", "priorp_optimizer.zero_grad", "next", "batcher.load", "batcher", "torch.kl_div", "F.kl_div.item", "F.kl_div.backward", "logger.info", "datetime.datetime.now().strftime", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "batcher", "priorp_model", "prior_plogits.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "semip_model", "semi_plogits.view", "input_id.dim", "semip_model.parameters", "datetime.datetime.now", "input_id.dim", "input_id.view", "segment_id.view", "input_id.view", "segment_id.view", "input_id.view", "semip_scheduler.get_lr", "input_id.view"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "train_step", "(", "global_step", ")", ":", "\n", "    ", "klloss_total", "=", "0.0", "\n", "semip_model", ".", "eval", "(", ")", "\n", "priorp_model", ".", "train", "(", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "accum_step", ")", ":", "\n", "        ", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "=", "next", "(", "train_loader", ")", "\n", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'p|cr'", ",", "None", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "semi_plogits", "=", "semip_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "semi_plogits", "=", "semi_plogits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "", "batch_dict", "=", "batcher", "(", "'p|c'", ",", "None", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "prior_plogits", "=", "priorp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "prior_plogits", "=", "prior_plogits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "klloss", "=", "F", ".", "kl_div", "(", "torch", ".", "log_softmax", "(", "prior_plogits", ",", "dim", "=", "1", ")", ",", "torch", ".", "softmax", "(", "semi_plogits", ",", "dim", "=", "1", ")", ")", "\n", "klloss_total", "+=", "klloss", ".", "item", "(", ")", "\n", "klloss", "=", "klloss", "/", "args", ".", "accum_step", "\n", "klloss", ".", "backward", "(", ")", "\n", "\n", "", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "semip_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "if", "grad_norm", ">=", "1e2", ":", "\n", "        ", "logger", ".", "info", "(", "'WARNING : Exploding Gradients {:.2f}'", ".", "format", "(", "grad_norm", ")", ")", "\n", "", "priorp_optimizer", ".", "step", "(", ")", "\n", "priorp_scheduler", ".", "step", "(", ")", "\n", "priorp_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "print_every", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "        ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "logger", ".", "info", "(", "\"Step: %d \\t| ks_loss: %.3f \\t| lr: %.8f \\t| %s\"", "%", "(", "\n", "global_step", ",", "klloss_total", ",", "semip_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "time_str", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaep.predict_step": [[285, 340], ["priorp_model.eval", "priorp_model.save_pretrained", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "os.path.join", "open", "batcher.load", "batcher", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "os.path.join", "f.write", "priorp_model", "logits.view", "logger.info", "torch.topk", "torch.topk", "torch.topk", "hyp.detach().cpu().tolist.detach().cpu().tolist", "range", "input_id.dim", "persona_list[].index", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "hypothesis.append", "logger.info", "input_id.view", "segment_id.view", "range", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "hyp.detach().cpu().tolist.detach().cpu", "input_id.view", "hyp.detach().cpu().tolist.detach", "min", "len"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "", "def", "predict_step", "(", "global_step", ")", ":", "\n", "#if split == 'test_seen':", "\n", "#    test_loader = test_seen_loader", "\n", "#else:", "\n", "#    raise ValueError", "\n", "    ", "hypothesis", "=", "[", "]", "\n", "priorp_model", ".", "eval", "(", ")", "\n", "count", "=", "0", "\n", "hit1", "=", "0", "\n", "hit2", "=", "0", "\n", "hit5", "=", "0", "\n", "hit10", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "\n", "batch_dict", "=", "batcher", "(", "'p|c'", ",", "None", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "priorp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "bs", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "bs", "=", "len", "(", "context_list", ")", "\n", "ref", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "# when only selected one persona", "\n", "# hyp=torch.max(logits,dim=1)[1]", "\n", "# hit1+=torch.sum(hyp==ref,dim=0).item()", "\n", "# when select multi", "\n", "#(bs,k)", "\n", "hyp", "=", "torch", ".", "topk", "(", "logits", ",", "k", "=", "10", ")", "[", "1", "]", "\n", "hit1", "+=", "torch", ".", "sum", "(", "torch", ".", "sum", "(", "hyp", "[", ":", ",", ":", "1", "]", "==", "ref", "[", ":", ",", "None", "]", ",", "dim", "=", "1", ")", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "hit2", "+=", "torch", ".", "sum", "(", "torch", ".", "sum", "(", "hyp", "[", ":", ",", ":", "2", "]", "==", "ref", "[", ":", ",", "None", "]", ",", "dim", "=", "1", ")", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "hit5", "+=", "torch", ".", "sum", "(", "torch", ".", "sum", "(", "hyp", "[", ":", ",", ":", "5", "]", "==", "ref", "[", ":", ",", "None", "]", ",", "dim", "=", "1", ")", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "hit10", "+=", "torch", ".", "sum", "(", "torch", ".", "sum", "(", "hyp", "[", ":", ",", ":", "10", "]", "==", "ref", "[", ":", ",", "None", "]", ",", "dim", "=", "1", ")", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "try", ":", "\n", "                ", "hyp", "=", "hyp", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                    ", "hypothesis", ".", "append", "(", "'<#p#>'", ".", "join", "(", "[", "persona_list", "[", "i", "]", "[", "min", "(", "j", ",", "len", "(", "persona_list", "[", "i", "]", ")", "-", "1", ")", "]", "for", "j", "in", "hyp", "[", "i", "]", "]", ")", ")", "\n", "", "", "except", ":", "\n", "                ", "logger", ".", "info", "(", "\"error when decoding hypothesis\"", ")", "\n", "\n", "", "", "", "priorp_model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_priorp_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Saved model checkpoint \\n\"", ")", "\n", "logger", ".", "info", "(", "\"hit at 1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 2 is {:.4f}\"", ".", "format", "(", "hit2", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 5 is {:.4f}\"", ".", "format", "(", "hit5", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 10 is {:.4f}\"", ".", "format", "(", "hit10", "/", "count", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_persona'", ".", "format", "(", "global_step", ")", ")", ",", "mode", "=", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "hyp", "in", "hypothesis", ":", "\n", "            ", "f", ".", "write", "(", "hyp", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.distill.recall_f1": [[129, 144], ["len", "range", "metric.f1_metric", "len", "len", "len", "sum", "len", "preds.append", "len", "len", "score.index", "max"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.f1_metric"], ["", "def", "recall_f1", "(", "scores", ",", "knowledges", ",", "responses", ")", ":", "\n", "    ", "count", "=", "[", "len", "(", "k", ")", "for", "k", "in", "knowledges", "]", "\n", "# all equals to the numbert of context", "\n", "assert", "len", "(", "knowledges", ")", "==", "len", "(", "responses", ")", "\n", "# all equals to the total number of knowledge sentences in every case", "\n", "assert", "sum", "(", "count", ")", "==", "len", "(", "scores", ")", "\n", "n", "=", "len", "(", "knowledges", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "len", "(", "knowledges", "[", "i", "]", ")", "]", "\n", "scores", "=", "scores", "[", "len", "(", "knowledges", "[", "i", "]", ")", ":", "]", "\n", "knowledge", "=", "knowledges", "[", "i", "]", "\n", "pred", "=", "knowledge", "[", "score", ".", "index", "(", "max", "(", "score", ")", ")", "]", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "return", "f1_metric", "(", "preds", ",", "responses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.distill.recall_metric": [[146, 174], ["range", "open", "json.load", "open", "json.load", "len", "numpy.array().sum", "len", "len", "len", "numpy.argsort", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "recall_metric", "(", "scores", ")", ":", "\n", "    ", "r1", ",", "r2", ",", "r5", ",", "r10", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "#count_path=r'/home/futc/cmudog/'+'train'+'_knowledge_count.json'", "\n", "#label_path=r'/home/futc/cmudog/'+'train'+'_label_index.json'", "\n", "with", "open", "(", "args", ".", "count_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "knowledge_count", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "args", ".", "label_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "label", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "assert", "len", "(", "scores", ")", "==", "np", ".", "array", "(", "knowledge_count", ")", ".", "sum", "(", ")", "\n", "assert", "len", "(", "knowledge_count", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "knowledge_count", ")", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "knowledge_count", "[", "i", "]", "]", "\n", "scores", "=", "scores", "[", "knowledge_count", "[", "i", "]", ":", "]", "\n", "order", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "gold", "=", "label", "[", "i", "]", "\n", "#gold=0 if correct_first else label[i]", "\n", "if", "gold", "in", "order", "[", ":", "1", "]", ":", "\n", "            ", "r1", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "2", "]", ":", "\n", "            ", "r2", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "5", "]", ":", "\n", "            ", "r5", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "10", "]", ":", "\n", "            ", "r10", "+=", "1", "\n", "\n", "", "", "return", "r1", "/", "len", "(", "knowledge_count", ")", ",", "r2", "/", "len", "(", "knowledge_count", ")", ",", "r5", "/", "len", "(", "knowledge_count", ")", ",", "r10", "/", "len", "(", "knowledge_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.distill.train_step": [[249, 294], ["dualkp_model.eval", "semip_model.train", "range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "semip_optimizer.step", "semip_scheduler.step", "semip_optimizer.zero_grad", "next", "batcher.load", "batcher", "torch.tensor", "torch.tensor", "torch.tensor", "loss.item", "loss.backward", "logger.info", "datetime.datetime.now().strftime", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "batcher", "semip_model", "semi_plogits.view", "dualkp_model", "post_plogits.view", "input_id.dim", "persona_list[].index", "semip_model.parameters", "datetime.datetime.now", "input_id.dim", "input_id.view", "segment_id.view", "range", "torch.cross_entropy", "input_id.view", "segment_id.view", "input_id.view", "len", "torch.KLDivLoss", "torch.log_softmax", "torch.softmax", "semip_scheduler.get_lr", "input_id.view"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "train_step", "(", "global_step", ")", ":", "\n", "    ", "distill_loss_total", "=", "0.0", "\n", "dualkp_model", ".", "eval", "(", ")", "\n", "semip_model", ".", "train", "(", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "accum_step", ")", ":", "\n", "#torch.cuda.empty_cache()", "\n", "        ", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "=", "next", "(", "train_loader", ")", "\n", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'p|crk'", ",", "klabel_list", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "post_plogits", "=", "dualkp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "post_plogits", "=", "post_plogits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "", "batch_dict", "=", "batcher", "(", "'p|cr'", ",", "None", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "semi_plogits", "=", "semip_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "semi_plogits", "=", "semi_plogits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "persona_list", ")", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "if", "args", ".", "loss", "==", "'standard'", ":", "\n", "            ", "loss", "=", "F", ".", "cross_entropy", "(", "semi_plogits", ",", "target", ")", "*", "(", "1", "-", "args", ".", "alpha", ")", "+", "nn", ".", "KLDivLoss", "(", ")", "(", "F", ".", "log_softmax", "(", "semi_plogits", "/", "args", ".", "temperature", ",", "dim", "=", "1", ")", ",", "F", ".", "softmax", "(", "post_plogits", "/", "args", ".", "temperature", ",", "dim", "=", "1", ")", ")", "*", "(", "args", ".", "alpha", "*", "args", ".", "temperature", "*", "args", ".", "temperature", ")", "\n", "", "else", ":", "\n", "#TODO: other kinds of ", "\n", "            ", "raise", "NotImplementedError", "\n", "", "distill_loss_total", "+=", "loss", ".", "item", "(", ")", "\n", "loss", "=", "loss", "/", "args", ".", "accum_step", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "semip_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "if", "grad_norm", ">=", "1e2", ":", "\n", "        ", "logger", ".", "info", "(", "'WARNING : Exploding Gradients {:.2f}'", ".", "format", "(", "grad_norm", ")", ")", "\n", "", "semip_optimizer", ".", "step", "(", ")", "\n", "semip_scheduler", ".", "step", "(", ")", "\n", "semip_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "print_every", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "        ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "logger", ".", "info", "(", "\"Step: %d \\t| ks_loss: %.3f \\t| lr: %.8f \\t| %s\"", "%", "(", "\n", "global_step", ",", "distill_loss_total", ",", "semip_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "time_str", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.distill.predict_step": [[296, 339], ["semip_model.eval", "logger.info", "logger.info", "logger.info", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "semip_model.save_pretrained", "logger.info", "batcher.load", "batcher", "len", "torch.tensor", "torch.tensor", "torch.tensor", "os.path.join", "semip_model", "logits.view", "logger.info", "torch.topk", "torch.topk", "torch.topk", "input_id.dim", "persona_list[].index", "input_id.view", "segment_id.view", "range", "input_id.view"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "", "def", "predict_step", "(", "global_step", ")", ":", "\n", "#if split == 'test_seen':", "\n", "#    test_loader = test_seen_loader", "\n", "#else:", "\n", "#    raise ValueError", "\n", "    ", "semip_model", ".", "eval", "(", ")", "\n", "labels", ",", "scores", "=", "[", "]", ",", "[", "]", "\n", "count", "=", "0", "\n", "hit1", "=", "0", "\n", "hit2", "=", "0", "\n", "hit5", "=", "0", "\n", "hit10", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "batch_dict", "=", "batcher", "(", "'p|cr'", ",", "None", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "semip_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "bs", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "bs", "=", "len", "(", "context_list", ")", "\n", "ref", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "hyp", "=", "torch", ".", "topk", "(", "logits", ",", "k", "=", "10", ")", "[", "1", "]", "\n", "\n", "hit1", "+=", "(", "hyp", "[", ":", ",", ":", "1", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit2", "+=", "(", "hyp", "[", ":", ",", ":", "2", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit5", "+=", "(", "hyp", "[", ":", ",", ":", "5", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit10", "+=", "(", "hyp", "[", ":", ",", ":", "10", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "\n", "", "", "if", "not", "args", ".", "predict", ":", "\n", "        ", "semip_model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_semip_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Saved model checkpoint \\n\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"hit at 1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 2 is {:.4f}\"", ".", "format", "(", "hit2", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 5 is {:.4f}\"", ".", "format", "(", "hit5", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 10 is {:.4f}\"", ".", "format", "(", "hit10", "/", "count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.PersonaDataset.__init__": [[120, 168], ["torch.utils.data.Dataset.__init__", "os.listdir", "logger.info", "open", "open", "open", "open", "json.load", "json.load", "zip", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open.readlines", "open.readlines", "json.loads", "json.loads", "pretrain_dual.PersonaDataset.examples.append", "len"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["    ", "def", "__init__", "(", "self", ",", "convo_path", ",", "persona_path", ",", "knowledge_path", ",", "pseudo_path", ",", "mode", ",", "n_knowledge", ",", "n_persona", ",", "debug", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "PersonaDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "examples", "=", "[", "]", "\n", "self", ".", "n_knowledge", "=", "n_knowledge", "\n", "self", ".", "n_persona", "=", "n_persona", "\n", "assert", "mode", "in", "[", "'train'", ",", "'eval'", "]", "\n", "for", "date", "in", "os", ".", "listdir", "(", "convo_path", ")", ":", "\n", "            ", "if", "(", "date", "==", "'2015-05'", "or", "date", "==", "'2015-06'", ")", "and", "mode", "==", "'train'", ":", "\n", "                ", "continue", "\n", "", "if", "mode", "==", "'eval'", "and", "date", "!=", "'2015-05'", ":", "\n", "                ", "continue", "\n", "", "fconvo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "convo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fper", "=", "open", "(", "os", ".", "path", ".", "join", "(", "persona_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fknow", "=", "open", "(", "os", ".", "path", ".", "join", "(", "knowledge_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fpseudo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "pseudo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "know_dict", "=", "json", ".", "load", "(", "fknow", ")", "\n", "per_dict", "=", "json", ".", "load", "(", "fper", ")", "\n", "for", "line1", ",", "line2", "in", "zip", "(", "fconvo", ".", "readlines", "(", ")", ",", "fpseudo", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "data", "=", "json", ".", "loads", "(", "line1", ")", "\n", "author", "=", "data", "[", "'author'", "]", "[", "-", "1", "]", "\n", "sid", "=", "data", "[", "'sid'", "]", "\n", "label", "=", "json", ".", "loads", "(", "line2", ")", "\n", "\n", "# persona=per_dict[author].copy()", "\n", "# persona.pop(persona.index(label['plabel']))", "\n", "# persona=persona[:self.n_persona-1]", "\n", "# persona.append(label['plabel'])", "\n", "# random.shuffle(persona)", "\n", "\n", "# knowledge=know_dict[sid].copy()", "\n", "# knowledge.pop(knowledge.index(label['klabel']))", "\n", "# knowledge=knowledge[:self.n_knowledge-1]", "\n", "# knowledge.append(label['klabel'])", "\n", "# random.shuffle(knowledge)", "\n", "\n", "self", ".", "examples", ".", "append", "(", "{", "\n", "'context'", ":", "data", "[", "'dialog'", "]", "[", ":", "-", "1", "]", ",", "\n", "'response'", ":", "data", "[", "'dialog'", "]", "[", "-", "1", "]", ",", "\n", "'knowledge'", ":", "know_dict", "[", "sid", "]", ",", "\n", "'persona'", ":", "per_dict", "[", "author", "]", ",", "\n", "'klabel'", ":", "label", "[", "'klabel'", "]", ",", "\n", "'plabel'", ":", "label", "[", "'plabel'", "]", "\n", "}", ")", "\n", "", "if", "debug", ":", "\n", "                ", "break", "\n", "", "", "if", "debug", "and", "mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "examples", "=", "self", ".", "examples", "[", ":", "16", "]", "\n", "", "logger", ".", "info", "(", "\"{} examples {}\"", ".", "format", "(", "mode", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.PersonaDataset.__len__": [[169, 171], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.PersonaDataset.__getitem__": [[172, 179], ["random.shuffle", "random.shuffle"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "example", "=", "self", ".", "examples", "[", "i", "]", "\n", "random", ".", "shuffle", "(", "example", "[", "'persona'", "]", ")", "\n", "random", ".", "shuffle", "(", "example", "[", "'knowledge'", "]", ")", "\n", "\n", "# note that the context and persona is a list, but knowledge is a string, a single piece of knowledge", "\n", "return", "example", "[", "'context'", "]", ",", "example", "[", "'response'", "]", ",", "example", "[", "'persona'", "]", ",", "example", "[", "'knowledge'", "]", ",", "example", "[", "'plabel'", "]", ",", "example", "[", "'klabel'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.PersonaDataset.collate_fn": [[180, 189], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "context_list", "=", "[", "item", "[", "0", "]", "for", "item", "in", "batch", "]", "\n", "response_list", "=", "[", "item", "[", "1", "]", "for", "item", "in", "batch", "]", "\n", "persona_list", "=", "[", "item", "[", "2", "]", "for", "item", "in", "batch", "]", "\n", "knowledge_list", "=", "[", "item", "[", "3", "]", "for", "item", "in", "batch", "]", "\n", "plabel_list", "=", "[", "item", "[", "4", "]", "for", "item", "in", "batch", "]", "\n", "klabel_list", "=", "[", "item", "[", "5", "]", "for", "item", "in", "batch", "]", "\n", "return", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.PersonaBatcher.__init__": [[191, 200], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "tokenizer", ",", "n_knowledge", ",", "n_persona", ",", "max_context_length", ",", "max_response_length", ",", "max_knowledge_length", ",", "max_persona_length", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "n_knowledge", "=", "n_knowledge", "\n", "self", ".", "n_persona", "=", "n_persona", "\n", "self", ".", "max_context_length", "=", "max_context_length", "\n", "self", ".", "max_response_length", "=", "max_response_length", "\n", "self", ".", "max_knowledge_length", "=", "max_knowledge_length", "\n", "self", ".", "max_persona_length", "=", "max_persona_length", "\n", "#assert glue in ['p|crk','k|crp','p|c','k|cp','p|cr']", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.PersonaBatcher.load": [[202, 245], ["len", "range", "max", "max", "range", "len", "len", "len", "len", "len", "len", "max", "max", "pretrain_dual.PersonaBatcher.persona_id_list.append", "pretrain_dual.PersonaBatcher.knowledge_id_list.append", "pretrain_dual.PersonaBatcher.context_id_list[].extend", "pretrain_dual.PersonaBatcher.response_id_list[].extend", "pretrain_dual.PersonaBatcher.tokenizer.encode", "range", "pretrain_dual.PersonaBatcher.tokenizer.encode", "range", "max", "max", "len", "len", "len", "len", "k.extend", "len", "pretrain_dual.PersonaBatcher.knowledge_id_list[].append", "p.extend", "len", "pretrain_dual.PersonaBatcher.persona_id_list[].append", "pretrain_dual.PersonaBatcher.tokenizer.encode", "pretrain_dual.PersonaBatcher.tokenizer.encode", "range", "range", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", ":", "\n", "        ", "assert", "len", "(", "context_list", ")", "==", "len", "(", "response_list", ")", "==", "len", "(", "persona_list", ")", "==", "len", "(", "knowledge_list", ")", "==", "len", "(", "plabel_list", ")", "==", "len", "(", "klabel_list", ")", "\n", "bs", "=", "len", "(", "context_list", ")", "\n", "self", ".", "context_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "' '", ".", "join", "(", "context_list", "[", "i", "]", ")", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_context_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "self", ".", "response_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "response_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_response_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "self", ".", "persona_id_list", "=", "[", "]", "\n", "self", ".", "knowledge_id_list", "=", "[", "]", "\n", "longest_persona", "=", "0", "\n", "longest_knowledge", "=", "0", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "persona", "=", "persona_list", "[", "i", "]", "\n", "knowledge", "=", "knowledge_list", "[", "i", "]", "\n", "# WARNING: We could not use random shuffle at here ", "\n", "# it is a list, every element is a single piece of persona id", "\n", "persona_id", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "p", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_persona_length", "]", "for", "p", "in", "persona", "[", ":", "self", ".", "n_persona", "]", "]", "\n", "longest_persona", "=", "max", "(", "max", "(", "[", "len", "(", "p", ")", "for", "p", "in", "persona_id", "]", ")", ",", "longest_persona", ")", "\n", "knowledge_id", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "k", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_knowledge_length", "]", "for", "k", "in", "knowledge", "[", ":", "self", ".", "n_knowledge", "]", "]", "\n", "longest_knowledge", "=", "max", "(", "max", "(", "[", "len", "(", "k", ")", "for", "k", "in", "knowledge_id", "]", ")", ",", "longest_knowledge", ")", "\n", "self", ".", "persona_id_list", ".", "append", "(", "persona_id", ")", "\n", "self", ".", "knowledge_id_list", ".", "append", "(", "knowledge_id", ")", "\n", "\n", "# padding", "\n", "", "longest_context", "=", "max", "(", "[", "len", "(", "self", ".", "context_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "longest_response", "=", "max", "(", "[", "len", "(", "self", ".", "response_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "padding_length", "=", "longest_context", "-", "len", "(", "self", ".", "context_id_list", "[", "i", "]", ")", "\n", "self", ".", "context_id_list", "[", "i", "]", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", ")", "\n", "padding_length", "=", "longest_response", "-", "len", "(", "self", ".", "response_id_list", "[", "i", "]", ")", "\n", "self", ".", "response_id_list", "[", "i", "]", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", ")", "\n", "for", "k", "in", "self", ".", "knowledge_id_list", "[", "i", "]", ":", "\n", "                ", "k", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_knowledge", "-", "len", "(", "k", ")", ")", ")", "\n", "", "while", "len", "(", "self", ".", "knowledge_id_list", "[", "i", "]", ")", "<", "self", ".", "n_knowledge", ":", "\n", "                ", "self", ".", "knowledge_id_list", "[", "i", "]", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "longest_knowledge", ")", "\n", "", "for", "p", "in", "self", ".", "persona_id_list", "[", "i", "]", ":", "\n", "                ", "p", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_persona", "-", "len", "(", "p", ")", ")", ")", "\n", "", "while", "len", "(", "self", ".", "persona_id_list", "[", "i", "]", ")", "<", "self", ".", "n_persona", ":", "\n", "                ", "self", ".", "persona_id_list", "[", "i", "]", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "longest_persona", ")", "\n", "\n", "", "", "self", ".", "bs", "=", "bs", "\n", "self", ".", "longest_context", "=", "longest_context", "\n", "self", ".", "longest_response", "=", "longest_response", "\n", "self", ".", "longest_persona", "=", "longest_persona", "\n", "self", ".", "longest_knowledge", "=", "longest_knowledge", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.PersonaBatcher.__call__": [[247, 333], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "isinstance", "range", "len", "max", "range", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "len", "isinstance", "range", "golden_knowedge_id.extend", "input_id.append", "segment_id.append", "len", "max", "range", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "len", "isinstance", "range", "pretrain_dual.PersonaBatcher.tokenizer.encode", "range", "len", "golden_persona_id.extend", "input_id.append", "segment_id.append", "len", "max", "range", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "range", "range", "pretrain_dual.PersonaBatcher.tokenizer.encode", "range", "len", "golden_persona_id.extend", "input_id.append", "segment_id.append", "range", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "range", "len", "range", "pretrain_dual.PersonaBatcher.tokenizer.encode", "range", "len", "input_id.append", "segment_id.append", "range", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "len", "range", "input_id.append", "segment_id.append", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "glue", ",", "golden_knowledge_list", "=", "None", ",", "golden_persona_list", "=", "None", ")", ":", "\n", "        ", "assert", "glue", "in", "[", "'p|crk'", ",", "'k|crp'", ",", "'k|cp'", ",", "'p|cr'", ",", "'p|c'", "]", "\n", "batch_input_id", "=", "[", "]", "\n", "batch_segment_id", "=", "[", "]", "\n", "if", "glue", "==", "'p|crk'", ":", "\n", "            ", "assert", "len", "(", "golden_knowledge_list", ")", "==", "self", ".", "bs", "\n", "bs", "=", "len", "(", "golden_knowledge_list", ")", "\n", "if", "isinstance", "(", "golden_knowledge_list", "[", "0", "]", ",", "str", ")", ":", "\n", "                ", "golden_knowledge_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "golden_knowledge_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_knowledge_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "longest_goldenk", "=", "max", "(", "[", "len", "(", "golden_knowledge_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "golden_knowedge_id", "in", "golden_knowledge_id_list", ":", "\n", "                    ", "golden_knowedge_id", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_goldenk", "-", "len", "(", "golden_knowedge_id", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_persona", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "response_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "golden_knowledge_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "persona_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "1", "+", "self", ".", "longest_context", "+", "1", "+", "self", ".", "longest_response", "+", "1", "+", "longest_goldenk", "+", "1", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_persona", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "\n", "", "", "elif", "glue", "==", "'k|crp'", ":", "\n", "            ", "assert", "len", "(", "golden_persona_list", ")", "==", "self", ".", "bs", "\n", "bs", "=", "len", "(", "golden_persona_list", ")", "\n", "if", "isinstance", "(", "golden_persona_list", "[", "0", "]", ",", "str", ")", ":", "\n", "                ", "golden_persona_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "golden_persona_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_persona_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "longest_goldenp", "=", "max", "(", "[", "len", "(", "golden_persona_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "golden_persona_id", "in", "golden_persona_id_list", ":", "\n", "                    ", "golden_persona_id", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_goldenp", "-", "len", "(", "golden_persona_id", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "golden_persona_id_list", "=", "golden_persona_list", "\n", "", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_knowledge", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "response_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "golden_persona_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "knowledge_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "self", ".", "longest_response", "+", "longest_goldenp", "+", "4", ")", "+", "[", "1", "]", "*", "(", "1", "+", "self", ".", "longest_knowledge", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "", "", "elif", "glue", "==", "'k|cp'", ":", "\n", "            ", "assert", "len", "(", "golden_persona_list", ")", "==", "self", ".", "bs", "\n", "bs", "=", "len", "(", "golden_persona_list", ")", "\n", "if", "isinstance", "(", "golden_persona_list", "[", "0", "]", ",", "str", ")", ":", "\n", "                ", "golden_persona_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "golden_persona_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_persona_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "longest_goldenp", "=", "max", "(", "[", "len", "(", "golden_persona_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "golden_persona_id", "in", "golden_persona_id_list", ":", "\n", "                    ", "golden_persona_id", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_goldenp", "-", "len", "(", "golden_persona_id", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_knowledge", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "golden_persona_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "knowledge_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "longest_goldenp", "+", "3", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_knowledge", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "", "", "elif", "glue", "==", "'p|cr'", ":", "\n", "            ", "bs", "=", "self", ".", "bs", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_persona", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "response_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "persona_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "self", ".", "longest_response", "+", "3", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_persona", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "", "", "elif", "glue", "==", "'p|c'", ":", "\n", "            ", "bs", "=", "self", ".", "bs", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_persona", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "persona_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "2", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_persona", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "\n", "", "", "batch_input_id", "=", "torch", ".", "tensor", "(", "batch_input_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "batch_segment_id", "=", "torch", ".", "tensor", "(", "batch_segment_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "return", "{", "\n", "'input_id'", ":", "batch_input_id", ",", "\n", "'segment_id'", ":", "batch_segment_id", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.recall_f1": [[337, 352], ["len", "range", "metric.f1_metric", "len", "len", "len", "sum", "len", "preds.append", "len", "len", "score.index", "max"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.f1_metric"], ["", "", "def", "recall_f1", "(", "scores", ",", "knowledges", ",", "responses", ")", ":", "\n", "    ", "count", "=", "[", "len", "(", "k", ")", "for", "k", "in", "knowledges", "]", "\n", "# all equals to the numbert of context", "\n", "assert", "len", "(", "knowledges", ")", "==", "len", "(", "responses", ")", "\n", "# all equals to the total number of knowledge sentences in every case", "\n", "assert", "sum", "(", "count", ")", "==", "len", "(", "scores", ")", "\n", "n", "=", "len", "(", "knowledges", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "len", "(", "knowledges", "[", "i", "]", ")", "]", "\n", "scores", "=", "scores", "[", "len", "(", "knowledges", "[", "i", "]", ")", ":", "]", "\n", "knowledge", "=", "knowledges", "[", "i", "]", "\n", "pred", "=", "knowledge", "[", "score", ".", "index", "(", "max", "(", "score", ")", ")", "]", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "return", "f1_metric", "(", "preds", ",", "responses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.recall_metric": [[354, 382], ["range", "open", "json.load", "open", "json.load", "len", "numpy.array().sum", "len", "len", "len", "numpy.argsort", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "recall_metric", "(", "scores", ")", ":", "\n", "    ", "r1", ",", "r2", ",", "r5", ",", "r10", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "#count_path=r'/home/futc/cmudog/'+'train'+'_knowledge_count.json'", "\n", "#label_path=r'/home/futc/cmudog/'+'train'+'_label_index.json'", "\n", "with", "open", "(", "args", ".", "count_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "knowledge_count", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "args", ".", "label_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "label", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "assert", "len", "(", "scores", ")", "==", "np", ".", "array", "(", "knowledge_count", ")", ".", "sum", "(", ")", "\n", "assert", "len", "(", "knowledge_count", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "knowledge_count", ")", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "knowledge_count", "[", "i", "]", "]", "\n", "scores", "=", "scores", "[", "knowledge_count", "[", "i", "]", ":", "]", "\n", "order", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "gold", "=", "label", "[", "i", "]", "\n", "#gold=0 if correct_first else label[i]", "\n", "if", "gold", "in", "order", "[", ":", "1", "]", ":", "\n", "            ", "r1", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "2", "]", ":", "\n", "            ", "r2", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "5", "]", ":", "\n", "            ", "r5", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "10", "]", ":", "\n", "            ", "r10", "+=", "1", "\n", "\n", "", "", "return", "r1", "/", "len", "(", "knowledge_count", ")", ",", "r2", "/", "len", "(", "knowledge_count", ")", ",", "r5", "/", "len", "(", "knowledge_count", ")", ",", "r10", "/", "len", "(", "knowledge_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.train_step": [[460, 520], ["range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "dualkp_optimizer.step", "dualkp_scheduler.step", "dualkp_optimizer.zero_grad", "dualpk_optimizer.step", "dualpk_scheduler.step", "dualpk_optimizer.zero_grad", "next", "dualpk_model.train", "dualkp_model.train", "batcher.load", "batcher", "torch.tensor", "torch.tensor", "F.multi_margin_loss.item", "F.multi_margin_loss.backward", "batcher", "torch.tensor", "torch.tensor", "F.multi_margin_loss.item", "F.multi_margin_loss.backward", "logger.info", "datetime.datetime.now().strftime", "logger.info", "dualpk_model", "dual_klogits.view", "torch.cross_entropy", "dualkp_model", "dual_plogits.view", "torch.cross_entropy", "input_id.dim", "knowledge_list[].index", "torch.multi_margin_loss", "input_id.dim", "persona_list[].index", "torch.multi_margin_loss", "dualkp_model.parameters", "dualpk_model.parameters", "datetime.datetime.now", "input_id.view", "segment_id.view", "range", "input_id.view", "segment_id.view", "range", "input_id.view", "input_id.view", "dualpk_scheduler.get_lr"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "train_step", "(", "global_step", ")", ":", "\n", "    ", "ks_loss_total", "=", "0.0", "\n", "for", "_", "in", "range", "(", "args", ".", "accum_step", ")", ":", "\n", "        ", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "=", "next", "(", "train_loader", ")", "\n", "#The dual learning part", "\n", "dualpk_model", ".", "train", "(", ")", "\n", "dualkp_model", ".", "train", "(", ")", "\n", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "\n", "batch_dict", "=", "batcher", "(", "'k|crp'", ",", "None", ",", "plabel_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "#(bs*n_know,2)", "\n", "dual_klogits", "=", "dualpk_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "#(bs,n_know)", "\n", "dual_klogits", "=", "dual_klogits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "#(bs)", "\n", "targetk", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "dual_klogits", ".", "device", ")", "\n", "if", "args", ".", "loss", "==", "'ce'", ":", "\n", "            ", "kloss", "=", "F", ".", "cross_entropy", "(", "dual_klogits", ",", "targetk", ")", "\n", "", "elif", "args", ".", "loss", "==", "'mm'", ":", "\n", "            ", "kloss", "=", "F", ".", "multi_margin_loss", "(", "dual_klogits", ",", "targetk", ")", "\n", "", "ks_loss_total", "+=", "kloss", ".", "item", "(", ")", "\n", "kloss", "=", "kloss", "/", "args", ".", "accum_step", "\n", "kloss", ".", "backward", "(", ")", "\n", "\n", "batch_dict", "=", "batcher", "(", "'p|crk'", ",", "klabel_list", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "dual_plogits", "=", "dualkp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "dual_plogits", "=", "dual_plogits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "targetp", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "if", "args", ".", "loss", "==", "'ce'", ":", "\n", "            ", "ploss", "=", "F", ".", "cross_entropy", "(", "dual_plogits", ",", "targetp", ")", "\n", "", "elif", "args", ".", "loss", "==", "'mm'", ":", "\n", "            ", "ploss", "=", "F", ".", "multi_margin_loss", "(", "dual_plogits", ",", "targetp", ")", "\n", "", "ks_loss_total", "+=", "ploss", ".", "item", "(", ")", "\n", "ploss", "=", "ploss", "/", "args", ".", "accum_step", "\n", "ploss", ".", "backward", "(", ")", "\n", "\n", "", "grad_norm1", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "dualkp_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "grad_norm2", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "dualpk_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "if", "grad_norm1", ">=", "1e2", "or", "grad_norm2", ">", "1e2", ":", "\n", "        ", "logger", ".", "info", "(", "'WARNING : Exploding Gradients {:.2f} {:.2f}'", ".", "format", "(", "grad_norm1", ",", "grad_norm2", ")", ")", "\n", "", "dualkp_optimizer", ".", "step", "(", ")", "\n", "dualkp_scheduler", ".", "step", "(", ")", "\n", "dualkp_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "dualpk_optimizer", ".", "step", "(", ")", "\n", "dualpk_scheduler", ".", "step", "(", ")", "\n", "dualpk_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "print_every", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "        ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "logger", ".", "info", "(", "\"Step: %d \\t| ks_loss: %.3f \\t| lr: %.8f \\t| %s\"", "%", "(", "\n", "global_step", ",", "ks_loss_total", ",", "dualpk_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "time_str", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_dual.predict_step": [[523, 594], ["dualpk_model.eval", "dualpk_model.save_pretrained", "dualkp_model.save_pretrained", "logger.info", "torch.no_grad", "torch.no_grad", "logger.info", "torch.no_grad", "torch.no_grad", "logger.info", "os.path.join", "os.path.join", "batcher.load", "batcher", "len", "torch.tensor", "torch.tensor", "len", "torch.sum().item", "torch.sum().item", "batcher.load", "batcher", "len", "torch.tensor", "torch.tensor", "len", "torch.sum().item", "torch.sum().item", "dualpk_model", "logits.view", "logger.info", "torch.max", "torch.max", "dualkp_model", "logits.view", "logger.info", "torch.max", "torch.max", "input_id.dim", "knowledge_list[].index", "torch.sum", "torch.sum", "input_id.dim", "persona_list[].index", "torch.sum", "torch.sum", "input_id.view", "segment_id.view", "range", "input_id.view", "segment_id.view", "range", "input_id.view", "input_id.view"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "", "def", "predict_step", "(", "global_step", ")", ":", "\n", "#if split == 'test_seen':", "\n", "#    test_loader = test_seen_loader", "\n", "#else:", "\n", "#    raise ValueError", "\n", "#dualkp_model.eval()", "\n", "    ", "dualpk_model", ".", "eval", "(", ")", "\n", "all", "=", "0", "\n", "hit1", "=", "0", "\n", "count", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "batch_dict", "=", "batcher", "(", "'k|crp'", ",", "None", ",", "plabel_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "dualpk_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "1", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "bs", "=", "len", "(", "context_list", ")", "\n", "ref", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "hyp", "=", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "all", "+=", "len", "(", "ref", ")", "\n", "hit1", "+=", "torch", ".", "sum", "(", "hyp", "==", "ref", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"from p infer k, the hit at 1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "all", ")", ")", "\n", "\n", "", "all", "=", "0", "\n", "hit1", "=", "0", "\n", "count", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "batch_dict", "=", "batcher", "(", "'p|crk'", ",", "klabel_list", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "dualkp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "1", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "bs", "=", "len", "(", "context_list", ")", "\n", "ref", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "hyp", "=", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "all", "+=", "len", "(", "ref", ")", "\n", "hit1", "+=", "torch", ".", "sum", "(", "hyp", "==", "ref", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"from k infer p, the hit at 1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "all", ")", ")", "\n", "\n", "# with open(os.path.join(args.out_dir, 'score-iter-{}.txt'.format( global_step)), 'w', encoding='utf-8') as f:", "\n", "#     for label, score in zip(labels, scores):", "\n", "#         f.write('{}\\t{}\\n'.format(label, score))", "\n", "\n", "\n", "\n", "\n", "\n", "", "dualpk_model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_dualpk_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "dualkp_model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_dualkp_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "#torch.save(dualpk_model,os.path.join(args.out_dir,'{}step_dualpk_model'.format(global_step)))", "\n", "#checkpoint_dir=os.path.join(args.out_dir,'{}step_model'.format(global_step))", "\n", "#torch.save(dualkp_model,os.path.join(args.out_dir,'{}step_dualkp_model'.format(global_step)))", "\n", "logger", ".", "info", "(", "\"Saved model checkpoint \\n\"", ")", "\n", "#logger.info(\"hit at 1 is {:.4f}\".format(hit1/all))", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.PersonaDataset.__init__": [[123, 167], ["torch.utils.data.Dataset.__init__", "os.listdir", "logger.info", "open", "open", "zip", "open", "open.readlines", "open.close", "open", "open.readlines", "open.close", "os.path.join", "os.path.join", "open.readlines", "open.readlines", "json.loads", "json.loads", "decode.PersonaDataset.examples.append", "decode.PersonaDataset.selected_knowledge.append", "decode.PersonaDataset.selected_persona.append", "len", "line.strip", "line.strip"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "convo_path", ",", "selectedp_path", ",", "selectedk_path", ",", "pseudo_path", ",", "mode", ")", "->", "None", ":", "\n", "        ", "super", "(", "PersonaDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "examples", "=", "[", "]", "\n", "self", ".", "selected_knowledge", "=", "[", "]", "\n", "self", ".", "selected_persona", "=", "[", "]", "\n", "assert", "mode", "in", "[", "'train'", ",", "'eval'", "]", "\n", "self", ".", "mode", "=", "mode", "\n", "for", "date", "in", "os", ".", "listdir", "(", "convo_path", ")", ":", "\n", "            ", "if", "(", "date", "==", "'2015-05'", "or", "date", "==", "'2015-06'", ")", "and", "mode", "==", "'train'", ":", "\n", "                ", "continue", "\n", "", "if", "mode", "==", "'eval'", "and", "date", "!=", "'2015-05'", ":", "\n", "                ", "continue", "\n", "", "fconvo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "convo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fpseudo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "pseudo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "line1", ",", "line2", "in", "zip", "(", "fconvo", ".", "readlines", "(", ")", ",", "fpseudo", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "data", "=", "json", ".", "loads", "(", "line1", ")", "\n", "author", "=", "data", "[", "'author'", "]", "[", "-", "1", "]", "\n", "sid", "=", "data", "[", "'sid'", "]", "\n", "label", "=", "json", ".", "loads", "(", "line2", ")", "\n", "self", ".", "examples", ".", "append", "(", "{", "\n", "'context'", ":", "data", "[", "'dialog'", "]", "[", ":", "-", "1", "]", ",", "\n", "'response'", ":", "data", "[", "'dialog'", "]", "[", "-", "1", "]", ",", "\n", "'klabel'", ":", "label", "[", "'klabel'", "]", ",", "\n", "'plabel'", ":", "label", "[", "'plabel'", "]", "\n", "}", ")", "\n", "", "if", "args", ".", "debug", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "mode", "==", "'eval'", "and", "args", ".", "prompt", "==", "'selected'", ":", "\n", "            ", "fsk", "=", "open", "(", "selectedk_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "line", "in", "fsk", ".", "readlines", "(", ")", ":", "\n", "                ", "self", ".", "selected_knowledge", ".", "append", "(", "line", ".", "strip", "(", "'\\n'", ")", ")", "\n", "", "fsk", ".", "close", "(", ")", "\n", "\n", "fsp", "=", "open", "(", "selectedp_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "line", "in", "fsp", ".", "readlines", "(", ")", ":", "\n", "                ", "self", ".", "selected_persona", ".", "append", "(", "line", ".", "strip", "(", "'\\n'", ")", ")", "\n", "", "fsp", ".", "close", "(", ")", "\n", "\n", "", "if", "args", ".", "debug", "and", "mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "examples", "=", "self", ".", "examples", "[", ":", "16", "]", "\n", "self", ".", "selected_persona", "=", "self", ".", "selected_persona", "[", ":", "16", "]", "\n", "self", ".", "selected_knowledge", "=", "self", ".", "selected_knowledge", "[", ":", "16", "]", "\n", "", "logger", ".", "info", "(", "\"{} examples {}\"", ".", "format", "(", "mode", ",", "len", "(", "self", ".", "examples", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.PersonaDataset.__len__": [[168, 170], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.PersonaDataset.__getitem__": [[171, 179], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "example", "=", "self", ".", "examples", "[", "i", "]", "\n", "if", "self", ".", "mode", "==", "'eval'", "and", "args", ".", "prompt", "==", "'selected'", ":", "\n", "            ", "return", "example", "[", "'context'", "]", ",", "example", "[", "'response'", "]", ",", "self", ".", "selected_persona", "[", "i", "]", ",", "self", ".", "selected_knowledge", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "assert", "example", "[", "'plabel'", "]", "is", "not", "None", "\n", "assert", "example", "[", "'klabel'", "]", "is", "not", "None", "\n", "return", "example", "[", "'context'", "]", ",", "example", "[", "'response'", "]", ",", "example", "[", "'plabel'", "]", ",", "example", "[", "'klabel'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.PersonaDataset.collate_fn": [[180, 187], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "context_list", "=", "[", "item", "[", "0", "]", "for", "item", "in", "batch", "]", "\n", "response_list", "=", "[", "item", "[", "1", "]", "for", "item", "in", "batch", "]", "\n", "persona_list", "=", "[", "item", "[", "2", "]", "for", "item", "in", "batch", "]", "\n", "knowledge_list", "=", "[", "item", "[", "3", "]", "for", "item", "in", "batch", "]", "\n", "return", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.PersonaBatcher.__init__": [[189, 196], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "tokenizer", ",", "max_context_length", ",", "max_response_length", ",", "max_knowledge_length", ",", "max_persona_length", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_context_length", "=", "max_context_length", "\n", "self", ".", "max_response_length", "=", "max_response_length", "\n", "self", ".", "max_knowledge_length", "=", "max_knowledge_length", "\n", "self", ".", "max_persona_length", "=", "max_persona_length", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.PersonaBatcher.__call__": [[198, 234], ["len", "range", "max", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "batch_knowledge_id.cuda.cuda.cuda", "batch_persona_id.cuda.cuda.cuda", "len", "len", "len", "len", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "batch_input_id[].extend", "batch_label[].extend", "decode.PersonaBatcher.tokenizer.batch_encode_plus", "decode.PersonaBatcher.tokenizer.batch_encode_plus", "logger.info", "logger.info", "decode.PersonaBatcher.tokenizer.encode", "len", "len", "decode.PersonaBatcher.tokenizer.encode", "decode.PersonaBatcher.tokenizer.encode", "range", "len", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "assert", "len", "(", "context_list", ")", "==", "len", "(", "response_list", ")", "==", "len", "(", "persona_list", ")", "==", "len", "(", "knowledge_list", ")", "\n", "bs", "=", "len", "(", "context_list", ")", "\n", "batch_input_id", "=", "[", "]", "\n", "batch_label", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "input_id", "=", "self", ".", "tokenizer", ".", "encode", "(", "' '", ".", "join", "(", "context_list", "[", "i", "]", ")", ")", "[", ":", "self", ".", "max_context_length", "]", "\n", "label", "=", "[", "-", "100", "]", "*", "len", "(", "input_id", ")", "\n", "if", "mode", "==", "'train'", ":", "\n", "                ", "input_id", "+=", "self", ".", "tokenizer", ".", "encode", "(", "response_list", "[", "i", "]", ")", "[", ":", "self", ".", "max_response_length", "]", "\n", "label", "+=", "self", ".", "tokenizer", ".", "encode", "(", "response_list", "[", "i", "]", ")", "[", ":", "self", ".", "max_response_length", "]", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_label", ".", "append", "(", "label", ")", "\n", "", "longest", "=", "max", "(", "[", "len", "(", "batch_input_id", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "batch_input_id", "[", "i", "]", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest", "-", "len", "(", "batch_input_id", "[", "i", "]", ")", ")", ")", "\n", "batch_label", "[", "i", "]", ".", "extend", "(", "[", "-", "100", "]", "*", "(", "longest", "-", "len", "(", "batch_label", "[", "i", "]", ")", ")", ")", "\n", "", "batch_knowledge_id", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "knowledge_list", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_knowledge_length", ",", "padding", "=", "'longest'", ",", "return_tensors", "=", "'pt'", ")", "[", "'input_ids'", "]", "\n", "batch_persona_id", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "persona_list", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_persona_length", ",", "padding", "=", "'longest'", ",", "return_tensors", "=", "'pt'", ")", "[", "'input_ids'", "]", "\n", "\n", "batch_input_id", "=", "torch", ".", "tensor", "(", "batch_input_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "batch_label", "=", "torch", ".", "tensor", "(", "batch_label", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "batch_knowledge_id", "=", "batch_knowledge_id", ".", "cuda", "(", ")", "\n", "batch_persona_id", "=", "batch_persona_id", ".", "cuda", "(", ")", "\n", "if", "batch_knowledge_id", ".", "shape", "[", "-", "1", "]", ">=", "1024", ":", "\n", "            ", "logger", ".", "info", "(", "\"too long batch knowledge id!!!\"", ")", "\n", "batch_knowledge_id", "=", "batch_knowledge_id", "[", ":", ",", "1023", "]", "\n", "", "if", "batch_persona_id", ".", "shape", "[", "-", "1", "]", ">=", "1024", ":", "\n", "            ", "logger", ".", "info", "(", "\"too long batch knowledge id!!!\"", ")", "\n", "batch_persona_id", "=", "batch_persona_id", "[", ":", ",", "1023", "]", "\n", "\n", "", "return", "{", "\n", "'input_id'", ":", "batch_input_id", ",", "\n", "'knowledge_id'", ":", "batch_knowledge_id", ",", "\n", "'persona_id'", ":", "batch_persona_id", ",", "\n", "'label'", ":", "batch_label", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.recall_f1": [[262, 277], ["len", "range", "metric.f1_metric", "len", "len", "len", "sum", "len", "preds.append", "len", "len", "score.index", "max"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.f1_metric"], ["", "", "def", "recall_f1", "(", "scores", ",", "knowledges", ",", "responses", ")", ":", "\n", "    ", "count", "=", "[", "len", "(", "k", ")", "for", "k", "in", "knowledges", "]", "\n", "# all equals to the number of context", "\n", "assert", "len", "(", "knowledges", ")", "==", "len", "(", "responses", ")", "\n", "# all equals to the total number of knowledge sentences in every case", "\n", "assert", "sum", "(", "count", ")", "==", "len", "(", "scores", ")", "\n", "n", "=", "len", "(", "knowledges", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "len", "(", "knowledges", "[", "i", "]", ")", "]", "\n", "scores", "=", "scores", "[", "len", "(", "knowledges", "[", "i", "]", ")", ":", "]", "\n", "knowledge", "=", "knowledges", "[", "i", "]", "\n", "pred", "=", "knowledge", "[", "score", ".", "index", "(", "max", "(", "score", ")", ")", "]", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "return", "f1_metric", "(", "preds", ",", "responses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.recall_metric": [[279, 307], ["range", "open", "json.load", "open", "json.load", "len", "numpy.array().sum", "len", "len", "len", "numpy.argsort", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "recall_metric", "(", "scores", ")", ":", "\n", "    ", "r1", ",", "r2", ",", "r5", ",", "r10", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "#count_path=r'/home/futc/cmudog/'+'train'+'_knowledge_count.json'", "\n", "#label_path=r'/home/futc/cmudog/'+'train'+'_label_index.json'", "\n", "with", "open", "(", "args", ".", "count_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "knowledge_count", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "args", ".", "label_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "label", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "assert", "len", "(", "scores", ")", "==", "np", ".", "array", "(", "knowledge_count", ")", ".", "sum", "(", ")", "\n", "assert", "len", "(", "knowledge_count", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "knowledge_count", ")", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "knowledge_count", "[", "i", "]", "]", "\n", "scores", "=", "scores", "[", "knowledge_count", "[", "i", "]", ":", "]", "\n", "order", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "gold", "=", "label", "[", "i", "]", "\n", "#gold=0 if correct_first else label[i]", "\n", "if", "gold", "in", "order", "[", ":", "1", "]", ":", "\n", "            ", "r1", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "2", "]", ":", "\n", "            ", "r2", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "5", "]", ":", "\n", "            ", "r5", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "10", "]", ":", "\n", "            ", "r10", "+=", "1", "\n", "\n", "", "", "return", "r1", "/", "len", "(", "knowledge_count", ")", ",", "r2", "/", "len", "(", "knowledge_count", ")", ",", "r5", "/", "len", "(", "knowledge_count", ")", ",", "r10", "/", "len", "(", "knowledge_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.train_step": [[373, 406], ["range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_optimizer.step", "model_scheduler.step", "model_optimizer.zero_grad", "next", "model.train", "batcher", "loss.item", "loss.backward", "logger.info", "datetime.datetime.now().strftime", "logger.info", "model", "model.parameters", "datetime.datetime.now", "model", "model", "model_scheduler.get_lr", "model"], "function", ["None"], ["", "def", "train_step", "(", "global_step", ")", ":", "\n", "    ", "loss_total", "=", "0.0", "\n", "for", "_", "in", "range", "(", "args", ".", "accum_step", ")", ":", "\n", "        ", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", "=", "next", "(", "train_loader", ")", "\n", "model", ".", "train", "(", ")", "\n", "batch_dict", "=", "batcher", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "knowledge_id", "=", "batch_dict", "[", "'knowledge_id'", "]", "\n", "persona_id", "=", "batch_dict", "[", "'persona_id'", "]", "\n", "label", "=", "batch_dict", "[", "'label'", "]", "\n", "if", "args", ".", "decoder", "==", "'v1'", ":", "\n", "            ", "loss", "=", "model", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "knowledge_id", "=", "knowledge_id", ",", "knowledge_attention_mask", "=", "(", "knowledge_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "persona_id", "=", "persona_id", ",", "persona_attention_mask", "=", "(", "persona_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "labels", "=", "label", ",", "return_dict", "=", "True", ")", "[", "'loss'", "]", "\n", "", "elif", "args", ".", "decoder", "==", "'ablationp'", ":", "\n", "            ", "loss", "=", "model", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "knowledge_id", "=", "knowledge_id", ",", "knowledge_attention_mask", "=", "(", "knowledge_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "labels", "=", "label", ",", "return_dict", "=", "True", ")", "[", "'loss'", "]", "\n", "", "elif", "args", ".", "decoder", "==", "'ablationk'", ":", "\n", "            ", "loss", "=", "model", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "persona_id", "=", "persona_id", ",", "persona_attention_mask", "=", "(", "persona_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "labels", "=", "label", ",", "return_dict", "=", "True", ")", "[", "'loss'", "]", "\n", "", "elif", "args", ".", "decoder", "==", "'v0'", ":", "\n", "            ", "loss", "=", "model", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "labels", "=", "label", ",", "return_dict", "=", "True", ")", "[", "'loss'", "]", "\n", "", "loss_total", "+=", "loss", ".", "item", "(", ")", "\n", "loss", "=", "loss", "/", "args", ".", "accum_step", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "if", "grad_norm", ">=", "1e2", ":", "\n", "        ", "logger", ".", "info", "(", "'WARNING : Exploding Gradients {:.2f}'", ".", "format", "(", "grad_norm", ")", ")", "\n", "", "model_optimizer", ".", "step", "(", ")", "\n", "model_scheduler", ".", "step", "(", ")", "\n", "model_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "print_every", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "        ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "logger", ".", "info", "(", "\"Step: %d \\t| ks_loss: %.3f \\t| lr: %.8f \\t| %s\"", "%", "(", "\n", "global_step", ",", "loss_total", ",", "model_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "time_str", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.decode.predict_step": [[409, 478], ["model.eval", "open", "open.close", "os.path.join", "open.write", "model.save_pretrained", "torch.no_grad", "torch.no_grad", "batcher", "tokenizer.batch_decode", "hypothesis.extend", "os.path.join", "model.generate_beam_search", "logger.info", "hyp.replace", "model.generate_beam_search", "len", "len", "model.generate_beam_search", "len", "len", "model.generate_beam_search", "len", "len"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.generate_beam_search", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.generate_beam_search", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.generate_beam_search", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.generate_beam_search"], ["", "", "def", "predict_step", "(", "global_step", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "hypothesis", "=", "[", "]", "\n", "count", "=", "0", "\n", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", "in", "eval_loader", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "mode", "=", "'eval'", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "knowledge_id", "=", "batch_dict", "[", "'knowledge_id'", "]", "\n", "persona_id", "=", "batch_dict", "[", "'persona_id'", "]", "\n", "label", "=", "batch_dict", "[", "'label'", "]", "\n", "if", "args", ".", "decoder", "==", "'v1'", ":", "\n", "                ", "modelout", "=", "model", ".", "generate_beam_search", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "knowledge_id", "=", "knowledge_id", ",", "knowledge_attention_mask", "=", "(", "knowledge_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "persona_id", "=", "persona_id", ",", "persona_attention_mask", "=", "(", "persona_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "cur_len", "=", "input_id", ".", "shape", "[", "1", "]", ",", "min_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "min_generate_length", ",", "max_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "max_generate_length", ",", "eos_token_id", "=", "tokenizer", ".", "eos_token_id", ",", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "num_beams", "=", "args", ".", "beamsize", ",", "vocab_size", "=", "len", "(", "tokenizer", ")", ")", "\n", "", "elif", "args", ".", "decoder", "==", "'ablationk'", ":", "\n", "                ", "modelout", "=", "model", ".", "generate_beam_search", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "persona_id", "=", "persona_id", ",", "persona_attention_mask", "=", "(", "persona_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "cur_len", "=", "input_id", ".", "shape", "[", "1", "]", ",", "min_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "min_generate_length", ",", "max_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "max_generate_length", ",", "eos_token_id", "=", "tokenizer", ".", "eos_token_id", ",", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "num_beams", "=", "args", ".", "beamsize", ",", "vocab_size", "=", "len", "(", "tokenizer", ")", ")", "\n", "", "elif", "args", ".", "decoder", "==", "'ablationp'", ":", "\n", "                ", "modelout", "=", "model", ".", "generate_beam_search", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "knowledge_id", "=", "knowledge_id", ",", "knowledge_attention_mask", "=", "(", "knowledge_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "cur_len", "=", "input_id", ".", "shape", "[", "1", "]", ",", "min_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "min_generate_length", ",", "max_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "max_generate_length", ",", "eos_token_id", "=", "tokenizer", ".", "eos_token_id", ",", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "num_beams", "=", "args", ".", "beamsize", ",", "vocab_size", "=", "len", "(", "tokenizer", ")", ")", "\n", "", "elif", "args", ".", "decoder", "==", "'v0'", ":", "\n", "                ", "modelout", "=", "model", ".", "generate_beam_search", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "(", "input_id", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "cur_len", "=", "input_id", ".", "shape", "[", "1", "]", ",", "min_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "min_generate_length", ",", "max_length", "=", "input_id", ".", "shape", "[", "1", "]", "+", "args", ".", "max_generate_length", ",", "eos_token_id", "=", "tokenizer", ".", "eos_token_id", ",", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "num_beams", "=", "args", ".", "beamsize", ",", "vocab_size", "=", "len", "(", "tokenizer", ")", ")", "\n", "", "generated", "=", "tokenizer", ".", "batch_decode", "(", "modelout", ",", "skip_special_tokens", "=", "True", ")", "\n", "hypothesis", ".", "extend", "(", "generated", ")", "\n", "if", "len", "(", "hypothesis", ")", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"decode finish {}\"", ".", "format", "(", "len", "(", "hypothesis", ")", ")", ")", "\n", "", "", "", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_result'", ".", "format", "(", "global_step", ")", ")", ",", "mode", "=", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "hyp", "in", "hypothesis", ":", "\n", "        ", "f", ".", "write", "(", "hyp", ".", "replace", "(", "'\\n'", ",", "''", ")", "+", "'\\n'", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "if", "not", "args", ".", "predict", ":", "\n", "        ", "model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_vae.recall_f1": [[124, 139], ["len", "range", "metric.f1_metric", "len", "len", "len", "sum", "len", "preds.append", "len", "len", "score.index", "max"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.f1_metric"], ["", "def", "recall_f1", "(", "scores", ",", "knowledges", ",", "responses", ")", ":", "\n", "    ", "count", "=", "[", "len", "(", "k", ")", "for", "k", "in", "knowledges", "]", "\n", "# all equals to the numbert of context", "\n", "assert", "len", "(", "knowledges", ")", "==", "len", "(", "responses", ")", "\n", "# all equals to the total number of knowledge sentences in every case", "\n", "assert", "sum", "(", "count", ")", "==", "len", "(", "scores", ")", "\n", "n", "=", "len", "(", "knowledges", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "len", "(", "knowledges", "[", "i", "]", ")", "]", "\n", "scores", "=", "scores", "[", "len", "(", "knowledges", "[", "i", "]", ")", ":", "]", "\n", "knowledge", "=", "knowledges", "[", "i", "]", "\n", "pred", "=", "knowledge", "[", "score", ".", "index", "(", "max", "(", "score", ")", ")", "]", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "return", "f1_metric", "(", "preds", ",", "responses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_vae.recall_metric": [[141, 169], ["range", "open", "json.load", "open", "json.load", "len", "numpy.array().sum", "len", "len", "len", "numpy.argsort", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "recall_metric", "(", "scores", ")", ":", "\n", "    ", "r1", ",", "r2", ",", "r5", ",", "r10", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "#count_path=r'/home/futc/cmudog/'+'train'+'_knowledge_count.json'", "\n", "#label_path=r'/home/futc/cmudog/'+'train'+'_label_index.json'", "\n", "with", "open", "(", "args", ".", "count_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "knowledge_count", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "args", ".", "label_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "label", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "assert", "len", "(", "scores", ")", "==", "np", ".", "array", "(", "knowledge_count", ")", ".", "sum", "(", ")", "\n", "assert", "len", "(", "knowledge_count", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "knowledge_count", ")", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "knowledge_count", "[", "i", "]", "]", "\n", "scores", "=", "scores", "[", "knowledge_count", "[", "i", "]", ":", "]", "\n", "order", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "gold", "=", "label", "[", "i", "]", "\n", "#gold=0 if correct_first else label[i]", "\n", "if", "gold", "in", "order", "[", ":", "1", "]", ":", "\n", "            ", "r1", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "2", "]", ":", "\n", "            ", "r2", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "5", "]", ":", "\n", "            ", "r5", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "10", "]", ":", "\n", "            ", "r10", "+=", "1", "\n", "\n", "", "", "return", "r1", "/", "len", "(", "knowledge_count", ")", ",", "r2", "/", "len", "(", "knowledge_count", ")", ",", "r5", "/", "len", "(", "knowledge_count", ")", ",", "r10", "/", "len", "(", "knowledge_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_vae.train_step": [[232, 297], ["range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_optimizer.step", "model_scheduler.step", "model_optimizer.zero_grad", "next", "len", "model.train", "batcher.load", "F.multi_margin_loss.item", "F.multi_margin_loss.backward", "logger.info", "datetime.datetime.now().strftime", "logger.info", "batcher", "torch.tensor", "torch.tensor", "model", "logits.view", "torch.cross_entropy", "batcher", "torch.tensor", "torch.tensor", "input_id.dim", "torch.multi_margin_loss", "model.parameters", "model.parameters", "datetime.datetime.now", "persona_list[].index", "batcher", "torch.tensor", "torch.tensor", "input_id.view", "segment_id.view", "range", "persona_list[].index", "batcher", "torch.tensor", "torch.tensor", "input_id.view", "model_scheduler.get_lr", "range", "knowledge_list[].index", "batcher", "torch.tensor", "torch.tensor", "range", "knowledge_list[].index", "range", "knowledge_list[].index", "range"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "train_step", "(", "global_step", ")", ":", "\n", "    ", "ks_loss_total", "=", "0.0", "\n", "for", "_", "in", "range", "(", "args", ".", "accum_step", ")", ":", "\n", "        ", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "=", "next", "(", "train_loader", ")", "\n", "#The dual learning part", "\n", "bs", "=", "len", "(", "context_list", ")", "\n", "model", ".", "train", "(", ")", "\n", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "if", "args", ".", "task", "==", "'semip'", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'p|cr'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'priorp'", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'p|c'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'priork'", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'k|cp'", ",", "None", ",", "plabel_list", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'postk_ablationp'", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'k|cr'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'priork_ablationp'", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'k|c'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "#(bs*n_know,2)", "\n", "# if args.task=='priorp' or args.task=='priork':", "\n", "#     input_id1,input_id2,input_id3,input_id4,input_id5,input_id6,input_id7,input_id8=torch.chunk(input_id,8,dim=1)", "\n", "#     segment_id1,segment_id2,segment_id3,segment_id4,segment_id5,segment_id6,segment_id7,segment_id8=torch.chunk(segment_id,8,dim=1)", "\n", "#     logits1=model(input_ids=input_id1.view(-1,seq_len),attention_mask=input_id1.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id1.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits2=model(input_ids=input_id2.view(-1,seq_len),attention_mask=input_id2.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id2.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits3=model(input_ids=input_id3.view(-1,seq_len),attention_mask=input_id3.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id3.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits4=model(input_ids=input_id4.view(-1,seq_len),attention_mask=input_id4.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id4.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits5=model(input_ids=input_id5.view(-1,seq_len),attention_mask=input_id5.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id5.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits6=model(input_ids=input_id6.view(-1,seq_len),attention_mask=input_id6.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id6.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits7=model(input_ids=input_id7.view(-1,seq_len),attention_mask=input_id7.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id7.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits8=model(input_ids=input_id8.view(-1,seq_len),attention_mask=input_id8.view(-1,seq_len)!=tokenizer.pad_token_id,token_type_ids=segment_id8.view(-1,seq_len),return_dict=True)['logits']", "\n", "#     logits=torch.torch.cat([logits1,logits2,logits3,logits4,logits5,logits6,logits7,logits8],dim=1)", "\n", "# else:", "\n", "logits", "=", "model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "#(bs,n_know)", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "if", "args", ".", "loss", "==", "'ce'", ":", "\n", "            ", "kloss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "target", ")", "\n", "", "elif", "args", ".", "loss", "==", "'mm'", ":", "\n", "            ", "kloss", "=", "F", ".", "multi_margin_loss", "(", "logits", ",", "target", ")", "\n", "", "ks_loss_total", "+=", "kloss", ".", "item", "(", ")", "\n", "kloss", "=", "kloss", "/", "args", ".", "accum_step", "\n", "kloss", ".", "backward", "(", ")", "\n", "\n", "", "grad_norm1", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "grad_norm2", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "if", "grad_norm1", ">=", "1e2", "or", "grad_norm2", ">", "1e2", ":", "\n", "        ", "logger", ".", "info", "(", "'WARNING : Exploding Gradients {:.2f} {:.2f}'", ".", "format", "(", "grad_norm1", ",", "grad_norm2", ")", ")", "\n", "", "model_optimizer", ".", "step", "(", ")", "\n", "model_scheduler", ".", "step", "(", ")", "\n", "model_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "print_every", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "        ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "logger", ".", "info", "(", "\"Step: %d \\t| ks_loss: %.3f \\t| lr: %.8f \\t| %s\"", "%", "(", "\n", "global_step", ",", "ks_loss_total", ",", "model_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "time_str", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.pretrain_vae.predict_step": [[300, 344], ["model.eval", "model.save_pretrained", "torch.no_grad", "torch.no_grad", "logger.info", "logger.info", "os.path.join", "len", "batcher.load", "len", "torch.sum().item", "torch.sum().item", "batcher", "torch.tensor", "torch.tensor", "model", "logits.view", "logger.info", "torch.max", "torch.max", "batcher", "torch.tensor", "torch.tensor", "input_id.dim", "torch.sum", "torch.sum", "persona_list[].index", "batcher", "torch.tensor", "torch.tensor", "input_id.view", "segment_id.view", "range", "persona_list[].index", "batcher", "torch.tensor", "torch.tensor", "input_id.view", "range", "knowledge_list[].index", "batcher", "torch.tensor", "torch.tensor", "range", "knowledge_list[].index", "range", "knowledge_list[].index", "range"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "", "def", "predict_step", "(", "global_step", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "hit1", "=", "0", "\n", "count", "=", "0", "\n", "if", "not", "args", ".", "predict", ":", "\n", "        ", "model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_{}'", ".", "format", "(", "global_step", ",", "args", ".", "task", ")", ")", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "bs", "=", "len", "(", "context_list", ")", "\n", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "if", "args", ".", "task", "==", "'semip'", ":", "\n", "                ", "batch_dict", "=", "batcher", "(", "'p|cr'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'priorp'", ":", "\n", "                ", "batch_dict", "=", "batcher", "(", "'p|c'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'priork'", ":", "\n", "                ", "batch_dict", "=", "batcher", "(", "'k|cp'", ",", "None", ",", "plabel_list", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'postk_ablationp'", ":", "\n", "                ", "batch_dict", "=", "batcher", "(", "'k|cr'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "elif", "args", ".", "task", "==", "'priork_ablationp'", ":", "\n", "                ", "batch_dict", "=", "batcher", "(", "'k|c'", ",", "None", ",", "None", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "bs", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "bs", "=", "len", "(", "context_list", ")", "\n", "hyp", "=", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "hit1", "+=", "torch", ".", "sum", "(", "hyp", "==", "target", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "\n", "", "", "if", "not", "args", ".", "predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"Saved model checkpoint \\n\"", ")", "\n", "", "if", "count", "!=", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"hit at 1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.VAEKDataset.__init__": [[177, 221], ["torch.utils.data.Dataset.__init__", "os.listdir", "open", "open", "open", "open", "json.load", "json.load", "zip", "open", "open.readlines", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open.readlines", "open.readlines", "json.loads", "json.loads", "vaek.VAEKDataset.examples.append", "isinstance", "vaek.VAEKDataset.selected.append", "str().strip().split", "str().strip", "str"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["    ", "def", "__init__", "(", "self", ",", "convo_path", ",", "persona_path", ",", "knowledge_path", ",", "pseudo_path", ",", "selected_path", ",", "mode", ",", "debug", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "VAEKDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "examples", "=", "[", "]", "\n", "self", ".", "selected", "=", "[", "]", "\n", "assert", "mode", "in", "[", "'train'", ",", "'eval'", "]", "\n", "self", ".", "mode", "=", "mode", "\n", "for", "date", "in", "os", ".", "listdir", "(", "convo_path", ")", ":", "\n", "            ", "if", "(", "date", "==", "'2015-05'", "or", "date", "==", "'2015-06'", ")", "and", "mode", "==", "'train'", ":", "\n", "                ", "continue", "\n", "", "if", "mode", "==", "'eval'", "and", "date", "!=", "'2015-05'", ":", "\n", "                ", "continue", "\n", "", "fconvo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "convo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fper", "=", "open", "(", "os", ".", "path", ".", "join", "(", "persona_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fknow", "=", "open", "(", "os", ".", "path", ".", "join", "(", "knowledge_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fpseudo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "pseudo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "know_dict", "=", "json", ".", "load", "(", "fknow", ")", "\n", "per_dict", "=", "json", ".", "load", "(", "fper", ")", "\n", "for", "line1", ",", "line2", "in", "zip", "(", "fconvo", ".", "readlines", "(", ")", ",", "fpseudo", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "data", "=", "json", ".", "loads", "(", "line1", ")", "\n", "author", "=", "data", "[", "'author'", "]", "[", "-", "1", "]", "\n", "sid", "=", "data", "[", "'sid'", "]", "\n", "label", "=", "json", ".", "loads", "(", "line2", ")", "\n", "\n", "self", ".", "examples", ".", "append", "(", "{", "\n", "'context'", ":", "data", "[", "'dialog'", "]", "[", ":", "-", "1", "]", ",", "\n", "'response'", ":", "data", "[", "'dialog'", "]", "[", "-", "1", "]", ",", "\n", "'knowledge'", ":", "know_dict", "[", "sid", "]", ",", "\n", "'persona'", ":", "per_dict", "[", "author", "]", ",", "\n", "'klabel'", ":", "label", "[", "'klabel'", "]", ",", "\n", "'plabel'", ":", "label", "[", "'plabel'", "]", "\n", "}", ")", "\n", "", "if", "debug", ":", "\n", "                ", "break", "\n", "", "", "if", "mode", "==", "'eval'", "and", "args", ".", "eval_origin", "==", "'selected'", ":", "\n", "            ", "fselected", "=", "open", "(", "selected_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "line", "in", "fselected", ".", "readlines", "(", ")", ":", "\n", "                ", "selectedp", "=", "str", "(", "line", ")", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'<#p#>'", ")", "[", ":", "args", ".", "n_glue", "]", "\n", "if", "isinstance", "(", "selectedp", ",", "list", ")", ":", "\n", "                    ", "selectedp", "=", "' '", ".", "join", "(", "selectedp", ")", "\n", "", "self", ".", "selected", ".", "append", "(", "selectedp", ")", "\n", "\n", "", "", "if", "debug", "and", "mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "examples", "=", "self", ".", "examples", "[", ":", "16", "]", "\n", "self", ".", "selected", "=", "self", ".", "selected", "[", ":", "16", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.VAEKDataset.__len__": [[223, 225], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.VAEKDataset.__getitem__": [[226, 234], ["random.shuffle", "random.shuffle"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "example", "=", "self", ".", "examples", "[", "i", "]", "\n", "random", ".", "shuffle", "(", "example", "[", "'persona'", "]", ")", "\n", "random", ".", "shuffle", "(", "example", "[", "'knowledge'", "]", ")", "\n", "if", "self", ".", "mode", "==", "'eval'", "and", "args", ".", "eval_origin", "==", "'selected'", ":", "\n", "            ", "return", "example", "[", "'context'", "]", ",", "example", "[", "'response'", "]", ",", "example", "[", "'persona'", "]", ",", "example", "[", "'knowledge'", "]", ",", "self", ".", "selected", "[", "i", "]", ",", "example", "[", "'klabel'", "]", "\n", "", "else", ":", "\n", "            ", "return", "example", "[", "'context'", "]", ",", "example", "[", "'response'", "]", ",", "example", "[", "'persona'", "]", ",", "example", "[", "'knowledge'", "]", ",", "example", "[", "'plabel'", "]", ",", "example", "[", "'klabel'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.VAEKDataset.collate_fn": [[237, 246], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "context_list", "=", "[", "item", "[", "0", "]", "for", "item", "in", "batch", "]", "\n", "response_list", "=", "[", "item", "[", "1", "]", "for", "item", "in", "batch", "]", "\n", "persona_list", "=", "[", "item", "[", "2", "]", "for", "item", "in", "batch", "]", "\n", "knowledge_list", "=", "[", "item", "[", "3", "]", "for", "item", "in", "batch", "]", "\n", "plabel_list", "=", "[", "item", "[", "4", "]", "for", "item", "in", "batch", "]", "\n", "klabel_list", "=", "[", "item", "[", "5", "]", "for", "item", "in", "batch", "]", "\n", "return", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.recall_f1": [[129, 144], ["len", "range", "metric.f1_metric", "len", "len", "len", "sum", "len", "preds.append", "len", "len", "score.index", "max"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.f1_metric"], ["", "def", "recall_f1", "(", "scores", ",", "knowledges", ",", "responses", ")", ":", "\n", "    ", "count", "=", "[", "len", "(", "k", ")", "for", "k", "in", "knowledges", "]", "\n", "# all equals to the numbert of context", "\n", "assert", "len", "(", "knowledges", ")", "==", "len", "(", "responses", ")", "\n", "# all equals to the total number of knowledge sentences in every case", "\n", "assert", "sum", "(", "count", ")", "==", "len", "(", "scores", ")", "\n", "n", "=", "len", "(", "knowledges", ")", "\n", "preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "len", "(", "knowledges", "[", "i", "]", ")", "]", "\n", "scores", "=", "scores", "[", "len", "(", "knowledges", "[", "i", "]", ")", ":", "]", "\n", "knowledge", "=", "knowledges", "[", "i", "]", "\n", "pred", "=", "knowledge", "[", "score", ".", "index", "(", "max", "(", "score", ")", ")", "]", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "", "return", "f1_metric", "(", "preds", ",", "responses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.recall_metric": [[146, 174], ["range", "open", "json.load", "open", "json.load", "len", "numpy.array().sum", "len", "len", "len", "numpy.argsort", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "recall_metric", "(", "scores", ")", ":", "\n", "    ", "r1", ",", "r2", ",", "r5", ",", "r10", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "#count_path=r'/home/futc/cmudog/'+'train'+'_knowledge_count.json'", "\n", "#label_path=r'/home/futc/cmudog/'+'train'+'_label_index.json'", "\n", "with", "open", "(", "args", ".", "count_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "knowledge_count", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "args", ".", "label_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "label", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "assert", "len", "(", "scores", ")", "==", "np", ".", "array", "(", "knowledge_count", ")", ".", "sum", "(", ")", "\n", "assert", "len", "(", "knowledge_count", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "knowledge_count", ")", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "knowledge_count", "[", "i", "]", "]", "\n", "scores", "=", "scores", "[", "knowledge_count", "[", "i", "]", ":", "]", "\n", "order", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "gold", "=", "label", "[", "i", "]", "\n", "#gold=0 if correct_first else label[i]", "\n", "if", "gold", "in", "order", "[", ":", "1", "]", ":", "\n", "            ", "r1", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "2", "]", ":", "\n", "            ", "r2", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "5", "]", ":", "\n", "            ", "r5", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "10", "]", ":", "\n", "            ", "r10", "+=", "1", "\n", "\n", "", "", "return", "r1", "/", "len", "(", "knowledge_count", ")", ",", "r2", "/", "len", "(", "knowledge_count", ")", ",", "r5", "/", "len", "(", "knowledge_count", ")", ",", "r10", "/", "len", "(", "knowledge_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.train_step": [[323, 363], ["dualpk_model.eval", "priork_model.train", "range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "priork_optimizer.step", "priork_scheduler.step", "priork_optimizer.zero_grad", "next", "batcher.load", "batcher", "torch.kl_div", "F.kl_div.item", "F.kl_div.backward", "logger.info", "datetime.datetime.now().strftime", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "batcher", "priork_model", "prior_klogits.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "dualpk_model", "dual_klogits.view", "input_id.dim", "priork_model.parameters", "datetime.datetime.now", "input_id.dim", "input_id.view", "segment_id.view", "input_id.view", "segment_id.view", "input_id.view", "priork_scheduler.get_lr", "input_id.view"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "train_step", "(", "global_step", ")", ":", "\n", "    ", "klloss_total", "=", "0.0", "\n", "dualpk_model", ".", "eval", "(", ")", "\n", "priork_model", ".", "train", "(", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "accum_step", ")", ":", "\n", "        ", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "inputp_list", ",", "klabel_list", "=", "next", "(", "train_loader", ")", "\n", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "None", ",", "None", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'k|crp'", ",", "None", ",", "inputp_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "dual_klogits", "=", "dualpk_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "dual_klogits", "=", "dual_klogits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "", "batch_dict", "=", "batcher", "(", "'k|cp'", ",", "None", ",", "inputp_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "prior_klogits", "=", "priork_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "prior_klogits", "=", "prior_klogits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "klloss", "=", "F", ".", "kl_div", "(", "torch", ".", "log_softmax", "(", "prior_klogits", ",", "dim", "=", "1", ")", ",", "torch", ".", "softmax", "(", "dual_klogits", ",", "dim", "=", "1", ")", ")", "\n", "klloss_total", "+=", "klloss", ".", "item", "(", ")", "\n", "klloss", "=", "klloss", "/", "args", ".", "accum_step", "\n", "klloss", ".", "backward", "(", ")", "\n", "\n", "", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "priork_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "if", "grad_norm", ">=", "1e2", ":", "\n", "        ", "logger", ".", "info", "(", "'WARNING : Exploding Gradients {:.2f}'", ".", "format", "(", "grad_norm", ")", ")", "\n", "", "priork_optimizer", ".", "step", "(", ")", "\n", "priork_scheduler", ".", "step", "(", ")", "\n", "priork_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "print_every", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "        ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "logger", ".", "info", "(", "\"Step: %d \\t| ks_loss: %.3f \\t| lr: %.8f \\t| %s\"", "%", "(", "\n", "global_step", ",", "klloss_total", ",", "priork_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "time_str", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.vaek.predict_step": [[365, 415], ["priork_model.eval", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "priork_model.save_pretrained", "batcher.load", "batcher", "torch.tensor", "torch.tensor", "torch.tensor", "os.path.join", "open", "json.dump", "priork_model", "logits.view", "logger.info", "torch.topk", "torch.topk", "torch.topk", "hyp.detach().cpu().tolist.detach().cpu().tolist", "range", "os.path.join", "input_id.dim", "knowledge_list[].index", "hypothesis.append", "logger.info", "input_id.view", "segment_id.view", "range", "hyp.detach().cpu().tolist.detach().cpu", "input_id.view", "hyp.detach().cpu().tolist.detach", "min", "len"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "", "def", "predict_step", "(", "global_step", ")", ":", "\n", "#if split == 'test_seen':", "\n", "#    test_loader = test_seen_loader", "\n", "#else:", "\n", "#    raise ValueError", "\n", "    ", "hypothesis", "=", "[", "]", "\n", "priork_model", ".", "eval", "(", ")", "\n", "count", "=", "0", "\n", "hit1", "=", "0", "\n", "hit2", "=", "0", "\n", "hit5", "=", "0", "\n", "hit10", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "inputp_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "None", ",", "None", ")", "\n", "batch_dict", "=", "batcher", "(", "'k|cp'", ",", "None", ",", "inputp_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "priork_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "bs", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "ref", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "# hyp=torch.max(logits,dim=1)[1]", "\n", "# hit1+=torch.sum(hyp==ref,dim=0).item()", "\n", "hyp", "=", "torch", ".", "topk", "(", "logits", ",", "k", "=", "10", ")", "[", "1", "]", "\n", "hit1", "+=", "(", "hyp", "[", ":", ",", ":", "1", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit2", "+=", "(", "hyp", "[", ":", ",", ":", "2", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit5", "+=", "(", "hyp", "[", ":", ",", ":", "5", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit10", "+=", "(", "hyp", "[", ":", ",", ":", "10", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "try", ":", "\n", "                ", "hyp", "=", "hyp", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                    ", "hypothesis", ".", "append", "(", "'<#k#>'", ".", "join", "(", "[", "knowledge_list", "[", "i", "]", "[", "min", "(", "j", ",", "len", "(", "knowledge_list", "[", "i", "]", ")", "-", "1", ")", "]", "for", "j", "in", "hyp", "[", "i", "]", "]", ")", ")", "\n", "", "", "except", ":", "\n", "                ", "logger", ".", "info", "(", "\"error when decoding hypothesis\"", ")", "\n", "", "", "", "if", "not", "args", ".", "predict", ":", "\n", "        ", "priork_model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_priork_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "", "logger", ".", "info", "(", "\"Saved model checkpoint \\n\"", ")", "\n", "logger", ".", "info", "(", "\"hit at 1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 2 is {:.4f}\"", ".", "format", "(", "hit2", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 5 is {:.4f}\"", ".", "format", "(", "hit5", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"hit at 10 is {:.4f}\"", ".", "format", "(", "hit10", "/", "count", ")", ")", "\n", "\n", "if", "args", ".", "eval_origin", "==", "'selected'", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_knowledge'", ".", "format", "(", "global_step", ")", ")", ",", "mode", "=", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "hypothesis", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.bleu_corpus": [[13, 26], ["hypothesis.copy.copy", "references.copy.copy", "corpus_bleu", "corpus_bleu", "corpus_bleu", "corpus_bleu", "hyp.split", "ref.split", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.SmoothingFunction", "nltk.translate.bleu_score.SmoothingFunction"], "function", ["None"], ["def", "bleu_corpus", "(", "hypothesis", ",", "references", ")", ":", "\n", "    ", "from", "nltk", ".", "translate", ".", "bleu_score", "import", "corpus_bleu", "\n", "hypothesis", "=", "hypothesis", ".", "copy", "(", ")", "\n", "references", "=", "references", ".", "copy", "(", ")", "\n", "hypothesis", "=", "[", "hyp", ".", "split", "(", ")", "for", "hyp", "in", "hypothesis", "]", "\n", "references", "=", "[", "[", "ref", ".", "split", "(", ")", "]", "for", "ref", "in", "references", "]", "\n", "# hypothesis = [normalize_answer(hyp).split(\" \") for hyp in hypothesis]", "\n", "# references = [[normalize_answer(ref).split(\" \")] for ref in references]", "\n", "b1", "=", "corpus_bleu", "(", "references", ",", "hypothesis", ",", "weights", "=", "(", "1.0", "/", "1.0", ",", ")", ",", "smoothing_function", "=", "nltkbleu", ".", "SmoothingFunction", "(", "epsilon", "=", "1e-12", ")", ".", "method1", ")", "\n", "b2", "=", "corpus_bleu", "(", "references", ",", "hypothesis", ",", "weights", "=", "(", "1.0", "/", "2.0", ",", "1.0", "/", "2.0", ")", ",", "smoothing_function", "=", "nltkbleu", ".", "SmoothingFunction", "(", "epsilon", "=", "1e-12", ")", ".", "method1", ")", "\n", "b3", "=", "corpus_bleu", "(", "references", ",", "hypothesis", ",", "weights", "=", "(", "1.0", "/", "3.0", ",", "1.0", "/", "3.0", ",", "1.0", "/", "3.0", ")", ",", "smoothing_function", "=", "nltkbleu", ".", "SmoothingFunction", "(", "epsilon", "=", "1e-12", ")", ".", "method1", ")", "\n", "b4", "=", "corpus_bleu", "(", "references", ",", "hypothesis", ",", "weights", "=", "(", "1.0", "/", "4.0", ",", "1.0", "/", "4.0", ",", "1.0", "/", "4.0", ",", "1.0", "/", "4.0", ")", ",", "smoothing_function", "=", "nltkbleu", ".", "SmoothingFunction", "(", "epsilon", "=", "1e-12", ")", ".", "method1", ")", "\n", "return", "(", "b1", ",", "b2", ",", "b3", ",", "b4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.bleu_metric": [[27, 29], ["metric.bleu_corpus"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.bleu_corpus"], ["", "def", "bleu_metric", "(", "hypothesis", ",", "references", ")", ":", "\n", "    ", "return", "bleu_corpus", "(", "hypothesis", ",", "references", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.distinct_metric": [[31, 46], ["collections.Counter", "collections.Counter", "hypo.split", "unigram_counter.update", "bigram_counter.update", "len", "sum", "len", "sum", "nltk.ngrams", "unigram_counter.values", "bigram_counter.values"], "function", ["None"], ["", "def", "distinct_metric", "(", "hypothesis", ")", ":", "\n", "    ", "'''\n    compute distinct metric\n    :param hypothesis: list of str\n    :return:\n    '''", "\n", "unigram_counter", ",", "bigram_counter", "=", "Counter", "(", ")", ",", "Counter", "(", ")", "\n", "for", "hypo", "in", "hypothesis", ":", "\n", "        ", "tokens", "=", "hypo", ".", "split", "(", ")", "\n", "unigram_counter", ".", "update", "(", "tokens", ")", "\n", "bigram_counter", ".", "update", "(", "ngrams", "(", "tokens", ",", "2", ")", ")", "\n", "\n", "", "distinct_1", "=", "len", "(", "unigram_counter", ")", "/", "sum", "(", "unigram_counter", ".", "values", "(", ")", ")", "\n", "distinct_2", "=", "len", "(", "bigram_counter", ")", "/", "sum", "(", "bigram_counter", ".", "values", "(", ")", ")", "\n", "return", "distinct_1", ",", "distinct_2", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer": [[50, 66], ["metric.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re_art", ".", "sub", "(", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "return", "re_punc", ".", "sub", "(", "' '", ",", "text", ")", "# convert punctuation to spaces", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer_new": [[67, 83], ["white_space_fix().split", "re_art.sub", "re_punc.sub", "text.lower", "text.split", "metric.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer_new", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re_art", ".", "sub", "(", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "return", "re_punc", ".", "sub", "(", "' '", ",", "text", ")", "# convert punctuation to spaces", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", ".", "split", "(", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._prec_recall_f1_score": [[85, 100], ["sum", "collections.Counter", "collections.Counter", "common.values", "len", "len"], "function", ["None"], ["", "def", "_prec_recall_f1_score", "(", "pred_items", ",", "gold_items", ")", ":", "\n", "    ", "\"\"\"\n    Compute precision, recall and f1 given a set of gold and prediction items.\n    :param pred_items: iterable of predicted values\n    :param gold_items: iterable of gold values\n    :return: tuple (p, r, f1) for precision, recall, f1\n    \"\"\"", "\n", "common", "=", "Counter", "(", "gold_items", ")", "&", "Counter", "(", "pred_items", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", ",", "0", ",", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_items", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_items", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._f1_score": [[102, 111], ["normalize_answer().split", "max", "metric._prec_recall_f1_score", "metric.normalize_answer", "normalize_answer().split", "metric.normalize_answer"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._prec_recall_f1_score", "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer", "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer"], ["", "def", "_f1_score", "(", "guess", ",", "answers", ")", ":", "\n", "    ", "\"\"\"Return the max F1 score between the guess and *any* answer.\"\"\"", "\n", "if", "guess", "is", "None", "or", "answers", "is", "None", ":", "\n", "        ", "return", "0", "\n", "", "g_tokens", "=", "normalize_answer", "(", "guess", ")", ".", "split", "(", ")", "\n", "scores", "=", "[", "\n", "_prec_recall_f1_score", "(", "g_tokens", ",", "normalize_answer", "(", "a", ")", ".", "split", "(", ")", ")", "for", "a", "in", "answers", "\n", "]", "\n", "return", "max", "(", "f1", "for", "_", ",", "_", ",", "f1", "in", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._recall_score": [[112, 121], ["normalize_answer().split", "max", "metric._prec_recall_f1_score", "metric.normalize_answer", "normalize_answer().split", "metric.normalize_answer"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._prec_recall_f1_score", "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer", "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer"], ["", "def", "_recall_score", "(", "guess", ",", "answers", ")", ":", "\n", "    ", "\"\"\"Return the max F1 score between the guess and *any* answer.\"\"\"", "\n", "if", "guess", "is", "None", "or", "answers", "is", "None", ":", "\n", "        ", "return", "0", "\n", "", "g_tokens", "=", "normalize_answer", "(", "guess", ")", ".", "split", "(", ")", "\n", "scores", "=", "[", "\n", "_prec_recall_f1_score", "(", "g_tokens", ",", "normalize_answer", "(", "a", ")", ".", "split", "(", ")", ")", "for", "a", "in", "answers", "\n", "]", "\n", "return", "max", "(", "recall", "for", "_", ",", "recall", ",", "_", "in", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._precision_score": [[122, 131], ["normalize_answer().split", "max", "metric._prec_recall_f1_score", "metric.normalize_answer", "normalize_answer().split", "metric.normalize_answer"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._prec_recall_f1_score", "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer", "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.normalize_answer"], ["", "def", "_precision_score", "(", "guess", ",", "answers", ")", ":", "\n", "    ", "\"\"\"Return the max F1 score between the guess and *any* answer.\"\"\"", "\n", "if", "guess", "is", "None", "or", "answers", "is", "None", ":", "\n", "        ", "return", "0", "\n", "", "g_tokens", "=", "normalize_answer", "(", "guess", ")", ".", "split", "(", ")", "\n", "scores", "=", "[", "\n", "_prec_recall_f1_score", "(", "g_tokens", ",", "normalize_answer", "(", "a", ")", ".", "split", "(", ")", ")", "for", "a", "in", "answers", "\n", "]", "\n", "return", "max", "(", "precision", "for", "precision", ",", "_", ",", "_", "in", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.f1_metric": [[133, 145], ["zip", "numpy.mean", "metric._f1_score", "f1.append"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric._f1_score"], ["", "def", "f1_metric", "(", "hypothesis", ",", "references", ")", ":", "\n", "    ", "'''\n    calculate f1 metric\n    :param hypothesis: list of str\n    :param references: list of str\n    :return:\n    '''", "\n", "f1", "=", "[", "]", "\n", "for", "hyp", ",", "ref", "in", "zip", "(", "hypothesis", ",", "references", ")", ":", "\n", "        ", "_f1", "=", "_f1_score", "(", "hyp", ",", "[", "ref", "]", ")", "\n", "f1", ".", "append", "(", "_f1", ")", "\n", "", "return", "np", ".", "mean", "(", "f1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.recall_2at1": [[147, 156], ["len", "numpy.argsort", "float", "numpy.array"], "function", ["None"], ["", "def", "recall_2at1", "(", "score_list", ",", "k", "=", "1", ")", ":", "\n", "    ", "num_correct", "=", "0", "\n", "num_total", "=", "len", "(", "score_list", ")", "\n", "for", "scores", "in", "score_list", ":", "\n", "        ", "ranking_index", "=", "np", ".", "argsort", "(", "-", "np", ".", "array", "(", "scores", "[", "0", ":", "2", "]", ")", ")", "\n", "# Message at index 0 is always correct next message in our test data", "\n", "if", "0", "in", "ranking_index", "[", ":", "k", "]", ":", "\n", "            ", "num_correct", "+=", "1", "\n", "", "", "return", "float", "(", "num_correct", ")", "/", "num_total", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.recall_at_k": [[158, 167], ["len", "numpy.argsort", "float", "numpy.array"], "function", ["None"], ["", "def", "recall_at_k", "(", "score_list", ",", "k", "=", "1", ")", ":", "\n", "    ", "num_correct", "=", "0", "\n", "num_total", "=", "len", "(", "score_list", ")", "\n", "for", "scores", "in", "score_list", ":", "\n", "        ", "ranking_index", "=", "np", ".", "argsort", "(", "-", "np", ".", "array", "(", "scores", ")", ")", "\n", "# Message at index 0 is always correct next message in our test data", "\n", "if", "0", "in", "ranking_index", "[", ":", "k", "]", ":", "\n", "            ", "num_correct", "+=", "1", "\n", "", "", "return", "float", "(", "num_correct", ")", "/", "num_total", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.recall_at_k_new": [[169, 185], ["scores.reshape.reshape", "labels.reshape.reshape", "range", "numpy.sort", "numpy.argsort", "numpy.sum", "range", "float", "float", "float"], "function", ["None"], ["", "def", "recall_at_k_new", "(", "labels", ",", "scores", ",", "k", "=", "1", ",", "doc_num", "=", "10", ")", ":", "\n", "    ", "scores", "=", "scores", ".", "reshape", "(", "-", "1", ",", "doc_num", ")", "# [batch, doc_num]", "\n", "labels", "=", "labels", ".", "reshape", "(", "-", "1", ",", "doc_num", ")", "# # [batch, doc_num]", "\n", "sorted", ",", "indices", "=", "np", ".", "sort", "(", "scores", ",", "1", ")", ",", "np", ".", "argsort", "(", "-", "scores", ",", "1", ")", "\n", "count_nonzero", "=", "0", "\n", "recall", "=", "0", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "num_rel", "=", "np", ".", "sum", "(", "labels", "[", "i", "]", ")", "\n", "if", "num_rel", "==", "0", ":", "continue", "\n", "rel", "=", "0", "\n", "for", "j", "in", "range", "(", "k", ")", ":", "\n", "            ", "if", "labels", "[", "i", ",", "indices", "[", "i", ",", "j", "]", "]", "==", "1", ":", "\n", "                ", "rel", "+=", "1", "\n", "", "", "recall", "+=", "float", "(", "rel", ")", "/", "float", "(", "num_rel", ")", "\n", "count_nonzero", "+=", "1", "\n", "", "return", "float", "(", "recall", ")", "/", "count_nonzero", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.precision_at_k": [[187, 204], ["scores.reshape.reshape", "labels.reshape.reshape", "range", "numpy.sort", "numpy.argsort", "numpy.sum", "range", "float", "float"], "function", ["None"], ["", "def", "precision_at_k", "(", "labels", ",", "scores", ",", "k", "=", "1", ",", "doc_num", "=", "10", ")", ":", "\n", "    ", "scores", "=", "scores", ".", "reshape", "(", "-", "1", ",", "doc_num", ")", "# [batch, doc_num]", "\n", "labels", "=", "labels", ".", "reshape", "(", "-", "1", ",", "doc_num", ")", "# [batch, doc_num]", "\n", "\n", "sorted", ",", "indices", "=", "np", ".", "sort", "(", "scores", ",", "1", ")", ",", "np", ".", "argsort", "(", "-", "scores", ",", "1", ")", "\n", "count_nonzero", "=", "0", "\n", "precision", "=", "0", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "num_rel", "=", "np", ".", "sum", "(", "labels", "[", "i", "]", ")", "\n", "if", "num_rel", "==", "0", ":", "continue", "\n", "rel", "=", "0", "\n", "for", "j", "in", "range", "(", "k", ")", ":", "\n", "            ", "if", "labels", "[", "i", ",", "indices", "[", "i", ",", "j", "]", "]", "==", "1", ":", "\n", "                ", "rel", "+=", "1", "\n", "", "", "precision", "+=", "float", "(", "rel", ")", "/", "float", "(", "k", ")", "\n", "count_nonzero", "+=", "1", "\n", "", "return", "precision", "/", "count_nonzero", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.MAP": [[206, 235], ["target.reshape.reshape", "logits.reshape.reshape", "range", "numpy.argsort", "range", "float", "numpy.sort", "float"], "function", ["None"], ["", "def", "MAP", "(", "target", ",", "logits", ",", "k", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Compute mean average precision.\n    :param target: 2d array [batch_size x num_clicks_per_query] true\n    :param logits: 2d array [batch_size x num_clicks_per_query] pred\n    :return: mean average precision [a float value]\n    \"\"\"", "\n", "assert", "logits", ".", "shape", "==", "target", ".", "shape", "\n", "\n", "target", "=", "target", ".", "reshape", "(", "-", "1", ",", "k", ")", "\n", "logits", "=", "logits", ".", "reshape", "(", "-", "1", ",", "k", ")", "\n", "\n", "sorted", ",", "indices", "=", "np", ".", "sort", "(", "logits", ",", "1", ")", "[", ":", ":", "-", "1", "]", ",", "np", ".", "argsort", "(", "-", "logits", ",", "1", ")", "\n", "count_nonzero", "=", "0", "\n", "map_sum", "=", "0", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "average_precision", "=", "0", "\n", "num_rel", "=", "0", "\n", "for", "j", "in", "range", "(", "indices", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "target", "[", "i", ",", "indices", "[", "i", ",", "j", "]", "]", "==", "1", ":", "\n", "                ", "num_rel", "+=", "1", "\n", "average_precision", "+=", "float", "(", "num_rel", ")", "/", "(", "j", "+", "1", ")", "\n", "", "", "if", "num_rel", "==", "0", ":", "continue", "\n", "average_precision", "=", "average_precision", "/", "num_rel", "\n", "# print(\"average_precision: \", average_precision)", "\n", "map_sum", "+=", "average_precision", "\n", "count_nonzero", "+=", "1", "\n", "# return map_sum / indices.shape[0]", "\n", "", "return", "float", "(", "map_sum", ")", "/", "count_nonzero", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.MRR": [[237, 262], ["target.reshape.reshape", "logits.reshape.reshape", "range", "numpy.argsort", "range", "float", "numpy.sort", "float"], "function", ["None"], ["", "def", "MRR", "(", "target", ",", "logits", ",", "k", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Compute mean reciprocal rank.\n    :param target: 2d array [batch_size x rel_docs_per_query]\n    :param logits: 2d array [batch_size x rel_docs_per_query]\n    :return: mean reciprocal rank [a float value]\n    \"\"\"", "\n", "assert", "logits", ".", "shape", "==", "target", ".", "shape", "\n", "target", "=", "target", ".", "reshape", "(", "-", "1", ",", "k", ")", "\n", "logits", "=", "logits", ".", "reshape", "(", "-", "1", ",", "k", ")", "\n", "\n", "sorted", ",", "indices", "=", "np", ".", "sort", "(", "logits", ",", "1", ")", "[", ":", ":", "-", "1", "]", ",", "np", ".", "argsort", "(", "-", "logits", ",", "1", ")", "\n", "count_nonzero", "=", "0", "\n", "reciprocal_rank", "=", "0", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "flag", "=", "0", "\n", "for", "j", "in", "range", "(", "indices", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "target", "[", "i", ",", "indices", "[", "i", ",", "j", "]", "]", "==", "1", ":", "\n", "                ", "reciprocal_rank", "+=", "float", "(", "1.0", ")", "/", "(", "j", "+", "1", ")", "\n", "flag", "=", "1", "\n", "break", "\n", "", "", "if", "flag", ":", "count_nonzero", "+=", "1", "\n", "\n", "# return reciprocal_rank / indices.shape[0]", "\n", "", "return", "float", "(", "reciprocal_rank", ")", "/", "count_nonzero", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.NDCG": [[264, 295], ["target.reshape.reshape", "logits.reshape.reshape", "range", "numpy.argsort", "numpy.count_nonzero", "range", "range", "float", "numpy.sort", "float", "numpy.log2", "float", "numpy.log2"], "function", ["None"], ["", "def", "NDCG", "(", "target", ",", "logits", ",", "k", ")", ":", "\n", "    ", "\"\"\"\n    Compute normalized discounted cumulative gain.\n    :param target: 2d array [batch_size x rel_docs_per_query]\n    :param logits: 2d array [batch_size x rel_docs_per_query]\n    :return: mean average precision [a float value]\n    \"\"\"", "\n", "assert", "logits", ".", "shape", "==", "target", ".", "shape", "\n", "target", "=", "target", ".", "reshape", "(", "-", "1", ",", "k", ")", "\n", "logits", "=", "logits", ".", "reshape", "(", "-", "1", ",", "k", ")", "\n", "\n", "assert", "logits", ".", "shape", "[", "1", "]", ">=", "k", ",", "'NDCG@K cannot be computed, invalid value of K.'", "\n", "\n", "sorted", ",", "indices", "=", "np", ".", "sort", "(", "logits", ",", "1", ")", "[", ":", ":", "-", "1", "]", ",", "np", ".", "argsort", "(", "-", "logits", ",", "1", ")", "\n", "NDCG", "=", "0", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "DCG_ref", "=", "0", "\n", "num_rel_docs", "=", "np", ".", "count_nonzero", "(", "target", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "indices", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "j", "==", "k", ":", "\n", "                ", "break", "\n", "", "if", "target", "[", "i", ",", "indices", "[", "i", ",", "j", "]", "]", "==", "1", ":", "\n", "                ", "DCG_ref", "+=", "float", "(", "1.0", ")", "/", "np", ".", "log2", "(", "j", "+", "2", ")", "\n", "", "", "DCG_gt", "=", "0", "\n", "for", "j", "in", "range", "(", "num_rel_docs", ")", ":", "\n", "            ", "if", "j", "==", "k", ":", "\n", "                ", "break", "\n", "", "DCG_gt", "+=", "float", "(", "1.0", ")", "/", "np", ".", "log2", "(", "j", "+", "2", ")", "\n", "", "NDCG", "+=", "DCG_ref", "/", "DCG_gt", "\n", "\n", "", "return", "float", "(", "NDCG", ")", "/", "indices", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.METEOR_metric": [[296, 310], ["NLGEval", "NLGEval.compute_metrics"], "function", ["None"], ["", "def", "METEOR_metric", "(", "hypothesis", ",", "references", ")", ":", "\n", "    ", "from", "nlgeval", "import", "NLGEval", "\n", "# from metrics import f1_metric, distinct_metric", "\n", "nlgeval", "=", "NLGEval", "(", "metrics_to_omit", "=", "[", "\n", "'CIDEr'", ",", "\n", "'SkipThoughtCS'", ",", "\n", "'EmbeddingAverageCosineSimilairty'", ",", "\n", "'VectorExtremaCosineSimilarity'", ",", "\n", "'GreedyMatchingScore'", ",", "\n", "'Bleu_1'", ",", "'Bleu_2'", ",", "'Bleu_3'", ",", "'Bleu_4'", ",", "\n", "'ROUGE_L'", "\n", "]", ")", "\n", "metrics_dict", "=", "nlgeval", ".", "compute_metrics", "(", "[", "references", "]", ",", "hypothesis", ")", "\n", "return", "metrics_dict", "[", "'METEOR'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.ROUGE_metric": [[311, 325], ["NLGEval", "NLGEval.compute_metrics"], "function", ["None"], ["", "def", "ROUGE_metric", "(", "hypothesis", ",", "references", ")", ":", "\n", "    ", "from", "nlgeval", "import", "NLGEval", "\n", "# from metrics import f1_metric, distinct_metric", "\n", "nlgeval", "=", "NLGEval", "(", "metrics_to_omit", "=", "[", "\n", "'CIDEr'", ",", "\n", "'SkipThoughtCS'", ",", "\n", "'EmbeddingAverageCosineSimilairty'", ",", "\n", "'VectorExtremaCosineSimilarity'", ",", "\n", "'GreedyMatchingScore'", ",", "\n", "'Bleu_1'", ",", "'Bleu_2'", ",", "'Bleu_3'", ",", "'Bleu_4'", ",", "\n", "'METEOR'", "\n", "]", ")", "\n", "metrics_dict", "=", "nlgeval", ".", "compute_metrics", "(", "[", "references", "]", ",", "hypothesis", ")", "\n", "return", "metrics_dict", "[", "'ROUGE_L'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.metric.rouge_metric": [[328, 349], ["rouge_scorer.RougeScorer", "zip", "scores.keys", "rouge_scorer.RougeScorer.score", "scorer.score.items", "scores[].append", "numpy.mean", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "rouge_metric", "(", "hypothesis", ",", "references", ",", "use_stemmer", "=", "True", ",", "average", "=", "True", ")", ":", "\n", "    ", "from", "language_evaluation", "import", "rouge_scorer", "\n", "\n", "rouge_types", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", "\n", "# rouge_types = [\"rouge1\", \"rouge2\"]", "\n", "scorer", "=", "rouge_scorer", ".", "RougeScorer", "(", "rouge_types", ",", "use_stemmer", ",", "normalize_answer_new", ")", "\n", "scores", "=", "{", "rouge_type", ":", "[", "]", "for", "rouge_type", "in", "rouge_types", "}", "\n", "for", "predict", ",", "answer", "in", "zip", "(", "hypothesis", ",", "references", ")", ":", "\n", "# TODO : support multi-reference", "\n", "        ", "score", "=", "scorer", ".", "score", "(", "answer", ",", "predict", ")", "\n", "for", "key", ",", "value", "in", "score", ".", "items", "(", ")", ":", "\n", "            ", "scores", "[", "key", "]", ".", "append", "(", "value", ".", "fmeasure", ")", "\n", "\n", "# Averaging", "\n", "", "", "for", "key", "in", "scores", ".", "keys", "(", ")", ":", "\n", "        ", "if", "average", ":", "\n", "            ", "scores", "[", "key", "]", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "scores", "[", "key", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "scores", "[", "key", "]", "=", "np", ".", "array", "(", "scores", "[", "key", "]", ")", "\n", "\n", "", "", "return", "scores", "[", "'rouge1'", "]", ",", "scores", "[", "'rouge2'", "]", ",", "scores", "[", "'rougeL'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.dual.recall_metric": [[125, 153], ["range", "open", "json.load", "open", "json.load", "len", "numpy.array().sum", "len", "len", "len", "numpy.argsort", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "recall_metric", "(", "scores", ")", ":", "\n", "    ", "r1", ",", "r2", ",", "r5", ",", "r10", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "#count_path=r'/home/futc/cmudog/'+'train'+'_knowledge_count.json'", "\n", "#label_path=r'/home/futc/cmudog/'+'train'+'_label_index.json'", "\n", "with", "open", "(", "args", ".", "count_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "knowledge_count", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "args", ".", "label_path", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "label", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "assert", "len", "(", "scores", ")", "==", "np", ".", "array", "(", "knowledge_count", ")", ".", "sum", "(", ")", "\n", "assert", "len", "(", "knowledge_count", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "knowledge_count", ")", ")", ":", "\n", "        ", "score", "=", "scores", "[", ":", "knowledge_count", "[", "i", "]", "]", "\n", "scores", "=", "scores", "[", "knowledge_count", "[", "i", "]", ":", "]", "\n", "order", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "gold", "=", "label", "[", "i", "]", "\n", "#gold=0 if correct_first else label[i]", "\n", "if", "gold", "in", "order", "[", ":", "1", "]", ":", "\n", "            ", "r1", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "2", "]", ":", "\n", "            ", "r2", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "5", "]", ":", "\n", "            ", "r5", "+=", "1", "\n", "", "if", "gold", "in", "order", "[", ":", "10", "]", ":", "\n", "            ", "r10", "+=", "1", "\n", "\n", "", "", "return", "r1", "/", "len", "(", "knowledge_count", ")", ",", "r2", "/", "len", "(", "knowledge_count", ")", ",", "r5", "/", "len", "(", "knowledge_count", ")", ",", "r10", "/", "len", "(", "knowledge_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.dual.train_step": [[241, 348], ["range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "dualkp_optimizer.step", "dualkp_scheduler.step", "dualkp_optimizer.zero_grad", "dualpk_optimizer.step", "dualpk_scheduler.step", "dualpk_optimizer.zero_grad", "next", "dualpk_model.train", "dualkp_model.eval", "batcher.load", "batcher", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "dual_loss1.item", "dual_loss1.backward", "dualkp_model.train", "dualpk_model.eval", "batcher", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "dual_loss2.item", "dual_loss2.backward", "logger.info", "datetime.datetime.now().strftime", "logger.info", "dualpk_model", "dual_klogits.view", "torch.no_grad", "torch.no_grad", "batcher", "torch.tensor", "torch.tensor", "torch.softmax", "torch.softmax", "torch.gather().squeeze", "torch.gather().squeeze", "torch.sum", "torch.sum", "dualkp_model", "dual_plogits.view", "torch.no_grad", "torch.no_grad", "batcher", "torch.tensor", "torch.tensor", "torch.softmax", "torch.softmax", "torch.gather().squeeze", "torch.gather().squeeze", "torch.sum", "torch.sum", "input_id.dim", "torch.multinomial", "torch.multinomial", "range", "dualkp_model", "post_plogits.view", "torch.gather", "torch.gather", "input_id.dim", "torch.multinomial", "torch.multinomial", "range", "dualpk_model", "post_klogits.view", "torch.gather", "torch.gather", "dualkp_model.parameters", "dualpk_model.parameters", "datetime.datetime.now", "input_id.view", "segment_id.view", "torch.softmax", "torch.softmax", "min", "input_id.dim", "persona_list[].index", "torch.gather", "torch.gather", "torch.log_softmax", "torch.log_softmax", "input_id.view", "segment_id.view", "torch.softmax", "torch.softmax", "min", "input_id.dim", "knowledge_list[].index", "torch.gather", "torch.gather", "torch.log_softmax", "torch.log_softmax", "input_id.view", "kind[].item", "input_id.view", "segment_id.view", "range", "torch.multinomial().squeeze.unsqueeze", "input_id.view", "pind[].item", "input_id.view", "segment_id.view", "range", "torch.multinomial().squeeze.unsqueeze", "dualkp_scheduler.get_lr", "len", "input_id.view", "torch.tensor.unsqueeze", "len", "input_id.view", "torch.tensor.unsqueeze"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "def", "train_step", "(", "global_step", ")", ":", "\n", "    ", "dualloss_total", "=", "0.0", "\n", "for", "_", "in", "range", "(", "args", ".", "accum_step", ")", ":", "\n", "        ", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "=", "next", "(", "train_loader", ")", "\n", "#The dual learning part", "\n", "dualpk_model", ".", "train", "(", ")", "\n", "dualkp_model", ".", "eval", "(", ")", "\n", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "batch_dict", "=", "batcher", "(", "'k|crp'", ",", "None", ",", "plabel_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "#(bs*n_know,2)", "\n", "dual_klogits", "=", "dualpk_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "#(bs,n_know)", "\n", "dual_klogits", "=", "dual_klogits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "#(bs)", "\n", "kind", "=", "torch", ".", "multinomial", "(", "torch", ".", "softmax", "(", "dual_klogits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ",", "replacement", "=", "True", ")", ".", "squeeze", "(", "1", ")", "\n", "#kind=torch.max(dual_klogits,dim=1)[1].detach().cpu().tolist()", "\n", "selected_know", "=", "[", "knowledge_list", "[", "i", "]", "[", "min", "(", "kind", "[", "i", "]", ".", "item", "(", ")", ",", "len", "(", "knowledge_list", "[", "i", "]", ")", "-", "1", ")", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'p|crk'", ",", "selected_know", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "# (bs*n_per,2)", "\n", "post_plogits", "=", "dualkp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "# (bs,n_per)", "\n", "post_plogits", "=", "post_plogits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "#(bs)", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "#(bs)", "\n", "post_pprob", "=", "torch", ".", "softmax", "(", "post_plogits", ",", "dim", "=", "1", ")", "\n", "# TODO: the reward need to be designed", "\n", "reward", "=", "torch", ".", "gather", "(", "post_pprob", ",", "dim", "=", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "# the tensor to backward the gradient ", "\n", "", "tensor1", "=", "torch", ".", "gather", "(", "torch", ".", "log_softmax", "(", "dual_klogits", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ",", "index", "=", "kind", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "dual_loss1", "=", "-", "torch", ".", "sum", "(", "tensor1", "*", "reward", ",", "dim", "=", "0", ")", "\n", "dualloss_total", "+=", "dual_loss1", ".", "item", "(", ")", "\n", "dual_loss1", "=", "dual_loss1", "/", "args", ".", "accum_step", "\n", "dual_loss1", ".", "backward", "(", ")", "\n", "\n", "dualkp_model", ".", "train", "(", ")", "\n", "dualpk_model", ".", "eval", "(", ")", "\n", "batch_dict", "=", "batcher", "(", "'p|crk'", ",", "klabel_list", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "# (bs*n_per,2)", "\n", "dual_plogits", "=", "dualkp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "# (bs,n_per)", "\n", "dual_plogits", "=", "dual_plogits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "pind", "=", "torch", ".", "multinomial", "(", "torch", ".", "softmax", "(", "dual_plogits", ",", "dim", "=", "1", ")", ",", "num_samples", "=", "1", ",", "replacement", "=", "True", ")", ".", "squeeze", "(", "1", ")", "\n", "#pind=torch.max(dual_plogits,dim=1)[1].detach().cpu().tolist()", "\n", "selected_per", "=", "[", "persona_list", "[", "i", "]", "[", "min", "(", "pind", "[", "i", "]", ".", "item", "(", ")", ",", "len", "(", "persona_list", "[", "i", "]", ")", "-", "1", ")", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_dict", "=", "batcher", "(", "'k|crp'", ",", "None", ",", "selected_per", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "#(bs*n_know,2)", "\n", "post_klogits", "=", "dualpk_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "#(bs,n_know)", "\n", "post_klogits", "=", "post_klogits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "#(bs)", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "#(bs)", "\n", "post_kprob", "=", "torch", ".", "softmax", "(", "post_klogits", ",", "dim", "=", "1", ")", "\n", "#reward=torch.gather(post_kprob,dim=1,index=target.unsqueeze(1)).squeeze(1)-torch.tensor([0.5]*bs,dtype=torch.float,device=device)", "\n", "reward", "=", "torch", ".", "gather", "(", "post_kprob", ",", "dim", "=", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "#reward=torch.gather(post_klogits,dim=1,index=target.unsqueeze(1)).squeeze(1)-torch.mean(post_klogits,dim=1)", "\n", "", "tensor2", "=", "torch", ".", "gather", "(", "torch", ".", "log_softmax", "(", "dual_plogits", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ",", "index", "=", "pind", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "dual_loss2", "=", "-", "torch", ".", "sum", "(", "tensor2", "*", "reward", ",", "dim", "=", "0", ")", "\n", "dualloss_total", "+=", "dual_loss2", ".", "item", "(", ")", "\n", "dual_loss2", "=", "dual_loss2", "/", "args", ".", "accum_step", "\n", "dual_loss2", ".", "backward", "(", ")", "\n", "# if args.dual_loss=='ce':", "\n", "#     loss=F.cross_entropy(plogits,target)", "\n", "# elif args.dual_loss=='mm':", "\n", "#     loss=F.multi_margin_loss(logits,target)", "\n", "# label=batch_dict['label']", "\n", "# loss=model(input_ids=input_id,attention_mask=attention_mask,token_type_ids=segment_id,labels=label,return_dict=True)['loss']", "\n", "# loss.backward()", "\n", "# ks_loss_total += loss.item()", "\n", "\n", "", "grad_norm1", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "dualkp_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "grad_norm2", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "dualpk_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "args", ".", "clip", ")", "\n", "if", "grad_norm1", ">=", "1e2", "or", "grad_norm2", ">", "1e2", ":", "\n", "        ", "logger", ".", "info", "(", "'WARNING : Exploding Gradients {:.2f} {:.2f}'", ".", "format", "(", "grad_norm1", ",", "grad_norm2", ")", ")", "\n", "", "dualkp_optimizer", ".", "step", "(", ")", "\n", "dualkp_scheduler", ".", "step", "(", ")", "\n", "dualkp_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "dualpk_optimizer", ".", "step", "(", ")", "\n", "dualpk_scheduler", ".", "step", "(", ")", "\n", "dualpk_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "print_every", "==", "0", "and", "global_step", "!=", "0", ":", "\n", "        ", "time_str", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", "\n", "logger", ".", "info", "(", "\"Step: %d \\t| ks_loss: %.3f \\t| lr: %.8f \\t| %s\"", "%", "(", "\n", "global_step", ",", "dualloss_total", ",", "dualkp_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "time_str", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.None.dual.predict_step": [[351, 443], ["dualkp_model.eval", "dualpk_model.eval", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "dualpk_model.save_pretrained", "dualkp_model.save_pretrained", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "exit", "os.path.join", "os.path.join", "batcher.load", "batcher", "len", "len", "torch.tensor", "torch.tensor", "batcher.load", "batcher", "len", "len", "torch.tensor", "torch.tensor", "dualpk_model", "logits.view", "logger.info", "torch.topk", "torch.topk", "dualkp_model", "logits.view", "logger.info", "torch.topk", "torch.topk", "input_id.dim", "knowledge_list[].index", "input_id.dim", "persona_list[].index", "input_id.view", "segment_id.view", "range", "input_id.view", "segment_id.view", "range", "input_id.view", "input_id.view"], "function", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["", "", "def", "predict_step", "(", "global_step", ")", ":", "\n", "#if split == 'test_seen':", "\n", "#    test_loader = test_seen_loader", "\n", "#else:", "\n", "#    raise ValueError", "\n", "    ", "dualkp_model", ".", "eval", "(", ")", "\n", "dualpk_model", ".", "eval", "(", ")", "\n", "hit1", "=", "0", "\n", "hit2", "=", "0", "\n", "hit5", "=", "0", "\n", "hit10", "=", "0", "\n", "count", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "batch_dict", "=", "batcher", "(", "'k|crp'", ",", "None", ",", "plabel_list", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_know", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "dualpk_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "(", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_know", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "len", "(", "context_list", ")", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "bs", "=", "len", "(", "context_list", ")", "\n", "ref", "=", "torch", ".", "tensor", "(", "[", "knowledge_list", "[", "i", "]", ".", "index", "(", "klabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "# hyp=torch.max(logits,dim=1)[1]", "\n", "# hit1+=torch.sum(hyp==ref,dim=0).item()", "\n", "hyp", "=", "torch", ".", "topk", "(", "logits", ",", "k", "=", "10", ")", "[", "1", "]", "\n", "hit1", "+=", "(", "hyp", "[", ":", ",", ":", "1", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit2", "+=", "(", "hyp", "[", ":", ",", ":", "2", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit5", "+=", "(", "hyp", "[", ":", ",", ":", "5", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit10", "+=", "(", "hyp", "[", ":", ",", ":", "10", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"knowledge prediction hit1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"knowledge prediction hit2 is {:.4f}\"", ".", "format", "(", "hit2", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"knowledge prediction hit5 is {:.4f}\"", ".", "format", "(", "hit5", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"knowledge prediction hit10 is {:.4f}\"", ".", "format", "(", "hit10", "/", "count", ")", ")", "\n", "\n", "hit1", "=", "0", "\n", "hit2", "=", "0", "\n", "hit5", "=", "0", "\n", "hit10", "=", "0", "\n", "count", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "in", "eval_loader", ":", "\n", "            ", "batcher", ".", "load", "(", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", "\n", "batch_dict", "=", "batcher", "(", "'p|crk'", ",", "klabel_list", ",", "None", ")", "\n", "input_id", "=", "batch_dict", "[", "'input_id'", "]", "\n", "segment_id", "=", "batch_dict", "[", "'segment_id'", "]", "\n", "assert", "input_id", ".", "dim", "(", ")", "==", "3", "and", "input_id", ".", "shape", "==", "segment_id", ".", "shape", "\n", "bs", ",", "n_per", ",", "seq_len", "=", "input_id", ".", "shape", "\n", "logits", "=", "dualkp_model", "(", "input_ids", "=", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "attention_mask", "=", "(", "input_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", "!=", "tokenizer", ".", "pad_token_id", ")", ",", "token_type_ids", "=", "segment_id", ".", "view", "(", "-", "1", ",", "seq_len", ")", ",", "return_dict", "=", "True", ")", "[", "'logits'", "]", "\n", "logits", "=", "logits", ".", "view", "(", "bs", ",", "n_per", ",", "-", "1", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "count", "+=", "len", "(", "context_list", ")", "\n", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"eval finishing {}\"", ".", "format", "(", "count", ")", ")", "\n", "", "bs", "=", "len", "(", "context_list", ")", "\n", "ref", "=", "torch", ".", "tensor", "(", "[", "persona_list", "[", "i", "]", ".", "index", "(", "plabel_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "# hyp=torch.max(logits,dim=1)[1]", "\n", "# hit1+=torch.sum(hyp==ref,dim=0).item()", "\n", "hyp", "=", "torch", ".", "topk", "(", "logits", ",", "k", "=", "10", ")", "[", "1", "]", "\n", "hit1", "+=", "(", "hyp", "[", ":", ",", ":", "1", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit2", "+=", "(", "hyp", "[", ":", ",", ":", "2", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit5", "+=", "(", "hyp", "[", ":", ",", ":", "5", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "hit10", "+=", "(", "hyp", "[", ":", ",", ":", "10", "]", "==", "ref", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"persona prediction hit1 is {:.4f}\"", ".", "format", "(", "hit1", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"persona prediction hit2 is {:.4f}\"", ".", "format", "(", "hit2", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"persona prediction hit5 is {:.4f}\"", ".", "format", "(", "hit5", "/", "count", ")", ")", "\n", "logger", ".", "info", "(", "\"persona prediction hit10 is {:.4f}\"", ".", "format", "(", "hit10", "/", "count", ")", ")", "\n", "\n", "if", "args", ".", "predict", ":", "\n", "        ", "exit", "(", ")", "\n", "# with open(os.path.join(args.out_dir, 'score-iter-{}.txt'.format( global_step)), 'w', encoding='utf-8') as f:", "\n", "#     for label, score in zip(labels, scores):", "\n", "#         f.write('{}\\t{}\\n'.format(label, score))", "\n", "\n", "# time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')", "\n", "# logger.info(\"**********************************\")", "\n", "# logger.info(\"test results..........\")", "\n", "# logger.info(\"Step: %d \\t|  %s\" % (global_step, time_str))", "\n", "\n", "#model_to_save = model.module if hasattr(model, \"module\") else model", "\n", "#checkpoint_dir=os.path.join(args.out_dir,'{}step_model'.format(global_step))", "\n", "", "dualpk_model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_dualpk_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "dualkp_model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "'{}step_dualkp_model'", ".", "format", "(", "global_step", ")", ")", ")", "\n", "#torch.save(dualpk_model,os.path.join(args.out_dir,'{}step_dualpk_model'.format(global_step)))", "\n", "#checkpoint_dir=os.path.join(args.out_dir,'{}step_model'.format(global_step))", "\n", "#torch.save(dualkp_model,os.path.join(args.out_dir,'{}step_dualkp_model'.format(global_step)))", "\n", "logger", ".", "info", "(", "\"Saved model checkpoint \\n\"", ")", "\n", "# f1=recall_metric(scores,test_knowledges,test_responses)", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.dataset.persona_dataset.PersonaDataset.__init__": [[7, 52], ["torch.utils.data.Dataset.__init__", "os.listdir", "open", "open", "open", "open", "json.load", "json.load", "zip", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open.readlines", "open.readlines", "json.loads", "json.loads", "persona_dataset.PersonaDataset.examples.append"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load", "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load"], ["    ", "def", "__init__", "(", "self", ",", "convo_path", ",", "persona_path", ",", "knowledge_path", ",", "pseudo_path", ",", "mode", ",", "debug", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "PersonaDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "examples", "=", "[", "]", "\n", "assert", "mode", "in", "[", "'train'", ",", "'eval'", "]", "\n", "for", "date", "in", "os", ".", "listdir", "(", "convo_path", ")", ":", "\n", "            ", "if", "(", "date", "==", "'2015-05'", "or", "date", "==", "'2015-06'", ")", "and", "mode", "==", "'train'", ":", "\n", "                ", "continue", "\n", "", "if", "mode", "==", "'eval'", "and", "date", "!=", "'2015-05'", ":", "\n", "                ", "continue", "\n", "", "fconvo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "convo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fper", "=", "open", "(", "os", ".", "path", ".", "join", "(", "persona_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fknow", "=", "open", "(", "os", ".", "path", ".", "join", "(", "knowledge_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fpseudo", "=", "open", "(", "os", ".", "path", ".", "join", "(", "pseudo_path", ",", "date", ")", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "know_dict", "=", "json", ".", "load", "(", "fknow", ")", "\n", "per_dict", "=", "json", ".", "load", "(", "fper", ")", "\n", "for", "line1", ",", "line2", "in", "zip", "(", "fconvo", ".", "readlines", "(", ")", ",", "fpseudo", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "data", "=", "json", ".", "loads", "(", "line1", ")", "\n", "author", "=", "data", "[", "'author'", "]", "[", "-", "1", "]", "\n", "sid", "=", "data", "[", "'sid'", "]", "\n", "label", "=", "json", ".", "loads", "(", "line2", ")", "\n", "\n", "# persona=per_dict[author].copy()", "\n", "# persona.pop(persona.index(label['plabel']))", "\n", "# persona=persona[:self.n_persona-1]", "\n", "# persona.append(label['plabel'])", "\n", "# random.shuffle(persona)", "\n", "\n", "# knowledge=know_dict[sid].copy()", "\n", "# knowledge.pop(knowledge.index(label['klabel']))", "\n", "# knowledge=knowledge[:self.n_knowledge-1]", "\n", "# knowledge.append(label['klabel'])", "\n", "# random.shuffle(knowledge)", "\n", "\n", "self", ".", "examples", ".", "append", "(", "{", "\n", "'context'", ":", "data", "[", "'dialog'", "]", "[", ":", "-", "1", "]", ",", "\n", "'response'", ":", "data", "[", "'dialog'", "]", "[", "-", "1", "]", ",", "\n", "'knowledge'", ":", "know_dict", "[", "sid", "]", ",", "\n", "'persona'", ":", "per_dict", "[", "author", "]", ",", "\n", "'klabel'", ":", "label", "[", "'klabel'", "]", ",", "\n", "'plabel'", ":", "label", "[", "'plabel'", "]", "\n", "}", ")", "\n", "", "if", "debug", ":", "\n", "                ", "break", "\n", "", "", "if", "debug", "and", "mode", "==", "'eval'", ":", "\n", "            ", "self", ".", "examples", "=", "self", ".", "examples", "[", ":", "16", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.dataset.persona_dataset.PersonaDataset.__len__": [[53, 55], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.dataset.persona_dataset.PersonaDataset.__getitem__": [[56, 63], ["random.shuffle", "random.shuffle"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "example", "=", "self", ".", "examples", "[", "i", "]", "\n", "random", ".", "shuffle", "(", "example", "[", "'persona'", "]", ")", "\n", "random", ".", "shuffle", "(", "example", "[", "'knowledge'", "]", ")", "\n", "\n", "# note that the context and persona is a list, but knowledge is a string, a single piece of knowledge", "\n", "return", "example", "[", "'context'", "]", ",", "example", "[", "'response'", "]", ",", "example", "[", "'persona'", "]", ",", "example", "[", "'knowledge'", "]", ",", "example", "[", "'plabel'", "]", ",", "example", "[", "'klabel'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.dataset.persona_dataset.PersonaDataset.collate_fn": [[64, 73], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "context_list", "=", "[", "item", "[", "0", "]", "for", "item", "in", "batch", "]", "\n", "response_list", "=", "[", "item", "[", "1", "]", "for", "item", "in", "batch", "]", "\n", "persona_list", "=", "[", "item", "[", "2", "]", "for", "item", "in", "batch", "]", "\n", "knowledge_list", "=", "[", "item", "[", "3", "]", "for", "item", "in", "batch", "]", "\n", "plabel_list", "=", "[", "item", "[", "4", "]", "for", "item", "in", "batch", "]", "\n", "klabel_list", "=", "[", "item", "[", "5", "]", "for", "item", "in", "batch", "]", "\n", "return", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", "", "", "", ""]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.bert_transformer.BertPosterior.__init__": [[9, 14], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "model.mlp.mlp"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "BertConfig", ",", "n_label", "=", "2", ")", "->", "None", ":", "\n", "        ", "super", "(", "BertPosterior", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "n_label", "=", "n_label", "\n", "self", ".", "classifier", "=", "mlp", "(", "config", ".", "hidden_size", ",", "self", ".", "num_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.bert_transformer.BertPosterior.resize_token_embeddings": [[15, 17], ["super().resize_token_embeddings"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.model.bert_transformer.BertPosterior.resize_token_embeddings"], ["", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", "->", "torch", ".", "nn", ".", "Embedding", ":", "\n", "        ", "return", "super", "(", ")", ".", "resize_token_embeddings", "(", "new_num_tokens", "=", "new_num_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.bert_transformer.BertPosterior.forward": [[18, 54], ["bert_transformer.BertPosterior.classifier", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bert_transformer.BertPosterior.start_mlp().squeeze", "bert_transformer.BertPosterior.end_mlp().squeeze", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "bert_transformer.BertPosterior.start_bag_mlp", "bert_transformer.BertPosterior.end_bag_mlp", "bert_transformer.BertPosterior.bert", "bert_transformer.BertPosterior.bert", "context_mask.unsqueeze().expand_as().float", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "context_realength[].float", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "context_rep.unsqueeze().expand_as", "bert_transformer.BertPosterior.start_mlp", "bert_transformer.BertPosterior.end_mlp", "context_mask.unsqueeze().expand_as", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_rep.unsqueeze", "torch.masked_fill.unsqueeze", "torch.masked_fill.unsqueeze", "torch.masked_fill.unsqueeze", "torch.masked_fill.unsqueeze", "context_mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_id", ",", "attention_mask", "=", "None", ")", ":", "\n", "\n", "        ", "assert", "input_id", ".", "shape", "[", "0", "]", "==", "attention_mask", ".", "shape", "[", "0", "]", "\n", "bs", "=", "input_id", ".", "shape", "[", "0", "]", "\n", "# (bs,hidden_size)", "\n", "logits", "=", "self", ".", "bert", "(", "input_ids", "=", "input_id", ",", "attention_mask", "=", "attention_mask", ",", "return_dict", "=", "'True'", ")", "[", "'logits'", "]", "\n", "#(bs,2)", "\n", "return", "self", ".", "classifier", "(", "logits", ")", "\n", "\n", "context_mask", "=", "attention_mask", "[", ":", ",", ":", "self", ".", "max_query_length", "]", "\n", "knowledge_mask", "=", "attention_mask", "[", ":", ",", "self", ".", "max_query_length", ":", "]", "\n", "\n", "#(bs,slen,hidden_dim)", "\n", "enc", "=", "self", ".", "bert", "(", "input_id", ",", "attention_mask", ",", "return_dict", "=", "True", ")", ".", "last_hidden_state", "\n", "#(bs,crlen,hidden_dim)", "\n", "context_enc", "=", "enc", "[", ":", ",", ":", "self", ".", "max_query_length", ",", ":", "]", "\n", "context_enc", "=", "context_enc", "*", "context_mask", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "context_enc", ")", ".", "float", "(", ")", "\n", "#(bs)", "\n", "context_realength", "=", "torch", ".", "sum", "(", "attention_mask", ",", "dim", "=", "1", ")", "\n", "#(bs,klen,hidden_dim)", "\n", "knowledge_enc", "=", "enc", "[", ":", ",", "self", ".", "max_query_length", ":", ",", ":", "]", "\n", "# (bs,hidden_dim) ", "\n", "# average pooling", "\n", "context_rep", "=", "torch", ".", "sum", "(", "context_enc", ",", "dim", "=", "1", ")", "/", "context_realength", "[", ":", ",", "None", "]", ".", "float", "(", ")", "\n", "# (bs,klen,hidden_dim*2)", "\n", "mlp_in", "=", "torch", ".", "cat", "(", "[", "context_rep", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "knowledge_enc", ")", ",", "knowledge_enc", "]", ",", "dim", "=", "-", "1", ")", "\n", "# (bs,klen)", "\n", "start_mlp_out", "=", "self", ".", "start_mlp", "(", "mlp_in", ")", ".", "squeeze", "(", ")", "\n", "end_mlp_out", "=", "self", ".", "end_mlp", "(", "mlp_in", ")", ".", "squeeze", "(", ")", "\n", "Zs", "=", "torch", ".", "masked_fill", "(", "start_mlp_out", ",", "knowledge_mask", "==", "0", ",", "1e-18", ")", "\n", "Ze", "=", "torch", ".", "masked_fill", "(", "end_mlp_out", ",", "knowledge_mask", "==", "0", ",", "1e-18", ")", "\n", "\n", "# (bs,hidden_dim)", "\n", "start_bag_logits", "=", "self", ".", "start_bag_mlp", "(", "torch", ".", "matmul", "(", "Zs", ".", "unsqueeze", "(", "1", ")", ",", "knowledge_enc", ")", ".", "squeeze", "(", "1", ")", ")", "\n", "end_bag_logits", "=", "self", ".", "end_bag_mlp", "(", "torch", ".", "matmul", "(", "Ze", ".", "unsqueeze", "(", "1", ")", ",", "knowledge_enc", ")", ".", "squeeze", "(", "1", ")", ")", "\n", "return", "Zs", ",", "Ze", ",", "start_bag_logits", ",", "end_bag_logits", "", "", "", ""]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.BeamHypotheses.__init__": [[35, 45], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", ")", ":", "\n", "        ", "\"\"\"\n        Initialize n-best list of hypotheses.\n        \"\"\"", "\n", "self", ".", "max_length", "=", "max_length", "-", "1", "# ignoring bos_token", "\n", "self", ".", "length_penalty", "=", "length_penalty", "\n", "self", ".", "early_stopping", "=", "early_stopping", "\n", "self", ".", "num_beams", "=", "num_beams", "\n", "self", ".", "beams", "=", "[", "]", "\n", "self", ".", "worst_score", "=", "1e9", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.BeamHypotheses.__len__": [[46, 51], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Number of hypotheses in the list.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "beams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.BeamHypotheses.add": [[52, 65], ["reimpl_gpt2v0.BeamHypotheses.beams.append", "len", "len", "len", "sorted", "min", "enumerate"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "hyp", ",", "sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Add a new hypothesis to the list.\n        \"\"\"", "\n", "score", "=", "sum_logprobs", "/", "len", "(", "hyp", ")", "**", "self", ".", "length_penalty", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "num_beams", "or", "score", ">", "self", ".", "worst_score", ":", "\n", "            ", "self", ".", "beams", ".", "append", "(", "(", "score", ",", "hyp", ")", ")", "\n", "if", "len", "(", "self", ")", ">", "self", ".", "num_beams", ":", "\n", "                ", "sorted_scores", "=", "sorted", "(", "[", "(", "s", ",", "idx", ")", "for", "idx", ",", "(", "s", ",", "_", ")", "in", "enumerate", "(", "self", ".", "beams", ")", "]", ")", "\n", "del", "self", ".", "beams", "[", "sorted_scores", "[", "0", "]", "[", "1", "]", "]", "\n", "self", ".", "worst_score", "=", "sorted_scores", "[", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "worst_score", "=", "min", "(", "score", ",", "self", ".", "worst_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.BeamHypotheses.is_done": [[66, 80], ["len"], "methods", ["None"], ["", "", "", "def", "is_done", "(", "self", ",", "best_sum_logprobs", ",", "cur_len", ")", ":", "\n", "        ", "\"\"\"\n        If there are enough hypotheses and that none of the hypotheses being generated\n        can become better than the worst one in the heap, then we are done with this sentence.\n        \"\"\"", "\n", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "num_beams", ":", "\n", "            ", "return", "False", "\n", "", "elif", "self", ".", "early_stopping", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "cur_score", "=", "best_sum_logprobs", "/", "cur_len", "**", "self", ".", "length_penalty", "\n", "ret", "=", "self", ".", "worst_score", ">=", "cur_score", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.__init__": [[85, 108], ["torch.Module.__init__", "reimpl_gpt2v0.Attention.register_buffer", "reimpl_gpt2v0.Attention.register_buffer", "transformers.modeling_gpt2.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "transformers.modeling_gpt2.Conv1D", "transformers.modeling_gpt2.Conv1D", "transformers.modeling_gpt2.Conv1D", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "is_cross_attention", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\n", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "(", "n_ctx", ",", "n_ctx", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", "\n", ")", "\n", "self", ".", "register_buffer", "(", "\"masked_bias\"", ",", "torch", ".", "tensor", "(", "-", "1e4", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "is_cross_attention", "=", "is_cross_attention", "\n", "if", "self", ".", "is_cross_attention", ":", "\n", "            ", "self", ".", "c_attn", "=", "Conv1D", "(", "2", "*", "n_state", ",", "nx", ")", "\n", "self", ".", "q_attn", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "c_attn", "=", "Conv1D", "(", "3", "*", "n_state", ",", "nx", ")", "\n", "", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.prune_heads": [[109, 125], ["transformers.modeling_gpt2.find_pruneable_heads_and_indices", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformers.modeling_gpt2.prune_conv1d_layer", "transformers.modeling_gpt2.prune_conv1d_layer", "reimpl_gpt2v0.Attention.pruned_heads.union", "len", "len", "len"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "\n", "heads", ",", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ",", "self", ".", "pruned_heads", "\n", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention._attn": [[126, 153], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "reimpl_gpt2v0.Attention.attn_dropout", "torch.where.size", "torch.where.size", "torch.where.size", "torch.where.size", "torch.where", "torch.where", "torch.where", "torch.where", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "reimpl_gpt2v0.Attention.masked_bias.to", "float", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "(", "float", "(", "v", ".", "size", "(", "-", "1", ")", ")", "**", "0.5", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "is_cross_attention", ":", "\n", "# if self attention, do causual mask, so the attention in gpt2 is masked self attention", "\n", "# if only \"normal\" attention layer implements causal mask", "\n", "            ", "mask", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "torch", ".", "where", "(", "mask", "==", "1", ",", "w", ",", "self", ".", "masked_bias", ".", "to", "(", "w", ".", "dtype", ")", ")", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.merge_heads": [[154, 158], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.split_heads": [[159, 167], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "#(bs, seq_len, n_head, dim_per_head)", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.forward": [[168, 211], ["reimpl_gpt2v0.Attention.split_heads", "reimpl_gpt2v0.Attention.split_heads", "reimpl_gpt2v0.Attention.split_heads", "reimpl_gpt2v0.Attention._attn", "reimpl_gpt2v0.Attention.merge_heads", "reimpl_gpt2v0.Attention.c_proj", "reimpl_gpt2v0.Attention.resid_dropout", "hasattr", "reimpl_gpt2v0.Attention.q_attn", "reimpl_gpt2v0.Attention.c_attn().split", "reimpl_gpt2v0.Attention.c_attn().split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer_past[].transpose", "reimpl_gpt2v0.Attention.c_attn", "reimpl_gpt2v0.Attention.c_attn", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.split_heads", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.split_heads", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.split_heads", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention._attn", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.merge_heads"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "layer_past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "\n", "self", ",", "\"q_attn\"", "\n", ")", ",", "\"If class is used as cross attention, the weights `q_attn` have to be defined. Please make sure to instantiate class with `Attention(..., is_cross_attention=True)`.\"", "\n", "query", "=", "self", ".", "q_attn", "(", "hidden_states", ")", "\n", "key", ",", "value", "=", "self", ".", "c_attn", "(", "encoder_hidden_states", ")", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "query", ",", "key", ",", "value", "=", "self", ".", "c_attn", "(", "hidden_states", ")", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "\n", "", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "\n", "", "if", "use_cache", "is", "True", ":", "\n", "            ", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "", "else", ":", "\n", "            ", "present", "=", "(", "None", ",", ")", "\n", "\n", "", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ",", "output_attentions", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.MLP.__init__": [[214, 221], ["torch.Module.__init__", "transformers.modeling_gpt2.Conv1D", "transformers.modeling_gpt2.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT2FN", "[", "config", ".", "activation_function", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.MLP.forward": [[222, 226], ["reimpl_gpt2v0.MLP.act", "reimpl_gpt2v0.MLP.c_proj", "reimpl_gpt2v0.MLP.dropout", "reimpl_gpt2v0.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Block.__init__": [[229, 240], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "reimpl_gpt2v0.Attention", "torch.LayerNorm", "torch.LayerNorm", "reimpl_gpt2v0.MLP", "reimpl_gpt2v0.Attention", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "hidden_size", "=", "config", ".", "n_embd", "\n", "inner_dim", "=", "config", ".", "n_inner", "if", "config", ".", "n_inner", "is", "not", "None", "else", "4", "*", "hidden_size", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "hidden_size", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "if", "config", ".", "add_cross_attention", ":", "\n", "            ", "self", ".", "crossattention", "=", "Attention", "(", "hidden_size", ",", "n_ctx", ",", "config", ",", "scale", ",", "is_cross_attention", "=", "True", ")", "\n", "self", ".", "ln_cross_attn", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "", "self", ".", "mlp", "=", "MLP", "(", "inner_dim", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Block.forward": [[241, 289], ["reimpl_gpt2v0.Block.attn", "reimpl_gpt2v0.Block.mlp", "reimpl_gpt2v0.Block.ln_1", "hasattr", "reimpl_gpt2v0.Block.crossattention", "reimpl_gpt2v0.Block.ln_2", "reimpl_gpt2v0.Block.ln_cross_attn"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "layer_past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "attn_outputs", "=", "self", ".", "attn", "(", "\n", "self", ".", "ln_1", "(", "hidden_states", ")", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "attn_output", "=", "attn_outputs", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "outputs", "=", "attn_outputs", "[", "1", ":", "]", "\n", "# residual connection", "\n", "hidden_states", "=", "attn_output", "+", "hidden_states", "\n", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "# add one self-attention block for cross-attention", "\n", "            ", "assert", "hasattr", "(", "\n", "self", ",", "\"crossattention\"", "\n", ")", ",", "f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.add_cross_attention=True`\"", "\n", "cross_attn_outputs", "=", "self", ".", "crossattention", "(", "\n", "self", ".", "ln_cross_attn", "(", "hidden_states", ")", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "attn_output", "=", "cross_attn_outputs", "[", "0", "]", "\n", "# residual connection", "\n", "hidden_states", "=", "hidden_states", "+", "attn_output", "\n", "outputs", "=", "outputs", "+", "cross_attn_outputs", "[", "1", ":", "]", "# add cross attentions if we output attention weights", "\n", "\n", "", "feed_forward_hidden_states", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "hidden_states", ")", ")", "\n", "# residual connection", "\n", "hidden_states", "=", "hidden_states", "+", "feed_forward_hidden_states", "\n", "\n", "outputs", "=", "[", "hidden_states", "]", "+", "outputs", "\n", "return", "outputs", "# hidden_states, present, (cross_attentions, attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2Model.__init__": [[291, 301], ["transformers.modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "reimpl_gpt2v0.GPT2Model.init_weights", "reimpl_gpt2v0.Block", "range"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2Model.get_input_embeddings": [[302, 304], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2Model.set_input_embeddings": [[305, 307], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "wte", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2Model._prune_heads": [[308, 314], ["heads_to_prune.items", "reimpl_gpt2v0.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"Prunes heads of the model.\n        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2Model.forward": [[315, 478], ["reimpl_gpt2v0.GPT2Model.get_head_mask", "reimpl_gpt2v0.GPT2Model.wpe", "reimpl_gpt2v0.GPT2Model.drop", "enumerate", "reimpl_gpt2v0.GPT2Model.ln_f", "hidden_states.view.view.view", "transformers.modeling_gpt2.BaseModelOutputWithPast", "kwargs.pop", "ValueError", "token_type_ids.view.view.view", "position_ids.unsqueeze().view.unsqueeze().view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.view", "attention_mask.to.to.to", "encoder_hidden_states.size", "reimpl_gpt2v0.GPT2Model.invert_attention_mask", "reimpl_gpt2v0.GPT2Model.wte", "reimpl_gpt2v0.GPT2Model.wte", "zip", "getattr", "tuple", "list", "input_ids.view.view.size", "input_ids.view.view.view", "len", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "hidden_states.view.view.size", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "block", "kwargs.keys", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "reimpl_gpt2v0.GPT2Model.forward.create_custom_forward"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "if", "\"past\"", "in", "kwargs", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "past_key_values", "=", "kwargs", ".", "pop", "(", "\"past\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "batch_size", "=", "inputs_embeds", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "if", "position_ids", "is", "not", "None", ":", "\n", "            ", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "past_key_values", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past_key_values", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past_key_values", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "assert", "batch_size", ">", "0", ",", "\"batch_size has to be defined and > 0\"", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "self", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "", "if", "self", ".", "config", ".", "add_cross_attention", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "", "encoder_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "n_layer", ")", "\n", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "if", "use_cache", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past_key_values", ")", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", ":", "\n", "\n", "                ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                    ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "# checkpointing only works with tuple returns, not with lists", "\n", "                        ", "return", "tuple", "(", "output", "for", "output", "in", "module", "(", "*", "inputs", ",", "use_cache", ",", "output_attentions", ")", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "block", ")", ",", "\n", "hidden_states", ",", "\n", "layer_past", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "block", "(", "\n", "hidden_states", ",", "\n", "layer_past", "=", "layer_past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "\n", "", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "use_cache", "is", "True", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "outputs", "[", "2", "]", ",", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "presents", ",", "all_hidden_states", ",", "all_attentions", "]", "if", "v", "is", "not", "None", ")", "\n", "\n", "", "return", "BaseModelOutputWithPast", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "\n", "past_key_values", "=", "presents", ",", "\n", "hidden_states", "=", "all_hidden_states", ",", "\n", "attentions", "=", "all_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.__init__": [[484, 490], ["transformers.modeling_gpt2.GPT2PreTrainedModel.__init__", "reimpl_gpt2v0.GPT2Model", "torch.Linear", "torch.Linear", "reimpl_gpt2v0.GPT2LMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.get_output_embeddings": [[491, 493], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.prepare_inputs_for_generation": [[495, 519], ["kwargs.get", "kwargs.get", "input_ids[].unsqueeze", "position_ids[].unsqueeze.masked_fill_", "kwargs.get", "kwargs.get.long().cumsum", "position_ids[].unsqueeze", "kwargs.get.long"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# only last token for inputs_ids if past is defined in kwargs", "\n", "        ", "if", "past", ":", "\n", "# if has past key values, we only keep the last one ", "\n", "# (bs,1)", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "attention_mask", "=", "kwargs", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "\n", "position_ids", "=", "kwargs", ".", "get", "(", "\"position_ids\"", ",", "None", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", "and", "position_ids", "is", "None", ":", "\n", "# create postion_ids on the fly for batch generation", "\n", "            ", "position_ids", "=", "attention_mask", ".", "long", "(", ")", ".", "cumsum", "(", "-", "1", ")", "-", "1", "\n", "position_ids", ".", "masked_fill_", "(", "attention_mask", "==", "0", ",", "1", ")", "\n", "if", "past", ":", "\n", "                ", "position_ids", "=", "position_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "position_ids", "=", "None", "\n", "", "return", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"past_key_values\"", ":", "past", ",", "\n", "\"use_cache\"", ":", "kwargs", ".", "get", "(", "\"use_cache\"", ")", ",", "\n", "\"position_ids\"", ":", "position_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.forward": [[521, 590], ["reimpl_gpt2v0.GPT2LMHeadModel.transformer", "reimpl_gpt2v0.GPT2LMHeadModel.lm_head", "transformers.modeling_gpt2.CausalLMOutputWithPast", "kwargs.pop", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "list", "lm_logits[].contiguous.view", "labels[].contiguous.view", "kwargs.keys", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for language modeling.\n            Note that the labels **are shifted** inside the model, i.e. you can set ``labels = input_ids``\n            Indices are selected in ``[-100, 0, ..., config.vocab_size]``\n            All labels set to ``-100`` are ignored (masked), the loss is only\n            computed for labels in ``[0, ..., config.vocab_size]``\n        \"\"\"", "\n", "if", "\"past\"", "in", "kwargs", ":", "\n", "            ", "past_key_values", "=", "kwargs", ".", "pop", "(", "\"past\"", ")", "\n", "", "assert", "kwargs", "==", "{", "}", ",", "f\"Unexpected keyword arguments: {list(kwargs.keys())}.\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "CausalLMOutputWithPast", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "lm_logits", ",", "\n", "past_key_values", "=", "transformer_outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "transformer_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "transformer_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.foo": [[591, 595], ["print", "print", "print"], "methods", ["None"], ["", "def", "foo", "(", "self", ")", ":", "\n", "        ", "print", "(", "1", ")", "\n", "print", "(", "2", ")", "\n", "print", "(", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel._reorder_cache": [[596, 598], ["tuple", "layer_past.index_select"], "methods", ["None"], ["", "def", "_reorder_cache", "(", "self", ",", "past", ",", "beam_idx", ")", ":", "\n", "        ", "return", "tuple", "(", "layer_past", ".", "index_select", "(", "1", ",", "beam_idx", ")", "for", "layer_past", "in", "past", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.enforce_repetition_penalty_": [[599, 610], ["range", "set", "prev_output_tokens[].tolist"], "methods", ["None"], ["", "def", "enforce_repetition_penalty_", "(", "self", ",", "lprobs", ",", "batch_size", ",", "num_beams", ",", "prev_output_tokens", ",", "repetition_penalty", ")", ":", "\n", "        ", "\"\"\"\n        Enforce the repetition penalty (from the `CTRL paper <https://arxiv.org/abs/1909.05858>`__).\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "            ", "for", "previous_token", "in", "set", "(", "prev_output_tokens", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                ", "if", "lprobs", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                    ", "lprobs", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                    ", "lprobs", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.postprocess_next_token_scores": [[611, 662], ["reimpl_gpt2v0.GPT2LMHeadModel.enforce_repetition_penalty_", "calc_banned_ngram_tokens", "enumerate", "list", "transformers.generation_utils.calc_banned_bad_words_ids", "reimpl_gpt2v0.set_scores_to_inf_for_banned_tokens", "float", "float", "filter", "input_ids.tolist", "float"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.enforce_repetition_penalty_", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.set_scores_to_inf_for_banned_tokens"], ["", "", "", "", "def", "postprocess_next_token_scores", "(", "\n", "self", ",", "\n", "scores", ",", "\n", "input_ids", ",", "\n", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", ",", "\n", "cur_len", ",", "\n", "min_length", ",", "\n", "max_length", ",", "\n", "eos_token_id", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "repetition_penalty", "=", "1.0", ",", "\n", "batch_size", "=", "2", ",", "\n", "num_beams", "=", "1", ",", "\n", ")", ":", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "        ", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "            ", "self", ".", "enforce_repetition_penalty_", "(", "\n", "scores", ",", "\n", "batch_size", ",", "\n", "num_beams", ",", "\n", "input_ids", ",", "\n", "repetition_penalty", ",", "\n", ")", "\n", "\n", "# set eos token prob to zero if min_length is not reached", "\n", "", "if", "eos_token_id", "is", "not", "None", "and", "cur_len", "<", "min_length", ":", "\n", "            ", "scores", "[", ":", ",", "eos_token_id", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "", "if", "pad_token_id", "is", "not", "None", "and", "cur_len", "<", "min_length", ":", "\n", "            ", "scores", "[", ":", ",", "pad_token_id", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "\n", "", "if", "no_repeat_ngram_size", ">", "0", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# calculate a list of banned tokens to prevent repetitively generating the same ngrams", "\n", "num_batch_hypotheses", "=", "batch_size", "*", "num_beams", "\n", "# from fairseq: https://github.com/pytorch/fairseq/blob/a07cb6f40480928c9e0548b737aadd36ee66ac76/fairseq/sequence_generator.py#L345", "\n", "banned_batch_tokens", "=", "calc_banned_ngram_tokens", "(", "\n", "input_ids", ",", "num_batch_hypotheses", ",", "no_repeat_ngram_size", ",", "cur_len", "\n", ")", "\n", "for", "i", ",", "banned_tokens", "in", "enumerate", "(", "banned_batch_tokens", ")", ":", "\n", "                ", "scores", "[", "i", ",", "banned_tokens", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n", "", "", "if", "bad_words_ids", "is", "not", "None", ":", "\n", "# Exclude EOS token (already processed)", "\n", "            ", "bad_words_ids", "=", "list", "(", "filter", "(", "lambda", "bad_token_seq", ":", "bad_token_seq", "!=", "[", "eos_token_id", "]", ",", "bad_words_ids", ")", ")", "\n", "# calculate a list of banned tokens according to bad words", "\n", "banned_tokens", "=", "calc_banned_bad_words_ids", "(", "input_ids", ".", "tolist", "(", ")", ",", "bad_words_ids", ")", "\n", "# Modify the scores in place by setting the banned tokens logits to `-inf`", "\n", "set_scores_to_inf_for_banned_tokens", "(", "scores", ",", "banned_tokens", ")", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.generate_beam_search": [[664, 956], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beam_scores.new.new.view", "range", "torch.cat.new", "torch.cat.new", "enumerate", "min", "torch.cat.new", "torch.cat.new", "enumerate", "torch.cat.dim", "torch.cat.dim", "torch.cat.ne().long", "torch.cat.ne().long", "torch.cat.unsqueeze().expand", "torch.cat.unsqueeze().expand", "torch.cat.unsqueeze().expand", "torch.cat.unsqueeze().expand", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "reimpl_gpt2v0.BeamHypotheses", "reimpl_gpt2v0.GPT2LMHeadModel.prepare_inputs_for_generation", "reimpl_gpt2v0.GPT2LMHeadModel.", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "reimpl_gpt2v0.GPT2LMHeadModel.postprocess_next_token_scores", "range", "all", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "sorted", "range", "torch.cat.new.min().item", "torch.cat.new.max().item", "torch.cat.new.fill_", "torch.cat.new_ones", "torch.cat.new_ones", "range", "range", "reimpl_gpt2v0.GPT2LMHeadModel.adjust_logits_during_generation", "top_k_top_p_filtering", "_scores.contiguous().view.contiguous().view.contiguous().view", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "next_scores.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "next_scores.view.view.size", "torch.gather.size", "torch.gather.size", "enumerate", "next_batch_beam.extend", "len", "reimpl_gpt2v0.GPT2LMHeadModel._reorder_cache", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all", "torch.all", "torch.all", "torch.all", "torch.all", "beam_scores[].item", "generated_hyps[].add", "len", "best.append", "torch.cat.new.max().item", "torch.cat.ne", "torch.cat.ne", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "beam_scores[].expand_as", "beam_scores[].expand_as", "next_batch_beam.extend", "zip", "generated_hyps[].is_done", "len", "len", "torch.cat.new.unsqueeze", "sorted.pop", "torch.cat.new.min", "torch.cat.new.max", "_scores.contiguous().view.contiguous().view.contiguous", "len", "generated_hyps[].add", "next_sent_beam.append", "len", "next_scores[].max().item", "torch.cat.new_ones", "torch.cat.new_ones", "beam_scores.new.new.view", "torch.cat.new.max", "token_id.item", "input_ids[].clone", "beam_token_score.item", "beam_scores.new.new.view", "next_scores[].max"], "methods", ["home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel.postprocess_next_token_scores", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.GPT2LMHeadModel._reorder_cache", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.BeamHypotheses.add", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.BeamHypotheses.is_done", "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.BeamHypotheses.add"], ["", "def", "generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "# (bs,seqlen)", "\n", "cur_len", "=", "1", ",", "\n", "max_length", "=", "20", ",", "# max generated length", "\n", "min_length", "=", "5", ",", "\n", "do_sample", "=", "False", ",", "\n", "early_stopping", "=", "False", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "1.0", ",", "\n", "no_repeat_ngram_size", "=", "0", ",", "\n", "bad_words_ids", "=", "None", ",", "\n", "pad_token_id", "=", "50256", ",", "\n", "eos_token_id", "=", "50256", ",", "\n", "batch_size", "=", "None", ",", "\n", "num_return_sequences", "=", "1", ",", "\n", "length_penalty", "=", "1", ",", "\n", "num_beams", "=", "2", ",", "\n", "vocab_size", "=", "50262", ",", "\n", "attention_mask", "=", "None", ",", "\n", "use_cache", "=", "True", ",", "\n", "model_kwargs", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Generate sequences for each example with beam search.\"\"\"", "\n", "# prepare before generate", "\n", "# attention mask and position ids should be created before head!", "\n", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", "\n", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "# real length with no pad token id ", "\n", "# (bs)", "\n", "real_length", "=", "(", "input_ids", "!=", "pad_token_id", ")", ".", "cumsum", "(", "dim", "=", "-", "1", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "if", "attention_mask", "is", "None", "and", "pad_token_id", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "ne", "(", "pad_token_id", ")", ".", "long", "(", ")", "\n", "", "elif", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "new_ones", "(", "input_ids", ".", "shape", ")", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "input_ids_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "input_ids_len", ")", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "input_ids_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "input_ids_len", ")", "\n", "attention_mask", "=", "attention_mask", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "input_ids_len", ")", "\n", "\n", "\n", "\n", "# generated hypotheses", "\n", "", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "early_stopping", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "\n", "# for greedy decoding it is made sure that only tokens of the first beam are considered to avoid sampling the exact same tokens three times", "\n", "if", "do_sample", "is", "False", ":", "\n", "            ", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "None", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "#cur_len=1", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "\n", "input_ids", ",", "past", "=", "past", ",", "attention_mask", "=", "attention_mask", ",", "use_cache", "=", "use_cache", ",", "#**model_kwargs", "\n", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ",", "return_dict", "=", "True", ")", "# (batch_size * num_beams, cur_len, vocab_size)", "\n", "# use the last one in the sequence length", "\n", "next_token_logits", "=", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "\"past_key_values\"", "in", "outputs", ":", "\n", "                ", "past", "=", "outputs", ".", "past_key_values", "\n", "", "elif", "\"mems\"", "in", "outputs", ":", "\n", "                ", "past", "=", "outputs", ".", "mems", "\n", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", "and", "do_sample", "is", "False", ":", "\n", "# TODO (PVP) still a bit hacky here - there might be a better solution", "\n", "                ", "next_token_logits", "=", "self", ".", "adjust_logits_during_generation", "(", "\n", "next_token_logits", ",", "cur_len", "=", "cur_len", ",", "max_length", "=", "max_length", "\n", ")", "\n", "\n", "", "scores", "=", "F", ".", "log_softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "scores", "=", "self", ".", "postprocess_next_token_scores", "(", "\n", "scores", "=", "scores", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "cur_len", "=", "cur_len", ",", "\n", "min_length", "=", "min_length", ",", "\n", "max_length", "=", "max_length", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", ")", "\n", "\n", "assert", "scores", ".", "shape", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", ",", "\"Shapes of scores: {} != {}\"", ".", "format", "(", "\n", "scores", ".", "shape", ",", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", ")", "\n", "\n", "if", "do_sample", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Temperature", "\n", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "_scores", "=", "_scores", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "_scores", "=", "top_k_top_p_filtering", "(", "\n", "_scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together to sample from all beam_idxs", "\n", "_scores", "=", "_scores", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", ",", "num_beams", "*", "vocab_size", "\n", ")", "# (batch_size, num_beams * vocab_size)", "\n", "\n", "# Sample 2 next tokens for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "probs", "=", "F", ".", "softmax", "(", "_scores", ",", "dim", "=", "-", "1", ")", "\n", "next_tokens", "=", "torch", ".", "multinomial", "(", "probs", ",", "num_samples", "=", "2", "*", "num_beams", ")", "# (batch_size, num_beams * 2)", "\n", "# Compute next scores", "\n", "next_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_tokens", ")", "# (batch_size, num_beams * 2)", "\n", "# sort the sampled vector to make sure that the first num_beams samples are the best", "\n", "next_scores", ",", "next_scores_indices", "=", "torch", ".", "sort", "(", "next_scores", ",", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "next_tokens", "=", "torch", ".", "gather", "(", "next_tokens", ",", "-", "1", ",", "next_scores_indices", ")", "# (batch_size, num_beams * 2)", "\n", "\n", "", "else", ":", "\n", "# repeat the score of a beam at every position", "\n", "                ", "next_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "\n", "batch_size", ",", "num_beams", "*", "vocab_size", "\n", ")", "# (batch_size, num_beams * vocab_size)", "\n", "\n", "next_scores", ",", "next_tokens", "=", "torch", ".", "topk", "(", "next_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_tokens", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence(case)", "\n", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence, add a pad token", "\n", "                ", "if", "done", "[", "batch_idx", "]", ":", "\n", "                    ", "assert", "(", "\n", "len", "(", "generated_hyps", "[", "batch_idx", "]", ")", ">=", "num_beams", "\n", ")", ",", "\"Batch can only be done if at least {} beams have been generated\"", ".", "format", "(", "num_beams", ")", "\n", "assert", "(", "\n", "eos_token_id", "is", "not", "None", "and", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"generated beams >= num_beams -> eos_token_id and pad_token have to be defined\"", "\n", "# all the hypothesis has the same length, ", "\n", "# even if it is already finished, add pad token to the same length(the max length)  ", "\n", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content, this will get added to next_batch_beam", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next tokens for this sentence", "\n", "for", "beam_token_rank", ",", "(", "beam_token_id", ",", "beam_token_score", ")", "in", "enumerate", "(", "\n", "zip", "(", "next_tokens", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", "\n", ")", ":", "\n", "# get beam and token IDs", "\n", "# \u8fd9\u4e2acase\u4e2d\u7b2c\u51e0\u4e2abeam \u5f97\u5230\u7684\u7ed3\u679c \u603b\u5171\u67092*numbeam", "\n", "                    ", "beam_id", "=", "beam_token_id", "//", "vocab_size", "\n", "token_id", "=", "beam_token_id", "%", "vocab_size", "\n", "\n", "effective_beam_id", "=", "batch_idx", "*", "num_beams", "+", "beam_id", "\n", "# add to generated hypotheses if end of sentence", "\n", "if", "(", "eos_token_id", "is", "not", "None", ")", "and", "(", "token_id", ".", "item", "(", ")", "==", "eos_token_id", ")", ":", "\n", "# if beam_token does not belong to top num_beams tokens, it should not be added", "\n", "                        ", "is_beam_token_worse_than_top_num_beams", "=", "beam_token_rank", ">=", "num_beams", "\n", "if", "is_beam_token_worse_than_top_num_beams", ":", "\n", "                            ", "continue", "\n", "", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "input_ids", "[", "effective_beam_id", "]", ".", "clone", "(", ")", ",", "\n", "beam_token_score", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "# add next predicted token since it is not eos_token", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "beam_token_score", ",", "token_id", ",", "effective_beam_id", ")", ")", "\n", "\n", "# once the beam for next step is full, don't add more tokens to it.", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# Check if we are done so that we can save a pad step if all(done)", "\n", "", "", "done", "[", "batch_idx", "]", "=", "done", "[", "batch_idx", "]", "or", "generated_hyps", "[", "batch_idx", "]", ".", "is_done", "(", "\n", "next_scores", "[", "batch_idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", ",", "cur_len", "\n", ")", "\n", "\n", "# update next beam content", "\n", "assert", "len", "(", "next_sent_beam", ")", "==", "num_beams", ",", "\"Beam should always be full\"", "\n", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_idx", "+", "1", ")", ",", "\"We should have added num_beams each step\"", "\n", "\n", "# stop when we are done with each sentence", "\n", "", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_tokens", "=", "input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch and update current length", "\n", "input_ids", "=", "input_ids", "[", "beam_idx", ",", ":", "]", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "beam_tokens", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# re-order internal states", "\n", "if", "past", "is", "not", "None", ":", "\n", "                ", "past", "=", "self", ".", "_reorder_cache", "(", "past", ",", "beam_idx", ")", "\n", "\n", "# extend attention_mask for new generated input if only decoder", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", "is", "False", ":", "\n", "                ", "attention_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attention_mask", ",", "attention_mask", ".", "new_ones", "(", "(", "attention_mask", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "]", ",", "dim", "=", "-", "1", "\n", ")", "\n", "\n", "# finalize all open beam hypotheses and add to generated hypotheses", "\n", "", "", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "done", "[", "batch_idx", "]", ":", "\n", "                ", "continue", "\n", "\n", "# test that beam scores match previously calculated scores if not eos and batch_idx not done", "\n", "", "if", "eos_token_id", "is", "not", "None", "and", "all", "(", "\n", "(", "token_id", "%", "vocab_size", ")", ".", "item", "(", ")", "!=", "eos_token_id", "for", "token_id", "in", "next_tokens", "[", "batch_idx", "]", "\n", ")", ":", "\n", "                ", "assert", "torch", ".", "all", "(", "\n", "next_scores", "[", "batch_idx", ",", ":", "num_beams", "]", "==", "beam_scores", ".", "view", "(", "batch_size", ",", "num_beams", ")", "[", "batch_idx", "]", "\n", ")", ",", "\"If batch_idx is not done, final next scores: {} have to equal to accumulated beam_scores: {}\"", ".", "format", "(", "\n", "next_scores", "[", ":", ",", ":", "num_beams", "]", "[", "batch_idx", "]", ",", "\n", "beam_scores", ".", "view", "(", "batch_size", ",", "num_beams", ")", "[", "batch_idx", "]", ",", "\n", ")", "\n", "\n", "# need to add best num_beams hypotheses to generated hyps", "\n", "", "for", "beam_id", "in", "range", "(", "num_beams", ")", ":", "\n", "                ", "effective_beam_id", "=", "batch_idx", "*", "num_beams", "+", "beam_id", "\n", "final_score", "=", "beam_scores", "[", "effective_beam_id", "]", ".", "item", "(", ")", "\n", "final_tokens", "=", "input_ids", "[", "effective_beam_id", "]", "\n", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "final_tokens", ",", "final_score", ")", "\n", "\n", "# depending on whether greedy generation is wanted or not define different output_batch_size and output_num_return_sequences_per_batch", "\n", "", "", "output_batch_size", "=", "batch_size", "if", "do_sample", "else", "batch_size", "*", "num_return_sequences", "\n", "output_num_return_sequences_per_batch", "=", "1", "if", "do_sample", "else", "num_return_sequences", "\n", "\n", "# select the best hypotheses", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "output_batch_size", ")", "\n", "best", "=", "[", "]", "\n", "\n", "# retrieve best hypotheses", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "sorted_hyps", "=", "sorted", "(", "hypotheses", ".", "beams", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "for", "j", "in", "range", "(", "output_num_return_sequences_per_batch", ")", ":", "\n", "                ", "effective_batch_idx", "=", "output_num_return_sequences_per_batch", "*", "i", "+", "j", "\n", "best_hyp", "=", "sorted_hyps", ".", "pop", "(", ")", "[", "1", "]", "\n", "sent_lengths", "[", "effective_batch_idx", "]", "=", "len", "(", "best_hyp", ")", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "\n", "# prepare for adding eos", "\n", "", "", "sent_max_len", "=", "min", "(", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ",", "max_length", ")", "\n", "decoded", "=", "input_ids", ".", "new", "(", "output_batch_size", ",", "sent_max_len", ")", "\n", "# shorter batches are padded if needed", "\n", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`pad_token_id` has to be defined\"", "\n", "decoded", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "# fill with hypotheses and eos_token_id if the latter fits in", "\n", "", "for", "i", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "#print(decoded.shape)", "\n", "#print(hypo.shape)", "\n", "            ", "decoded", "[", "i", ",", ":", "sent_lengths", "[", "i", "]", "]", "=", "hypo", "\n", "decoded", "[", "i", ",", ":", "real_length", "[", "i", "]", "]", "=", "pad_token_id", "\n", "if", "sent_lengths", "[", "i", "]", "<", "max_length", ":", "\n", "                ", "decoded", "[", "i", ",", "sent_lengths", "[", "i", "]", "]", "=", "eos_token_id", "\n", "\n", "\n", "", "", "return", "decoded", "", "", "", ""]], "home.repos.pwc.inspect_result.lucasftc_personakgc.model.reimpl_gpt2v0.set_scores_to_inf_for_banned_tokens": [[11, 33], ["enumerate", "torch.LongTensor", "torch.LongTensor", "torch.ones", "torch.ones", "torch.sparse.LongTensor().to().to_dense", "torch.sparse.LongTensor().to().to_dense", "scores.masked_fill_", "len", "banned_mask_list.append", "torch.sparse.LongTensor().to", "torch.sparse.LongTensor().to", "float", "torch.sparse.LongTensor", "torch.sparse.LongTensor", "torch.sparse.LongTensor().to().to_dense.t", "scores.size"], "function", ["None"], ["def", "set_scores_to_inf_for_banned_tokens", "(", "scores", ",", "banned_tokens", ")", "->", "None", ":", "\n", "    ", "\"\"\"Modifies the scores in place by setting the banned token positions to `-inf`. Banned token is expected to be\n    a list of list of banned tokens to ban in the format [[batch index, vocabulary position],...]\n        Args:\n            scores: logits distribution of shape (batch size, vocabulary size)\n            banned_tokens: list of list of tokens to ban of length (batch_size)\n    \"\"\"", "\n", "banned_mask_list", "=", "[", "]", "\n", "for", "idx", ",", "batch_banned_tokens", "in", "enumerate", "(", "banned_tokens", ")", ":", "\n", "        ", "for", "token", "in", "batch_banned_tokens", ":", "\n", "            ", "banned_mask_list", ".", "append", "(", "[", "idx", ",", "token", "]", ")", "\n", "", "", "if", "not", "banned_mask_list", ":", "\n", "        ", "return", "\n", "", "banned_mask", "=", "torch", ".", "LongTensor", "(", "banned_mask_list", ")", "\n", "indices", "=", "torch", ".", "ones", "(", "len", "(", "banned_mask", ")", ")", "\n", "# A sparse tensor is generated from a list of coordinates: [[0, 1], [0, 2], [2, 0]]. A conversion to dense tensor generates:", "\n", "# [ 0  1  1 ]", "\n", "# [ 0  0  0 ]", "\n", "# [ 1  0  0 ]", "\n", "\n", "banned_mask", "=", "torch", ".", "sparse", ".", "LongTensor", "(", "banned_mask", ".", "t", "(", ")", ",", "indices", ",", "scores", ".", "size", "(", ")", ")", ".", "to", "(", "scores", ".", "device", ")", ".", "to_dense", "(", ")", "\n", "scores", ".", "masked_fill_", "(", "banned_mask", "==", "1", ",", "-", "float", "(", "\"inf\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__init__": [[4, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "tokenizer", ",", "n_knowledge", ",", "n_persona", ",", "max_context_length", ",", "max_response_length", ",", "max_knowledge_length", ",", "max_persona_length", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "n_knowledge", "=", "n_knowledge", "\n", "self", ".", "n_persona", "=", "n_persona", "\n", "self", ".", "max_context_length", "=", "max_context_length", "\n", "self", ".", "max_response_length", "=", "max_response_length", "\n", "self", ".", "max_knowledge_length", "=", "max_knowledge_length", "\n", "self", ".", "max_persona_length", "=", "max_persona_length", "\n", "#assert glue in ['p|crk','k|crp','p|c','k|cp','p|cr']", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.load": [[15, 58], ["len", "range", "max", "max", "range", "len", "len", "len", "len", "max", "max", "persona_batcher.PersonaBatcher.persona_id_list.append", "persona_batcher.PersonaBatcher.knowledge_id_list.append", "persona_batcher.PersonaBatcher.context_id_list[].extend", "persona_batcher.PersonaBatcher.response_id_list[].extend", "persona_batcher.PersonaBatcher.tokenizer.encode", "range", "persona_batcher.PersonaBatcher.tokenizer.encode", "range", "max", "max", "len", "len", "len", "len", "k.extend", "len", "persona_batcher.PersonaBatcher.knowledge_id_list[].append", "p.extend", "len", "persona_batcher.PersonaBatcher.persona_id_list[].append", "persona_batcher.PersonaBatcher.tokenizer.encode", "persona_batcher.PersonaBatcher.tokenizer.encode", "range", "range", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "context_list", ",", "response_list", ",", "persona_list", ",", "knowledge_list", ",", "plabel_list", ",", "klabel_list", ")", ":", "\n", "        ", "assert", "len", "(", "context_list", ")", "==", "len", "(", "response_list", ")", "==", "len", "(", "persona_list", ")", "==", "len", "(", "knowledge_list", ")", "\n", "bs", "=", "len", "(", "context_list", ")", "\n", "self", ".", "context_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "' '", ".", "join", "(", "context_list", "[", "i", "]", ")", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_context_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "self", ".", "response_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "response_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_response_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "self", ".", "persona_id_list", "=", "[", "]", "\n", "self", ".", "knowledge_id_list", "=", "[", "]", "\n", "longest_persona", "=", "0", "\n", "longest_knowledge", "=", "0", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "persona", "=", "persona_list", "[", "i", "]", "\n", "knowledge", "=", "knowledge_list", "[", "i", "]", "\n", "# WARNING: We could not use random shuffle at here ", "\n", "# it is a list, every element is a single piece of persona id", "\n", "persona_id", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "p", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_persona_length", "]", "for", "p", "in", "persona", "[", ":", "self", ".", "n_persona", "]", "]", "\n", "longest_persona", "=", "max", "(", "max", "(", "[", "len", "(", "p", ")", "for", "p", "in", "persona_id", "]", ")", ",", "longest_persona", ")", "\n", "knowledge_id", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "k", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_knowledge_length", "]", "for", "k", "in", "knowledge", "[", ":", "self", ".", "n_knowledge", "]", "]", "\n", "longest_knowledge", "=", "max", "(", "max", "(", "[", "len", "(", "k", ")", "for", "k", "in", "knowledge_id", "]", ")", ",", "longest_knowledge", ")", "\n", "self", ".", "persona_id_list", ".", "append", "(", "persona_id", ")", "\n", "self", ".", "knowledge_id_list", ".", "append", "(", "knowledge_id", ")", "\n", "\n", "# padding", "\n", "", "longest_context", "=", "max", "(", "[", "len", "(", "self", ".", "context_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "longest_response", "=", "max", "(", "[", "len", "(", "self", ".", "response_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "padding_length", "=", "longest_context", "-", "len", "(", "self", ".", "context_id_list", "[", "i", "]", ")", "\n", "self", ".", "context_id_list", "[", "i", "]", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", ")", "\n", "padding_length", "=", "longest_response", "-", "len", "(", "self", ".", "response_id_list", "[", "i", "]", ")", "\n", "self", ".", "response_id_list", "[", "i", "]", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", ")", "\n", "for", "k", "in", "self", ".", "knowledge_id_list", "[", "i", "]", ":", "\n", "                ", "k", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_knowledge", "-", "len", "(", "k", ")", ")", ")", "\n", "", "while", "len", "(", "self", ".", "knowledge_id_list", "[", "i", "]", ")", "<", "self", ".", "n_knowledge", ":", "\n", "                ", "self", ".", "knowledge_id_list", "[", "i", "]", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "longest_knowledge", ")", "\n", "", "for", "p", "in", "self", ".", "persona_id_list", "[", "i", "]", ":", "\n", "                ", "p", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_persona", "-", "len", "(", "p", ")", ")", ")", "\n", "", "while", "len", "(", "self", ".", "persona_id_list", "[", "i", "]", ")", "<", "self", ".", "n_persona", ":", "\n", "                ", "self", ".", "persona_id_list", "[", "i", "]", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "longest_persona", ")", "\n", "\n", "", "", "self", ".", "bs", "=", "bs", "\n", "self", ".", "longest_context", "=", "longest_context", "\n", "self", ".", "longest_response", "=", "longest_response", "\n", "self", ".", "longest_persona", "=", "longest_persona", "\n", "self", ".", "longest_knowledge", "=", "longest_knowledge", "\n", "\n"]], "home.repos.pwc.inspect_result.lucasftc_personakgc.batcher.persona_batcher.PersonaBatcher.__call__": [[60, 170], ["torch.tensor", "torch.tensor", "len", "isinstance", "range", "len", "max", "range", "torch.tensor.append", "torch.tensor.append", "len", "isinstance", "range", "golden_knowedge_id.extend", "input_id.append", "segment_id.append", "len", "max", "range", "torch.tensor.append", "torch.tensor.append", "len", "isinstance", "range", "persona_batcher.PersonaBatcher.tokenizer.encode", "range", "len", "golden_persona_id.extend", "input_id.append", "segment_id.append", "len", "max", "range", "torch.tensor.append", "torch.tensor.append", "range", "range", "persona_batcher.PersonaBatcher.tokenizer.encode", "range", "len", "golden_persona_id.extend", "input_id.append", "segment_id.append", "range", "torch.tensor.append", "torch.tensor.append", "range", "len", "range", "persona_batcher.PersonaBatcher.tokenizer.encode", "range", "len", "input_id.append", "segment_id.append", "range", "torch.tensor.append", "torch.tensor.append", "range", "len", "range", "input_id.append", "segment_id.append", "range", "torch.tensor.append", "torch.tensor.append", "range", "len", "input_id.append", "segment_id.append", "range", "torch.tensor.append", "torch.tensor.append", "input_id.append", "segment_id.append"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "glue", ",", "golden_knowledge_list", "=", "None", ",", "golden_persona_list", "=", "None", ")", ":", "\n", "        ", "assert", "glue", "in", "[", "'p|crk'", ",", "'k|crp'", ",", "'k|cp'", ",", "'p|cr'", ",", "'p|c'", ",", "'k|cr'", ",", "'k|c'", "]", "\n", "# Note that k|cr and k|c are for ablation only", "\n", "batch_input_id", "=", "[", "]", "\n", "batch_segment_id", "=", "[", "]", "\n", "if", "glue", "==", "'p|crk'", ":", "\n", "            ", "assert", "len", "(", "golden_knowledge_list", ")", "==", "self", ".", "bs", "\n", "bs", "=", "len", "(", "golden_knowledge_list", ")", "\n", "if", "isinstance", "(", "golden_knowledge_list", "[", "0", "]", ",", "str", ")", ":", "\n", "                ", "golden_knowledge_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "golden_knowledge_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_knowledge_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "longest_goldenk", "=", "max", "(", "[", "len", "(", "golden_knowledge_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "golden_knowedge_id", "in", "golden_knowledge_id_list", ":", "\n", "                    ", "golden_knowedge_id", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_goldenk", "-", "len", "(", "golden_knowedge_id", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_persona", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "response_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "golden_knowledge_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "persona_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "1", "+", "self", ".", "longest_context", "+", "1", "+", "self", ".", "longest_response", "+", "1", "+", "longest_goldenk", "+", "1", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_persona", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "\n", "", "", "elif", "glue", "==", "'k|crp'", ":", "\n", "            ", "assert", "len", "(", "golden_persona_list", ")", "==", "self", ".", "bs", "\n", "bs", "=", "len", "(", "golden_persona_list", ")", "\n", "if", "isinstance", "(", "golden_persona_list", "[", "0", "]", ",", "str", ")", ":", "\n", "                ", "golden_persona_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "golden_persona_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_persona_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "longest_goldenp", "=", "max", "(", "[", "len", "(", "golden_persona_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "golden_persona_id", "in", "golden_persona_id_list", ":", "\n", "                    ", "golden_persona_id", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_goldenp", "-", "len", "(", "golden_persona_id", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "golden_persona_id_list", "=", "golden_persona_list", "\n", "", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_knowledge", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "response_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "golden_persona_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "knowledge_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "self", ".", "longest_response", "+", "longest_goldenp", "+", "4", ")", "+", "[", "1", "]", "*", "(", "1", "+", "self", ".", "longest_knowledge", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "", "", "elif", "glue", "==", "'k|cp'", ":", "\n", "            ", "assert", "len", "(", "golden_persona_list", ")", "==", "self", ".", "bs", "\n", "bs", "=", "len", "(", "golden_persona_list", ")", "\n", "if", "isinstance", "(", "golden_persona_list", "[", "0", "]", ",", "str", ")", ":", "\n", "                ", "golden_persona_id_list", "=", "[", "self", ".", "tokenizer", ".", "encode", "(", "golden_persona_list", "[", "i", "]", ",", "add_special_tokens", "=", "False", ")", "[", ":", "self", ".", "max_persona_length", "]", "for", "i", "in", "range", "(", "bs", ")", "]", "\n", "longest_goldenp", "=", "max", "(", "[", "len", "(", "golden_persona_id_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "bs", ")", "]", ")", "\n", "for", "golden_persona_id", "in", "golden_persona_id_list", ":", "\n", "                    ", "golden_persona_id", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "(", "longest_goldenp", "-", "len", "(", "golden_persona_id", ")", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_knowledge", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "golden_persona_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "knowledge_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "longest_goldenp", "+", "3", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_knowledge", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "", "", "elif", "glue", "==", "'p|cr'", ":", "\n", "            ", "bs", "=", "self", ".", "bs", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_persona", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "response_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "persona_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "self", ".", "longest_response", "+", "3", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_persona", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "\n", "", "", "elif", "glue", "==", "'k|cr'", ":", "\n", "            ", "bs", "=", "self", ".", "bs", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_knowledge", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "response_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "knowledge_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "self", ".", "longest_response", "+", "3", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_knowledge", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "\n", "", "", "elif", "glue", "==", "'k|c'", ":", "\n", "            ", "bs", "=", "self", ".", "bs", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_knowledge", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "knowledge_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "2", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_knowledge", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "\n", "", "", "elif", "glue", "==", "'p|c'", ":", "\n", "            ", "bs", "=", "self", ".", "bs", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "                ", "input_id", "=", "[", "]", "\n", "segment_id", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "n_persona", ")", ":", "\n", "                    ", "input_id", ".", "append", "(", "[", "self", ".", "tokenizer", ".", "cls_token_id", "]", "+", "self", ".", "context_id_list", "[", "i", "]", "+", "[", "self", ".", "tokenizer", ".", "sep_token_id", "]", "+", "self", ".", "persona_id_list", "[", "i", "]", "[", "j", "]", "+", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "segment_id", ".", "append", "(", "[", "0", "]", "*", "(", "self", ".", "longest_context", "+", "2", ")", "+", "[", "1", "]", "*", "(", "self", ".", "longest_persona", "+", "1", ")", ")", "\n", "", "batch_input_id", ".", "append", "(", "input_id", ")", "\n", "batch_segment_id", ".", "append", "(", "segment_id", ")", "\n", "\n", "", "", "batch_input_id", "=", "torch", ".", "tensor", "(", "batch_input_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "batch_segment_id", "=", "torch", ".", "tensor", "(", "batch_segment_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "return", "{", "\n", "'input_id'", ":", "batch_input_id", ",", "\n", "'segment_id'", ":", "batch_segment_id", "\n", "}", ""]]}