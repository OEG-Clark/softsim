{"home.repos.pwc.inspect_result.ShengzheXu_stan.None.test.test_artificial": [[7, 16], ["stannetflow.artificial.datamaker.artificial_data_generator", "stannetflow.artificial.datamaker.artificial_data_generator.sample", "stannetflow.artificial.datamaker.artificial_data_generator.agg", "stannetflow.STANSynthesizer", "stannetflow.STANSynthesizer.fit", "stannetflow.STANSynthesizer.sample", "print"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.agg", "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.fit", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample"], ["def", "test_artificial", "(", ")", ":", "\n", "  ", "adg", "=", "artificial_data_generator", "(", "weight_list", "=", "[", "0.9", ",", "0.9", "]", ")", "\n", "df_naive", "=", "adg", ".", "sample", "(", "row_num", "=", "100", ")", "\n", "X", ",", "y", "=", "adg", ".", "agg", "(", "agg", "=", "1", ")", "\n", "\n", "stan", "=", "STANSynthesizer", "(", "dim_in", "=", "2", ",", "dim_window", "=", "1", ")", "\n", "stan", ".", "fit", "(", "X", ",", "y", ")", "\n", "samples", "=", "stan", ".", "sample", "(", "10", ")", "\n", "print", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.None.test.test_ugr16": [[17, 45], ["stannetflow.STANCustomDataLoader().get_loader", "stannetflow.STANSynthesizer", "stannetflow.NetflowFormatTransformer", "stannetflow.STANSynthesizer.time_series_sample", "stannetflow.NetflowFormatTransformer.rev_transfer", "print", "stannetflow.STANSynthesizer.batch_fit", "stannetflow.STANSynthesizer.load_model", "stannetflow.STANCustomDataLoader"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANCustomDataLoader.get_loader", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.time_series_sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.rev_transfer", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.batch_fit", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.load_model"], ["", "def", "test_ugr16", "(", "train_file", ",", "load_checkpoint", "=", "False", ")", ":", "\n", "  ", "train_loader", "=", "STANCustomDataLoader", "(", "train_file", ",", "6", ",", "16", ")", ".", "get_loader", "(", ")", "\n", "ugr16_n_col", ",", "ugr16_n_agg", ",", "ugr16_arch_mode", "=", "16", ",", "5", ",", "'B'", "\n", "# index of the columns that are discrete (in one-hot groups), categorical (number of types)", "\n", "# or any order if wanted", "\n", "ugr16_discrete_columns", "=", "[", "[", "11", ",", "12", "]", ",", "[", "13", ",", "14", ",", "15", "]", "]", "\n", "ugr16_categorical_columns", "=", "{", "5", ":", "1670", ",", "6", ":", "1670", ",", "7", ":", "256", ",", "8", ":", "256", ",", "9", ":", "256", ",", "10", ":", "256", "}", "\n", "ugr16_execute_order", "=", "[", "0", ",", "1", ",", "13", ",", "11", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "3", ",", "2", ",", "4", "]", "\n", "\n", "stan", "=", "STANSynthesizer", "(", "dim_in", "=", "ugr16_n_col", ",", "dim_window", "=", "ugr16_n_agg", ",", "\n", "discrete_columns", "=", "ugr16_discrete_columns", ",", "\n", "categorical_columns", "=", "ugr16_categorical_columns", ",", "\n", "execute_order", "=", "ugr16_execute_order", ",", "\n", "arch_mode", "=", "ugr16_arch_mode", "\n", ")", "\n", "\n", "if", "load_checkpoint", "is", "False", ":", "\n", "    ", "stan", ".", "batch_fit", "(", "train_loader", ",", "epochs", "=", "2", ")", "\n", "", "else", ":", "\n", "    ", "stan", ".", "load_model", "(", "'ep998'", ")", "# checkpoint name", "\n", "# validation", "\n", "# stan.validate_loss(test_loader, loaded_ep='ep998')", "\n", "\n", "", "ntt", "=", "NetflowFormatTransformer", "(", ")", "\n", "samples", "=", "stan", ".", "time_series_sample", "(", "8640", ")", "\n", "df_rev", "=", "ntt", ".", "rev_transfer", "(", "samples", ")", "\n", "print", "(", "df_rev", ")", "\n", "return", "df_rev", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.preprocess.user_analysis": [[5, 7], ["stannetflow.analyze_functions.analyze"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.analyze"], ["def", "user_analysis", "(", ")", ":", "\n", "  ", "analyze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.preprocess.user_selection": [[8, 17], ["configparser.ConfigParser", "configparser.ConfigParser.read", "[].split", "print", "stannetflow.analyze_functions.prepare_folders", "stannetflow.analyze_functions.extract"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.prepare_folders", "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.extract"], ["", "def", "user_selection", "(", ")", ":", "\n", "  ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'./ugr16_config.ini'", ")", "\n", "# print({section: dict(config[section]) for section in config.sections()})", "\n", "user_list", "=", "config", "[", "'DEFAULT'", "]", "[", "'userlist'", "]", ".", "split", "(", "','", ")", "\n", "print", "(", "'extracting:'", ",", "user_list", ")", "\n", "prepare_folders", "(", ")", "\n", "# recover_userlist_from_folder()", "\n", "extract", "(", "user_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.preprocess.download_ugr16": [[18, 21], ["print", "print"], "function", ["None"], ["", "def", "download_ugr16", "(", ")", ":", "\n", "  ", "print", "(", "'Visit the following url to download april_week3.csv'", ")", "\n", "print", "(", "'https://nesg.ugr.es/nesg-ugr16/april_week3.php'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.preprocess._prepare": [[22, 34], ["len", "len", "NetflowFormatTransformer", "STANTemporalTransformer", "glob.glob", "print", "print", "pd.read_csv", "STANTemporalTransformer.push_back", "f.split"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer.push_back"], ["", "def", "_prepare", "(", "folder", "=", "''", ",", "output", "=", "''", ")", ":", "\n", "  ", "if", "len", "(", "folder", ")", "and", "len", "(", "output", ")", ":", "\n", "    ", "count", "=", "0", "\n", "ntt", "=", "NetflowFormatTransformer", "(", ")", "\n", "tft", "=", "STANTemporalTransformer", "(", "folder", ")", "\n", "for", "f", "in", "glob", ".", "glob", "(", "output", ")", ":", "\n", "      ", "print", "(", "'user:'", ",", "f", ")", "\n", "this_ip", "=", "f", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "df", "=", "pd", ".", "read_csv", "(", "f", ")", "\n", "tft", ".", "push_back", "(", "df", ",", "agg", "=", "agg", ",", "transformer", "=", "ntt", ")", "\n", "count", "+=", "1", "\n", "", "print", "(", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.preprocess.prepare_standata": [[35, 43], ["len", "len", "print", "preprocess._prepare", "print", "preprocess._prepare"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.preprocess._prepare", "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.preprocess._prepare"], ["", "", "def", "prepare_standata", "(", "agg", "=", "5", ",", "train_folder", "=", "'stan_data/day1_data'", ",", "train_output", "=", "'to_train.csv'", ",", "\n", "test_folder", "=", "'stan_data/day2_data'", ",", "test_output", "=", "'to_test.csv'", ")", ":", "\n", "  ", "if", "len", "(", "train_folder", ")", ":", "\n", "    ", "print", "(", "'making train for:'", ")", "\n", "_prepare", "(", "'stan_data/'", "+", "train_output", ",", "train_folder", "+", "'/*.csv'", ")", "\n", "", "if", "len", "(", "test_folder", ")", ":", "\n", "    ", "print", "(", "'making test for:'", ")", "\n", "_prepare", "(", "'stan_data/'", "+", "test_output", ",", "test_folder", "+", "'/*.csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.prepare_folders": [[18, 25], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "prepare_folders", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "working_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "working_folder", ")", "\n", "", "sub_folders", "=", "[", "'raw_data'", ",", "'cleaned_data'", ",", "'gen_data'", "]", "\n", "for", "i", "in", "sub_folders", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "working_folder", "+", "i", "+", "'/'", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "working_folder", "+", "i", "+", "'/'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.do_write": [[26, 33], ["os.path.isfile", "df.to_csv", "df.to_csv"], "function", ["None"], ["", "", "", "def", "do_write", "(", "df", ",", "filename", ")", ":", "\n", "    ", "filename", "=", "outputfile", "%", "filename", "\n", "# if file does not exist write header ", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "filename", ")", ":", "\n", "        ", "df", ".", "to_csv", "(", "filename", ",", "header", "=", "'column_names'", ",", "index", "=", "False", ")", "\n", "", "else", ":", "# else it exists so append without writing the header", "\n", "        ", "df", ".", "to_csv", "(", "filename", ",", "mode", "=", "'a'", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.extract": [[34, 64], ["pandas.read_csv", "datetime.datetime.now", "isinstance", "datetime.datetime.now", "print", "gc.collect", "len", "print", "analyze_functions.do_write", "chunk[].str.startswith", "len", "print", "analyze_functions.do_write", "len"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.do_write", "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.do_write"], ["", "", "def", "extract", "(", "theUserIP", ")", ":", "\n", "    ", "chunkNum", "=", "0", "\n", "gen_flag", "=", "True", "\n", "chunksize", "=", "10", "**", "6", "\n", "import", "gc", "\n", "\n", "for", "chunk", "in", "pd", ".", "read_csv", "(", "normal_datafile", ",", "chunksize", "=", "chunksize", ",", "header", "=", "None", ",", "names", "=", "columnName", ")", ":", "\n", "        ", "block_time1", "=", "datetime", ".", "now", "(", ")", "\n", "chunk", "=", "chunk", "[", "chunk", "[", "'te'", "]", ".", "str", ".", "startswith", "(", "theDate", ")", "]", "\n", "if", "(", "len", "(", "chunk", ".", "index", ")", "==", "0", ")", ":", "\n", "            ", "break", "\n", "\n", "", "chunkNum", "+=", "1", "\n", "# chunk = chunk.sample(n=int(len(chunk.index)/10),random_state=131,axis=0)", "\n", "if", "isinstance", "(", "theUserIP", ",", "list", ")", ":", "\n", "            ", "for", "one_ip", "in", "theUserIP", ":", "\n", "                ", "chunk2", "=", "chunk", "[", "(", "chunk", "[", "'sa'", "]", "==", "one_ip", ")", "|", "(", "chunk", "[", "'da'", "]", "==", "one_ip", ")", "]", "\n", "if", "gen_flag", ":", "\n", "                    ", "print", "(", "len", "(", "chunk2", ".", "index", ")", ",", "\"to write for\"", ",", "one_ip", ")", "\n", "do_write", "(", "chunk2", ",", "one_ip", ")", "\n", "", "del", "chunk2", "\n", "", "", "else", ":", "\n", "            ", "chunk2", "=", "chunk", "[", "chunk", "[", "'sa'", "]", "==", "theUserIP", "]", "\n", "print", "(", "len", "(", "chunk2", ".", "index", ")", ",", "\"to write\"", ")", "\n", "do_write", "(", "chunk2", ",", "theUserIP", ")", "\n", "\n", "", "block_time2", "=", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"blockNum\"", ",", "chunkNum", ",", "\",time:\"", ",", "(", "block_time2", "-", "block_time1", ")", ".", "seconds", ")", "\n", "del", "chunk", "\n", "gc", ".", "collect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.sample_choice": [[65, 69], ["pandas.read_csv", "all_record.sample.sample", "analyze_functions.do_write"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.do_write"], ["", "", "def", "sample_choice", "(", "filename", ",", "num_of_row", ")", ":", "\n", "    ", "all_record", "=", "pd", ".", "read_csv", "(", "filename", ")", "\n", "all_record", "=", "all_record", ".", "sample", "(", "n", "=", "num_of_row", ",", "random_state", "=", "131", ",", "axis", "=", "0", ")", "\n", "do_write", "(", "all_record", ",", "'sampled_10IPs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.cal_stats": [[73, 99], ["zip", "r[].startswith", "r[].startswith", "r[].startswith", "r[].startswith"], "function", ["None"], ["def", "cal_stats", "(", "df", ")", ":", "\n", "    ", "for", "r", "in", "zip", "(", "df", "[", "'sa'", "]", ",", "df", "[", "'da'", "]", ")", ":", "\n", "# count occurence of the sa", "\n", "        ", "if", "r", "[", "0", "]", ".", "startswith", "(", "internal_ip", ")", ":", "\n", "            ", "if", "r", "[", "0", "]", "in", "occur_dict", ":", "\n", "                ", "occur_dict", "[", "r", "[", "0", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "occur_dict", "[", "r", "[", "0", "]", "]", "=", "1", "\n", "# judge the outgoing traffic to an external ip", "\n", "", "if", "not", "r", "[", "1", "]", ".", "startswith", "(", "internal_ip", ")", ":", "\n", "                ", "if", "r", "[", "0", "]", "in", "outgoing_dict", ":", "\n", "                    ", "outgoing_dict", "[", "r", "[", "0", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "outgoing_dict", "[", "r", "[", "0", "]", "]", "=", "1", "\n", "# count occurence of the da", "\n", "", "", "", "if", "r", "[", "1", "]", ".", "startswith", "(", "internal_ip", ")", ":", "\n", "            ", "if", "r", "[", "1", "]", "in", "occur_dict", ":", "\n", "                ", "occur_dict", "[", "r", "[", "1", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "occur_dict", "[", "r", "[", "1", "]", "]", "=", "1", "\n", "# judge the incoming traffic from an external ip", "\n", "", "if", "not", "r", "[", "0", "]", ".", "startswith", "(", "internal_ip", ")", ":", "\n", "                ", "if", "r", "[", "1", "]", "in", "incoming_dict", ":", "\n", "                    ", "incoming_dict", "[", "r", "[", "1", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "incoming_dict", "[", "r", "[", "1", "]", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.analyze": [[100, 148], ["datetime.datetime.now", "pandas.read_csv", "sorted", "print", "print", "print", "datetime.datetime.now", "print", "analyze_functions.cal_stats", "print", "gc.collect", "open", "f.write", "len", "len", "chunk[].str.startswith", "occur_dict.items", "chunk[].str.startswith", "chunk[].str.startswith", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.cal_stats"], ["", "", "", "", "", "def", "analyze", "(", ")", ":", "\n", "    ", "starttime", "=", "datetime", ".", "now", "(", ")", "\n", "chunksize", "=", "10", "**", "6", "\n", "chunkNum", "=", "0", "\n", "import", "gc", "\n", "\n", "for", "chunk", "in", "pd", ".", "read_csv", "(", "normal_datafile", ",", "chunksize", "=", "chunksize", ",", "header", "=", "None", ",", "names", "=", "columnName", ")", ":", "\n", "        ", "chunk", "=", "chunk", "[", "chunk", "[", "'te'", "]", ".", "str", ".", "startswith", "(", "theDate", ")", "]", "\n", "if", "(", "len", "(", "chunk", ".", "index", ")", "==", "0", ")", ":", "\n", "            ", "break", "\n", "", "chunk", "=", "chunk", "[", "chunk", "[", "'sa'", "]", ".", "str", ".", "startswith", "(", "internal_ip", ")", "|", "chunk", "[", "'da'", "]", ".", "str", ".", "startswith", "(", "internal_ip", ")", "]", "\n", "chunkNum", "+=", "1", "\n", "cal_stats", "(", "chunk", ")", "\n", "print", "(", "\"blockNum\"", ",", "chunkNum", ",", "\"with\"", ",", "len", "(", "chunk", ".", "index", ")", ")", "\n", "del", "chunk", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "most_occure", "=", "sorted", "(", "(", "(", "v", ",", "k", ")", "for", "k", ",", "v", "in", "occur_dict", ".", "items", "(", ")", ")", ",", "reverse", "=", "True", ")", "\n", "print", "(", "\"most bi-direction traffic users\"", ",", "most_occure", "[", ":", "20", "]", ")", "\n", "\n", "categories_count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "# both sent&recieve, only sent to ex, only recieve from ex, interal-to-internal", "\n", "with", "open", "(", "'data_stats.csv'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "outstring", "=", "'number_of_rows,ip,incoming_num,outgoing_num,user_type\\n'", "\n", "for", "case", "in", "most_occure", ":", "\n", "            ", "if", "case", "[", "1", "]", "not", "in", "incoming_dict", ":", "\n", "                ", "incoming_dict", "[", "case", "[", "1", "]", "]", "=", "0", "\n", "", "if", "case", "[", "1", "]", "not", "in", "outgoing_dict", ":", "\n", "                ", "outgoing_dict", "[", "case", "[", "1", "]", "]", "=", "0", "\n", "", "user_type", "=", "-", "1", "\n", "if", "incoming_dict", "[", "case", "[", "1", "]", "]", ">", "0", "and", "outgoing_dict", "[", "case", "[", "1", "]", "]", ">", "0", ":", "\n", "                ", "categories_count", "[", "0", "]", "+=", "1", "\n", "user_type", "=", "0", "\n", "", "elif", "incoming_dict", "[", "case", "[", "1", "]", "]", "==", "0", "and", "outgoing_dict", "[", "case", "[", "1", "]", "]", ">", "0", ":", "\n", "                ", "categories_count", "[", "1", "]", "+=", "1", "\n", "user_type", "=", "1", "\n", "", "elif", "incoming_dict", "[", "case", "[", "1", "]", "]", ">", "0", "and", "outgoing_dict", "[", "case", "[", "1", "]", "]", "==", "0", ":", "\n", "                ", "categories_count", "[", "2", "]", "+=", "1", "\n", "user_type", "=", "2", "\n", "", "else", ":", "# incoming_dict[case[1]]==0 and outgoing_dict[case[1]]==0", "\n", "                ", "categories_count", "[", "3", "]", "+=", "1", "\n", "user_type", "=", "3", "\n", "", "outstring", "+=", "','", ".", "join", "(", "[", "str", "(", "case", "[", "0", "]", ")", ",", "case", "[", "1", "]", ",", "str", "(", "incoming_dict", "[", "case", "[", "1", "]", "]", ")", ",", "str", "(", "outgoing_dict", "[", "case", "[", "1", "]", "]", ")", ",", "str", "(", "user_type", ")", "]", ")", "+", "'\\n'", "\n", "\n", "", "f", ".", "write", "(", "outstring", ")", "\n", "", "print", "(", "\"4 categories count: both sent&recieve, only sent to ex, only recieve from ex, interal-to-internal\"", ")", "\n", "print", "(", "categories_count", ")", "\n", "endtime", "=", "datetime", ".", "now", "(", ")", "\n", "print", "(", "'process time'", ",", "(", "endtime", "-", "starttime", ")", ".", "seconds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.previous_check": [[149, 152], ["print", "len"], "function", ["None"], ["", "def", "previous_check", "(", "previous_user_list", ",", "a_ip_list", ")", ":", "\n", "    ", "retA", "=", "[", "i", "for", "i", "in", "previous_user_list", "if", "i", "in", "a_ip_list", "]", "\n", "print", "(", "'previous ip type 0'", ",", "len", "(", "retA", ")", ",", "retA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.plot_refer": [[154, 191], ["pandas.read_csv", "sys.path.append", "print", "a[].values.tolist", "plot_source_distribution", "a[].values.tolist", "int", "int", "int", "sample", "print", "print", "analyze_functions.previous_check", "numpy.log", "range", "print", "len", "sum", "str", "configparser.ConfigParser", "configparser.ConfigParser.read", "a[].str.startswith", "a[].tolist", "len", "len", "open", "configparser.ConfigParser.write", "len"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.previous_check"], ["", "def", "plot_refer", "(", "stats_file", ",", "set_config_user", "=", "False", ",", "previous_user_list", "=", "None", ")", ":", "\n", "    ", "a", "=", "pd", ".", "read_csv", "(", "stats_file", ")", "\n", "a", "=", "a", "[", "a", "[", "'ip'", "]", ".", "str", ".", "startswith", "(", "internal_ip", ")", "]", "\n", "a", "=", "a", "[", "a", "[", "'user_type'", "]", "==", "0", "]", "\n", "if", "previous_user_list", "is", "not", "None", ":", "\n", "        ", "previous_check", "(", "previous_user_list", ",", "a", "[", "'ip'", "]", ".", "tolist", "(", ")", ")", "\n", "", "sys", ".", "path", ".", "append", "(", "'../'", ")", "\n", "print", "(", "\"current sys path:\"", ",", "sys", ".", "path", ")", "\n", "from", "utils", ".", "plot_utils", "import", "plot_source_distribution", "\n", "\n", "num_of_connection", "=", "a", "[", "'number_of_rows'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "plot_source_distribution", "(", "np", ".", "log", "(", "num_of_connection", ")", ")", "\n", "\n", "user_addresses", "=", "a", "[", "'ip'", "]", ".", "values", ".", "tolist", "(", ")", "\n", "q_1", "=", "int", "(", "len", "(", "num_of_connection", ")", "/", "4", ")", "\n", "median_index", "=", "int", "(", "len", "(", "num_of_connection", ")", "/", "2", ")", "\n", "q_3", "=", "int", "(", "len", "(", "num_of_connection", ")", "*", "3", "/", "4", ")", "\n", "\n", "from", "random", "import", "sample", "\n", "selected_users_index", "=", "sample", "(", "range", "(", "q_1", ",", "q_3", ")", ",", "100", ")", "\n", "# selected_users_index = range(450, 551)", "\n", "\n", "for", "i", "in", "selected_users_index", ":", "\n", "        ", "print", "(", "user_addresses", "[", "i", "]", ",", "num_of_connection", "[", "i", "]", ")", "\n", "\n", "", "print", "(", "'total:'", ",", "len", "(", "num_of_connection", ")", ",", "sum", "(", "num_of_connection", ")", ")", "\n", "print", "(", "'we selected between:'", ",", "q_1", ",", "q_3", ",", "selected_users_index", ")", "\n", "\n", "selected_users", "=", "[", "str", "(", "user_addresses", "[", "x", "]", ")", "for", "x", "in", "selected_users_index", "]", "\n", "if", "set_config_user", "is", "True", ":", "\n", "        ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'./ugr16_config.ini'", ")", "\n", "config", "[", "'DEFAULT'", "]", "[", "'userlist'", "]", "=", "','", ".", "join", "(", "selected_users", ")", "\n", "config", "[", "'GENERATE'", "]", "[", "'gen_users'", "]", "=", "','", ".", "join", "(", "selected_users", ")", "\n", "\n", "with", "open", "(", "'./ugr16_config.ini'", ",", "'w'", ")", "as", "configfile", ":", "\n", "            ", "config", ".", "write", "(", "configfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.stannetflow.analyze_functions.recover_userlist_from_folder": [[192, 208], ["glob.glob", "print", "configparser.ConfigParser", "configparser.ConfigParser.read", "user_list.append", "len", "open", "configparser.ConfigParser.write", "pandas.read_csv", "f.split"], "function", ["None"], ["", "", "", "def", "recover_userlist_from_folder", "(", ")", ":", "\n", "    ", "import", "glob", "\n", "source_folder", "=", "'./../data/raw_data/'", "\n", "user_list", "=", "[", "]", "\n", "how_long", "=", "0", "\n", "for", "f", "in", "glob", ".", "glob", "(", "source_folder", "+", "'*.csv'", ")", ":", "\n", "        ", "user_list", ".", "append", "(", "f", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", "\n", "how_long", "+=", "len", "(", "pd", ".", "read_csv", "(", "f", ")", ".", "index", ")", "\n", "", "print", "(", "'recovered userlist: %d rows in total\\n'", "%", "how_long", ",", "user_list", ")", "\n", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'./ugr16_config.ini'", ")", "\n", "config", "[", "'DEFAULT'", "]", "[", "'userlist'", "]", "=", "','", ".", "join", "(", "user_list", ")", "\n", "config", "[", "'GENERATE'", "]", "[", "'gen_users'", "]", "=", "','", ".", "join", "(", "user_list", ")", "\n", "\n", "with", "open", "(", "'./ugr16_config.ini'", ",", "'w'", ")", "as", "configfile", ":", "\n", "        ", "config", ".", "write", "(", "configfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.__init__": [[11, 48], ["torch.Module.__init__", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "nets.SingleTaskNet.make_layers", "nets.MixtureDensityNetwork", "nets.SingleTaskNet.make_decs", "len"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.__init__", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.make_layers", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.make_decs"], ["    ", "def", "__init__", "(", "self", ",", "dim_in", ",", "dim_out", ",", "dim_window", "=", "1", ",", "mask_mode", "=", "None", ",", "encoder_arch", "=", "None", ",", "decoder_arch", "=", "None", ",", "model_tag", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# data dimension", "\n", "self", ".", "model_tag", "=", "model_tag", "\n", "self", ".", "dim_in", "=", "dim_in", "\n", "self", ".", "dim_out", "=", "dim_out", "\n", "\n", "self", ".", "window_cnn_network", "=", "None", "\n", "self", ".", "window_fc_network", "=", "None", "\n", "self", ".", "gmm_network", "=", "None", "\n", "self", ".", "dec_network", "=", "None", "\n", "self", ".", "memory", "=", "[", "]", "\n", "\n", "# mask", "\n", "self", ".", "mask_mode", "=", "mask_mode", "\n", "self", ".", "mask", "=", "None", "\n", "\n", "if", "mask_mode", "is", "None", ":", "\n", "            ", "self", ".", "mask", "=", "torch", ".", "ones", "(", "(", "(", "dim_window", "+", "1", ")", ",", "dim_in", ")", ")", "\n", "self", ".", "mask", "[", "dim_window", ",", ":", "]", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "mask", "=", "torch", ".", "ones", "(", "(", "(", "dim_window", "+", "1", ")", ",", "dim_in", ")", ")", "\n", "for", "col_i", "in", "range", "(", "len", "(", "mask_mode", ")", ")", ":", "\n", "                ", "self", ".", "mask", "[", "dim_window", ",", "col_i", "]", "=", "mask_mode", "[", "col_i", "]", "\n", "\n", "", "", "curr_in", "=", "dim_in", "*", "dim_window", "if", "mask_mode", "is", "None", "else", "dim_in", "*", "(", "dim_window", "+", "1", ")", "\n", "# curr_in = dim_in * (dim_window+1)", "\n", "if", "encoder_arch", "is", "not", "None", ":", "\n", "            ", "self", ".", "window_cnn_network", "=", "self", ".", "make_layers", "(", "encoder_arch", ")", "\n", "# self.window_fc = nn.Linear(dim_in, dim_in)", "\n", "curr_in", "=", "96", "\n", "", "assert", "decoder_arch", "[", "0", "]", "in", "[", "'gmm'", ",", "'softmax'", "]", ",", "\"Unknown Decoder Type\"", "\n", "self", ".", "decoder_type", "=", "decoder_arch", "[", "0", "]", "\n", "if", "self", ".", "decoder_type", "==", "'gmm'", ":", "\n", "            ", "self", ".", "gmm_network", "=", "MixtureDensityNetwork", "(", "curr_in", ",", "dim_out", ",", "n_components", "=", "decoder_arch", "[", "1", "]", ")", "\n", "", "else", ":", "#softmax", "\n", "            ", "self", ".", "dec_network", "=", "self", ".", "make_decs", "(", "curr_in", ",", "dim_out", ",", "hidden_dim", "=", "decoder_arch", "[", "1", "]", ",", "is_onehot", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.forward": [[49, 79], ["nets.SingleTaskNet.make_mask", "nets.SingleTaskNet.view", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "nets.SingleTaskNet.window_cnn_network", "out_window.view.view.view", "nets.SingleTaskNet.gmm_network", "nets.SingleTaskNet.dec_network", "nets.SingleTaskNet.size", "out_window.view.view.size"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.make_mask"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# print('forward x', x.shape)", "\n", "# print('example x', x[0])", "\n", "        ", "out", "=", "self", ".", "make_mask", "(", "x", ")", "\n", "\n", "if", "self", ".", "window_cnn_network", "is", "not", "None", ":", "\n", "# out_window = out[:, :-1, :]", "\n", "# out_row = out[:, -1, :]", "\n", "\n", "            ", "out_window", "=", "torch", ".", "unsqueeze", "(", "out", ",", "1", ")", "\n", "out_window", "=", "self", ".", "window_cnn_network", "(", "out_window", ")", "\n", "out_window", "=", "out_window", ".", "view", "(", "out_window", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "# reslink", "\n", "# out_row = F.relu(self.window_fc(out_row))", "\n", "# print(out.shape)", "\n", "# out = torch.cat((out_window, out_row), 1)", "\n", "# print(out_window.shape)", "\n", "# print(out_row.shape)", "\n", "# print(out.shape)", "\n", "# input()", "\n", "\n", "", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "gmm_network", "is", "not", "None", ":", "\n", "            ", "pi", ",", "normal", "=", "self", ".", "gmm_network", "(", "out", ")", "\n", "return", "pi", ",", "normal", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "dec_network", "(", "out", ")", "\n", "# print('dec_out', out)", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.loss": [[80, 107], ["nets.SingleTaskNet.memory.append", "nets.SingleTaskNet.forward", "nets.SingleTaskNet.forward", "nets.SingleTaskNet.cpu().detach().numpy", "nets.SingleTaskNet.gmm_network.bin_loss", "nets.SingleTaskNet.gmm_network.loss", "[].long", "y_reshape_func.long().squeeze", "y_reshape_func.size", "y_reshape_func", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "print", "print", "nets.SingleTaskNet.cpu().detach", "y_reshape_func.long", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "nets.SingleTaskNet.cpu"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.Net.forward", "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.Net.forward", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.bin_loss", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.loss"], ["", "", "def", "loss", "(", "self", ",", "x", ",", "y", ",", "y_reshape_func", "=", "None", ",", "bin_type", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "decoder_type", "==", "'gmm'", ":", "\n", "            ", "pi", ",", "normal", "=", "self", ".", "forward", "(", "x", ")", "\n", "if", "bin_type", ":", "\n", "                ", "batch_loss", "=", "self", ".", "gmm_network", ".", "bin_loss", "(", "pi", ",", "normal", ",", "y", ")", "\n", "", "else", ":", "\n", "                ", "batch_loss", "=", "self", ".", "gmm_network", ".", "loss", "(", "pi", ",", "normal", ",", "y", ")", "\n", "", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "forward", "(", "x", ")", "\n", "# print('model_tag',self.model_tag, y.shape, 'y_type', type(y), y)", "\n", "# input()", "\n", "if", "y", ".", "size", "(", ")", "[", "1", "]", ">", "1", ":", "\n", "                ", "y", "=", "torch", ".", "max", "(", "y", ",", "1", ")", "[", "1", "]", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "y_reshape_func", "is", "not", "None", ":", "\n", "                    ", "y", "=", "y_reshape_func", "(", "y", ")", "\n", "", "y", "=", "y", ".", "long", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "# print('out', out)", "\n", "# print('fixed', y)", "\n", "", "try", ":", "\n", "                ", "batch_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "(", "out", ",", "y", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "'y'", ",", "y", ")", "\n", "print", "(", "'out'", ",", "out", ")", "\n", "", "", "self", ".", "memory", ".", "append", "(", "batch_loss", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# print('batch_loss', batch_loss.detach().numpy())", "\n", "return", "batch_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.batch_reset": [[108, 110], ["None"], "methods", ["None"], ["", "def", "batch_reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "memory", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.get_batch_loss": [[111, 116], ["numpy.mean"], "methods", ["None"], ["", "def", "get_batch_loss", "(", "self", ")", ":", "\n", "# print(self.memory)", "\n", "# print(np.mean(self.memory[0]))", "\n", "# input()", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "memory", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.sample": [[117, 125], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "nets.SingleTaskNet.forward", "nets.SingleTaskNet.gmm_network.sample", "nets.SingleTaskNet.forward", "nets.SingleTaskNet.softmax_sample"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.Net.forward", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.Net.forward", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.softmax_sample"], ["", "def", "sample", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "torch", ".", "unsqueeze", "(", "x", ",", "0", ")", "\n", "if", "self", ".", "decoder_type", "==", "'gmm'", ":", "\n", "            ", "pi", ",", "normal", "=", "self", ".", "forward", "(", "x", ")", "\n", "return", "self", ".", "gmm_network", ".", "sample", "(", "pi", ",", "normal", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "forward", "(", "x", ")", "\n", "return", "self", ".", "softmax_sample", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.make_mask": [[126, 133], ["x.to", "nets.SingleTaskNet.mask.to"], "methods", ["None"], ["", "", "def", "make_mask", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "mask_mode", "is", "None", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", "-", "self", ".", "dim_in", "]", "\n", "# x = x * self.mask", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "to", "(", "device", ")", "*", "self", ".", "mask", ".", "to", "(", "device", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.make_layers": [[134, 149], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["", "def", "make_layers", "(", "self", ",", "cfg", ",", "batch_norm", "=", "True", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "in_channels", "=", "1", "\n", "# print(cfg)", "\n", "for", "v", "in", "cfg", ":", "\n", "            ", "if", "v", "==", "'M'", ":", "\n", "                ", "layers", "+=", "[", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "]", "\n", "", "else", ":", "\n", "                ", "conv2d", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "v", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "if", "batch_norm", ":", "\n", "                    ", "layers", "+=", "[", "conv2d", ",", "nn", ".", "BatchNorm2d", "(", "v", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "", "else", ":", "\n", "                    ", "layers", "+=", "[", "conv2d", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "", "in_channels", "=", "v", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.make_decs": [[150, 167], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["", "def", "make_decs", "(", "self", ",", "input_dim", ",", "output_dim", ",", "hidden_dim", "=", "100", ",", "is_onehot", "=", "True", ")", ":", "\n", "        ", "if", "is_onehot", ":", "\n", "            ", "dec_layer", "=", "nn", ".", "Sequential", "(", "\n", "#nn.Linear(input_num, hidden_num),", "\n", "#nn.ReLU(inplace=True),", "\n", "#nn.Linear(hidden_num, output_num),", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", ",", "\n", "# nn.Softmax()", "\n", ")", "\n", "", "else", ":", "\n", "            ", "dec_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "output_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n", "", "return", "dec_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.softmax_sample": [[168, 175], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical.sample().data.tolist", "torch.distributions.Categorical.sample().data.tolist", "torch.distributions.Categorical.sample().data.tolist", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample"], ["", "def", "softmax_sample", "(", "self", ",", "out", ")", ":", "\n", "        ", "probs", "=", "F", ".", "softmax", "(", "out", ",", "dim", "=", "1", ")", "\n", "dist", "=", "torch", ".", "distributions", ".", "Categorical", "(", "probs", ")", "\n", "sample", "=", "dist", ".", "sample", "(", ")", ".", "data", ".", "tolist", "(", ")", "[", "0", "]", "\n", "# print(out, probs, dist, sample)", "\n", "# input()", "\n", "return", "sample", ",", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.__init__": [[189, 194], ["torch.Module.__init__", "nets.CategoricalNetwork", "nets.MixtureDiagNormalNetwork"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.__init__"], ["def", "__init__", "(", "self", ",", "dim_in", ",", "dim_out", ",", "n_components", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pi_network", "=", "CategoricalNetwork", "(", "dim_in", ",", "n_components", ")", "\n", "self", ".", "normal_network", "=", "MixtureDiagNormalNetwork", "(", "dim_in", ",", "dim_out", ",", "\n", "n_components", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.forward": [[195, 197], ["nets.MixtureDensityNetwork.pi_network", "nets.MixtureDensityNetwork.normal_network"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "pi_network", "(", "x", ")", ",", "self", ".", "normal_network", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.manual_logsumexp": [[198, 200], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "manual_logsumexp", "(", "self", ",", "x", ",", "dim", "=", "1", ")", ":", "\n", "        ", "return", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "x", ")", ",", "dim", "=", "dim", ")", "+", "1e-10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.cdf_func": [[201, 203], ["torch.erf", "torch.erf", "torch.erf", "torch.erf", "torch.erf", "torch.erf", "torch.erf", "torch.erf", "torch.erf", "math.sqrt", "sigma.reciprocal"], "methods", ["None"], ["", "def", "cdf_func", "(", "self", ",", "sigma", ",", "mu", ",", "value", ")", ":", "\n", "        ", "return", "0.5", "*", "(", "1", "+", "torch", ".", "erf", "(", "(", "value", "-", "mu", ")", "*", "sigma", ".", "reciprocal", "(", ")", "/", "math", ".", "sqrt", "(", "2", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.bin_loss": [[204, 213], ["y.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "normal.cdf", "normal.cdf", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "y.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "bin_loss", "(", "self", ",", "pi", ",", "normal", ",", "y", ")", ":", "\n", "        ", "binwidth", "=", "1.0", "/", "200", "/", "2.0", "\n", "y", "=", "y", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "normal", ".", "loc", ")", "\n", "# loglik = self.cdf_func(normal.scale, normal.loc, y+binwidth) - self.cdf_func(normal.scale, normal.loc, y-binwidth)", "\n", "loglik", "=", "normal", ".", "cdf", "(", "y", "+", "binwidth", ")", "-", "normal", ".", "cdf", "(", "y", "-", "binwidth", ")", "\n", "loglik", "=", "torch", ".", "prod", "(", "loglik", ",", "dim", "=", "2", ")", "\n", "loss", "=", "-", "torch", ".", "log", "(", "torch", ".", "sum", "(", "pi", ".", "probs", "*", "loglik", ",", "dim", "=", "1", ")", "+", "1e-10", ")", "\n", "\n", "return", "torch", ".", "mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.loss": [[214, 221], ["y.to.to.to", "normal.log_prob", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "y.to.to.unsqueeze().expand_as", "nets.MixtureDensityNetwork.manual_logsumexp", "y.to.to.unsqueeze", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.manual_logsumexp"], ["", "def", "loss", "(", "self", ",", "pi", ",", "normal", ",", "y", ")", ":", "\n", "        ", "y", "=", "y", ".", "to", "(", "device", ")", "\n", "loglik", "=", "normal", ".", "log_prob", "(", "y", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "normal", ".", "loc", ")", ")", "\n", "loglik", "=", "torch", ".", "sum", "(", "loglik", ",", "dim", "=", "2", ")", "\n", "# loss = -torch.logsumexp(torch.log(pi.probs) + loglik, dim=1)", "\n", "loss", "=", "-", "self", ".", "manual_logsumexp", "(", "torch", ".", "log", "(", "pi", ".", "probs", ")", "+", "loglik", ",", "dim", "=", "1", ")", "\n", "return", "torch", ".", "mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.sample": [[222, 226], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "pi.sample().unsqueeze", "normal.sample", "pi.sample"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample"], ["", "def", "sample", "(", "self", ",", "pi", ",", "normal", ")", ":", "\n", "# pi, normal = self.forward(x)", "\n", "        ", "samples", "=", "torch", ".", "sum", "(", "pi", ".", "sample", "(", ")", ".", "unsqueeze", "(", "2", ")", "*", "normal", ".", "sample", "(", ")", ",", "dim", "=", "1", ")", "\n", "return", "samples", ",", "normal", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDiagNormalNetwork.__init__": [[230, 239], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ELU", "torch.ELU", "torch.ELU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ",", "n_components", ",", "hidden_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_components", "=", "n_components", "\n", "if", "hidden_dim", "is", "None", ":", "\n", "            ", "hidden_dim", "=", "in_dim", "\n", "", "self", ".", "network", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "2", "*", "out_dim", "*", "n_components", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDiagNormalNetwork.forward": [[241, 249], ["nets.MixtureDiagNormalNetwork.network", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp().transpose", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "params", "=", "self", ".", "network", "(", "x", ")", "\n", "# print(params)", "\n", "# input()", "\n", "mean", ",", "sd", "=", "torch", ".", "split", "(", "params", ",", "params", ".", "shape", "[", "1", "]", "//", "2", ",", "dim", "=", "1", ")", "\n", "mean", "=", "torch", ".", "stack", "(", "mean", ".", "split", "(", "mean", ".", "shape", "[", "1", "]", "//", "self", ".", "n_components", ",", "1", ")", ")", "\n", "sd", "=", "torch", ".", "stack", "(", "sd", ".", "split", "(", "sd", ".", "shape", "[", "1", "]", "//", "self", ".", "n_components", ",", "1", ")", ")", "\n", "return", "Normal", "(", "mean", ".", "transpose", "(", "0", ",", "1", ")", ",", "torch", ".", "exp", "(", "sd", ")", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.CategoricalNetwork.__init__": [[252, 260], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ELU", "torch.ELU", "torch.ELU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ",", "hidden_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "hidden_dim", "is", "None", ":", "\n", "            ", "hidden_dim", "=", "in_dim", "\n", "", "self", ".", "network", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "out_dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.CategoricalNetwork.forward": [[262, 265], ["nets.CategoricalNetwork.network", "torch.distributions.OneHotCategorical", "torch.distributions.OneHotCategorical", "torch.distributions.OneHotCategorical"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "params", "=", "self", ".", "network", "(", "x", ")", "\n", "return", "OneHotCategorical", "(", "logits", "=", "params", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.__init__": [[25, 134], ["range", "sorted", "stan.STANSynthesizer.discrete_belong.keys", "stannetflow.synthesizers.nets.SingleTaskNet", "sum", "torch.Adam", "torch.Adam", "torch.Adam", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "stan.STANSynthesizer.discrete_belong.keys", "range", "stan.STANSynthesizer.models.keys", "stan.STANSynthesizer.models[].to", "stan.STANSynthesizer.categorical_columns_dim.keys", "stan.STANSynthesizer.disc_agents.append", "stan.STANSynthesizer.categorical_columns_dim.keys", "stan.STANSynthesizer.disc_agents.append", "stan.STANSynthesizer.cont_agents.append", "stannetflow.synthesizers.nets.SingleTaskNet.parameters", "stannetflow.synthesizers.nets.SingleTaskNet", "sum", "torch.Adam", "torch.Adam", "torch.Adam", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "input", "p.numel", "stannetflow.synthesizers.nets.SingleTaskNet.parameters", "stannetflow.synthesizers.nets.SingleTaskNet.parameters", "p.numel", "stannetflow.synthesizers.nets.SingleTaskNet.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dim_in", ",", "dim_window", ",", "discrete_columns", "=", "[", "]", ",", "categorical_columns", "=", "{", "}", ",", "\n", "execute_order", "=", "None", ",", "\n", "learning_mode", "=", "'B'", ",", "arch_mode", "=", "'A'", ")", ":", "\n", "        ", "assert", "learning_mode", "in", "[", "'A'", ",", "'B'", "]", ",", "\"Unknown Mask Type\"", "\n", "self", ".", "dim_in", "=", "dim_in", "\n", "self", ".", "dim_window", "=", "dim_window", "\n", "self", ".", "execute_order", "=", "execute_order", "\n", "self", ".", "cur_epoch", "=", "0", "\n", "\n", "#######################################################################", "\n", "# prepare for discrete columns", "\n", "#######################################################################", "\n", "self", ".", "discrete_columns", "=", "discrete_columns", "\n", "self", ".", "categorical_columns_dim", "=", "categorical_columns", "\n", "self", ".", "discrete_belong", "=", "{", "}", "\n", "# self.discrete_dim = {}", "\n", "for", "dis_col", "in", "discrete_columns", ":", "\n", "            ", "for", "sub_dis_col", "in", "dis_col", ":", "\n", "                ", "self", ".", "discrete_belong", "[", "sub_dis_col", "]", "=", "dis_col", "[", "0", "]", "\n", "if", "dis_col", "[", "0", "]", "in", "self", ".", "categorical_columns_dim", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "categorical_columns_dim", "[", "dis_col", "[", "0", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "self", ".", "categorical_columns_dim", "[", "dis_col", "[", "0", "]", "]", "=", "1", "\n", "\n", "", "", "", "self", ".", "cont_agents", "=", "[", "]", "\n", "self", ".", "disc_agents", "=", "[", "]", "\n", "for", "col_i", "in", "range", "(", "self", ".", "dim_in", ")", ":", "\n", "            ", "if", "col_i", "in", "self", ".", "discrete_belong", ".", "keys", "(", ")", ":", "\n", "                ", "if", "self", ".", "discrete_belong", "[", "col_i", "]", "not", "in", "self", ".", "disc_agents", ":", "\n", "                    ", "self", ".", "disc_agents", ".", "append", "(", "self", ".", "discrete_belong", "[", "col_i", "]", ")", "\n", "", "", "elif", "col_i", "in", "self", ".", "categorical_columns_dim", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "disc_agents", ".", "append", "(", "col_i", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "cont_agents", ".", "append", "(", "col_i", ")", "\n", "\n", "#######################################################################", "\n", "# initialize models", "\n", "####################################################################### ", "\n", "# print('initing', self.dim_window, dim_in)", "\n", "", "", "if", "arch_mode", "==", "'A'", ":", "\n", "            ", "encoder_arch", "=", "None", "\n", "gmm_arch", "=", "[", "'gmm'", ",", "2", "]", "\n", "gmm_lr", "=", "0.02", "\n", "dec_arch", "=", "[", "'softmax'", ",", "100", "]", "\n", "dec_lr", "=", "0.02", "\n", "", "else", ":", "\n", "            ", "encoder_arch", "=", "[", "64", ",", "64", ",", "'M'", ",", "128", ",", "128", ",", "'M'", "]", "\n", "gmm_arch", "=", "[", "'gmm'", ",", "10", "]", "\n", "gmm_lr", "=", "0.001", "\n", "dec_arch", "=", "[", "'softmax'", ",", "100", "]", "\n", "dec_lr", "=", "0.01", "\n", "\n", "", "self", ".", "models", "=", "{", "}", "\n", "self", ".", "optimizers", "=", "{", "}", "\n", "self", ".", "schedulers", "=", "{", "}", "\n", "\n", "if", "self", ".", "execute_order", "is", "None", ":", "\n", "            ", "self", ".", "execute_order", "=", "self", ".", "cont_agents", "+", "self", ".", "disc_agents", "\n", "# print(execute_order)", "\n", "# input()", "\n", "", "p_mask", "=", "[", "0", "]", "*", "dim_in", "\n", "for", "col_i", "in", "self", ".", "execute_order", ":", "\n", "            ", "if", "col_i", "in", "self", ".", "cont_agents", ":", "\n", "                ", "mask_mode", "=", "None", "if", "learning_mode", "==", "'A'", "else", "p_mask", "\n", "model_i", "=", "SingleTaskNet", "(", "dim_in", "=", "dim_in", ",", "dim_out", "=", "1", ",", "\n", "dim_window", "=", "dim_window", ",", "mask_mode", "=", "mask_mode", ",", "\n", "encoder_arch", "=", "encoder_arch", ",", "\n", "decoder_arch", "=", "gmm_arch", ",", "model_tag", "=", "col_i", ")", "\n", "\n", "pytorch_total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model_i", ".", "parameters", "(", ")", ")", "\n", "# print(pytorch_total_params)", "\n", "optim_i", "=", "optim", ".", "Adam", "(", "model_i", ".", "parameters", "(", ")", ",", "lr", "=", "gmm_lr", ")", "# 0.005", "\n", "sched_i", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optim_i", ",", "step_size", "=", "10", ",", "gamma", "=", "0.9", ")", "\n", "\n", "self", ".", "models", "[", "col_i", "]", "=", "model_i", "\n", "self", ".", "optimizers", "[", "col_i", "]", "=", "optim_i", "\n", "self", ".", "schedulers", "[", "col_i", "]", "=", "sched_i", "\n", "", "elif", "col_i", "in", "self", ".", "disc_agents", ":", "\n", "                ", "mask_mode", "=", "None", "if", "learning_mode", "==", "'A'", "else", "p_mask", "\n", "model_i", "=", "SingleTaskNet", "(", "dim_in", "=", "dim_in", ",", "dim_out", "=", "self", ".", "categorical_columns_dim", "[", "col_i", "]", ",", "\n", "dim_window", "=", "dim_window", ",", "mask_mode", "=", "mask_mode", ",", "\n", "encoder_arch", "=", "encoder_arch", ",", "\n", "decoder_arch", "=", "dec_arch", ",", "model_tag", "=", "col_i", ")", "\n", "pytorch_total_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model_i", ".", "parameters", "(", ")", ")", "\n", "# print(pytorch_total_params)", "\n", "optim_i", "=", "optim", ".", "Adam", "(", "model_i", ".", "parameters", "(", ")", ",", "lr", "=", "dec_lr", ")", "\n", "sched_i", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optim_i", ",", "step_size", "=", "10", ",", "gamma", "=", "0.9", ")", "\n", "\n", "self", ".", "models", "[", "col_i", "]", "=", "model_i", "\n", "self", ".", "optimizers", "[", "col_i", "]", "=", "optim_i", "\n", "self", ".", "schedulers", "[", "col_i", "]", "=", "sched_i", "\n", "", "else", ":", "\n", "                ", "input", "(", "'init cols error'", ")", "\n", "# add to mask", "\n", "", "if", "col_i", "in", "self", ".", "discrete_belong", ".", "keys", "(", ")", ":", "\n", "                ", "l", "=", "self", ".", "categorical_columns_dim", "[", "col_i", "]", "\n", "# print('l_len', l)", "\n", "for", "j", "in", "range", "(", "col_i", ",", "col_i", "+", "l", ")", ":", "\n", "                    ", "p_mask", "[", "j", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                ", "p_mask", "[", "col_i", "]", "=", "1", "\n", "\n", "# for col_i in self.execute_order:", "\n", "#     print(col_i, self.models[col_i].mask)", "\n", "# input()", "\n", "\n", "", "", "if", "device", ".", "type", "==", "'cuda'", ":", "\n", "            ", "for", "col_i", "in", "sorted", "(", "self", ".", "models", ".", "keys", "(", ")", ")", ":", "\n", "                ", "self", ".", "models", "[", "col_i", "]", ".", "to", "(", "device", ")", "\n", "# and torch.cuda.device_count() > 1:", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._get_variable_i": [[139, 146], ["stan.STANSynthesizer.discrete_belong.keys", "y[].view"], "methods", ["None"], ["", "", "", "def", "_get_variable_i", "(", "self", ",", "y", ",", "col_i", ")", ":", "\n", "        ", "if", "col_i", "in", "self", ".", "discrete_belong", ".", "keys", "(", ")", ":", "\n", "            ", "l", "=", "self", ".", "categorical_columns_dim", "[", "col_i", "]", "\n", "# print('l_len', l)", "\n", "return", "y", "[", ":", ",", "col_i", ":", "col_i", "+", "l", "]", "\n", "", "else", ":", "\n", "            ", "return", "y", "[", ":", ",", "col_i", "]", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._fill_variable_i": [[147, 157], ["stan.STANSynthesizer.discrete_belong.keys", "stan.STANSynthesizer.categorical_columns_dim.keys"], "methods", ["None"], ["", "", "def", "_fill_variable_i", "(", "self", ",", "y", ",", "col_i", ",", "fill", ")", ":", "\n", "        ", "if", "col_i", "in", "self", ".", "discrete_belong", ".", "keys", "(", ")", ":", "\n", "            ", "l", "=", "self", ".", "categorical_columns_dim", "[", "col_i", "]", "\n", "# print('l_len', l)", "\n", "y", "[", "-", "1", ",", "col_i", "+", "fill", "]", "=", "1", "\n", "", "elif", "col_i", "in", "self", ".", "categorical_columns_dim", ".", "keys", "(", ")", ":", "\n", "            ", "y", "[", "-", "1", ",", "col_i", "]", "=", "fill", "/", "self", ".", "categorical_columns_dim", "[", "col_i", "]", "\n", "", "else", ":", "\n", "            ", "y", "[", "-", "1", ",", "col_i", "]", "=", "fill", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.validate_loss": [[158, 186], ["time.time", "enumerate", "time.time", "sorted", "print", "batch_X.view().to", "temp.append", "open", "csv.writer", "csv.writer.writerows", "open", "csv.writer", "csv.writer.writerows", "stan.STANSynthesizer._get_variable_i().to", "model.loss().mean", "print", "stan.STANSynthesizer.models[].get_batch_loss", "batch_X.view", "stan.STANSynthesizer._get_variable_i", "model.loss", "sorted", "stan.STANSynthesizer.models.keys"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.get_batch_loss", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._get_variable_i", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.loss"], ["", "def", "validate_loss", "(", "self", ",", "train_loader", ",", "loaded_ep", "=", "0", ",", "new_file", "=", "False", ")", ":", "\n", "        ", "self", ".", "loss_file", "=", "'validation_loss.csv'", "\n", "if", "new_file", ":", "\n", "            ", "with", "open", "(", "self", ".", "loss_file", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerows", "(", "[", "[", "'epoch'", ",", "'time'", "]", "+", "sorted", "(", "self", ".", "models", ".", "keys", "(", ")", ")", "]", ")", "\n", "\n", "", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "minibatch", "=", "batch_X", ".", "view", "(", "-", "1", ",", "self", ".", "dim_window", "+", "1", ",", "self", ".", "dim_in", ")", ".", "to", "(", "device", ")", "\n", "for", "col_i", "in", "self", ".", "execute_order", ":", "\n", "# print('training', col_i)", "\n", "                ", "model", "=", "self", ".", "models", "[", "col_i", "]", "\n", "y_", "=", "self", ".", "_get_variable_i", "(", "batch_y", ",", "col_i", ")", ".", "to", "(", "device", ")", "\n", "loss", "=", "model", ".", "loss", "(", "minibatch", ",", "y_", ",", "bin_type", "=", "True", ")", ".", "mean", "(", ")", "\n", "# print(col_i, loss)", "\n", "", "if", "step", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "'batch steps:'", ",", "step", ")", "\n", "\n", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "temp", "=", "[", "loaded_ep", ",", "end_time", "-", "start_time", "]", "\n", "for", "col_i", "in", "sorted", "(", "self", ".", "execute_order", ")", ":", "\n", "            ", "temp", ".", "append", "(", "self", ".", "models", "[", "col_i", "]", ".", "get_batch_loss", "(", ")", ")", "\n", "\n", "", "print", "(", "temp", ")", "\n", "with", "open", "(", "self", ".", "loss_file", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerows", "(", "[", "temp", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.batch_fit": [[187, 221], ["range", "open", "csv.writer", "csv.writer.writerows", "time.time", "enumerate", "time.time", "sorted", "batch_X.view().to", "scheduler.step", "temp.append", "stan.STANSynthesizer._save_model", "stan.STANSynthesizer.models[].batch_reset", "open", "csv.writer", "csv.writer.writerows", "stan.STANSynthesizer._get_variable_i().to", "optimizer.zero_grad", "model.loss().mean", "model.loss().mean.backward", "optimizer.step", "stan.STANSynthesizer.models[].get_batch_loss", "sorted", "batch_X.view", "stan.STANSynthesizer.models.keys", "stan.STANSynthesizer._get_variable_i", "model.loss"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._save_model", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.batch_reset", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.SingleTaskNet.get_batch_loss", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._get_variable_i", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.loss"], ["", "", "def", "batch_fit", "(", "self", ",", "train_loader", ",", "epochs", "=", "1000", ")", ":", "\n", "        ", "self", ".", "loss_file", "=", "'train_loss.csv'", "\n", "with", "open", "(", "self", ".", "loss_file", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerows", "(", "[", "[", "'epoch'", ",", "'time'", "]", "+", "sorted", "(", "self", ".", "models", ".", "keys", "(", ")", ")", "]", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "                ", "minibatch", "=", "batch_X", ".", "view", "(", "-", "1", ",", "self", ".", "dim_window", "+", "1", ",", "self", ".", "dim_in", ")", ".", "to", "(", "device", ")", "\n", "for", "col_i", "in", "self", ".", "execute_order", ":", "\n", "# print('training', col_i)", "\n", "                    ", "model", "=", "self", ".", "models", "[", "col_i", "]", "\n", "optimizer", "=", "self", ".", "optimizers", "[", "col_i", "]", "\n", "y_", "=", "self", ".", "_get_variable_i", "(", "batch_y", ",", "col_i", ")", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "model", ".", "loss", "(", "minibatch", ",", "y_", ",", "bin_type", "=", "True", ")", ".", "mean", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# print(col_i, loss)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "temp", "=", "[", "epoch", ",", "end_time", "-", "start_time", "]", "\n", "for", "col_i", "in", "sorted", "(", "self", ".", "execute_order", ")", ":", "\n", "                ", "scheduler", "=", "self", ".", "schedulers", "[", "col_i", "]", "\n", "scheduler", ".", "step", "(", ")", "\n", "temp", ".", "append", "(", "self", ".", "models", "[", "col_i", "]", ".", "get_batch_loss", "(", ")", ")", "\n", "self", ".", "_save_model", "(", "col_i", ",", "epoch", ",", "self", ".", "models", "[", "col_i", "]", ")", "\n", "self", ".", "models", "[", "col_i", "]", ".", "batch_reset", "(", ")", "\n", "# print(temp)", "\n", "", "with", "open", "(", "self", ".", "loss_file", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerows", "(", "[", "temp", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.fit": [[222, 233], ["range", "y[].view", "range", "optimizer.zero_grad", "model.loss().mean", "model.loss().mean.backward", "optimizer.step", "model.loss"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.nets.MixtureDensityNetwork.loss"], ["", "", "", "def", "fit", "(", "self", ",", "X", ",", "y", ",", "epochs", "=", "100", ")", ":", "\n", "# X = torch.unsqueeze(X, 0)", "\n", "        ", "for", "col_i", "in", "range", "(", "self", ".", "dim_in", ")", ":", "\n", "            ", "model", "=", "self", ".", "models", "[", "col_i", "]", "\n", "optimizer", "=", "self", ".", "optimizers", "[", "col_i", "]", "\n", "y_", "=", "y", "[", ":", ",", "col_i", "]", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "epochs", ")", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "model", ".", "loss", "(", "X", ",", "y_", ")", ".", "mean", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "# if i % 100 == 0:", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.sample": [[236, 259], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "pandas.DataFrame", "torch.cat().view.append", "torch.cat().view.append", "torch.cat().view.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().view.numpy", "torch.cat().view.numpy", "torch.cat().view.numpy", "model_i.sample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample"], ["", "", "", "def", "sample", "(", "self", ",", "sample_num", ")", ":", "\n", "        ", "p_samp", "=", "torch", ".", "zeros", "(", "(", "(", "self", ".", "dim_window", "+", "1", ")", ",", "self", ".", "dim_in", ")", ")", "\n", "\n", "gen_buff", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "sample_num", ")", ":", "\n", "# print('input x_i', p_samp.size(), p_samp)", "\n", "            ", "j", "=", "0", "\n", "for", "col_i", "in", "self", ".", "execute_order", ":", "\n", "                ", "model_i", "=", "self", ".", "models", "[", "col_i", "]", "\n", "sample_i", ",", "normal_i", "=", "model_i", ".", "sample", "(", "p_samp", ")", "\n", "fill_position", "=", "self", ".", "dim_window", "*", "self", ".", "dim_in", "+", "col_i", "\n", "\n", "p_samp", "[", "-", "1", ",", "col_i", "]", "=", "sample_i", "\n", "\n", "\n", "", "gen_buff", ".", "append", "(", "p_samp", "[", "-", "1", ",", ":", "]", ")", "\n", "\n", "p_samp", "=", "torch", ".", "cat", "(", "(", "p_samp", "[", "1", ":", ",", ":", "]", ",", "torch", ".", "zeros", "(", "1", ",", "self", ".", "dim_in", ")", ")", ",", "0", ")", "\n", "\n", "", "gen_buff", "=", "torch", ".", "cat", "(", "gen_buff", ",", "0", ")", ".", "view", "(", "-", "1", ",", "self", ".", "dim_in", ")", "\n", "\n", "\n", "return", "pd", ".", "DataFrame", "(", "gen_buff", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.time_series_sample": [[260, 300], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "pandas.DataFrame", "torch.cat().view.append", "torch.cat().view.append", "torch.cat().view.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().view.cpu().numpy", "torch.cat().view.cpu().numpy", "torch.cat().view.cpu().numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model_i.sample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_i.sample", "stan.STANSynthesizer._fill_variable_i", "stan.STANSynthesizer._fill_variable_i", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.cat().view.cpu", "torch.cat().view.cpu", "torch.cat().view.cpu", "int", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._fill_variable_i", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._fill_variable_i"], ["", "def", "time_series_sample", "(", "self", ",", "time_limit", ")", ":", "\n", "        ", "tot_time", "=", "0", "\n", "row_num", "=", "0", "\n", "generated_rows", "=", "[", "]", "\n", "\n", "p_samp", "=", "torch", ".", "zeros", "(", "(", "self", ".", "dim_window", "+", "1", ")", ",", "self", ".", "dim_in", ")", ".", "to", "(", "device", ")", "\n", "\n", "gen_buff", "=", "[", "]", "\n", "while", "tot_time", "<", "time_limit", ":", "\n", "            ", "outputs", "=", "[", "]", "\n", "j", "=", "0", "\n", "for", "col_i", "in", "self", ".", "execute_order", ":", "\n", "                ", "model_i", "=", "self", ".", "models", "[", "col_i", "]", "\n", "# print(p_samp.shape)", "\n", "sample_i", ",", "normal_i", "=", "model_i", ".", "sample", "(", "p_samp", ")", "\n", "tiktok", "=", "0", "\n", "while", "col_i", "in", "self", ".", "cont_agents", "and", "(", "sample_i", "<", "0", "or", "sample_i", ">", "1", ")", ":", "\n", "# print('!!!!', tot_time, col_i, sample_i)", "\n", "                    ", "if", "tiktok", ">", "10", ":", "\n", "                        ", "sample_i", "=", "0", "\n", "break", "\n", "", "tiktok", "+=", "1", "\n", "sample_i", ",", "normal_i", "=", "model_i", ".", "sample", "(", "p_samp", ")", "\n", "# print(p_samp[-1, :],'==>', sample_i)", "\n", "\n", "", "if", "col_i", "==", "0", ":", "\n", "                    ", "self", ".", "_fill_variable_i", "(", "p_samp", ",", "col_i", ",", "int", "(", "tot_time", "/", "3600", ")", "/", "24.0", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_fill_variable_i", "(", "p_samp", ",", "col_i", ",", "sample_i", ")", "\n", "if", "col_i", "==", "1", ":", "\n", "                        ", "tot_time", "+=", "int", "(", "sample_i", "*", "1430", ")", "\n", "\n", "", "", "", "gen_buff", ".", "append", "(", "p_samp", "[", "-", "1", ",", ":", "]", ")", "\n", "# print('whole row', tot_time, 'at', p_samp[-1, :])", "\n", "# input()", "\n", "\n", "p_samp", "=", "torch", ".", "cat", "(", "(", "p_samp", "[", "1", ":", ",", ":", "]", ",", "torch", ".", "zeros", "(", "1", ",", "self", ".", "dim_in", ")", ".", "to", "(", "device", ")", ")", ",", "0", ")", "\n", "", "gen_buff", "=", "torch", ".", "cat", "(", "gen_buff", ",", "0", ")", ".", "view", "(", "-", "1", ",", "self", ".", "dim_in", ")", "\n", "\n", "return", "pd", ".", "DataFrame", "(", "gen_buff", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._save_model": [[301, 308], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "model.state_dict"], "methods", ["None"], ["", "def", "_save_model", "(", "self", ",", "name", ",", "epoch", ",", "model", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./saved_model'", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "'./saved_model'", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'./saved_model/model_%d'", "%", "name", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "'./saved_model/model_%d'", "%", "name", ")", "\n", "", "checkpoint", "=", "'./saved_model/model_%d'", "%", "name", "+", "'/ep%d.pkl'", "%", "epoch", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._cpu_loading": [[309, 316], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "collections.OrderedDict", "torch.load.items", "torch.load.items", "torch.load.items", "model.load_state_dict"], "methods", ["None"], ["", "def", "_cpu_loading", "(", "self", ",", "model", ",", "checkpoint", ")", ":", "\n", "        ", "state_dict", "=", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "device", ")", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "name", "=", "k", "[", "7", ":", "]", "# remove module.", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._load_model": [[317, 325], ["model.load_state_dict", "stan.STANSynthesizer._cpu_loading", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._cpu_loading"], ["", "def", "_load_model", "(", "self", ",", "name", ",", "epoch", ",", "model", ")", ":", "\n", "        ", "checkpoint", "=", "'./saved_model/model_%d'", "%", "name", "+", "'/%s.pkl'", "%", "epoch", "\n", "#model.load_state_dict(torch.load(checkpoint))", "\n", "# print(name, model, epoch)", "\n", "if", "device", ".", "type", "==", "'cuda'", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_cpu_loading", "(", "model", ",", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer.load_model": [[326, 334], ["isinstance", "stan.STANSynthesizer._load_model", "stan.STANSynthesizer._load_model"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._load_model", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANSynthesizer._load_model"], ["", "", "def", "load_model", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "if", "isinstance", "(", "epoch", ",", "dict", ")", ":", "\n", "            ", "for", "col_i", "in", "self", ".", "execute_order", ":", "\n", "# print('loading', col_i, 'with checkpoint', epoch[col_i])", "\n", "                ", "self", ".", "_load_model", "(", "col_i", ",", "epoch", "[", "col_i", "]", ",", "self", ".", "models", "[", "col_i", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "col_i", "in", "self", ".", "execute_order", ":", "\n", "                ", "self", ".", "_load_model", "(", "col_i", ",", "epoch", ",", "self", ".", "models", "[", "col_i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANCustomDataset.__init__": [[336, 347], ["pandas.read_csv"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "csv_path", ",", "height", ",", "width", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            csv_path (string): path to csv file\n            height (int): image height\n            width (int): image width\n            transform: pytorch transforms for transforms and tensor conversion\n        \"\"\"", "\n", "self", ".", "data", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "width", "=", "width", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANCustomDataset.__getitem__": [[348, 353], ["torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.asarray().reshape().astype", "numpy.asarray().reshape().astype", "numpy.asarray().reshape", "numpy.asarray().reshape", "numpy.asarray", "numpy.asarray"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "single_image_label", "=", "np", ".", "asarray", "(", "self", ".", "data", ".", "iloc", "[", "index", "]", ")", ".", "reshape", "(", "self", ".", "height", "+", "1", ",", "self", ".", "width", ")", ".", "astype", "(", "np", ".", "float32", ")", "[", "-", "1", "]", "\n", "img_as_np", "=", "np", ".", "asarray", "(", "self", ".", "data", ".", "iloc", "[", "index", "]", ")", ".", "reshape", "(", "self", ".", "height", "+", "1", ",", "self", ".", "width", ")", ".", "astype", "(", "np", ".", "float32", ")", "[", ":", "-", "1", "]", "\n", "img_as_tensor", "=", "torch", ".", "from_numpy", "(", "img_as_np", ")", "\n", "return", "(", "img_as_tensor", ",", "single_image_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANCustomDataset.__len__": [[354, 356], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANCustomDataLoader.__init__": [[358, 369], ["stan.STANCustomDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "csv_path", ",", "height", ",", "width", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            csv_path (string): path to csv file\n            height (int): image height\n            width (int): image width\n            transform: pytorch transforms for transforms and tensor conversion\n        \"\"\"", "\n", "self", ".", "dataset", "=", "STANCustomDataset", "(", "csv_path", ",", "height", ",", "width", ")", "\n", "self", ".", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "self", ".", "dataset", ",", "batch_size", "=", "512", ",", "shuffle", "=", "True", ",", "num_workers", "=", "16", ",", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANCustomDataLoader.get_loader": [[370, 372], ["None"], "methods", ["None"], ["", "def", "get_loader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.__init__": [[374, 376], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer._map_ip_str_to_int_list": [[377, 388], ["ip_str.split", "list", "range", "reversed", "label_rt.append", "len", "rt.append", "range", "int", "len"], "methods", ["None"], ["", "def", "_map_ip_str_to_int_list", "(", "self", ",", "ip_str", ",", "ipspace", "=", "None", ")", ":", "\n", "        ", "ip_group", "=", "ip_str", ".", "split", "(", "'.'", ")", "\n", "label_rt", "=", "[", "]", "\n", "rt", "=", "[", "]", "\n", "pw", "=", "1", "\n", "# print(ip_str)", "\n", "for", "i", "in", "list", "(", "reversed", "(", "range", "(", "len", "(", "ip_group", ")", ")", ")", ")", ":", "\n", "            ", "label_rt", ".", "append", "(", "int", "(", "ip_group", "[", "i", "]", ")", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "label_rt", ")", ")", ":", "\n", "            ", "rt", ".", "append", "(", "label_rt", "[", "i", "]", "/", "ipspace", ")", "\n", "", "return", "rt", ",", "label_rt", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer._port_number_interpreter": [[389, 396], ["stan.NetflowFormatTransformer._port_number_interpreter.get_category"], "methods", ["None"], ["", "def", "_port_number_interpreter", "(", "self", ",", "port_num", ",", "portspace", "=", "None", ")", ":", "\n", "        ", "rt", "=", "[", "port_num", "/", "portspace", "]", "\n", "\n", "def", "get_category", "(", "x", ")", ":", "\n", "            ", "return", "(", "x", "-", "1024", ")", "//", "100", "+", "1024", "if", "x", ">=", "1024", "else", "x", "\n", "", "label_rt", "=", "[", "get_category", "(", "port_num", ")", "]", "\n", "return", "rt", ",", "label_rt", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.rev_port": [[397, 404], ["int", "numpy.random.randint"], "methods", ["None"], ["", "def", "rev_port", "(", "self", ",", "emb", ")", ":", "\n", "        ", "pred_num", "=", "int", "(", "emb", "*", "1670", ")", "\n", "interv", "=", "(", "pred_num", "-", "1024", ")", "*", "100", "+", "1024", "\n", "decode_port", "=", "pred_num", "if", "pred_num", "<", "1024", "else", "np", ".", "random", ".", "randint", "(", "interv", ",", "interv", "+", "100", ")", "\n", "if", "decode_port", ">", "65535", ":", "\n", "            ", "decode_port", "=", "65535", "\n", "", "return", "decode_port", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.rev_transfer": [[405, 448], ["numpy.exp", "numpy.exp", "df.iterrows", "pandas.DataFrame", "random.choice", "buffer.append", "int", "int", "int", "line.append", "line.append", "line.append", "line.append", "line.append", "line.append", "line.append", "line.append", "line.append", "stan.NetflowFormatTransformer.rev_port", "stan.NetflowFormatTransformer.rev_port", "stan.NetflowFormatTransformer.rev_port", "stan.NetflowFormatTransformer.rev_port", "line.append", "line.append", "str", "str", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.rev_port", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.rev_port", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.rev_port", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.rev_port"], ["", "def", "rev_transfer", "(", "self", ",", "df", ",", "this_ip", "=", "None", ")", ":", "\n", "        ", "bytmax", "=", "20.12915933105231", "# df['log_byt'].max()", "\n", "pktmax", "=", "12.83", "\n", "tdmax", "=", "363", "\n", "teTmax", "=", "23", "# df['teT'].max()", "\n", "teDeltamax", "=", "1336", "# df['teDelta'].max()", "\n", "ipspace", "=", "255", "\n", "portspace", "=", "65535", "\n", "td_max", "=", "1430", "\n", "b_max", "=", "20.12915933105231", "\n", "if", "this_ip", "is", "None", ":", "\n", "            ", "this_ip", "=", "random", ".", "choice", "(", "[", "'42.219.153.159'", ",", "'42.219.153.16'", ",", "'42.219.153.165'", ",", "'42.219.153.170'", ",", "'42.219.153.174'", ",", "'42.219.153.179'", ",", "'42.219.153.187'", ",", "'42.219.153.190'", ",", "'42.219.153.193'", ",", "'42.219.153.198'", ",", "'42.219.153.210'", ",", "'42.219.153.214'", ",", "'42.219.153.216'", ",", "'42.219.153.220'", ",", "'42.219.153.221'", ",", "'42.219.153.23'", ",", "'42.219.153.238'", ",", "'42.219.153.241'", ",", "'42.219.153.246'", ",", "'42.219.153.250'", ",", "'42.219.153.35'", ",", "'42.219.153.36'", ",", "'42.219.153.45'", ",", "'42.219.153.47'", ",", "'42.219.153.5'", ",", "'42.219.153.53'", ",", "'42.219.153.59'", ",", "'42.219.153.60'", ",", "'42.219.153.71'", ",", "'42.219.153.75'", ",", "'42.219.153.80'", ",", "'42.219.153.81'", ",", "'42.219.153.82'", ",", "'42.219.153.83'", ",", "'42.219.153.9'", ",", "'42.219.154.124'", ",", "'42.219.154.134'", ",", "'42.219.154.145'", ",", "'42.219.154.152'", ",", "'42.219.154.155'", ",", "'42.219.154.18'", ",", "'42.219.154.181'", ",", "'42.219.154.184'", ",", "'42.219.154.185'", ",", "'42.219.154.189'", ",", "'42.219.154.191'", ",", "'42.219.155.115'", ",", "'42.219.155.123'", ",", "'42.219.155.128'", ",", "'42.219.155.132'", ",", "'42.219.155.19'", ",", "'42.219.155.25'", ",", "'42.219.155.27'", ",", "'42.219.155.30'", ",", "'42.219.155.68'", ",", "'42.219.155.69'", ",", "'42.219.155.72'", ",", "'42.219.155.86'", ",", "'42.219.155.87'", ",", "'42.219.155.89'", ",", "'42.219.155.91'", ",", "'42.219.156.188'", ",", "'42.219.156.190'", ",", "'42.219.156.194'", ",", "'42.219.156.227'", ",", "'42.219.156.237'", ",", "'42.219.156.240'", ",", "'42.219.157.13'", ",", "'42.219.157.220'", ",", "'42.219.157.246'", ",", "'42.219.157.28'", ",", "'42.219.158.162'", ",", "'42.219.158.163'", ",", "'42.219.158.169'", ",", "'42.219.158.205'", ",", "'42.219.158.209'", ",", "'42.219.158.211'", ",", "'42.219.158.217'", ",", "'42.219.158.223'", ",", "'42.219.158.224'", "]", ")", "\n", "\n", "# print(df.head()) ", "\n", "", "df", "[", "'raw_scale_byt'", "]", "=", "np", ".", "exp", "(", "df", "[", "2", "]", "*", "b_max", ")", "\n", "df", "[", "'raw_scale_pkt'", "]", "=", "np", ".", "exp", "(", "df", "[", "3", "]", "*", "pktmax", ")", "\n", "\n", "buffer", "=", "[", "]", "\n", "for", "index", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "            ", "line", "=", "[", "int", "(", "row", "[", "0", "]", "*", "24", ")", ",", "row", "[", "1", "]", "*", "td_max", ",", "int", "(", "row", "[", "'raw_scale_byt'", "]", ")", ",", "int", "(", "row", "[", "'raw_scale_pkt'", "]", ")", ",", "row", "[", "4", "]", "*", "tdmax", "]", "\n", "# line = [int(row[0]*24), row[1]*td_max, int(row['raw_scale_byt']*b_max), int(row['raw_scale_pkt']*pktmax), row[4]*tdmax]", "\n", "if", "row", "[", "11", "]", "==", "1", ":", "\n", "                ", "line", ".", "append", "(", "self", ".", "rev_port", "(", "row", "[", "5", "]", ")", ")", "# sp", "\n", "line", ".", "append", "(", "self", ".", "rev_port", "(", "row", "[", "6", "]", ")", ")", "# dp", "\n", "line", ".", "append", "(", "this_ip", ")", "#sa", "\n", "line", ".", "append", "(", "'.'", ".", "join", "(", "[", "str", "(", "int", "(", "da_i", "*", "256", ")", ")", "for", "da_i", "in", "row", "[", "7", ":", "7", "+", "4", "]", "]", ")", ")", "#da", "\n", "", "else", ":", "\n", "                ", "line", ".", "append", "(", "self", ".", "rev_port", "(", "row", "[", "6", "]", ")", ")", "# dp", "\n", "line", ".", "append", "(", "self", ".", "rev_port", "(", "row", "[", "5", "]", ")", ")", "# sp", "\n", "line", ".", "append", "(", "'.'", ".", "join", "(", "[", "str", "(", "int", "(", "da_i", "*", "256", ")", ")", "for", "da_i", "in", "row", "[", "7", ":", "7", "+", "4", "]", "]", ")", ")", "#da", "\n", "line", ".", "append", "(", "this_ip", ")", "#sa", "\n", "", "prt", "=", "[", "'TCP'", ",", "'UDP'", ",", "'Other'", "]", "\n", "if", "row", "[", "13", "]", "==", "1", ":", "\n", "                ", "line", ".", "append", "(", "prt", "[", "0", "]", ")", "\n", "", "elif", "row", "[", "14", "]", "==", "1", ":", "\n", "                ", "line", ".", "append", "(", "prt", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "line", ".", "append", "(", "prt", "[", "2", "]", ")", "\n", "", "buffer", ".", "append", "(", "line", ")", "\n", "", "out_df", "=", "pd", ".", "DataFrame", "(", "buffer", ")", "\n", "out_df", ".", "columns", "=", "[", "'hour'", ",", "'time_delta'", ",", "'byt'", ",", "'pkt'", ",", "'time_duration'", ",", "'sp'", ",", "'dp'", ",", "'sa'", ",", "'da'", ",", "'pr'", "]", "\n", "\n", "return", "out_df", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.transfer": [[449, 509], ["numpy.log", "numpy.log", "pandas.DataFrame.iterrows", "pandas.DataFrame", "stan.NetflowFormatTransformer._map_ip_str_to_int_list", "stan.NetflowFormatTransformer._map_ip_str_to_int_list", "stan.NetflowFormatTransformer._port_number_interpreter", "stan.NetflowFormatTransformer._port_number_interpreter", "buffer.append"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer._map_ip_str_to_int_list", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer._map_ip_str_to_int_list", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer._port_number_interpreter", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer._port_number_interpreter"], ["", "def", "transfer", "(", "self", ",", "df", ")", ":", "\n", "        ", "df", "[", "'log_byt'", "]", "=", "np", ".", "log", "(", "df", "[", "'byt'", "]", ")", "\n", "df", "[", "'log_pkt'", "]", "=", "np", ".", "log", "(", "df", "[", "'pkt'", "]", ")", "\n", "bytmax", "=", "20.12915933105231", "# df['log_byt'].max()", "\n", "pktmax", "=", "12.83", "\n", "tdmax", "=", "363", "\n", "teTmax", "=", "23", "# df['teT'].max()", "\n", "teDeltamax", "=", "1336", "# df['teDelta'].max()", "\n", "ipspace", "=", "255", "\n", "portspace", "=", "65535", "\n", "td_max", "=", "1430", "\n", "b_max", "=", "20.12915933105231", "\n", "this_ip", "=", "df", ".", "iloc", "[", "0", "]", "[", "'this_ip'", "]", "\n", "\n", "buffer", "=", "[", "]", "\n", "for", "index", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "# each row: teT, delta_t, byt, in/out, tcp/udp/other, sa*4, da*4, sp_sig/sp_sys/sp_other, dp*3 ", "\n", "            ", "line", "=", "[", "row", "[", "'teT'", "]", "/", "teTmax", ",", "row", "[", "'teDelta'", "]", "/", "td_max", ",", "row", "[", "'log_byt'", "]", "/", "b_max", ",", "row", "[", "'log_pkt'", "]", "/", "pktmax", ",", "row", "[", "'td'", "]", "/", "tdmax", "]", "\n", "label_line", "=", "[", "row", "[", "'teT'", "]", "/", "teTmax", ",", "row", "[", "'teDelta'", "]", "/", "td_max", ",", "row", "[", "'log_byt'", "]", "/", "b_max", ",", "row", "[", "'log_pkt'", "]", "/", "pktmax", ",", "row", "[", "'td'", "]", "/", "tdmax", "]", "\n", "# line = [row['teT']/teTmax, row['log_byt']/bytmax]", "\n", "# [out, in]", "\n", "sip_list", ",", "label_sip_list", "=", "self", ".", "_map_ip_str_to_int_list", "(", "row", "[", "'sa'", "]", ",", "ipspace", ")", "\n", "dip_list", ",", "label_dip_list", "=", "self", ".", "_map_ip_str_to_int_list", "(", "row", "[", "'da'", "]", ",", "ipspace", ")", "\n", "\n", "spo_list", ",", "label_spo_list", "=", "self", ".", "_port_number_interpreter", "(", "row", "[", "'sp'", "]", ",", "portspace", ")", "\n", "dpo_list", ",", "label_dpo_list", "=", "self", ".", "_port_number_interpreter", "(", "row", "[", "'dp'", "]", ",", "portspace", ")", "\n", "\n", "if", "row", "[", "'sa'", "]", "==", "this_ip", ":", "\n", "#line += sip_list + dip_list", "\n", "                ", "line", "+=", "spo_list", "\n", "line", "+=", "dpo_list", "+", "dip_list", "\n", "line", "+=", "[", "1", ",", "0", "]", "\n", "\n", "label_line", "+=", "label_spo_list", "\n", "label_line", "+=", "label_dpo_list", "+", "label_dip_list", "\n", "label_line", "+=", "[", "1", ",", "0", "]", "\n", "", "else", ":", "\n", "                ", "line", "+=", "dpo_list", "\n", "line", "+=", "spo_list", "+", "sip_list", "\n", "line", "+=", "[", "0", ",", "1", "]", "\n", "\n", "label_line", "+=", "label_dpo_list", "\n", "label_line", "+=", "label_spo_list", "+", "label_sip_list", "\n", "label_line", "+=", "[", "0", ",", "1", "]", "\n", "\n", "", "line_pr", "=", "[", "]", "\n", "if", "row", "[", "'pr'", "]", "==", "'TCP'", ":", "\n", "                ", "line_pr", "=", "[", "1", ",", "0", ",", "0", "]", "\n", "", "elif", "row", "[", "'pr'", "]", "==", "'UDP'", ":", "\n", "                ", "line_pr", "=", "[", "0", ",", "1", ",", "0", "]", "\n", "", "else", ":", "\n", "                ", "line_pr", "=", "[", "0", ",", "0", ",", "1", "]", "\n", "", "line", "+=", "line_pr", "\n", "label_line", "+=", "line_pr", "\n", "\n", "buffer", ".", "append", "(", "line", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "buffer", ")", "\n", "# print(df)", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer.__init__": [[511, 517], ["open", "open.close"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "output_file", ",", "special_data", "=", "None", ")", ":", "\n", "        ", "self", ".", "output_file", "=", "output_file", "\n", "self", ".", "special_data", "=", "special_data", "\n", "self", ".", "X", ",", "self", ".", "y", "=", "None", ",", "None", "\n", "f", "=", "open", "(", "output_file", ",", "\"w+\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer.push_back": [[518, 525], ["transformer.transfer.dropna", "stan.STANTemporalTransformer.agg", "X.to_csv", "transformer.transfer"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.agg", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.NetflowFormatTransformer.transfer"], ["", "def", "push_back", "(", "self", ",", "df", ",", "agg", "=", "1", ",", "transformer", "=", "None", ")", ":", "\n", "        ", "df", "=", "df", ".", "dropna", "(", ")", "\n", "if", "transformer", ":", "\n", "            ", "df", "=", "transformer", ".", "transfer", "(", "df", ")", "\n", "\n", "", "X", ",", "y", "=", "self", ".", "agg", "(", "df", ",", "agg", "=", "agg", ")", "\n", "X", ".", "to_csv", "(", "self", ".", "output_file", ",", "mode", "=", "'a'", ",", "header", "=", "False", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer.agg": [[527, 531], ["stan.STANTemporalTransformer._agg_window"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator._agg_window"], ["", "def", "agg", "(", "self", ",", "df", ",", "agg", "=", "None", ")", ":", "\n", "        ", "if", "agg", ":", "\n", "            ", "self", ".", "X", ",", "self", ".", "y", "=", "self", ".", "_agg_window", "(", "df", ",", "agg", ")", "\n", "", "return", "self", ".", "X", ",", "self", ".", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer._get_category": [[532, 534], ["None"], "methods", ["None"], ["", "def", "_get_category", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "(", "x", "-", "1024", ")", "//", "100", "+", "1024", "if", "x", ">=", "1024", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer._ugr16_label": [[535, 544], ["row_list.copy", "stan.STANTemporalTransformer._get_category", "stan.STANTemporalTransformer._get_category", "min", "min", "min", "min", "numpy.rint", "numpy.rint", "numpy.rint", "numpy.rint", "numpy.rint", "numpy.rint"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer._get_category", "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer._get_category"], ["", "def", "_ugr16_label", "(", "self", ",", "row_list", ")", ":", "\n", "        ", "new_list", "=", "row_list", ".", "copy", "(", ")", "\n", "new_list", "[", "5", "]", "=", "self", ".", "_get_category", "(", "np", ".", "rint", "(", "new_list", "[", "5", "]", "*", "65536", ")", ")", "\n", "new_list", "[", "6", "]", "=", "self", ".", "_get_category", "(", "np", ".", "rint", "(", "new_list", "[", "6", "]", "*", "65536", ")", ")", "\n", "new_list", "[", "7", "]", "=", "min", "(", "np", ".", "rint", "(", "new_list", "[", "7", "]", "*", "255", ")", ",", "255", ")", "\n", "new_list", "[", "8", "]", "=", "min", "(", "np", ".", "rint", "(", "new_list", "[", "8", "]", "*", "255", ")", ",", "255", ")", "\n", "new_list", "[", "9", "]", "=", "min", "(", "np", ".", "rint", "(", "new_list", "[", "9", "]", "*", "255", ")", ",", "255", ")", "\n", "new_list", "[", "10", "]", "=", "min", "(", "np", ".", "rint", "(", "new_list", "[", "10", "]", "*", "255", ")", ",", "255", ")", "\n", "return", "new_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer._agg_window": [[545, 564], ["len", "df_naive.values.tolist", "pandas.DataFrame", "pandas.DataFrame", "buffer.append", "stan.STANTemporalTransformer._ugr16_label", "pandas.DataFrame.append", "pandas.DataFrame.append"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.synthesizers.stan.STANTemporalTransformer._ugr16_label"], ["", "def", "_agg_window", "(", "self", ",", "df_naive", ",", "agg_size", ")", ":", "\n", "        ", "col_num", "=", "len", "(", "df_naive", ".", "columns", ")", "\n", "buffer", "=", "[", "[", "0", "]", "*", "col_num", "]", "*", "agg_size", "\n", "X", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "\n", "list_naive", "=", "df_naive", ".", "values", ".", "tolist", "(", ")", "\n", "for", "row", "in", "list_naive", ":", "\n", "            ", "buffer", ".", "append", "(", "row", ")", "\n", "row_with_window", "=", "[", "]", "\n", "for", "r", "in", "buffer", "[", "-", "agg_size", "-", "1", ":", "]", ":", "\n", "                ", "row_with_window", "+=", "r", "\n", "", "ugr16_label_row", "=", "self", ".", "_ugr16_label", "(", "row", ")", "\n", "\n", "X", ".", "append", "(", "row_with_window", "+", "ugr16_label_row", ")", "\n", "y", ".", "append", "(", "row", ")", "\n", "\n", "", "X", "=", "pd", ".", "DataFrame", "(", "X", ")", "\n", "y", "=", "pd", ".", "DataFrame", "(", "y", ")", "\n", "return", "X", ",", "y", "", "", "", ""]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.load_folder": [[10, 24], ["glob.glob", "glob.glob", "print", "pandas.read_csv", "pandas.read_csv", "pandas.concat", "pd.concat.max", "pandas.concat"], "function", ["None"], ["def", "load_folder", "(", ")", ":", "\n", "    ", "col", "=", "'td'", "\n", "cache", "=", "None", "\n", "for", "f", "in", "glob", ".", "glob", "(", "'train_set/*.csv'", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "f", ")", "\n", "if", "cache", "is", "None", ":", "\n", "            ", "cache", "=", "df", "[", "col", "]", "\n", "", "else", ":", "\n", "            ", "cache", "=", "pd", ".", "concat", "(", "[", "cache", ",", "df", "[", "col", "]", "]", ",", "ignore_index", "=", "True", ")", "\n", "", "", "for", "f", "in", "glob", ".", "glob", "(", "'test_set/*.csv'", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "f", ")", "\n", "cache", "=", "pd", ".", "concat", "(", "[", "cache", ",", "df", "[", "col", "]", "]", ",", "ignore_index", "=", "True", ")", "\n", "#cache = cache.apply(lambda x: np.log(x))", "\n", "", "print", "(", "cache", ".", "max", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.plot_distribution": [[25, 28], ["cache.hist().get_figure", "cache.hist().get_figure.savefig", "cache.hist"], "function", ["None"], ["", "def", "plot_distribution", "(", ")", ":", "\n", "    ", "d", "=", "cache", ".", "hist", "(", ")", ".", "get_figure", "(", ")", "\n", "d", ".", "savefig", "(", "'2%s.jpg'", "%", "col", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.pr_mod": [[29, 36], ["None"], "function", ["None"], ["", "def", "pr_mod", "(", "x", ")", ":", "\n", "    ", "if", "x", "==", "'TCP'", ":", "\n", "        ", "return", "0", "\n", "", "elif", "x", "==", "'UDP'", ":", "\n", "        ", "return", "1", "\n", "", "else", ":", "\n", "        ", "return", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.scale_process": [[37, 46], ["df[].apply", "df[].apply", "df[].apply", "numpy.log", "numpy.log"], "function", ["None"], ["", "", "def", "scale_process", "(", "df", ")", ":", "\n", "    ", "df", "[", "'byt'", "]", "=", "df", "[", "'byt'", "]", ".", "apply", "(", "lambda", "x", ":", "np", ".", "log", "(", "x", "+", "1", ")", ")", "\n", "df", "[", "'pkt'", "]", "=", "df", "[", "'pkt'", "]", ".", "apply", "(", "lambda", "x", ":", "np", ".", "log", "(", "x", "+", "1", ")", ")", "\n", "df", "[", "'pr'", "]", "=", "df", "[", "'pr'", "]", ".", "apply", "(", "pr_mod", ")", "\n", "rmv", "=", "[", "'byt'", ",", "'pkt'", ",", "'td'", ",", "'sp'", ",", "'dp'", ",", "'pr'", "]", "\n", "for", "col", "in", "df", ".", "columns", ":", "\n", "        ", "if", "col", "not", "in", "rmv", ":", "\n", "            ", "del", "df", "[", "col", "]", "\n", "", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.calc_JS": [[47, 53], ["src.metric_utils.gd", "src.metric_utils.gd", "src.metric_utils.JS"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.gd", "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.gd", "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.JS"], ["", "def", "calc_JS", "(", "col1", ",", "col2", ")", ":", "\n", "    ", "pk", "=", "gd", "(", "col1", ")", "\n", "qk", "=", "gd", "(", "col2", ")", "\n", "#js_score = euclidean_distances(pk, qk)", "\n", "js_score", "=", "JS", "(", "pk", ",", "qk", ",", "KL", "=", "None", ")", "\n", "return", "js_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.swap_localip": [[54, 70], ["pandas.concat", "print", "print"], "function", ["None"], ["", "def", "swap_localip", "(", "df", ")", ":", "\n", "    ", "df1", "=", "df", "[", "(", "df", "[", "'sa_0'", "]", "==", "42", ")", "&", "(", "df", "[", "'sa_1'", "]", "==", "219", ")", "]", "\n", "df2", "=", "df", "[", "(", "df", "[", "'sa_0'", "]", "!=", "42", ")", "|", "(", "df", "[", "'sa_1'", "]", "!=", "219", ")", "]", "\n", "\n", "df2", "[", "'sa_0'", "]", ",", "df2", "[", "'da_0'", "]", "=", "df2", "[", "'da_0'", "]", ",", "df2", "[", "'sa_0'", "]", "\n", "df2", "[", "'sa_1'", "]", ",", "df2", "[", "'da_1'", "]", "=", "df2", "[", "'da_1'", "]", ",", "df2", "[", "'sa_1'", "]", "\n", "df2", "[", "'sa_2'", "]", ",", "df2", "[", "'da_2'", "]", "=", "df2", "[", "'da_2'", "]", ",", "df2", "[", "'sa_2'", "]", "\n", "df2", "[", "'sa_3'", "]", ",", "df2", "[", "'da_3'", "]", "=", "df2", "[", "'da_3'", "]", ",", "df2", "[", "'sa_3'", "]", "\n", "df2", "[", "'sp'", "]", ",", "df2", "[", "'dp'", "]", "=", "df2", "[", "'dp'", "]", ",", "df2", "[", "'sp'", "]", "\n", "\n", "df", "=", "pd", ".", "concat", "(", "[", "df1", ",", "df2", "]", ",", "axis", "=", "0", ",", "sort", "=", "False", ")", "\n", "print", "(", "df", ".", "columns", ")", "\n", "df", ".", "columns", "=", "[", "'td'", ",", "'localPort'", ",", "'outPort'", ",", "'pr'", ",", "'pkt'", ",", "'byt'", ",", "'localIP_0'", ",", "'localIP_1'", ",", "'localIP_2'", ",", "'localIP_3'", ",", "\n", "'outIP_0'", ",", "'outIP_1'", ",", "'outIP_2'", ",", "'outIP_3'", "]", "\n", "print", "(", "df", ".", "columns", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.see_f_dist": [[71, 170], ["files.append", "len", "print", "list", "os.path.exists", "os.makedirs", "print", "metric_runner.scale_process", "temp_df.dropna.replace", "temp_df.dropna.dropna", "dfs.append", "print", "print", "list", "len", "len", "print", "js_day2_gendata.append", "range", "open", "print", "print", "pandas.read_csv", "list", "dfs[].head", "print", "print", "[].value_counts().iteritems", "print", "print", "[].value_counts().iteritems", "metric_runner.calc_JS", "len", "list", "type", "print", "type", "print", "matplotlib.pyplot.savefig", "matplotlib.pyplot.clf", "print", "str", "str", "[].value_counts", "[].value_counts", "[].value_counts", "[].value_counts", "df[].plot.hist", "matplotlib.pyplot.xlim", "matplotlib.pyplot.ylim", "df[].plot.hist", "print", "print", "str"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.scale_process", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.metric_runner.calc_JS"], ["", "def", "see_f_dist", "(", "gen_data", ",", "name_id", ",", "piece_i", ")", ":", "\n", "# plot_names = ['stan' ,'ANDS', 'B1','B2','B3','B4']", "\n", "# plot_names = ['stan']", "\n", "    ", "plot_names", "=", "gen_data", "\n", "gen_data", "=", "gen_data", "[", "name_i", "]", "\n", "#task = 'task3_'", "\n", "files", "=", "[", "'./postprocessed_data/real/day2_90user.csv'", "]", "\n", "gen_file", "=", "'./postprocessed_data/%s/%s'", "%", "(", "gen_data", ",", "gen_data", ")", "+", "'_all.csv'", "#'_piece%d.csv' % piece_i", "\n", "gen_file", "=", "'./postprocessed_data/%s/%s'", "%", "(", "gen_data", ",", "gen_data", ")", "+", "'_piece%d.csv'", "%", "piece_i", "\n", "files", ".", "append", "(", "gen_file", ")", "\n", "plot_folder", "=", "'./results/aaai_metric_plots/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "plot_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "plot_folder", ")", "\n", "", "dfs", "=", "[", "]", "\n", "for", "f", "in", "files", ":", "\n", "        ", "print", "(", "'processing:'", ",", "f", ")", "\n", "temp_df", "=", "scale_process", "(", "pd", ".", "read_csv", "(", "f", ")", ")", "\n", "temp_df", "=", "temp_df", ".", "replace", "(", "[", "np", ".", "inf", ",", "-", "np", ".", "inf", "]", ",", "np", ".", "nan", ")", "\n", "temp_df", "=", "temp_df", ".", "dropna", "(", ")", "\n", "#temp_df = swap_localip(scale_process(pd.read_csv(folder+task+f)))", "\n", "dfs", ".", "append", "(", "temp_df", ")", "\n", "print", "(", "list", "(", "dfs", "[", "-", "1", "]", ".", "columns", ")", ")", "\n", "print", "(", "dfs", "[", "-", "1", "]", ".", "head", "(", "2", ")", ")", "\n", "#input()", "\n", "", "col_len", "=", "len", "(", "list", "(", "dfs", "[", "-", "1", "]", ".", "columns", ")", ")", "\n", "col_ith", "=", "0", "\n", "js_day2_arcnn", "=", "[", "]", "\n", "js_day1_arcnn", "=", "[", "]", "\n", "js_day2_day1", "=", "[", "]", "\n", "js_day2_gendata", "=", "[", "]", "\n", "\n", "#fig, ax = plt.subplots(4, 14, sharex='col', sharey='row')", "\n", "print", "(", "'data size:'", ",", "len", "(", "dfs", "[", "0", "]", ".", "index", ")", ",", "'vs'", ",", "len", "(", "dfs", "[", "1", "]", ".", "index", ")", ")", "\n", "#df.hist(column = df.columns[m], bins = 12, ax=ax[i,j], figsize=(20, 18))", "\n", "for", "col", "in", "list", "(", "dfs", "[", "0", "]", ".", "columns", ")", ":", "\n", "        ", "print", "(", "'doing'", ",", "col", ")", "\n", "if", "col", "==", "'pr'", ":", "\n", "            ", "print", "(", "'day2_pr_dist'", ")", "\n", "print", "(", "type", "(", "dfs", "[", "0", "]", "[", "col", "]", ".", "value_counts", "(", ")", ")", ")", "\n", "for", "val", ",", "cnt", "in", "dfs", "[", "0", "]", "[", "col", "]", ".", "value_counts", "(", ")", ".", "iteritems", "(", ")", ":", "\n", "                ", "print", "(", "gen_data", ",", "val", ",", "cnt", ")", "\n", "", "print", "(", "'stan_pr_dist'", ")", "\n", "print", "(", "type", "(", "dfs", "[", "1", "]", "[", "col", "]", ".", "value_counts", "(", ")", ")", ")", "\n", "for", "val", ",", "cnt", "in", "dfs", "[", "1", "]", "[", "col", "]", ".", "value_counts", "(", ")", ".", "iteritems", "(", ")", ":", "\n", "                ", "print", "(", "gen_data", ",", "val", ",", "cnt", ")", "\n", "#input()", "\n", "#js_day2_day1.append(calc_JS(dfs[0][col], dfs[1][col]))", "\n", "", "", "js_day2_gendata", ".", "append", "(", "calc_JS", "(", "dfs", "[", "0", "]", "[", "col", "]", ",", "dfs", "[", "1", "]", "[", "col", "]", ")", ")", "\n", "#js_day1_arcnn.append(calc_JS(dfs[1][col], dfs[5][col]))", "\n", "\n", "# continue", "\n", "if", "col", "!=", "'byt'", ":", "\n", "            ", "continue", "\n", "", "for", "i", "in", "range", "(", "len", "(", "dfs", ")", ")", ":", "\n", "            ", "try", ":", "\n", "#if True:", "\n", "# print('==>', i, len(dfs))", "\n", "# input()", "\n", "                ", "df", "=", "dfs", "[", "i", "]", "\n", "#df[col].plot.kde(label=files[i])", "\n", "alp", "=", "0.75", "if", "i", "<=", "1", "else", "0.5", "\n", "# use this following one", "\n", "# print('=====>', i, df[col])", "\n", "if", "col", "==", "'byt'", ":", "\n", "                    ", "df", "[", "col", "]", ".", "plot", ".", "hist", "(", "density", "=", "True", ",", "bins", "=", "304", ",", "alpha", "=", "alp", ",", "label", "=", "files", "[", "i", "]", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "20", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "df", "[", "col", "]", ".", "plot", ".", "hist", "(", "normed", "=", "True", ",", "alpha", "=", "alp", ",", "label", "=", "files", "[", "i", "]", ")", "\n", "#=====", "\n", "#df[col].plot.hist(bins=304, alpha=alp, label=files[i])", "\n", "#plt.legend(loc='upper right')", "\n", "# if i == 0:", "\n", "# plt.title(col +' of real test data')", "\n", "# else:", "\n", "# plt.title(col + ' of ' +plot_names[name_id])", "\n", "\n", "", "plt", ".", "savefig", "(", "plot_folder", "+", "plot_names", "[", "name_id", "]", "+", "'_'", "+", "col", "+", "'_'", "+", "str", "(", "i", ")", "+", "'.png'", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "print", "(", "'ploting'", ",", "plot_names", "[", "name_id", "]", ",", "':'", ",", "col_ith", ",", "'of'", ",", "col_len", ",", "':'", ",", "col", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "e", ")", "\n", "print", "(", "'cant plot'", ",", "col", ",", "'of'", ",", "files", "[", "i", "]", ")", "\n", "\n", "", "", "col_ith", "+=", "1", "\n", "# return", "\n", "# with open('results/__ggplot_rev_kl_score.txt', 'a') as f:", "\n", "#     nm = list(dfs[0].columns)", "\n", "#     for i in range(len(nm)):", "\n", "#         out_ = [nm[i], str(js_day2_gendata[i]), gen_data]", "\n", "#         print(','.join(out_), file=f)", "\n", "\n", "# return", "\n", "", "with", "open", "(", "'results/__js_score.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "print", "(", "list", "(", "dfs", "[", "0", "]", ".", "columns", ")", ",", "file", "=", "f", ")", "\n", "#print(js_day2_day1, file=f) ", "\n", "#print(js_day1_arcnn, file=f) ", "\n", "out_", "=", "[", "gen_data", ",", "str", "(", "piece_i", ")", "]", "+", "[", "str", "(", "x", ")", "for", "x", "in", "js_day2_gendata", "]", "\n", "print", "(", "gen_data", ",", "','", ",", "piece_i", ",", "','", ",", "js_day2_gendata", ",", "file", "=", "f", ")", "\n", "#        fig, ax = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(12,7))", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkOneIPIntern": [[7, 14], ["None"], "function", ["None"], ["def", "checkOneIPIntern", "(", "srcIP", ",", "dstIP", ")", ":", "\n", "    ", "global", "succeeded_one_ip_intern", "\n", "global", "failed_one_ip_intern", "\n", "if", "srcIP", "[", ":", "6", "]", "==", "\"42.219\"", "or", "dstIP", "[", ":", "6", "]", "==", "\"42.219\"", "or", "srcIP", "==", "\"0.0.0.0\"", "or", "dstIP", "==", "\"255.255.255.255\"", ":", "\n", "        ", "succeeded_one_ip_intern", "+=", "1", "\n", "", "else", ":", "\n", "        ", "failed_one_ip_intern", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkPort80TCP": [[18, 26], ["None"], "function", ["None"], ["def", "checkPort80TCP", "(", "proto", ",", "srcPt", ",", "dstPt", ")", ":", "\n", "    ", "global", "succeeded_tcp_80", "\n", "global", "failed_tcp_80", "\n", "if", "srcPt", "==", "80", "or", "srcPt", "==", "443", "or", "dstPt", "==", "80", "or", "dstPt", "==", "443", ":", "\n", "        ", "if", "proto", "==", "\"TCP\"", ":", "\n", "            ", "succeeded_tcp_80", "+=", "1", "\n", "", "else", ":", "\n", "            ", "failed_tcp_80", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkPort53UDP": [[30, 38], ["None"], "function", ["None"], ["def", "checkPort53UDP", "(", "proto", ",", "srcPt", ",", "dstPt", ")", ":", "\n", "    ", "global", "succeeded_udp_53", "\n", "global", "failed_udp_53", "\n", "if", "srcPt", "in", "[", "53", ",", "52", "]", "or", "dstPt", "in", "[", "52", ",", "53", "]", ":", "\n", "        ", "if", "proto", "==", "\"UDP\"", ":", "\n", "            ", "succeeded_udp_53", "+=", "1", "\n", "", "else", ":", "\n", "            ", "failed_udp_53", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkMultiBroadcast": [[42, 55], ["int", "int", "int", "int", "srcIP.split", "srcIP.split", "dstIP.split", "dstIP.split"], "function", ["None"], ["def", "checkMultiBroadcast", "(", "srcIP", ",", "dstIP", ",", "row", ")", ":", "\n", "    ", "global", "succeeded_multicast", "\n", "global", "failed_multicast", "\n", "ip1_1", "=", "int", "(", "srcIP", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "ip1_4", "=", "int", "(", "srcIP", ".", "split", "(", "\".\"", ")", "[", "3", "]", ")", "\n", "\n", "ip2_1", "=", "int", "(", "dstIP", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "ip2_4", "=", "int", "(", "dstIP", ".", "split", "(", "\".\"", ")", "[", "3", "]", ")", "\n", "\n", "if", "(", "ip2_1", ">", "223", "or", "(", "ip2_1", "==", "192", "and", "ip2_4", "==", "255", ")", ")", "and", "ip1_1", "<", "224", "and", "not", "(", "ip1_4", "==", "192", "and", "ip1_4", "==", "255", ")", ":", "\n", "        ", "succeeded_multicast", "+=", "1", "\n", "", "elif", "ip1_1", ">", "223", "or", "(", "ip1_4", "==", "192", "and", "ip1_4", "==", "255", ")", ":", "\n", "        ", "failed_multicast", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkNetbios": [[59, 73], ["int", "int", "int", "int", "srcIP.split", "srcIP.split", "dstIP.split", "dstIP.split"], "function", ["None"], ["def", "checkNetbios", "(", "srcIP", ",", "dstIP", ",", "dstPt", ",", "proto", ")", ":", "\n", "    ", "global", "succeeded_netbios", "\n", "global", "failed_netbios", "\n", "ip1_1", "=", "int", "(", "srcIP", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "ip1_2", "=", "int", "(", "srcIP", ".", "split", "(", "\".\"", ")", "[", "1", "]", ")", "\n", "\n", "ip2_1", "=", "int", "(", "dstIP", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "ip2_4", "=", "int", "(", "dstIP", ".", "split", "(", "\".\"", ")", "[", "3", "]", ")", "\n", "\n", "if", "dstPt", "==", "137", "or", "dstPt", "==", "138", ":", "\n", "        ", "if", "ip1_1", "==", "42", "and", "ip1_2", "==", "219", "and", "proto", "==", "\"UDP\"", "and", "ip2_1", "==", "42", "and", "ip2_4", "==", "255", ":", "\n", "            ", "succeeded_netbios", "+=", "1", "\n", "", "else", ":", "\n", "            ", "failed_netbios", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.dsn21_check_ip": [[79, 88], ["print", "input"], "function", ["None"], ["def", "dsn21_check_ip", "(", "srcIP", ",", "dstIP", ")", ":", "\n", "    ", "global", "succeeded_dsn21_check1", "\n", "global", "failed_dsn21_check1", "\n", "print", "(", "srcIP", ",", "dstIP", ")", "\n", "input", "(", ")", "\n", "if", "srcIP", "in", "reserved_ip_set", "or", "dstIP", "in", "reserved_ip_set", ":", "\n", "        ", "failed_dsn21_check1", "+=", "1", "\n", "", "else", ":", "\n", "        ", "succeeded_dsn21_check1", "+=", "1", "\n", "# ip1s = [int(x) for x in srcIP.split(\".\")]", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkRelationBytePackets": [[116, 126], ["None"], "function", ["None"], ["def", "checkRelationBytePackets", "(", "bytzes", ",", "packets", ")", ":", "\n", "    ", "global", "succeeded_byte_packet", "\n", "global", "failed_byte_packet", "\n", "# possible_bin = 1.0/200/2", "\n", "# min_edge = int(np.exp((np.log(40)/20.12915933105231-possible_bin)*20.12915933105231))", "\n", "# print(min_edge)", "\n", "if", "bytzes", ">=", "packets", "*", "41", "and", "bytzes", "<=", "packets", "*", "65536", ":", "\n", "        ", "succeeded_byte_packet", "+=", "1", "\n", "", "else", ":", "\n", "        ", "failed_byte_packet", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkDurationOnePacket": [[130, 139], ["float"], "function", ["None"], ["def", "checkDurationOnePacket", "(", "duration", ",", "packets", ")", ":", "\n", "    ", "global", "succeeded_dur_one_packet", "\n", "global", "failed_dur_one_packet", "\n", "if", "packets", "<=", "1", ":", "\n", "        ", "d", "=", "float", "(", "duration", ")", "\n", "if", "d", "<", "1", ":", "# duration == \"0.000\" or duration == \"0\" or d == 0: ", "\n", "            ", "succeeded_dur_one_packet", "+=", "1", "\n", "", "else", ":", "\n", "            ", "failed_dur_one_packet", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.output_rst": [[141, 149], ["open", "print", "print"], "function", ["None"], ["", "", "", "def", "output_rst", "(", "data_name", ",", "test_name", ",", "true_count", ",", "false_count", ")", ":", "\n", "    ", "tot_count", "=", "true_count", "+", "false_count", "\n", "with", "open", "(", "'results/rule_check_results.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "#print(data_name, '='*10, file=f)", "\n", "        ", "if", "tot_count", ">", "0", ":", "\n", "            ", "print", "(", "test_name", ",", "'true'", ",", "true_count", ",", "'total'", ",", "tot_count", ",", "'percent'", ",", "true_count", "/", "tot_count", ",", "file", "=", "f", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "test_name", ",", "'no sample'", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.test_one_piece": [[150, 182], ["print", "pd.read_csv.iterrows", "rule_check_runner.output_rst", "pandas.read_csv", "rule_check_runner.checkRelationBytePackets", "open", "print", "pandas.read_csv", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.output_rst", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.checkRelationBytePackets"], ["", "", "", "def", "test_one_piece", "(", "data_idx", ",", "piece_idx", ")", ":", "\n", "    ", "files", "=", "[", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real1'", ",", "'real2'", "]", "\n", "if", "files", "[", "data_idx", "]", "==", "'real1'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/real/day1_90user.csv\"", ")", "\n", "", "elif", "files", "[", "data_idx", "]", "==", "'real2'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/real/day2_90user.csv\"", ")", "\n", "", "else", ":", "\n", "#     df = pd.read_csv(\"./postprocessed_data/%s/%s_piece%d.csv\" % (files[data_idx], files[data_idx], piece_idx))", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "piece_idx", ")", ")", "\n", "", "print", "(", "'checking'", ",", "files", "[", "data_idx", "]", ")", "\n", "for", "index", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "#print(row['c1'], row['c2'])", "\n", "# done", "\n", "# checkOneIPIntern(row['sa'], row['da'])", "\n", "# checkPort80TCP(row['pr'],row['sp'],row['dp'])", "\n", "# checkPort53UDP(row['pr'],row['sp'],row['dp'])", "\n", "        ", "checkRelationBytePackets", "(", "row", "[", "'byt'", "]", ",", "row", "[", "'pkt'", "]", ")", "\n", "\n", "# ignore", "\n", "# checkDurationOnePacket(row['td'],row['pkt'])", "\n", "#checkNetbios(row['sa'], row['da'],row['dp'],row['pr'])", "\n", "\n", "# dsn21_check_ip(row['sa'], row['da'])", "\n", "\n", "", "data_name", "=", "'%s_piece%d'", "%", "(", "files", "[", "data_idx", "]", ",", "piece_idx", ")", "\n", "with", "open", "(", "'results/rule_check_results.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "print", "(", "data_name", ",", "'='", "*", "10", ",", "file", "=", "f", ")", "\n", "# output_rst(data_name, 'test1', succeeded_one_ip_intern, failed_one_ip_intern)", "\n", "# output_rst(data_name, 'test2', succeeded_tcp_80, failed_tcp_80)", "\n", "# output_rst(data_name, 'test3', succeeded_udp_53, failed_udp_53)", "\n", "# #output_rst(data_name, 'test4', succeeded_netbios, failed_netbios)", "\n", "", "output_rst", "(", "data_name", ",", "'test5'", ",", "succeeded_byte_packet", ",", "failed_byte_packet", ")", "\n", "# output_rst(data_name, 'test6', succeeded_dur_one_packet, failed_dur_one_packet)", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.rule_check_runner.reset": [[185, 209], ["None"], "function", ["None"], ["", "def", "reset", "(", ")", ":", "\n", "    ", "global", "succeeded_one_ip_intern", "\n", "global", "failed_one_ip_intern", "\n", "\n", "global", "succeeded_tcp_80", "\n", "global", "failed_tcp_80", "\n", "\n", "global", "succeeded_dsn21_check1", "\n", "global", "failed_dsn21_check1", "\n", "\n", "global", "succeeded_byte_packet", "\n", "global", "failed_byte_packet", "\n", "\n", "succeeded_byte_packet", "=", "0", "\n", "failed_byte_packet", "=", "0", "\n", "\n", "succeeded_one_ip_intern", "=", "0", "\n", "failed_one_ip_intern", "=", "0", "\n", "\n", "succeeded_tcp_80", "=", "0", "\n", "failed_tcp_80", "=", "0", "\n", "\n", "succeeded_dsn21_check1", "=", "0", "\n", "failed_dsn21_check1", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.acf": [[20, 23], ["numpy.array", "numpy.corrcoef", "range"], "function", ["None"], ["def", "acf", "(", "x", ",", "length", "=", "10", ")", ":", "\n", "  ", "return", "np", ".", "array", "(", "[", "1", "]", "+", "[", "np", ".", "corrcoef", "(", "x", "[", ":", "-", "i", "]", ",", "x", "[", "i", ":", "]", ")", "[", "0", ",", "1", "]", "for", "i", "in", "range", "(", "1", ",", "length", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.scale_check": [[24, 48], ["print", "pandas.read_csv", "scale_list.append", "scale_list.append", "scale_list.append", "scale_list.append", "pandas.read_csv", "pandas.read_csv", "range", "pandas.concat", "str", "str", "pandas.read_csv", "li.append", "numpy.min", "numpy.log", "numpy.max"], "function", ["None"], ["", "def", "scale_check", "(", "data_idx", ",", "plot", "=", "False", ")", ":", "\n", "    ", "files", "=", "[", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "names", "=", "[", "'stan_b'", ",", "'stan_a'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "\n", "if", "files", "[", "data_idx", "]", "==", "'real'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/day2_90user.csv\"", "%", "files", "[", "data_idx", "]", ")", "\n", "", "elif", "files", "[", "data_idx", "]", "==", "'stanc'", "or", "files", "[", "data_idx", "]", "==", "'stan'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ",", "index_col", "=", "None", ")", "\n", "li", "=", "[", "df", "]", "\n", "for", "piece_idx", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "piece_idx", ")", ",", "index_col", "=", "None", ",", "header", "=", "0", ")", "\n", "li", ".", "append", "(", "df", ")", "\n", "", "df", "=", "pd", ".", "concat", "(", "li", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "scale_list", "=", "[", "]", "\n", "for", "col", "in", "[", "'byt'", ",", "'pkt'", "]", ":", "\n", "        ", "scale_list", ".", "append", "(", "col", ")", "\n", "scale_list", ".", "append", "(", "str", "(", "np", ".", "min", "(", "df", "[", "col", "]", ")", ")", ")", "\n", "scale_list", ".", "append", "(", "str", "(", "np", ".", "log", "(", "np", ".", "max", "(", "df", "[", "col", "]", ")", ")", ")", ")", "\n", "scale_list", ".", "append", "(", "';'", ")", "\n", "\n", "", "print", "(", "files", "[", "data_idx", "]", ",", "':'", ",", "(", "' '", ".", "join", "(", "scale_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.pr_distribution": [[49, 81], ["df[].value_counts", "print", "df[].value_counts.keys", "print", "pandas.read_csv", "open", "out.write", "pandas.read_csv", "pandas.read_csv", "range", "pandas.concat", "sum", "pandas.read_csv", "li.append", "str", "str", "str"], "function", ["None"], ["", "def", "pr_distribution", "(", "data_idx", ",", "plot", "=", "False", ")", ":", "\n", "    ", "files", "=", "[", "'stan'", ",", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "names", "=", "[", "'stan_fwd'", ",", "'stan_b'", ",", "'stan_a'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "\n", "if", "files", "[", "data_idx", "]", "==", "'real'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/day2_90user.csv\"", "%", "files", "[", "data_idx", "]", ")", "\n", "", "elif", "files", "[", "data_idx", "]", "==", "'stanc'", "or", "files", "[", "data_idx", "]", "==", "'stan'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ",", "index_col", "=", "None", ")", "\n", "li", "=", "[", "df", "]", "\n", "for", "piece_idx", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "piece_idx", ")", ",", "index_col", "=", "None", ",", "header", "=", "0", ")", "\n", "li", ".", "append", "(", "df", ")", "\n", "", "df", "=", "pd", ".", "concat", "(", "li", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ")", "\n", "\n", "# pr marginal distribution", "\n", "", "pr_series", "=", "df", "[", "'pr'", "]", ".", "value_counts", "(", ")", "\n", "print", "(", "names", "[", "data_idx", "]", ",", "pr_series", ")", "\n", "ct", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "for", "i", "in", "pr_series", ".", "keys", "(", ")", ":", "\n", "        ", "if", "i", "==", "'TCP'", ":", "\n", "            ", "ct", "[", "0", "]", "+=", "pr_series", "[", "i", "]", "\n", "", "elif", "i", "==", "'UDP'", ":", "\n", "            ", "ct", "[", "1", "]", "+=", "pr_series", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "ct", "[", "2", "]", "+=", "pr_series", "[", "i", "]", "\n", "", "", "ct2", "=", "[", "x", "/", "sum", "(", "ct", ")", "for", "x", "in", "ct", "]", "\n", "print", "(", "ct2", ")", "\n", "\n", "with", "open", "(", "'results/pr/pr_marginal.csv'", ",", "'a'", ")", "as", "out", ":", "\n", "        ", "out", ".", "write", "(", "','", ".", "join", "(", "[", "names", "[", "data_idx", "]", ",", "str", "(", "ct2", "[", "0", "]", ")", ",", "str", "(", "ct2", "[", "1", "]", ")", ",", "str", "(", "ct2", "[", "2", "]", ")", ",", "'\\n'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.check_distribution": [[96, 138], ["df.astype.astype", "print", "df.astype.hist", "matplotlib.savefig", "matplotlib.clf", "range", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.title", "l_p.append", "l_o.append", "len", "df.astype.value_counts", "df.astype.value_counts", "len", "sum"], "function", ["None"], ["", "", "def", "check_distribution", "(", "df", ",", "name", ",", "user", "=", "None", ")", ":", "\n", "# count = df_all.value_counts()", "\n", "# df.hist = df.hist()", "\n", "    ", "df", "=", "df", ".", "astype", "(", "int", ")", "\n", "\n", "# print(df.value_counts(normalize=True))", "\n", "global", "port_hist", "\n", "global", "user_port_hist", "\n", "if", "port_dir", "==", "'sys'", ":", "\n", "        ", "df", ".", "hist", "(", "bins", "=", "1024", ")", "# s is an instance of Series", "\n", "# plt.plot(df.value_counts().index, df.value_counts().values)", "\n", "plt", ".", "savefig", "(", "'./results/ports/%s/%s.png'", "%", "(", "port_dir", ",", "name", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "port_hist", "[", "name", "+", "'_port'", "]", "=", "df", ".", "value_counts", "(", "normalize", "=", "True", ")", "[", ":", "10", "]", ".", "index", "\n", "port_hist", "[", "name", "+", "'_occ'", "]", "=", "df", ".", "value_counts", "(", "normalize", "=", "True", ")", "[", ":", "10", "]", ".", "values", "\n", "", "else", ":", "\n", "        ", "l_p", "=", "[", "]", "\n", "l_o", "=", "[", "]", "\n", "bar_size", "=", "6000", "\n", "for", "i", "in", "range", "(", "1024", ",", "65536", ",", "bar_size", ")", ":", "\n", "            ", "l_p", ".", "append", "(", "i", ")", "\n", "l_o", ".", "append", "(", "len", "(", "df", "[", "(", "i", "<=", "df", ")", "&", "(", "df", "<", "i", "+", "bar_size", ")", "]", ".", "index", ")", ")", "\n", "\n", "# print(df[(i<=df) & (df<i+bar_size)])", "\n", "# print(i, i+bar_size)", "\n", "# input()", "\n", "# print(l_o, name)", "\n", "\n", "", "l_o", "=", "[", "x", "/", "sum", "(", "l_o", ")", "for", "x", "in", "l_o", "]", "\n", "if", "len", "(", "user_port_hist", ".", "columns", ")", "==", "1", ":", "\n", "            ", "user_port_hist", "[", "name", "+", "'_port'", "]", "=", "l_p", "\n", "", "user_port_hist", "[", "name", "+", "'_occ'", "]", "=", "l_o", "\n", "plt", ".", "plot", "(", "l_p", ",", "l_o", ")", "\n", "plt", ".", "xlabel", "(", "\"user port\"", ")", "\n", "plt", ".", "ylabel", "(", "\"probability\"", ")", "\n", "plt", ".", "title", "(", "\"user port distribution\"", ")", "\n", "\n", "# plt.xticks(x_pos, x)", "\n", "# plt.savefig('./results/ports/%s/%s.png' % (port_dir, name))", "\n", "# plt.clf()", "\n", "\n", "", "print", "(", "'plotted %s'", "%", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.port_distribution": [[139, 173], ["pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "range", "pandas.concat", "distribution_check.check_distribution", "distribution_check.check_distribution", "pandas.read_csv", "li.append", "df_pr.dropna", "df_pr[].str.startswith", "df_pr[].str.startswith"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.check_distribution", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.check_distribution"], ["", "def", "port_distribution", "(", "data_idx", ",", "plot", "=", "False", ")", ":", "\n", "    ", "files", "=", "[", "'stan'", ",", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "names", "=", "[", "'stan_fwd'", ",", "'stan_b'", ",", "'stan_a'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "\n", "if", "files", "[", "data_idx", "]", "==", "'real'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/day2_90user.csv\"", "%", "files", "[", "data_idx", "]", ")", "\n", "", "elif", "files", "[", "data_idx", "]", "==", "'stanc'", "or", "files", "[", "data_idx", "]", "==", "'stan'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ",", "index_col", "=", "None", ")", "\n", "li", "=", "[", "df", "]", "\n", "for", "piece_idx", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "piece_idx", ")", ",", "index_col", "=", "None", ",", "header", "=", "0", ")", "\n", "li", ".", "append", "(", "df", ")", "\n", "", "df", "=", "pd", ".", "concat", "(", "li", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ")", "\n", "", "for", "pr", "in", "[", "'TCP'", ",", "'UDP'", "]", ":", "\n", "        ", "df_pr", "=", "df", "[", "df", "[", "'pr'", "]", "==", "pr", "]", "\n", "if", "flow_dir", "==", "'outgoing'", ":", "\n", "            ", "flows", "=", "df_pr", "[", "df_pr", "[", "'sa'", "]", ".", "str", ".", "startswith", "(", "'42.219'", ")", "]", "\n", "", "elif", "flow_dir", "==", "'incoming'", ":", "\n", "            ", "flows", "=", "df_pr", "[", "df_pr", "[", "'da'", "]", ".", "str", ".", "startswith", "(", "'42.219'", ")", "]", "\n", "", "else", ":", "\n", "            ", "flows", "=", "df_pr", ".", "dropna", "(", ")", "\n", "\n", "# outgoing_port = pd.concat([outgoing_flows['sp'], outgoing_flows['dp']], axis= 0)", "\n", "# check_distribution(outgoing_port, files[data_idx]+'_outgoing')", "\n", "\n", "# incoming_port = pd.concat([flows['sp'], flows['dp']], axis= 0)", "\n", "", "if", "port_dir", "==", "'sys'", ":", "\n", "            ", "incoming_port", "=", "flows", "[", "flows", "[", "'dp'", "]", "<", "1024", "]", "[", "'dp'", "]", "\n", "check_distribution", "(", "incoming_port", ",", "names", "[", "data_idx", "]", "+", "'_'", "+", "pr", "+", "'_'", "+", "flow_dir", ")", "\n", "", "else", ":", "\n", "            ", "user_port", "=", "flows", "[", "flows", "[", "'dp'", "]", ">=", "1024", "]", "[", "'dp'", "]", "\n", "check_distribution", "(", "user_port", ",", "names", "[", "data_idx", "]", "+", "'_'", "+", "pr", "+", "'_'", "+", "flow_dir", ",", "user", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.attribute_autocorr": [[174, 202], ["distribution_check.acf", "print", "pandas.read_csv", "matplotlib.plot", "pandas.read_csv", "pandas.read_csv", "range", "pandas.concat", "matplotlib.savefig", "matplotlib.clf", "pandas.read_csv", "li.append"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.acf"], ["", "", "", "def", "attribute_autocorr", "(", "data_idx", ",", "plot", "=", "False", ")", ":", "\n", "    ", "files", "=", "[", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "# files = ['stanc', 'arcnn_f90', 'wpgan', 'ctgan', 'real'] ", "\n", "if", "files", "[", "data_idx", "]", "==", "'real'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/day2_90user.csv\"", "%", "files", "[", "data_idx", "]", ")", "\n", "", "elif", "files", "[", "data_idx", "]", "==", "'stanc'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ",", "index_col", "=", "None", ")", "\n", "li", "=", "[", "df", "]", "\n", "for", "piece_idx", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "piece_idx", ")", ",", "index_col", "=", "None", ",", "header", "=", "0", ")", "\n", "li", ".", "append", "(", "df", ")", "\n", "", "df", "=", "pd", ".", "concat", "(", "li", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ")", "\n", "", "df1", "=", "df", "[", "[", "'byt'", ",", "'pkt'", "]", "]", "\n", "# print(df1)", "\n", "# input()", "\n", "auto", "=", "acf", "(", "df1", "[", "'byt'", "]", ")", "\n", "print", "(", "files", "[", "data_idx", "]", ",", "auto", ")", "\n", "if", "plot", ":", "\n", "# df_plot = pd.read_csv('results/ip_power_law/volumn_%s.csv' % files[data_idx], header=None)", "\n", "# print(df_plot)", "\n", "# input()", "\n", "        ", "plt", ".", "plot", "(", "auto", ")", "\n", "# plt.plot(df_plot[1])", "\n", "if", "plot_mode", "!=", "'all_in_one'", ":", "\n", "            ", "plt", ".", "savefig", "(", "'results/ip_power_law/%s.png'", "%", "files", "[", "data_idx", "]", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.ip_volumne": [[203, 253], ["pandas.concat", "df_nolocal.sample.sample", "df_nolocal.sample.columns.tolist", "df_nolocal.columns.tolist.remove", "[].sum", "count.sort_values", "print", "count.sort_values.to_csv", "pandas.read_csv", "len", "len", "len", "len", "pandas.read_csv", "matplotlib.plot", "pandas.read_csv", "pandas.read_csv", "range", "pandas.concat", "numpy.log", "matplotlib.savefig", "matplotlib.clf", "pandas.read_csv", "li.append", "df_all[].str.startswith", "df_nolocal.sample.groupby"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample"], ["", "", "", "def", "ip_volumne", "(", "data_idx", ",", "plot", "=", "False", ")", ":", "\n", "    ", "files", "=", "[", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "# files = ['stanc', 'arcnn_f90', 'wpgan', 'ctgan', 'real'] ", "\n", "if", "files", "[", "data_idx", "]", "==", "'real'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/day2_90user.csv\"", "%", "files", "[", "data_idx", "]", ")", "\n", "", "elif", "files", "[", "data_idx", "]", "==", "'stanc'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ",", "index_col", "=", "None", ")", "\n", "li", "=", "[", "df", "]", "\n", "for", "piece_idx", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "piece_idx", ")", ",", "index_col", "=", "None", ",", "header", "=", "0", ")", "\n", "li", ".", "append", "(", "df", ")", "\n", "", "df", "=", "pd", ".", "concat", "(", "li", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ")", "\n", "", "df1", "=", "df", "[", "[", "'sa'", ",", "'da'", ",", "'byt'", "]", "]", "\n", "df2_s", "=", "df1", "[", "[", "'sa'", ",", "'byt'", "]", "]", "\n", "df2_d", "=", "df1", "[", "[", "'da'", ",", "'byt'", "]", "]", "\n", "df2_s", ".", "columns", "=", "[", "'ip'", ",", "'byt'", "]", "\n", "df2_d", ".", "columns", "=", "[", "'ip'", ",", "'byt'", "]", "\n", "\n", "df_all", "=", "pd", ".", "concat", "(", "[", "df2_s", ",", "df2_d", "]", ",", "axis", "=", "0", ")", "\n", "df_nolocal", "=", "df_all", "[", "~", "df_all", "[", "'ip'", "]", ".", "str", ".", "startswith", "(", "'42.219'", ")", "]", "\n", "df_nolocal", "=", "df_nolocal", ".", "sample", "(", "1000000", ")", "\n", "\n", "group_cols", "=", "df_nolocal", ".", "columns", ".", "tolist", "(", ")", "\n", "group_cols", ".", "remove", "(", "'byt'", ")", "\n", "\n", "df_sum", "=", "df_nolocal", ".", "groupby", "(", "group_cols", ",", "as_index", "=", "False", ")", "[", "'byt'", "]", ".", "sum", "(", ")", "\n", "\n", "# print(df_sum)", "\n", "# print(df_sum[df_sum['ip']=='185.165.153.56'])", "\n", "# input()", "\n", "count", "=", "df_sum", "[", "'byt'", "]", "#.value_counts()", "\n", "s", "=", "count", ".", "sort_values", "(", "ascending", "=", "False", ")", "\n", "# final_df = count.sort_values(by=['byt'], ascending=False)", "\n", "# print(final_df)", "\n", "# input()", "\n", "print", "(", "files", "[", "data_idx", "]", ",", "len", "(", "df", ".", "index", ")", ",", "len", "(", "df_nolocal", ".", "index", ")", ",", "len", "(", "df_sum", ".", "index", ")", ",", "len", "(", "count", ".", "index", ")", ")", "\n", "\n", "s", ".", "to_csv", "(", "'results/ip_power_law/volumn_%s.csv'", "%", "files", "[", "data_idx", "]", ")", "\n", "\n", "if", "plot", ":", "\n", "        ", "df_plot", "=", "pd", ".", "read_csv", "(", "'results/ip_power_law/volumn_%s.csv'", "%", "files", "[", "data_idx", "]", ",", "header", "=", "None", ")", "\n", "# print(df_plot)", "\n", "# input()", "\n", "plt", ".", "plot", "(", "np", ".", "log", "(", "df_plot", "[", "1", "]", ")", ")", "\n", "# plt.plot(df_plot[1])", "\n", "if", "plot_mode", "!=", "'all_in_one'", ":", "\n", "            ", "plt", ".", "savefig", "(", "'results/ip_power_law/%s.png'", "%", "files", "[", "data_idx", "]", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.distribution_check.ip_power_law": [[254, 291], ["pandas.concat", "df_nolocal.sample.sample", "df_nolocal.sample.value_counts", "print", "df_nolocal.value_counts.to_csv", "pandas.read_csv", "len", "pandas.read_csv", "matplotlib.plot", "pandas.read_csv", "pandas.read_csv", "range", "pandas.concat", "numpy.log", "matplotlib.savefig", "matplotlib.clf", "pandas.read_csv", "li.append", "pd.concat.str.startswith"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample"], ["", "", "", "def", "ip_power_law", "(", "data_idx", ",", "plot", "=", "False", ")", ":", "\n", "    ", "files", "=", "[", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'bsl1'", ",", "'bsl2'", ",", "'real'", "]", "\n", "files", "=", "[", "'stanc'", ",", "'arcnn_f90'", ",", "'wpgan'", ",", "'ctgan'", ",", "'real'", "]", "\n", "if", "files", "[", "data_idx", "]", "==", "'real'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/day2_90user.csv\"", "%", "files", "[", "data_idx", "]", ")", "\n", "", "elif", "files", "[", "data_idx", "]", "==", "'stanc'", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "0", ")", ",", "index_col", "=", "None", ")", "\n", "li", "=", "[", "df", "]", "\n", "for", "piece_idx", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "            ", "df", "=", "pd", ".", "read_csv", "(", "\"./postprocessed_data/%s/%s_piece%d.csv\"", "%", "(", "files", "[", "data_idx", "]", ",", "files", "[", "data_idx", "]", ",", "piece_idx", ")", ",", "index_col", "=", "None", ",", "header", "=", "0", ")", "\n", "li", ".", "append", "(", "df", ")", "\n", "", "df", "=", "pd", ".", "concat", "(", "li", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ")", "\n", "\n", "# count = df['sa'].value_counts()", "\n", "# df = df.sample(1000000)", "\n", "\n", "", "df_all", "=", "pd", ".", "concat", "(", "[", "df", "[", "'sa'", "]", ",", "df", "[", "'da'", "]", "]", ",", "axis", "=", "0", ")", "\n", "df_nolocal", "=", "df_all", "[", "~", "df_all", ".", "str", ".", "startswith", "(", "'42.219'", ")", "]", "\n", "df_nolocal", "=", "df_nolocal", ".", "sample", "(", "1000000", ")", "\n", "count", "=", "df_nolocal", ".", "value_counts", "(", ")", "\n", "# count_no_local = count[~count.index.str.startswith('42.219')]", "\n", "if", "plot_mode", "==", "'all_in_one'", ":", "\n", "# count = count[:38000]", "\n", "        ", "pass", "\n", "# print(len(count[count.index.str.startswith('42.219')].index))", "\n", "", "print", "(", "len", "(", "count", ".", "index", ")", ")", "\n", "count", ".", "to_csv", "(", "'results/ip_power_law/%s.csv'", "%", "files", "[", "data_idx", "]", ")", "\n", "\n", "if", "plot", ":", "\n", "        ", "df_plot", "=", "pd", ".", "read_csv", "(", "'results/ip_power_law/%s.csv'", "%", "files", "[", "data_idx", "]", ",", "header", "=", "None", ")", "\n", "# print(df_plot)", "\n", "plt", ".", "plot", "(", "np", ".", "log", "(", "df_plot", "[", "1", "]", ")", ")", "\n", "if", "plot_mode", "!=", "'all_in_one'", ":", "\n", "            ", "plt", ".", "savefig", "(", "'results/ip_power_law/%s.png'", "%", "files", "[", "data_idx", "]", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "# input()", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.plot_data": [[9, 13], ["matplotlib.hist2d", "matplotlib.xlim", "matplotlib.ylim", "numpy.array"], "function", ["None"], ["def", "plot_data", "(", "x", ",", "y", ")", ":", "\n", "    ", "plt", ".", "hist2d", "(", "x", ",", "y", ",", "bins", "=", "50", ",", "cmap", "=", "plt", ".", "cm", ".", "BuPu", ",", "range", "=", "np", ".", "array", "(", "[", "(", "-", "1", ",", "1", ")", ",", "(", "-", "1", ",", "1", ")", "]", ")", ")", "\n", "plt", ".", "xlim", "(", "-", "1", ",", "1", ")", "\n", "plt", ".", "ylim", "(", "-", "1", ",", "1", ")", "\n", "# plt.axis('off')", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.save_plot": [[15, 27], ["matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tick_params", "matplotlib.savefig", "matplotlib.clf"], "function", ["None"], ["", "def", "save_plot", "(", "save_file", ")", ":", "\n", "# plt.gca().xaxis.set_major_locator(plt.NullLocator())", "\n", "# plt.gca().yaxis.set_major_locator(plt.NullLocator())", "\n", "# plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)", "\n", "# plt.margins(0,0)", "\n", "    ", "plt", ".", "xlabel", "(", "'x'", ",", "fontsize", "=", "50", ")", "\n", "plt", ".", "ylabel", "(", "'x-1'", ",", "fontsize", "=", "50", ")", "\n", "\n", "plt", ".", "tick_params", "(", "labelsize", "=", "50", ")", "\n", "plt", ".", "savefig", "(", "save_file", ",", "bbox_inches", "=", "'tight'", ",", "pad_inches", "=", "0", ")", "\n", "# plt.savefig(save_file)", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.estimated_autocorrelation": [[28, 40], ["len", "x.var", "x.mean", "numpy.correlate", "numpy.arange"], "function", ["None"], ["", "def", "estimated_autocorrelation", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    http://stackoverflow.com/q/14297012/190597\n    http://en.wikipedia.org/wiki/Autocorrelation#Estimation\n    \"\"\"", "\n", "n", "=", "len", "(", "x", ")", "\n", "variance", "=", "x", ".", "var", "(", ")", "\n", "x", "=", "x", "-", "x", ".", "mean", "(", ")", "\n", "r", "=", "np", ".", "correlate", "(", "x", ",", "x", ",", "mode", "=", "'full'", ")", "[", "-", "n", ":", "]", "\n", "# assert np.allclose(r, np.array([(x[:n-k]*x[-(n-k):]).sum() for k in range(n)]))", "\n", "result", "=", "r", "/", "(", "variance", "*", "(", "np", ".", "arange", "(", "n", ",", "0", ",", "-", "1", ")", ")", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.corr_plot": [[41, 108], ["pandas.read_csv", "df_naive.dropna.columns.astype", "df_naive[].shift", "df_naive.dropna.dropna", "pandas.read_csv", "tfs_A_samples.dropna.columns.astype", "tfs_A_samples[].shift", "tfs_A_samples.dropna.dropna", "pandas.read_csv", "tfs_B_samples.dropna.columns.astype", "tfs_B_samples[].shift", "tfs_B_samples.dropna.dropna", "pandas.read_csv", "b1_samples.dropna.columns.astype", "b1_samples[].shift", "b1_samples.dropna.dropna", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.corrcoef", "numpy.corrcoef", "numpy.corrcoef", "numpy.corrcoef", "matplotlib.figure", "correlation.plot_data", "correlation.save_plot", "correlation.plot_data", "correlation.save_plot", "correlation.plot_data", "correlation.save_plot", "correlation.plot_data", "correlation.save_plot", "correlation.estimated_autocorrelation", "correlation.estimated_autocorrelation", "correlation.estimated_autocorrelation", "correlation.estimated_autocorrelation", "os.path.exists", "os.makedirs", "df_naive[].to_numpy", "df_naive[].to_numpy", "tfs_A_samples[].to_numpy", "tfs_A_samples[].to_numpy", "tfs_B_samples[].to_numpy", "tfs_B_samples[].to_numpy", "b1_samples[].to_numpy", "b1_samples[].to_numpy", "df_naive[].to_numpy", "tfs_A_samples[].to_numpy", "tfs_B_samples[].to_numpy", "b1_samples[].to_numpy"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.plot_data", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.save_plot", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.plot_data", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.save_plot", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.plot_data", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.save_plot", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.plot_data", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.save_plot", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.estimated_autocorrelation", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.estimated_autocorrelation", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.estimated_autocorrelation", "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.estimated_autocorrelation"], ["", "def", "corr_plot", "(", "data_path", "=", "'./stan_data/'", ",", "plot", "=", "False", ",", "plot_axis", "=", "'xy'", ")", ":", "\n", "    ", "df_naive", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_raw.csv'", ")", "\n", "df_naive", ".", "columns", "=", "df_naive", ".", "columns", ".", "astype", "(", "int", ")", "\n", "df_naive", "[", "2", "]", "=", "df_naive", "[", "0", "]", ".", "shift", "(", "1", ")", "\n", "df_naive", "=", "df_naive", ".", "dropna", "(", ")", "\n", "\n", "tfs_A_samples", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_tfs_a_2.csv'", ")", "\n", "tfs_A_samples", ".", "columns", "=", "tfs_A_samples", ".", "columns", ".", "astype", "(", "int", ")", "\n", "tfs_A_samples", "[", "2", "]", "=", "tfs_A_samples", "[", "0", "]", ".", "shift", "(", "1", ")", "\n", "tfs_A_samples", "=", "tfs_A_samples", ".", "dropna", "(", ")", "\n", "\n", "tfs_B_samples", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_tfs_b.csv'", ")", "\n", "tfs_B_samples", ".", "columns", "=", "tfs_B_samples", ".", "columns", ".", "astype", "(", "int", ")", "\n", "tfs_B_samples", "[", "2", "]", "=", "tfs_B_samples", "[", "0", "]", ".", "shift", "(", "1", ")", "\n", "tfs_B_samples", "=", "tfs_B_samples", ".", "dropna", "(", ")", "\n", "\n", "b1_samples", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_b1.csv'", ")", "\n", "b1_samples", ".", "columns", "=", "b1_samples", ".", "columns", ".", "astype", "(", "int", ")", "\n", "b1_samples", "[", "2", "]", "=", "b1_samples", "[", "0", "]", ".", "shift", "(", "1", ")", "\n", "b1_samples", "=", "b1_samples", ".", "dropna", "(", ")", "\n", "\n", "# b4_samples = pd.read_csv(data_path+'artificial_b4.csv')", "\n", "# b4_samples.columns = b4_samples.columns.astype(int)", "\n", "# tfs_C_samples = pd.read_csv(data_path+'artificial_tfs_prior.csv')", "\n", "# tfs_C_samples.columns = tfs_C_samples.columns.astype(int)", "\n", "\n", "########################################################################", "\n", "# plotting gen data", "\n", "########################################################################", "\n", "to_cmp", "=", "1", "if", "plot_axis", "==", "'xy'", "else", "2", "\n", "\n", "print", "(", "'#'", "*", "30", "+", "'corr_xy'", "+", "'#'", "*", "30", ")", "\n", "corr_raw", "=", "np", ".", "corrcoef", "(", "df_naive", "[", "0", "]", ",", "df_naive", "[", "to_cmp", "]", ")", "[", "0", ",", "1", "]", "\n", "corr_tfs_A", "=", "np", ".", "corrcoef", "(", "tfs_A_samples", "[", "0", "]", ",", "tfs_A_samples", "[", "to_cmp", "]", ")", "[", "0", ",", "1", "]", "\n", "corr_tfs_B", "=", "np", ".", "corrcoef", "(", "tfs_B_samples", "[", "0", "]", ",", "tfs_B_samples", "[", "to_cmp", "]", ")", "[", "0", ",", "1", "]", "\n", "corr_b1", "=", "np", ".", "corrcoef", "(", "b1_samples", "[", "0", "]", ",", "b1_samples", "[", "to_cmp", "]", ")", "[", "0", ",", "1", "]", "\n", "# corr_b4 = np.corrcoef(b4_samples[0], b4_samples[to_cmp])[0, 1]", "\n", "print", "(", "'xy_corr_raw'", ",", "corr_raw", ")", "\n", "print", "(", "'xy_corr_tfs_A'", ",", "corr_tfs_A", ")", "\n", "print", "(", "'xy_corr_tfs_B'", ",", "corr_tfs_B", ")", "\n", "print", "(", "'xy_corr_b1'", ",", "corr_b1", ")", "\n", "# print('xy_corr_b4', corr_b4)", "\n", "\n", "print", "(", "'#'", "*", "30", "+", "'autocorr_x'", "+", "'#'", "*", "30", ")", "\n", "print", "(", "'x_autocorr_raw'", ",", "estimated_autocorrelation", "(", "df_naive", "[", "0", "]", ".", "to_numpy", "(", ")", ")", "[", ":", "5", "]", ")", "\n", "print", "(", "'x_autocorr_tfs_A'", ",", "estimated_autocorrelation", "(", "tfs_A_samples", "[", "0", "]", ".", "to_numpy", "(", ")", ")", "[", ":", "5", "]", ")", "\n", "print", "(", "'x_autocorr_tfs_B'", ",", "estimated_autocorrelation", "(", "tfs_B_samples", "[", "0", "]", ".", "to_numpy", "(", ")", ")", "[", ":", "5", "]", ")", "\n", "print", "(", "'x_autocorr_b1'", ",", "estimated_autocorrelation", "(", "b1_samples", "[", "0", "]", ".", "to_numpy", "(", ")", ")", "[", ":", "5", "]", ")", "\n", "# print('x_autocorr_b4', estimated_autocorrelation(b4_samples[0].to_numpy())[:5])", "\n", "\n", "if", "plot", ":", "\n", "        ", "data_path", "=", "'./plots_artificial/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "data_path", ")", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "12", ")", ")", "\n", "\n", "plot_data", "(", "df_naive", "[", "0", "]", ".", "to_numpy", "(", ")", ",", "df_naive", "[", "to_cmp", "]", ".", "to_numpy", "(", ")", ")", "\n", "save_plot", "(", "data_path", "+", "'observed_%s.png'", "%", "plot_axis", ")", "\n", "\n", "plot_data", "(", "tfs_A_samples", "[", "0", "]", ".", "to_numpy", "(", ")", ",", "tfs_A_samples", "[", "to_cmp", "]", ".", "to_numpy", "(", ")", ")", "\n", "save_plot", "(", "data_path", "+", "'tfs_a_%s.png'", "%", "plot_axis", ")", "\n", "\n", "plot_data", "(", "tfs_B_samples", "[", "0", "]", ".", "to_numpy", "(", ")", ",", "tfs_B_samples", "[", "to_cmp", "]", ".", "to_numpy", "(", ")", ")", "\n", "save_plot", "(", "data_path", "+", "'tfs_b_%s.png'", "%", "plot_axis", ")", "\n", "\n", "plot_data", "(", "b1_samples", "[", "0", "]", ".", "to_numpy", "(", ")", ",", "b1_samples", "[", "to_cmp", "]", ".", "to_numpy", "(", ")", ")", "\n", "save_plot", "(", "data_path", "+", "'b1_%s.png'", "%", "plot_axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.mse_same_row": [[116, 138], ["print", "correlation.mse_same_row.mse_xy"], "function", ["None"], ["", "", "def", "mse_same_row", "(", "data_path", "=", "'./stan_data/'", ")", ":", "\n", "    ", "print", "(", "'='", "*", "30", "+", "'eval_task_same_row'", "+", "'='", "*", "30", ")", "\n", "def", "mse_xy", "(", "data_name", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_%s.csv'", "%", "data_name", ")", "\n", "df", ".", "columns", "=", "df", ".", "columns", ".", "astype", "(", "int", ")", "\n", "df_raw", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_raw.csv'", ")", "\n", "df_raw", ".", "columns", "=", "df_raw", ".", "columns", ".", "astype", "(", "int", ")", "\n", "\n", "x", "=", "np", ".", "reshape", "(", "df", "[", "0", "]", ".", "tolist", "(", ")", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "y", "=", "np", ".", "reshape", "(", "df", "[", "1", "]", ".", "tolist", "(", ")", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "x_true", "=", "np", ".", "reshape", "(", "df_raw", "[", "0", "]", ".", "tolist", "(", ")", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "y_true", "=", "np", ".", "reshape", "(", "df_raw", "[", "1", "]", ".", "tolist", "(", ")", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "reg", "=", "LinearRegression", "(", ")", ".", "fit", "(", "x", ",", "y", ")", "\n", "y_pred", "=", "reg", ".", "predict", "(", "x_true", ")", "\n", "print", "(", "'%s_train_mse'", "%", "data_name", ",", "mean_squared_error", "(", "y_true", ",", "y_pred", ")", ")", "\n", "# print('real_train_rmse', mean_squared_error(real_y, pred_y, squared=False))", "\n", "", "mse_xy", "(", "'raw'", ")", "\n", "mse_xy", "(", "'tfs_prior_2'", ")", "\n", "mse_xy", "(", "'tfs_a_2'", ")", "\n", "mse_xy", "(", "'tfs_b'", ")", "\n", "mse_xy", "(", "'b1'", ")", "\n", "mse_xy", "(", "'b4'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.evaluation.correlation.mse_temporal": [[139, 166], ["print", "correlation.mse_temporal.mse_x"], "function", ["None"], ["", "def", "mse_temporal", "(", "data_path", "=", "'./stan_data/'", ")", ":", "\n", "    ", "print", "(", "'='", "*", "30", "+", "'eval_task_temporal'", "+", "'='", "*", "30", ")", "\n", "def", "mse_x", "(", "data_name", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_%s.csv'", "%", "data_name", ")", "\n", "df", ".", "columns", "=", "df", ".", "columns", ".", "astype", "(", "int", ")", "\n", "df_len", "=", "len", "(", "df", ".", "columns", ")", "\n", "df", "[", "df_len", "]", "=", "df", "[", "0", "]", ".", "shift", "(", "-", "1", ")", "\n", "df", "=", "df", ".", "dropna", "(", ")", "\n", "\n", "df_raw", "=", "pd", ".", "read_csv", "(", "data_path", "+", "'artificial_raw.csv'", ")", "\n", "df_raw", ".", "columns", "=", "df_raw", ".", "columns", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "df_len", "]", "=", "df_raw", "[", "0", "]", ".", "shift", "(", "-", "1", ")", "\n", "df_raw", "=", "df_raw", ".", "dropna", "(", ")", "\n", "\n", "x", "=", "df", "[", "[", "0", ",", "1", "]", "]", ".", "to_numpy", "(", ")", "#np.reshape(df['raw_x'].tolist(), (-1, 1))", "\n", "y", "=", "df", "[", "[", "2", "]", "]", ".", "to_numpy", "(", ")", "\n", "x_true", "=", "df_raw", "[", "[", "0", ",", "1", "]", "]", ".", "to_numpy", "(", ")", "#np.reshape(df['raw_x'].tolist(), (-1, 1))", "\n", "y_true", "=", "df_raw", "[", "[", "2", "]", "]", ".", "to_numpy", "(", ")", "\n", "reg", "=", "LinearRegression", "(", ")", ".", "fit", "(", "x", ",", "y", ")", "\n", "y_pred", "=", "reg", ".", "predict", "(", "x_true", ")", "\n", "print", "(", "'%s_train_mse'", "%", "data_name", ",", "mean_squared_error", "(", "y_true", ",", "y_pred", ")", ")", "\n", "# print('real_train_rmse', mean_squared_error(real_y, pred_y, squared=False))", "\n", "", "mse_x", "(", "'raw'", ")", "\n", "mse_x", "(", "'tfs_a'", ")", "\n", "mse_x", "(", "'tfs_b'", ")", "\n", "mse_x", "(", "'b1'", ")", "\n", "mse_x", "(", "'b4'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.JS": [[4, 15], ["scipy.stats.entropy", "zip", "scipy.stats.entropy", "scipy.stats.entropy", "scipy.stats.entropy", "input"], "function", ["None"], ["def", "JS", "(", "pk", ",", "qk", ",", "KL", "=", "None", ")", ":", "\n", "    ", "if", "KL", "is", "None", ":", "\n", "        ", "avgk", "=", "[", "(", "x", "+", "y", ")", "/", "2", "for", "x", ",", "y", "in", "zip", "(", "pk", ",", "qk", ")", "]", "\n", "JS", "=", "(", "scipy", ".", "stats", ".", "entropy", "(", "pk", ",", "avgk", ")", "+", "scipy", ".", "stats", ".", "entropy", "(", "qk", ",", "avgk", ")", ")", "/", "2", "\n", "", "elif", "KL", "is", "True", ":", "\n", "        ", "JS", "=", "scipy", ".", "stats", ".", "entropy", "(", "pk", ",", "qk", ")", "\n", "", "elif", "KL", "is", "False", ":", "\n", "        ", "JS", "=", "scipy", ".", "stats", ".", "entropy", "(", "qk", ",", "pk", ")", "\n", "", "else", ":", "\n", "        ", "input", "(", "\"Error: JS param bug.\"", ")", "\n", "", "return", "JS", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.gd": [[16, 26], ["list", "pandas.cut", "list", "metric_utils.get_distribution_with_laplace_smoothing", "pd.cut.value_counts"], "function", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.get_distribution_with_laplace_smoothing"], ["", "def", "gd", "(", "pd_data", ",", "bins", "=", "304", ")", ":", "\n", "#values1 = list(np.log(pd_data.byt))", "\n", "    ", "values1", "=", "list", "(", "pd_data", ")", "\n", "#print(values1)", "\n", "cats1", "=", "pd", ".", "cut", "(", "values1", ",", "bins", ")", "\n", "pr1", "=", "list", "(", "cats1", ".", "value_counts", "(", ")", ")", "\n", "# print(pr1)", "\n", "#pk = get_distribution(pr1)", "\n", "pk", "=", "get_distribution_with_laplace_smoothing", "(", "pr1", ")", "\n", "return", "pk", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.get_distribution_with_laplace_smoothing": [[27, 37], ["sum", "len", "p.append"], "function", ["None"], ["", "def", "get_distribution_with_laplace_smoothing", "(", "a_count", ")", ":", "\n", "    ", "k", "=", "1.0", "\n", "tot_k", "=", "len", "(", "a_count", ")", "*", "k", "\n", "sum_count", "=", "sum", "(", "a_count", ")", "\n", "p", "=", "[", "]", "\n", "for", "component", "in", "a_count", ":", "\n", "        ", "adj_component", "=", "(", "component", "+", "k", ")", "/", "(", "sum_count", "+", "tot_k", ")", "\n", "p", ".", "append", "(", "adj_component", ")", "\n", "# print('laplace_smoothing:\\n', len(a_count), sum(a_count), sum(p), max(p), min(p))", "\n", "", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.metric_utils.get_distribution": [[38, 46], ["sum", "p.append"], "function", ["None"], ["", "def", "get_distribution", "(", "a_count", ")", ":", "\n", "    ", "sum_count", "=", "sum", "(", "a_count", ")", "\n", "p", "=", "[", "]", "\n", "for", "component", "in", "a_count", ":", "\n", "        ", "adj_component", "=", "component", "/", "sum_count", "\n", "p", ".", "append", "(", "adj_component", ")", "\n", "# print('get_distribution:\\n', len(a_count), sum(a_count), sum(p), max(p), min(p))", "\n", "", "return", "p", "\n", "", ""]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_classifier.Net.__init__": [[16, 22], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_feature", ",", "n_hidden", ",", "n_output", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden", "=", "torch", ".", "nn", ".", "Linear", "(", "n_feature", ",", "n_hidden", ")", "# hidden layer", "\n", "#self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer", "\n", "#self.hidden3 = torch.nn.Linear(n_hidden*2, n_hidden)   # hidden layer", "\n", "self", ".", "predict", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_output", ")", "# output layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_classifier.Net.forward": [[23, 29], ["torch.relu", "torch.relu", "torch.relu", "nn_classifier.Net.predict", "nn_classifier.Net.hidden"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.predict"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "#x = F.relu(self.hidden2(x))      # activation function for hidden layer", "\n", "#x = F.relu(self.hidden3(x))      # activation function for hidden layer", "\n", "x", "=", "self", ".", "predict", "(", "x", ")", "# linear output", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_classifier.task1_classifier.__init__": [[33, 39], ["nn_classifier.Net", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "nn_classifier.task1_classifier.net.to", "sklearn.preprocessing.MinMaxScaler"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "net", "=", "Net", "(", "n_feature", "=", "5", ",", "n_hidden", "=", "50", ",", "n_output", "=", "3", ")", "\n", "self", ".", "net", "=", "torch", ".", "nn", ".", "DataParallel", "(", "self", ".", "net", ")", "\n", "self", ".", "net", "=", "self", ".", "net", ".", "to", "(", "device", ")", "\n", "#print(net)  # net architecture", "\n", "self", ".", "min_max_scaler", "=", "MinMaxScaler", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_classifier.task1_classifier.scale": [[40, 47], ["pandas.concat", "nn_classifier.task1_classifier.min_max_scaler.fit"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.fit"], ["", "def", "scale", "(", "self", ",", "train_X", ",", "test_X", ")", ":", "\n", "#print(train_X.columns)", "\n", "#print(test_X.columns)", "\n", "#input()", "\n", "        ", "all_X", "=", "pd", ".", "concat", "(", "[", "train_X", ",", "test_X", "]", ",", "axis", "=", "0", ",", "sort", "=", "False", ")", "\n", "self", ".", "min_max_scaler", ".", "fit", "(", "all_X", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_classifier.task1_classifier.fit": [[48, 85], ["nn_classifier.task1_classifier.min_max_scaler.transform", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "nn_classifier.task1_classifier.net.parameters", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "batch_x.to.to.to", "batch_y.to.to.to", "torch.optim.SGD.zero_grad", "torch.optim.SGD.zero_grad", "torch.optim.SGD.zero_grad", "nn_classifier.task1_classifier.net", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "print", "torch.nn.CrossEntropyLoss.backward", "torch.optim.SGD.step", "torch.optim.SGD.step", "torch.optim.SGD.step", "batch_y.to.to.long().squeeze", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "batch_y.to.to.long"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "train_X", ",", "train_y", ",", "epochs", "=", "100", ")", ":", "\n", "        ", "x", "=", "self", ".", "min_max_scaler", ".", "transform", "(", "train_X", ")", "\n", "#x = train_X.to_numpy()", "\n", "\n", "#train_target = torch.tensor(train_y.values.astype(np.float32))", "\n", "#train = torch.tensor(train_X.values.astype(np.float32)) ", "\n", "#train_tensor = data_utils.TensorDataset(train) ", "\n", "#train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", "#.to(device)", "\n", "y", "=", "torch", ".", "from_numpy", "(", "train_y", ".", "values", ")", ".", "float", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "#.to(device)", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "net", ".", "parameters", "(", ")", ",", "lr", "=", "0.02", ")", "\n", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "# this is for regression mean squared loss", "\n", "batch_size", "=", "25600", "\n", "train", "=", "torch", ".", "utils", ".", "data", ".", "TensorDataset", "(", "x", ",", "y", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "8", ",", "pin_memory", "=", "True", ")", "\n", "\n", "for", "t", "in", "range", "(", "epochs", ")", ":", "\n", "            ", "for", "step", ",", "(", "batch_x", ",", "batch_y", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "                ", "batch_x", "=", "batch_x", ".", "to", "(", "device", ")", "\n", "batch_y", "=", "batch_y", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "prediction", "=", "self", ".", "net", "(", "batch_x", ")", "# input x and predict based on x", "\n", "#print(y, type(y))", "\n", "loss", "=", "loss_func", "(", "prediction", ",", "batch_y", ".", "long", "(", ")", ".", "squeeze", "(", "1", ")", ")", "# must be (1. nn output, 2. target)", "\n", "print", "(", "t", ",", "loss", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "# backpropagation, compute gradients", "\n", "optimizer", ".", "step", "(", ")", "# apply gradients", "\n", "\n", "#if t % 5 == 0:", "\n", "#    # plot and show learning process", "\n", "#    plt.cla()", "\n", "#    plt.scatter(x.data.numpy(), y.data.numpy())", "\n", "#    plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)", "\n", "#    plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color':  'red'})", "\n", "#    plt.pause(0.1)", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_classifier.task1_classifier.predict": [[86, 93], ["nn_classifier.task1_classifier.min_max_scaler.transform", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "nn_classifier.task1_classifier.net", "[].long", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "test_X", ")", ":", "\n", "        ", "x", "=", "self", ".", "min_max_scaler", ".", "transform", "(", "test_X", ")", "\n", "#x = test_X.to_numpy()", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "prediction", "=", "self", ".", "net", "(", "x", ")", "\n", "#print(prediction)", "\n", "return", "torch", ".", "max", "(", "prediction", ",", "1", ")", "[", "1", "]", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.validation_utils.ip_split": [[3, 16], ["df[].str.split", "range", "df.drop", "new[].astype"], "function", ["None"], ["def", "ip_split", "(", "df", ",", "col_name", ",", "norm", "=", "False", ")", ":", "\n", "# new data frame with split value columns", "\n", "    ", "new", "=", "df", "[", "col_name", "]", ".", "str", ".", "split", "(", "\".\"", ",", "expand", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "# making separate first name column from new data frame", "\n", "        ", "if", "norm", ":", "\n", "            ", "new", "[", "i", "]", "=", "new", "[", "i", "]", ".", "astype", "(", "int", ")", "/", "255.0", "\n", "", "df", "[", "col_name", "+", "\"_%d\"", "%", "i", "]", "=", "new", "[", "i", "]", "\n", "\n", "\n", "# Dropping old Name columns", "\n", "", "df", ".", "drop", "(", "columns", "=", "[", "col_name", "]", ",", "inplace", "=", "True", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.validation_utils.hms_to_second": [[17, 27], ["isinstance", "print", "len", "datetime.datetime.strptime", "datetime.datetime.strptime", "float"], "function", ["None"], ["", "def", "hms_to_second", "(", "te_str", ")", ":", "\n", "    ", "if", "isinstance", "(", "te_str", ",", "int", ")", ":", "\n", "        ", "return", "te_str", "*", "3600", "/", "86400", "\n", "", "if", "len", "(", "te_str", ")", ">", "10", ":", "\n", "        ", "datetime_object", "=", "datetime", ".", "strptime", "(", "te_str", ",", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "", "else", ":", "\n", "        ", "datetime_object", "=", "datetime", ".", "strptime", "(", "te_str", ",", "\"%H:%M:%S\"", ")", "\n", "", "seconds", "=", "float", "(", "datetime_object", ".", "hour", "*", "3600.0", "+", "datetime_object", ".", "minute", "*", "60.0", "+", "datetime_object", ".", "second", ")", "/", "86400.0", "\n", "print", "(", "te_str", ",", "datetime_object", ",", "seconds", ")", "\n", "return", "seconds", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.Net.__init__": [[15, 19], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_feature", ",", "n_hidden", ",", "n_output", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden", "=", "torch", ".", "nn", ".", "Linear", "(", "n_feature", ",", "n_hidden", ")", "# hidden layer", "\n", "self", ".", "predict", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_output", ")", "# output layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.Net.forward": [[20, 24], ["torch.relu", "torch.relu", "nn_regressor.Net.predict", "nn_regressor.Net.hidden"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.predict"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "x", "=", "self", ".", "predict", "(", "x", ")", "# linear output", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.__init__": [[28, 32], ["Net().to", "sklearn.preprocessing.MinMaxScaler", "nn_regressor.Net"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "net", "=", "Net", "(", "n_feature", "=", "25", ",", "n_hidden", "=", "100", ",", "n_output", "=", "1", ")", ".", "to", "(", "device", ")", "\n", "#print(net)  # net architecture", "\n", "self", ".", "min_max_scaler", "=", "MinMaxScaler", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.scale": [[33, 40], ["pandas.concat", "nn_regressor.task2_regressor.min_max_scaler.fit"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.fit"], ["", "def", "scale", "(", "self", ",", "train_X", ",", "test_X", ")", ":", "\n", "#print(train_X.columns)", "\n", "#print(test_X.columns)", "\n", "#input()", "\n", "        ", "all_X", "=", "pd", ".", "concat", "(", "[", "train_X", ",", "test_X", "]", ",", "axis", "=", "0", ",", "sort", "=", "False", ")", "\n", "self", ".", "min_max_scaler", ".", "fit", "(", "all_X", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.fit": [[41, 70], ["nn_regressor.task2_regressor.min_max_scaler.transform", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().reshape().to", "torch.from_numpy().float().reshape().to", "torch.from_numpy().float().reshape().to", "torch.from_numpy().float().reshape().to", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "range", "nn_regressor.task2_regressor.net.parameters", "nn_regressor.task2_regressor.net", "torch.nn.MSELoss.", "torch.nn.MSELoss.", "torch.optim.SGD.zero_grad", "torch.optim.SGD.zero_grad", "torch.nn.MSELoss.backward", "torch.optim.SGD.step", "torch.optim.SGD.step", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy().float().reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "train_X", ",", "train_y", ",", "epochs", "=", "200", ")", ":", "\n", "        ", "x", "=", "self", ".", "min_max_scaler", ".", "transform", "(", "train_X", ")", "\n", "#train_target = torch.tensor(train_y.values.astype(np.float32))", "\n", "#train = torch.tensor(train_X.values.astype(np.float32)) ", "\n", "#train_tensor = data_utils.TensorDataset(train) ", "\n", "#train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "y", "=", "torch", ".", "from_numpy", "(", "train_y", ".", "values", ")", ".", "float", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "net", ".", "parameters", "(", ")", ",", "lr", "=", "0.2", ")", "\n", "loss_func", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "# this is for regression mean squared loss", "\n", "\n", "for", "t", "in", "range", "(", "epochs", ")", ":", "\n", "            ", "prediction", "=", "self", ".", "net", "(", "x", ")", "# input x and predict based on x", "\n", "\n", "loss", "=", "loss_func", "(", "prediction", ",", "y", ")", "# must be (1. nn output, 2. target)", "\n", "#print(t, loss)", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "# clear gradients for next train", "\n", "loss", ".", "backward", "(", ")", "# backpropagation, compute gradients", "\n", "optimizer", ".", "step", "(", ")", "# apply gradients", "\n", "\n", "#if t % 5 == 0:", "\n", "#    # plot and show learning process", "\n", "#    plt.cla()", "\n", "#    plt.scatter(x.data.numpy(), y.data.numpy())", "\n", "#    plt.plot(x.data.numpy(), prediction.data.numpy(), 'r-', lw=5)", "\n", "#    plt.text(0.5, 0, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color':  'red'})", "\n", "#    plt.pause(0.1)", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.task_model.nn_regressor.task2_regressor.predict": [[71, 76], ["nn_regressor.task2_regressor.min_max_scaler.transform", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "nn_regressor.task2_regressor.net().cpu().detach().numpy", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "nn_regressor.task2_regressor.net().cpu().detach", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "nn_regressor.task2_regressor.net().cpu", "nn_regressor.task2_regressor.net"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "test_X", ")", ":", "\n", "        ", "x", "=", "self", ".", "min_max_scaler", ".", "transform", "(", "test_X", ")", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "prediction", "=", "self", ".", "net", "(", "x", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "return", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.__init__": [[12, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "weight_list", ")", ":", "\n", "        ", "self", ".", "weight_list", "=", "weight_list", "\n", "self", ".", "df_naive", "=", "None", "\n", "self", ".", "X", ",", "self", ".", "y", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample": [[17, 20], ["datamaker.artificial_data_generator._gen_continuous"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator._gen_continuous"], ["", "def", "sample", "(", "self", ",", "row_num", "=", "10000", ")", ":", "\n", "        ", "self", ".", "df_naive", "=", "self", ".", "_gen_continuous", "(", "row_num", ",", "self", ".", "weight_list", ")", "\n", "return", "self", ".", "df_naive", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.agg": [[21, 26], ["datamaker.artificial_data_generator._agg_window"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator._agg_window"], ["", "def", "agg", "(", "self", ",", "agg", "=", "None", ")", ":", "\n", "        ", "if", "agg", "is", "None", ":", "\n", "            ", "return", "None", ",", "None", "\n", "", "self", ".", "X", ",", "self", ".", "y", "=", "self", ".", "_agg_window", "(", "self", ".", "df_naive", ",", "agg", ")", "\n", "return", "self", ".", "X", ",", "self", ".", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator._gen_continuous": [[27, 44], ["torch.distributions.Normal", "torch.distributions.Normal", "range", "pandas.DataFrame.from_records", "rt.append", "samp.append", "samp.append", "samp.append", "torch.distributions.Normal.sample().tolist", "torch.distributions.Normal.sample().tolist", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample().tolist", "torch.distributions.Normal.sample().tolist", "torch.distributions.Normal.sample().tolist", "torch.distributions.Normal.sample().tolist", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample", "torch.distributions.Normal.sample"], "methods", ["home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample", "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator.sample"], ["", "def", "_gen_continuous", "(", "self", ",", "row_num", ",", "weight_list", "=", "[", "]", ")", ":", "\n", "        ", "noise", "=", "Normal", "(", "0", ",", "1", ")", "\n", "row_dep", "=", "weight_list", "[", "0", "]", "\n", "\n", "rt", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "row_num", ")", ":", "\n", "            ", "samp", "=", "[", "]", "\n", "if", "i", "==", "0", ":", "\n", "                ", "samp", ".", "append", "(", "noise", ".", "sample", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "samp", ".", "append", "(", "row_dep", "*", "rt", "[", "-", "1", "]", "[", "0", "]", "+", "(", "1", "-", "row_dep", ")", "*", "noise", ".", "sample", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "for", "col_dep_i", "in", "weight_list", "[", "1", ":", "]", ":", "\n", "                ", "samp", ".", "append", "(", "col_dep_i", "*", "samp", "[", "-", "1", "]", "+", "(", "1", "-", "col_dep_i", ")", "*", "noise", ".", "sample", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "rt", ".", "append", "(", "samp", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", ".", "from_records", "(", "rt", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.ShengzheXu_stan.artificial.datamaker.artificial_data_generator._agg_window": [[45, 64], ["len", "df_naive.values.tolist", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "buffer.append", "torch.Tensor().view.append", "torch.Tensor().view.append", "torch.Tensor().view.append", "torch.Tensor().view.append", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "_agg_window", "(", "self", ",", "df_naive", ",", "agg_size", ")", ":", "\n", "        ", "col_num", "=", "len", "(", "df_naive", ".", "columns", ")", "\n", "buffer", "=", "[", "[", "0", "]", "*", "col_num", "]", "*", "agg_size", "\n", "X", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "\n", "list_naive", "=", "df_naive", ".", "values", ".", "tolist", "(", ")", "\n", "for", "row", "in", "list_naive", ":", "\n", "            ", "buffer", ".", "append", "(", "row", ")", "\n", "row_with_window", "=", "[", "]", "\n", "for", "r", "in", "buffer", "[", "-", "agg_size", "-", "1", ":", "]", ":", "\n", "                ", "row_with_window", "+=", "r", "\n", "", "X", ".", "append", "(", "row_with_window", ")", "\n", "y", ".", "append", "(", "row", ")", "\n", "\n", "\n", "", "X", "=", "torch", ".", "Tensor", "(", "X", ")", ".", "view", "(", "len", "(", "X", ")", ",", "-", "1", ",", "col_num", ")", "#col_num*(agg_size+1)", "\n", "y", "=", "torch", ".", "Tensor", "(", "y", ")", ".", "view", "(", "-", "1", ",", "col_num", ")", "\n", "\n", "return", "X", ",", "y", "", "", "", ""]]}