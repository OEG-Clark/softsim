{"home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_tf_reddit.output_filename": [[39, 45], ["os.path.expanduser", "os.path.join", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "output_filename", "(", ")", ":", "\n", "  ", "out_dir", "=", "os", ".", "path", ".", "expanduser", "(", "FLAGS", ".", "out_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "out_filename", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'reddit-%s-%s-%s.csv'", "%", "(", "FLAGS", ".", "model", ",", "FLAGS", ".", "fanout", ",", "FLAGS", ".", "run_id", ")", ")", "\n", "return", "out_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_tf_reddit.main": [[48, 139], ["tensorflow.keras.optimizers.Adam", "os.path.expanduser", "numpy.load", "tf.convert_to_tensor.mean", "tf.convert_to_tensor.std", "numpy.array", "tensorflow.convert_to_tensor", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "copy.deepcopy", "set", "set.update", "set", "framework.compact_adj.CompactAdjacency.from_file", "tensorflow.cast", "tensorflow.sparse.SparseTensor", "json.loads", "model_class", "timing.WallClockTimer", "timing.WallClockTimer.start", "range", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "np.load.max", "os.path.join", "numpy.stack", "int", "numpy.random.permutation", "tqdm.tqdm", "open", "fout.write", "print", "compact_adj.CompactAdjacency.from_file.adj.nonzero", "tensorflow.ones", "FLAGS.fanout.split", "range", "framework.traversals.np_traverse", "framework.accumulation.SampledAdjacency.from_walk_forest", "accumulation.SampledAdjacency.from_walk_forest.tf_trim_x", "tape.gradient", "tf.keras.optimizers.Adam.apply_gradients", "timing.WallClockTimer.stop", "print", "csv_out.append", "timing.WallClockTimer.start", "train_tf_reddit.output_filename", "FLAGS.model.split", "len", "tensorflow.GradientTape", "model_class.", "accumulation.SampledAdjacency.from_walk_forest.tf_untrim_gather", "tensorflow.reduce_mean", "tensorflow.add_n", "zip", "tensorflow.device", "model_class.", "tensorflow.reduce_mean().numpy", "tensorflow.argmax().numpy", "min", "train_tf_reddit.output_filename", "tensorflow.nn.softmax_cross_entropy_with_logits", "FLAGS.model.split", "tensorflow.reduce_mean", "tensorflow.argmax", "tensorflow.one_hot", "tensorflow.reduce_sum", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.gather", "tensorflow.one_hot", "tensorflow.gather"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.start", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.from_walk_forest", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.tf_trim_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.stop", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.start", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_reddit.output_filename", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.tf_untrim_gather", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_reddit.output_filename"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "opt", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "FLAGS", ".", "lr", ")", "#1e-3 is probably best #1e-4 gave 82%", "\n", "directory", "=", "os", ".", "path", ".", "expanduser", "(", "'~/data/graphs/reddit'", ")", "\n", "\n", "allx", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'feat_data.npy'", ")", ")", "\n", "allx", "-=", "allx", ".", "mean", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "allx", "/=", "allx", ".", "std", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "allx", "=", "np", ".", "array", "(", "allx", ",", "'float32'", ")", "\n", "allx", "=", "tf", ".", "convert_to_tensor", "(", "allx", ")", "\n", "ally", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'labels.npy'", ")", ")", "\n", "ally", "=", "ally", "[", ":", ",", "0", "]", "\n", "\n", "train_ids", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'train_ids.npy'", ")", ")", "\n", "val_ids", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'val_ids.npy'", ")", ")", "\n", "test_ids", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'test_ids.npy'", ")", ")", "\n", "\n", "trainy", "=", "copy", ".", "deepcopy", "(", "ally", ")", "\n", "trainy", "[", "val_ids", "]", "=", "-", "1", "\n", "trainy", "[", "test_ids", "]", "=", "-", "1", "\n", "\n", "\n", "train_id_set", "=", "set", "(", "train_ids", ")", "\n", "train_id_set", ".", "update", "(", "val_ids", ")", "\n", "test_id_set", "=", "set", "(", "test_ids", ")", "\n", "\n", "num_classes", "=", "ally", ".", "max", "(", ")", "+", "1", "\n", "\n", "c_adj", "=", "compact_adj", ".", "CompactAdjacency", ".", "from_file", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'cadj.npz'", ")", ")", "\n", "num_nodes", "=", "c_adj", ".", "adj", ".", "shape", "[", "0", "]", "\n", "eval_adj_tf", "=", "tf", ".", "cast", "(", "np", ".", "stack", "(", "c_adj", ".", "adj", ".", "nonzero", "(", ")", ",", "-", "1", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "eval_adj_tf", "=", "tf", ".", "sparse", ".", "SparseTensor", "(", "\n", "indices", "=", "eval_adj_tf", ",", "values", "=", "tf", ".", "ones", "(", "[", "eval_adj_tf", ".", "shape", "[", "0", "]", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "dense_shape", "=", "[", "num_nodes", ",", "num_nodes", "]", ")", "\n", "\n", "\n", "\n", "model_class", "=", "models_tf", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "0", "]", "]", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "1", "]", "]", "\n", "model_kwargs", "=", "json", ".", "loads", "(", "FLAGS", ".", "model_kwargs", ")", "\n", "gcn", "=", "model_class", "(", "num_classes", ",", "allx", ".", "shape", "[", "1", "]", ",", "**", "model_kwargs", ")", "\n", "least_validate_loss", "=", "(", "99999999", ",", "0", ")", "# (Validate loss, test accuracy)", "\n", "fanouts", "=", "[", "int", "(", "f", ")", "for", "f", "in", "FLAGS", ".", "fanout", ".", "split", "(", "'x'", ")", "]", "\n", "\n", "first_batch_offset", "=", "None", "\n", "timer", "=", "timing", ".", "WallClockTimer", "(", ")", "\n", "timer", ".", "start", "(", ")", "# Will be stopped only when evaluating test accuracy.", "\n", "csv_out", "=", "[", "'epoch,time,accuracy'", "]", "\n", "for", "epoch", "in", "range", "(", "FLAGS", ".", "epochs", ")", ":", "\n", "    ", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "train_ids", ")", "\n", "tt", "=", "tqdm", ".", "tqdm", "(", "range", "(", "0", ",", "len", "(", "permutation", ")", ",", "FLAGS", ".", "batch_size", ")", ")", "\n", "for", "starti", "in", "tt", ":", "\n", "      ", "endi", "=", "starti", "+", "FLAGS", ".", "batch_size", "\n", "batch", "=", "permutation", "[", "starti", ":", "endi", "]", "\n", "forest", "=", "traversals", ".", "np_traverse", "(", "c_adj", ",", "batch", ",", "fanouts", "=", "fanouts", ")", "\n", "dense_shape", "=", "(", "num_nodes", ",", "num_nodes", ")", "\n", "sampled_adj", "=", "accumulation", ".", "SampledAdjacency", ".", "from_walk_forest", "(", "forest", ",", "dense_shape", ")", "\n", "trimmed_adj", "=", "sampled_adj", ".", "tf_trimmed", "\n", "trimmed_x", "=", "sampled_adj", ".", "tf_trim_x", "(", "allx", ")", "\n", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "tape", ":", "\n", "        ", "output", "=", "gcn", "(", "trimmed_x", ",", "trimmed_adj", ")", "\n", "labeled_logits", "=", "sampled_adj", ".", "tf_untrim_gather", "(", "output", ",", "batch", ")", "\n", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "tf", ".", "one_hot", "(", "ally", "[", "batch", "]", ",", "num_classes", ")", ",", "logits", "=", "labeled_logits", ")", ")", "\n", "variables", "=", "gcn", ".", "trainable_variables", "\n", "loss", "+=", "tf", ".", "add_n", "(", "[", "tf", ".", "reduce_sum", "(", "v", "**", "2", ")", "*", "FLAGS", ".", "l2_reg", "for", "v", "in", "variables", "]", ")", "# if 'kernel' in v.name", "\n", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "variables", ")", "\n", "opt", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "variables", ")", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "FLAGS", ".", "eval_every", "==", "0", ":", "\n", "      ", "timer", ".", "stop", "(", ")", "\n", "with", "tf", ".", "device", "(", "'cpu:0'", ")", ":", "\n", "        ", "output", "=", "gcn", "(", "allx", ",", "eval_adj_tf", ",", "training", "=", "False", ")", "\n", "vloss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "tf", ".", "one_hot", "(", "ally", "[", "val_ids", "]", ",", "num_classes", ")", ",", "\n", "logits", "=", "tf", ".", "gather", "(", "output", ",", "val_ids", ")", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "preds", "=", "tf", ".", "argmax", "(", "tf", ".", "gather", "(", "output", ",", "test_ids", ")", ",", "1", ")", ".", "numpy", "(", ")", "\n", "test_accuracy", "=", "(", "preds", "==", "ally", "[", "test_ids", "]", ")", ".", "mean", "(", ")", "\n", "least_validate_loss", "=", "min", "(", "least_validate_loss", ",", "(", "vloss", ",", "test_accuracy", ")", ")", "\n", "", "print", "(", "'%s-%s-%s] Test: %g (@ best validate=%g)'", "%", "(", "\n", "FLAGS", ".", "model", ",", "FLAGS", ".", "fanout", ",", "FLAGS", ".", "run_id", ",", "test_accuracy", ",", "least_validate_loss", "[", "1", "]", ")", ")", "\n", "first_batch_offset", "=", "first_batch_offset", "or", "timer", ".", "total", "\n", "csv_out", ".", "append", "(", "'%i,%f,%f'", "%", "(", "epoch", ",", "timer", ".", "total", "-", "first_batch_offset", ",", "least_validate_loss", "[", "1", "]", ")", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "", "", "with", "open", "(", "output_filename", "(", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "    ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "csv_out", ")", ")", "\n", "print", "(", "'wrote '", "+", "output_filename", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcn.main": [[36, 101], ["training_loops.datasets.read_planetoid_dataset", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "numpy.arange", "numpy.arange", "framework.compact_adj.CompactAdjacency", "utils.torch_utils.kipf_renorm_sp", "utils.torch_utils.sparse_mx_to_torch_sparse_tensor().to", "json.loads", "model_class", "gcn.to.to", "tqdm.tqdm", "print", "torch.max", "torch.max", "torch.max", "torch.Adam", "torch.Adam", "int", "range", "framework.traversals.np_traverse", "framework.accumulation.SampledAdjacency.from_walk_forest", "utils.torch_utils.kipf_renorm_sp", "utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "trimmed_adj.to.to", "accumulation.SampledAdjacency.from_walk_forest.torch_trim_x", "trimmed_x.to.to", "gcn.to.train", "optim.Adam.zero_grad", "gcn.to.", "F.nll_loss.backward", "optim.Adam.step", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "gcn.to.parameters", "gcn.to.parameters", "FLAGS.fanout.split", "torch.cross_entropy", "torch.log_softmax", "torch.nll_loss", "gcn.to.eval", "gcn.to.", "torch.nll_loss().detach().cpu().numpy", "[].detach().cpu().numpy", "min", "tqdm.tqdm.set_description", "torch.from_numpy().to.todense", "FLAGS.model.split", "FLAGS.model.split", "accumulation.SampledAdjacency.from_walk_forest.torch_untrim_gather", "accumulation.SampledAdjacency.from_walk_forest.torch_untrim_gather", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.nll_loss().detach().cpu", "[].detach().cpu", "FLAGS.model.split", "ally[].argmax", "torch.nll_loss().detach", "[].detach", "torch.nll_loss", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.read_planetoid_dataset", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.kipf_renorm_sp", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.from_walk_forest", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.kipf_renorm_sp", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_trim_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_untrim_gather", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_untrim_gather"], ["def", "main", "(", "_", ")", ":", "\n", "  ", "if", "FLAGS", ".", "device", "==", "\"cuda\"", "and", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "    ", "print", "(", "\"Warning: CUDA not available, using CPU.\"", ")", "\n", "FLAGS", ".", "device", "=", "\"cpu\"", "\n", "", "adj", ",", "allx", ",", "ally", ",", "test_id", "=", "datasets", ".", "read_planetoid_dataset", "(", "dataset_name", "=", "FLAGS", ".", "gcn_dataset", ")", "\n", "allx", "=", "torch", ".", "from_numpy", "(", "allx", ".", "todense", "(", ")", ")", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "num_nodes", "=", "allx", ".", "shape", "[", "0", "]", "\n", "num_classes", "=", "ally", ".", "shape", "[", "1", "]", "\n", "labeled_nodes", "=", "np", ".", "arange", "(", "20", "*", "num_classes", ",", "dtype", "=", "'int32'", ")", "# Planetoid", "\n", "validate_idx", "=", "np", ".", "arange", "(", "20", "*", "num_classes", ",", "20", "*", "num_classes", "+", "500", ",", "dtype", "=", "'int32'", ")", "\n", "labels", "=", "torch", ".", "max", "(", "torch", ".", "LongTensor", "(", "ally", ")", ".", "to", "(", "FLAGS", ".", "device", ")", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "\n", "c_adj", "=", "compact_adj", ".", "CompactAdjacency", "(", "adj", ")", "\n", "eval_adj", "=", "torch_utils", ".", "kipf_renorm_sp", "(", "adj", ")", "\n", "eval_adj_torch", "=", "torch_utils", ".", "sparse_mx_to_torch_sparse_tensor", "(", "eval_adj", ")", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "\n", "model_class", "=", "models_pytorch", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "0", "]", "]", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "1", "]", "]", "\n", "model_kwargs", "=", "json", ".", "loads", "(", "FLAGS", ".", "model_kwargs", ")", "\n", "gcn", "=", "model_class", "(", "num_classes", ",", "allx", ".", "shape", "[", "1", "]", ",", "**", "model_kwargs", ")", "\n", "gcn", "=", "gcn", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "if", "FLAGS", ".", "l2_reg", ">", "0", ":", "\n", "    ", "optimizer", "=", "optim", ".", "Adam", "(", "gcn", ".", "parameters", "(", ")", ",", "lr", "=", "FLAGS", ".", "lr", ",", "weight_decay", "=", "FLAGS", ".", "l2_reg", ")", "\n", "", "else", ":", "\n", "    ", "optimizer", "=", "optim", ".", "Adam", "(", "gcn", ".", "parameters", "(", ")", ",", "lr", "=", "FLAGS", ".", "lr", ")", "\n", "\n", "\n", "", "least_validate_loss", "=", "(", "99999999", ",", "0", ")", "# (Validate loss, test accuracy)", "\n", "fanouts", "=", "[", "int", "(", "f", ")", "for", "f", "in", "FLAGS", ".", "fanout", ".", "split", "(", "'x'", ")", "]", "\n", "\n", "tt", "=", "tqdm", ".", "tqdm", "(", "range", "(", "FLAGS", ".", "epochs", ")", ")", "\n", "for", "epoch", "in", "tt", ":", "\n", "    ", "forest", "=", "traversals", ".", "np_traverse", "(", "c_adj", ",", "labeled_nodes", ",", "fanouts", "=", "fanouts", ")", "\n", "dense_shape", "=", "(", "num_nodes", ",", "num_nodes", ")", "\n", "sampled_adj", "=", "accumulation", ".", "SampledAdjacency", ".", "from_walk_forest", "(", "forest", ",", "dense_shape", ")", "\n", "trimmed_adj", "=", "sampled_adj", ".", "csr_trimmed", "\n", "trimmed_adj", "=", "torch_utils", ".", "kipf_renorm_sp", "(", "trimmed_adj", ")", "\n", "trimmed_adj", "=", "torch_utils", ".", "sparse_mx_to_torch_sparse_tensor", "(", "trimmed_adj", ")", "\n", "trimmed_adj", "=", "trimmed_adj", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "trimmed_x", "=", "sampled_adj", ".", "torch_trim_x", "(", "allx", ")", "\n", "trimmed_x", "=", "trimmed_x", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "\n", "# Optimization step", "\n", "gcn", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "gcn_output", "=", "gcn", "(", "trimmed_x", ",", "trimmed_adj", ")", "\n", "\n", "if", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "1", "]", "==", "'SGC'", ":", "# THIS IS A HACK. SHOULD BE REFACTORED", "\n", "# Isn't this equivalent to the else-clause?", "\n", "      ", "loss_train", "=", "F", ".", "cross_entropy", "(", "sampled_adj", ".", "torch_untrim_gather", "(", "gcn_output", ",", "labeled_nodes", ")", ",", "labels", "[", "labeled_nodes", "]", ")", "\n", "", "else", ":", "\n", "      ", "logits", "=", "F", ".", "log_softmax", "(", "gcn_output", ",", "dim", "=", "1", ")", "\n", "loss_train", "=", "F", ".", "nll_loss", "(", "sampled_adj", ".", "torch_untrim_gather", "(", "logits", ",", "labeled_nodes", ")", ",", "labels", "[", "labeled_nodes", "]", ")", "\n", "", "loss_train", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "epoch", "%", "FLAGS", ".", "eval_every", "==", "0", ":", "\n", "#timer.stop()", "\n", "      ", "gcn", ".", "eval", "(", ")", "\n", "output", "=", "gcn", "(", "allx", ",", "eval_adj_torch", ")", "\n", "vloss", "=", "F", ".", "nll_loss", "(", "output", "[", "validate_idx", "]", ",", "labels", "[", "validate_idx", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "preds", "=", "torch", ".", "max", "(", "output", "[", "test_id", "]", ",", "1", ")", "[", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "test_accuracy", "=", "(", "preds", "==", "ally", "[", "test_id", "]", ".", "argmax", "(", "1", ")", ")", ".", "mean", "(", ")", "\n", "least_validate_loss", "=", "min", "(", "least_validate_loss", ",", "(", "vloss", ",", "test_accuracy", ")", ")", "\n", "tt", ".", "set_description", "(", "'Test: %g (@ best validate=%g)'", "%", "(", "test_accuracy", ",", "least_validate_loss", "[", "1", "]", ")", ")", "\n", "#first_batch_offset = first_batch_offset or timer.total", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_reddit.output_filename": [[45, 51], ["os.path.expanduser", "os.path.join", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "output_filename", "(", ")", ":", "\n", "  ", "out_dir", "=", "os", ".", "path", ".", "expanduser", "(", "FLAGS", ".", "out_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "out_filename", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'reddit-%s-%s-%s.csv'", "%", "(", "FLAGS", ".", "model", ",", "FLAGS", ".", "fanout", ",", "FLAGS", ".", "run_id", ")", ")", "\n", "return", "out_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_reddit.main": [[53, 164], ["os.path.expanduser", "numpy.load", "torch.from_numpy().to.mean", "torch.from_numpy().to.std", "numpy.array", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "copy.deepcopy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "set", "set.update", "set", "framework.compact_adj.CompactAdjacency.from_file", "utils.torch_utils.kipf_renorm_sp", "utils.torch_utils.sparse_mx_to_torch_sparse_tensor().to", "json.loads", "model_class", "gcn.to.to", "timing.WallClockTimer", "timing.WallClockTimer.start", "range", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "np.load.max", "os.path.join", "torch.Adam", "torch.Adam", "int", "numpy.random.permutation", "tqdm.tqdm", "open", "fout.write", "print", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "gcn.to.parameters", "gcn.to.parameters", "FLAGS.fanout.split", "range", "framework.traversals.np_traverse", "framework.accumulation.SampledAdjacency.from_walk_forest", "utils.torch_utils.kipf_renorm_sp", "utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "trimmed_adj.to.to", "accumulation.SampledAdjacency.from_walk_forest.torch_trim_x", "trimmed_x.to.to", "gcn.to.train", "optim.Adam.zero_grad", "gcn.to.", "torch.nll_loss", "F.nll_loss.backward", "optim.Adam.step", "timing.WallClockTimer.stop", "gcn.to.to", "gcn.to.eval", "gcn.to.", "torch.nll_loss().detach().cpu().numpy", "[].detach().cpu().numpy", "min", "print", "csv_out.append", "gcn.to.to", "timing.WallClockTimer.start", "train_torch_reddit.output_filename", "FLAGS.model.split", "len", "len", "torch.log_softmax", "train_torch_reddit.output_filename", "accumulation.SampledAdjacency.from_walk_forest.torch_untrim_gather", "torch.nll_loss().detach().cpu", "[].detach().cpu", "FLAGS.model.split", "torch.nll_loss().detach", "[].detach", "torch.nll_loss", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.kipf_renorm_sp", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.start", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.from_walk_forest", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.kipf_renorm_sp", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_trim_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.stop", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.start", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_reddit.output_filename", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_reddit.output_filename", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_untrim_gather"], ["", "def", "main", "(", "_", ")", ":", "\n", "\n", "  ", "directory", "=", "os", ".", "path", ".", "expanduser", "(", "'~/data/graphs/reddit'", ")", "\n", "\n", "allx", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'feat_data.npy'", ")", ")", "\n", "allx", "-=", "allx", ".", "mean", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "allx", "/=", "allx", ".", "std", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "allx", "=", "np", ".", "array", "(", "allx", ",", "'float32'", ")", "\n", "allx", "=", "torch", ".", "from_numpy", "(", "allx", ")", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "ally", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'labels.npy'", ")", ")", "\n", "ally", "=", "ally", "[", ":", ",", "0", "]", "\n", "\n", "train_ids", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'train_ids.npy'", ")", ")", "\n", "val_ids", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'val_ids.npy'", ")", ")", "\n", "test_ids", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'test_ids.npy'", ")", ")", "\n", "\n", "trainy", "=", "copy", ".", "deepcopy", "(", "ally", ")", "\n", "trainy", "[", "val_ids", "]", "=", "-", "1", "\n", "trainy", "[", "test_ids", "]", "=", "-", "1", "\n", "trainy", "=", "torch", ".", "from_numpy", "(", "trainy", ")", "\n", "valy", "=", "torch", ".", "from_numpy", "(", "ally", "[", "val_ids", "]", ")", "\n", "\n", "\n", "train_id_set", "=", "set", "(", "train_ids", ")", "\n", "train_id_set", ".", "update", "(", "val_ids", ")", "\n", "test_id_set", "=", "set", "(", "test_ids", ")", "\n", "\n", "num_classes", "=", "ally", ".", "max", "(", ")", "+", "1", "\n", "\n", "c_adj", "=", "compact_adj", ".", "CompactAdjacency", ".", "from_file", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'cadj.npz'", ")", ")", "\n", "num_nodes", "=", "c_adj", ".", "adj", ".", "shape", "[", "0", "]", "\n", "eval_adj", "=", "torch_utils", ".", "kipf_renorm_sp", "(", "c_adj", ".", "adj", ")", "\n", "eval_adj_torch", "=", "torch_utils", ".", "sparse_mx_to_torch_sparse_tensor", "(", "eval_adj", ")", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "\n", "\n", "model_class", "=", "models_pytorch", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "0", "]", "]", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "1", "]", "]", "\n", "model_kwargs", "=", "json", ".", "loads", "(", "FLAGS", ".", "model_kwargs", ")", "\n", "gcn", "=", "model_class", "(", "num_classes", ",", "allx", ".", "shape", "[", "1", "]", ",", "**", "model_kwargs", ")", "\n", "gcn", "=", "gcn", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "if", "FLAGS", ".", "l2_reg", ">", "0", ":", "\n", "    ", "optimizer", "=", "optim", ".", "Adam", "(", "gcn", ".", "parameters", "(", ")", ",", "lr", "=", "FLAGS", ".", "lr", ",", "weight_decay", "=", "FLAGS", ".", "l2_reg", ")", "\n", "", "else", ":", "\n", "    ", "optimizer", "=", "optim", ".", "Adam", "(", "gcn", ".", "parameters", "(", ")", ",", "lr", "=", "FLAGS", ".", "lr", ")", "\n", "", "least_validate_loss", "=", "(", "99999999", ",", "0", ")", "# (Validate loss, test accuracy)", "\n", "fanouts", "=", "[", "int", "(", "f", ")", "for", "f", "in", "FLAGS", ".", "fanout", ".", "split", "(", "'x'", ")", "]", "\n", "\n", "first_batch_offset", "=", "None", "\n", "timer", "=", "timing", ".", "WallClockTimer", "(", ")", "\n", "timer", ".", "start", "(", ")", "# Will be stopped only when evaluating test accuracy.", "\n", "csv_out", "=", "[", "'epoch,time,accuracy'", "]", "\n", "for", "epoch", "in", "range", "(", "FLAGS", ".", "epochs", ")", ":", "\n", "    ", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "train_ids", ")", "\n", "tt", "=", "tqdm", ".", "tqdm", "(", "range", "(", "0", ",", "len", "(", "permutation", ")", ",", "FLAGS", ".", "batch_size", ")", ")", "\n", "for", "starti", "in", "tt", ":", "\n", "      ", "endi", "=", "starti", "+", "FLAGS", ".", "batch_size", "\n", "if", "endi", ">", "len", "(", "permutation", ")", ":", "\n", "        ", "continue", "\n", "", "batch", "=", "permutation", "[", "starti", ":", "endi", "]", "\n", "forest", "=", "traversals", ".", "np_traverse", "(", "c_adj", ",", "batch", ",", "fanouts", "=", "fanouts", ")", "\n", "dense_shape", "=", "(", "num_nodes", ",", "num_nodes", ")", "\n", "sampled_adj", "=", "accumulation", ".", "SampledAdjacency", ".", "from_walk_forest", "(", "forest", ",", "dense_shape", ")", "\n", "trimmed_adj", "=", "sampled_adj", ".", "csr_trimmed", "\n", "trimmed_adj", "=", "torch_utils", ".", "kipf_renorm_sp", "(", "trimmed_adj", ")", "\n", "trimmed_adj", "=", "torch_utils", ".", "sparse_mx_to_torch_sparse_tensor", "(", "trimmed_adj", ")", "\n", "trimmed_adj", "=", "trimmed_adj", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "trimmed_x", "=", "sampled_adj", ".", "torch_trim_x", "(", "allx", ")", "\n", "trimmed_x", "=", "trimmed_x", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "\n", "gcn", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "gcn_output", "=", "gcn", "(", "trimmed_x", ",", "trimmed_adj", ")", "\n", "\n", "loss_train", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "sampled_adj", ".", "torch_untrim_gather", "(", "gcn_output", ",", "batch", ")", ",", "dim", "=", "1", ")", ",", "\n", "trainy", "[", "batch", "]", ")", "\n", "loss_train", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "FLAGS", ".", "eval_every", "==", "0", ":", "\n", "      ", "timer", ".", "stop", "(", ")", "\n", "gcn_cpu", "=", "gcn", ".", "to", "(", "'cpu'", ")", "\n", "gcn_cpu", ".", "eval", "(", ")", "\n", "output", "=", "gcn", "(", "allx", ",", "eval_adj_torch", ")", "\n", "\n", "vloss", "=", "F", ".", "nll_loss", "(", "output", "[", "val_ids", "]", ",", "valy", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "preds", "=", "torch", ".", "max", "(", "output", "[", "test_ids", "]", ",", "1", ")", "[", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "test_accuracy", "=", "(", "preds", "==", "ally", "[", "test_ids", "]", ")", ".", "mean", "(", ")", "\n", "least_validate_loss", "=", "min", "(", "least_validate_loss", ",", "(", "vloss", ",", "test_accuracy", ")", ")", "\n", "\"\"\"\n        output = gcn(allx, eval_adj_tf, training=False)\n        vloss = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(\n                labels=tf.one_hot(ally[val_ids], num_classes),\n                logits=tf.gather(output, val_ids))).numpy()\n\n        preds = tf.argmax(tf.gather(output, test_ids), 1).numpy()\n        test_accuracy = (preds == ally[test_ids]).mean()\n        least_validate_loss = min(least_validate_loss, (vloss, test_accuracy))\n      \"\"\"", "\n", "print", "(", "'%s-%s-%s] Test: %g (@ best validate=%g)'", "%", "(", "\n", "FLAGS", ".", "model", ",", "FLAGS", ".", "fanout", ",", "FLAGS", ".", "run_id", ",", "test_accuracy", ",", "least_validate_loss", "[", "1", "]", ")", ")", "\n", "first_batch_offset", "=", "first_batch_offset", "or", "timer", ".", "total", "\n", "csv_out", ".", "append", "(", "'%i,%f,%f'", "%", "(", "epoch", ",", "timer", ".", "total", "-", "first_batch_offset", ",", "least_validate_loss", "[", "1", "]", ")", ")", "\n", "gcn", ".", "to", "(", "FLAGS", ".", "device", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "", "", "with", "open", "(", "output_filename", "(", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "    ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "csv_out", ")", ")", "\n", "print", "(", "'wrote '", "+", "output_filename", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.__init__": [[7, 11], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "total_", "=", "0", "\n", "self", ".", "state_", "=", "0", "\n", "self", ".", "started_at_", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.start": [[12, 17], ["time.time", "ValueError"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "state_", "!=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'Each start() must be followed with stop() before next call to start()'", ")", "\n", "", "self", ".", "state_", "=", "1", "\n", "self", ".", "started_at_", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.stop": [[18, 24], ["time.time", "valueerror"], "methods", ["None"], ["", "def", "stop", "(", "self", ")", ":", "\n", "    ", "now", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "state_", "!=", "1", ":", "\n", "      ", "raise", "valueerror", "(", "'stop() must follow with start()'", ")", "\n", "", "self", ".", "state_", "=", "0", "\n", "self", ".", "total_", "+=", "now", "-", "self", ".", "started_at_", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.timing.WallClockTimer.total": [[25, 31], ["valueerror"], "methods", ["None"], ["", "@", "property", "\n", "def", "total", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "state_", "!=", "0", ":", "\n", "      ", "raise", "valueerror", "(", "'total must be called after stop()'", ")", "\n", "\n", "", "return", "self", ".", "total_", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_tf_skipgram.main": [[57, 100], ["data.asymproj_datasets.read_dataset", "scipy.csr_matrix", "framework.compact_adj.CompactAdjacency", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.keras.optimizers.Adam", "utils.common.IdBatcher", "tqdm.tqdm", "numpy.concatenate", "numpy.concatenate", "numpy.random.uniform", "set", "int", "range", "utils.common.IdBatcher.batch", "numpy.array", "framework.traversals.np_traverse", "tape.gradient", "tf.keras.optimizers.Adam.apply_gradients", "tf.Variable.numpy", "utils.common.sym_dot", "utils.common.sym_dot", "numpy.concatenate", "sklearn.metrics.roc_auc_score", "tqdm.tqdm.set_description", "numpy.ones", "FLAGS.fanout.split", "tensorflow.GradientTape", "models_tf.deepwalk.calculate_deepwalk_loss_on_forest", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.data.asymproj_datasets.read_dataset", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.IdBatcher.batch", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.deepwalk.calculate_deepwalk_loss_on_forest"], ["def", "main", "(", "_", ")", ":", "\n", "  ", "num_nodes", ",", "train_edges", ",", "test_pos_arr", ",", "test_neg_arr", ",", "is_directed", "=", "asymproj_datasets", ".", "read_dataset", "(", "FLAGS", ".", "dataset_dir", ")", "\n", "adj_rows", "=", "train_edges", "[", ":", ",", "0", "]", "\n", "adj_cols", "=", "train_edges", "[", ":", ",", "1", "]", "\n", "if", "not", "is_directed", ":", "\n", "    ", "adj_rows", "=", "np", ".", "concatenate", "(", "[", "adj_rows", ",", "train_edges", "[", ":", ",", "1", "]", "]", ",", "axis", "=", "0", ")", "\n", "adj_cols", "=", "np", ".", "concatenate", "(", "[", "adj_cols", ",", "train_edges", "[", ":", ",", "0", "]", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "csr_adj", "=", "sp", ".", "csr_matrix", "(", "\n", "(", "np", ".", "ones", "(", "len", "(", "adj_rows", ")", ",", "dtype", "=", "'int32'", ")", ",", "(", "adj_rows", ",", "adj_cols", ")", ")", ",", "\n", "shape", "=", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "cadj", "=", "compact_adj", ".", "CompactAdjacency", "(", "csr_adj", ")", "\n", "\n", "# Trainable embeddings.", "\n", "Z", "=", "tf", ".", "Variable", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0.01", ",", "high", "=", "0.01", ",", "size", "=", "[", "num_nodes", ",", "FLAGS", ".", "d", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'Y'", ")", "\n", "lr", "=", "tf", ".", "Variable", "(", "FLAGS", ".", "lr", ",", "name", "=", "'LR'", ")", "\n", "\n", "opt", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "lr", ",", "clipnorm", "=", "0.01", ")", "\n", "\n", "batcher", "=", "IdBatcher", "(", "set", "(", "adj_rows", ")", ")", "\n", "fanouts", "=", "[", "int", "(", "f", ")", "for", "f", "in", "FLAGS", ".", "fanout", ".", "split", "(", "'x'", ")", "]", "\n", "tt", "=", "tqdm", ".", "tqdm", "(", "range", "(", "FLAGS", ".", "steps", ")", ")", "\n", "for", "i", "in", "tt", ":", "\n", "    ", "seed_ids", "=", "batcher", ".", "batch", "(", "FLAGS", ".", "batch_size", ")", "\n", "seed_ids", "=", "np", ".", "array", "(", "seed_ids", ")", "\n", "forest", "=", "traversals", ".", "np_traverse", "(", "cadj", ",", "seed_ids", ",", "fanouts", ")", "\n", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "      ", "pos_loss", ",", "neg_loss", "=", "deepwalk", ".", "calculate_deepwalk_loss_on_forest", "(", "Z", ",", "forest", ",", "negative_samples", "=", "FLAGS", ".", "neg_samples", ")", "\n", "total_loss", "=", "FLAGS", ".", "pos_coeff", "*", "pos_loss", "+", "neg_loss", "\n", "\n", "", "gZ", "=", "tape", ".", "gradient", "(", "total_loss", ",", "Z", ")", "\n", "opt", ".", "apply_gradients", "(", "[", "(", "gZ", ",", "Z", ")", "]", ")", "\n", "\n", "## Eval", "\n", "npe", "=", "Z", ".", "numpy", "(", ")", "\n", "# test_accuracy = deepwalk_eval(npe, test_pos_arr, test_neg_arr)", "\n", "test_scores", "=", "sym_dot", "(", "npe", "[", "test_pos_arr", "[", ":", ",", "0", "]", "]", ",", "npe", "[", "test_pos_arr", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "\n", "test_neg_scores", "=", "sym_dot", "(", "npe", "[", "test_neg_arr", "[", ":", ",", "0", "]", "]", ",", "npe", "[", "test_neg_arr", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "\n", "test_y", "=", "[", "0", "]", "*", "len", "(", "test_neg_scores", ")", "+", "[", "1", "]", "*", "len", "(", "test_scores", ")", "\n", "test_y_pred", "=", "np", ".", "concatenate", "(", "[", "test_neg_scores", ",", "test_scores", "]", ",", "0", ")", "\n", "test_accuracy", "=", "metrics", ".", "roc_auc_score", "(", "test_y", ",", "test_y_pred", ")", "\n", "tt", ".", "set_description", "(", "'Test=%g'", "%", "test_accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_tf_gcn.main": [[31, 84], ["training_loops.datasets.read_planetoid_dataset", "tensorflow.keras.optimizers.Adam", "tensorflow.convert_to_tensor", "numpy.arange", "numpy.arange", "framework.compact_adj.CompactAdjacency", "tensorflow.cast", "tensorflow.sparse.SparseTensor", "json.loads", "model_class", "tqdm.tqdm", "tf.convert_to_tensor.todense", "numpy.stack", "int", "range", "framework.traversals.np_traverse", "framework.accumulation.SampledAdjacency.from_walk_forest", "accumulation.SampledAdjacency.from_walk_forest.tf_trim_x", "tape.gradient", "tf.keras.optimizers.Adam.apply_gradients", "compact_adj.CompactAdjacency.adj.nonzero", "tensorflow.ones", "FLAGS.fanout.split", "tensorflow.GradientTape", "model_class.", "accumulation.SampledAdjacency.from_walk_forest.tf_untrim_gather", "tensorflow.reduce_mean", "tensorflow.add_n", "zip", "model_class.", "tensorflow.reduce_mean().numpy", "tensorflow.argmax().numpy", "min", "tqdm.tqdm.set_description", "FLAGS.model.split", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.argmax", "FLAGS.model.split", "tensorflow.reduce_sum", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.gather", "ally[].argmax", "tensorflow.gather"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.read_planetoid_dataset", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.from_walk_forest", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.tf_trim_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.tf_untrim_gather"], ["def", "main", "(", "_", ")", ":", "\n", "  ", "adj", ",", "allx", ",", "ally", ",", "test_id", "=", "datasets", ".", "read_planetoid_dataset", "(", "dataset_name", "=", "FLAGS", ".", "gcn_dataset", ")", "\n", "opt", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "FLAGS", ".", "lr", ")", "#1e-3 is probably best #1e-4 gave 82%", "\n", "\n", "allx", "=", "tf", ".", "convert_to_tensor", "(", "allx", ".", "todense", "(", ")", ")", "\n", "num_nodes", "=", "allx", ".", "shape", "[", "0", "]", "\n", "num_classes", "=", "ally", ".", "shape", "[", "1", "]", "\n", "labeled_nodes", "=", "np", ".", "arange", "(", "20", "*", "num_classes", ",", "dtype", "=", "'int32'", ")", "# Planetoid", "\n", "validate_idx", "=", "np", ".", "arange", "(", "20", "*", "num_classes", ",", "20", "*", "num_classes", "+", "500", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "c_adj", "=", "compact_adj", ".", "CompactAdjacency", "(", "adj", ")", "\n", "eval_adj_tf", "=", "tf", ".", "cast", "(", "np", ".", "stack", "(", "c_adj", ".", "adj", ".", "nonzero", "(", ")", ",", "-", "1", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "eval_adj_tf", "=", "tf", ".", "sparse", ".", "SparseTensor", "(", "\n", "indices", "=", "eval_adj_tf", ",", "values", "=", "tf", ".", "ones", "(", "[", "eval_adj_tf", ".", "shape", "[", "0", "]", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "dense_shape", "=", "[", "num_nodes", ",", "num_nodes", "]", ")", "\n", "\n", "model_class", "=", "models_tf", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "0", "]", "]", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "1", "]", "]", "\n", "model_kwargs", "=", "json", ".", "loads", "(", "FLAGS", ".", "model_kwargs", ")", "\n", "gcn", "=", "model_class", "(", "num_classes", ",", "allx", ".", "shape", "[", "1", "]", ",", "**", "model_kwargs", ")", "\n", "least_validate_loss", "=", "(", "99999999", ",", "0", ")", "# (Validate loss, test accuracy)", "\n", "fanouts", "=", "[", "int", "(", "f", ")", "for", "f", "in", "FLAGS", ".", "fanout", ".", "split", "(", "'x'", ")", "]", "\n", "\n", "tt", "=", "tqdm", ".", "tqdm", "(", "range", "(", "FLAGS", ".", "epochs", ")", ")", "\n", "for", "epoch", "in", "tt", ":", "\n", "    ", "forest", "=", "traversals", ".", "np_traverse", "(", "c_adj", ",", "labeled_nodes", ",", "fanouts", "=", "fanouts", ")", "\n", "dense_shape", "=", "(", "num_nodes", ",", "num_nodes", ")", "\n", "sampled_adj", "=", "accumulation", ".", "SampledAdjacency", ".", "from_walk_forest", "(", "forest", ",", "dense_shape", ")", "\n", "trimmed_adj", "=", "sampled_adj", ".", "tf_trimmed", "\n", "trimmed_x", "=", "sampled_adj", ".", "tf_trim_x", "(", "allx", ")", "\n", "\n", "with", "tf", ".", "GradientTape", "(", "persistent", "=", "True", ")", "as", "tape", ":", "\n", "      ", "output", "=", "gcn", "(", "trimmed_x", ",", "trimmed_adj", ")", "\n", "labeled_logits", "=", "sampled_adj", ".", "tf_untrim_gather", "(", "output", ",", "labeled_nodes", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "ally", "[", "labeled_nodes", "]", ",", "logits", "=", "labeled_logits", ")", ")", "\n", "variables", "=", "gcn", ".", "trainable_variables", "\n", "loss", "+=", "tf", ".", "add_n", "(", "[", "tf", ".", "reduce_sum", "(", "v", "**", "2", ")", "*", "FLAGS", ".", "l2_reg", "for", "v", "in", "variables", "]", ")", "# if 'kernel' in v.name", "\n", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "variables", ")", "\n", "opt", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "variables", ")", ")", "\n", "\n", "if", "epoch", "%", "FLAGS", ".", "eval_every", "==", "0", ":", "\n", "#timer.stop()", "\n", "      ", "output", "=", "gcn", "(", "allx", ",", "eval_adj_tf", ",", "training", "=", "False", ")", "\n", "vloss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "ally", "[", "validate_idx", "]", ",", "\n", "logits", "=", "tf", ".", "gather", "(", "output", ",", "validate_idx", ")", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "preds", "=", "tf", ".", "argmax", "(", "tf", ".", "gather", "(", "output", ",", "test_id", ")", ",", "1", ")", ".", "numpy", "(", ")", "\n", "test_accuracy", "=", "(", "preds", "==", "ally", "[", "test_id", "]", ".", "argmax", "(", "1", ")", ")", ".", "mean", "(", ")", "\n", "least_validate_loss", "=", "min", "(", "least_validate_loss", ",", "(", "vloss", ",", "test_accuracy", ")", ")", "\n", "tt", ".", "set_description", "(", "'Test: %g (@ best validate=%g)'", "%", "(", "test_accuracy", ",", "least_validate_loss", "[", "1", "]", ")", ")", "\n", "#first_batch_offset = first_batch_offset or timer.total", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.GraphDataset.__init__": [[39, 42], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "V", ",", "labels", ")", ":", "\n", "        ", "self", ".", "V", "=", "V", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.GraphDataset.__getitem__": [[43, 45], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "V", "[", "index", "]", ",", "self", ".", "labels", "[", "self", ".", "V", "[", "index", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.GraphDataset.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "V", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.WalkForestCollator.__init__": [[51, 54], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "compAdj", ":", "CompAdj", ",", "fanouts", ")", ":", "\n", "        ", "self", ".", "compAdj", "=", "compAdj", "\n", "self", ".", "fanouts", "=", "fanouts", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.WalkForestCollator.__call__": [[55, 65], ["numpy.array", "batch_np[].astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "framework.traversals.np_traverse", "range", "batch_np[].astype().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch.from_numpy().flatten", "torch_forest.append", "len", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "torch.from_numpy().reshape", "batch_np[].astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_np", "=", "np", ".", "array", "(", "batch", ",", "dtype", "=", "object", ")", "\n", "node_ids", "=", "batch_np", "[", ":", ",", "0", "]", ".", "astype", "(", "int", ")", "\n", "node_labels", "=", "torch", ".", "from_numpy", "(", "batch_np", "[", ":", ",", "1", "]", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", ")", "\n", "forest", "=", "traversals", ".", "np_traverse", "(", "self", ".", "compAdj", ",", "node_ids", ",", "self", ".", "fanouts", ")", "\n", "torch_forest", "=", "[", "torch", ".", "from_numpy", "(", "forest", "[", "0", "]", ")", ".", "flatten", "(", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "forest", ")", "-", "1", ")", ":", "\n", "            ", "torch_forest", ".", "append", "(", "torch", ".", "from_numpy", "(", "forest", "[", "i", "+", "1", "]", ")", ".", "reshape", "(", "-", "1", ",", "self", ".", "fanouts", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "torch_forest", ",", "node_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.train": [[67, 132], ["torch.device", "torch.device", "torch.device", "print", "train_torch_sage.WalkForestCollator", "train_torch_sage.WalkForestCollator", "train_torch_sage.GraphDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train_torch_sage.GraphDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit", "sklearn.preprocessing.StandardScaler.transform", "list", "models_pytorch.sage.GraphSage", "models_pytorch.sage.GraphSage.to", "torch.CrossEntropyLoss", "torch.Adam", "timeit.default_timer", "range", "timeit.default_timer", "models_pytorch.sage.GraphSage.eval", "print", "map", "len", "numpy.max", "filter", "models_pytorch.sage.GraphSage.train", "enumerate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "sklearn.metrics.f1_score", "print", "str", "FLAGS.hidden_dims.split", "models_pytorch.sage.GraphSage.parameters", "tqdm.tqdm", "optim.Adam.zero_grad", "batch_labels.to.to().long", "models_pytorch.sage.GraphSage.", "nn.CrossEntropyLoss.", "loss_fn.backward", "optim.Adam.step", "tqdm.tqdm", "batch_labels.to.to", "models_pytorch.sage.GraphSage.", "net.cpu().data.numpy().argmax", "batch_labels.to.cpu().numpy", "list", "list", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "int", "level.to", "level.to", "batch_labels.to.to", "net.cpu().data.numpy", "batch_labels.to.cpu", "net.cpu"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters"], ["", "", "def", "train", "(", "feat_data", ",", "labels", ",", "train_comp_adj", ",", "val_comp_adj", ",", "train_ids", ",", "val_ids", ",", "fanouts", ")", ":", "\n", "    ", "dev", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", "&", "(", "FLAGS", ".", "device", "==", "'cuda'", ")", ")", "else", "\"cpu\"", ")", "\n", "print", "(", "'Training on {}'", ".", "format", "(", "str", "(", "dev", ")", ")", ")", "\n", "\n", "train_collator", "=", "WalkForestCollator", "(", "train_comp_adj", ",", "fanouts", ")", "\n", "val_collator", "=", "WalkForestCollator", "(", "val_comp_adj", ",", "fanouts", ")", "\n", "\n", "train_dataset", "=", "GraphDataset", "(", "train_ids", ",", "labels", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "FLAGS", ".", "num_workers", ",", "\n", "collate_fn", "=", "train_collator", ",", "pin_memory", "=", "True", ")", "\n", "\n", "val_dataset", "=", "GraphDataset", "(", "val_ids", ",", "labels", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "1024", ",", "shuffle", "=", "True", ",", "num_workers", "=", "FLAGS", ".", "num_workers", ",", "\n", "collate_fn", "=", "val_collator", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Normalize features", "\n", "train_feats", "=", "feat_data", "[", "train_ids", "]", "\n", "scaler", "=", "StandardScaler", "(", ")", "\n", "scaler", ".", "fit", "(", "train_feats", ")", "\n", "feat_data", "=", "scaler", ".", "transform", "(", "feat_data", ")", "\n", "\n", "hidden_dims", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "FLAGS", ".", "hidden_dims", ".", "split", "(", "','", ")", ")", ")", "\n", "assert", "len", "(", "hidden_dims", ")", "==", "2", ",", "'Must specify only two hidden dims for a 2 layer SAGE model'", "\n", "\n", "num_classes", "=", "np", ".", "max", "(", "labels", ")", "+", "1", "\n", "net", "=", "GraphSage", "(", "feat_data", ",", "num_classes", ",", "hidden_dims", "[", "0", "]", ",", "hidden_dims", "[", "1", "]", ",", "FLAGS", ".", "dropout", ")", "\n", "net", ".", "to", "(", "dev", ")", "\n", "\n", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "net", ".", "parameters", "(", ")", ")", ",", "lr", "=", "FLAGS", ".", "lr", ")", "\n", "\n", "start", "=", "timer", "(", ")", "\n", "for", "epoch", "in", "range", "(", "FLAGS", ".", "epochs", ")", ":", "\n", "        ", "net", ".", "train", "(", ")", "\n", "Y_true", "=", "[", "]", "\n", "Y_pred", "=", "[", "]", "\n", "for", "i", ",", "(", "batch_forest", ",", "batch_labels", ")", "in", "enumerate", "(", "tqdm", "(", "train_loader", ")", ")", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "forest", "=", "[", "level", ".", "to", "(", "device", "=", "dev", ",", "dtype", "=", "torch", ".", "long", ",", "non_blocking", "=", "True", ")", "for", "level", "in", "batch_forest", "]", "\n", "batch_labels", "=", "batch_labels", ".", "to", "(", "dev", ",", "non_blocking", "=", "True", ")", ".", "long", "(", ")", "\n", "\n", "scores", "=", "net", "(", "forest", ")", "\n", "\n", "loss", "=", "loss_fn", "(", "scores", ",", "batch_labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "end", "=", "timer", "(", ")", "\n", "\n", "net", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "(", "batch_forest", ",", "batch_labels", ")", "in", "enumerate", "(", "tqdm", "(", "val_loader", ")", ")", ":", "\n", "            ", "forest", "=", "[", "level", ".", "to", "(", "device", "=", "dev", ",", "dtype", "=", "torch", ".", "long", ",", "non_blocking", "=", "True", ")", "for", "level", "in", "batch_forest", "]", "\n", "batch_labels", "=", "batch_labels", ".", "to", "(", "dev", ",", "non_blocking", "=", "True", ")", "\n", "\n", "scores", "=", "net", "(", "forest", ")", "\n", "y_pred", "=", "scores", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "y_true", "=", "batch_labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Y_true", "+=", "list", "(", "y_true", ")", "\n", "Y_pred", "+=", "list", "(", "y_pred", ")", "\n", "\n", "", "f1", "=", "f1_score", "(", "Y_true", ",", "Y_pred", ",", "average", "=", "\"micro\"", ")", "\n", "print", "(", "'Test F1 = {}'", ".", "format", "(", "f1", ")", ")", "\n", "\n", "", "print", "(", "'Training time = {} seconds'", ".", "format", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.eval_acc": [[134, 139], ["len"], "function", ["None"], ["", "def", "eval_acc", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "total", "=", "len", "(", "y_true", ")", "\n", "correct", "=", "(", "y_true", "==", "y_pred", ")", ".", "sum", "(", ")", "\n", "\n", "return", "correct", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_sage.main": [[141, 156], ["os.path.join", "list", "map", "training_loops.datasets.load_reddit", "train_torch_sage.train", "FLAGS.fanouts.split", "training_loops.datasets.load_ogbproducts", "train_torch_sage.train", "int", "training_loops.datasets.load_amazon", "train_torch_sage.train"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_reddit", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_ogbproducts", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_amazon", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "FLAGS", ".", "dataset", ")", "\n", "fanouts", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "FLAGS", ".", "fanouts", ".", "split", "(", "'x'", ")", ")", ")", "\n", "\n", "if", "(", "FLAGS", ".", "dataset", "==", "'reddit'", ")", ":", "\n", "        ", "train_comp_adj", ",", "test_comp_adj", ",", "feat_data", ",", "labels", ",", "train_ids", ",", "val_ids", ",", "test_ids", "=", "datasets", ".", "load_reddit", "(", "path", ")", "\n", "train", "(", "feat_data", ",", "labels", ",", "train_comp_adj", ",", "test_comp_adj", ",", "train_ids", ",", "test_ids", ",", "fanouts", ")", "\n", "\n", "", "elif", "(", "FLAGS", ".", "dataset", "==", "'products'", ")", ":", "\n", "        ", "feat_data", ",", "labels", ",", "comp_adj", ",", "degrees", ",", "train_ids", ",", "val_ids", ",", "test_ids", "=", "datasets", ".", "load_ogbproducts", "(", "path", ")", "\n", "train", "(", "feat_data", ",", "labels", ",", "comp_adj", ",", "comp_adj", ",", "train_ids", ",", "test_ids", ",", "fanouts", ")", "\n", "\n", "", "elif", "(", "FLAGS", ".", "dataset", "==", "'amazon'", ")", ":", "\n", "        ", "feat_data", ",", "labels", ",", "train_comp_adj", ",", "comp_adj", ",", "train_ids", ",", "val_ids", ",", "test_ids", "=", "datasets", ".", "load_amazon", "(", "path", ")", "\n", "train", "(", "feat_data", ",", "labels", ",", "train_comp_adj", ",", "comp_adj", ",", "train_ids", ",", "test_ids", ",", "fanouts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_skipgram.main": [[57, 96], ["data.asymproj_datasets.read_dataset", "scipy.csr_matrix", "framework.compact_adj.CompactAdjacency", "model_class", "torch.optim.Adam", "utils.common.IdBatcher", "tqdm.tqdm", "numpy.concatenate", "numpy.concatenate", "int", "filter", "set", "range", "model_class.train", "optim.Adam.zero_grad", "utils.common.IdBatcher.batch", "numpy.array", "model_class.loss", "model.loss.backward", "optim.Adam.step", "tqdm.tqdm.set_description", "numpy.ones", "FLAGS.fanout.split", "len", "model_class.parameters", "torch.LongTensor", "e.weight.detach().numpy", "len", "utils.common.skipgram_eval", "utils.common.skipgram_eval", "len", "FLAGS.model.split", "framework.traversals.np_traverse", "model_class.embeddings", "e.weight.detach", "FLAGS.model.split"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.data.asymproj_datasets.read_dataset", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.IdBatcher.batch", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.wys.WYS.loss", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.skipgram_eval", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.skipgram_eval", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.wys.WYS.embeddings"], ["def", "main", "(", "_", ")", ":", "\n", "    ", "num_nodes", ",", "train_edges", ",", "test_pos_arr", ",", "test_neg_arr", ",", "is_directed", "=", "asymproj_datasets", ".", "read_dataset", "(", "FLAGS", ".", "dataset_dir", ")", "\n", "adj_rows", "=", "train_edges", "[", ":", ",", "0", "]", "\n", "adj_cols", "=", "train_edges", "[", ":", ",", "1", "]", "\n", "if", "not", "is_directed", ":", "\n", "        ", "adj_rows", "=", "np", ".", "concatenate", "(", "[", "adj_rows", ",", "train_edges", "[", ":", ",", "1", "]", "]", ",", "axis", "=", "0", ")", "\n", "adj_cols", "=", "np", ".", "concatenate", "(", "[", "adj_cols", ",", "train_edges", "[", ":", ",", "0", "]", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "csr_adj", "=", "sp", ".", "csr_matrix", "(", "\n", "(", "np", ".", "ones", "(", "len", "(", "adj_rows", ")", ",", "dtype", "=", "'int32'", ")", ",", "(", "adj_rows", ",", "adj_cols", ")", ")", ",", "\n", "shape", "=", "(", "num_nodes", ",", "num_nodes", ")", ")", "\n", "cadj", "=", "compact_adj", ".", "CompactAdjacency", "(", "csr_adj", ")", "\n", "\n", "fanouts", "=", "[", "int", "(", "f", ")", "for", "f", "in", "FLAGS", ".", "fanout", ".", "split", "(", "'x'", ")", "]", "\n", "model_class", "=", "models_pytorch", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "0", "]", "]", ".", "__dict__", "[", "FLAGS", ".", "model", ".", "split", "(", "'.'", ")", "[", "1", "]", "]", "\n", "model", "=", "model_class", "(", "num_nodes", "=", "num_nodes", ",", "emb_dim", "=", "FLAGS", ".", "d", ",", "window_size", "=", "len", "(", "fanouts", ")", ")", "\n", "opt", "=", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "lr", "=", "FLAGS", ".", "lr", ")", "\n", "\n", "batcher", "=", "IdBatcher", "(", "set", "(", "adj_rows", ")", ")", "\n", "tt", "=", "tqdm", ".", "tqdm", "(", "range", "(", "FLAGS", ".", "steps", ")", ")", "\n", "for", "i", "in", "tt", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "seed_ids", "=", "batcher", ".", "batch", "(", "FLAGS", ".", "batch_size", ")", "\n", "seed_ids", "=", "np", ".", "array", "(", "seed_ids", ")", "\n", "forest", "=", "[", "torch", ".", "LongTensor", "(", "x", ")", "for", "x", "in", "traversals", ".", "np_traverse", "(", "cadj", ",", "seed_ids", ",", "fanouts", ")", "]", "\n", "\n", "loss_train", "=", "model", ".", "loss", "(", "forest", ",", "negative_samples", "=", "FLAGS", ".", "neg_samples", ",", "pos_coeff", "=", "FLAGS", ".", "pos_coeff", ")", "\n", "\n", "loss_train", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "\n", "## Eval", "\n", "embeddings", "=", "[", "e", ".", "weight", ".", "detach", "(", ")", ".", "numpy", "(", ")", "for", "e", "in", "model", ".", "embeddings", "(", ")", "]", "\n", "if", "len", "(", "embeddings", ")", "==", "1", ":", "\n", "            ", "test_accuracy", "=", "skipgram_eval", "(", "embeddings", "[", "0", "]", ",", "embeddings", "[", "0", "]", ",", "test_pos_arr", ",", "test_neg_arr", ",", "directed", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "test_accuracy", "=", "skipgram_eval", "(", "embeddings", "[", "0", "]", ",", "embeddings", "[", "1", "]", ",", "test_pos_arr", ",", "test_neg_arr", ",", "directed", "=", "False", ")", "\n", "", "tt", ".", "set_description", "(", "'Test=%g'", "%", "test_accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.accuracy": [[54, 59], ["[].type_as", "[].type_as.eq().double", "correct.sum.sum", "len", "[].type_as.eq", "output.max"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "labels", ")", ":", "\n", "    ", "preds", "=", "output", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type_as", "(", "labels", ")", "\n", "correct", "=", "preds", ".", "eq", "(", "labels", ")", ".", "double", "(", ")", "\n", "correct", "=", "correct", ".", "sum", "(", ")", "\n", "return", "correct", "/", "len", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.normalize": [[60, 69], ["numpy.array", "numpy.power().flatten", "scipy.diags", "sp.diags.dot", "r_mat_inv.dot.sum", "numpy.power", "numpy.isinf"], "function", ["None"], ["", "def", "normalize", "(", "mx", ")", ":", "\n", "    ", "\"\"\"Row-normalize sparse matrix\"\"\"", "\n", "rowsum", "=", "np", ".", "array", "(", "mx", ".", "sum", "(", "1", ")", ")", "\n", "rowsum", "=", "(", "rowsum", "==", "0", ")", "*", "1", "+", "rowsum", "\n", "r_inv", "=", "np", ".", "power", "(", "rowsum", ",", "-", "1", ")", ".", "flatten", "(", ")", "\n", "r_inv", "[", "np", ".", "isinf", "(", "r_inv", ")", "]", "=", "0.", "\n", "r_mat_inv", "=", "sp", ".", "diags", "(", "r_inv", ")", "\n", "mx", "=", "r_mat_inv", ".", "dot", "(", "mx", ")", "\n", "return", "mx", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.parse_index_file": [[70, 76], ["open", "index.append", "int", "line.strip"], "function", ["None"], ["", "def", "parse_index_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Parse index file.\"\"\"", "\n", "index", "=", "[", "]", "\n", "for", "line", "in", "open", "(", "filename", ")", ":", "\n", "        ", "index", ".", "append", "(", "int", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.load_citation": [[78, 129], ["os.path.expanduser", "range", "tuple", "train_torch_gcnii.parse_index_file", "numpy.sort", "scipy.vstack().tolil", "networkx.adjacency_matrix", "numpy.vstack", "np.sort.tolist", "range", "range", "train_torch_gcnii.normalize", "torch.FloatTensor().float", "torch.FloatTensor().float", "torch.FloatTensor().float", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "os.path.join", "os.path.exists", "ValueError", "len", "os.path.join", "range", "scipy.lil_matrix", "numpy.zeros", "networkx.from_dict_of_lists", "nx.adjacency_matrix.multiply", "len", "len", "torch.max", "torch.max", "torch.max", "os.path.expanduser", "open", "min", "scipy.vstack", "nx.adjacency_matrix.T.multiply", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "os.path.join", "objects.append", "objects.append", "max", "len", "len", "numpy.array", "pickle.load", "pickle.load", "torch.FloatTensor().float.todense", "dataset_str.lower", "min", "min"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.parse_index_file", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.normalize"], ["", "def", "load_citation", "(", "dataset_str", "=", "\"cora\"", ",", "dataset_dir", "=", "\"~/data/planetoid/data\"", ")", ":", "\n", "    ", "\"\"\"\n    Load Citation Networks Datasets.\n    \"\"\"", "\n", "basepath", "=", "os", ".", "path", ".", "expanduser", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "expanduser", "(", "dataset_dir", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'cannot find dataset_dir=%s. Please:\\nmkdir -p ~/data; cd ~/data; git clone git@github.com:kimiyoung/planetoid.git'", ")", "\n", "", "names", "=", "[", "'x'", ",", "'y'", ",", "'tx'", ",", "'ty'", ",", "'allx'", ",", "'ally'", ",", "'graph'", "]", "\n", "objects", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "names", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "basepath", ",", "\"ind.{}.{}\"", ".", "format", "(", "dataset_str", ".", "lower", "(", ")", ",", "names", "[", "i", "]", ")", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "if", "sys", ".", "version_info", ">", "(", "3", ",", "0", ")", ":", "\n", "                ", "objects", ".", "append", "(", "pkl", ".", "load", "(", "f", ",", "encoding", "=", "'latin1'", ")", ")", "\n", "", "else", ":", "\n", "                ", "objects", ".", "append", "(", "pkl", ".", "load", "(", "f", ")", ")", "\n", "\n", "", "", "", "x", ",", "y", ",", "tx", ",", "ty", ",", "allx", ",", "ally", ",", "graph", "=", "tuple", "(", "objects", ")", "\n", "test_idx_reorder", "=", "parse_index_file", "(", "os", ".", "path", ".", "join", "(", "basepath", ",", "\"ind.{}.test.index\"", ".", "format", "(", "dataset_str", ")", ")", ")", "\n", "test_idx_range", "=", "np", ".", "sort", "(", "test_idx_reorder", ")", "\n", "\n", "if", "dataset_str", "==", "'citeseer'", ":", "\n", "# Fix citeseer dataset (there are some isolated nodes in the graph)", "\n", "# Find isolated nodes, add them as zero-vecs into the right position", "\n", "        ", "test_idx_range_full", "=", "range", "(", "min", "(", "test_idx_reorder", ")", ",", "max", "(", "test_idx_reorder", ")", "+", "1", ")", "\n", "tx_extended", "=", "sp", ".", "lil_matrix", "(", "(", "len", "(", "test_idx_range_full", ")", ",", "x", ".", "shape", "[", "1", "]", ")", ")", "\n", "tx_extended", "[", "test_idx_range", "-", "min", "(", "test_idx_range", ")", ",", ":", "]", "=", "tx", "\n", "tx", "=", "tx_extended", "\n", "ty_extended", "=", "np", ".", "zeros", "(", "(", "len", "(", "test_idx_range_full", ")", ",", "y", ".", "shape", "[", "1", "]", ")", ")", "\n", "ty_extended", "[", "test_idx_range", "-", "min", "(", "test_idx_range", ")", ",", ":", "]", "=", "ty", "\n", "ty", "=", "ty_extended", "\n", "\n", "", "features", "=", "sp", ".", "vstack", "(", "(", "allx", ",", "tx", ")", ")", ".", "tolil", "(", ")", "\n", "features", "[", "test_idx_reorder", ",", ":", "]", "=", "features", "[", "test_idx_range", ",", ":", "]", "\n", "adj", "=", "nx", ".", "adjacency_matrix", "(", "nx", ".", "from_dict_of_lists", "(", "graph", ")", ")", "\n", "adj", "=", "adj", "+", "adj", ".", "T", ".", "multiply", "(", "adj", ".", "T", ">", "adj", ")", "-", "adj", ".", "multiply", "(", "adj", ".", "T", ">", "adj", ")", "\n", "labels", "=", "np", ".", "vstack", "(", "(", "ally", ",", "ty", ")", ")", "\n", "labels", "[", "test_idx_reorder", ",", ":", "]", "=", "labels", "[", "test_idx_range", ",", ":", "]", "\n", "\n", "idx_test", "=", "test_idx_range", ".", "tolist", "(", ")", "\n", "idx_train", "=", "range", "(", "len", "(", "y", ")", ")", "\n", "idx_val", "=", "range", "(", "len", "(", "y", ")", ",", "len", "(", "y", ")", "+", "500", ")", "\n", "\n", "features", "=", "normalize", "(", "features", ")", "\n", "# porting to pytorch", "\n", "features", "=", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "features", ".", "todense", "(", ")", ")", ")", ".", "float", "(", ")", "\n", "labels", "=", "torch", ".", "LongTensor", "(", "labels", ")", "\n", "labels", "=", "torch", ".", "max", "(", "labels", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "idx_train", "=", "torch", ".", "LongTensor", "(", "idx_train", ")", "\n", "idx_val", "=", "torch", ".", "LongTensor", "(", "idx_val", ")", "\n", "idx_test", "=", "torch", ".", "LongTensor", "(", "idx_test", ")", "\n", "return", "adj", ",", "features", ",", "labels", ",", "idx_train", ",", "idx_val", ",", "idx_test", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.run_model_with_gttf": [[130, 143], ["framework.traversals.np_traverse", "framework.accumulation.SampledAdjacency.from_walk_forest", "utils.torch_utils.kipf_renorm_sp", "utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "trimmed_adj.to.to", "accumulation.SampledAdjacency.from_walk_forest.torch_trim_x", "trimmed_x.to.to", "model", "accumulation.SampledAdjacency.from_walk_forest.torch_untrim_gather", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.from_walk_forest", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.kipf_renorm_sp", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.sparse_mx_to_torch_sparse_tensor", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_trim_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_untrim_gather"], ["", "def", "run_model_with_gttf", "(", "model", ",", "idx", ")", ":", "\n", "    ", "forest", "=", "traversals", ".", "np_traverse", "(", "c_adj", ",", "np", ".", "array", "(", "idx", ")", ",", "fanouts", "=", "args", ".", "fanouts", ")", "\n", "dense_shape", "=", "(", "num_nodes", ",", "num_nodes", ")", "\n", "sampled_adj", "=", "accumulation", ".", "SampledAdjacency", ".", "from_walk_forest", "(", "forest", ",", "dense_shape", ")", "\n", "trimmed_adj", "=", "sampled_adj", ".", "csr_trimmed", "\n", "trimmed_adj", "=", "torch_utils", ".", "kipf_renorm_sp", "(", "trimmed_adj", ")", "\n", "trimmed_adj", "=", "torch_utils", ".", "sparse_mx_to_torch_sparse_tensor", "(", "trimmed_adj", ")", "\n", "trimmed_adj", "=", "trimmed_adj", ".", "to", "(", "device", ")", "\n", "trimmed_x", "=", "sampled_adj", ".", "torch_trim_x", "(", "features", ")", "\n", "trimmed_x", "=", "trimmed_x", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "trimmed_x", ",", "trimmed_adj", ")", "\n", "output", "=", "sampled_adj", ".", "torch_untrim_gather", "(", "output", ",", "np", ".", "array", "(", "idx", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train": [[170, 179], ["model.train", "optimizer.zero_grad", "train_torch_gcnii.run_model_with_gttf", "train_torch_gcnii.accuracy", "torch.nll_loss", "F.nll_loss.backward", "optimizer.step", "labels[].to", "labels[].to", "F.nll_loss.item", "accuracy.item"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.train", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.run_model_with_gttf", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.accuracy"], ["def", "train", "(", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "run_model_with_gttf", "(", "model", ",", "idx_train", ")", "\n", "acc_train", "=", "accuracy", "(", "output", ",", "labels", "[", "idx_train", "]", ".", "to", "(", "device", ")", ")", "\n", "loss_train", "=", "F", ".", "nll_loss", "(", "output", ",", "labels", "[", "idx_train", "]", ".", "to", "(", "device", ")", ")", "\n", "loss_train", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "return", "loss_train", ".", "item", "(", ")", ",", "acc_train", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.validate": [[180, 187], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "train_torch_gcnii.run_model_with_gttf", "torch.nll_loss", "train_torch_gcnii.accuracy", "labels[].to", "labels[].to", "F.nll_loss.item", "accuracy.item"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.run_model_with_gttf", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.accuracy"], ["", "def", "validate", "(", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "output", "=", "run_model_with_gttf", "(", "model", ",", "idx_val", ")", "\n", "loss_val", "=", "F", ".", "nll_loss", "(", "output", ",", "labels", "[", "idx_val", "]", ".", "to", "(", "device", ")", ")", "\n", "acc_val", "=", "accuracy", "(", "output", ",", "labels", "[", "idx_val", "]", ".", "to", "(", "device", ")", ")", "\n", "return", "loss_val", ".", "item", "(", ")", ",", "acc_val", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.test": [[188, 196], ["model.load_state_dict", "model.eval", "torch.load", "torch.load", "torch.load", "torch.no_grad", "torch.no_grad", "torch.no_grad", "train_torch_gcnii.run_model_with_gttf", "torch.nll_loss", "train_torch_gcnii.accuracy", "labels[].to", "labels[].to", "F.nll_loss.item", "accuracy.item"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.run_model_with_gttf", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.None.train_torch_gcnii.accuracy"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpt_file", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "output", "=", "run_model_with_gttf", "(", "model", ",", "idx_test", ")", "\n", "loss_test", "=", "F", ".", "nll_loss", "(", "output", ",", "labels", "[", "idx_test", "]", ".", "to", "(", "device", ")", ")", "\n", "acc_test", "=", "accuracy", "(", "output", ",", "labels", "[", "idx_test", "]", ".", "to", "(", "device", ")", ")", "\n", "return", "loss_test", ".", "item", "(", ")", ",", "acc_test", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.tf_utils.kipf_renorm_tf": [[4, 21], ["tensorflow.sparse.maximum", "tensorflow.sparse.eye", "tensorflow.sparse.maximum", "tensorflow.sparse.reduce_sum", "tensorflow.sqrt", "tensorflow.sparse.transpose", "tensorflow.reshape"], "function", ["None"], ["def", "kipf_renorm_tf", "(", "adj", ",", "return_normalizer", "=", "False", ")", ":", "\n", "# adj: a tf sparse tensor, possibly on gpu", "\n", "# Kipf's re-norm trick", "\n", "  ", "adj", "=", "tf", ".", "sparse", ".", "maximum", "(", "adj", ",", "tf", ".", "sparse", ".", "transpose", "(", "adj", ")", ")", "# Make symmetric", "\n", "\n", "num_nodes", "=", "adj", ".", "shape", "[", "0", "]", "\n", "\n", "eye", "=", "tf", ".", "sparse", ".", "eye", "(", "num_nodes", ",", "dtype", "=", "'float32'", ")", "\n", "adj", "=", "tf", ".", "sparse", ".", "maximum", "(", "adj", ",", "eye", ")", "# Set diagonal", "\n", "\n", "sums", "=", "tf", ".", "sparse", ".", "reduce_sum", "(", "adj", ",", "1", ")", "\n", "inv_sqrt_degree", "=", "tf", ".", "sqrt", "(", "1.0", "/", "sums", ")", "\n", "normed_adj", "=", "adj", "*", "inv_sqrt_degree", "*", "tf", ".", "reshape", "(", "inv_sqrt_degree", ",", "(", "num_nodes", ",", "1", ")", ")", "\n", "if", "return_normalizer", ":", "\n", "    ", "return", "normed_adj", ",", "inv_sqrt_degree", "\n", "", "else", ":", "\n", "    ", "return", "normed_adj", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.tf_utils.adj_times_x": [[24, 29], ["range", "tensorflow.sparse.sparse_dense_matmul"], "function", ["None"], ["", "", "def", "adj_times_x", "(", "adj", ",", "x", ",", "adj_pow", "=", "1", ")", ":", "\n", "  ", "\"\"\"Multiplies (adj^adj_pow)*x.\"\"\"", "\n", "for", "i", "in", "range", "(", "adj_pow", ")", ":", "\n", "    ", "x", "=", "tf", ".", "sparse", ".", "sparse_dense_matmul", "(", "adj", ",", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.IdBatcher.__init__": [[11, 14], ["list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ids", ")", ":", "\n", "        ", "self", ".", "ids", "=", "list", "(", "ids", ")", "\n", "self", ".", "queue", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.IdBatcher.batch": [[15, 24], ["len", "random.shuffle"], "methods", ["None"], ["", "def", "batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "while", "len", "(", "self", ".", "queue", ")", "<", "batch_size", ":", "\n", "            ", "shuffled_ids", "=", "[", "ii", "for", "ii", "in", "self", ".", "ids", "]", "\n", "random", ".", "shuffle", "(", "shuffled_ids", ")", "\n", "self", ".", "queue", "+=", "shuffled_ids", "\n", "\n", "", "selected_batch", "=", "self", ".", "queue", "[", ":", "batch_size", "]", "\n", "self", ".", "queue", "=", "self", ".", "queue", "[", "batch_size", ":", "]", "\n", "return", "selected_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot": [[26, 28], ["numpy.np.sum", "numpy.np.sum", "numpy.np.sum", "numpy.np.sum", "numpy.np.sum", "numpy.np.sum"], "function", ["None"], ["", "", "def", "sym_dot", "(", "embeds1", ",", "embeds2", ",", "sum_fn", "=", "np", ".", "sum", ")", ":", "\n", "    ", "return", "sum_fn", "(", "embeds1", "*", "embeds2", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.asym_dot": [[30, 34], ["sum_fn"], "function", ["None"], ["", "def", "asym_dot", "(", "embeds1", ",", "embeds2", ",", "sum_fn", ",", "**", "kwargs", ")", ":", "\n", "  ", "size", "=", "embeds1", ".", "shape", "[", "1", "]", "\n", "hs", "=", "size", "//", "2", "\n", "return", "sum_fn", "(", "embeds1", "[", ":", ",", ":", "hs", "]", "*", "embeds2", "[", ":", ",", "hs", ":", "]", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.skipgram_eval": [[36, 48], ["numpy.concatenate", "sklearn.metrics.roc_auc_score", "common.sym_dot", "common.sym_dot", "len", "len", "common.sym_dot", "common.sym_dot", "common.sym_dot", "common.sym_dot"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.sym_dot"], ["", "def", "skipgram_eval", "(", "embed1", ",", "embed2", ",", "test_pos", ",", "test_neg", ",", "directed", "=", "False", ")", ":", "\n", "    ", "if", "directed", ":", "\n", "        ", "test_scores", "=", "sym_dot", "(", "embed1", "[", "test_pos", "[", ":", ",", "0", "]", "]", ",", "embed2", "[", "test_pos", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "\n", "test_neg_scores", "=", "sym_dot", "(", "embed1", "[", "test_neg", "[", ":", ",", "0", "]", "]", ",", "embed2", "[", "test_neg", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "\n", "", "else", ":", "\n", "        ", "test_scores", "=", "0.5", "*", "sym_dot", "(", "embed1", "[", "test_pos", "[", ":", ",", "0", "]", "]", ",", "embed2", "[", "test_pos", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "+", "0.5", "*", "sym_dot", "(", "embed2", "[", "test_pos", "[", ":", ",", "0", "]", "]", ",", "embed1", "[", "test_pos", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "\n", "test_neg_scores", "=", "0.5", "*", "sym_dot", "(", "embed1", "[", "test_neg", "[", ":", ",", "0", "]", "]", ",", "embed2", "[", "test_neg", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "+", "0.5", "*", "sym_dot", "(", "embed2", "[", "test_neg", "[", ":", ",", "0", "]", "]", ",", "embed1", "[", "test_neg", "[", ":", ",", "1", "]", "]", ",", "np", ".", "sum", ")", "\n", "", "test_y", "=", "[", "0", "]", "*", "len", "(", "test_neg_scores", ")", "+", "[", "1", "]", "*", "len", "(", "test_scores", ")", "\n", "test_y_pred", "=", "np", ".", "concatenate", "(", "[", "test_neg_scores", ",", "test_scores", "]", ",", "0", ")", "\n", "test_accuracy", "=", "metrics", ".", "roc_auc_score", "(", "test_y", ",", "test_y_pred", ")", "\n", "\n", "return", "test_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.sparse_mx_to_torch_sparse_tensor": [[5, 13], ["sparse_mx.tocoo().astype.tocoo().astype", "torch.from_numpy", "torch.from_numpy", "torch.Size", "torch.sparse.FloatTensor", "numpy.vstack().astype", "sparse_mx.tocoo().astype.tocoo", "numpy.vstack"], "function", ["None"], ["def", "sparse_mx_to_torch_sparse_tensor", "(", "sparse_mx", ")", ":", "\n", "    ", "\"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"", "\n", "sparse_mx", "=", "sparse_mx", ".", "tocoo", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "indices", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "vstack", "(", "(", "sparse_mx", ".", "row", ",", "sparse_mx", ".", "col", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", ")", "\n", "values", "=", "torch", ".", "from_numpy", "(", "sparse_mx", ".", "data", ")", "\n", "shape", "=", "torch", ".", "Size", "(", "sparse_mx", ".", "shape", ")", "\n", "return", "torch", ".", "sparse", ".", "FloatTensor", "(", "indices", ",", "values", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.torch_utils.kipf_renorm_sp": [[14, 40], ["numpy.array", "numpy.power().flatten", "scipy.diags", "sp.diags.dot", "mx.tolil.dot", "type", "mx.tolil.tolil", "mx.tolil.sum", "scipy.eye", "numpy.power", "numpy.isinf"], "function", ["None"], ["", "def", "kipf_renorm_sp", "(", "mx", ")", ":", "\n", "    ", "\"\"\"Normalize sparse adjacency matrix,\n    A' = (D + I)^-1/2 * ( A + I ) * (D + I)^-1/2\n    Row-normalize sparse matrix\n\n    Parameters\n    ----------\n    mx : scipy.sparse.csr_matrix\n        matrix to be normalized\n\n    Returns\n    -------\n    scipy.sprase.lil_matrix\n        normalized matrix\n    \"\"\"", "\n", "if", "type", "(", "mx", ")", "is", "not", "sp", ".", "lil", ".", "lil_matrix", ":", "\n", "        ", "mx", "=", "mx", ".", "tolil", "(", ")", "\n", "", "if", "mx", "[", "0", ",", "0", "]", "==", "0", ":", "\n", "        ", "mx", "=", "mx", "+", "sp", ".", "eye", "(", "mx", ".", "shape", "[", "0", "]", ")", "\n", "", "rowsum", "=", "np", ".", "array", "(", "mx", ".", "sum", "(", "1", ")", ")", "\n", "r_inv", "=", "np", ".", "power", "(", "rowsum", ",", "-", "1", "/", "2", ")", ".", "flatten", "(", ")", "\n", "r_inv", "[", "np", ".", "isinf", "(", "r_inv", ")", "]", "=", "0.", "\n", "r_mat_inv", "=", "sp", ".", "diags", "(", "r_inv", ")", "\n", "mx", "=", "r_mat_inv", ".", "dot", "(", "mx", ")", "\n", "mx", "=", "mx", ".", "dot", "(", "r_mat_inv", ")", "\n", "return", "mx", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.samplers.np_uniform_sample_next": [[18, 33], ["numpy.repeat", "numpy.repeat", "numpy.random.uniform", "numpy.array", "numpy.array().reshape", "numpy.array", "np.repeat.reshape", "np.array().reshape.reshape"], "function", ["None"], ["def", "np_uniform_sample_next", "(", "compact_adj", ",", "tree", ",", "fanout", ")", ":", "\n", "  ", "\"Uniform SampleFunction for unbiased walks\"", "\n", "last_level", "=", "tree", "[", "-", "1", "]", "# [batch, f^depth]", "\n", "batch_lengths", "=", "compact_adj", ".", "degrees", "[", "last_level", "]", "\n", "nodes", "=", "np", ".", "repeat", "(", "last_level", ",", "fanout", ",", "axis", "=", "1", ")", "\n", "batch_lengths", "=", "np", ".", "repeat", "(", "batch_lengths", ",", "fanout", ",", "axis", "=", "1", ")", "\n", "batch_next_neighbor_ids", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "batch_lengths", ".", "shape", ",", "low", "=", "0", ",", "high", "=", "1", "-", "1e-9", ")", "\n", "# Shape = (len(nodes), neighbors_per_node)", "\n", "batch_next_neighbor_ids", "=", "np", ".", "array", "(", "\n", "batch_next_neighbor_ids", "*", "batch_lengths", ",", "\n", "dtype", "=", "last_level", ".", "dtype", ")", "\n", "shape", "=", "batch_next_neighbor_ids", ".", "shape", "\n", "batch_next_neighbor_ids", "=", "np", ".", "array", "(", "compact_adj", ".", "compact_adj", "[", "nodes", ".", "reshape", "(", "-", "1", ")", ",", "batch_next_neighbor_ids", ".", "reshape", "(", "-", "1", ")", "]", ")", ".", "reshape", "(", "shape", ")", "\n", "\n", "return", "batch_next_neighbor_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.__init__": [[21, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "edges", ",", "dense_shape", ")", ":", "\n", "    ", "self", ".", "edges", "=", "edges", "\n", "self", ".", "dense_shape", "=", "dense_shape", "\n", "\n", "self", ".", "lazy_cache", "=", "{", "}", "\n", "\"\"\"\n    self._sampled_nodes = None  # Set on sampled_nodes()\n    self._sp_csr = None\n    self._trimmed_csr = None\n    \"\"\"", "\n", "", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.__getattr__": [[31, 41], ["attr.startswith", "getattr", "getattr.", "ValueError"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "    ", "if", "attr", ".", "startswith", "(", "'_lazy_'", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'Member not found: .'", "+", "attr", "[", "6", ":", "]", ")", "\n", "", "if", "attr", "in", "self", ".", "lazy_cache", ":", "\n", "      ", "return", "self", ".", "lazy_cache", "[", "attr", "]", "\n", "", "method", "=", "'_lazy_'", "+", "attr", "\n", "method", "=", "getattr", "(", "self", ",", "method", ")", "\n", "result", "=", "method", "(", ")", "\n", "self", ".", "lazy_cache", "[", "attr", "]", "=", "result", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.from_walk_forest": [[42, 47], ["accumulation.accumulate_unique_edges", "accumulation.SampledAdjacency"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.accumulate_unique_edges"], ["", "@", "staticmethod", "\n", "def", "from_walk_forest", "(", "walk_forest", ",", "dense_shape", ",", "directed", "=", "False", ")", ":", "\n", "    ", "\"\"\"Used to instantiate SampledAdjacency from a walk forest\"\"\"", "\n", "edges", "=", "accumulate_unique_edges", "(", "walk_forest", ",", "directed", "=", "directed", ")", "\n", "return", "SampledAdjacency", "(", "edges", ",", "dense_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy_sp_csr": [[48, 53], ["numpy.ones", "scipy.sparse.csr_matrix"], "methods", ["None"], ["", "def", "_lazy_sp_csr", "(", "self", ")", ":", "\n", "    ", "data_arr", "=", "np", ".", "ones", "(", "[", "self", ".", "edges", ".", "shape", "[", "0", "]", "]", ",", "dtype", "=", "'float32'", ")", "\n", "return", "scipy", ".", "sparse", ".", "csr_matrix", "(", "\n", "(", "data_arr", ",", "(", "self", ".", "edges", "[", ":", ",", "0", "]", ",", "self", ".", "edges", "[", ":", ",", "1", "]", ")", ")", ",", "\n", "shape", "=", "self", ".", "dense_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy_sparse_tf": [[54, 56], ["None"], "methods", ["None"], ["", "def", "_lazy_sparse_tf", "(", "self", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy_sampled_nodes": [[57, 59], ["numpy.unique"], "methods", ["None"], ["", "def", "_lazy_sampled_nodes", "(", "self", ")", ":", "\n", "    ", "return", "np", ".", "unique", "(", "self", ".", "edges", ")", "\n", "#if self._sampled_nodes is None:", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy__torch": [[63, 66], ["None"], "methods", ["None"], ["", "def", "_lazy__torch", "(", "self", ")", ":", "\n", "    ", "import", "torch", "\n", "return", "torch", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy_torch_trimmed": [[67, 80], ["accumulation.SampledAdjacency.csr_trimmed.nonzero", "torch.stack", "torch.ones", "torch.sparse.FloatTensor", "torch.Size", "torch.from_numpy", "torch.from_numpy", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_lazy_torch_trimmed", "(", "self", ")", ":", "\n", "    ", "sampled_nodes", "=", "self", ".", "sampled_nodes", "\n", "rows", ",", "cols", "=", "self", ".", "csr_trimmed", ".", "nonzero", "(", ")", "\n", "torch", "=", "self", ".", "_torch", "\n", "#import IPython; IPython.embed()", "\n", "indices", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "rows", ",", "dtype", "=", "'int64'", ")", ")", ",", "\n", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "cols", ",", "dtype", "=", "'int64'", ")", ")", ",", "\n", "]", ",", "axis", "=", "0", ")", "\n", "values", "=", "torch", ".", "ones", "(", "rows", ".", "shape", ")", "\n", "return", "torch", ".", "sparse", ".", "FloatTensor", "(", "\n", "indices", ",", "values", ",", "\n", "torch", ".", "Size", "(", "[", "sampled_nodes", ".", "shape", "[", "0", "]", ",", "sampled_nodes", ".", "shape", "[", "0", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy_csr_trimmed": [[81, 84], ["None"], "methods", ["None"], ["", "def", "_lazy_csr_trimmed", "(", "self", ")", ":", "\n", "    ", "sampled_nodes", "=", "self", ".", "sampled_nodes", "\n", "return", "self", ".", "sp_csr", "[", "sampled_nodes", "]", "[", ":", ",", "sampled_nodes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy_tf_trimmed": [[85, 88], ["accumulation.csr_binary_matrix_to_tf", "accumulation.SampledAdjacency.csr_trimmed.nonzero"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.csr_binary_matrix_to_tf"], ["", "def", "_lazy_tf_trimmed", "(", "self", ")", ":", "\n", "    ", "sampled_nodes", "=", "self", ".", "sampled_nodes", "\n", "return", "csr_binary_matrix_to_tf", "(", "self", ".", "csr_trimmed", ".", "nonzero", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency._lazy__tf": [[89, 92], ["None"], "methods", ["None"], ["", "def", "_lazy__tf", "(", "self", ")", ":", "\n", "    ", "import", "tensorflow", "\n", "return", "tensorflow", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_trim_x": [[93, 104], ["None"], "methods", ["None"], ["", "def", "torch_trim_x", "(", "self", ",", "x", ",", "unused_x_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"Trims an X matrix. Keeps only the a row or a column in adjacency is set.\n\n    Args:\n      x: tensorflow dense matrix with height equals number of nodes.\n      x_ids: If given, must be a vector with size == x.shape[0].\n        If so, it must contain node IDs corresponding to rows in x.\n        If not given, it is equivalent to passing arange(x.shape[0])\n    \"\"\"", "\n", "#TODO: Deal with x_ids/unused_x_ids in doc/paramaters", "\n", "return", "x", "[", "self", ".", "sampled_nodes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.torch_untrim_gather": [[105, 109], ["numpy.searchsorted"], "methods", ["None"], ["", "def", "torch_untrim_gather", "(", "self", ",", "y", ",", "y_ids", "=", "None", ")", ":", "\n", "    ", "sampled_nodes", "=", "self", ".", "sampled_nodes", "\n", "positions", "=", "np", ".", "searchsorted", "(", "sampled_nodes", ",", "y_ids", ")", "\n", "return", "y", "[", "positions", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.tf_trim_x": [[110, 122], ["accumulation.SampledAdjacency._tf.gather"], "methods", ["None"], ["", "def", "tf_trim_x", "(", "self", ",", "x", ",", "unused_x_ids", "=", "None", ")", ":", "\n", "    ", "\"\"\"Trims an X matrix. Keeps only the a row or a column in adjacency is set.\n\n    Args:\n      x: tensorflow dense matrix with height equals number of nodes.\n      x_ids: If given, must be a vector with size == x.shape[0].\n        If so, it must contain node IDs corresponding to rows in x.\n        If not given, it is equivalent to passing arange(x.shape[0])\n    \"\"\"", "\n", "#TODO: Deal with x_ids/unused_x_ids in doc/paramaters", "\n", "sampled_nodes", "=", "self", ".", "sampled_nodes", "\n", "return", "self", ".", "_tf", ".", "gather", "(", "x", ",", "sampled_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.SampledAdjacency.tf_untrim_gather": [[123, 127], ["numpy.searchsorted", "accumulation.SampledAdjacency._tf.gather"], "methods", ["None"], ["", "def", "tf_untrim_gather", "(", "self", ",", "y", ",", "y_ids", "=", "None", ")", ":", "\n", "    ", "sampled_nodes", "=", "self", ".", "sampled_nodes", "\n", "positions", "=", "np", ".", "searchsorted", "(", "sampled_nodes", ",", "y_ids", ")", "\n", "return", "self", ".", "_tf", ".", "gather", "(", "y", ",", "positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.AccFunction.__init__": [[177, 182], ["copy.deepcopy"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "acc_fn", ",", "acc_arg", ",", "acc_handler", ")", ":", "\n", "      ", "self", ".", "acc_fn", "=", "acc_fn", "\n", "self", ".", "acc_arg_default", "=", "copy", ".", "deepcopy", "(", "acc_arg", ")", "\n", "self", ".", "acc_arg", "=", "acc_arg", "\n", "self", ".", "acc_handler", "=", "acc_handler", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.AccFunction.wrap": [[183, 189], ["accumulation.AccFunction", "copy.deepcopy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "wrap", "(", "acc_arg", "=", "None", ",", "acc_handler", "=", "None", ")", ":", "\n", "      ", "def", "wrapper", "(", "wrapped", ")", ":", "\n", "          ", "runnable", "=", "AccFunction", "(", "wrapped", ",", "copy", ".", "deepcopy", "(", "acc_arg", ")", ",", "acc_handler", ")", "\n", "return", "runnable", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.AccFunction.reset_acc": [[190, 192], ["copy.deepcopy"], "methods", ["None"], ["", "def", "reset_acc", "(", "self", ")", ":", "\n", "      ", "self", ".", "acc_arg", "=", "copy", ".", "deepcopy", "(", "self", ".", "acc_arg_default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.AccFunction.__call__": [[193, 198], ["accumulation.AccFunction.acc_fn", "accumulation.AccFunction.acc_fn"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "walk_forest", ",", "nodes", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "      ", "if", "self", ".", "acc_arg", "is", "not", "None", ":", "\n", "          ", "return", "self", ".", "acc_fn", "(", "walk_forest", ",", "nodes", ",", "self", ".", "acc_arg", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "          ", "return", "self", ".", "acc_fn", "(", "walk_forest", ",", "nodes", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.accumulate_unique_edges": [[128, 145], ["range", "numpy.concatenate", "numpy.unique", "numpy.repeat", "numpy.stack().reshape", "np.unique.append", "numpy.concatenate", "numpy.unique", "len", "numpy.stack"], "function", ["None"], ["", "", "def", "accumulate_unique_edges", "(", "walk_forest", ",", "directed", "=", "False", ")", ":", "\n", "  ", "all_edges", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "walk_forest", ")", "-", "1", ")", ":", "\n", "    ", "src", "=", "walk_forest", "[", "i", "]", "\n", "dst", "=", "walk_forest", "[", "i", "+", "1", "]", "\n", "fanout", "=", "dst", ".", "shape", "[", "1", "]", "//", "src", ".", "shape", "[", "1", "]", "\n", "src_repeated", "=", "np", ".", "repeat", "(", "src", ",", "fanout", ",", "axis", "=", "1", ")", "\n", "step_edges", "=", "np", ".", "stack", "(", "[", "src_repeated", ",", "dst", "]", ",", "-", "1", ")", ".", "reshape", "(", "(", "-", "1", ",", "2", ")", ")", "\n", "all_edges", ".", "append", "(", "step_edges", ")", "\n", "", "all_edges", "=", "np", ".", "concatenate", "(", "all_edges", ",", "0", ")", "\n", "all_edges", "=", "np", ".", "unique", "(", "all_edges", ",", "axis", "=", "0", ")", "\n", "\n", "if", "not", "directed", ":", "\n", "    ", "all_edges", "=", "np", ".", "concatenate", "(", "[", "all_edges", ",", "all_edges", "[", ":", ",", ":", ":", "-", "1", "]", "]", ",", "0", ")", "\n", "all_edges", "=", "np", ".", "unique", "(", "all_edges", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "all_edges", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.forest_to_loss_accumulation": [[147, 149], ["None"], "function", ["None"], ["", "def", "forest_to_loss_accumulation", "(", "walk_forest", ")", ":", "\n", "  ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.accumulation.csr_binary_matrix_to_tf": [[152, 162], ["mat.nonzero", "tf.stack", "tf.ones", "tf.sparse.SparseTensor", "tf.convert_to_tensor", "tf.convert_to_tensor"], "function", ["None"], ["", "def", "csr_binary_matrix_to_tf", "(", "mat", ")", ":", "\n", "  ", "import", "tensorflow", "as", "tf", "\n", "rows", ",", "cols", "=", "mat", ".", "nonzero", "(", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "\n", "tf", ".", "convert_to_tensor", "(", "rows", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "tf", ".", "convert_to_tensor", "(", "cols", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "]", ",", "axis", "=", "-", "1", ")", "\n", "values", "=", "tf", ".", "ones", "(", "rows", ".", "shape", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "tf", ".", "sparse", ".", "SparseTensor", "(", "indices", ",", "values", ",", "\n", "dense_shape", "=", "(", "mat", ".", "shape", "[", "0", "]", ",", "mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.__init__": [[14, 53], ["print", "compact_adj.CompactAdjacency.compact_adj.tocsr", "len", "scipy.sparse.dok_matrix", "numpy.zeros", "tqdm.tqdm.tqdm", "ValueError", "print", "isinstance", "len", "set", "range", "len", "isinstance", "numpy.array", "list", "isinstance", "numpy.array", "compact_adj.CompactAdjacency.adj[].intersection", "list", "compact_adj.CompactAdjacency.adj[].nonzero", "numpy.arange", "len"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "adj", ",", "precomputed", "=", "None", ",", "subset", "=", "None", ")", ":", "\n", "    ", "\"\"\"Constructs CompactAdjacency.\n\n    Args:\n      adj: scipy sparse matrix containing full adjacency.\n      precomputed: If given, must be a tuple (compact_adj, degrees).\n        In this case, adj must be None. If supplied, subset will be ignored.\n    \"\"\"", "\n", "if", "adj", "is", "None", ":", "\n", "      ", "return", "\n", "\n", "", "if", "precomputed", ":", "\n", "      ", "if", "adj", "is", "not", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'Both adj and precomputed are set.'", ")", "\n", "", "if", "subset", "is", "not", "None", ":", "\n", "        ", "print", "(", "'WARNING: subset is provided. It is ignored, since precomputed is supplied.'", ")", "\n", "", "self", ".", "compact_adj", ",", "self", ".", "degrees", "=", "precomputed", "\n", "self", ".", "num_nodes", "=", "len", "(", "self", ".", "degrees", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "adj", "=", "adj", "\n", "self", ".", "num_nodes", "=", "len", "(", "self", ".", "adj", ")", "if", "isinstance", "(", "self", ".", "adj", ",", "dict", ")", "else", "self", ".", "adj", ".", "shape", "[", "0", "]", "\n", "self", ".", "compact_adj", "=", "scipy", ".", "sparse", ".", "dok_matrix", "(", "\n", "(", "self", ".", "num_nodes", ",", "self", ".", "num_nodes", ")", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "degrees", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "num_nodes", "]", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "node_set", "=", "set", "(", "subset", ")", "if", "subset", "is", "not", "None", "else", "None", "\n", "\n", "for", "v", "in", "tqdm", "(", "range", "(", "self", ".", "num_nodes", ")", ",", "desc", "=", "'Compacting adjacency'", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "adj", ",", "dict", ")", "and", "self", ".", "node_set", "is", "not", "None", ":", "\n", "          ", "connection_ids", "=", "np", ".", "array", "(", "list", "(", "self", ".", "adj", "[", "v", "]", ".", "intersection", "(", "self", ".", "node_set", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "adj", ",", "dict", ")", "and", "self", ".", "node_set", "is", "None", ":", "\n", "          ", "connection_ids", "=", "np", ".", "array", "(", "list", "(", "self", ".", "adj", "[", "v", "]", ")", ")", "\n", "", "else", ":", "\n", "          ", "connection_ids", "=", "self", ".", "adj", "[", "v", "]", ".", "nonzero", "(", ")", "[", "1", "]", "\n", "\n", "", "self", ".", "degrees", "[", "v", "]", "=", "len", "(", "connection_ids", ")", "\n", "self", ".", "compact_adj", "[", "v", ",", "np", ".", "arange", "(", "len", "(", "connection_ids", ")", ",", "dtype", "=", "'int32'", ")", "]", "=", "connection_ids", "\n", "\n", "", "", "print", "(", "'Converting to csr'", ")", "\n", "self", ".", "compact_adj", "=", "self", ".", "compact_adj", ".", "tocsr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file": [[54, 63], ["compact_adj.CompactAdjacency", "pickle.load", "gzip.open"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "from_file", "(", "filename", ")", ":", "\n", "    ", "instance", "=", "CompactAdjacency", "(", "None", ",", "None", ")", "\n", "data", "=", "pickle", ".", "load", "(", "gzip", ".", "open", "(", "filename", ",", "'rb'", ")", ")", "\n", "instance", ".", "compact_adj", "=", "data", "[", "'compact_adj'", "]", "\n", "instance", ".", "adj", "=", "data", "[", "'adj'", "]", "\n", "instance", ".", "degrees", "=", "data", "[", "'degrees'", "]", "if", "'degrees'", "in", "data", "else", "data", "[", "'lengths'", "]", "\n", "instance", ".", "num_nodes", "=", "data", "[", "'num_nodes'", "]", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_directory": [[64, 75], ["compact_adj.CompactAdjacency", "numpy.load", "scipy.sparse.load_npz", "print", "IPython.embed", "scipy.sparse.load_npz", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "from_directory", "(", "directory", ")", ":", "\n", "    ", "instance", "=", "CompactAdjacency", "(", "None", ",", "None", ")", "\n", "instance", ".", "degrees", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'degrees.npy'", ")", ")", "\n", "instance", ".", "compact_adj", "=", "scipy", ".", "sparse", ".", "load_npz", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'cadj.npz'", ")", ")", "\n", "print", "(", "'\\n\\ncompact_adj.py from_directory\\n\\n'", ")", "\n", "# Make adj from cadj and save to adj.npz", "\n", "import", "IPython", ";", "IPython", ".", "embed", "(", ")", "\n", "instance", ".", "adj", "=", "scipy", ".", "sparse", ".", "load_npz", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'adj.npz'", ")", ")", "\n", "instance", ".", "num_nodes", "=", "instance", ".", "adj", ".", "shape", "[", "0", "]", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.save": [[76, 84], ["gzip.open", "pickle.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "    ", "with", "gzip", ".", "open", "(", "filename", ",", "'wb'", ")", "as", "fout", ":", "\n", "      ", "pickle", ".", "dump", "(", "{", "\n", "'compact_adj'", ":", "self", ".", "compact_adj", ",", "\n", "'adj'", ":", "self", ".", "adj", ",", "\n", "'degrees'", ":", "self", ".", "degrees", ",", "\n", "'num_nodes'", ":", "self", ".", "num_nodes", ",", "\n", "}", ",", "fout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.neighbors_of": [[85, 88], ["compact_adj.CompactAdjacency.compact_adj[].todense", "numpy.array"], "methods", ["None"], ["", "", "def", "neighbors_of", "(", "self", ",", "node", ")", ":", "\n", "    ", "neighbors", "=", "self", ".", "compact_adj", "[", "node", ",", ":", "self", ".", "degrees", "[", "node", "]", "]", ".", "todense", "(", ")", "\n", "return", "np", ".", "array", "(", "neighbors", ")", "[", "0", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.traversals.np_traverse": [[14, 41], ["isinstance", "ValueError", "ValueError", "len", "numpy.expand_dims", "sample_fn", "forest_array.append", "len", "len", "str().startswith", "str"], "function", ["None"], ["def", "np_traverse", "(", "compact_adj", ",", "seed_nodes", ",", "fanouts", "=", "(", "1", ",", ")", ",", "sample_fn", "=", "samplers", ".", "np_uniform_sample_next", ")", ":", "\n", "  ", "\"\"\"Traverses using numpy. Returns walk tree.\n  \n  Args:\n    compact_adj: instance of CompactAdj\n    seed_nodes: np.array of type int32. Can be 1D or 2D.\n    fanouts: The list (iterable) of fanout sizes to use on each step\n    sample_fn: The sampling function to describe the random walk \n  \"\"\"", "\n", "if", "not", "isinstance", "(", "seed_nodes", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'Seed must a numpy array'", ")", "\n", "\n", "", "if", "len", "(", "seed_nodes", ".", "shape", ")", ">", "2", "or", "len", "(", "seed_nodes", ".", "shape", ")", "<", "1", "or", "not", "str", "(", "seed_nodes", ".", "dtype", ")", ".", "startswith", "(", "'int'", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'seed_nodes must be 1D or 2D int array'", ")", "\n", "\n", "", "if", "len", "(", "seed_nodes", ".", "shape", ")", "==", "1", ":", "\n", "    ", "seed_nodes", "=", "np", ".", "expand_dims", "(", "seed_nodes", ",", "1", ")", "\n", "\n", "# Make walk-tree", "\n", "", "forest_array", "=", "[", "seed_nodes", "]", "\n", "for", "f", "in", "fanouts", ":", "\n", "    ", "next_level", "=", "sample_fn", "(", "compact_adj", ",", "forest_array", ",", "f", ")", "\n", "assert", "next_level", ".", "shape", "[", "1", "]", "==", "forest_array", "[", "-", "1", "]", ".", "shape", "[", "1", "]", "*", "f", "\n", "\n", "forest_array", ".", "append", "(", "next_level", ")", "\n", "\n", "", "return", "forest_array", "\n", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.kipf_gcn.KipfGCN.__init__": [[8, 13], ["tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "num_classes", ",", "unused_num_feats", ",", "hidden_dim", "=", "64", ",", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "layer1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "hidden_dim", ",", "use_bias", "=", "False", ")", "\n", "self", ".", "dropout1", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "layer2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "num_classes", ",", "use_bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.kipf_gcn.KipfGCN.trainable_variables": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_variables", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "layer1", ".", "trainable_variables", "+", "self", ".", "layer2", ".", "trainable_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.kipf_gcn.KipfGCN.__call__": [[18, 30], ["isinstance", "kipf_gcn.KipfGCN.layer1", "tensorflow.nn.relu", "kipf_gcn.KipfGCN.layer2", "renorm", "utils.tf_utils.adj_times_x", "utils.tf_utils.adj_times_x", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.tf_utils.adj_times_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.tf_utils.adj_times_x"], ["", "def", "__call__", "(", "self", ",", "x", ",", "adj", ",", "training", "=", "True", ",", "renorm", "=", "tf_utils", ".", "kipf_renorm_tf", ")", ":", "\n", "    ", "if", "renorm", ":", "\n", "      ", "adj", "=", "renorm", "(", "adj", ")", "# Add ones along diagonal & symmetric degree norm.", "\n", "", "assert", "isinstance", "(", "adj", ",", "tf", ".", "sparse", ".", "SparseTensor", ")", "\n", "adj", "=", "adj", "\n", "\n", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "tf_utils", ".", "adj_times_x", "(", "adj", ",", "x", ")", ")", "# GC layer", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "if", "training", ":", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "x", ")", "\n", "return", "self", ".", "layer2", "(", "tf_utils", ".", "adj_times_x", "(", "adj", ",", "x", ")", ")", "# GC layer", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.kipf_gcn.SimpleGCN.__init__": [[35, 39], ["tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "num_classes", ",", "unused_num_feats", ",", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "dropout1", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "layer2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "num_classes", ",", "use_bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.kipf_gcn.SimpleGCN.trainable_variables": [[40, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_variables", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "layer2", ".", "trainable_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.kipf_gcn.SimpleGCN.__call__": [[44, 53], ["isinstance", "utils.tf_utils.adj_times_x", "kipf_gcn.SimpleGCN.layer2", "renorm", "utils.tf_utils.adj_times_x"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.tf_utils.adj_times_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.tf_utils.adj_times_x"], ["", "def", "__call__", "(", "self", ",", "x", ",", "adj", ",", "training", "=", "True", ",", "renorm", "=", "tf_utils", ".", "kipf_renorm_tf", ")", ":", "\n", "    ", "if", "renorm", ":", "\n", "      ", "adj", "=", "renorm", "(", "adj", ")", "# Add ones along diagonal & symmetric degree norm.", "\n", "", "assert", "isinstance", "(", "adj", ",", "tf", ".", "sparse", ".", "SparseTensor", ")", "\n", "adj", "=", "adj", "\n", "\n", "x", "=", "tf_utils", ".", "adj_times_x", "(", "adj", ",", "x", ")", "\n", "#if training: x = tf.keras.layers.Dropout(0.8)(x)", "\n", "return", "self", ".", "layer2", "(", "tf_utils", ".", "adj_times_x", "(", "adj", ",", "x", ")", ")", "# GC layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.deepwalk.calculate_deepwalk_loss_on_forest": [[8, 53], ["int", "tensorflow.nn.embedding_lookup", "enumerate", "numpy.random.choice", "tensorflow.nn.embedding_lookup", "utils.common.asym_dot", "utils.common.asym_dot", "tensorflow.math.reduce_logsumexp", "len", "tensorflow.nn.embedding_lookup", "tensorflow.expand_dims", "tensorflow.stop_gradient", "tensorflow.transpose", "len", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.asym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.asym_dot"], ["def", "calculate_deepwalk_loss_on_forest", "(", "Z", ",", "forest", ",", "negative_samples", "=", "5", ")", ":", "\n", "  ", "\"\"\"\n\n  Args:\n    Z: embedding dictionary tensor\n    forest: list of 2D int tensors of node IDs\n  \n  Return:\n    tuple of two float (pos_loss, neg_loss) losses approximating -log P(u|v).\n    where P(u|v) = softmax <L_u, R_v>\n    where L_u is left-half(Z[u]) and R_v is right-half(Z[v])\n    Since -log P = -log softmax = - <L_u, R_v> + LogSumExp_t <L_u, L_t>\n    the returned result will contain a pair: \n      pos_loss = - <L_u, R_v>\n      neg_loss =~ LogSumExp_t <L_u, L_t> [only an approximation, using `negative_samples` negatives]\n  \"\"\"", "\n", "num_nodes", "=", "int", "(", "Z", ".", "shape", "[", "0", "]", ")", "\n", "center_embeds", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "Z", ",", "forest", "[", "0", "]", "[", ":", ",", "0", "]", ")", "\n", "\n", "## POSITIVES.", "\n", "mean_context_embeds", "=", "None", "\n", "window_size", "=", "len", "(", "forest", ")", "-", "1", "\n", "total_weight", "=", "0", "\n", "for", "w", ",", "context_nodes", "in", "enumerate", "(", "forest", "[", "1", ":", "]", ")", ":", "\n", "    ", "context_embeds", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "Z", ",", "context_nodes", ")", "\n", "if", "mean_context_embeds", "is", "None", ":", "\n", "      ", "mean_context_embeds", "=", "tf", ".", "reduce_mean", "(", "context_embeds", ",", "axis", "=", "1", ")", "*", "(", "window_size", "-", "w", ")", "/", "window_size", "\n", "", "else", ":", "\n", "      ", "mean_context_embeds", "+=", "tf", ".", "reduce_mean", "(", "context_embeds", ",", "axis", "=", "1", ")", "*", "(", "window_size", "-", "w", ")", "/", "window_size", "\n", "", "total_weight", "+=", "(", "window_size", "-", "w", ")", "/", "window_size", "\n", "\n", "## NEGATIVES.", "\n", "", "negs", "=", "np", ".", "random", ".", "choice", "(", "num_nodes", ",", "size", "=", "(", "len", "(", "forest", "[", "0", "]", ")", ",", "negative_samples", ")", ")", "\n", "neg_embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "Z", ",", "negs", ")", "\n", "# shape: num pos X num neg", "\n", "#center_dot_negs = tf.reduce_sum(tf.expand_dims(center_embeds, 1) * neg_embeddings, axis=-1)", "\n", "center_dot_negs", "=", "asym_dot", "(", "\n", "tf", ".", "expand_dims", "(", "center_embeds", ",", "2", ")", ",", "\n", "tf", ".", "stop_gradient", "(", "tf", ".", "transpose", "(", "neg_embeddings", ",", "(", "0", ",", "2", ",", "1", ")", ")", ")", ",", "sum_fn", "=", "tf", ".", "math", ".", "reduce_sum", ",", "axis", "=", "1", ")", "\n", "#center_dot_context = tf.reduce_sum(center_embeds * mean_context_embeds, axis=-1)", "\n", "center_dot_context", "=", "asym_dot", "(", "center_embeds", ",", "mean_context_embeds", ",", "sum_fn", "=", "tf", ".", "math", ".", "reduce_sum", ",", "axis", "=", "1", ")", "\n", "neg_loss", "=", "tf", ".", "math", ".", "reduce_logsumexp", "(", "center_dot_negs", ",", "axis", "=", "1", ")", "\n", "pos_loss", "=", "-", "center_dot_context", "\n", "\n", "return", "pos_loss", ",", "neg_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopGCN.__init__": [[9, 27], ["enumerate", "mixhop.MixHopGCN.mixhop_layers.append", "max", "enumerate", "mixhop_layer.append", "len", "tensorflow.keras.layers.Dense"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "layer_dims", ",", "use_bias", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      layer_dims: must be list of lists. Outer list indicates number of layers\n        and inner list determines the dimensions devoted to each adjacency power.\n    \"\"\"", "\n", "self", ".", "layer_dims", "=", "layer_dims", "\n", "self", ".", "mixhop_layers", "=", "[", "]", "\n", "self", ".", "all_layers", "=", "[", "]", "\n", "self", ".", "max_power", "=", "0", "\n", "for", "i", ",", "layer_d", "in", "enumerate", "(", "layer_dims", ")", ":", "\n", "      ", "mixhop_layer", "=", "[", "]", "\n", "self", ".", "mixhop_layers", ".", "append", "(", "mixhop_layer", ")", "\n", "self", ".", "max_power", "=", "max", "(", "self", ".", "max_power", ",", "len", "(", "layer_d", ")", "-", "1", ")", "\n", "for", "j", ",", "dim", "in", "enumerate", "(", "layer_d", ")", ":", "\n", "        ", "mixhop_layer", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "use_bias", "=", "use_bias", ",", "name", "=", "'MixHop_L%i_pow%i'", "%", "(", "i", ",", "j", ")", ")", ")", "\n", "", "self", ".", "all_layers", "+=", "mixhop_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopGCN.trainable_variables": [[28, 34], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "trainable_variables", "(", "self", ")", ":", "\n", "    ", "variables", "=", "[", "]", "\n", "for", "layer", "in", "self", ".", "all_layers", ":", "\n", "      ", "variables", "+=", "layer", ".", "trainable_variables", "\n", "", "return", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopGCN.__call__": [[35, 53], ["enumerate", "renorm", "range", "tensorflow.concat", "utils.tf_utils.adj_times_x", "adj_pow_times_x.append", "sub_layer", "tensorflow.nn.relu", "enumerate", "len", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.tf_utils.adj_times_x"], ["", "def", "__call__", "(", "self", ",", "x", ",", "adj", ",", "training", "=", "True", ",", "renorm", "=", "tf_utils", ".", "kipf_renorm_tf", ")", ":", "\n", "    ", "if", "renorm", ":", "\n", "      ", "adj", "=", "renorm", "(", "adj", ")", "# Add ones along diagonal & symmetric degree norm.", "\n", "", "t_adj", "=", "adj", "\n", "for", "k", ",", "mixhop_layer", "in", "enumerate", "(", "self", ".", "mixhop_layers", ")", ":", "\n", "      ", "adj_pow_times_x", "=", "[", "x", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "max_power", ")", ":", "\n", "        ", "next_val", "=", "tf_utils", ".", "adj_times_x", "(", "t_adj", ",", "adj_pow_times_x", "[", "-", "1", "]", ")", "\n", "adj_pow_times_x", ".", "append", "(", "next_val", ")", "\n", "\n", "", "layer_output", "=", "[", "sub_layer", "(", "adj_pow_times_x", "[", "j", "]", ")", "for", "j", ",", "sub_layer", "in", "enumerate", "(", "mixhop_layer", ")", "]", "\n", "layer_output", "=", "tf", ".", "concat", "(", "layer_output", ",", "axis", "=", "1", ")", "\n", "x", "=", "layer_output", "\n", "if", "k", "<", "len", "(", "self", ".", "mixhop_layers", ")", "-", "1", ":", "\n", "        ", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "if", "training", ":", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "x", ")", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopWithPSumClassifier.__init__": [[58, 62], ["mixhop.MixHopGCN"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "num_classes", ",", "unused_num_feats", ",", "layer_dims", ",", "use_bias", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "mixhop", "=", "MixHopGCN", "(", "layer_dims", ",", "use_bias", "=", "False", ",", "**", "kwargs", ")", "\n", "self", ".", "psum_weights", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopWithPSumClassifier.trainable_variables": [[63, 66], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_variables", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "mixhop", ".", "trainable_variables", "+", "[", "self", ".", "psum_weights", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopWithPSumClassifier.__call__": [[67, 84], ["mixhop.MixHopWithPSumClassifier.mixhop", "range", "tensorflow.stack", "tensorflow.reduce_sum", "tensorflow.Variable", "tensorflow.stack.append", "tensorflow.nn.softmax", "tensorflow.zeros"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ",", "adj", ",", "training", "=", "True", ",", "renorm", "=", "tf_utils", ".", "kipf_renorm_tf", ")", ":", "\n", "    ", "x", "=", "self", ".", "mixhop", "(", "x", ",", "adj", ",", "training", "=", "training", ",", "renorm", "=", "renorm", ")", "\n", "assert", "x", ".", "shape", "[", "1", "]", "%", "self", ".", "num_classes", "==", "0", "\n", "\n", "num_groups", "=", "x", ".", "shape", "[", "1", "]", "//", "self", ".", "num_classes", "\n", "if", "self", ".", "psum_weights", "is", "None", ":", "\n", "      ", "self", ".", "psum_weights", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "num_groups", "]", ")", ",", "name", "=", "'psum_weights'", ")", "\n", "\n", "", "output_divided", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "num_groups", ")", ":", "\n", "      ", "output_divided", ".", "append", "(", "x", "[", ":", ",", "j", "*", "self", ".", "num_classes", ":", "(", "j", "+", "1", ")", "*", "self", ".", "num_classes", "]", ")", "\n", "\n", "", "output_divided", "=", "tf", ".", "stack", "(", "output_divided", ",", "2", ")", "\n", "output_final", "=", "output_divided", "*", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "psum_weights", ")", "\n", "output_final", "=", "tf", ".", "reduce_sum", "(", "output_final", ",", "-", "1", ")", "\n", "\n", "return", "output_final", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopWithFCClassifier.__init__": [[89, 93], ["mixhop.MixHopGCN", "tensorflow.keras.layers.Dense"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "num_classes", ",", "unused_num_feats", ",", "layer_dims", ",", "use_bias", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "mixhop", "=", "MixHopGCN", "(", "layer_dims", ",", "use_bias", "=", "False", ",", "**", "kwargs", ")", "\n", "self", ".", "fc", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopWithFCClassifier.trainable_variables": [[94, 97], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_variables", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "mixhop", ".", "trainable_variables", "+", "self", ".", "fc", ".", "trainable_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_tf.mixhop.MixHopWithFCClassifier.__call__": [[98, 104], ["mixhop.MixHopWithFCClassifier.mixhop", "tensorflow.nn.relu", "mixhop.MixHopWithFCClassifier.fc", "tensorflow.keras.layers.Dropout"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ",", "adj", ",", "training", "=", "True", ",", "renorm", "=", "tf_utils", ".", "kipf_renorm_tf", ")", ":", "\n", "    ", "x", "=", "self", ".", "mixhop", "(", "x", ",", "adj", ",", "training", "=", "training", ",", "renorm", "=", "renorm", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "if", "training", ":", "\n", "      ", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "x", ")", "\n", "", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.deepwalk.DeepWalk.__init__": [[11, 20], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Parameter", "torch.from_numpy", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__"], []], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.deepwalk.DeepWalk.embeddings": [[21, 23], ["None"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.deepwalk.DeepWalk.loss": [[24, 75], ["deepwalk.DeepWalk.Z", "enumerate", "torch.from_numpy", "deepwalk.DeepWalk.Z", "utils.common.asym_dot", "utils.common.asym_dot", "torch.logsumexp", "torch.mean", "deepwalk.DeepWalk.Z", "numpy.random.choice", "torch.transpose().detach", "torch.transpose", "len"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.asym_dot", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.utils.common.asym_dot"], ["num_nodes", "=", "int", "(", "Z", ".", "shape", "[", "0", "]", ")", "\n", "center_embeds", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "Z", ",", "forest", "[", "0", "]", "[", ":", ",", "0", "]", ")", "\n", "\n", "## POSITIVES.", "\n", "mean_context_embeds", "=", "None", "\n", "window_size", "=", "len", "(", "forest", ")", "-", "1", "\n", "total_weight", "=", "0", "\n", "for", "w", ",", "context_nodes", "in", "enumerate", "(", "forest", "[", "1", ":", "]", ")", ":", "\n", "    ", "context_embeds", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "Z", ",", "context_nodes", ")", "\n", "if", "mean_context_embeds", "is", "None", ":", "\n", "      ", "mean_context_embeds", "=", "tf", ".", "reduce_mean", "(", "context_embeds", ",", "axis", "=", "1", ")", "*", "(", "window_size", "-", "w", ")", "/", "window_size", "\n", "", "else", ":", "\n", "      ", "mean_context_embeds", "+=", "tf", ".", "reduce_mean", "(", "context_embeds", ",", "axis", "=", "1", ")", "*", "(", "window_size", "-", "w", ")", "/", "window_size", "\n", "", "total_weight", "+=", "(", "window_size", "-", "w", ")", "/", "window_size", "\n", "\n", "## NEGATIVES.", "\n", "", "negs", "=", "np", ".", "random", ".", "choice", "(", "num_nodes", ",", "size", "=", "(", "len", "(", "forest", "[", "0", "]", ")", ",", "negative_samples", ")", ")", "\n", "neg_embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "Z", ",", "negs", ")", "\n", "# shape: num pos X num neg", "\n", "#center_dot_negs = tf.reduce_sum(tf.expand_dims(center_embeds, 1) * neg_embeddings, axis=-1)", "\n", "center_dot_negs", "=", "asym_dot", "(", "\n", "tf", ".", "expand_dims", "(", "center_embeds", ",", "2", ")", ",", "\n", "tf", ".", "stop_gradient", "(", "tf", ".", "transpose", "(", "neg_embeddings", ",", "(", "0", ",", "2", ",", "1", ")", ")", ")", ",", "sum_fn", "=", "tf", ".", "math", ".", "reduce_sum", ",", "axis", "=", "1", ")", "\n", "#center_dot_context = tf.reduce_sum(center_embeds * mean_context_embeds, axis=-1)", "\n", "center_dot_context", "=", "asym_dot", "(", "center_embeds", ",", "mean_context_embeds", ",", "sum_fn", "=", "tf", ".", "math", ".", "reduce_sum", ",", "axis", "=", "1", ")", "\n", "neg_loss", "=", "tf", ".", "math", ".", "reduce_logsumexp", "(", "center_dot_negs", ",", "axis", "=", "1", ")", "\n", "pos_loss", "=", "-", "center_dot_context", "\n", "\n", "return", "pos_loss", ",", "neg_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.deepwalk.DeepWalk.forward": [[76, 78], ["deepwalk.DeepWalk.Z"], "methods", ["None"], []], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.sage.GraphSage.__init__": [[6, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Parameter", "torch.Parameter", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__"], ["\t", "def", "__init__", "(", "self", ",", "feat_data", ",", "num_classes", ",", "hidden_dim1", ",", "hidden_dim2", ",", "dropout", ")", ":", "\n", "\t\t", "super", "(", "GraphSage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feat_dim", "=", "feat_data", ".", "shape", "[", "1", "]", "\n", "self", ".", "hidden_dim1", "=", "hidden_dim1", "\n", "self", ".", "hidden_dim2", "=", "hidden_dim2", "\n", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Linear", "(", "2", "*", "feat_data", ".", "shape", "[", "1", "]", ",", "hidden_dim1", ",", "bias", "=", "False", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_dim1", ",", "hidden_dim2", ",", "bias", "=", "False", ")", "\n", "self", ".", "output_layer", "=", "nn", ".", "Linear", "(", "hidden_dim2", ",", "num_classes", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "embedding_table", "=", "nn", ".", "Embedding", "(", "feat_data", ".", "shape", "[", "0", "]", ",", "feat_data", ".", "shape", "[", "1", "]", ")", "\n", "self", ".", "embedding_table", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "feat_data", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.sage.GraphSage.forward": [[26, 52], ["sage.GraphSage.embedding_table", "sage.GraphSage.embedding_table", "sage.GraphSage.embedding_table().mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sage.GraphSage.relu", "sage.GraphSage.dropout", "sage.GraphSage.embedding_table().mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sage.GraphSage.relu", "sage.GraphSage.dropout", "feat_1.reshape().mean.reshape().mean.reshape().mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sage.GraphSage.relu", "sage.GraphSage.output_layer", "sage.GraphSage.layer1", "sage.GraphSage.layer1", "sage.GraphSage.layer2", "sage.GraphSage.embedding_table", "sage.GraphSage.embedding_table", "feat_1.reshape().mean.reshape().mean.reshape", "feat_1.reshape().mean.reshape().mean.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "T", ")", ":", "\n", "\t\t", "feat_0", "=", "self", ".", "embedding_table", "(", "T", "[", "0", "]", ")", "# Of shape torch.Size([|B|, feat_dim])", "\n", "feat_1", "=", "self", ".", "embedding_table", "(", "T", "[", "1", "]", ")", "# Of shape torch.size(|B|, fanouts[0], feat_dim)", "\n", "\n", "# Depth 1", "\n", "x", "=", "self", ".", "embedding_table", "(", "T", "[", "1", "]", ")", ".", "mean", "(", "dim", "=", "1", ")", "# Of shape torch.size(|B|, feat_dim)", "\n", "feat_0", "=", "torch", ".", "cat", "(", "(", "feat_0", ",", "x", ")", ",", "dim", "=", "1", ")", "# Of shape torch.size(|B|, 2 * feat_dim)", "\n", "feat_0", "=", "self", ".", "relu", "(", "self", ".", "layer1", "(", "feat_0", ")", ")", "# Of shape torch.size(|B|, hidden_dim1)", "\n", "feat_0", "=", "self", ".", "dropout", "(", "feat_0", ")", "\n", "\n", "# Depth 2", "\n", "x", "=", "self", ".", "embedding_table", "(", "T", "[", "2", "]", ")", ".", "mean", "(", "dim", "=", "1", ")", "# Of shape torch.size(|B|*fanouts[0], feat_dim)\t", "\n", "feat_1", "=", "torch", ".", "cat", "(", "(", "feat_1", ".", "reshape", "(", "-", "1", ",", "self", ".", "feat_dim", ")", ",", "x", ")", ",", "dim", "=", "1", ")", "# Of shape torch.size(|B|*fanouts[0], 2 * feat_dim)", "\n", "feat_1", "=", "self", ".", "relu", "(", "self", ".", "layer1", "(", "feat_1", ")", ")", "# Of shape torch.size(|B|*fanouts[0], hidden_dim1)", "\n", "feat_1", "=", "self", ".", "dropout", "(", "feat_1", ")", "\n", "\n", "# Combine", "\n", "feat_1", "=", "feat_1", ".", "reshape", "(", "T", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "self", ".", "hidden_dim1", ")", ".", "mean", "(", "dim", "=", "1", ")", "# Of shape torch.size([|B|, hidden_dim_1])", "\n", "combined", "=", "torch", ".", "cat", "(", "(", "feat_0", ",", "feat_1", ")", ",", "dim", "=", "1", ")", "# Of shape torch.Size(|B|, 2 * hidden_dim1)", "\n", "embedding", "=", "self", ".", "relu", "(", "self", ".", "layer2", "(", "combined", ")", ")", "# Of shape torch.Size(|B|, hidden_dim2)", "\n", "\n", "\n", "# Output class scores", "\n", "scores", "=", "self", ".", "output_layer", "(", "embedding", ")", "\n", "\n", "return", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GraphConvolution.__init__": [[14, 26], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "gcnii.GraphConvolution.reset_parameters", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GraphConvolution.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "residual", "=", "False", ",", "variant", "=", "False", ")", ":", "\n", "        ", "super", "(", "GraphConvolution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "variant", "=", "variant", "\n", "if", "self", ".", "variant", ":", "\n", "            ", "self", ".", "in_features", "=", "2", "*", "in_features", "\n", "", "else", ":", "\n", "            ", "self", ".", "in_features", "=", "in_features", "\n", "\n", "", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "residual", "=", "residual", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "in_features", ",", "self", ".", "out_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GraphConvolution.reset_parameters": [[27, 30], ["gcnii.GraphConvolution.weight.data.uniform_", "math.sqrt"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "out_features", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GraphConvolution.forward": [[31, 44], ["math.log", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "adj", ",", "h0", ",", "lamda", ",", "alpha", ",", "l", ")", ":", "\n", "        ", "theta", "=", "math", ".", "log", "(", "lamda", "/", "l", "+", "1", ")", "\n", "hi", "=", "torch", ".", "spmm", "(", "adj", ",", "input", ")", "\n", "if", "self", ".", "variant", ":", "\n", "            ", "support", "=", "torch", ".", "cat", "(", "[", "hi", ",", "h0", "]", ",", "1", ")", "\n", "r", "=", "(", "1", "-", "alpha", ")", "*", "hi", "+", "alpha", "*", "h0", "\n", "", "else", ":", "\n", "            ", "support", "=", "(", "1", "-", "alpha", ")", "*", "hi", "+", "alpha", "*", "h0", "\n", "r", "=", "support", "\n", "", "output", "=", "theta", "*", "torch", ".", "mm", "(", "support", ",", "self", ".", "weight", ")", "+", "(", "1", "-", "theta", ")", "*", "r", "\n", "if", "self", ".", "residual", ":", "\n", "            ", "output", "=", "output", "+", "input", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNII.__init__": [[46, 62], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "gcnii.GCNII.fcs.append", "gcnii.GCNII.fcs.append", "list", "list", "torch.ReLU", "torch.ReLU", "torch.ReLU", "gcnii.GCNII.convs.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "gcnii.GCNII.convs.parameters", "gcnii.GCNII.fcs.parameters", "gcnii.GraphConvolution"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters"], ["    ", "def", "__init__", "(", "self", ",", "nclass", ",", "nfeat", ",", "nlayers", "=", "16", ",", "nhidden", "=", "64", ",", "dropout", "=", "0.5", ",", "lamda", "=", ".5", ",", "alpha", "=", "0.1", ",", "variant", "=", "False", ",", "wd1", "=", "0.01", ",", "wd2", "=", "5e-4", ")", ":", "\n", "        ", "super", "(", "GCNII", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "self", ".", "convs", ".", "append", "(", "GraphConvolution", "(", "nhidden", ",", "nhidden", ",", "variant", "=", "variant", ")", ")", "\n", "", "self", ".", "fcs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "fcs", ".", "append", "(", "nn", ".", "Linear", "(", "nfeat", ",", "nhidden", ")", ")", "\n", "self", ".", "fcs", ".", "append", "(", "nn", ".", "Linear", "(", "nhidden", ",", "nclass", ")", ")", "\n", "self", ".", "params1", "=", "list", "(", "self", ".", "convs", ".", "parameters", "(", ")", ")", "\n", "self", ".", "params2", "=", "list", "(", "self", ".", "fcs", ".", "parameters", "(", ")", ")", "\n", "self", ".", "act_fn", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "lamda", "=", "lamda", "\n", "self", ".", "wd1", "=", "wd1", "\n", "self", ".", "wd2", "=", "wd2", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNII.forward": [[63, 74], ["torch.dropout", "torch.dropout", "torch.dropout", "gcnii.GCNII.act_fn", "_layers.append", "enumerate", "torch.dropout", "torch.dropout", "torch.dropout", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.dropout", "torch.dropout", "torch.dropout", "gcnii.GCNII.act_fn", "con"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "adj", ")", ":", "\n", "        ", "_layers", "=", "[", "]", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "layer_inner", "=", "self", ".", "act_fn", "(", "self", ".", "fcs", "[", "0", "]", "(", "x", ")", ")", "\n", "_layers", ".", "append", "(", "layer_inner", ")", "\n", "for", "i", ",", "con", "in", "enumerate", "(", "self", ".", "convs", ")", ":", "\n", "            ", "layer_inner", "=", "F", ".", "dropout", "(", "layer_inner", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "layer_inner", "=", "self", ".", "act_fn", "(", "con", "(", "layer_inner", ",", "adj", ",", "_layers", "[", "0", "]", ",", "self", ".", "lamda", ",", "self", ".", "alpha", ",", "i", "+", "1", ")", ")", "\n", "", "layer_inner", "=", "F", ".", "dropout", "(", "layer_inner", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "layer_inner", "=", "self", ".", "fcs", "[", "-", "1", "]", "(", "layer_inner", ")", "\n", "return", "F", ".", "log_softmax", "(", "layer_inner", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.__init__": [[76, 89], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "gcnii.GCNIIppi.fcs.append", "gcnii.GCNIIppi.fcs.append", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "gcnii.GCNIIppi.convs.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "gcnii.GraphConvolution"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nfeat", ",", "nlayers", ",", "nhidden", ",", "nclass", ",", "dropout", ",", "lamda", ",", "alpha", ",", "variant", ")", ":", "\n", "        ", "super", "(", "GCNIIppi", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "nlayers", ")", ":", "\n", "            ", "self", ".", "convs", ".", "append", "(", "GraphConvolution", "(", "nhidden", ",", "nhidden", ",", "variant", "=", "variant", ",", "residual", "=", "True", ")", ")", "\n", "", "self", ".", "fcs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "fcs", ".", "append", "(", "nn", ".", "Linear", "(", "nfeat", ",", "nhidden", ")", ")", "\n", "self", ".", "fcs", ".", "append", "(", "nn", ".", "Linear", "(", "nhidden", ",", "nclass", ")", ")", "\n", "self", ".", "act_fn", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "lamda", "=", "lamda", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.parameters": [[90, 94], ["None"], "methods", ["None"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "      ", "return", "[", "\n", "{", "'params'", ":", "self", ".", "params1", ",", "'weight_decay'", ":", "self", ".", "wd1", "}", ",", "\n", "{", "'params'", ":", "self", ".", "params2", ",", "'weight_decay'", ":", "self", ".", "wd2", "}", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.gcnii.GCNIIppi.forward": [[96, 107], ["torch.dropout", "torch.dropout", "torch.dropout", "gcnii.GCNIIppi.act_fn", "_layers.append", "enumerate", "torch.dropout", "torch.dropout", "torch.dropout", "gcnii.GCNIIppi.sig", "torch.dropout", "torch.dropout", "torch.dropout", "gcnii.GCNIIppi.act_fn", "con"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "adj", ")", ":", "\n", "        ", "_layers", "=", "[", "]", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "layer_inner", "=", "self", ".", "act_fn", "(", "self", ".", "fcs", "[", "0", "]", "(", "x", ")", ")", "\n", "_layers", ".", "append", "(", "layer_inner", ")", "\n", "for", "i", ",", "con", "in", "enumerate", "(", "self", ".", "convs", ")", ":", "\n", "            ", "layer_inner", "=", "F", ".", "dropout", "(", "layer_inner", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "layer_inner", "=", "self", ".", "act_fn", "(", "con", "(", "layer_inner", ",", "adj", ",", "_layers", "[", "0", "]", ",", "self", ".", "lamda", ",", "self", ".", "alpha", ",", "i", "+", "1", ")", ")", "\n", "", "layer_inner", "=", "F", ".", "dropout", "(", "layer_inner", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "layer_inner", "=", "self", ".", "sig", "(", "self", ".", "fcs", "[", "-", "1", "]", "(", "layer_inner", ")", ")", "\n", "return", "layer_inner", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.wys.WYS.__init__": [[12, 23], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.random.uniform", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_nodes", ",", "emb_dim", ",", "window_size", ")", ":", "\n", "        ", "super", "(", "WYS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_nodes", "=", "num_nodes", "\n", "self", ".", "window_size", "=", "window_size", "\n", "\n", "self", ".", "Q", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "window_size", ",", ")", ")", "\n", "self", ".", "L", "=", "nn", ".", "Embedding", "(", "self", ".", "num_nodes", ",", "emb_dim", "//", "2", ")", "\n", "self", ".", "L", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0.01", ",", "high", "=", "0.01", ",", "size", "=", "[", "num_nodes", ",", "emb_dim", "]", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "R", "=", "nn", ".", "Embedding", "(", "self", ".", "num_nodes", ",", "emb_dim", "//", "2", ")", "\n", "self", ".", "R", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0.01", ",", "high", "=", "0.01", ",", "size", "=", "[", "num_nodes", ",", "emb_dim", "]", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.wys.WYS.embeddings": [[24, 26], ["None"], "methods", ["None"], ["", "def", "embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "L", ",", "self", ".", "R", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.wys.WYS.loss": [[27, 74], ["wys.WYS.L", "wys.WYS.R", "torch.softmax", "torch.softmax", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "wys.WYS.L", "wys.WYS.R", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "wys.WYS.L", "wys.WYS.R", "obj_terms.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "numpy.random.choice", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "len", "wys.WYS.unsqueeze", "wys.WYS.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "wys.WYS.unsqueeze", "wys.WYS.unsqueeze"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "forest", ",", "negative_samples", "=", "5", ",", "pos_coeff", "=", "5", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          Z: embedding dictionary tensor\n          forest: list of 2D int tensors of node IDs\n\n        Return:\n          tuple of two float (pos_loss, neg_loss) losses approximating -log P(u|v).\n          where P(u|v) = softmax <L_u, R_v>\n          where L_u is left-half(Z[u]) and R_v is right-half(Z[v])\n          Since -log P = -log softmax = - <L_u, R_v> + LogSumExp_t <L_u, L_t>\n          the returned result will contain a pair:\n            pos_loss = - <L_u, R_v>\n            neg_loss =~ LogSumExp_t <L_u, L_t> [only an approximation, using `negative_samples` negatives]\n        \"\"\"", "\n", "\n", "l0", "=", "self", ".", "L", "(", "forest", "[", "0", "]", "[", ":", ",", "0", "]", ")", "\n", "r0", "=", "self", ".", "R", "(", "forest", "[", "0", "]", "[", ":", ",", "0", "]", ")", "\n", "Q_softmax", "=", "F", ".", "softmax", "(", "self", ".", "Q", ",", "dim", "=", "0", ")", "\n", "\n", "## POSITIVES.", "\n", "obj_terms", "=", "[", "]", "\n", "for", "w", ",", "context_nodes", "in", "enumerate", "(", "forest", "[", "1", ":", "]", ")", ":", "\n", "            ", "l", "=", "self", ".", "L", "(", "context_nodes", ")", "\n", "r", "=", "self", ".", "R", "(", "context_nodes", ")", "\n", "pos_term", "=", "-", "(", "Q_softmax", "[", "w", "]", ")", "*", "torch", ".", "mean", "(", "F", ".", "logsigmoid", "(", "0.5", "*", "torch", ".", "sum", "(", "l0", ".", "unsqueeze", "(", "1", ")", "*", "r", ",", "axis", "=", "2", ")", "+", "0.5", "*", "torch", ".", "sum", "(", "r0", ".", "unsqueeze", "(", "1", ")", "*", "l", ",", "axis", "=", "2", ")", ")", ")", "\n", "obj_terms", ".", "append", "(", "pos_term", ")", "\n", "\n", "", "pos_obj_term", "=", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "obj_terms", ")", ")", "\n", "\n", "\n", "# ## NEGATIVES.", "\n", "negs", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "choice", "(", "self", ".", "num_nodes", ",", "size", "=", "(", "len", "(", "forest", "[", "0", "]", ")", ",", "negative_samples", ")", ")", ")", "\n", "neg_l", "=", "self", ".", "L", "(", "negs", ")", "\n", "neg_r", "=", "self", ".", "R", "(", "negs", ")", "\n", "negp", "=", "0.5", "*", "torch", ".", "sum", "(", "l0", ".", "unsqueeze", "(", "1", ")", "*", "neg_r", ",", "axis", "=", "2", ")", "+", "0.5", "*", "torch", ".", "sum", "(", "r0", ".", "unsqueeze", "(", "1", ")", "*", "neg_l", ",", "axis", "=", "2", ")", "\n", "neg_obj_mean", "=", "torch", ".", "mean", "(", "-", "F", ".", "logsigmoid", "(", "-", "negp", ")", ")", "\n", "\n", "# ## REGULARIZER", "\n", "reg_obj", "=", "0.5", "*", "torch", ".", "sum", "(", "self", ".", "Q", "**", "2", ")", "\n", "reg_obj", "+=", "1e-5", "*", "torch", ".", "sum", "(", "self", ".", "L", ".", "weight", "**", "2", ")", "\n", "reg_obj", "+=", "1e-5", "*", "torch", ".", "sum", "(", "self", ".", "R", ".", "weight", "**", "2", ")", "\n", "\n", "total_loss", "=", "pos_obj_term", "+", "neg_obj_mean", "+", "reg_obj", "\n", "\n", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.wys.WYS.forward": [[75, 77], ["wys.WYS.L", "wys.WYS.R"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "L", "(", "x", ")", ",", "self", ".", "R", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__": [[6, 14], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nclass", ",", "nfeat", ",", "k", "=", "2", ")", ":", "\n", "        ", "super", "(", "SGC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#SGC params", "\n", "nfeat", "=", "nfeat", "\n", "nclass", "=", "nclass", "\n", "self", ".", "k", "=", "k", "\n", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "nfeat", ",", "nclass", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.models_pytorch.simple_gcn.SGC.forward": [[15, 19], ["range", "simple_gcn.SGC.W", "torch.spmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "adj", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "            ", "x", "=", "torch", ".", "spmm", "(", "adj", ",", "x", ")", "\n", "", "return", "self", ".", "W", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.concatenate_csr_matrices_by_rows": [[11, 24], ["numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "scipy.sparse.csr_matrix", "len"], "function", ["None"], ["def", "concatenate_csr_matrices_by_rows", "(", "matrix1", ",", "matrix2", ")", ":", "\n", "  ", "\"\"\"Concatenates sparse csr matrices matrix1 above matrix2.\n  \n  Adapted from:\n  https://stackoverflow.com/questions/6844998/is-there-an-efficient-way-of-concatenating-scipy-sparse-matrices\n  \"\"\"", "\n", "new_data", "=", "np", ".", "concatenate", "(", "(", "matrix1", ".", "data", ",", "matrix2", ".", "data", ")", ")", "\n", "new_indices", "=", "np", ".", "concatenate", "(", "(", "matrix1", ".", "indices", ",", "matrix2", ".", "indices", ")", ")", "\n", "new_ind_ptr", "=", "matrix2", ".", "indptr", "+", "len", "(", "matrix1", ".", "data", ")", "\n", "new_ind_ptr", "=", "new_ind_ptr", "[", "1", ":", "]", "\n", "new_ind_ptr", "=", "np", ".", "concatenate", "(", "(", "matrix1", ".", "indptr", ",", "new_ind_ptr", ")", ")", "\n", "\n", "return", "scipy", ".", "sparse", ".", "csr_matrix", "(", "(", "new_data", ",", "new_indices", ",", "new_ind_ptr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_x": [[27, 29], ["pickle.load", "open"], "function", ["None"], ["", "def", "load_x", "(", "filename", ")", ":", "\n", "  ", "return", "pickle", ".", "load", "(", "open", "(", "filename", ",", "'rb'", ")", ",", "encoding", "=", "'latin1'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.read_planetoid_dataset": [[30, 88], ["os.path.expanduser", "pickle.load", "datasets.load_x", "numpy.array", "datasets.load_x", "list", "scipy.sparse.csr_matrix", "datasets.concatenate_csr_matrices_by_rows", "concatenate_csr_matrices_by_rows.tolil", "set", "numpy.array", "numpy.concatenate", "len", "collections.defaultdict", "pickle.load.items", "collections.defaultdict.items", "numpy.array", "numpy.array", "scipy.sparse.csr_matrix", "os.path.join", "os.path.exists", "ValueError", "open", "numpy.load", "map", "numpy.load", "os.path.expanduser", "max", "min", "numpy.zeros", "edge_sets[].add", "edge_sets[].add", "np.array.append", "np.array.append", "open().read().split", "open().read", "open"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_x", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.concatenate_csr_matrices_by_rows"], ["", "def", "read_planetoid_dataset", "(", "dataset_name", "=", "'ind.cora'", ",", "dataset_dir", "=", "'~/data/planetoid/data/'", ")", ":", "\n", "  ", "base_path", "=", "os", ".", "path", ".", "expanduser", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "dataset_name", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "expanduser", "(", "dataset_dir", ")", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'cannot find dataset_dir=%s. Please:\\nmkdir -p ~/data; cd ~/data; git clone git@github.com:kimiyoung/planetoid.git'", ")", "\n", "", "edge_lists", "=", "pickle", ".", "load", "(", "open", "(", "base_path", "+", "'.graph'", ",", "'rb'", ")", ")", "\n", "\n", "allx", "=", "load_x", "(", "base_path", "+", "'.allx'", ")", "\n", "\n", "ally", "=", "np", ".", "array", "(", "np", ".", "load", "(", "base_path", "+", "'.ally'", ",", "allow_pickle", "=", "True", ")", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "testx", "=", "load_x", "(", "base_path", "+", "'.tx'", ")", "\n", "\n", "# Add test", "\n", "test_idx", "=", "list", "(", "map", "(", "int", ",", "open", "(", "base_path", "+", "'.test.index'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "num_test_examples", "=", "max", "(", "test_idx", ")", "-", "min", "(", "test_idx", ")", "+", "1", "\n", "sparse_zeros", "=", "scipy", ".", "sparse", ".", "csr_matrix", "(", "(", "num_test_examples", ",", "allx", ".", "shape", "[", "1", "]", ")", ",", "\n", "dtype", "=", "'float32'", ")", "\n", "\n", "allx", "=", "concatenate_csr_matrices_by_rows", "(", "allx", ",", "sparse_zeros", ")", "\n", "llallx", "=", "allx", ".", "tolil", "(", ")", "\n", "llallx", "[", "test_idx", "]", "=", "testx", "\n", "#allx = scipy.vstack([allx, sparse_zeros])", "\n", "\n", "test_idx_set", "=", "set", "(", "test_idx", ")", "\n", "\n", "\n", "testy", "=", "np", ".", "array", "(", "np", ".", "load", "(", "base_path", "+", "'.ty'", ",", "allow_pickle", "=", "True", ")", ",", "dtype", "=", "'float32'", ")", "\n", "ally", "=", "np", ".", "concatenate", "(", "\n", "[", "ally", ",", "np", ".", "zeros", "(", "(", "num_test_examples", ",", "ally", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "'float32'", ")", "]", ",", "\n", "0", ")", "\n", "ally", "[", "test_idx", "]", "=", "testy", "\n", "\n", "num_nodes", "=", "len", "(", "edge_lists", ")", "\n", "\n", "# Will be used to construct (sparse) adjacency matrix.", "\n", "edge_sets", "=", "collections", ".", "defaultdict", "(", "set", ")", "\n", "for", "node", ",", "neighbors", "in", "edge_lists", ".", "items", "(", ")", ":", "\n", "    ", "for", "n", "in", "neighbors", ":", "\n", "      ", "edge_sets", "[", "node", "]", ".", "add", "(", "n", ")", "\n", "edge_sets", "[", "n", "]", ".", "add", "(", "node", ")", "# Assume undirected.", "\n", "\n", "# Now, build adjacency list.", "\n", "", "", "adj_indices", "=", "[", "]", "\n", "adj_values", "=", "[", "]", "\n", "for", "node", ",", "neighbors", "in", "edge_sets", ".", "items", "(", ")", ":", "\n", "    ", "for", "n", "in", "neighbors", ":", "\n", "      ", "adj_indices", ".", "append", "(", "(", "node", ",", "n", ")", ")", "\n", "adj_values", ".", "append", "(", "1", ")", "\n", "\n", "", "", "adj_indices", "=", "np", ".", "array", "(", "adj_indices", ",", "dtype", "=", "'int32'", ")", "\n", "adj_values", "=", "np", ".", "array", "(", "adj_values", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "adj", "=", "scipy", ".", "sparse", ".", "csr_matrix", "(", "(", "num_nodes", ",", "num_nodes", ")", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "adj", "[", "adj_indices", "[", ":", ",", "0", "]", ",", "adj_indices", "[", ":", ",", "1", "]", "]", "=", "adj_values", "\n", "\n", "return", "adj", ",", "llallx", ",", "ally", ",", "test_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_reddit": [[89, 99], ["framework.compact_adj.CompactAdjacency.from_file", "framework.compact_adj.CompactAdjacency.from_file", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file"], ["", "def", "load_reddit", "(", "path", ")", ":", "\n", "    ", "train_comp_adj", "=", "CompAdj", ".", "from_file", "(", "path", "+", "'/train_comp_adj_reddit.pkl'", ")", "\n", "test_comp_adj", "=", "CompAdj", ".", "from_file", "(", "path", "+", "'/test_comp_adj_reddit.pkl'", ")", "\n", "feat_data", "=", "np", ".", "load", "(", "path", "+", "'/feat_data.npy'", ")", "\n", "labels", "=", "np", ".", "load", "(", "path", "+", "'/labels.npy'", ")", "\n", "train_ids", "=", "np", ".", "load", "(", "path", "+", "'/train_ids.npy'", ")", "\n", "val_ids", "=", "np", ".", "load", "(", "path", "+", "'/val_ids.npy'", ")", "\n", "test_ids", "=", "np", ".", "load", "(", "path", "+", "'/test_ids.npy'", ")", "\n", "\n", "return", "train_comp_adj", ",", "test_comp_adj", ",", "feat_data", ",", "labels", ",", "train_ids", ",", "val_ids", ",", "test_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_amazon": [[101, 111], ["framework.compact_adj.CompactAdjacency.from_file", "framework.compact_adj.CompactAdjacency.from_file", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file", "home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file"], ["", "def", "load_amazon", "(", "path", ")", ":", "\n", "  ", "comp_adj", "=", "CompAdj", ".", "from_file", "(", "path", "+", "'/comp_adj.pkl'", ")", "\n", "train_comp_adj", "=", "CompAdj", ".", "from_file", "(", "path", "+", "'/train_comp_adj.pkl'", ")", "\n", "feat_data", "=", "np", ".", "load", "(", "path", "+", "'/feat_data.npy'", ")", "\n", "labels", "=", "np", ".", "load", "(", "path", "+", "'/labels.npy'", ")", "\n", "train_ids", "=", "np", ".", "load", "(", "path", "+", "'/train_ids.npy'", ")", "\n", "val_ids", "=", "np", ".", "load", "(", "path", "+", "'/val_ids.npy'", ")", "\n", "test_ids", "=", "np", ".", "load", "(", "path", "+", "'/test_ids.npy'", ")", "\n", "\n", "return", "feat_data", ",", "labels", ",", "train_comp_adj", ",", "comp_adj", ",", "train_ids", ",", "val_ids", ",", "test_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.training_loops.datasets.load_ogbproducts": [[113, 123], ["framework.compact_adj.CompactAdjacency.from_file", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.isi-usc-edu_gttf.framework.compact_adj.CompactAdjacency.from_file"], ["", "def", "load_ogbproducts", "(", "path", ")", ":", "\n", "  ", "comp_adj", "=", "CompAdj", ".", "from_file", "(", "path", "+", "'/products_comp_adj.pkl'", ")", "\n", "degrees", "=", "np", ".", "load", "(", "path", "+", "'/degrees.npy'", ")", "\n", "feat_data", "=", "np", ".", "load", "(", "path", "+", "'/feat_data.npy'", ")", "\n", "labels", "=", "np", ".", "load", "(", "path", "+", "'/labels.npy'", ")", "\n", "train_ids", "=", "np", ".", "load", "(", "path", "+", "'/train_ids.npy'", ")", "\n", "val_ids", "=", "np", ".", "load", "(", "path", "+", "'/val_ids.npy'", ")", "\n", "test_ids", "=", "np", ".", "load", "(", "path", "+", "'/test_ids.npy'", ")", "\n", "\n", "return", "feat_data", ",", "labels", ",", "comp_adj", ",", "degrees", ",", "train_ids", ",", "val_ids", ",", "test_ids", "", "", ""]], "home.repos.pwc.inspect_result.isi-usc-edu_gttf.data.asymproj_datasets.read_dataset": [[6, 55], ["os.path.expanduser", "os.path.exists", "os.path.exists", "os.path.join", "os.path.exists", "os.path.join", "os.path.exists", "os.path.join", "print", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "numpy.load", "pickle.load", "numpy.load", "os.path.join", "numpy.load", "numpy.load", "open", "numpy.load", "open", "open", "len", "len", "np.load.max", "open", "open", "open", "os.path.join", "open", "os.path.join"], "function", ["None"], ["def", "read_dataset", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Reads graph dataset from directory.\n\n  These datasets are used in WatchYourStep and AsymProjection, available on:\n  https://github.com/google/asymproj_edge_dnn/tree/master/datasets\n\n  Args:\n    dataset_dir: directory of dataset containing files {train, test, test.neg}.txt.npy and index.pkl\n\n  Returns:\n    tuple (num_nodes, train_edges, test_pos_arr, test_neg_arr)\n  \"\"\"", "\n", "dataset_dir", "=", "os", ".", "path", ".", "expanduser", "(", "dataset_dir", ")", "\n", "\n", "## Load train edges", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'train_c.txt.npz'", ")", ")", ":", "\n", "    ", "print", "(", "'Loading taking compressed version.'", ")", "\n", "train_edges", "=", "np", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'train_c.txt.npz'", ")", ",", "'rb'", ")", ")", "[", "'arr_0'", "]", "\n", "", "else", ":", "\n", "    ", "train_edges", "=", "np", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'train.txt.npy'", ")", ",", "'rb'", ")", ")", "\n", "\n", "## Load test edges.", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'test_c.txt.npz'", ")", ")", ":", "\n", "    ", "test_pos_file", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'test_c.txt.npz'", ")", "\n", "test_pos_arr", "=", "np", ".", "load", "(", "open", "(", "test_pos_file", ",", "'rb'", ")", ")", "[", "'arr_0'", "]", "\n", "", "else", ":", "\n", "    ", "test_pos_file", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'test.txt.npy'", ")", "\n", "test_pos_arr", "=", "np", ".", "load", "(", "open", "(", "test_pos_file", ",", "'rb'", ")", ")", "\n", "\n", "", "index_file", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'index.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_file", ")", ":", "\n", "    ", "index", "=", "pickle", ".", "load", "(", "open", "(", "index_file", ",", "'rb'", ")", ")", "\n", "if", "'index'", "in", "index", ":", "\n", "      ", "num_nodes", "=", "len", "(", "index", "[", "'index'", "]", ")", "\n", "", "else", ":", "\n", "      ", "num_nodes", "=", "len", "(", "index", ")", "\n", "", "", "else", ":", "\n", "    ", "num_nodes", "=", "train_edges", ".", "max", "(", ")", "+", "1", "\n", "", "directed_negs_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'test.directed.neg.txt.npy'", ")", "\n", "is_directed", "=", "os", ".", "path", ".", "exists", "(", "directed_negs_filename", ")", "\n", "if", "is_directed", ":", "\n", "    ", "test_neg_arr", "=", "np", ".", "load", "(", "open", "(", "directed_negs_filename", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "    ", "test_neg_file", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'test.neg.txt.npy'", ")", "\n", "test_neg_arr", "=", "np", ".", "load", "(", "open", "(", "test_neg_file", ",", "'rb'", ")", ")", "\n", "\n", "", "return", "num_nodes", ",", "train_edges", ",", "test_pos_arr", ",", "test_neg_arr", ",", "is_directed", "\n", "\n"]]}