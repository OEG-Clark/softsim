{"home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.PommermanJSONEncoder.default": [[19, 37], ["isinstance", "json.JSONEncoder.default", "obj.tolist", "isinstance", "isinstance", "isinstance", "isinstance", "int", "hasattr", "obj.to_json", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.PommermanJSONEncoder.default", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.to_json"], ["def", "default", "(", "self", ",", "obj", ")", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "obj", ".", "tolist", "(", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "constants", ".", "Item", ")", ":", "\n", "            ", "return", "obj", ".", "value", "\n", "", "elif", "isinstance", "(", "obj", ",", "constants", ".", "Action", ")", ":", "\n", "            ", "return", "obj", ".", "value", "\n", "", "elif", "isinstance", "(", "obj", ",", "constants", ".", "GameType", ")", ":", "\n", "            ", "return", "obj", ".", "value", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "int64", ")", ":", "\n", "            ", "return", "int", "(", "obj", ")", "\n", "", "elif", "hasattr", "(", "obj", ",", "'to_json'", ")", ":", "\n", "            ", "return", "obj", ".", "to_json", "(", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "spaces", ".", "Discrete", ")", ":", "\n", "            ", "return", "obj", ".", "n", "\n", "", "elif", "isinstance", "(", "obj", ",", "spaces", ".", "Tuple", ")", ":", "\n", "            ", "return", "[", "space", ".", "n", "for", "space", "in", "obj", ".", "spaces", "]", "\n", "", "return", "json", ".", "JSONEncoder", ".", "default", "(", "self", ",", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.make_board": [[39, 154], ["utility.make_board.make"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make"], ["", "", "def", "make_board", "(", "size", ",", "num_rigid", "=", "0", ",", "num_wood", "=", "0", ",", "num_agents", "=", "4", ")", ":", "\n", "    ", "\"\"\"Make the random but symmetric board.\n\n    The numbers refer to the Item enum in constants. This is:\n     0 - passage\n     1 - rigid wall\n     2 - wood wall\n     3 - bomb\n     4 - flames\n     5 - fog\n     6 - extra bomb item\n     7 - extra firepower item\n     8 - kick\n     9 - skull\n     10 - 13: agents\n\n    Args:\n      size: The dimension of the board, i.e. it's sizeXsize.\n      num_rigid: The number of rigid walls on the board. This should be even.\n      num_wood: Similar to above but for wood walls.\n\n    Returns:\n      board: The resulting random board.\n    \"\"\"", "\n", "\n", "def", "lay_wall", "(", "value", ",", "num_left", ",", "coordinates", ",", "board", ")", ":", "\n", "        ", "'''Lays all of the walls on a board'''", "\n", "x", ",", "y", "=", "random", ".", "sample", "(", "coordinates", ",", "1", ")", "[", "0", "]", "\n", "coordinates", ".", "remove", "(", "(", "x", ",", "y", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "y", ",", "x", ")", ")", "\n", "board", "[", "x", ",", "y", "]", "=", "value", "\n", "board", "[", "y", ",", "x", "]", "=", "value", "\n", "num_left", "-=", "2", "\n", "return", "num_left", "\n", "\n", "", "def", "make", "(", "size", ",", "num_rigid", ",", "num_wood", ",", "num_agents", ")", ":", "\n", "        ", "'''Constructs a game/board'''", "\n", "# Initialize everything as a passage.", "\n", "board", "=", "np", ".", "ones", "(", "(", "size", ",", "\n", "size", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "*", "constants", ".", "Item", ".", "Passage", ".", "value", "\n", "\n", "# Gather all the possible coordinates to use for walls.", "\n", "coordinates", "=", "set", "(", "[", "\n", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "itertools", ".", "product", "(", "range", "(", "size", ")", ",", "range", "(", "size", ")", ")", "if", "x", "!=", "y", "]", ")", "\n", "\n", "# Set the players down. Exclude them from coordinates.", "\n", "# Agent0 is in top left. Agent1 is in bottom left.", "\n", "# Agent2 is in bottom right. Agent 3 is in top right.", "\n", "assert", "(", "num_agents", "%", "2", "==", "0", ")", "\n", "\n", "if", "num_agents", "==", "2", ":", "\n", "            ", "board", "[", "1", ",", "1", "]", "=", "constants", ".", "Item", ".", "Agent0", ".", "value", "\n", "board", "[", "size", "-", "2", ",", "size", "-", "2", "]", "=", "constants", ".", "Item", ".", "Agent1", ".", "value", "\n", "agents", "=", "[", "(", "1", ",", "1", ")", ",", "(", "size", "-", "2", ",", "size", "-", "2", ")", "]", "\n", "", "else", ":", "\n", "            ", "board", "[", "1", ",", "1", "]", "=", "constants", ".", "Item", ".", "Agent0", ".", "value", "\n", "board", "[", "size", "-", "2", ",", "1", "]", "=", "constants", ".", "Item", ".", "Agent1", ".", "value", "\n", "board", "[", "size", "-", "2", ",", "size", "-", "2", "]", "=", "constants", ".", "Item", ".", "Agent2", ".", "value", "\n", "board", "[", "1", ",", "size", "-", "2", "]", "=", "constants", ".", "Item", ".", "Agent3", ".", "value", "\n", "agents", "=", "[", "(", "1", ",", "1", ")", ",", "(", "size", "-", "2", ",", "1", ")", ",", "(", "1", ",", "size", "-", "2", ")", ",", "(", "size", "-", "2", ",", "size", "-", "2", ")", "]", "\n", "\n", "", "for", "position", "in", "agents", ":", "\n", "            ", "if", "position", "in", "coordinates", ":", "\n", "                ", "coordinates", ".", "remove", "(", "position", ")", "\n", "\n", "# Exclude breathing room on either side of the agents.", "\n", "", "", "for", "i", "in", "range", "(", "2", ",", "4", ")", ":", "\n", "            ", "coordinates", ".", "remove", "(", "(", "1", ",", "i", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "i", ",", "1", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "size", "-", "2", ",", "size", "-", "i", "-", "1", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "size", "-", "i", "-", "1", ",", "size", "-", "2", ")", ")", "\n", "\n", "if", "num_agents", "==", "4", ":", "\n", "                ", "coordinates", ".", "remove", "(", "(", "1", ",", "size", "-", "i", "-", "1", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "size", "-", "i", "-", "1", ",", "1", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "i", ",", "size", "-", "2", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "size", "-", "2", ",", "i", ")", ")", "\n", "\n", "# Lay down wooden walls providing guaranteed passage to other agents.", "\n", "", "", "wood", "=", "constants", ".", "Item", ".", "Wood", ".", "value", "\n", "if", "num_agents", "==", "4", ":", "\n", "            ", "for", "i", "in", "range", "(", "4", ",", "size", "-", "4", ")", ":", "\n", "                ", "board", "[", "1", ",", "i", "]", "=", "wood", "\n", "board", "[", "size", "-", "i", "-", "1", ",", "1", "]", "=", "wood", "\n", "board", "[", "size", "-", "2", ",", "size", "-", "i", "-", "1", "]", "=", "wood", "\n", "board", "[", "size", "-", "i", "-", "1", ",", "size", "-", "2", "]", "=", "wood", "\n", "coordinates", ".", "remove", "(", "(", "1", ",", "i", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "size", "-", "i", "-", "1", ",", "1", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "size", "-", "2", ",", "size", "-", "i", "-", "1", ")", ")", "\n", "coordinates", ".", "remove", "(", "(", "size", "-", "i", "-", "1", ",", "size", "-", "2", ")", ")", "\n", "num_wood", "-=", "4", "\n", "\n", "# Lay down the rigid walls.", "\n", "", "", "while", "num_rigid", ">", "0", ":", "\n", "            ", "num_rigid", "=", "lay_wall", "(", "constants", ".", "Item", ".", "Rigid", ".", "value", ",", "num_rigid", ",", "\n", "coordinates", ",", "board", ")", "\n", "\n", "# Lay down the wooden walls.", "\n", "", "while", "num_wood", ">", "0", ":", "\n", "            ", "num_wood", "=", "lay_wall", "(", "constants", ".", "Item", ".", "Wood", ".", "value", ",", "num_wood", ",", "\n", "coordinates", ",", "board", ")", "\n", "\n", "", "return", "board", ",", "agents", "\n", "\n", "", "assert", "(", "num_rigid", "%", "2", "==", "0", ")", "\n", "assert", "(", "num_wood", "%", "2", "==", "0", ")", "\n", "board", ",", "agents", "=", "make", "(", "size", ",", "num_rigid", ",", "num_wood", ",", "num_agents", ")", "\n", "\n", "# Make sure it's possible to reach most of the passages.", "\n", "while", "len", "(", "inaccessible_passages", "(", "board", ",", "agents", ")", ")", ">", "4", ":", "\n", "        ", "board", ",", "agents", "=", "make", "(", "size", ",", "num_rigid", ",", "num_wood", ",", "num_agents", ")", "\n", "\n", "", "return", "board", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.make_items": [[156, 173], ["random.randint", "random.randint", "random.choice", "len", "len"], "function", ["None"], ["", "def", "make_items", "(", "board", ",", "num_items", ")", ":", "\n", "    ", "'''Lays all of the items on the board'''", "\n", "item_positions", "=", "{", "}", "\n", "while", "num_items", ">", "0", ":", "\n", "        ", "row", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "board", ")", "-", "1", ")", "\n", "col", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "board", "[", "0", "]", ")", "-", "1", ")", "\n", "if", "board", "[", "row", ",", "col", "]", "!=", "constants", ".", "Item", ".", "Wood", ".", "value", ":", "\n", "            ", "continue", "\n", "", "if", "(", "row", ",", "col", ")", "in", "item_positions", ":", "\n", "            ", "continue", "\n", "\n", "", "item_positions", "[", "(", "row", ",", "col", ")", "]", "=", "random", ".", "choice", "(", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", ")", ".", "value", "\n", "num_items", "-=", "1", "\n", "", "return", "item_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.inaccessible_passages": [[175, 202], ["set", "agent_positions.pop", "numpy.where", "list", "zip", "Q.pop", "utility.position_is_rigid", "set.add", "Q.append", "utility.position_on_board", "list.pop", "list.index", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_rigid", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board"], ["", "def", "inaccessible_passages", "(", "board", ",", "agent_positions", ")", ":", "\n", "    ", "\"\"\"Return inaccessible passages on this board.\"\"\"", "\n", "seen", "=", "set", "(", ")", "\n", "agent_position", "=", "agent_positions", ".", "pop", "(", ")", "\n", "passage_positions", "=", "np", ".", "where", "(", "board", "==", "constants", ".", "Item", ".", "Passage", ".", "value", ")", "\n", "positions", "=", "list", "(", "zip", "(", "passage_positions", "[", "0", "]", ",", "passage_positions", "[", "1", "]", ")", ")", "\n", "\n", "Q", "=", "[", "agent_position", "]", "\n", "while", "Q", ":", "\n", "        ", "row", ",", "col", "=", "Q", ".", "pop", "(", ")", "\n", "for", "(", "i", ",", "j", ")", "in", "[", "(", "1", ",", "0", ")", ",", "(", "-", "1", ",", "0", ")", ",", "(", "0", ",", "1", ")", ",", "(", "0", ",", "-", "1", ")", "]", ":", "\n", "            ", "next_position", "=", "(", "row", "+", "i", ",", "col", "+", "j", ")", "\n", "if", "next_position", "in", "seen", ":", "\n", "                ", "continue", "\n", "", "if", "not", "position_on_board", "(", "board", ",", "next_position", ")", ":", "\n", "                ", "continue", "\n", "", "if", "position_is_rigid", "(", "board", ",", "next_position", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "next_position", "in", "positions", ":", "\n", "                ", "positions", ".", "pop", "(", "positions", ".", "index", "(", "next_position", ")", ")", "\n", "if", "not", "len", "(", "positions", ")", ":", "\n", "                    ", "return", "[", "]", "\n", "\n", "", "", "seen", ".", "add", "(", "next_position", ")", "\n", "Q", ".", "append", "(", "next_position", ")", "\n", "", "", "return", "positions", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.is_valid_direction": [[204, 230], ["constants.InvalidAction", "constants.Action", "constants.Action", "constants.Action", "constants.Action", "constants.Action", "len", "len"], "function", ["None"], ["", "def", "is_valid_direction", "(", "board", ",", "position", ",", "direction", ",", "invalid_values", "=", "None", ")", ":", "\n", "    ", "'''Determins if a move is in a valid direction'''", "\n", "row", ",", "col", "=", "position", "\n", "if", "invalid_values", "is", "None", ":", "\n", "        ", "invalid_values", "=", "[", "item", ".", "value", "for", "item", "in", "[", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Wood", "]", "]", "\n", "\n", "", "if", "constants", ".", "Action", "(", "direction", ")", "==", "constants", ".", "Action", ".", "Stop", ":", "\n", "        ", "return", "True", "\n", "\n", "", "if", "constants", ".", "Action", "(", "direction", ")", "==", "constants", ".", "Action", ".", "Up", ":", "\n", "        ", "return", "row", "-", "1", ">=", "0", "and", "board", "[", "row", "-", "1", "]", "[", "col", "]", "not", "in", "invalid_values", "\n", "\n", "", "if", "constants", ".", "Action", "(", "direction", ")", "==", "constants", ".", "Action", ".", "Down", ":", "\n", "        ", "return", "row", "+", "1", "<", "len", "(", "board", ")", "and", "board", "[", "row", "+", "\n", "1", "]", "[", "col", "]", "not", "in", "invalid_values", "\n", "\n", "", "if", "constants", ".", "Action", "(", "direction", ")", "==", "constants", ".", "Action", ".", "Left", ":", "\n", "        ", "return", "col", "-", "1", ">=", "0", "and", "board", "[", "row", "]", "[", "col", "-", "1", "]", "not", "in", "invalid_values", "\n", "\n", "", "if", "constants", ".", "Action", "(", "direction", ")", "==", "constants", ".", "Action", ".", "Right", ":", "\n", "        ", "return", "col", "+", "1", "<", "len", "(", "board", "[", "0", "]", ")", "and", "board", "[", "row", "]", "[", "col", "+", "1", "]", "not", "in", "invalid_values", "\n", "\n", "", "raise", "constants", ".", "InvalidAction", "(", "\"We did not receive a valid direction: \"", ",", "\n", "direction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility._position_is_item": [[232, 235], ["constants.Item.Flames", "constants.Item.Passage", "constants.Item.Rigid", "constants.Item.Wood", "constants.Item.Fog"], "function", ["None"], ["", "def", "_position_is_item", "(", "board", ",", "position", ",", "item", ")", ":", "\n", "    ", "'''Determins if a position holds an item'''", "\n", "return", "board", "[", "position", "]", "==", "item", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_flames": [[237, 240], ["utility._position_is_item"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility._position_is_item"], ["", "def", "position_is_flames", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins if a position has flames'''", "\n", "return", "_position_is_item", "(", "board", ",", "position", ",", "constants", ".", "Item", ".", "Flames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_bomb": [[242, 252], ["None"], "function", ["None"], ["", "def", "position_is_bomb", "(", "bombs", ",", "position", ")", ":", "\n", "    ", "\"\"\"Check if a given position is a bomb.\n    \n    We don't check the board because that is an unreliable source. An agent\n    may be obscuring the bomb on the board.\n    \"\"\"", "\n", "for", "bomb", "in", "bombs", ":", "\n", "        ", "if", "position", "==", "bomb", ".", "position", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_powerup": [[254, 261], ["None"], "function", ["None"], ["", "def", "position_is_powerup", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins is a position has a powerup present'''", "\n", "powerups", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "item_values", "=", "[", "item", ".", "value", "for", "item", "in", "powerups", "]", "\n", "return", "board", "[", "position", "]", "in", "item_values", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_wall": [[263, 267], ["utility.position_is_rigid", "utility.position_is_wood"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_rigid", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_wood"], ["", "def", "position_is_wall", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins if a position is a wall tile'''", "\n", "return", "position_is_rigid", "(", "board", ",", "position", ")", "or", "position_is_wood", "(", "board", ",", "position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passage": [[269, 272], ["utility._position_is_item"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility._position_is_item"], ["", "def", "position_is_passage", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins if a position is passage tile'''", "\n", "return", "_position_is_item", "(", "board", ",", "position", ",", "constants", ".", "Item", ".", "Passage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_rigid": [[274, 277], ["utility._position_is_item"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility._position_is_item"], ["", "def", "position_is_rigid", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins if a position has a rigid tile'''", "\n", "return", "_position_is_item", "(", "board", ",", "position", ",", "constants", ".", "Item", ".", "Rigid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_wood": [[279, 282], ["utility._position_is_item"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility._position_is_item"], ["", "def", "position_is_wood", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins if a position has a wood tile'''", "\n", "return", "_position_is_item", "(", "board", ",", "position", ",", "constants", ".", "Item", ".", "Wood", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_agent": [[284, 289], ["None"], "function", ["None"], ["", "def", "position_is_agent", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins if a position has an agent present'''", "\n", "return", "board", "[", "position", "]", "in", "[", "\n", "constants", ".", "Item", ".", "Agent0", ".", "value", ",", "constants", ".", "Item", ".", "Agent1", ".", "value", ",", "\n", "constants", ".", "Item", ".", "Agent2", ".", "value", ",", "constants", ".", "Item", ".", "Agent3", ".", "value", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_enemy": [[292, 295], ["constants.Item"], "function", ["None"], ["", "def", "position_is_enemy", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "    ", "'''Determins if a position is an enemy'''", "\n", "return", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "in", "enemies", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable": [[298, 306], ["all", "any", "utility.position_is_enemy", "utility.position_is_agent", "utility.position_is_powerup", "utility.position_is_passage"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_enemy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_agent", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_powerup", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passage"], ["", "def", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "    ", "'''Determins if a possible can be passed'''", "\n", "return", "all", "(", "[", "\n", "any", "(", "[", "\n", "position_is_agent", "(", "board", ",", "position", ")", ",", "\n", "position_is_powerup", "(", "board", ",", "position", ")", ",", "\n", "position_is_passage", "(", "board", ",", "position", ")", "\n", "]", ")", ",", "not", "position_is_enemy", "(", "board", ",", "position", ",", "enemies", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_fog": [[309, 312], ["utility._position_is_item"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility._position_is_item"], ["", "def", "position_is_fog", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determins if a position is fog'''", "\n", "return", "_position_is_item", "(", "board", ",", "position", ",", "constants", ".", "Item", ".", "Fog", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.agent_value": [[314, 317], ["getattr"], "function", ["None"], ["", "def", "agent_value", "(", "id_", ")", ":", "\n", "    ", "'''Gets the state value based off of agents \"name\"'''", "\n", "return", "getattr", "(", "constants", ".", "Item", ",", "'Agent%d'", "%", "id_", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_in_items": [[319, 322], ["any", "utility._position_is_item"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility._position_is_item"], ["", "def", "position_in_items", "(", "board", ",", "position", ",", "items", ")", ":", "\n", "    ", "'''Dtermines if the current positions has an item'''", "\n", "return", "any", "(", "[", "_position_is_item", "(", "board", ",", "position", ",", "item", ")", "for", "item", "in", "items", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board": [[324, 328], ["all", "len", "len"], "function", ["None"], ["", "def", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "    ", "'''Determines if a positions is on the board'''", "\n", "x", ",", "y", "=", "position", "\n", "return", "all", "(", "[", "len", "(", "board", ")", ">", "x", ",", "len", "(", "board", "[", "0", "]", ")", ">", "y", ",", "x", ">=", "0", ",", "y", ">=", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction": [[330, 349], ["constants.InvalidAction"], "function", ["None"], ["", "def", "get_direction", "(", "position", ",", "next_position", ")", ":", "\n", "    ", "\"\"\"Get the direction such that position --> next_position.\n\n    We assume that they are adjacent.\n    \"\"\"", "\n", "x", ",", "y", "=", "position", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "x", "==", "next_x", ":", "\n", "        ", "if", "y", "<", "next_y", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Right", "\n", "", "else", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Left", "\n", "", "", "elif", "y", "==", "next_y", ":", "\n", "        ", "if", "x", "<", "next_x", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Down", "\n", "", "else", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Up", "\n", "", "", "raise", "constants", ".", "InvalidAction", "(", "\n", "\"We did not receive a valid position transition.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_next_position": [[351, 365], ["constants.InvalidAction"], "function", ["None"], ["", "def", "get_next_position", "(", "position", ",", "direction", ")", ":", "\n", "    ", "'''Returns the next position coordinates'''", "\n", "x", ",", "y", "=", "position", "\n", "if", "direction", "==", "constants", ".", "Action", ".", "Right", ":", "\n", "        ", "return", "(", "x", ",", "y", "+", "1", ")", "\n", "", "elif", "direction", "==", "constants", ".", "Action", ".", "Left", ":", "\n", "        ", "return", "(", "x", ",", "y", "-", "1", ")", "\n", "", "elif", "direction", "==", "constants", ".", "Action", ".", "Down", ":", "\n", "        ", "return", "(", "x", "+", "1", ",", "y", ")", "\n", "", "elif", "direction", "==", "constants", ".", "Action", ".", "Up", ":", "\n", "        ", "return", "(", "x", "-", "1", ",", "y", ")", "\n", "", "elif", "direction", "==", "constants", ".", "Action", ".", "Stop", ":", "\n", "        ", "return", "(", "x", ",", "y", ")", "\n", "", "raise", "constants", ".", "InvalidAction", "(", "\"We did not receive a valid direction.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.make_np_float": [[367, 370], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["", "def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "'''Converts an integer feature space into a floats'''", "\n", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.join_json_state": [[372, 410], ["jsonmerge.Merger", "jsonmerge.Merger.merge", "os.walk", "os.walk", "open", "f.write", "os.path.join", "os.path.join", "json.dumps", "name.endswith", "os.remove", "open", "json.load", "jsonmerge.Merger.merge", "os.path.join"], "function", ["None"], ["", "def", "join_json_state", "(", "record_json_dir", ",", "agents", ",", "finished_at", ",", "config", ",", "info", ")", ":", "\n", "    ", "'''Combines all of the json state files into one'''", "\n", "json_schema", "=", "{", "\"properties\"", ":", "{", "\"state\"", ":", "{", "\"mergeStrategy\"", ":", "\"append\"", "}", "}", "}", "\n", "\n", "json_template", "=", "{", "\n", "\"agents\"", ":", "agents", ",", "\n", "\"finished_at\"", ":", "finished_at", ",", "\n", "\"config\"", ":", "config", ",", "\n", "\"result\"", ":", "{", "\n", "\"name\"", ":", "info", "[", "'result'", "]", ".", "name", ",", "\n", "\"id\"", ":", "info", "[", "'result'", "]", ".", "value", "\n", "}", "\n", "}", "\n", "\n", "if", "info", "[", "'result'", "]", "is", "not", "constants", ".", "Result", ".", "Tie", ":", "\n", "        ", "json_template", "[", "'winners'", "]", "=", "info", "[", "'winners'", "]", "\n", "\n", "", "json_template", "[", "'state'", "]", "=", "[", "]", "\n", "\n", "merger", "=", "Merger", "(", "json_schema", ")", "\n", "base", "=", "merger", ".", "merge", "(", "{", "}", ",", "json_template", ")", "\n", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "record_json_dir", ")", ":", "\n", "        ", "for", "name", "in", "files", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "record_json_dir", ",", "name", ")", "\n", "if", "name", ".", "endswith", "(", "'.json'", ")", "and", "\"game_state\"", "not", "in", "name", ":", "\n", "                ", "with", "open", "(", "path", ")", "as", "data_file", ":", "\n", "                    ", "data", "=", "json", ".", "load", "(", "data_file", ")", "\n", "head", "=", "{", "\"state\"", ":", "[", "data", "]", "}", "\n", "base", "=", "merger", ".", "merge", "(", "base", ",", "head", ")", "\n", "\n", "", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "record_json_dir", ",", "'game_state.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "base", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "record_json_dir", ")", ":", "\n", "        ", "for", "name", "in", "files", ":", "\n", "            ", "if", "\"game_state\"", "not", "in", "name", ":", "\n", "                ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "record_json_dir", ",", "name", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.__init__": [[46, 61], ["glEnable", "glBlendFunc"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", "=", "None", "\n", "self", ".", "display", "=", "None", "\n", "self", ".", "_agents", "=", "[", "]", "\n", "self", ".", "_agent_count", "=", "0", "\n", "self", ".", "_board_state", "=", "None", "\n", "self", ".", "_batch", "=", "None", "\n", "self", ".", "window", "=", "None", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "_agent_view_size", "=", "None", "\n", "self", ".", "_is_partially_observable", "=", "False", "\n", "self", ".", "isopen", "=", "False", "\n", "\n", "glEnable", "(", "GL_BLEND", ")", "\n", "glBlendFunc", "(", "GL_SRC_ALPHA", ",", "GL_ONE_MINUS_SRC_ALPHA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_board": [[62, 64], ["None"], "methods", ["None"], ["", "def", "set_board", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "_board_state", "=", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_bombs": [[65, 67], ["None"], "methods", ["None"], ["", "def", "set_bombs", "(", "self", ",", "bombs", ")", ":", "\n", "        ", "self", ".", "_bombs", "=", "bombs", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_agents": [[68, 71], ["len"], "methods", ["None"], ["", "def", "set_agents", "(", "self", ",", "agents", ")", ":", "\n", "        ", "self", ".", "_agents", "=", "agents", "\n", "self", ".", "_agent_count", "=", "len", "(", "agents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_step": [[72, 74], ["None"], "methods", ["None"], ["", "def", "set_step", "(", "self", ",", "step", ")", ":", "\n", "        ", "self", ".", "_step", "=", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.close": [[75, 78], ["graphics.Viewer.window.close"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "close", "(", ")", "\n", "self", ".", "isopen", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.window_closed_by_user": [[79, 81], ["None"], "methods", ["None"], ["", "def", "window_closed_by_user", "(", "self", ")", ":", "\n", "        ", "self", ".", "isopen", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save": [[82, 88], ["datetime.datetime.datetime.now", "os.path.join", "pyglet.image.get_buffer_manager().get_color_buffer().save", "datetime.datetime.now.strftime", "str", "pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "filename", "=", "now", ".", "strftime", "(", "'%m-%d-%y_%H-%M-%S_'", ")", "+", "str", "(", "\n", "self", ".", "_step", ")", "+", "'.png'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", "\n", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", ".", "save", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PixelViewer.__init__": [[92, 107], ["graphics.Viewer.__init__", "rendering.get_display", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["def", "__init__", "(", "self", ",", "\n", "display", "=", "None", ",", "\n", "board_size", "=", "11", ",", "\n", "agents", "=", "[", "]", ",", "\n", "partially_observable", "=", "False", ",", "\n", "agent_view_size", "=", "None", ",", "\n", "game_type", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "from", "gym", ".", "envs", ".", "classic_control", "import", "rendering", "\n", "self", ".", "display", "=", "rendering", ".", "get_display", "(", "display", ")", "\n", "self", ".", "_board_size", "=", "board_size", "\n", "self", ".", "_agent_count", "=", "len", "(", "agents", ")", "\n", "self", ".", "_agents", "=", "agents", "\n", "self", ".", "_is_partially_observable", "=", "partially_observable", "\n", "self", ".", "_agent_view_size", "=", "agent_view_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PixelViewer.render": [[108, 149], ["graphics.PixelViewer.build_frame", "pyglet.image.ImageData", "graphics.PixelViewer.window.clear", "graphics.PixelViewer.window.switch_to", "graphics.PixelViewer.window.dispatch_events", "pyglet.image.ImageData.blit", "graphics.PixelViewer.window.flip", "pyglet.window.Window", "len", "graphics.PixelViewer.tobytes"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PixelViewer.build_frame"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "frames", "=", "self", ".", "build_frame", "(", ")", "\n", "\n", "if", "self", ".", "window", "is", "None", ":", "\n", "            ", "height", ",", "width", ",", "_channels", "=", "frames", ".", "shape", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "\n", "width", "=", "4", "*", "width", ",", "\n", "height", "=", "4", "*", "height", ",", "\n", "display", "=", "self", ".", "display", ",", "\n", "vsync", "=", "False", ",", "\n", "resizable", "=", "True", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "isopen", "=", "True", "\n", "\n", "@", "self", ".", "window", ".", "event", "\n", "def", "on_resize", "(", "width", ",", "height", ")", ":", "\n", "                ", "'''Registers an event handler with a pyglet window to resize the window'''", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "\n", "", "@", "self", ".", "window", ".", "event", "\n", "def", "on_close", "(", ")", ":", "\n", "                ", "''' Registers an event handler with a pyglet to tell the render engine the\n                    window is closed\n                '''", "\n", "self", ".", "isopen", "=", "True", "\n", "\n", "", "", "assert", "len", "(", "frames", ".", "shape", "\n", ")", "==", "3", ",", "\"You passed in an image with the wrong number shape\"", "\n", "image", "=", "pyglet", ".", "image", ".", "ImageData", "(", "\n", "frames", ".", "shape", "[", "1", "]", ",", "\n", "frames", ".", "shape", "[", "0", "]", ",", "\n", "'RGB'", ",", "\n", "frames", ".", "tobytes", "(", ")", ",", "\n", "pitch", "=", "frames", ".", "shape", "[", "1", "]", "*", "-", "3", ")", "\n", "self", ".", "window", ".", "clear", "(", ")", "\n", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "image", ".", "blit", "(", "0", ",", "0", ",", "width", "=", "self", ".", "window", ".", "width", ",", "height", "=", "self", ".", "window", ".", "height", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PixelViewer.build_frame": [[150, 172], ["graphics.PixelViewer.rgb_array", "numpy.array", "numpy.concatenate", "numpy.concatenate", "PIL.Image.fromarray().resize", "numpy.array", "PIL.Image.fromarray().resize", "PIL.Image.fromarray", "rgb_array[].astype", "PIL.Image.fromarray", "int", "int", "frame.astype", "len", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PixelViewer.rgb_array"], ["", "def", "build_frame", "(", "self", ")", ":", "\n", "        ", "board", "=", "self", ".", "_board_state", "\n", "board_size", "=", "self", ".", "_board_size", "\n", "agents", "=", "self", ".", "_agents", "\n", "human_factor", "=", "constants", ".", "HUMAN_FACTOR", "\n", "rgb_array", "=", "self", ".", "rgb_array", "(", "board", ",", "board_size", ",", "agents", ",", "\n", "self", ".", "_is_partially_observable", ",", "\n", "self", ".", "_agent_view_size", ")", "\n", "\n", "all_img", "=", "np", ".", "array", "(", "Image", ".", "fromarray", "(", "rgb_array", "[", "0", "]", ".", "astype", "(", "np", ".", "uint8", ")", ")", ".", "resize", "(", "\n", "(", "board_size", "*", "human_factor", ",", "board_size", "*", "human_factor", ")", ",", "resample", "=", "Image", ".", "NEAREST", ")", ")", "\n", "other_imgs", "=", "[", "\n", "np", ".", "array", "(", "Image", ".", "fromarray", "(", "frame", ".", "astype", "(", "np", ".", "uint8", ")", ")", ".", "resize", "(", "\n", "(", "int", "(", "board_size", "*", "human_factor", "/", "len", "(", "self", ".", "_agents", ")", ")", ",", "\n", "int", "(", "board_size", "*", "human_factor", "/", "len", "(", "self", ".", "_agents", ")", ")", ")", ",", "\n", "resample", "=", "Image", ".", "NEAREST", ")", ")", "for", "frame", "in", "rgb_array", "[", "1", ":", "]", "\n", "]", "\n", "\n", "other_imgs", "=", "np", ".", "concatenate", "(", "other_imgs", ",", "0", ")", "\n", "img", "=", "np", ".", "concatenate", "(", "[", "all_img", ",", "other_imgs", "]", ",", "1", ")", "\n", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PixelViewer.rgb_array": [[173, 208], ["numpy.zeros", "len", "range", "numpy.array", "frames.append", "range", "numpy.array.copy", "range", "frames.append", "utility.position_is_agent", "range", "all"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_agent"], ["", "@", "staticmethod", "\n", "def", "rgb_array", "(", "board", ",", "board_size", ",", "agents", ",", "is_partially_observable", ",", "\n", "agent_view_size", ")", ":", "\n", "        ", "frames", "=", "[", "]", "\n", "\n", "all_frame", "=", "np", ".", "zeros", "(", "(", "board_size", ",", "board_size", ",", "3", ")", ")", "\n", "num_items", "=", "len", "(", "constants", ".", "Item", ")", "\n", "for", "row", "in", "range", "(", "board_size", ")", ":", "\n", "            ", "for", "col", "in", "range", "(", "board_size", ")", ":", "\n", "                ", "value", "=", "board", "[", "row", "]", "[", "col", "]", "\n", "if", "utility", ".", "position_is_agent", "(", "board", ",", "(", "row", ",", "col", ")", ")", ":", "\n", "                    ", "num_agent", "=", "value", "-", "num_items", "+", "4", "\n", "if", "agents", "[", "num_agent", "]", ".", "is_alive", ":", "\n", "                        ", "all_frame", "[", "row", "]", "[", "col", "]", "=", "constants", ".", "AGENT_COLORS", "[", "num_agent", "]", "\n", "", "", "else", ":", "\n", "                    ", "all_frame", "[", "row", "]", "[", "col", "]", "=", "constants", ".", "ITEM_COLORS", "[", "value", "]", "\n", "\n", "", "", "", "all_frame", "=", "np", ".", "array", "(", "all_frame", ")", "\n", "frames", ".", "append", "(", "all_frame", ")", "\n", "\n", "for", "agent", "in", "agents", ":", "\n", "            ", "row", ",", "col", "=", "agent", ".", "position", "\n", "my_frame", "=", "all_frame", ".", "copy", "(", ")", "\n", "for", "r", "in", "range", "(", "board_size", ")", ":", "\n", "                ", "for", "c", "in", "range", "(", "board_size", ")", ":", "\n", "                    ", "if", "is_partially_observable", "and", "not", "all", "(", "[", "\n", "row", ">=", "r", "-", "agent_view_size", ",", "row", "<", "\n", "r", "+", "agent_view_size", ",", "col", ">=", "c", "-", "agent_view_size", ",", "\n", "col", "<", "c", "+", "agent_view_size", "\n", "]", ")", ":", "\n", "                        ", "my_frame", "[", "r", ",", "c", "]", "=", "constants", ".", "ITEM_COLORS", "[", "\n", "constants", ".", "Item", ".", "Fog", ".", "value", "]", "\n", "", "", "", "frames", ".", "append", "(", "my_frame", ")", "\n", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.__init__": [[212, 249], ["graphics.Viewer.__init__", "rendering.get_display", "math.ceil", "math.ceil", "pyglet.window.Window", "graphics.PommeViewer.window.set_caption", "graphics.ResourceManager", "len", "graphics.PommeViewer.window.close"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close"], ["def", "__init__", "(", "self", ",", "\n", "display", "=", "None", ",", "\n", "board_size", "=", "11", ",", "\n", "agents", "=", "[", "]", ",", "\n", "partially_observable", "=", "False", ",", "\n", "agent_view_size", "=", "None", ",", "\n", "game_type", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "from", "gym", ".", "envs", ".", "classic_control", "import", "rendering", "\n", "self", ".", "display", "=", "rendering", ".", "get_display", "(", "display", ")", "\n", "board_height", "=", "constants", ".", "TILE_SIZE", "*", "board_size", "\n", "height", "=", "math", ".", "ceil", "(", "board_height", "+", "(", "constants", ".", "BORDER_SIZE", "*", "2", ")", "+", "\n", "(", "constants", ".", "MARGIN_SIZE", "*", "3", ")", ")", "\n", "width", "=", "math", ".", "ceil", "(", "board_height", "+", "board_height", "/", "4", "+", "\n", "(", "constants", ".", "BORDER_SIZE", "*", "2", ")", "+", "constants", ".", "MARGIN_SIZE", ")", "\n", "\n", "self", ".", "_height", "=", "height", "\n", "self", ".", "_width", "=", "width", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "\n", "width", "=", "width", ",", "height", "=", "height", ",", "display", "=", "display", ")", "\n", "self", ".", "window", ".", "set_caption", "(", "'Pommerman'", ")", "\n", "self", ".", "isopen", "=", "True", "\n", "self", ".", "_board_size", "=", "board_size", "\n", "self", ".", "_resource_manager", "=", "ResourceManager", "(", "game_type", ")", "\n", "self", ".", "_tile_size", "=", "constants", ".", "TILE_SIZE", "\n", "self", ".", "_agent_tile_size", "=", "(", "board_height", "/", "4", ")", "/", "board_size", "\n", "self", ".", "_agent_count", "=", "len", "(", "agents", ")", "\n", "self", ".", "_agents", "=", "agents", "\n", "self", ".", "_game_type", "=", "game_type", "\n", "self", ".", "_is_partially_observable", "=", "partially_observable", "\n", "self", ".", "_agent_view_size", "=", "agent_view_size", "\n", "\n", "@", "self", ".", "window", ".", "event", "\n", "def", "close", "(", "self", ")", ":", "\n", "            ", "'''Pyglet event handler to close the window'''", "\n", "self", ".", "window", ".", "close", "(", ")", "\n", "self", ".", "isopen", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render": [[250, 263], ["graphics.PommeViewer.window.switch_to", "graphics.PommeViewer.window.dispatch_events", "pyglet.graphics.Batch", "graphics.PommeViewer.render_background", "graphics.PommeViewer.render_text", "graphics.PommeViewer.render_dead_alive", "graphics.PommeViewer.render_main_board", "graphics.PommeViewer.render_agents_board", "graphics.PommeViewer._batch.draw", "graphics.PommeViewer.window.flip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_background", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_text", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_dead_alive", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_main_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_agents_board"], ["", "", "def", "render", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "self", ".", "_batch", "=", "pyglet", ".", "graphics", ".", "Batch", "(", ")", "\n", "\n", "background", "=", "self", ".", "render_background", "(", ")", "\n", "text", "=", "self", ".", "render_text", "(", ")", "\n", "agents", "=", "self", ".", "render_dead_alive", "(", ")", "\n", "board", "=", "self", ".", "render_main_board", "(", ")", "\n", "agents_board", "=", "self", ".", "render_agents_board", "(", ")", "\n", "\n", "self", ".", "_batch", ".", "draw", "(", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_main_board": [[264, 271], ["graphics.PommeViewer.board_top", "graphics.PommeViewer.render_board"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.board_top", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_board"], ["", "def", "render_main_board", "(", "self", ")", ":", "\n", "        ", "board", "=", "self", ".", "_board_state", "\n", "size", "=", "self", ".", "_tile_size", "\n", "x_offset", "=", "constants", ".", "BORDER_SIZE", "\n", "y_offset", "=", "constants", ".", "BORDER_SIZE", "\n", "top", "=", "self", ".", "board_top", "(", "-", "constants", ".", "BORDER_SIZE", "-", "8", ")", "\n", "return", "self", ".", "render_board", "(", "board", ",", "x_offset", ",", "y_offset", ",", "size", ",", "top", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_agents_board": [[272, 286], ["graphics.PommeViewer.agent_view", "graphics.PommeViewer.render_board", "agents.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.agent_view", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_board"], ["", "def", "render_agents_board", "(", "self", ")", ":", "\n", "        ", "x_offset", "=", "self", ".", "_board_size", "*", "self", ".", "_tile_size", "+", "constants", ".", "BORDER_SIZE", "\n", "x_offset", "+=", "constants", ".", "MARGIN_SIZE", "\n", "size", "=", "self", ".", "_agent_tile_size", "\n", "agents", "=", "[", "]", "\n", "top", "=", "self", ".", "_height", "-", "constants", ".", "BORDER_SIZE", "+", "constants", ".", "MARGIN_SIZE", "\n", "for", "agent", "in", "self", ".", "_agents", ":", "\n", "            ", "y_offset", "=", "agent", ".", "agent_id", "*", "size", "*", "self", ".", "_board_size", "+", "(", "\n", "agent", ".", "agent_id", "*", "constants", ".", "MARGIN_SIZE", ")", "+", "constants", ".", "BORDER_SIZE", "\n", "agent_board", "=", "self", ".", "agent_view", "(", "agent", ")", "\n", "sprite", "=", "self", ".", "render_board", "(", "agent_board", ",", "x_offset", ",", "y_offset", ",", "size", ",", "\n", "top", ")", "\n", "agents", ".", "append", "(", "sprite", ")", "\n", "", "return", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_board": [[287, 305], ["range", "range", "pyglet.sprite.Sprite", "sprites.append", "graphics.PommeViewer.get_bomb_life", "graphics.PommeViewer._resource_manager.get_bomb_tile", "graphics.PommeViewer._resource_manager.tile_from_state_value"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.get_bomb_life", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.get_bomb_tile", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.tile_from_state_value"], ["", "def", "render_board", "(", "self", ",", "board", ",", "x_offset", ",", "y_offset", ",", "size", ",", "top", "=", "0", ")", ":", "\n", "        ", "sprites", "=", "[", "]", "\n", "for", "row", "in", "range", "(", "self", ".", "_board_size", ")", ":", "\n", "            ", "for", "col", "in", "range", "(", "self", ".", "_board_size", ")", ":", "\n", "                ", "x", "=", "col", "*", "size", "+", "x_offset", "\n", "y", "=", "top", "-", "y_offset", "-", "row", "*", "size", "\n", "tile_state", "=", "board", "[", "row", "]", "[", "col", "]", "\n", "if", "tile_state", "==", "constants", ".", "Item", ".", "Bomb", ".", "value", ":", "\n", "                    ", "bomb_life", "=", "self", ".", "get_bomb_life", "(", "row", ",", "col", ")", "\n", "tile", "=", "self", ".", "_resource_manager", ".", "get_bomb_tile", "(", "bomb_life", ")", "\n", "", "else", ":", "\n", "                    ", "tile", "=", "self", ".", "_resource_manager", ".", "tile_from_state_value", "(", "tile_state", ")", "\n", "", "tile", ".", "width", "=", "size", "\n", "tile", ".", "height", "=", "size", "\n", "sprite", "=", "pyglet", ".", "sprite", ".", "Sprite", "(", "\n", "tile", ",", "x", ",", "y", ",", "batch", "=", "self", ".", "_batch", ",", "group", "=", "LAYER_FOREGROUND", ")", "\n", "sprites", ".", "append", "(", "sprite", ")", "\n", "", "", "return", "sprites", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.agent_view": [[306, 324], ["graphics.PommeViewer._board_state.copy", "graphics.PommeViewer._resource_manager.fog_value", "range", "range", "all"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.fog_value"], ["", "def", "agent_view", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "not", "self", ".", "_is_partially_observable", ":", "\n", "            ", "return", "self", ".", "_board_state", "\n", "\n", "", "agent_view_size", "=", "self", ".", "_agent_view_size", "\n", "state", "=", "self", ".", "_board_state", ".", "copy", "(", ")", "\n", "fog_value", "=", "self", ".", "_resource_manager", ".", "fog_value", "(", ")", "\n", "row", ",", "col", "=", "agent", ".", "position", "\n", "\n", "for", "r", "in", "range", "(", "self", ".", "_board_size", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "self", ".", "_board_size", ")", ":", "\n", "                ", "if", "self", ".", "_is_partially_observable", "and", "not", "all", "(", "[", "\n", "row", ">=", "r", "-", "agent_view_size", ",", "row", "<=", "r", "+", "agent_view_size", ",", "\n", "col", ">=", "c", "-", "agent_view_size", ",", "col", "<=", "c", "+", "agent_view_size", "\n", "]", ")", ":", "\n", "                    ", "state", "[", "r", "]", "[", "c", "]", "=", "fog_value", "\n", "\n", "", "", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_background": [[325, 331], ["pyglet.image.SolidColorImagePattern", "pyglet.image.SolidColorImagePattern.create_image", "pyglet.sprite.Sprite"], "methods", ["None"], ["", "def", "render_background", "(", "self", ")", ":", "\n", "        ", "image_pattern", "=", "pyglet", ".", "image", ".", "SolidColorImagePattern", "(", "\n", "color", "=", "constants", ".", "BACKGROUND_COLOR", ")", "\n", "image", "=", "image_pattern", ".", "create_image", "(", "self", ".", "_width", ",", "self", ".", "_height", ")", "\n", "return", "pyglet", ".", "sprite", ".", "Sprite", "(", "\n", "image", ",", "0", ",", "0", ",", "batch", "=", "self", ".", "_batch", ",", "group", "=", "LAYER_BACKGROUND", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_text": [[332, 364], ["graphics.PommeViewer.board_top", "pyglet.text.Label", "text.append", "pyglet.text.Label", "text.append", "time.strftime", "str"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.board_top"], ["", "def", "render_text", "(", "self", ")", ":", "\n", "        ", "text", "=", "[", "]", "\n", "board_top", "=", "self", ".", "board_top", "(", "y_offset", "=", "8", ")", "\n", "title_label", "=", "pyglet", ".", "text", ".", "Label", "(", "\n", "'Pommerman'", ",", "\n", "font_name", "=", "'Cousine-Regular'", ",", "\n", "font_size", "=", "36", ",", "\n", "x", "=", "constants", ".", "BORDER_SIZE", ",", "\n", "y", "=", "board_top", ",", "\n", "batch", "=", "self", ".", "_batch", ",", "\n", "group", "=", "LAYER_TOP", ")", "\n", "title_label", ".", "color", "=", "constants", ".", "TILE_COLOR", "\n", "text", ".", "append", "(", "title_label", ")", "\n", "\n", "info_text", "=", "''", "\n", "if", "self", ".", "_game_type", "is", "not", "None", ":", "\n", "            ", "info_text", "+=", "'Mode: '", "+", "self", ".", "_game_type", ".", "name", "+", "'   '", "\n", "\n", "", "info_text", "+=", "'Time: '", "+", "strftime", "(", "'%b %d, %Y %H:%M:%S'", ")", "\n", "info_text", "+=", "'   Step: '", "+", "str", "(", "self", ".", "_step", ")", "\n", "\n", "time_label", "=", "pyglet", ".", "text", ".", "Label", "(", "\n", "info_text", ",", "\n", "font_name", "=", "'Arial'", ",", "\n", "font_size", "=", "10", ",", "\n", "x", "=", "constants", ".", "BORDER_SIZE", ",", "\n", "y", "=", "5", ",", "\n", "batch", "=", "self", ".", "_batch", ",", "\n", "group", "=", "LAYER_TOP", ")", "\n", "time_label", ".", "color", "=", "constants", ".", "TEXT_COLOR", "\n", "text", ".", "append", "(", "time_label", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.render_dead_alive": [[365, 406], ["graphics.PommeViewer.board_top", "graphics.PommeViewer._resource_manager.dead_marker", "enumerate", "graphics.PommeViewer._resource_manager.agent_image", "sprites.append", "graphics.PommeViewer.board_right", "pyglet.sprite.Sprite", "sprites.append", "pyglet.sprite.Sprite", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.board_top", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.dead_marker", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.agent_image", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.board_right"], ["", "def", "render_dead_alive", "(", "self", ")", ":", "\n", "        ", "board_top", "=", "self", ".", "board_top", "(", "y_offset", "=", "5", ")", "\n", "image_size", "=", "30", "\n", "spacing", "=", "5", "\n", "dead", "=", "self", ".", "_resource_manager", ".", "dead_marker", "(", ")", "\n", "dead", ".", "width", "=", "image_size", "\n", "dead", ".", "height", "=", "image_size", "\n", "sprites", "=", "[", "]", "\n", "\n", "if", "self", ".", "_game_type", "is", "constants", ".", "GameType", ".", "FFA", "or", "self", ".", "_game_type", "is", "constants", ".", "GameType", ".", "OneVsOne", ":", "\n", "            ", "agents", "=", "self", ".", "_agents", "\n", "", "else", ":", "\n", "            ", "agents", "=", "[", "self", ".", "_agents", "[", "i", "]", "for", "i", "in", "[", "0", ",", "2", ",", "1", ",", "3", "]", "]", "\n", "\n", "", "for", "index", ",", "agent", "in", "enumerate", "(", "agents", ")", ":", "\n", "# weird math to make sure the alignment", "\n", "# is correct. 'image_size + spacing' is an offset", "\n", "# that includes padding (spacing) for each image. ", "\n", "# '4 - index' is used to space each agent out based", "\n", "# on where they are in the array based off of their", "\n", "# index. ", "\n", "            ", "x", "=", "self", ".", "board_right", "(", ")", "-", "(", "len", "(", "agents", ")", "-", "index", ")", "*", "(", "\n", "image_size", "+", "spacing", ")", "\n", "y", "=", "board_top", "\n", "agent_image", "=", "self", ".", "_resource_manager", ".", "agent_image", "(", "agent", ".", "agent_id", ")", "\n", "agent_image", ".", "width", "=", "image_size", "\n", "agent_image", ".", "height", "=", "image_size", "\n", "sprites", ".", "append", "(", "\n", "pyglet", ".", "sprite", ".", "Sprite", "(", "\n", "agent_image", ",", "\n", "x", ",", "\n", "y", ",", "\n", "batch", "=", "self", ".", "_batch", ",", "\n", "group", "=", "LAYER_FOREGROUND", ")", ")", "\n", "\n", "if", "agent", ".", "is_alive", "is", "False", ":", "\n", "                ", "sprites", ".", "append", "(", "\n", "pyglet", ".", "sprite", ".", "Sprite", "(", "\n", "dead", ",", "x", ",", "y", ",", "batch", "=", "self", ".", "_batch", ",", "group", "=", "LAYER_TOP", ")", ")", "\n", "\n", "", "", "return", "sprites", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.board_top": [[407, 410], ["None"], "methods", ["None"], ["", "def", "board_top", "(", "self", ",", "y_offset", "=", "0", ")", ":", "\n", "        ", "return", "constants", ".", "BORDER_SIZE", "+", "(", "\n", "self", ".", "_board_size", "*", "self", ".", "_tile_size", ")", "+", "y_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.board_right": [[411, 414], ["None"], "methods", ["None"], ["", "def", "board_right", "(", "self", ",", "x_offset", "=", "0", ")", ":", "\n", "        ", "return", "constants", ".", "BORDER_SIZE", "+", "(", "\n", "self", ".", "_board_size", "*", "self", ".", "_tile_size", ")", "+", "x_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PommeViewer.get_bomb_life": [[415, 420], ["None"], "methods", ["None"], ["", "def", "get_bomb_life", "(", "self", ",", "row", ",", "col", ")", ":", "\n", "        ", "for", "bomb", "in", "self", ".", "_bombs", ":", "\n", "            ", "x", ",", "y", "=", "bomb", ".", "position", "\n", "if", "x", "==", "row", "and", "y", "==", "col", ":", "\n", "                ", "return", "bomb", ".", "life", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.__init__": [[424, 434], ["graphics.ResourceManager._index_resources", "graphics.ResourceManager._load_fonts", "graphics.ResourceManager._load_images", "graphics.ResourceManager._load_bombs", "graphics.ResourceManager._get_fog_index_value"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._index_resources", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._load_fonts", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._load_images", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._load_bombs", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._get_fog_index_value"], ["def", "__init__", "(", "self", ",", "game_type", ")", ":", "\n", "        ", "self", ".", "_index_resources", "(", ")", "\n", "self", ".", "_load_fonts", "(", ")", "\n", "self", ".", "images", "=", "self", ".", "_load_images", "(", ")", "\n", "self", ".", "bombs", "=", "self", ".", "_load_bombs", "(", ")", "\n", "self", ".", "_fog_value", "=", "self", ".", "_get_fog_index_value", "(", ")", "\n", "self", ".", "_is_team", "=", "True", "\n", "\n", "if", "game_type", "==", "constants", ".", "GameType", ".", "FFA", "or", "game_type", "==", "constants", ".", "GameType", ".", "OneVsOne", ":", "\n", "            ", "self", ".", "_is_team", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._index_resources": [[435, 440], ["pyglet.resource.reindex"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_index_resources", "(", ")", ":", "\n", "# Tell pyglet where to find the resources", "\n", "        ", "pyglet", ".", "resource", ".", "path", "=", "[", "RESOURCE_PATH", "]", "\n", "pyglet", ".", "resource", ".", "reindex", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._load_images": [[441, 450], ["range", "len", "pyglet.resource.image"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_load_images", "(", ")", ":", "\n", "        ", "images_dict", "=", "constants", ".", "IMAGES_DICT", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "images_dict", ")", ")", ":", "\n", "            ", "image_data", "=", "images_dict", "[", "i", "]", "\n", "image", "=", "pyglet", ".", "resource", ".", "image", "(", "image_data", "[", "'file_name'", "]", ")", "\n", "images_dict", "[", "i", "]", "[", "'image'", "]", "=", "image", "\n", "\n", "", "return", "images_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._load_bombs": [[451, 460], ["range", "len", "pyglet.resource.image"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_load_bombs", "(", ")", ":", "\n", "        ", "images_dict", "=", "constants", ".", "BOMB_DICT", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "images_dict", ")", ")", ":", "\n", "            ", "image_data", "=", "images_dict", "[", "i", "]", "\n", "image", "=", "pyglet", ".", "resource", ".", "image", "(", "image_data", "[", "'file_name'", "]", ")", "\n", "images_dict", "[", "i", "]", "[", "'image'", "]", "=", "image", "\n", "\n", "", "return", "images_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._load_fonts": [[461, 467], ["range", "len", "os.path.join", "pyglet.font.add_file"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_load_fonts", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "constants", ".", "FONTS_FILE_NAMES", ")", ")", ":", "\n", "            ", "font_path", "=", "os", ".", "path", ".", "join", "(", "RESOURCE_PATH", ",", "\n", "constants", ".", "FONTS_FILE_NAMES", "[", "i", "]", ")", "\n", "pyglet", ".", "font", ".", "add_file", "(", "font_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager._get_fog_index_value": [[468, 473], ["constants.IMAGES_DICT.items"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_get_fog_index_value", "(", ")", ":", "\n", "        ", "for", "id", ",", "data", "in", "constants", ".", "IMAGES_DICT", ".", "items", "(", ")", ":", "\n", "            ", "if", "data", "[", "'name'", "]", "==", "'Fog'", ":", "\n", "                ", "return", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.tile_from_state_value": [[474, 479], ["range"], "methods", ["None"], ["", "", "", "def", "tile_from_state_value", "(", "self", ",", "value", ")", ":", "\n", "        ", "if", "self", ".", "_is_team", "and", "value", "in", "range", "(", "10", ",", "14", ")", ":", "\n", "            ", "return", "self", ".", "images", "[", "value", "+", "10", "]", "[", "'image'", "]", "\n", "\n", "", "return", "self", ".", "images", "[", "value", "]", "[", "'image'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.agent_image": [[480, 485], ["None"], "methods", ["None"], ["", "def", "agent_image", "(", "self", ",", "agent_id", ")", ":", "\n", "        ", "if", "self", ".", "_is_team", ":", "\n", "            ", "return", "self", ".", "images", "[", "agent_id", "+", "24", "]", "[", "'image'", "]", "\n", "\n", "", "return", "self", ".", "images", "[", "agent_id", "+", "15", "]", "[", "'image'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.dead_marker": [[486, 488], ["None"], "methods", ["None"], ["", "def", "dead_marker", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "images", "[", "19", "]", "[", "'image'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.fog_value": [[489, 491], ["None"], "methods", ["None"], ["", "def", "fog_value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_fog_value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.fog_tile": [[492, 495], ["None"], "methods", ["None"], ["", "def", "fog_tile", "(", "self", ")", ":", "\n", "        ", "img", "=", "self", ".", "images", "[", "self", ".", "_fog_value", "]", "\n", "return", "img", "[", "'image'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.ResourceManager.get_bomb_tile": [[496, 498], ["None"], "methods", ["None"], ["", "def", "get_bomb_tile", "(", "self", ",", "life", ")", ":", "\n", "        ", "return", "self", ".", "bombs", "[", "life", "-", "1", "]", "[", "'image'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.__init__": [[12, 20], ["characters.Bomber.set_agent_id"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.set_agent_id"], ["def", "__init__", "(", "self", ",", "agent_id", "=", "None", ",", "game_type", "=", "None", ")", ":", "\n", "        ", "self", ".", "_game_type", "=", "game_type", "\n", "self", ".", "ammo", "=", "1", "\n", "self", ".", "is_alive", "=", "True", "\n", "self", ".", "blast_strength", "=", "constants", ".", "DEFAULT_BLAST_STRENGTH", "\n", "self", ".", "can_kick", "=", "False", "\n", "if", "agent_id", "is", "not", "None", ":", "\n", "            ", "self", ".", "set_agent_id", "(", "agent_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.set_agent_id": [[21, 46], ["getattr", "getattr", "characters.Bomber.enemies.append", "range", "getattr", "getattr", "range", "range"], "methods", ["None"], ["", "", "def", "set_agent_id", "(", "self", ",", "agent_id", ")", ":", "\n", "        ", "self", ".", "agent_id", "=", "agent_id", "\n", "if", "self", ".", "_game_type", "==", "constants", ".", "GameType", ".", "FFA", ":", "\n", "            ", "self", ".", "teammate", "=", "constants", ".", "Item", ".", "AgentDummy", "\n", "self", ".", "enemies", "=", "[", "\n", "getattr", "(", "constants", ".", "Item", ",", "'Agent%d'", "%", "id_", ")", "\n", "for", "id_", "in", "range", "(", "4", ")", "\n", "if", "id_", "!=", "agent_id", "\n", "]", "\n", "", "elif", "self", ".", "_game_type", "==", "constants", ".", "GameType", ".", "OneVsOne", ":", "\n", "            ", "self", ".", "teammate", "=", "constants", ".", "Item", ".", "AgentDummy", "\n", "self", ".", "enemies", "=", "[", "\n", "getattr", "(", "constants", ".", "Item", ",", "'Agent%d'", "%", "id_", ")", "\n", "for", "id_", "in", "range", "(", "2", ")", "\n", "if", "id_", "!=", "agent_id", "\n", "]", "\n", "", "else", ":", "\n", "            ", "teammate_id", "=", "(", "agent_id", "+", "2", ")", "%", "4", "\n", "self", ".", "teammate", "=", "getattr", "(", "constants", ".", "Item", ",", "'Agent%d'", "%", "teammate_id", ")", "\n", "self", ".", "enemies", "=", "[", "\n", "getattr", "(", "constants", ".", "Item", ",", "'Agent%d'", "%", "id_", ")", "\n", "for", "id_", "in", "range", "(", "4", ")", "\n", "if", "id_", "!=", "agent_id", "and", "id_", "!=", "teammate_id", "\n", "]", "\n", "self", ".", "enemies", ".", "append", "(", "constants", ".", "Item", ".", "AgentDummy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.maybe_lay_bomb": [[47, 53], ["characters.Bomb"], "methods", ["None"], ["", "", "def", "maybe_lay_bomb", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "ammo", ">", "0", ":", "\n", "            ", "self", ".", "ammo", "-=", "1", "\n", "return", "Bomb", "(", "self", ",", "self", ".", "position", ",", "constants", ".", "DEFAULT_BOMB_LIFE", "+", "1", ",", "\n", "self", ".", "blast_strength", ")", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.incr_ammo": [[54, 56], ["min"], "methods", ["None"], ["", "def", "incr_ammo", "(", "self", ")", ":", "\n", "        ", "self", ".", "ammo", "=", "min", "(", "self", ".", "ammo", "+", "1", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position": [[57, 60], ["constants.Action", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "def", "get_next_position", "(", "self", ",", "direction", ")", ":", "\n", "        ", "action", "=", "constants", ".", "Action", "(", "direction", ")", "\n", "return", "utility", ".", "get_next_position", "(", "self", ".", "position", ",", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.move": [[61, 63], ["characters.Bomber.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "def", "move", "(", "self", ",", "direction", ")", ":", "\n", "        ", "self", ".", "position", "=", "self", ".", "get_next_position", "(", "direction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.stop": [[64, 66], ["None"], "methods", ["None"], ["", "def", "stop", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.in_range": [[67, 70], ["None"], "methods", ["None"], ["", "def", "in_range", "(", "self", ",", "exploded_map", ")", ":", "\n", "        ", "row", ",", "col", "=", "self", ".", "position", "\n", "return", "exploded_map", "[", "row", "]", "[", "col", "]", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.die": [[71, 73], ["None"], "methods", ["None"], ["", "def", "die", "(", "self", ")", ":", "\n", "        ", "self", ".", "is_alive", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.set_start_position": [[74, 76], ["None"], "methods", ["None"], ["", "def", "set_start_position", "(", "self", ",", "start_position", ")", ":", "\n", "        ", "self", ".", "start_position", "=", "start_position", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.reset": [[77, 83], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "ammo", "=", "1", ",", "is_alive", "=", "True", ",", "blast_strength", "=", "None", ",", "can_kick", "=", "False", ")", ":", "\n", "        ", "self", ".", "position", "=", "self", ".", "start_position", "\n", "self", ".", "ammo", "=", "ammo", "\n", "self", ".", "is_alive", "=", "is_alive", "\n", "self", ".", "blast_strength", "=", "blast_strength", "or", "constants", ".", "DEFAULT_BLAST_STRENGTH", "\n", "self", ".", "can_kick", "=", "can_kick", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.pick_up": [[84, 92], ["characters.Bomber.incr_ammo", "min"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.incr_ammo"], ["", "def", "pick_up", "(", "self", ",", "item", ",", "max_blast_strength", ")", ":", "\n", "        ", "if", "item", "==", "constants", ".", "Item", ".", "ExtraBomb", ":", "\n", "            ", "self", ".", "incr_ammo", "(", ")", "\n", "", "elif", "item", "==", "constants", ".", "Item", ".", "IncrRange", ":", "\n", "            ", "self", ".", "blast_strength", "=", "min", "(", "self", ".", "blast_strength", "+", "1", ",", "\n", "max_blast_strength", ")", "\n", "", "elif", "item", "==", "constants", ".", "Item", ".", "Kick", ":", "\n", "            ", "self", ".", "can_kick", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.to_json": [[93, 101], ["None"], "methods", ["None"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"agent_id\"", ":", "self", ".", "agent_id", ",", "\n", "\"is_alive\"", ":", "self", ".", "is_alive", ",", "\n", "\"position\"", ":", "self", ".", "position", ",", "\n", "\"ammo\"", ":", "self", ".", "ammo", ",", "\n", "\"blast_strength\"", ":", "self", ".", "blast_strength", ",", "\n", "\"can_kick\"", ":", "self", ".", "can_kick", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.__init__": [[107, 118], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "bomber", ",", "\n", "position", ",", "\n", "life", ",", "\n", "blast_strength", ",", "\n", "moving_direction", "=", "None", ")", ":", "\n", "        ", "self", ".", "bomber", "=", "bomber", "\n", "self", ".", "position", "=", "position", "\n", "self", ".", "life", "=", "life", "\n", "self", ".", "blast_strength", "=", "blast_strength", "\n", "self", ".", "moving_direction", "=", "moving_direction", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.tick": [[119, 121], ["None"], "methods", ["None"], ["", "def", "tick", "(", "self", ")", ":", "\n", "        ", "self", ".", "life", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.fire": [[122, 125], ["None"], "methods", ["None"], ["", "def", "fire", "(", "self", ")", ":", "\n", "        ", "\"\"\"Encounter Flames and blow up.\"\"\"", "\n", "self", ".", "life", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.move": [[126, 130], ["characters.Bomb.is_moving", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.is_moving", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "def", "move", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "is_moving", "(", ")", ":", "\n", "            ", "self", ".", "position", "=", "utility", ".", "get_next_position", "(", "self", ".", "position", ",", "\n", "self", ".", "moving_direction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.stop": [[131, 133], ["None"], "methods", ["None"], ["", "", "def", "stop", "(", "self", ")", ":", "\n", "        ", "self", ".", "moving_direction", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.exploded": [[134, 136], ["None"], "methods", ["None"], ["", "def", "exploded", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "life", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.explode": [[137, 146], ["range", "range", "range", "range"], "methods", ["None"], ["", "def", "explode", "(", "self", ")", ":", "\n", "        ", "row", ",", "col", "=", "self", ".", "position", "\n", "indices", "=", "{", "\n", "'up'", ":", "(", "[", "row", "-", "i", ",", "col", "]", "for", "i", "in", "range", "(", "1", ",", "self", ".", "blast_strength", ")", ")", ",", "\n", "'down'", ":", "(", "[", "row", "+", "i", ",", "col", "]", "for", "i", "in", "range", "(", "self", ".", "blast_strength", ")", ")", ",", "\n", "'left'", ":", "(", "[", "row", ",", "col", "-", "i", "]", "for", "i", "in", "range", "(", "1", ",", "self", ".", "blast_strength", ")", ")", ",", "\n", "'right'", ":", "(", "[", "row", ",", "col", "+", "i", "]", "for", "i", "in", "range", "(", "1", ",", "self", ".", "blast_strength", ")", ")", "\n", "}", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.in_range": [[147, 150], ["None"], "methods", ["None"], ["", "def", "in_range", "(", "self", ",", "exploded_map", ")", ":", "\n", "        ", "row", ",", "col", "=", "self", ".", "position", "\n", "return", "exploded_map", "[", "row", "]", "[", "col", "]", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.is_moving": [[151, 153], ["None"], "methods", ["None"], ["", "def", "is_moving", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "moving_direction", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.to_json": [[154, 161], ["None"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"position\"", ":", "self", ".", "position", ",", "\n", "\"bomber_id\"", ":", "self", ".", "bomber", ".", "agent_id", ",", "\n", "\"life\"", ":", "self", ".", "life", ",", "\n", "\"blast_strength\"", ":", "self", ".", "blast_strength", ",", "\n", "\"moving_direction\"", ":", "self", ".", "moving_direction", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.__init__": [[167, 170], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "position", ",", "life", "=", "2", ")", ":", "\n", "        ", "self", ".", "position", "=", "position", "\n", "self", ".", "life", "=", "life", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.tick": [[171, 173], ["None"], "methods", ["None"], ["", "def", "tick", "(", "self", ")", ":", "\n", "        ", "self", ".", "life", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.is_dead": [[174, 176], ["None"], "methods", ["None"], ["", "def", "is_dead", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "life", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.to_json": [[177, 179], ["None"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"position\"", ":", "self", ".", "position", ",", "\"life\"", ":", "self", ".", "life", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.run": [[14, 83], ["forward_model.ForwardModel.get_observations", "forward_model.ForwardModel.act", "forward_model.ForwardModel.step", "forward_model.ForwardModel.get_observations", "forward_model.ForwardModel.get_rewards", "forward_model.ForwardModel.get_done", "forward_model.ForwardModel.get_info", "steps.append", "agent.episode_end"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_rewards", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_done", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_info", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.episode_end"], ["def", "run", "(", "self", ",", "\n", "num_times", ",", "\n", "board", ",", "\n", "agents", ",", "\n", "bombs", ",", "\n", "items", ",", "\n", "flames", ",", "\n", "is_partially_observable", ",", "\n", "agent_view_size", ",", "\n", "action_space", ",", "\n", "training_agent", "=", "None", ",", "\n", "is_communicative", "=", "False", ")", ":", "\n", "        ", "\"\"\"Run the forward model.\n\n        Args:\n          num_times: The number of times to run it for. This is a maximum and\n            it will stop early if we reach a done.\n          board: The board state to run it from.\n          agents: The agents to use to run it.\n          bombs: The starting bombs.\n          items: The starting items.\n          flames: The starting flames.\n          is_partially_observable: Whether the board is partially observable or\n            not. Only applies to TeamRadio.\n          agent_view_size: If it's partially observable, then the size of the\n            square that the agent can view.\n          action_space: The actions that each agent can take.\n          training_agent: The training agent to pass to done.\n          is_communicative: Whether the action depends on communication\n            observations as well.\n\n        Returns:\n          steps: The list of step results, which are each a dict of \"obs\",\n            \"next_obs\", \"reward\", \"action\".\n          board: Updated board.\n          agents: Updated agents, same models though.\n          bombs: Updated bombs.\n          items: Updated items.\n          flames: Updated flames.\n          done: Whether we completed the game in these steps.\n          info: The result of the game if it's completed.\n        \"\"\"", "\n", "steps", "=", "[", "]", "\n", "for", "_", "in", "num_times", ":", "\n", "            ", "obs", "=", "self", ".", "get_observations", "(", "\n", "board", ",", "agents", ",", "bombs", ",", "is_partially_observable", ",", "agent_view_size", ")", "\n", "actions", "=", "self", ".", "act", "(", "\n", "agents", ",", "obs", ",", "action_space", ",", "is_communicative", "=", "is_communicative", ")", "\n", "board", ",", "agents", ",", "bombs", ",", "items", ",", "flames", "=", "self", ".", "step", "(", "\n", "actions", ",", "board", ",", "agents", ",", "bombs", ",", "items", ",", "flames", ")", "\n", "next_obs", "=", "self", ".", "get_observations", "(", "\n", "board", ",", "agents", ",", "bombs", ",", "is_partially_observable", ",", "agent_view_size", ")", "\n", "reward", "=", "self", ".", "get_rewards", "(", "agents", ",", "game_type", ",", "step_count", ",", "max_steps", ")", "\n", "done", "=", "self", ".", "get_done", "(", "agents", ",", "game_type", ",", "step_count", ",", "max_steps", ",", "\n", "training_agent", ")", "\n", "info", "=", "self", ".", "get_info", "(", "done", ",", "rewards", ",", "game_type", ",", "agents", ")", "\n", "\n", "steps", ".", "append", "(", "{", "\n", "\"obs\"", ":", "obs", ",", "\n", "\"next_obs\"", ":", "next_obs", ",", "\n", "\"reward\"", ":", "reward", ",", "\n", "\"actions\"", ":", "actions", ",", "\n", "}", ")", "\n", "if", "done", ":", "\n", "# Callback to let the agents know that the game has ended.", "\n", "                ", "for", "agent", "in", "agents", ":", "\n", "                    ", "agent", ".", "episode_end", "(", "reward", "[", "agent", ".", "agent_id", "]", ")", "\n", "", "break", "\n", "", "", "return", "steps", ",", "board", ",", "agents", ",", "bombs", ",", "items", ",", "flames", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.act": [[84, 124], ["agent.act", "agent.act", "ret.append", "ret.append", "type", "type", "forward_model.ForwardModel.act.act_with_communication"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act"], ["", "@", "staticmethod", "\n", "def", "act", "(", "agents", ",", "obs", ",", "action_space", ",", "is_communicative", "=", "False", ")", ":", "\n", "        ", "\"\"\"Returns actions for each agent in this list.\n\n        Args:\n          agents: A list of agent objects.\n          obs: A list of matching observations per agent.\n          action_space: The action space for the environment using this model.\n          is_communicative: Whether the action depends on communication\n            observations as well.\n\n        Returns a list of actions.\n        \"\"\"", "\n", "\n", "def", "act_ex_communication", "(", "agent", ")", ":", "\n", "            ", "'''Handles agent's move without communication'''", "\n", "if", "agent", ".", "is_alive", ":", "\n", "                ", "return", "agent", ".", "act", "(", "obs", "[", "agent", ".", "agent_id", "]", ",", "action_space", "=", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "return", "constants", ".", "Action", ".", "Stop", ".", "value", "\n", "\n", "", "", "def", "act_with_communication", "(", "agent", ")", ":", "\n", "            ", "'''Handles agent's move with communication'''", "\n", "if", "agent", ".", "is_alive", ":", "\n", "                ", "action", "=", "agent", ".", "act", "(", "\n", "obs", "[", "agent", ".", "agent_id", "]", ",", "action_space", "=", "action_space", ")", "\n", "if", "type", "(", "action", ")", "==", "int", ":", "\n", "                    ", "action", "=", "[", "action", "]", "+", "[", "0", ",", "0", "]", "\n", "", "assert", "(", "type", "(", "action", ")", "==", "list", ")", "\n", "return", "action", "\n", "", "else", ":", "\n", "                ", "return", "[", "constants", ".", "Action", ".", "Stop", ".", "value", ",", "0", ",", "0", "]", "\n", "\n", "", "", "ret", "=", "[", "]", "\n", "for", "agent", "in", "agents", ":", "\n", "            ", "if", "is_communicative", ":", "\n", "                ", "ret", ".", "append", "(", "act_with_communication", "(", "agent", ")", ")", "\n", "", "else", ":", "\n", "                ", "ret", ".", "append", "(", "act_ex_communication", "(", "agent", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.step": [[125, 487], ["len", "enumerate", "enumerate", "enumerate", "enumerate", "collections.defaultdict", "collections.defaultdict", "enumerate", "enumerate", "enumerate", "numpy.zeros_like", "numpy.where", "zip", "flame.is_dead", "agent.maybe_lay_bomb.is_moving", "enumerate", "enumerate", "constants.Action", "utility.get_next_position", "enumerate", "enumerate", "agent.maybe_lay_bomb.tick", "agent.maybe_lay_bomb.exploded", "curr_flames.append", "curr_items.get", "flame.tick", "flames.append", "utility.get_next_position", "min", "forward_model.ForwardModel.step.crossing"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.is_dead", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.is_moving", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.tick", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.exploded", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Flame.tick", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "step", "(", "actions", ",", "\n", "curr_board", ",", "\n", "curr_agents", ",", "\n", "curr_bombs", ",", "\n", "curr_items", ",", "\n", "curr_flames", ",", "\n", "max_blast_strength", "=", "10", ")", ":", "\n", "        ", "board_size", "=", "len", "(", "curr_board", ")", "\n", "\n", "# Tick the flames. Replace any dead ones with passages. If there is an", "\n", "# item there, then reveal that item.", "\n", "flames", "=", "[", "]", "\n", "for", "flame", "in", "curr_flames", ":", "\n", "            ", "position", "=", "flame", ".", "position", "\n", "if", "flame", ".", "is_dead", "(", ")", ":", "\n", "                ", "item_value", "=", "curr_items", ".", "get", "(", "position", ")", "\n", "if", "item_value", ":", "\n", "                    ", "del", "curr_items", "[", "position", "]", "\n", "", "else", ":", "\n", "                    ", "item_value", "=", "constants", ".", "Item", ".", "Passage", ".", "value", "\n", "", "curr_board", "[", "position", "]", "=", "item_value", "\n", "", "else", ":", "\n", "                ", "flame", ".", "tick", "(", ")", "\n", "flames", ".", "append", "(", "flame", ")", "\n", "", "", "curr_flames", "=", "flames", "\n", "\n", "# Redraw all current flames", "\n", "# Multiple flames may share a position and the map should contain", "\n", "# a flame until all flames are dead to avoid issues with bomb", "\n", "# movements and explosions.", "\n", "for", "flame", "in", "curr_flames", ":", "\n", "            ", "curr_board", "[", "flame", ".", "position", "]", "=", "constants", ".", "Item", ".", "Flames", ".", "value", "\n", "\n", "# Step the living agents and moving bombs.", "\n", "# If two agents try to go to the same spot, they should bounce back to", "\n", "# their previous spots. This is complicated with one example being when", "\n", "# there are three agents all in a row. If the one in the middle tries", "\n", "# to go to the left and bounces with the one on the left, and then the", "\n", "# one on the right tried to go to the middle one's position, she should", "\n", "# also bounce. A way of doing this is to gather all the new positions", "\n", "# before taking any actions. Then, if there are disputes, correct those", "\n", "# disputes iteratively.", "\n", "# Additionally, if two agents try to switch spots by moving into each", "\n", "# Figure out desired next position for alive agents", "\n", "", "alive_agents", "=", "[", "agent", "for", "agent", "in", "curr_agents", "if", "agent", ".", "is_alive", "]", "\n", "desired_agent_positions", "=", "[", "agent", ".", "position", "for", "agent", "in", "alive_agents", "]", "\n", "\n", "for", "num_agent", ",", "agent", "in", "enumerate", "(", "alive_agents", ")", ":", "\n", "            ", "position", "=", "agent", ".", "position", "\n", "# We change the curr_board here as a safeguard. We will later", "\n", "# update the agent's new position.", "\n", "curr_board", "[", "position", "]", "=", "constants", ".", "Item", ".", "Passage", ".", "value", "\n", "action", "=", "actions", "[", "agent", ".", "agent_id", "]", "\n", "\n", "if", "action", "==", "constants", ".", "Action", ".", "Stop", ".", "value", ":", "\n", "                ", "pass", "\n", "", "elif", "action", "==", "constants", ".", "Action", ".", "Bomb", ".", "value", ":", "\n", "                ", "position", "=", "agent", ".", "position", "\n", "if", "not", "utility", ".", "position_is_bomb", "(", "curr_bombs", ",", "position", ")", ":", "\n", "                    ", "bomb", "=", "agent", ".", "maybe_lay_bomb", "(", ")", "\n", "if", "bomb", ":", "\n", "                        ", "curr_bombs", ".", "append", "(", "bomb", ")", "\n", "", "", "", "elif", "utility", ".", "is_valid_direction", "(", "curr_board", ",", "position", ",", "action", ")", ":", "\n", "                ", "desired_agent_positions", "[", "num_agent", "]", "=", "agent", ".", "get_next_position", "(", "\n", "action", ")", "\n", "\n", "# Gather desired next positions for moving bombs. Handle kicks later.", "\n", "", "", "desired_bomb_positions", "=", "[", "bomb", ".", "position", "for", "bomb", "in", "curr_bombs", "]", "\n", "\n", "for", "num_bomb", ",", "bomb", "in", "enumerate", "(", "curr_bombs", ")", ":", "\n", "            ", "curr_board", "[", "bomb", ".", "position", "]", "=", "constants", ".", "Item", ".", "Passage", ".", "value", "\n", "if", "bomb", ".", "is_moving", "(", ")", ":", "\n", "                ", "desired_position", "=", "utility", ".", "get_next_position", "(", "\n", "bomb", ".", "position", ",", "bomb", ".", "moving_direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "curr_board", ",", "desired_position", ")", "and", "not", "utility", ".", "position_is_powerup", "(", "curr_board", ",", "desired_position", ")", "and", "not", "utility", ".", "position_is_wall", "(", "curr_board", ",", "desired_position", ")", ":", "\n", "                    ", "desired_bomb_positions", "[", "num_bomb", "]", "=", "desired_position", "\n", "\n", "# Position switches:", "\n", "# Agent <-> Agent => revert both to previous position.", "\n", "# Bomb <-> Bomb => revert both to previous position.", "\n", "# Agent <-> Bomb => revert Bomb to previous position.", "\n", "", "", "", "crossings", "=", "{", "}", "\n", "\n", "def", "crossing", "(", "current", ",", "desired", ")", ":", "\n", "            ", "'''Checks to see if an agent is crossing paths'''", "\n", "current_x", ",", "current_y", "=", "current", "\n", "desired_x", ",", "desired_y", "=", "desired", "\n", "if", "current_x", "!=", "desired_x", ":", "\n", "                ", "assert", "current_y", "==", "desired_y", "\n", "return", "(", "'X'", ",", "min", "(", "current_x", ",", "desired_x", ")", ",", "current_y", ")", "\n", "", "assert", "current_x", "==", "desired_x", "\n", "return", "(", "'Y'", ",", "current_x", ",", "min", "(", "current_y", ",", "desired_y", ")", ")", "\n", "\n", "", "for", "num_agent", ",", "agent", "in", "enumerate", "(", "alive_agents", ")", ":", "\n", "            ", "if", "desired_agent_positions", "[", "num_agent", "]", "!=", "agent", ".", "position", ":", "\n", "                ", "desired_position", "=", "desired_agent_positions", "[", "num_agent", "]", "\n", "border", "=", "crossing", "(", "agent", ".", "position", ",", "desired_position", ")", "\n", "if", "border", "in", "crossings", ":", "\n", "# Crossed another agent - revert both to prior positions.", "\n", "                    ", "desired_agent_positions", "[", "num_agent", "]", "=", "agent", ".", "position", "\n", "num_agent2", ",", "_", "=", "crossings", "[", "border", "]", "\n", "desired_agent_positions", "[", "num_agent2", "]", "=", "alive_agents", "[", "\n", "num_agent2", "]", ".", "position", "\n", "", "else", ":", "\n", "                    ", "crossings", "[", "border", "]", "=", "(", "num_agent", ",", "True", ")", "\n", "\n", "", "", "", "for", "num_bomb", ",", "bomb", "in", "enumerate", "(", "curr_bombs", ")", ":", "\n", "            ", "if", "desired_bomb_positions", "[", "num_bomb", "]", "!=", "bomb", ".", "position", ":", "\n", "                ", "desired_position", "=", "desired_bomb_positions", "[", "num_bomb", "]", "\n", "border", "=", "crossing", "(", "bomb", ".", "position", ",", "desired_position", ")", "\n", "if", "border", "in", "crossings", ":", "\n", "# Crossed - revert to prior position.", "\n", "                    ", "desired_bomb_positions", "[", "num_bomb", "]", "=", "bomb", ".", "position", "\n", "num", ",", "is_agent", "=", "crossings", "[", "border", "]", "\n", "if", "not", "is_agent", ":", "\n", "# Crossed bomb - revert that to prior position as well.", "\n", "                        ", "desired_bomb_positions", "[", "num", "]", "=", "curr_bombs", "[", "num", "]", ".", "position", "\n", "", "", "else", ":", "\n", "                    ", "crossings", "[", "border", "]", "=", "(", "num_bomb", ",", "False", ")", "\n", "\n", "# Deal with multiple agents or multiple bomb collisions on desired next", "\n", "# position by resetting desired position to current position for", "\n", "# everyone involved in the collision.", "\n", "", "", "", "agent_occupancy", "=", "defaultdict", "(", "int", ")", "\n", "bomb_occupancy", "=", "defaultdict", "(", "int", ")", "\n", "for", "desired_position", "in", "desired_agent_positions", ":", "\n", "            ", "agent_occupancy", "[", "desired_position", "]", "+=", "1", "\n", "", "for", "desired_position", "in", "desired_bomb_positions", ":", "\n", "            ", "bomb_occupancy", "[", "desired_position", "]", "+=", "1", "\n", "\n", "# Resolve >=2 agents or >=2 bombs trying to occupy the same space.", "\n", "", "change", "=", "True", "\n", "while", "change", ":", "\n", "            ", "change", "=", "False", "\n", "for", "num_agent", ",", "agent", "in", "enumerate", "(", "alive_agents", ")", ":", "\n", "                ", "desired_position", "=", "desired_agent_positions", "[", "num_agent", "]", "\n", "curr_position", "=", "agent", ".", "position", "\n", "# Either another agent is going to this position or more than", "\n", "# one bomb is going to this position. In both scenarios, revert", "\n", "# to the original position.", "\n", "if", "desired_position", "!=", "curr_position", "and", "(", "agent_occupancy", "[", "desired_position", "]", ">", "1", "or", "bomb_occupancy", "[", "desired_position", "]", ">", "1", ")", ":", "\n", "                    ", "desired_agent_positions", "[", "num_agent", "]", "=", "curr_position", "\n", "agent_occupancy", "[", "curr_position", "]", "+=", "1", "\n", "change", "=", "True", "\n", "\n", "", "", "for", "num_bomb", ",", "bomb", "in", "enumerate", "(", "curr_bombs", ")", ":", "\n", "                ", "desired_position", "=", "desired_bomb_positions", "[", "num_bomb", "]", "\n", "curr_position", "=", "bomb", ".", "position", "\n", "if", "desired_position", "!=", "curr_position", "and", "(", "bomb_occupancy", "[", "desired_position", "]", ">", "1", "or", "agent_occupancy", "[", "desired_position", "]", ">", "1", ")", ":", "\n", "                    ", "desired_bomb_positions", "[", "num_bomb", "]", "=", "curr_position", "\n", "bomb_occupancy", "[", "curr_position", "]", "+=", "1", "\n", "change", "=", "True", "\n", "\n", "# Handle kicks.", "\n", "", "", "", "agent_indexed_by_kicked_bomb", "=", "{", "}", "\n", "kicked_bomb_indexed_by_agent", "=", "{", "}", "\n", "delayed_bomb_updates", "=", "[", "]", "\n", "delayed_agent_updates", "=", "[", "]", "\n", "\n", "# Loop through all bombs to see if they need a good kicking or cause", "\n", "# collisions with an agent.", "\n", "for", "num_bomb", ",", "bomb", "in", "enumerate", "(", "curr_bombs", ")", ":", "\n", "            ", "desired_position", "=", "desired_bomb_positions", "[", "num_bomb", "]", "\n", "\n", "if", "agent_occupancy", "[", "desired_position", "]", "==", "0", ":", "\n", "# There was never an agent around to kick or collide.", "\n", "                ", "continue", "\n", "\n", "", "agent_list", "=", "[", "\n", "(", "num_agent", ",", "agent", ")", "for", "(", "num_agent", ",", "agent", ")", "in", "enumerate", "(", "alive_agents", ")", "if", "desired_position", "==", "desired_agent_positions", "[", "num_agent", "]", "]", "\n", "if", "not", "agent_list", ":", "\n", "# Agents moved from collision.", "\n", "                ", "continue", "\n", "\n", "# The agent_list should contain a single element at this point.", "\n", "", "assert", "(", "len", "(", "agent_list", ")", "==", "1", ")", "\n", "num_agent", ",", "agent", "=", "agent_list", "[", "0", "]", "\n", "\n", "if", "desired_position", "==", "agent", ".", "position", ":", "\n", "# Agent did not move", "\n", "                ", "if", "desired_position", "!=", "bomb", ".", "position", ":", "\n", "# Bomb moved, but agent did not. The bomb should revert", "\n", "# and stop.", "\n", "                    ", "delayed_bomb_updates", ".", "append", "(", "(", "num_bomb", ",", "bomb", ".", "position", ")", ")", "\n", "", "continue", "\n", "\n", "# NOTE: At this point, we have that the agent in question tried to", "\n", "# move into this position.", "\n", "", "if", "not", "agent", ".", "can_kick", ":", "\n", "# If we move the agent at this point, then we risk having two", "\n", "# agents on a square in future iterations of the loop. So we", "\n", "# push this change to the next stage instead.", "\n", "                ", "delayed_bomb_updates", ".", "append", "(", "(", "num_bomb", ",", "bomb", ".", "position", ")", ")", "\n", "delayed_agent_updates", ".", "append", "(", "(", "num_agent", ",", "agent", ".", "position", ")", ")", "\n", "continue", "\n", "\n", "# Agent moved and can kick - see if the target for the kick never had anyhing on it", "\n", "", "direction", "=", "constants", ".", "Action", "(", "actions", "[", "agent", ".", "agent_id", "]", ")", "\n", "target_position", "=", "utility", ".", "get_next_position", "(", "desired_position", ",", "\n", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "curr_board", ",", "target_position", ")", "and", "agent_occupancy", "[", "target_position", "]", "==", "0", "and", "bomb_occupancy", "[", "target_position", "]", "==", "0", "and", "not", "utility", ".", "position_is_powerup", "(", "curr_board", ",", "target_position", ")", "and", "not", "utility", ".", "position_is_wall", "(", "curr_board", ",", "target_position", ")", ":", "\n", "# Ok to update bomb desired location as we won't iterate over it again here", "\n", "# but we can not update bomb_occupancy on target position and need to check it again", "\n", "# However we need to set the bomb count on the current position to zero so", "\n", "# that the agent can stay on this position.", "\n", "                ", "bomb_occupancy", "[", "desired_position", "]", "=", "0", "\n", "delayed_bomb_updates", ".", "append", "(", "(", "num_bomb", ",", "target_position", ")", ")", "\n", "agent_indexed_by_kicked_bomb", "[", "num_bomb", "]", "=", "num_agent", "\n", "kicked_bomb_indexed_by_agent", "[", "num_agent", "]", "=", "num_bomb", "\n", "bomb", ".", "moving_direction", "=", "direction", "\n", "# Bombs may still collide and we then need to reverse bomb and agent ..", "\n", "", "else", ":", "\n", "                ", "delayed_bomb_updates", ".", "append", "(", "(", "num_bomb", ",", "bomb", ".", "position", ")", ")", "\n", "delayed_agent_updates", ".", "append", "(", "(", "num_agent", ",", "agent", ".", "position", ")", ")", "\n", "\n", "", "", "for", "(", "num_bomb", ",", "bomb_position", ")", "in", "delayed_bomb_updates", ":", "\n", "            ", "desired_bomb_positions", "[", "num_bomb", "]", "=", "bomb_position", "\n", "bomb_occupancy", "[", "bomb_position", "]", "+=", "1", "\n", "change", "=", "True", "\n", "\n", "", "for", "(", "num_agent", ",", "agent_position", ")", "in", "delayed_agent_updates", ":", "\n", "            ", "desired_agent_positions", "[", "num_agent", "]", "=", "agent_position", "\n", "agent_occupancy", "[", "agent_position", "]", "+=", "1", "\n", "change", "=", "True", "\n", "\n", "", "while", "change", ":", "\n", "            ", "change", "=", "False", "\n", "for", "num_agent", ",", "agent", "in", "enumerate", "(", "alive_agents", ")", ":", "\n", "                ", "desired_position", "=", "desired_agent_positions", "[", "num_agent", "]", "\n", "curr_position", "=", "agent", ".", "position", "\n", "# Agents and bombs can only share a square if they are both in their", "\n", "# original position (Agent dropped bomb and has not moved)", "\n", "if", "desired_position", "!=", "curr_position", "and", "(", "agent_occupancy", "[", "desired_position", "]", ">", "1", "or", "bomb_occupancy", "[", "desired_position", "]", "!=", "0", ")", ":", "\n", "# Late collisions resulting from failed kicks force this agent to stay at the", "\n", "# original position. Check if this agent successfully kicked a bomb above and undo", "\n", "# the kick.", "\n", "                    ", "if", "num_agent", "in", "kicked_bomb_indexed_by_agent", ":", "\n", "                        ", "num_bomb", "=", "kicked_bomb_indexed_by_agent", "[", "num_agent", "]", "\n", "bomb", "=", "curr_bombs", "[", "num_bomb", "]", "\n", "desired_bomb_positions", "[", "num_bomb", "]", "=", "bomb", ".", "position", "\n", "bomb_occupancy", "[", "bomb", ".", "position", "]", "+=", "1", "\n", "del", "agent_indexed_by_kicked_bomb", "[", "num_bomb", "]", "\n", "del", "kicked_bomb_indexed_by_agent", "[", "num_agent", "]", "\n", "", "desired_agent_positions", "[", "num_agent", "]", "=", "curr_position", "\n", "agent_occupancy", "[", "curr_position", "]", "+=", "1", "\n", "change", "=", "True", "\n", "\n", "", "", "for", "num_bomb", ",", "bomb", "in", "enumerate", "(", "curr_bombs", ")", ":", "\n", "                ", "desired_position", "=", "desired_bomb_positions", "[", "num_bomb", "]", "\n", "curr_position", "=", "bomb", ".", "position", "\n", "\n", "# This bomb may be a boomerang, i.e. it was kicked back to the", "\n", "# original location it moved from. If it is blocked now, it", "\n", "# can't be kicked and the agent needs to move back to stay", "\n", "# consistent with other movements.", "\n", "if", "desired_position", "==", "curr_position", "and", "num_bomb", "not", "in", "agent_indexed_by_kicked_bomb", ":", "\n", "                    ", "continue", "\n", "\n", "", "bomb_occupancy_", "=", "bomb_occupancy", "[", "desired_position", "]", "\n", "agent_occupancy_", "=", "agent_occupancy", "[", "desired_position", "]", "\n", "# Agents and bombs can only share a square if they are both in their", "\n", "# original position (Agent dropped bomb and has not moved)", "\n", "if", "bomb_occupancy_", ">", "1", "or", "agent_occupancy_", "!=", "0", ":", "\n", "                    ", "desired_bomb_positions", "[", "num_bomb", "]", "=", "curr_position", "\n", "bomb_occupancy", "[", "curr_position", "]", "+=", "1", "\n", "num_agent", "=", "agent_indexed_by_kicked_bomb", ".", "get", "(", "num_bomb", ")", "\n", "if", "num_agent", "is", "not", "None", ":", "\n", "                        ", "agent", "=", "alive_agents", "[", "num_agent", "]", "\n", "desired_agent_positions", "[", "num_agent", "]", "=", "agent", ".", "position", "\n", "agent_occupancy", "[", "agent", ".", "position", "]", "+=", "1", "\n", "del", "kicked_bomb_indexed_by_agent", "[", "num_agent", "]", "\n", "del", "agent_indexed_by_kicked_bomb", "[", "num_bomb", "]", "\n", "", "change", "=", "True", "\n", "\n", "", "", "", "for", "num_bomb", ",", "bomb", "in", "enumerate", "(", "curr_bombs", ")", ":", "\n", "            ", "if", "desired_bomb_positions", "[", "num_bomb", "]", "==", "bomb", ".", "position", "and", "not", "num_bomb", "in", "agent_indexed_by_kicked_bomb", ":", "\n", "# Bomb was not kicked this turn and its desired position is its", "\n", "# current location. Stop it just in case it was moving before.", "\n", "                ", "bomb", ".", "stop", "(", ")", "\n", "", "else", ":", "\n", "# Move bomb to the new position.", "\n", "# NOTE: We already set the moving direction up above.", "\n", "                ", "bomb", ".", "position", "=", "desired_bomb_positions", "[", "num_bomb", "]", "\n", "\n", "", "", "for", "num_agent", ",", "agent", "in", "enumerate", "(", "alive_agents", ")", ":", "\n", "            ", "if", "desired_agent_positions", "[", "num_agent", "]", "!=", "agent", ".", "position", ":", "\n", "                ", "agent", ".", "move", "(", "actions", "[", "agent", ".", "agent_id", "]", ")", "\n", "if", "utility", ".", "position_is_powerup", "(", "curr_board", ",", "agent", ".", "position", ")", ":", "\n", "                    ", "agent", ".", "pick_up", "(", "\n", "constants", ".", "Item", "(", "curr_board", "[", "agent", ".", "position", "]", ")", ",", "\n", "max_blast_strength", "=", "max_blast_strength", ")", "\n", "\n", "# Explode bombs.", "\n", "", "", "", "exploded_map", "=", "np", ".", "zeros_like", "(", "curr_board", ")", "\n", "has_new_explosions", "=", "False", "\n", "\n", "for", "bomb", "in", "curr_bombs", ":", "\n", "            ", "bomb", ".", "tick", "(", ")", "\n", "if", "bomb", ".", "exploded", "(", ")", ":", "\n", "                ", "has_new_explosions", "=", "True", "\n", "", "elif", "curr_board", "[", "bomb", ".", "position", "]", "==", "constants", ".", "Item", ".", "Flames", ".", "value", ":", "\n", "                ", "bomb", ".", "fire", "(", ")", "\n", "has_new_explosions", "=", "True", "\n", "\n", "# Chain the explosions.", "\n", "", "", "while", "has_new_explosions", ":", "\n", "            ", "next_bombs", "=", "[", "]", "\n", "has_new_explosions", "=", "False", "\n", "for", "bomb", "in", "curr_bombs", ":", "\n", "                ", "if", "not", "bomb", ".", "exploded", "(", ")", ":", "\n", "                    ", "next_bombs", ".", "append", "(", "bomb", ")", "\n", "continue", "\n", "\n", "", "bomb", ".", "bomber", ".", "incr_ammo", "(", ")", "\n", "for", "_", ",", "indices", "in", "bomb", ".", "explode", "(", ")", ".", "items", "(", ")", ":", "\n", "                    ", "for", "r", ",", "c", "in", "indices", ":", "\n", "                        ", "if", "not", "all", "(", "\n", "[", "r", ">=", "0", ",", "c", ">=", "0", ",", "r", "<", "board_size", ",", "c", "<", "board_size", "]", ")", ":", "\n", "                            ", "break", "\n", "", "if", "curr_board", "[", "r", "]", "[", "c", "]", "==", "constants", ".", "Item", ".", "Rigid", ".", "value", ":", "\n", "                            ", "break", "\n", "", "exploded_map", "[", "r", "]", "[", "c", "]", "=", "1", "\n", "if", "curr_board", "[", "r", "]", "[", "c", "]", "==", "constants", ".", "Item", ".", "Wood", ".", "value", ":", "\n", "                            ", "break", "\n", "\n", "", "", "", "", "curr_bombs", "=", "next_bombs", "\n", "for", "bomb", "in", "curr_bombs", ":", "\n", "                ", "if", "bomb", ".", "in_range", "(", "exploded_map", ")", ":", "\n", "                    ", "bomb", ".", "fire", "(", ")", "\n", "has_new_explosions", "=", "True", "\n", "\n", "# Update the board's bombs.", "\n", "", "", "", "for", "bomb", "in", "curr_bombs", ":", "\n", "            ", "curr_board", "[", "bomb", ".", "position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "# Update the board's flames.", "\n", "", "flame_positions", "=", "np", ".", "where", "(", "exploded_map", "==", "1", ")", "\n", "for", "row", ",", "col", "in", "zip", "(", "flame_positions", "[", "0", "]", ",", "flame_positions", "[", "1", "]", ")", ":", "\n", "            ", "curr_flames", ".", "append", "(", "characters", ".", "Flame", "(", "(", "row", ",", "col", ")", ")", ")", "\n", "", "for", "flame", "in", "curr_flames", ":", "\n", "            ", "curr_board", "[", "flame", ".", "position", "]", "=", "constants", ".", "Item", ".", "Flames", ".", "value", "\n", "\n", "# Kill agents on flames. Otherwise, update position on curr_board.", "\n", "", "for", "agent", "in", "alive_agents", ":", "\n", "            ", "if", "curr_board", "[", "agent", ".", "position", "]", "==", "constants", ".", "Item", ".", "Flames", ".", "value", ":", "\n", "                ", "agent", ".", "die", "(", ")", "\n", "", "else", ":", "\n", "                ", "curr_board", "[", "agent", ".", "position", "]", "=", "utility", ".", "agent_value", "(", "agent", ".", "agent_id", ")", "\n", "\n", "", "", "return", "curr_board", ",", "curr_agents", ",", "curr_bombs", ",", "curr_items", ",", "curr_flames", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_observations": [[488, 571], ["len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "all", "utility.agent_value", "curr_board.copy", "forward_model.ForwardModel.get_observations.make_bomb_maps"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.agent_value", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "get_observations", "(", "self", ",", "curr_board", ",", "agents", ",", "bombs", ",", "flames", ",", "\n", "is_partially_observable", ",", "agent_view_size", ",", "\n", "game_type", ",", "game_env", ")", ":", "\n", "        ", "\"\"\"Gets the observations as an np.array of the visible squares.\n\n        The agent gets to choose whether it wants to keep the fogged part in\n        memory.\n        \"\"\"", "\n", "board_size", "=", "len", "(", "curr_board", ")", "\n", "\n", "def", "make_bomb_maps", "(", "position", ")", ":", "\n", "            ", "''' Makes an array of an agents bombs and the bombs attributes '''", "\n", "blast_strengths", "=", "np", ".", "zeros", "(", "(", "board_size", ",", "board_size", ")", ")", "\n", "life", "=", "np", ".", "zeros", "(", "(", "board_size", ",", "board_size", ")", ")", "\n", "moving_direction", "=", "np", ".", "zeros", "(", "(", "board_size", ",", "board_size", ")", ")", "\n", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "x", ",", "y", "=", "bomb", ".", "position", "\n", "if", "not", "is_partially_observable", "or", "in_view_range", "(", "position", ",", "x", ",", "y", ")", ":", "\n", "                    ", "blast_strengths", "[", "(", "x", ",", "y", ")", "]", "=", "bomb", ".", "blast_strength", "\n", "life", "[", "(", "x", ",", "y", ")", "]", "=", "bomb", ".", "life", "\n", "if", "bomb", ".", "moving_direction", "is", "not", "None", ":", "\n", "                        ", "moving_direction", "[", "(", "x", ",", "y", ")", "]", "=", "bomb", ".", "moving_direction", ".", "value", "\n", "", "", "", "return", "blast_strengths", ",", "life", ",", "moving_direction", "\n", "\n", "", "def", "make_flame_map", "(", "position", ")", ":", "\n", "            ", "''' Makes an array of an agents flame life'''", "\n", "life", "=", "np", ".", "zeros", "(", "(", "board_size", ",", "board_size", ")", ")", "\n", "\n", "for", "flame", "in", "flames", ":", "\n", "                ", "x", ",", "y", "=", "flame", ".", "position", "\n", "if", "not", "is_partially_observable", "or", "in_view_range", "(", "position", ",", "x", ",", "y", ")", ":", "\n", "# +1 needed because flame removal check is done", "\n", "# before flame is ticked down, i.e. flame life", "\n", "# in environment is 2 -> 1 -> 0 -> dead", "\n", "                    ", "life", "[", "(", "x", ",", "y", ")", "]", "=", "flame", ".", "life", "+", "1", "\n", "", "", "return", "life", "\n", "\n", "", "def", "in_view_range", "(", "position", ",", "v_row", ",", "v_col", ")", ":", "\n", "            ", "'''Checks to see if a tile is in an agents viewing area'''", "\n", "row", ",", "col", "=", "position", "\n", "return", "all", "(", "[", "\n", "row", ">=", "v_row", "-", "agent_view_size", ",", "row", "<=", "v_row", "+", "agent_view_size", ",", "\n", "col", ">=", "v_col", "-", "agent_view_size", ",", "col", "<=", "v_col", "+", "agent_view_size", "\n", "]", ")", "\n", "\n", "", "attrs", "=", "[", "\n", "'position'", ",", "'blast_strength'", ",", "'can_kick'", ",", "'teammate'", ",", "'ammo'", ",", "\n", "'enemies'", "\n", "]", "\n", "alive_agents", "=", "[", "\n", "utility", ".", "agent_value", "(", "agent", ".", "agent_id", ")", "\n", "for", "agent", "in", "agents", "\n", "if", "agent", ".", "is_alive", "\n", "]", "\n", "\n", "observations", "=", "[", "]", "\n", "for", "agent", "in", "agents", ":", "\n", "            ", "agent_obs", "=", "{", "'alive'", ":", "alive_agents", "}", "\n", "board", "=", "curr_board", ".", "copy", "(", ")", "\n", "if", "is_partially_observable", ":", "\n", "                ", "for", "row", "in", "range", "(", "board_size", ")", ":", "\n", "                    ", "for", "col", "in", "range", "(", "board_size", ")", ":", "\n", "                        ", "if", "not", "in_view_range", "(", "agent", ".", "position", ",", "row", ",", "col", ")", ":", "\n", "                            ", "board", "[", "row", ",", "col", "]", "=", "constants", ".", "Item", ".", "Fog", ".", "value", "\n", "", "", "", "", "agent_obs", "[", "'board'", "]", "=", "board", "\n", "bomb_blast_strengths", ",", "bomb_life", ",", "bomb_moving_direction", "=", "make_bomb_maps", "(", "agent", ".", "position", ")", "\n", "agent_obs", "[", "'bomb_blast_strength'", "]", "=", "bomb_blast_strengths", "\n", "agent_obs", "[", "'bomb_life'", "]", "=", "bomb_life", "\n", "agent_obs", "[", "'bomb_moving_direction'", "]", "=", "bomb_moving_direction", "\n", "flame_life", "=", "make_flame_map", "(", "agent", ".", "position", ")", "\n", "agent_obs", "[", "'flame_life'", "]", "=", "flame_life", "\n", "agent_obs", "[", "'game_type'", "]", "=", "game_type", ".", "value", "\n", "agent_obs", "[", "'game_env'", "]", "=", "game_env", "\n", "\n", "for", "attr", "in", "attrs", ":", "\n", "                ", "assert", "hasattr", "(", "agent", ",", "attr", ")", "\n", "agent_obs", "[", "attr", "]", "=", "getattr", "(", "agent", ",", "attr", ")", "\n", "", "observations", ".", "append", "(", "agent_obs", ")", "\n", "\n", "", "return", "observations", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_done": [[572, 589], ["sorted", "any", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_done", "(", "agents", ",", "step_count", ",", "max_steps", ",", "game_type", ",", "training_agent", ")", ":", "\n", "        ", "alive", "=", "[", "agent", "for", "agent", "in", "agents", "if", "agent", ".", "is_alive", "]", "\n", "alive_ids", "=", "sorted", "(", "[", "agent", ".", "agent_id", "for", "agent", "in", "alive", "]", ")", "\n", "if", "step_count", ">=", "max_steps", ":", "\n", "            ", "return", "True", "\n", "", "elif", "game_type", "==", "constants", ".", "GameType", ".", "FFA", "or", "game_type", "==", "constants", ".", "GameType", ".", "OneVsOne", ":", "\n", "            ", "if", "training_agent", "is", "not", "None", "and", "training_agent", "not", "in", "alive_ids", ":", "\n", "                ", "return", "True", "\n", "", "return", "len", "(", "alive", ")", "<=", "1", "\n", "", "elif", "any", "(", "[", "\n", "len", "(", "alive_ids", ")", "<=", "1", ",", "\n", "alive_ids", "==", "[", "0", ",", "2", "]", ",", "\n", "alive_ids", "==", "[", "1", ",", "3", "]", ",", "\n", "]", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_info": [[590, 626], ["len", "enumerate", "enumerate"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_info", "(", "done", ",", "rewards", ",", "game_type", ",", "agents", ")", ":", "\n", "        ", "if", "game_type", "==", "constants", ".", "GameType", ".", "FFA", "or", "game_type", "==", "constants", ".", "GameType", ".", "OneVsOne", ":", "\n", "            ", "alive", "=", "[", "agent", "for", "agent", "in", "agents", "if", "agent", ".", "is_alive", "]", "\n", "if", "done", ":", "\n", "                ", "if", "len", "(", "alive", ")", "!=", "1", ":", "\n", "# Either we have more than 1 alive (reached max steps) or", "\n", "# we have 0 alive (last agents died at the same time).", "\n", "                    ", "return", "{", "\n", "'result'", ":", "constants", ".", "Result", ".", "Tie", ",", "\n", "}", "\n", "", "else", ":", "\n", "                    ", "return", "{", "\n", "'result'", ":", "constants", ".", "Result", ".", "Win", ",", "\n", "'winners'", ":", "[", "num", "for", "num", ",", "reward", "in", "enumerate", "(", "rewards", ")", "if", "reward", "==", "1", "]", "\n", "}", "\n", "", "", "else", ":", "\n", "                ", "return", "{", "\n", "'result'", ":", "constants", ".", "Result", ".", "Incomplete", ",", "\n", "}", "\n", "", "", "elif", "done", ":", "\n", "# We are playing a team game.", "\n", "            ", "if", "rewards", "==", "[", "-", "1", "]", "*", "4", ":", "\n", "                ", "return", "{", "\n", "'result'", ":", "constants", ".", "Result", ".", "Tie", ",", "\n", "}", "\n", "", "else", ":", "\n", "                ", "return", "{", "\n", "'result'", ":", "constants", ".", "Result", ".", "Win", ",", "\n", "'winners'", ":", "[", "num", "for", "num", ",", "reward", "in", "enumerate", "(", "rewards", ")", "if", "reward", "==", "1", "]", ",", "\n", "}", "\n", "", "", "else", ":", "\n", "            ", "return", "{", "\n", "'result'", ":", "constants", ".", "Result", ".", "Incomplete", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_rewards": [[628, 674], ["any", "enumerate", "len", "forward_model.ForwardModel.get_rewards.any_lst_equal"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "get_rewards", "(", "agents", ",", "game_type", ",", "step_count", ",", "max_steps", ")", ":", "\n", "\n", "        ", "def", "any_lst_equal", "(", "lst", ",", "values", ")", ":", "\n", "            ", "'''Checks if list are equal'''", "\n", "return", "any", "(", "[", "lst", "==", "v", "for", "v", "in", "values", "]", ")", "\n", "\n", "", "alive_agents", "=", "[", "num", "for", "num", ",", "agent", "in", "enumerate", "(", "agents", ")", "if", "agent", ".", "is_alive", "]", "\n", "if", "game_type", "==", "constants", ".", "GameType", ".", "FFA", ":", "\n", "            ", "if", "len", "(", "alive_agents", ")", "==", "1", ":", "\n", "# An agent won. Give them +1, others -1.", "\n", "                ", "return", "[", "2", "*", "int", "(", "agent", ".", "is_alive", ")", "-", "1", "for", "agent", "in", "agents", "]", "\n", "", "elif", "step_count", ">=", "max_steps", ":", "\n", "# Game is over from time. Everyone gets -1.", "\n", "                ", "return", "[", "-", "1", "]", "*", "4", "\n", "", "else", ":", "\n", "# Game running: 0 for alive, -1 for dead.", "\n", "                ", "return", "[", "int", "(", "agent", ".", "is_alive", ")", "-", "1", "for", "agent", "in", "agents", "]", "\n", "", "", "elif", "game_type", "==", "constants", ".", "GameType", ".", "OneVsOne", ":", "\n", "            ", "if", "len", "(", "alive_agents", ")", "==", "1", ":", "\n", "# An agent won. Give them +1, the other -1.", "\n", "                ", "return", "[", "2", "*", "int", "(", "agent", ".", "is_alive", ")", "-", "1", "for", "agent", "in", "agents", "]", "\n", "", "elif", "step_count", ">=", "max_steps", ":", "\n", "# Game is over from time. Everyone gets -1.", "\n", "                ", "return", "[", "-", "1", "]", "*", "2", "\n", "", "else", ":", "\n", "# Game running", "\n", "                ", "return", "[", "0", ",", "0", "]", "\n", "", "", "else", ":", "\n", "# We are playing a team game.", "\n", "            ", "if", "any_lst_equal", "(", "alive_agents", ",", "[", "[", "0", ",", "2", "]", ",", "[", "0", "]", ",", "[", "2", "]", "]", ")", ":", "\n", "# Team [0, 2] wins.", "\n", "                ", "return", "[", "1", ",", "-", "1", ",", "1", ",", "-", "1", "]", "\n", "", "elif", "any_lst_equal", "(", "alive_agents", ",", "[", "[", "1", ",", "3", "]", ",", "[", "1", "]", ",", "[", "3", "]", "]", ")", ":", "\n", "# Team [1, 3] wins.", "\n", "                ", "return", "[", "-", "1", ",", "1", ",", "-", "1", ",", "1", "]", "\n", "", "elif", "step_count", ">=", "max_steps", ":", "\n", "# Game is over by max_steps. All agents tie.", "\n", "                ", "return", "[", "-", "1", "]", "*", "4", "\n", "", "elif", "len", "(", "alive_agents", ")", "==", "0", ":", "\n", "# Everyone's dead. All agents tie.", "\n", "                ", "return", "[", "-", "1", "]", "*", "4", "\n", "", "else", ":", "\n", "# No team has yet won or lost.", "\n", "                ", "return", "[", "0", "]", "*", "4", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__._register": [[16, 30], ["inspect.getmembers", "f", "gym.envs.registration.register", "REGISTRY.append", "name.endswith"], "function", ["None"], ["def", "_register", "(", ")", ":", "\n", "    ", "global", "REGISTRY", "\n", "REGISTRY", "=", "[", "]", "\n", "for", "name", ",", "f", "in", "inspect", ".", "getmembers", "(", "configs", ",", "inspect", ".", "isfunction", ")", ":", "\n", "        ", "if", "not", "name", ".", "endswith", "(", "'_env'", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "config", "=", "f", "(", ")", "\n", "gym", ".", "envs", ".", "registration", ".", "register", "(", "\n", "id", "=", "config", "[", "'env_id'", "]", ",", "\n", "entry_point", "=", "config", "[", "'env_entry_point'", "]", ",", "\n", "kwargs", "=", "config", "[", "'env_kwargs'", "]", "\n", ")", "\n", "REGISTRY", ".", "append", "(", "config", "[", "'env_id'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make": [[35, 50], ["gym.make", "enumerate", "gym.make.set_agents", "gym.make.set_init_game_state", "gym.make.set_render_mode", "isinstance", "agent.init_agent"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_agents", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_init_game_state", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_render_mode", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.init_agent"], ["def", "make", "(", "config_id", ",", "agent_list", ",", "game_state_file", "=", "None", ",", "render_mode", "=", "'human'", ")", ":", "\n", "    ", "'''Makes the pommerman env and registers it with gym'''", "\n", "assert", "config_id", "in", "REGISTRY", ",", "\"Unknown configuration '{}'. \"", "\"Possible values: {}\"", ".", "format", "(", "config_id", ",", "REGISTRY", ")", "\n", "env", "=", "gym", ".", "make", "(", "config_id", ")", "\n", "\n", "for", "id_", ",", "agent", "in", "enumerate", "(", "agent_list", ")", ":", "\n", "        ", "assert", "isinstance", "(", "agent", ",", "agents", ".", "BaseAgent", ")", "\n", "# NOTE: This is IMPORTANT so that the agent character is initialized", "\n", "agent", ".", "init_agent", "(", "id_", ",", "env", ".", "spec", ".", "_kwargs", "[", "'game_type'", "]", ")", "\n", "\n", "", "env", ".", "set_agents", "(", "agent_list", ")", "\n", "env", ".", "set_init_game_state", "(", "game_state_file", ")", "\n", "env", ".", "set_render_mode", "(", "render_mode", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.__init__": [[334, 337], ["dict.__init__", "dict.__setattr__"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.__setattr__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "AttrDict", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "super", "(", "AttrDict", ",", "self", ")", ".", "__setattr__", "(", "'_mutable'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.__getattr__": [[338, 343], ["key.startswith", "configs.AttrDict.get"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "key", ")", ":", "\n", "# Do not provide None for unimplemented magic attributes.", "\n", "        ", "if", "key", ".", "startswith", "(", "'__'", ")", ":", "\n", "            ", "raise", "AttributeError", "\n", "", "return", "self", ".", "get", "(", "key", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.__setattr__": [[344, 352], ["key.startswith", "RuntimeError", "AttributeError"], "methods", ["None"], ["", "def", "__setattr__", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "        ", "if", "not", "self", ".", "_mutable", ":", "\n", "            ", "message", "=", "\"Cannot set attribute '{}'.\"", ".", "format", "(", "key", ")", "\n", "message", "+=", "\" Use 'with obj.unlocked:' scope to set attributes.\"", "\n", "raise", "RuntimeError", "(", "message", ")", "\n", "", "if", "key", ".", "startswith", "(", "'__'", ")", ":", "\n", "            ", "raise", "AttributeError", "(", "\"Cannot set magic attribute '{}'\"", ".", "format", "(", "key", ")", ")", "\n", "", "self", "[", "key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.unlocked": [[353, 359], ["dict.__setattr__", "dict.__setattr__"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.__setattr__", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.__setattr__"], ["", "@", "property", "\n", "@", "contextlib", ".", "contextmanager", "\n", "def", "unlocked", "(", "self", ")", ":", "\n", "        ", "super", "(", "AttrDict", ",", "self", ")", ".", "__setattr__", "(", "'_mutable'", ",", "True", ")", "\n", "yield", "\n", "super", "(", "AttrDict", ",", "self", ")", ".", "__setattr__", "(", "'_mutable'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy": [[360, 362], ["type", "super().copy"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "type", "(", "self", ")", "(", "super", "(", "AttrDict", ",", "self", ")", ".", "copy", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.one_vs_one_env": [[20, 38], ["locals"], "function", ["None"], ["def", "one_vs_one_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up an OneVsOne config with the default settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "OneVsOne", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'OneVsOne-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE_ONE_VS_ONE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID_ONE_VS_ONE", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD_ONE_VS_ONE", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS_ONE_VS_ONE", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.ffa_competition_env": [[40, 58], ["locals"], "function", ["None"], ["", "def", "ffa_competition_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a FFA config with the competition settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "FFA", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'PommeFFACompetition-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.ffa_competition_fast_env": [[60, 78], ["locals"], "function", ["None"], ["", "def", "ffa_competition_fast_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a FFA config with the competition settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "FFA", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'PommeFFACompetitionFast-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "1000", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.team_competition_env": [[80, 100], ["locals"], "function", ["None"], ["", "def", "team_competition_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a Team config with the competition settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "Team", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'PommeTeamCompetition-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'agent_view_size'", ":", "constants", ".", "AGENT_VIEW_SIZE", ",", "\n", "'is_partially_observable'", ":", "True", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.team_competition_fast_env": [[102, 122], ["locals"], "function", ["None"], ["", "def", "team_competition_fast_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a Team config with the competition settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "Team", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'PommeTeamCompetitionFast-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "1000", ",", "\n", "'agent_view_size'", ":", "constants", ".", "AGENT_VIEW_SIZE", ",", "\n", "'is_partially_observable'", ":", "True", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.team_competition_v1_env": [[124, 145], ["locals"], "function", ["None"], ["", "def", "team_competition_v1_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a collapsing Team config with the competition settings.\"\"\"", "\n", "env", "=", "envs", ".", "v1", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "Team", "\n", "env_entry_point", "=", "'pommerman.envs.v1:Pomme'", "\n", "env_id", "=", "'PommeTeamCompetition-v1'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'first_collapse'", ":", "constants", ".", "FIRST_COLLAPSE", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'agent_view_size'", ":", "constants", ".", "AGENT_VIEW_SIZE", ",", "\n", "'is_partially_observable'", ":", "True", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.ffa_v0_fast_env": [[147, 165], ["locals"], "function", ["None"], ["", "def", "ffa_v0_fast_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a FFA config with the default settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "FFA", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'PommeFFAFast-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "1000", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.ffa_v1_env": [[167, 186], ["locals"], "function", ["None"], ["", "def", "ffa_v1_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a collapsing FFA config with the default settings.\"\"\"", "\n", "env", "=", "envs", ".", "v1", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "FFA", "\n", "env_entry_point", "=", "'pommerman.envs.v1:Pomme'", "\n", "env_id", "=", "'PommeFFA-v1'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'first_collapse'", ":", "constants", ".", "FIRST_COLLAPSE", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.team_v0_env": [[188, 206], ["locals"], "function", ["None"], ["", "def", "team_v0_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a team config with the default settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "Team", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'PommeTeam-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.team_v0_fast_env": [[208, 226], ["locals"], "function", ["None"], ["", "def", "team_v0_fast_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a team config with the default settings.\"\"\"", "\n", "env", "=", "envs", ".", "v0", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "Team", "\n", "env_entry_point", "=", "'pommerman.envs.v0:Pomme'", "\n", "env_id", "=", "'PommeTeamFast-v0'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "2000", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.radio_v2_env": [[228, 250], ["locals"], "function", ["None"], ["", "def", "radio_v2_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a team radio config with the default settings.\"\"\"", "\n", "env", "=", "envs", ".", "v2", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "TeamRadio", "\n", "env_entry_point", "=", "'pommerman.envs.v2:Pomme'", "\n", "env_id", "=", "'PommeRadio-v2'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'agent_view_size'", ":", "constants", ".", "AGENT_VIEW_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'is_partially_observable'", ":", "True", ",", "\n", "'radio_vocab_size'", ":", "constants", ".", "RADIO_VOCAB_SIZE", ",", "\n", "'radio_num_words'", ":", "constants", ".", "RADIO_NUM_WORDS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.radio_competition_env": [[252, 274], ["locals"], "function", ["None"], ["", "def", "radio_competition_env", "(", ")", ":", "\n", "    ", "\"\"\"Start up a team radio config with the default settings.\"\"\"", "\n", "env", "=", "envs", ".", "v2", ".", "Pomme", "\n", "game_type", "=", "constants", ".", "GameType", ".", "TeamRadio", "\n", "env_entry_point", "=", "'pommerman.envs.v2:Pomme'", "\n", "env_id", "=", "'PommeRadioCompetition-v2'", "\n", "env_kwargs", "=", "{", "\n", "'game_type'", ":", "game_type", ",", "\n", "'board_size'", ":", "constants", ".", "BOARD_SIZE", ",", "\n", "'num_rigid'", ":", "constants", ".", "NUM_RIGID", ",", "\n", "'num_wood'", ":", "constants", ".", "NUM_WOOD", ",", "\n", "'num_items'", ":", "constants", ".", "NUM_ITEMS", ",", "\n", "'max_steps'", ":", "constants", ".", "MAX_STEPS", ",", "\n", "'render_fps'", ":", "constants", ".", "RENDER_FPS", ",", "\n", "'agent_view_size'", ":", "constants", ".", "AGENT_VIEW_SIZE", ",", "\n", "'is_partially_observable'", ":", "True", ",", "\n", "'env'", ":", "env_entry_point", ",", "\n", "'radio_vocab_size'", ":", "constants", ".", "RADIO_VOCAB_SIZE", ",", "\n", "'radio_num_words'", ":", "constants", ".", "RADIO_NUM_WORDS", ",", "\n", "}", "\n", "agent", "=", "characters", ".", "Bomber", "\n", "return", "locals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.save_config": [[276, 304], ["logging.info", "os.makedirs", "os.path.join", "logging.info", "message.format", "open", "ruamel.dump"], "function", ["None"], ["", "def", "save_config", "(", "config", ",", "logdir", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save a new configuration by name.\n\n    If a logging directory is specified, is will be created and the configuration\n    will be stored there. Otherwise, a log message will be printed.\n\n    Args:\n      config: Configuration object.\n      logdir: Location for writing summaries and checkpoints if specified.\n\n    Returns:\n      Configuration object.\n    \"\"\"", "\n", "if", "logdir", ":", "\n", "        ", "with", "config", ".", "unlocked", ":", "\n", "            ", "config", ".", "logdir", "=", "logdir", "\n", "", "message", "=", "'Start a new run and write summaries and checkpoints to {}.'", "\n", "logging", ".", "info", "(", "message", ".", "format", "(", "config", ".", "logdir", ")", ")", "\n", "os", ".", "makedirs", "(", "config", ".", "logdir", ")", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "logdir", ",", "'config.yaml'", ")", "\n", "with", "open", "(", "config_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "yaml", ".", "dump", "(", "config", ",", "f", ",", "default_flow_style", "=", "False", ")", "\n", "", "", "else", ":", "\n", "        ", "message", "=", "(", "\n", "'Start a new run without storing summaries and checkpoints since no '", "\n", "'logging directory was specified.'", ")", "\n", "logging", ".", "info", "(", "message", ")", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.load_config": [[306, 329], ["logging.info", "os.path.join", "IOError", "open", "ruamel.load", "message.format", "os.path.exists"], "function", ["None"], ["", "def", "load_config", "(", "logdir", ")", ":", "\n", "    ", "\"\"\"Load a configuration from the log directory.\n\n    Args:\n      logdir: The logging directory containing the configuration file.\n\n    Raises:\n      IOError: The logging directory does not contain a configuration file.\n\n    Returns:\n      Configuration object.\n    \"\"\"", "\n", "config_path", "=", "logdir", "and", "os", ".", "path", ".", "join", "(", "logdir", ",", "'config.yaml'", ")", "\n", "if", "not", "config_path", "or", "not", "os", ".", "path", ".", "exists", "(", "config_path", ")", ":", "\n", "        ", "message", "=", "(", "\n", "'Cannot resume an existing run since the logging directory does not '", "\n", "'contain a configuration file.'", ")", "\n", "raise", "IOError", "(", "message", ")", "\n", "", "with", "open", "(", "config_path", ",", "'r'", ")", "as", "file_", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "file_", ")", "\n", "", "message", "=", "'Resume run and write summaries and checkpoints to {}.'", "\n", "logging", ".", "info", "(", "message", ".", "format", "(", "config", ".", "logdir", ")", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.match.unique_uuid": [[20, 32], ["os.listdir", "str", "os.makedirs", "uuid.uuid4", "str", "uuid.uuid4"], "function", ["None"], ["def", "unique_uuid", "(", "dir", ")", ":", "\n", "    ", "\"\"\"Generates a unique UUID and checks for collision with files within the\n    specified directory (So we don't override a pre-existing file)\"\"\"", "\n", "try", ":", "\n", "        ", "ls_dir", "=", "os", ".", "listdir", "(", "dir", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "        ", "os", ".", "makedirs", "(", "dir", ")", "\n", "ls_dir", "=", "[", "]", "\n", "", "uuid_", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "[", ":", "10", "]", "\n", "while", "uuid_", "+", "\".json\"", "in", "ls_dir", ":", "\n", "        ", "uuid_", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "[", ":", "10", "]", "\n", "", "return", "uuid_", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.match.resolve_classes": [[34, 53], ["isinstance", "enumerate", "list", "isinstance", "hasattr", "match.resolve_classes", "isinstance", "isinstance", "isinstance", "str", "isinstance", "value.tolist", "isinstance", "isinstance", "int"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.match.resolve_classes"], ["", "def", "resolve_classes", "(", "i", ")", ":", "\n", "    ", "\"\"\"Resolves observation into JSONable types by looping over every element\n    in it\"\"\"", "\n", "if", "isinstance", "(", "i", ",", "tuple", ")", ":", "\n", "        ", "i", "=", "list", "(", "i", ")", "\n", "", "for", "key", ",", "value", "in", "enumerate", "(", "i", ")", ":", "\n", "        ", "if", "isinstance", "(", "i", ",", "dict", ")", ":", "\n", "            ", "key", "=", "value", "\n", "value", "=", "i", "[", "key", "]", "\n", "", "if", "hasattr", "(", "value", ",", "'__iter__'", ")", "and", "not", "isinstance", "(", "\n", "i", "[", "key", "]", ",", "str", ")", "and", "not", "isinstance", "(", "i", "[", "key", "]", ",", "numpy", ".", "ndarray", ")", ":", "\n", "            ", "i", "[", "key", "]", "=", "resolve_classes", "(", "value", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "enum", ".", "Enum", ")", ":", "\n", "            ", "i", "[", "key", "]", "=", "str", "(", "value", ".", "name", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "numpy", ".", "ndarray", ")", ":", "\n", "            ", "i", "[", "key", "]", "=", "value", ".", "tolist", "(", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "numpy", ".", "uint8", ")", "or", "isinstance", "(", "value", ",", "numpy", ".", "int64", ")", ":", "\n", "            ", "i", "[", "key", "]", "=", "int", "(", "value", ")", "\n", "", "", "return", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.match.thread": [[55, 113], ["match.unique_uuid", "pommerman.make", "multiprocessing.Pipe", "queue_subproc.put", "pommerman.make.reset", "pommerman.make.close", "net.send", "net.recv", "exit", "numpy.array().tolist", "str", "match.resolve_classes", "record[].append", "open", "rapidjson.dump", "base_agent", "base_agent", "base_agent", "base_agent", "env.reset.copy", "str", "enumerate", "net.send", "net.recv", "numpy.array().tolist", "pommerman.make.step", "numpy.array", "uuid.uuid4", "obs_bytes.append", "obs_bytes.append", "len", "numpy.array", "gzip.compress", "gzip.compress", "bytes", "bytes", "rapidjson.dumps", "rapidjson.dumps"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.match.unique_uuid", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.match.resolve_classes", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["", "def", "thread", "(", "players", ",", "queue_subproc", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Handles running of the match loop\"\"\"", "\n", "uuid_", "=", "unique_uuid", "(", "\"matches\"", ")", "\n", "base_agent", "=", "pommerman", ".", "agents", ".", "BaseAgent", "\n", "env", "=", "pommerman", ".", "make", "(", "\n", "mode", ",", "\n", "[", "base_agent", "(", ")", ",", "base_agent", "(", ")", ",", "\n", "base_agent", "(", ")", ",", "base_agent", "(", ")", "]", ")", "\n", "net", ",", "net_end", "=", "multiprocessing", ".", "Pipe", "(", ")", "\n", "queue_subproc", ".", "put", "(", "[", "net_end", ",", "players", ",", "uuid_", "]", ")", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "record", "=", "{", "\n", "\"board\"", ":", "numpy", ".", "array", "(", "env", ".", "_board", ",", "copy", "=", "True", ")", ".", "tolist", "(", ")", ",", "\n", "\"actions\"", ":", "[", "]", ",", "\n", "\"mode\"", ":", "str", "(", "mode", ")", "\n", "}", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "obs_res", "=", "resolve_classes", "(", "obs", ".", "copy", "(", ")", ")", "\n", "turn_id", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "[", ":", "5", "]", "\n", "try", ":", "\n", "            ", "obs_bytes", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "enumerate", "(", "obs_res", ")", ":", "\n", "                ", "if", "10", "+", "key", "in", "obs", "[", "0", "]", "[", "\"alive\"", "]", ":", "\n", "                    ", "obs_bytes", ".", "append", "(", "\n", "gzip", ".", "compress", "(", "\n", "bytes", "(", "\n", "rapidjson", ".", "dumps", "(", "{", "\n", "\"o\"", ":", "value", ",", "# o = obs", "\n", "\"i\"", ":", "turn_id", ",", "# i = Turn ID", "\n", "\"d\"", ":", "False", "# d = Dead", "\n", "}", ")", ",", "\n", "\"utf8\"", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "obs_bytes", ".", "append", "(", "\n", "gzip", ".", "compress", "(", "\n", "bytes", "(", "\n", "rapidjson", ".", "dumps", "(", "{", "\n", "\"d\"", ":", "True", "# d = Dead", "\n", "}", ")", ",", "\n", "\"utf8\"", ")", ")", ")", "\n", "", "", "net", ".", "send", "(", "[", "\n", "constants", ".", "SubprocessCommands", ".", "match_next", ".", "value", ",", "turn_id", ",", "\n", "obs_bytes", ",", "\n", "len", "(", "obs", "[", "0", "]", "[", "\"alive\"", "]", ")", "\n", "]", ")", "\n", "act", "=", "net", ".", "recv", "(", ")", "\n", "", "except", ":", "\n", "            ", "act", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "", "record", "[", "\"actions\"", "]", ".", "append", "(", "numpy", ".", "array", "(", "act", ",", "copy", "=", "True", ")", ".", "tolist", "(", ")", ")", "\n", "obs", ",", "rew", ",", "done", "=", "env", ".", "step", "(", "act", ")", "[", ":", "3", "]", "\n", "", "record", "[", "\"reward\"", "]", "=", "rew", "\n", "env", ".", "close", "(", ")", "\n", "with", "open", "(", "\"./matches/\"", "+", "uuid_", "+", "\".json\"", ",", "\"w\"", ")", "as", "file", ":", "\n", "        ", "rapidjson", ".", "dump", "(", "record", ",", "file", ")", "\n", "", "net", ".", "send", "(", "[", "constants", ".", "SubprocessCommands", ".", "match_end", ".", "value", ",", "rew", "]", ")", "\n", "net", ".", "recv", "(", ")", "\n", "exit", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.network._run_server": [[237, 243], ["asyncio.set_event_loop", "asyncio.get_event_loop().run_until_complete", "asyncio.get_event_loop().run_forever", "asyncio.new_event_loop", "websockets.serve", "asyncio.get_event_loop", "asyncio.get_event_loop"], "function", ["None"], ["", "", "", "def", "_run_server", "(", "port", ")", ":", "\n", "    ", "\"\"\"Handles running the websocket thread\"\"\"", "\n", "asyncio", ".", "set_event_loop", "(", "asyncio", ".", "new_event_loop", "(", ")", ")", "\n", "asyncio", ".", "get_event_loop", "(", ")", ".", "run_until_complete", "(", "\n", "websockets", ".", "serve", "(", "ws_handler", ",", "'localhost'", ",", "port", ")", ")", "\n", "asyncio", ".", "get_event_loop", "(", ")", ".", "run_forever", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.network.thread": [[245, 260], ["threading.Thread", "threading.Thread.start", "asyncio.set_event_loop", "asyncio.get_event_loop().run_until_complete", "asyncio.get_event_loop().run_forever", "threading.Thread.join", "asyncio.new_event_loop", "program_loop", "asyncio.get_event_loop", "asyncio.get_event_loop"], "function", ["None"], ["", "def", "thread", "(", "pipe_main", ",", "queue_subproc", ",", "port", ",", "max_players", ",", "mode", ",", "stop_timeout", ")", ":", "\n", "    ", "\"\"\"Creates a network thread\"\"\"", "\n", "# Note: Multiple threads are used so globals are used to share data b/w them", "\n", "global", "MAX_PLAYERS", ",", "PIPE_MAIN", ",", "QUEUE_SUBPROC", ",", "MODE", ",", "STOP_TIMEOUT", "\n", "MAX_PLAYERS", "=", "max_players", "\n", "PIPE_MAIN", "=", "pipe_main", "\n", "QUEUE_SUBPROC", "=", "queue_subproc", "\n", "MODE", "=", "mode", "\n", "STOP_TIMEOUT", "=", "stop_timeout", "\n", "ws_thread", "=", "threading", ".", "Thread", "(", "target", "=", "_run_server", ",", "args", "=", "(", "port", ",", ")", ")", "\n", "ws_thread", ".", "start", "(", ")", "\n", "asyncio", ".", "set_event_loop", "(", "asyncio", ".", "new_event_loop", "(", ")", ")", "\n", "asyncio", ".", "get_event_loop", "(", ")", ".", "run_until_complete", "(", "program_loop", "(", ")", ")", "\n", "asyncio", ".", "get_event_loop", "(", ")", ".", "run_forever", "(", ")", "\n", "ws_thread", ".", "join", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.__init__._exit_handler": [[23, 36], ["ui.info", "subprocess_net.terminate", "exit", "i.terminate"], "function", ["None"], ["", "config", "=", "f", "(", ")", "\n", "gym", ".", "envs", ".", "registration", ".", "register", "(", "\n", "id", "=", "config", "[", "'env_id'", "]", ",", "\n", "entry_point", "=", "config", "[", "'env_entry_point'", "]", ",", "\n", "kwargs", "=", "config", "[", "'env_kwargs'", "]", "\n", ")", "\n", "REGISTRY", ".", "append", "(", "config", "[", "'env_id'", "]", ")", "\n", "\n", "\n", "# Register environments with gym", "\n", "", "", "_register", "(", ")", "\n", "\n", "def", "make", "(", "config_id", ",", "agent_list", ",", "game_state_file", "=", "None", ",", "render_mode", "=", "'human'", ")", ":", "\n", "    ", "'''Makes the pommerman env and registers it with gym'''", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.__init__.init": [[38, 57], ["ui.info", "int", "int", "pommerman.configs.__dir__", "float", "str", "__init__.run", "ui.ask_string", "ui.ask_string", "ui.fatal", "ui.ask_string", "ui.ask_choice", "modes.append", "getattr"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\"Possible values: {}\"", ".", "format", "(", "config_id", ",", "REGISTRY", ")", "\n", "env", "=", "gym", ".", "make", "(", "config_id", ")", "\n", "\n", "for", "id_", ",", "agent", "in", "enumerate", "(", "agent_list", ")", ":", "\n", "        ", "assert", "isinstance", "(", "agent", ",", "agents", ".", "BaseAgent", ")", "\n", "# NOTE: This is IMPORTANT so that the agent character is initialized", "\n", "agent", ".", "init_agent", "(", "id_", ",", "env", ".", "spec", ".", "_kwargs", "[", "'game_type'", "]", ")", "\n", "\n", "", "env", ".", "set_agents", "(", "agent_list", ")", "\n", "env", ".", "set_init_game_state", "(", "game_state_file", ")", "\n", "env", ".", "set_render_mode", "(", "render_mode", ")", "\n", "return", "env", "\n", "\n", "\n", "", "from", ".", "import", "cli", "\n", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.__init__.run": [[59, 135], ["multiprocessing.Pipe", "multiprocessing.Queue", "multiprocessing.Process", "multiprocessing.Process.start", "int", "signal.signal", "ui.info", "netpipe.send", "netpipe.recv", "tuple", "time.sleep", "__init__._exit_handler", "ui.Symbol", "int", "list", "netpipe.send", "ui.info", "concurrent_list[].keys", "len", "random.sample", "range", "process.is_alive", "MATCH_SUBPROCESS.remove", "len", "MATCH_SUBPROCESS.append", "int", "MATCH_SUBPROCESS.append", "__init__._create_match", "int", "__init__._create_match", "len", "len", "concurrent_list[].index"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__._exit_handler", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.__init__._create_match", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.__init__._create_match"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.server.__init__._create_match": [[137, 143], ["multiprocessing.Process", "multiprocessing.Process.start"], "function", ["None"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.__init__": [[20, 26], ["websocket.create_connection", "threading.Lock", "str"], "methods", ["None"], ["\n", "CONCURRENTLY_LOOKING", "=", "{", "\n", "\"room\"", ":", "{", "}", ",", "\n", "\"noroom\"", ":", "[", "]", "\n", "}", "# This holds the IDs of players concurrently looking for a room", "\n", "PLAYER_WS", "=", "{", "}", "# This stores the mapping from player ID to the websocket object", "\n", "MATCH_PROCESS", "=", "{", "}", "# This holds pipes to match processes", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.server_status": [[27, 39], ["network.Network._send", "network.Network._recieve", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._send", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._recieve"], ["MAX_PLAYERS", "=", "0", "\n", "PIPE_MAIN", "=", "False", "# This holds the queue (Main-proc <-> Network-proc)", "\n", "QUEUE_SUBPROC", "=", "False", "# This holds the queue (Subproc <-> Network-proc)", "\n", "MODE", "=", "\"\"", "\n", "STOP_TIMEOUT", "=", "0", "\n", "\n", "\n", "async", "def", "message_parse", "(", "message", ",", "websocket", ")", ":", "\n", "    ", "\"\"\"Parse the messages recieved from the clients\"\"\"", "\n", "if", "message", "[", "\"intent\"", "]", "is", "constants", ".", "NetworkCommands", ".", "check", ".", "value", ":", "\n", "        ", "await", "websocket", ".", "send", "(", "\n", "rapidjson", ".", "dumps", "(", "{", "\n", "\"intent\"", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.join_list": [[40, 59], ["network.Network._recieve", "network.Network._send", "network.Network._send", "Exception", "Exception", "str"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._recieve", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._send", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._send"], ["constants", ".", "NetworkCommands", ".", "status_ok", ".", "value", ",", "\n", "\"players\"", ":", "\n", "len", "(", "PLAYER_WS", ")", ",", "\n", "\"matches\"", ":", "\n", "len", "(", "MATCH_PROCESS", ")", "\n", "}", ")", ")", "\n", "", "elif", "message", "[", "\"intent\"", "]", "is", "constants", ".", "NetworkCommands", ".", "match_act", ".", "value", ":", "\n", "        ", "if", "message", "[", "\"turn_id\"", "]", "==", "MATCH_PROCESS", "[", "message", "[", "\"match_id\"", "]", "]", "[", "\"turn_id\"", "]", ":", "\n", "# Note: The statements below assign the action to the respective players", "\n", "            ", "MATCH_PROCESS", "[", "message", "[", "\"match_id\"", "]", "]", "[", "\"act\"", "]", "[", "\n", "MATCH_PROCESS", "[", "message", "[", "\"match_id\"", "]", "]", "[", "\"players\"", "]", ".", "index", "(", "\n", "message", "[", "\"player_id\"", "]", ")", "]", "=", "message", "[", "\"act\"", "]", "\n", "MATCH_PROCESS", "[", "message", "[", "\"match_id\"", "]", "]", "[", "\"recv\"", "]", "[", "MATCH_PROCESS", "[", "message", "[", "\n", "\"match_id\"", "]", "]", "[", "\"players\"", "]", ".", "index", "(", "message", "[", "\"player_id\"", "]", ")", "]", "=", "True", "\n", "", "", "elif", "message", "[", "\"intent\"", "]", "is", "constants", ".", "NetworkCommands", ".", "replay", ".", "value", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"matches\"", ")", ",", "\n", "str", "(", "message", "[", "\"replay_id\"", "]", ")", "+", "\".json\"", ")", ",", "'r'", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.wait_match": [[60, 67], ["network.Network._recieve"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._recieve"], ["# Note: Registry expression match comes after as it's an expensive operation as compared to file I/O", "\n", "                ", "if", "re", ".", "fullmatch", "(", "\"^[a-z0-9-]*$\"", ",", "\n", "message", "[", "\"replay_id\"", "]", ")", "is", "not", "None", ":", "\n", "                    ", "f", "=", "rapidjson", ".", "load", "(", "f", ")", "\n", "await", "websocket", ".", "send", "(", "\n", "gzip", ".", "compress", "(", "\n", "bytes", "(", "\n", "rapidjson", ".", "dumps", "(", "[", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.match_get": [[68, 113], ["network.Network.lock.acquire", "tuple", "enumerate", "network.Network.ws_.recv", "network.Network.lock.release", "rapidjson.loads", "numpy.asarray", "Exception", "str", "gzip.decompress", "rapidjson.loads", "Exception", "int", "int"], "methods", ["None"], ["constants", ".", "NetworkCommands", ".", "status_ok", ".", "value", ",", "f", "\n", "]", ")", ",", "\"utf8\"", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "await", "websocket", ".", "send", "(", "\n", "gzip", ".", "compress", "(", "\n", "bytes", "(", "\n", "rapidjson", ".", "dumps", "(", "[", "\n", "constants", ".", "NetworkCommands", ".", "status_fail", ".", "value", "\n", "]", ")", ",", "\"utf8\"", ")", ")", ")", "\n", "", "", "", "except", ":", "\n", "            ", "await", "websocket", ".", "send", "(", "\n", "gzip", ".", "compress", "(", "\n", "bytes", "(", "\n", "rapidjson", ".", "dumps", "(", "\n", "[", "constants", ".", "NetworkCommands", ".", "status_fail", ".", "value", "]", ")", ",", "\n", "\"utf8\"", ")", ")", ")", "\n", "", "", "elif", "message", "[", "\"intent\"", "]", "in", "[", "\n", "constants", ".", "NetworkCommands", ".", "match", ".", "value", ",", "\n", "constants", ".", "NetworkCommands", ".", "room", ".", "value", "\n", "]", ":", "\n", "        ", "if", "len", "(", "PLAYER_WS", ")", ">=", "MAX_PLAYERS", ":", "\n", "            ", "await", "websocket", ".", "send", "(", "\n", "rapidjson", ".", "dumps", "(", "{", "\n", "\"intent\"", ":", "\n", "constants", ".", "NetworkCommands", ".", "status_full", ".", "value", "\n", "}", ")", ")", "\n", "return", "\n", "", "uuid_", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "while", "uuid_", "in", "PLAYER_WS", ":", "\n", "            ", "uuid_", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "", "PLAYER_WS", "[", "uuid_", "]", "=", "{", "\"ws\"", ":", "websocket", "}", "\n", "if", "message", "[", "\"intent\"", "]", "is", "constants", ".", "NetworkCommands", ".", "match", ".", "value", ":", "\n", "            ", "CONCURRENTLY_LOOKING", "[", "\"noroom\"", "]", ".", "append", "(", "uuid_", ")", "\n", "PLAYER_WS", "[", "uuid_", "]", "[", "\"noroom\"", "]", "=", "True", "\n", "", "elif", "message", "[", "\"intent\"", "]", "is", "constants", ".", "NetworkCommands", ".", "room", ".", "value", ":", "\n", "            ", "if", "message", "[", "\"room\"", "]", "in", "CONCURRENTLY_LOOKING", "[", "\"room\"", "]", ":", "\n", "                ", "if", "len", "(", "CONCURRENTLY_LOOKING", "[", "\"room\"", "]", "[", "message", "[", "\"room\"", "]", "]", ")", "<=", "4", ":", "\n", "                    ", "CONCURRENTLY_LOOKING", "[", "\"room\"", "]", "[", "message", "[", "\"room\"", "]", "]", ".", "append", "(", "uuid_", ")", "\n", "", "else", ":", "\n", "                    ", "await", "websocket", ".", "send", "(", "\n", "rapidjson", ".", "dumps", "(", "{", "\n", "\"intent\"", ":", "\n", "constants", ".", "NetworkCommands", ".", "status_full", ".", "value", "\n", "}", ")", ")", "\n", "return", "\n", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.send_move": [[114, 126], ["network.Network._send"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._send"], ["                ", "CONCURRENTLY_LOOKING", "[", "\"room\"", "]", "[", "message", "[", "\"room\"", "]", "]", "=", "[", "uuid_", "]", "\n", "", "PLAYER_WS", "[", "uuid_", "]", "[", "\"noroom\"", "]", "=", "False", "\n", "PLAYER_WS", "[", "uuid_", "]", "[", "\"room\"", "]", "=", "str", "(", "message", "[", "\"room\"", "]", ")", "\n", "", "await", "websocket", ".", "send", "(", "\n", "rapidjson", ".", "dumps", "(", "{", "\n", "\"intent\"", ":", "\n", "constants", ".", "NetworkCommands", ".", "status_reg", ".", "value", ",", "\n", "\"player_id\"", ":", "\n", "uuid_", ",", "\n", "\"mode\"", ":", "\n", "MODE", "\n", "}", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.get_replay": [[127, 141], ["network.Network._send", "rapidjson.loads", "Exception", "str", "Exception", "gzip.decompress", "network.Network.ws_.recv"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._send"], ["\n", "", "", "async", "def", "ws_handler", "(", "websocket", ",", "pth", "=", "None", ")", ":", "# pylint: disable=unused-argument", "\n", "    ", "\"\"\"Handle the messages recieved by WebSocket (pth is not required but still\\\nreturned by the 'websockets' library)\"\"\"", "\n", "try", ":", "\n", "        ", "async", "for", "message", "in", "websocket", ":", "\n", "            ", "try", ":", "\n", "                ", "await", "message_parse", "(", "rapidjson", ".", "loads", "(", "message", ")", ",", "websocket", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "", "except", "websockets", ".", "exceptions", ".", "ConnectionClosed", ":", "\n", "        ", "pass", "\n", "\n", "\n", "", "", "async", "def", "program_loop", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._send": [[142, 150], ["network.Network.lock.acquire", "network.Network.ws_.send", "network.Network.lock.release", "rapidjson.dumps", "Exception"], "methods", ["None"], ["    ", "\"\"\"Handles other network-related function\"\"\"", "\n", "global", "CONCURRENTLY_LOOKING", "\n", "while", "(", "True", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "for", "uuid_", "in", "list", "(", "PLAYER_WS", ".", "keys", "(", ")", ")", ":", "\n", "                ", "i", "=", "PLAYER_WS", "[", "uuid_", "]", "\n", "if", "not", "i", "[", "\"ws\"", "]", ".", "open", ":", "\n", "                    ", "if", "i", "[", "\"noroom\"", "]", "is", "True", ":", "\n", "                        ", "try", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network._recieve": [[151, 166], ["network.Network.lock.acquire", "network.Network.ws_.recv", "network.Network.lock.release", "rapidjson.loads", "Exception", "Exception", "Exception"], "methods", ["None"], ["                            ", "del", "CONCURRENTLY_LOOKING", "[", "\"noroom\"", "]", "[", "CONCURRENTLY_LOOKING", "[", "\n", "\"noroom\"", "]", ".", "index", "(", "uuid_", ")", "]", "\n", "", "except", ":", "\n", "                            ", "pass", "\n", "", "", "elif", "i", "[", "\"noroom\"", "]", "is", "False", ":", "\n", "                        ", "try", ":", "\n", "                            ", "del", "CONCURRENTLY_LOOKING", "[", "\"room\"", "]", "[", "i", "[", "\"room\"", "]", "]", "[", "\n", "CONCURRENTLY_LOOKING", "[", "\"room\"", "]", "[", "i", "[", "\"room\"", "]", "]", ".", "index", "(", "\n", "uuid_", ")", "]", "\n", "", "except", ":", "\n", "                            ", "pass", "\n", "", "", "try", ":", "\n", "                        ", "del", "PLAYER_WS", "[", "uuid_", "]", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "", "", "", "if", "PIPE_MAIN", ".", "poll", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__._exit_handler": [[26, 33], ["ui.info", "exit"], "function", ["None"], ["entry_point", "=", "config", "[", "'env_entry_point'", "]", ",", "\n", "kwargs", "=", "config", "[", "'env_kwargs'", "]", "\n", ")", "\n", "REGISTRY", ".", "append", "(", "config", "[", "'env_id'", "]", ")", "\n", "\n", "\n", "# Register environments with gym", "\n", "", "", "_register", "(", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.init": [[35, 66], ["ui.ask_yes_no", "ui.info", "network.Network", "signal.signal", "ui.info", "__init__.intent", "ui.ask_string", "network.Network.server_status", "ui.fatal", "ui.fatal", "str"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.intent", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.server_status"], ["def", "make", "(", "config_id", ",", "agent_list", ",", "game_state_file", "=", "None", ",", "render_mode", "=", "'human'", ")", ":", "\n", "    ", "'''Makes the pommerman env and registers it with gym'''", "\n", "assert", "config_id", "in", "REGISTRY", ",", "\"Unknown configuration '{}'. \"", "\"Possible values: {}\"", ".", "format", "(", "config_id", ",", "REGISTRY", ")", "\n", "env", "=", "gym", ".", "make", "(", "config_id", ")", "\n", "\n", "for", "id_", ",", "agent", "in", "enumerate", "(", "agent_list", ")", ":", "\n", "        ", "assert", "isinstance", "(", "agent", ",", "agents", ".", "BaseAgent", ")", "\n", "# NOTE: This is IMPORTANT so that the agent character is initialized", "\n", "agent", ".", "init_agent", "(", "id_", ",", "env", ".", "spec", ".", "_kwargs", "[", "'game_type'", "]", ")", "\n", "\n", "", "env", ".", "set_agents", "(", "agent_list", ")", "\n", "env", ".", "set_init_game_state", "(", "game_state_file", ")", "\n", "env", ".", "set_render_mode", "(", "render_mode", ")", "\n", "return", "env", "\n", "\n", "\n", "", "from", ".", "import", "cli", "\n", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__._agent_prompt": [[68, 79], ["sys.path.append", "importlib.import_module", "ui.ask_string", "getattr", "getattr", "os.getcwd", "ui.ask_string", "getattr.__dir__", "ui.fatal", "ui.info"], "function", ["None"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.intent": [[81, 110], ["ui.ask_choice", "__init__._agent_prompt", "__init__.match", "str", "__init__._agent_prompt", "__init__.match", "ui.ask_string", "__init__.replay", "exit"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__._agent_prompt", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.match", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__._agent_prompt", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.match", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.replay"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.match": [[112, 183], ["agent.", "ui.info", "ui.ask_yes_no", "ui.info", "network.join_list", "ui.info", "ui.info", "network.wait_match", "ui.info", "__init__.replay", "__init__.intent", "agent.init_agent", "network.match_get", "agent.act", "ui.fatal", "ui.fatal", "gym.spaces.Discrete", "network.send_move", "agent.episode_end", "ui.fatal", "ui.info", "ui.fatal", "ui.info", "ui.info", "pommerman.constants.Item"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.join_list", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.wait_match", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.replay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.intent", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.init_agent", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.match_get", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.send_move", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.episode_end"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.replay": [[185, 242], ["ui.info", "pommerman.make", "pommerman.make.reset", "numpy.array", "pommerman.make.close", "__init__.intent", "ui.ask_string", "str", "network.get_replay", "ui.info", "pommerman.make.render", "ui.info", "ui.fatal", "str", "pommerman.agents.BaseAgent", "pommerman.agents.BaseAgent", "pommerman.agents.BaseAgent", "pommerman.agents.BaseAgent", "pommerman.make.step", "ui.info", "Exception", "ui.fatal", "str"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.__init__.intent", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.client.network.Network.get_replay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.cli.train_with_tensorforce.WrappedEnv.__init__": [[38, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gym", ",", "visualize", "=", "False", ")", ":", "\n", "        ", "self", ".", "gym", "=", "gym", "\n", "self", ".", "visualize", "=", "visualize", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.cli.train_with_tensorforce.WrappedEnv.execute": [[42, 55], ["train_with_tensorforce.WrappedEnv.unflatten_action", "train_with_tensorforce.WrappedEnv.gym.get_observations", "train_with_tensorforce.WrappedEnv.gym.act", "train_with_tensorforce.WrappedEnv.insert", "train_with_tensorforce.WrappedEnv.gym.step", "train_with_tensorforce.WrappedEnv.gym.featurize", "train_with_tensorforce.WrappedEnv.gym.render"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render"], ["", "def", "execute", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "visualize", ":", "\n", "            ", "self", ".", "gym", ".", "render", "(", ")", "\n", "\n", "", "actions", "=", "self", ".", "unflatten_action", "(", "action", "=", "action", ")", "\n", "\n", "obs", "=", "self", ".", "gym", ".", "get_observations", "(", ")", "\n", "all_actions", "=", "self", ".", "gym", ".", "act", "(", "obs", ")", "\n", "all_actions", ".", "insert", "(", "self", ".", "gym", ".", "training_agent", ",", "actions", ")", "\n", "state", ",", "reward", ",", "terminal", ",", "_", "=", "self", ".", "gym", ".", "step", "(", "all_actions", ")", "\n", "agent_state", "=", "self", ".", "gym", ".", "featurize", "(", "state", "[", "self", ".", "gym", ".", "training_agent", "]", ")", "\n", "agent_reward", "=", "reward", "[", "self", ".", "gym", ".", "training_agent", "]", "\n", "return", "agent_state", ",", "terminal", ",", "agent_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.cli.train_with_tensorforce.WrappedEnv.reset": [[56, 60], ["train_with_tensorforce.WrappedEnv.gym.reset", "train_with_tensorforce.WrappedEnv.gym.featurize"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "gym", ".", "reset", "(", ")", "\n", "agent_obs", "=", "self", ".", "gym", ".", "featurize", "(", "obs", "[", "3", "]", ")", "\n", "return", "agent_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.cli.train_with_tensorforce.clean_up_agents": [[29, 32], ["agent.shutdown"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.shutdown"], ["def", "clean_up_agents", "(", "agents", ")", ":", "\n", "    ", "\"\"\"Stops all agents\"\"\"", "\n", "return", "[", "agent", ".", "shutdown", "(", ")", "for", "agent", "in", "agents", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.cli.train_with_tensorforce.main": [[62, 150], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "pommerman.make", "training_agent.initialize", "atexit.register", "train_with_tensorforce.WrappedEnv", "tensorforce.execution.Runner", "tensorforce.execution.Runner.run", "print", "pommerman.helpers.make_agent_from_string", "os.makedirs", "os.makedirs", "functools.partial", "tensorforce.execution.Runner.close", "enumerate", "type", "pommerman.make.set_training_agent", "os.path.isdir", "os.path.isdir", "parser.parse_args.agents.split"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.helpers.__init__.make_agent_from_string", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_training_agent"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "'''CLI interface to bootstrap taining'''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Playground Flags.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--game\"", ",", "default", "=", "\"pommerman\"", ",", "help", "=", "\"Game to choose.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config\"", ",", "\n", "default", "=", "\"PommeFFACompetition-v0\"", ",", "\n", "help", "=", "\"Configuration to execute. See env_ids in \"", "\n", "\"configs.py for options.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--agents\"", ",", "\n", "default", "=", "\"tensorforce::ppo,test::agents.SimpleAgent,\"", "\n", "\"test::agents.SimpleAgent,test::agents.SimpleAgent\"", ",", "\n", "help", "=", "\"Comma delineated list of agent types and docker \"", "\n", "\"locations to run the agents.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--agent_env_vars\"", ",", "\n", "help", "=", "\"Comma delineated list of agent environment vars \"", "\n", "\"to pass to Docker. This is only for the Docker Agent.\"", "\n", "\" An example is '0:foo=bar:baz=lar,3:foo=lam', which \"", "\n", "\"would send two arguments to Docker Agent 0 and one to\"", "\n", "\" Docker Agent 3.\"", ",", "\n", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--record_pngs_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Directory to record the PNGs of the game. \"", "\n", "\"Doesn't record if None.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--record_json_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Directory to record the JSON representations of \"", "\n", "\"the game. Doesn't record if None.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--render\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to render or not. Defaults to False.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--game_state_file\"", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"File from which to load game state. Defaults to \"", "\n", "\"None.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "config", "=", "args", ".", "config", "\n", "record_pngs_dir", "=", "args", ".", "record_pngs_dir", "\n", "record_json_dir", "=", "args", ".", "record_json_dir", "\n", "agent_env_vars", "=", "args", ".", "agent_env_vars", "\n", "game_state_file", "=", "args", ".", "game_state_file", "\n", "\n", "# TODO: After https://github.com/MultiAgentLearning/playground/pull/40", "\n", "#       this is still missing the docker_env_dict parsing for the agents.", "\n", "agents", "=", "[", "\n", "helpers", ".", "make_agent_from_string", "(", "agent_string", ",", "agent_id", "+", "1000", ")", "\n", "for", "agent_id", ",", "agent_string", "in", "enumerate", "(", "args", ".", "agents", ".", "split", "(", "\",\"", ")", ")", "\n", "]", "\n", "\n", "env", "=", "make", "(", "config", ",", "agents", ",", "game_state_file", ")", "\n", "training_agent", "=", "None", "\n", "\n", "for", "agent", "in", "agents", ":", "\n", "        ", "if", "type", "(", "agent", ")", "==", "TensorForceAgent", ":", "\n", "            ", "training_agent", "=", "agent", "\n", "env", ".", "set_training_agent", "(", "agent", ".", "agent_id", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "record_pngs_dir", ":", "\n", "        ", "assert", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "record_pngs_dir", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "record_pngs_dir", ")", "\n", "", "if", "args", ".", "record_json_dir", ":", "\n", "        ", "assert", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "record_json_dir", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "record_json_dir", ")", "\n", "\n", "# Create a Proximal Policy Optimization agent", "\n", "", "agent", "=", "training_agent", ".", "initialize", "(", "env", ")", "\n", "\n", "atexit", ".", "register", "(", "functools", ".", "partial", "(", "clean_up_agents", ",", "agents", ")", ")", "\n", "wrapped_env", "=", "WrappedEnv", "(", "env", ",", "visualize", "=", "args", ".", "render", ")", "\n", "runner", "=", "Runner", "(", "agent", "=", "agent", ",", "environment", "=", "wrapped_env", ")", "\n", "runner", ".", "run", "(", "episodes", "=", "10", ",", "max_episode_timesteps", "=", "2000", ")", "\n", "print", "(", "\"Stats: \"", ",", "runner", ".", "episode_rewards", ",", "runner", ".", "episode_timesteps", ",", "\n", "runner", ".", "episode_times", ")", "\n", "\n", "try", ":", "\n", "        ", "runner", ".", "close", "(", ")", "\n", "", "except", "AttributeError", "as", "e", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.cli.run_battle.run": [[30, 115], ["make", "numpy.random.seed", "random.seed", "make.seed", "range", "atexit.register", "helpers.make_agent_from_string", "print", "make.reset", "print", "random.randint", "time.time", "infos.append", "times.append", "print", "enumerate", "os.makedirs", "os.makedirs", "make.act", "make.step", "make.render", "make.render", "make.save_json", "time.sleep", "datetime.datetime.now().isoformat", "args.agents.split", "pommerman.utility.join_json_state", "run_battle.run._run"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.helpers.__init__.make_agent_from_string", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.save_json", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.join_json_state"], ["def", "run", "(", "args", ",", "num_times", "=", "1", ",", "seed", "=", "None", ")", ":", "\n", "    ", "'''Wrapper to help start the game'''", "\n", "config", "=", "args", ".", "config", "\n", "record_pngs_dir", "=", "args", ".", "record_pngs_dir", "\n", "record_json_dir", "=", "args", ".", "record_json_dir", "\n", "agent_env_vars", "=", "args", ".", "agent_env_vars", "\n", "game_state_file", "=", "args", ".", "game_state_file", "\n", "render_mode", "=", "args", ".", "render_mode", "\n", "do_sleep", "=", "args", ".", "do_sleep", "\n", "\n", "agents", "=", "[", "\n", "helpers", ".", "make_agent_from_string", "(", "agent_string", ",", "agent_id", ")", "\n", "for", "agent_id", ",", "agent_string", "in", "enumerate", "(", "args", ".", "agents", ".", "split", "(", "','", ")", ")", "\n", "]", "\n", "\n", "env", "=", "make", "(", "config", ",", "agents", ",", "game_state_file", ",", "render_mode", "=", "render_mode", ")", "\n", "\n", "def", "_run", "(", "record_pngs_dir", "=", "None", ",", "record_json_dir", "=", "None", ")", ":", "\n", "        ", "'''Runs a game'''", "\n", "print", "(", "\"Starting the Game.\"", ")", "\n", "if", "record_pngs_dir", "and", "not", "os", ".", "path", ".", "isdir", "(", "record_pngs_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "record_pngs_dir", ")", "\n", "", "if", "record_json_dir", "and", "not", "os", ".", "path", ".", "isdir", "(", "record_json_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "record_json_dir", ")", "\n", "\n", "", "obs", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "\n", "while", "not", "done", ":", "\n", "            ", "if", "args", ".", "render", ":", "\n", "                ", "env", ".", "render", "(", "\n", "record_pngs_dir", "=", "record_pngs_dir", ",", "\n", "record_json_dir", "=", "record_json_dir", ",", "\n", "do_sleep", "=", "do_sleep", ")", "\n", "", "if", "args", ".", "render", "is", "False", "and", "record_json_dir", ":", "\n", "                ", "env", ".", "save_json", "(", "record_json_dir", ")", "\n", "time", ".", "sleep", "(", "1.0", "/", "env", ".", "_render_fps", ")", "\n", "", "actions", "=", "env", ".", "act", "(", "obs", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "\n", "", "print", "(", "\"Final Result: \"", ",", "info", ")", "\n", "if", "args", ".", "render", ":", "\n", "            ", "env", ".", "render", "(", "\n", "record_pngs_dir", "=", "record_pngs_dir", ",", "\n", "record_json_dir", "=", "record_json_dir", ",", "\n", "do_sleep", "=", "do_sleep", ")", "\n", "if", "do_sleep", ":", "\n", "                ", "time", ".", "sleep", "(", "5", ")", "\n", "", "env", ".", "render", "(", "close", "=", "True", ")", "\n", "\n", "", "if", "args", ".", "render", "is", "False", "and", "record_json_dir", ":", "\n", "            ", "env", ".", "save_json", "(", "record_json_dir", ")", "\n", "time", ".", "sleep", "(", "1.0", "/", "env", ".", "_render_fps", ")", "\n", "\n", "", "if", "record_json_dir", ":", "\n", "            ", "finished_at", "=", "datetime", ".", "now", "(", ")", ".", "isoformat", "(", ")", "\n", "_agents", "=", "args", ".", "agents", ".", "split", "(", "','", ")", "\n", "utility", ".", "join_json_state", "(", "record_json_dir", ",", "_agents", ",", "finished_at", ",", "\n", "config", ",", "info", ")", "\n", "\n", "", "return", "info", "\n", "\n", "", "if", "seed", "is", "None", ":", "\n", "# Pick a random seed between 0 and 2^31 - 1", "\n", "        ", "seed", "=", "random", ".", "randint", "(", "0", ",", "np", ".", "iinfo", "(", "np", ".", "int32", ")", ".", "max", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "\n", "infos", "=", "[", "]", "\n", "times", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_times", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "record_pngs_dir_", "=", "record_pngs_dir", "+", "'/%d'", "%", "(", "i", "+", "1", ")", "if", "record_pngs_dir", "else", "None", "\n", "record_json_dir_", "=", "record_json_dir", "+", "'/%d'", "%", "(", "i", "+", "1", ")", "if", "record_json_dir", "else", "None", "\n", "infos", ".", "append", "(", "_run", "(", "record_pngs_dir_", ",", "record_json_dir_", ")", ")", "\n", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "print", "(", "\"Game Time: \"", ",", "times", "[", "-", "1", "]", ")", "\n", "\n", "", "atexit", ".", "register", "(", "env", ".", "close", ")", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.cli.run_battle.main": [[117, 173], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run_battle.run"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "main", "(", ")", ":", "\n", "    ", "'''CLI entry pointed used to bootstrap a battle'''", "\n", "simple_agent", "=", "'test::agents.SimpleAgent'", "\n", "player_agent", "=", "'player::arrows'", "\n", "docker_agent", "=", "'docker::pommerman/simple-agent'", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Playground Flags.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--config'", ",", "\n", "default", "=", "'PommeFFACompetition-v0'", ",", "\n", "help", "=", "'Configuration to execute. See env_ids in '", "\n", "'configs.py for options.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--agents'", ",", "\n", "default", "=", "','", ".", "join", "(", "[", "simple_agent", "]", "*", "4", ")", ",", "\n", "# default=','.join([player_agent] + [simple_agent]*3]),", "\n", "# default=','.join([docker_agent] + [simple_agent]*3]),", "\n", "help", "=", "'Comma delineated list of agent types and docker '", "\n", "'locations to run the agents.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--agent_env_vars'", ",", "\n", "help", "=", "'Comma delineated list of agent environment vars '", "\n", "'to pass to Docker. This is only for the Docker Agent.'", "\n", "\" An example is '0:foo=bar:baz=lar,3:foo=lam', which \"", "\n", "'would send two arguments to Docker Agent 0 and one '", "\n", "'to Docker Agent 3.'", ",", "\n", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--record_pngs_dir'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'Directory to record the PNGs of the game. '", "\n", "\"Doesn't record if None.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--record_json_dir'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'Directory to record the JSON representations of '", "\n", "\"the game. Doesn't record if None.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--render\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to render or not. Defaults to False.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--render_mode'", ",", "\n", "default", "=", "'human'", ",", "\n", "help", "=", "\"What mode to render. Options are human, rgb_pixel, and rgb_array\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--game_state_file'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"File from which to load game state.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--do_sleep'", ",", "\n", "default", "=", "True", ",", "\n", "help", "=", "\"Whether we sleep after each rendering.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "run", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent.__init__": [[24, 33], ["BaseAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SimpleAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Keep track of recently visited uninteresting positions so that we", "\n", "# don't keep visiting the same places.", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "# Keep track of the previous direction to help with the enemy standoffs.", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent.act": [[34, 117], ["tuple", "numpy.array", "simple_agent.SimpleAgent.act.convert_bombs"], "methods", ["None"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", "=", "6", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "# Maybe lay a bomb if we are within a space of a wooden wall.", "\n", "", "if", "self", ".", "_near_wood", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "1", ")", ":", "\n", "            ", "if", "self", ".", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "                ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "", "else", ":", "\n", "                ", "return", "constants", ".", "Action", ".", "Stop", ".", "value", "\n", "\n", "# Move towards a wooden wall if there is one within two reachable spaces and you have a bomb.", "\n", "", "", "direction", "=", "self", ".", "_near_wood", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "[", "direction", "]", ",", "bombs", ")", "\n", "if", "directions", ":", "\n", "                ", "return", "directions", "[", "0", "]", ".", "value", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._djikstra": [[118, 184], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "simple_agent.SimpleAgent._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._directions_in_range_of_bomb": [[185, 227], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._find_safe_directions": [[228, 322], ["queue.PriorityQueue", "queue.PriorityQueue.put", "set", "len", "board.copy", "unsafe_directions.items", "utility.get_direction", "queue.PriorityQueue.empty", "queue.PriorityQueue.get", "set.add", "utility.get_next_position", "utility.position_on_board", "disallowed.append", "utility.position_is_passable", "utility.position_is_fog", "safe.append", "queue.PriorityQueue.put", "simple_agent.SimpleAgent._find_safe_directions.is_stuck_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_fog"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._is_adjacent_enemy": [[323, 330], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._has_bomb": [[331, 334], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._maybe_bomb": [[335, 363], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._nearest_position": [[364, 377], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._get_direction_towards_position": [[378, 392], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._near_enemy": [[393, 399], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._near_good_powerup": [[400, 409], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._near_wood": [[410, 416], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._filter_invalid_directions": [[417, 427], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._filter_unsafe_directions": [[428, 444], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.simple_agent.SimpleAgent._filter_recently_visited": [[445, 457], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.__init__": [[62, 75], ["BaseAgent.__init__", "RL_brain_CHAT.CHAT"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CHATAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "RL", "=", "CHAT", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ",", "model_path", "=", "False", ")", "\n", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "# Keep track of the previous direction to help with the enemy standoffs.", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "execution", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.executionenv": [[76, 78], ["None"], "methods", ["None"], ["", "def", "executionenv", "(", "self", ")", ":", "\n", "        ", "self", ".", "execution", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.act": [[79, 88], ["chat.featurize", "chat.CHATAgent.RL.choose_action", "chat.CHATAgent.act2", "chat.CHATAgent.RL.get_confidence"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.get_confidence"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "obs_new", "=", "featurize", "(", "obs", ")", "\n", "action", "=", "self", ".", "RL", ".", "choose_action", "(", "obs_new", ",", "self", ".", "execution", ")", "\n", "if", "action", "==", "6", ":", "#the choice is the advisor action ", "\n", "            ", "action", "=", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "conf", "=", "self", ".", "RL", ".", "get_confidence", "(", "obs_new", ",", "action", ")", "\n", "if", "conf", "<", "0.6", ":", "\n", "                ", "action", "=", "0", "# If confidence is less than the threshold, chat returns a placeholder action", "\n", "", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.store": [[89, 94], ["chat.CHATAgent.act2", "chat.featurize", "chat.featurize", "chat.CHATAgent.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "advisor_act", "=", "self", ".", "act2", "(", "obs", ",", "6", ")", "\n", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "reward", ",", "obs_", ",", "act_", ",", "advisor_act", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.learn": [[95, 97], ["chat.CHATAgent.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.copy_network": [[98, 100], ["chat.CHATAgent.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.save_model": [[101, 103], ["chat.CHATAgent.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent.act2": [[105, 175], ["tuple", "numpy.array", "chat.CHATAgent.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._djikstra": [[176, 242], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "chat.CHATAgent._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._directions_in_range_of_bomb": [[243, 285], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._find_safe_directions": [[286, 380], ["queue.PriorityQueue", "queue.PriorityQueue.put", "set", "len", "board.copy", "unsafe_directions.items", "utility.get_direction", "queue.PriorityQueue.empty", "queue.PriorityQueue.get", "set.add", "utility.get_next_position", "utility.position_on_board", "disallowed.append", "utility.position_is_passable", "utility.position_is_fog", "safe.append", "queue.PriorityQueue.put", "chat.CHATAgent._find_safe_directions.is_stuck_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_fog"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._is_adjacent_enemy": [[381, 388], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._has_bomb": [[389, 392], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._maybe_bomb": [[393, 421], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._nearest_position": [[422, 435], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._get_direction_towards_position": [[436, 450], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._near_enemy": [[451, 457], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._near_good_powerup": [[458, 467], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._near_wood": [[468, 474], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._filter_invalid_directions": [[475, 485], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._filter_unsafe_directions": [[486, 502], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.CHATAgent._filter_recently_visited": [[503, 515], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.make_np_float": [[24, 26], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.chat.featurize": [[33, 56], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "chat.make_np_float", "chat.make_np_float", "chat.make_np_float", "chat.make_np_float", "chat.make_np_float", "chat.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.__init__": [[67, 82], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor3admiralae", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "action_space", "=", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.set": [[83, 85], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.act": [[86, 93], ["numpy.random.uniform", "advisor3admiralae.Advisor3admiralae.act2", "advisor3admiralae.featurize", "advisor3admiralae.Advisor3admiralae.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.store": [[94, 98], ["advisor3admiralae.featurize", "advisor3admiralae.featurize", "advisor3admiralae.Advisor3admiralae.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.learn": [[99, 101], ["advisor3admiralae.Advisor3admiralae.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.copy_network": [[102, 104], ["advisor3admiralae.Advisor3admiralae.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.save_model": [[105, 107], ["advisor3admiralae.Advisor3admiralae.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae.act2": [[108, 161], ["tuple", "numpy.array", "advisor3admiralae.Advisor3admiralae.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._djikstra": [[162, 228], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor3admiralae.Advisor3admiralae._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._directions_in_range_of_bomb": [[229, 271], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._find_safe_directions": [[272, 366], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor3admiralae.Advisor3admiralae.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._is_adjacent_enemy": [[367, 374], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._has_bomb": [[375, 378], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._maybe_bomb": [[379, 407], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._nearest_position": [[408, 421], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._get_direction_towards_position": [[422, 436], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._near_enemy": [[437, 443], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._near_good_powerup": [[444, 453], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._near_wood": [[454, 460], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._filter_invalid_directions": [[461, 471], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._filter_unsafe_directions": [[472, 488], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.Advisor3admiralae._filter_recently_visited": [[489, 501], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.make_np_float": [[28, 30], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralae.featurize": [[37, 60], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor3admiralae.make_np_float", "advisor3admiralae.make_np_float", "advisor3admiralae.make_np_float", "advisor3admiralae.make_np_float", "advisor3admiralae.make_np_float", "advisor3admiralae.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.__init__": [[65, 80], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor4admiralae", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "action_space", "=", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.act": [[85, 92], ["numpy.random.uniform", "advisor4admiralae.Advisor4admiralae.act2", "advisor4admiralae.featurize", "advisor4admiralae.Advisor4admiralae.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.store": [[94, 98], ["advisor4admiralae.featurize", "advisor4admiralae.featurize", "advisor4admiralae.Advisor4admiralae.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.learn": [[100, 102], ["advisor4admiralae.Advisor4admiralae.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.copy_network": [[103, 105], ["advisor4admiralae.Advisor4admiralae.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.save_model": [[106, 108], ["advisor4admiralae.Advisor4admiralae.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.Advisor4admiralae.act2": [[109, 111], ["action_space.sample"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "return", "action_space", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralae.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor4admiralae.make_np_float", "advisor4admiralae.make_np_float", "advisor4admiralae.make_np_float", "advisor4admiralae.make_np_float", "advisor4admiralae.make_np_float", "advisor4admiralae.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm2.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1admiraldm", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "eps", "=", "0.8", "\n", "self", ".", "execution", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.set": [[83, 85], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.executionenv": [[87, 89], ["None"], "methods", ["None"], ["", "def", "executionenv", "(", "self", ")", ":", "\n", "        ", "self", ".", "execution", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.linear_decay": [[90, 106], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.act": [[108, 114], ["numpy.random.uniform", "advisor1admiraldm.Advisor1admiraldm.act2", "advisor1admiraldm.featurize", "advisor1admiraldm.Advisor1admiraldm.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ",", "self", ".", "execution", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.store": [[115, 119], ["advisor1admiraldm.featurize", "advisor1admiraldm.featurize", "advisor1admiraldm.Advisor1admiraldm.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.learn": [[120, 127], ["advisor1admiraldm.Advisor1admiraldm.RL.learn", "advisor1admiraldm.Advisor1admiraldm.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "            ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.8", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.copy_network": [[129, 131], ["advisor1admiraldm.Advisor1admiraldm.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.save_model": [[132, 134], ["advisor1admiraldm.Advisor1admiraldm.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm.act2": [[135, 209], ["tuple", "numpy.array", "advisor1admiraldm.Advisor1admiraldm.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._djikstra": [[210, 276], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1admiraldm.Advisor1admiraldm._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._directions_in_range_of_bomb": [[277, 319], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._find_safe_directions": [[320, 414], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor1admiraldm.Advisor1admiraldm.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._is_adjacent_enemy": [[415, 422], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._has_bomb": [[423, 426], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._maybe_bomb": [[427, 455], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._nearest_position": [[456, 469], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._get_direction_towards_position": [[470, 484], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._near_enemy": [[485, 491], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._near_good_powerup": [[492, 501], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._near_wood": [[502, 508], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._filter_invalid_directions": [[509, 519], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._filter_unsafe_directions": [[520, 536], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.Advisor1admiraldm._filter_recently_visited": [[537, 549], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldm.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1admiraldm.make_np_float", "advisor1admiraldm.make_np_float", "advisor1admiraldm.make_np_float", "advisor1admiraldm.make_np_float", "advisor1admiraldm.make_np_float", "advisor1admiraldm.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.DQNAgent.__init__": [[62, 71], ["BaseAgent.__init__", "RL_brain_DQN.DeepQNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DQNAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "RL", "=", "DeepQNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ",", "model_path", "=", "False", ")", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "execution", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.DQNAgent.act": [[72, 75], ["dqn.featurize", "dqn.DQNAgent.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "execution", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.DQNAgent.executionenv": [[76, 78], ["None"], "methods", ["None"], ["", "def", "executionenv", "(", "self", ")", ":", "\n", "        ", "self", ".", "execution", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.DQNAgent.store": [[79, 83], ["dqn.featurize", "dqn.featurize", "dqn.DQNAgent.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "reward", ",", "obs_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "reward", ",", "obs_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.DQNAgent.learn": [[84, 86], ["dqn.DQNAgent.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.DQNAgent.copy_network": [[87, 89], ["dqn.DQNAgent.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.DQNAgent.save_model": [[90, 92], ["dqn.DQNAgent.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.make_np_float": [[24, 26], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqn.featurize": [[33, 56], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "dqn.make_np_float", "dqn.make_np_float", "dqn.make_np_float", "dqn.make_np_float", "dqn.make_np_float", "dqn.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm2.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1small", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "eps", "=", "0.9", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.linear_decay": [[86, 102], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.act": [[106, 132], ["numpy.random.uniform", "advisor1small.Advisor1small.act2", "advisor1small.featurize", "advisor1small.Advisor1small.RL.choose_action", "numpy.random.uniform", "advisor1small.Advisor1small.act2", "advisor1small.featurize", "advisor1small.Advisor1small.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.store": [[134, 138], ["advisor1small.featurize", "advisor1small.featurize", "advisor1small.Advisor1small.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.learn": [[139, 147], ["advisor1small.Advisor1small.RL.learn", "advisor1small.Advisor1small.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "            ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.9", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.copy_network": [[148, 150], ["advisor1small.Advisor1small.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.save_model": [[151, 153], ["advisor1small.Advisor1small.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small.act2": [[154, 228], ["tuple", "numpy.array", "advisor1small.Advisor1small.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._djikstra": [[229, 295], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1small.Advisor1small._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._directions_in_range_of_bomb": [[296, 338], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._find_safe_directions": [[339, 433], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor1small.Advisor1small.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._is_adjacent_enemy": [[434, 441], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._has_bomb": [[442, 445], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._maybe_bomb": [[446, 474], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._nearest_position": [[475, 488], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._get_direction_towards_position": [[489, 503], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._near_enemy": [[504, 510], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._near_good_powerup": [[511, 520], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._near_wood": [[521, 527], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._filter_invalid_directions": [[528, 538], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._filter_unsafe_directions": [[539, 555], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.Advisor1small._filter_recently_visited": [[556, 568], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1small.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1small.make_np_float", "advisor1small.make_np_float", "advisor1small.make_np_float", "advisor1small.make_np_float", "advisor1small.make_np_float", "advisor1small.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.random_agent.RandomAgent.act": [[8, 10], ["action_space.sample"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["def", "act", "(", "self", ",", "obs", ",", "action_space", "=", "6", ")", ":", "\n", "        ", "return", "action_space", ".", "sample", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.__init__": [[66, 81], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1admiralaeteamcomp", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.9", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action_space", "=", "6", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.act": [[82, 89], ["numpy.random.uniform", "advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.act2", "advisor1admiralaeteamcomp.featurize", "advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.store": [[91, 95], ["advisor1admiralaeteamcomp.featurize", "advisor1admiralaeteamcomp.featurize", "advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.learn": [[96, 98], ["advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.set": [[99, 101], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.copy_network": [[102, 104], ["advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.save_model": [[105, 107], ["advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.act2": [[108, 182], ["tuple", "numpy.array", "advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._djikstra": [[183, 249], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._directions_in_range_of_bomb": [[250, 292], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._find_safe_directions": [[293, 387], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._is_adjacent_enemy": [[388, 395], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._has_bomb": [[396, 399], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._maybe_bomb": [[400, 428], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._nearest_position": [[429, 442], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._get_direction_towards_position": [[443, 457], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._near_enemy": [[458, 464], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._near_good_powerup": [[465, 474], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._near_wood": [[475, 481], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._filter_invalid_directions": [[482, 492], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._filter_unsafe_directions": [[493, 509], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.Advisor1admiralaeteamcomp._filter_recently_visited": [[510, 522], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.make_np_float": [[28, 30], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeteamcomp.featurize": [[37, 60], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1admiralaeteamcomp.make_np_float", "advisor1admiralaeteamcomp.make_np_float", "advisor1admiralaeteamcomp.make_np_float", "advisor1admiralaeteamcomp.make_np_float", "advisor1admiralaeteamcomp.make_np_float", "advisor1admiralaeteamcomp.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.__init__": [[65, 80], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor4admiralaeteamcomp", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "action_space", "=", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.act": [[85, 92], ["numpy.random.uniform", "advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.act2", "advisor4admiralaeteamcomp.featurize", "advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.store": [[94, 98], ["advisor4admiralaeteamcomp.featurize", "advisor4admiralaeteamcomp.featurize", "advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.learn": [[100, 102], ["advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.copy_network": [[103, 105], ["advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.save_model": [[106, 108], ["advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.Advisor4admiralaeteamcomp.act2": [[109, 111], ["action_space.sample"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "return", "action_space", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4admiralaeteamcomp.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor4admiralaeteamcomp.make_np_float", "advisor4admiralaeteamcomp.make_np_float", "advisor4admiralaeteamcomp.make_np_float", "advisor4admiralaeteamcomp.make_np_float", "advisor4admiralaeteamcomp.make_np_float", "advisor4admiralaeteamcomp.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.__init__": [[65, 80], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor2admiralae", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "action_space", "=", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.set": [[81, 83], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.act": [[85, 93], ["numpy.random.uniform", "advisor2admiralae.Advisor2admiralae.act2", "advisor2admiralae.featurize", "advisor2admiralae.Advisor2admiralae.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.store": [[95, 99], ["advisor2admiralae.featurize", "advisor2admiralae.featurize", "advisor2admiralae.Advisor2admiralae.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.learn": [[100, 102], ["advisor2admiralae.Advisor2admiralae.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.copy_network": [[103, 105], ["advisor2admiralae.Advisor2admiralae.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.save_model": [[106, 108], ["advisor2admiralae.Advisor2admiralae.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae.act2": [[109, 168], ["tuple", "numpy.array", "advisor2admiralae.Advisor2admiralae.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._djikstra": [[169, 235], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor2admiralae.Advisor2admiralae._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._directions_in_range_of_bomb": [[236, 278], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._find_safe_directions": [[279, 373], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor2admiralae.Advisor2admiralae.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._is_adjacent_enemy": [[374, 381], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._has_bomb": [[382, 385], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._maybe_bomb": [[386, 414], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._nearest_position": [[415, 428], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._get_direction_towards_position": [[429, 443], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._near_enemy": [[444, 450], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._near_good_powerup": [[451, 460], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._near_wood": [[461, 467], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._filter_invalid_directions": [[468, 478], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._filter_unsafe_directions": [[479, 495], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.Advisor2admiralae._filter_recently_visited": [[496, 508], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralae.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor2admiralae.make_np_float", "advisor2admiralae.make_np_float", "advisor2admiralae.make_np_float", "advisor2admiralae.make_np_float", "advisor2admiralae.make_np_float", "advisor2admiralae.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.__init__": [[9, 11], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "character", "=", "characters", ".", "Bomber", ")", ":", "\n", "        ", "self", ".", "_character", "=", "character", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.__getattr__": [[12, 14], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "_character", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.act": [[15, 17], ["NotImplementedError"], "methods", ["None"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.episode_end": [[18, 26], ["None"], "methods", ["None"], ["", "def", "episode_end", "(", "self", ",", "reward", ")", ":", "\n", "        ", "\"\"\"This is called at the end of the episode to let the agent know that\n        the episode has ended and what is the reward.\n\n        Args:\n          reward: The single reward scalar to this agent.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.init_agent": [[27, 29], ["base_agent.BaseAgent._character"], "methods", ["None"], ["", "def", "init_agent", "(", "self", ",", "id_", ",", "game_type", ")", ":", "\n", "        ", "self", ".", "_character", "=", "self", ".", "_character", "(", "id_", ",", "game_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.has_user_input": [[30, 33], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "has_user_input", "(", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.shutdown": [[34, 36], ["None"], "methods", ["None"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac.__init__": [[65, 77], ["BaseAgent.__init__", "RL_brain_admiraldmac.Actor", "RL_brain_admiraldmac.Critic"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_f", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1admiraldmac", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "\n", "self", ".", "actor", "=", "Actor", "(", "sess", ",", "n_features", "=", "n_f", ",", "n_actions", "=", "6", ",", "lr", "=", "0.00001", ")", "\n", "self", ".", "critic", "=", "Critic", "(", "sess", ",", "n_features", "=", "n_f", ",", "lr", "=", "0.001", ")", "\n", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "eps", "=", "0.8", "\n", "self", ".", "execution", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac.executionenv": [[78, 80], ["None"], "methods", ["None"], ["", "def", "executionenv", "(", "self", ")", ":", "\n", "        ", "self", ".", "execution", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac.linear_decay": [[82, 98], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac.act": [[102, 108], ["numpy.random.uniform", "advisor1admiraldmac.Advisor1admiraldmac.act2", "advisor1admiraldmac.featurize", "advisor1admiraldmac.Advisor1admiraldmac.actor.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "actor", ".", "choose_action", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac.learn": [[111, 123], ["advisor1admiraldmac.featurize", "advisor1admiraldmac.featurize", "advisor1admiraldmac.Advisor1admiraldmac.critic.learn", "advisor1admiraldmac.Advisor1admiraldmac.actor.learn", "advisor1admiraldmac.Advisor1admiraldmac.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "", "def", "learn", "(", "self", ",", "obs", ",", "act", ",", "act2", ",", "reward", ",", "obs_", ",", "act2_", ",", "done", ")", ":", "\n", "        ", "if", "done", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "            ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.8", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eps", "=", "0", "\n", "\n", "", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "td_error", "=", "self", ".", "critic", ".", "learn", "(", "obs", ",", "act2", ",", "reward", ",", "obs_", ",", "act2_", ")", "\n", "self", ".", "actor", ".", "learn", "(", "obs", ",", "act", ",", "td_error", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac.act2": [[126, 200], ["tuple", "numpy.array", "advisor1admiraldmac.Advisor1admiraldmac.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._djikstra": [[201, 267], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1admiraldmac.Advisor1admiraldmac._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._directions_in_range_of_bomb": [[268, 310], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._find_safe_directions": [[311, 405], ["queue.PriorityQueue", "queue.PriorityQueue.put", "set", "len", "board.copy", "unsafe_directions.items", "utility.get_direction", "queue.PriorityQueue.empty", "queue.PriorityQueue.get", "set.add", "utility.get_next_position", "utility.position_on_board", "disallowed.append", "utility.position_is_passable", "utility.position_is_fog", "safe.append", "queue.PriorityQueue.put", "advisor1admiraldmac.Advisor1admiraldmac._find_safe_directions.is_stuck_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_fog"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._is_adjacent_enemy": [[406, 413], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._has_bomb": [[414, 417], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._maybe_bomb": [[418, 446], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._nearest_position": [[447, 460], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._get_direction_towards_position": [[461, 475], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._near_enemy": [[476, 482], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._near_good_powerup": [[483, 492], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._near_wood": [[493, 499], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._filter_invalid_directions": [[500, 510], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._filter_unsafe_directions": [[511, 527], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.Advisor1admiraldmac._filter_recently_visited": [[528, 540], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiraldmac.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1admiraldmac.make_np_float", "advisor1admiraldmac.make_np_float", "advisor1admiraldmac.make_np_float", "advisor1admiraldmac.make_np_float", "advisor1admiraldmac.make_np_float", "advisor1admiraldmac.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.__init__": [[65, 80], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor2admiralaeteamcomp", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "action_space", "=", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.set": [[81, 83], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.act": [[85, 93], ["numpy.random.uniform", "advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.act2", "advisor2admiralaeteamcomp.featurize", "advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.store": [[95, 99], ["advisor2admiralaeteamcomp.featurize", "advisor2admiralaeteamcomp.featurize", "advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.learn": [[100, 102], ["advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.copy_network": [[103, 105], ["advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.save_model": [[106, 108], ["advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.act2": [[109, 168], ["tuple", "numpy.array", "advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._djikstra": [[169, 235], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._directions_in_range_of_bomb": [[236, 278], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._find_safe_directions": [[279, 373], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._is_adjacent_enemy": [[374, 381], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._has_bomb": [[382, 385], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._maybe_bomb": [[386, 414], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._nearest_position": [[415, 428], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._get_direction_towards_position": [[429, 443], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._near_enemy": [[444, 450], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._near_good_powerup": [[451, 460], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._near_wood": [[461, 467], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._filter_invalid_directions": [[468, 478], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._filter_unsafe_directions": [[479, 495], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.Advisor2admiralaeteamcomp._filter_recently_visited": [[496, 508], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2admiralaeteamcomp.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor2admiralaeteamcomp.make_np_float", "advisor2admiralaeteamcomp.make_np_float", "advisor2admiralaeteamcomp.make_np_float", "advisor2admiralaeteamcomp.make_np_float", "advisor2admiralaeteamcomp.make_np_float", "advisor2admiralaeteamcomp.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor4", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.7", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "eps", "=", "0", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.set": [[85, 87], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.linear_decay": [[90, 106], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.act": [[110, 138], ["numpy.random.uniform", "advisor4.Advisor4.act2", "advisor4.featurize", "advisor4.Advisor4.RL.choose_action", "numpy.random.uniform", "advisor4.Advisor4.act2", "advisor4.featurize", "advisor4.Advisor4.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "\n", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.store": [[141, 145], ["advisor4.featurize", "advisor4.featurize", "advisor4.Advisor4.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.learn": [[146, 151], ["advisor4.Advisor4.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.copy_network": [[152, 154], ["advisor4.Advisor4.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.save_model": [[155, 157], ["advisor4.Advisor4.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.Advisor4.act2": [[158, 160], ["action_space.sample"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "return", "action_space", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor4.make_np_float", "advisor4.make_np_float", "advisor4.make_np_float", "advisor4.make_np_float", "advisor4.make_np_float", "advisor4.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm2.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor4small", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "eps", "=", "0", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.linear_decay": [[86, 102], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.act": [[105, 133], ["numpy.random.uniform", "advisor4small.Advisor4small.act2", "advisor4small.featurize", "advisor4small.Advisor4small.RL.choose_action", "numpy.random.uniform", "advisor4small.Advisor4small.act2", "advisor4small.featurize", "advisor4small.Advisor4small.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "\n", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.store": [[136, 140], ["advisor4small.featurize", "advisor4small.featurize", "advisor4small.Advisor4small.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.learn": [[141, 146], ["advisor4small.Advisor4small.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.copy_network": [[147, 149], ["advisor4small.Advisor4small.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.save_model": [[150, 152], ["advisor4small.Advisor4small.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.Advisor4small.act2": [[153, 155], ["action_space.sample"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "return", "action_space", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor4small.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor4small.make_np_float", "advisor4small.make_np_float", "advisor4small.make_np_float", "advisor4small.make_np_float", "advisor4small.make_np_float", "advisor4small.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.__init__": [[66, 83], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1admiralaeadaptive", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.9", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action_space", "=", "6", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "bombactioncount", "=", "0", "\n", "self", ".", "steps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.act": [[84, 91], ["numpy.random.uniform", "advisor1admiralaeadaptive.Advisor1admiralaeadaptive.act2", "advisor1admiralaeadaptive.featurize", "advisor1admiralaeadaptive.Advisor1admiralaeadaptive.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.bombactionpercent": [[92, 95], ["None"], "methods", ["None"], ["", "", "def", "bombactionpercent", "(", "self", ")", ":", "\n", "        ", "percent", "=", "(", "self", ".", "bombactioncount", "/", "self", ".", "steps", ")", "*", "100", "\n", "return", "percent", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.store": [[96, 103], ["advisor1admiralaeadaptive.featurize", "advisor1admiralaeadaptive.featurize", "advisor1admiralaeadaptive.Advisor1admiralaeadaptive.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "if", "act_other", "==", "5", ":", "\n", "            ", "self", ".", "bombactioncount", "=", "self", ".", "bombactioncount", "+", "1", "\n", "", "self", ".", "steps", "=", "self", ".", "steps", "+", "1", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.learn": [[104, 108], ["advisor1admiralaeadaptive.Advisor1admiralaeadaptive.RL.learn", "advisor1admiralaeadaptive.Advisor1admiralaeadaptive.bombactionpercent"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.bombactionpercent"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "percent", "=", "self", ".", "bombactionpercent", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.set": [[110, 112], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.copy_network": [[113, 115], ["advisor1admiralaeadaptive.Advisor1admiralaeadaptive.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.save_model": [[116, 118], ["advisor1admiralaeadaptive.Advisor1admiralaeadaptive.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive.act2": [[119, 229], ["action_space.sample", "tuple", "numpy.array", "advisor1admiralaeadaptive.Advisor1admiralaeadaptive.act2.convert_bombs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "self", ".", "counter", "<", "5000", ":", "\n", "            ", "return", "action_space", ".", "sample", "(", ")", "\n", "", "else", ":", "\n", "            ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "                ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                    ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "\n", "if", "self", ".", "bombactionpercent", "(", ")", ">", "5", ":", "# Risk averse ", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "                ", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "                    ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "                    ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "                    ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "\n", "\n", "\n", "", "else", ":", "# Risk seeking ", "\n", "\n", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "                ", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "                    ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "                    ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "                    ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "                    ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._djikstra": [[231, 297], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1admiralaeadaptive.Advisor1admiralaeadaptive._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "", "", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._directions_in_range_of_bomb": [[298, 340], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._find_safe_directions": [[341, 435], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor1admiralaeadaptive.Advisor1admiralaeadaptive.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._is_adjacent_enemy": [[436, 443], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._has_bomb": [[444, 447], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._maybe_bomb": [[448, 476], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._nearest_position": [[477, 490], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._get_direction_towards_position": [[491, 505], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._near_enemy": [[506, 512], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._near_good_powerup": [[513, 522], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._near_wood": [[523, 529], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._filter_invalid_directions": [[530, 540], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._filter_unsafe_directions": [[541, 557], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.Advisor1admiralaeadaptive._filter_recently_visited": [[558, 570], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.make_np_float": [[28, 30], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaeadaptive.featurize": [[37, 60], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1admiralaeadaptive.make_np_float", "advisor1admiralaeadaptive.make_np_float", "advisor1admiralaeadaptive.make_np_float", "advisor1admiralaeadaptive.make_np_float", "advisor1admiralaeadaptive.make_np_float", "advisor1admiralaeadaptive.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.__init__": [[66, 81], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1admiralae", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.9", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action_space", "=", "6", "\n", "self", ".", "action2", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.act": [[82, 89], ["numpy.random.uniform", "advisor1admiralae.Advisor1admiralae.act2", "advisor1admiralae.featurize", "advisor1admiralae.Advisor1admiralae.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.store": [[91, 95], ["advisor1admiralae.featurize", "advisor1admiralae.featurize", "advisor1admiralae.Advisor1admiralae.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.learn": [[96, 98], ["advisor1admiralae.Advisor1admiralae.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.set": [[99, 101], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.copy_network": [[102, 104], ["advisor1admiralae.Advisor1admiralae.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.save_model": [[105, 107], ["advisor1admiralae.Advisor1admiralae.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae.act2": [[108, 182], ["tuple", "numpy.array", "advisor1admiralae.Advisor1admiralae.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._djikstra": [[183, 249], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1admiralae.Advisor1admiralae._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._directions_in_range_of_bomb": [[250, 292], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._find_safe_directions": [[293, 387], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor1admiralae.Advisor1admiralae.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._is_adjacent_enemy": [[388, 395], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._has_bomb": [[396, 399], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._maybe_bomb": [[400, 428], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._nearest_position": [[429, 442], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._get_direction_towards_position": [[443, 457], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._near_enemy": [[458, 464], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._near_good_powerup": [[465, 474], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._near_wood": [[475, 481], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._filter_invalid_directions": [[482, 492], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._filter_unsafe_directions": [[493, 509], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.Advisor1admiralae._filter_recently_visited": [[510, 522], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.make_np_float": [[28, 30], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralae.featurize": [[37, 60], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1admiralae.make_np_float", "advisor1admiralae.make_np_float", "advisor1admiralae.make_np_float", "advisor1admiralae.make_np_float", "advisor1admiralae.make_np_float", "advisor1admiralae.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor2", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.9", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "eps", "=", "0.7", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.set": [[83, 85], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.linear_decay": [[89, 105], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.act": [[112, 137], ["numpy.random.uniform", "advisor2.Advisor2.act2", "advisor2.featurize", "advisor2.Advisor2.RL.choose_action", "numpy.random.uniform", "advisor2.Advisor2.act2", "advisor2.featurize", "advisor2.Advisor2.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.store": [[141, 145], ["advisor2.featurize", "advisor2.featurize", "advisor2.Advisor2.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.learn": [[146, 154], ["advisor2.Advisor2.RL.learn", "advisor2.Advisor2.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "            ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.9", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.copy_network": [[155, 157], ["advisor2.Advisor2.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.save_model": [[158, 160], ["advisor2.Advisor2.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2.act2": [[161, 220], ["tuple", "numpy.array", "advisor2.Advisor2.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._djikstra": [[221, 287], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor2.Advisor2._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._directions_in_range_of_bomb": [[288, 330], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._find_safe_directions": [[331, 425], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor2.Advisor2.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._is_adjacent_enemy": [[426, 433], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._has_bomb": [[434, 437], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._maybe_bomb": [[438, 466], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._nearest_position": [[467, 480], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._get_direction_towards_position": [[481, 495], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._near_enemy": [[496, 502], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._near_good_powerup": [[503, 512], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._near_wood": [[513, 519], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._filter_invalid_directions": [[520, 530], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._filter_unsafe_directions": [[531, 547], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.Advisor2._filter_recently_visited": [[548, 560], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor2.make_np_float", "advisor2.make_np_float", "advisor2.make_np_float", "advisor2.make_np_float", "advisor2.make_np_float", "advisor2.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.__init__": [[66, 81], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor3admiralaeteamcomp", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "action_space", "=", "6", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.act": [[85, 92], ["numpy.random.uniform", "advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.act2", "advisor3admiralaeteamcomp.featurize", "advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.store": [[93, 97], ["advisor3admiralaeteamcomp.featurize", "advisor3admiralaeteamcomp.featurize", "advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.learn": [[98, 100], ["advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.copy_network": [[101, 103], ["advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.save_model": [[104, 106], ["advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.act2": [[107, 160], ["tuple", "numpy.array", "advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._djikstra": [[161, 227], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._directions_in_range_of_bomb": [[228, 270], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._find_safe_directions": [[271, 365], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._is_adjacent_enemy": [[366, 373], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._has_bomb": [[374, 377], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._maybe_bomb": [[378, 406], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._nearest_position": [[407, 420], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._get_direction_towards_position": [[421, 435], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._near_enemy": [[436, 442], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._near_good_powerup": [[443, 452], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._near_wood": [[453, 459], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._filter_invalid_directions": [[460, 470], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._filter_unsafe_directions": [[471, 487], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.Advisor3admiralaeteamcomp._filter_recently_visited": [[488, 500], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3admiralaeteamcomp.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor3admiralaeteamcomp.make_np_float", "advisor3admiralaeteamcomp.make_np_float", "advisor3admiralaeteamcomp.make_np_float", "advisor3admiralaeteamcomp.make_np_float", "advisor3admiralaeteamcomp.make_np_float", "advisor3admiralaeteamcomp.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.DeepsarsaAgent.__init__": [[62, 70], ["BaseAgent.__init__", "RL_brain_Deepsarsa.DeepSarsa"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeepsarsaAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "RL", "=", "DeepSarsa", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ",", "model_path", "=", "False", ")", "\n", "self", ".", "action2", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.DeepsarsaAgent.act": [[72, 75], ["deepsarsa.featurize", "deepsarsa.DeepsarsaAgent.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.DeepsarsaAgent.store": [[76, 80], ["deepsarsa.featurize", "deepsarsa.featurize", "deepsarsa.DeepsarsaAgent.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.DeepsarsaAgent.learn": [[81, 83], ["deepsarsa.DeepsarsaAgent.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.DeepsarsaAgent.copy_network": [[84, 86], ["deepsarsa.DeepsarsaAgent.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.DeepsarsaAgent.save_model": [[87, 89], ["deepsarsa.DeepsarsaAgent.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.make_np_float": [[24, 26], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.deepsarsa.featurize": [[33, 56], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "deepsarsa.make_np_float", "deepsarsa.make_np_float", "deepsarsa.make_np_float", "deepsarsa.make_np_float", "deepsarsa.make_np_float", "deepsarsa.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.__init__": [[66, 82], ["BaseAgent.__init__", "RL_brain_admiraldm2.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor3small", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "eps", "=", "0.3", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.set": [[85, 87], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.linear_decay": [[89, 105], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.act": [[106, 135], ["numpy.random.uniform", "advisor3small.Advisor3small.act2", "advisor3small.featurize", "advisor3small.Advisor3small.RL.choose_action", "numpy.random.uniform", "advisor3small.Advisor3small.act2", "advisor3small.featurize", "advisor3small.Advisor3small.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "\n", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.store": [[138, 142], ["advisor3small.featurize", "advisor3small.featurize", "advisor3small.Advisor3small.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.learn": [[143, 152], ["advisor3small.Advisor3small.RL.learn", "advisor3small.Advisor3small.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "            ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.9", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.copy_network": [[153, 155], ["advisor3small.Advisor3small.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.save_model": [[156, 158], ["advisor3small.Advisor3small.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small.act2": [[159, 212], ["tuple", "numpy.array", "advisor3small.Advisor3small.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._djikstra": [[213, 279], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor3small.Advisor3small._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._directions_in_range_of_bomb": [[280, 322], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._find_safe_directions": [[323, 417], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor3small.Advisor3small.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._is_adjacent_enemy": [[418, 425], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._has_bomb": [[426, 429], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._maybe_bomb": [[430, 458], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._nearest_position": [[459, 472], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._get_direction_towards_position": [[473, 487], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._near_enemy": [[488, 494], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._near_good_powerup": [[495, 504], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._near_wood": [[505, 511], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._filter_invalid_directions": [[512, 522], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._filter_unsafe_directions": [[523, 539], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.Advisor3small._filter_recently_visited": [[540, 552], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3small.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor3small.make_np_float", "advisor3small.make_np_float", "advisor3small.make_np_float", "advisor3small.make_np_float", "advisor3small.make_np_float", "advisor3small.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.DQfDAgent.__init__": [[49, 67], ["BaseAgent.__init__", "dqfd.DQfDAgent.agent.pre_train", "collections.deque", "open", "pickle.load", "collections.deque", "tensorflow.variable_scope", "DQfD_V3.DQfD", "itertools.islice", "len", "Config.Config.DQfDConfig", "str"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.pre_train"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DQfDAgent", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "with", "open", "(", "Config", ".", "DEMO_DATA_PATH", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "self", ".", "demo_transitions", "=", "pickle", ".", "load", "(", "f", ")", "\n", "self", ".", "demo_transitions", "=", "deque", "(", "itertools", ".", "islice", "(", "self", ".", "demo_transitions", ",", "0", ",", "Config", ".", "demo_buffer_size", ")", ")", "\n", "assert", "len", "(", "self", ".", "demo_transitions", ")", "==", "Config", ".", "demo_buffer_size", "\n", "", "index", "=", "1", "\n", "with", "tf", ".", "variable_scope", "(", "'DQfD_'", "+", "str", "(", "index", ")", ")", ":", "\n", "            ", "self", ".", "agent", "=", "DQfD", "(", "sess", ",", "nf", ",", "6", ",", "DQfDConfig", "(", ")", ",", "demo_transitions", "=", "self", ".", "demo_transitions", ")", "\n", "\n", "", "self", ".", "agent", ".", "pre_train", "(", ")", "# use the demo data to pre-train network", "\n", "self", ".", "scores", "=", "[", "]", "\n", "self", ".", "e", "=", "0", "\n", "self", ".", "replay_full_episode", "=", "None", "\n", "self", ".", "score", "=", "0", "\n", "self", ".", "n_step_reward", "=", "None", "\n", "self", ".", "t_q", "=", "deque", "(", "maxlen", "=", "Config", ".", "trajectory_n", ")", "\n", "self", ".", "execution", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.DQfDAgent.executionenv": [[69, 71], ["None"], "methods", ["None"], ["", "def", "executionenv", "(", "self", ")", ":", "\n", "        ", "self", ".", "execution", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.DQfDAgent.act": [[72, 76], ["dqfd.featurize", "dqfd.DQfDAgent.agent.egreedy_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.egreedy_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", "=", "6", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "action", "=", "self", ".", "agent", ".", "egreedy_action", "(", "obs", ",", "self", ".", "execution", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.DQfDAgent.restorevalue": [[77, 82], ["collections.deque"], "methods", ["None"], ["", "def", "restorevalue", "(", "self", ")", ":", "\n", "        ", "self", ".", "score", "=", "0", "\n", "self", ".", "n_step_reward", "=", "None", "\n", "self", ".", "t_q", "=", "deque", "(", "maxlen", "=", "Config", ".", "trajectory_n", ")", "\n", "self", ".", "e", "=", "self", ".", "e", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.DQfDAgent.set_n_step": [[84, 95], ["list", "sum", "range", "len", "min", "t_list[].extend", "enumerate", "len", "min", "len"], "methods", ["None"], ["", "def", "set_n_step", "(", "self", ",", "container", ",", "n", ")", ":", "\n", "        ", "t_list", "=", "list", "(", "container", ")", "\n", "# accumulated reward of first (trajectory_n-1) transitions", "\n", "n_step_reward", "=", "sum", "(", "[", "t", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "i", "for", "i", ",", "t", "in", "enumerate", "(", "t_list", "[", "0", ":", "min", "(", "len", "(", "t_list", ")", ",", "n", ")", "-", "1", "]", ")", "]", ")", "\n", "for", "begin", "in", "range", "(", "len", "(", "t_list", ")", ")", ":", "\n", "            ", "end", "=", "min", "(", "len", "(", "t_list", ")", "-", "1", ",", "begin", "+", "Config", ".", "trajectory_n", "-", "1", ")", "\n", "n_step_reward", "+=", "t_list", "[", "end", "]", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "(", "end", "-", "begin", ")", "\n", "# extend[n_reward, n_next_s, n_done, actual_n]", "\n", "t_list", "[", "begin", "]", ".", "extend", "(", "[", "n_step_reward", ",", "t_list", "[", "end", "]", "[", "3", "]", ",", "t_list", "[", "end", "]", "[", "4", "]", ",", "end", "-", "begin", "+", "1", "]", ")", "\n", "n_step_reward", "=", "(", "n_step_reward", "-", "t_list", "[", "begin", "]", "[", "2", "]", ")", "/", "Config", ".", "GAMMA", "\n", "", "return", "t_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.DQfDAgent.run_DQfD": [[98, 128], ["dqfd.featurize", "dqfd.featurize", "dqfd.DQfDAgent.t_q.append", "dqfd.DQfDAgent.t_q.popleft", "dqfd.DQfDAgent.set_n_step", "dqfd.DQfDAgent.agent.replay_memory.full", "len", "dqfd.DQfDAgent.t_q[].extend", "dqfd.DQfDAgent.agent.perceive", "dqfd.DQfDAgent.agent.replay_memory.full", "dqfd.DQfDAgent.agent.perceive", "dqfd.DQfDAgent.agent.replay_memory.full", "dqfd.DQfDAgent.scores.append", "dqfd.DQfDAgent.agent.sess.run", "len", "sum", "dqfd.DQfDAgent.agent.train_Q_network", "dqfd.DQfDAgent.agent.train_Q_network", "enumerate"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.perceive", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.perceive", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network"], ["", "def", "run_DQfD", "(", "self", ",", "state", ",", "action", ",", "reward", ",", "next_state", ",", "done", ")", ":", "\n", "        ", "state", "=", "featurize", "(", "state", ")", "\n", "next_state", "=", "featurize", "(", "next_state", ")", "\n", "if", "done", "is", "False", ":", "\n", "            ", "self", ".", "score", "+=", "reward", "\n", "reward_to_sub", "=", "0.", "if", "len", "(", "self", ".", "t_q", ")", "<", "self", ".", "t_q", ".", "maxlen", "else", "self", ".", "t_q", "[", "0", "]", "[", "2", "]", "# record the earliest reward for the sub", "\n", "self", ".", "t_q", ".", "append", "(", "[", "state", ",", "action", ",", "reward", ",", "next_state", ",", "done", ",", "0.0", "]", ")", "\n", "if", "len", "(", "self", ".", "t_q", ")", "==", "self", ".", "t_q", ".", "maxlen", ":", "\n", "                ", "if", "self", ".", "n_step_reward", "is", "None", ":", "# only compute once when t_q first filled", "\n", "                    ", "self", ".", "n_step_reward", "=", "sum", "(", "[", "t", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "t_q", ")", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "n_step_reward", "=", "(", "self", ".", "n_step_reward", "-", "reward_to_sub", ")", "/", "Config", ".", "GAMMA", "\n", "self", ".", "n_step_reward", "+=", "reward", "*", "Config", ".", "GAMMA", "**", "(", "Config", ".", "trajectory_n", "-", "1", ")", "\n", "", "self", ".", "t_q", "[", "0", "]", ".", "extend", "(", "[", "self", ".", "n_step_reward", ",", "next_state", ",", "done", ",", "self", ".", "t_q", ".", "maxlen", "]", ")", "# actual_n is max_len here", "\n", "self", ".", "agent", ".", "perceive", "(", "self", ".", "t_q", "[", "0", "]", ")", "# perceive when a transition is completed", "\n", "if", "self", ".", "agent", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "                    ", "self", ".", "agent", ".", "train_Q_network", "(", ")", "# train along with generation", "\n", "self", ".", "replay_full_episode", "=", "self", ".", "replay_full_episode", "or", "self", ".", "e", "\n", "", "", "", "if", "done", ":", "\n", "# handle transitions left in t_q", "\n", "            ", "self", ".", "t_q", ".", "popleft", "(", ")", "# first transition's n-step is already set", "\n", "transitions", "=", "self", ".", "set_n_step", "(", "self", ".", "t_q", ",", "Config", ".", "trajectory_n", ")", "\n", "for", "t", "in", "transitions", ":", "\n", "                ", "self", ".", "agent", ".", "perceive", "(", "t", ")", "\n", "if", "self", ".", "agent", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "                    ", "self", ".", "agent", ".", "train_Q_network", "(", ")", "\n", "self", ".", "replay_full_episode", "=", "self", ".", "replay_full_episode", "or", "self", ".", "e", "\n", "", "", "if", "self", ".", "agent", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "                ", "self", ".", "scores", ".", "append", "(", "self", ".", "score", ")", "\n", "self", ".", "agent", ".", "sess", ".", "run", "(", "self", ".", "agent", ".", "update_target_net", ")", "\n", "# if np.mean(scores[-min(10, len(scores)):]) > 495:", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.make_np_float": [[19, 21], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.dqfd.featurize": [[22, 45], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "dqfd.make_np_float", "dqfd.make_np_float", "dqfd.make_np_float", "dqfd.make_np_float", "dqfd.make_np_float", "dqfd.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.__init__": [[66, 81], ["BaseAgent.__init__", "RL_brain_admiralae.AdmiralaeNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1admiralaenonadaptive", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.9", "\n", "self", ".", "RL", "=", "AdmiralaeNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action_space", "=", "6", "\n", "self", ".", "action2", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.act": [[82, 89], ["numpy.random.uniform", "advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.act2", "advisor1admiralaenonadaptive.featurize", "advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ")", ":", "\n", "            ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "\n", "", "else", ":", "\n", "            ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.store": [[91, 95], ["advisor1admiralaenonadaptive.featurize", "advisor1admiralaenonadaptive.featurize", "advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "reward", ",", "obs_", ",", "act_", ",", "act_other_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.learn": [[96, 98], ["advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.RL.learn"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.set": [[99, 101], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.copy_network": [[102, 104], ["advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.save_model": [[105, 107], ["advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.act2": [[108, 167], ["tuple", "numpy.array", "advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._djikstra": [[168, 234], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._directions_in_range_of_bomb": [[235, 277], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._find_safe_directions": [[278, 372], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._is_adjacent_enemy": [[373, 380], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._has_bomb": [[381, 384], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._maybe_bomb": [[385, 413], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._nearest_position": [[414, 427], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._get_direction_towards_position": [[428, 442], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._near_enemy": [[443, 449], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._near_good_powerup": [[450, 459], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._near_wood": [[460, 466], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._filter_invalid_directions": [[467, 477], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._filter_unsafe_directions": [[478, 494], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.Advisor1admiralaenonadaptive._filter_recently_visited": [[495, 507], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.make_np_float": [[28, 30], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1admiralaenonadaptive.featurize": [[37, 60], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1admiralaenonadaptive.make_np_float", "advisor1admiralaenonadaptive.make_np_float", "advisor1admiralaenonadaptive.make_np_float", "advisor1admiralaenonadaptive.make_np_float", "advisor1admiralaenonadaptive.make_np_float", "advisor1admiralaenonadaptive.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm2.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor2small", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.5", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "0", "\n", "self", ".", "eps", "=", "0.7", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.linear_decay": [[85, 101], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.act": [[104, 129], ["numpy.random.uniform", "advisor2small.Advisor2small.act2", "advisor2small.featurize", "advisor2small.Advisor2small.RL.choose_action", "numpy.random.uniform", "advisor2small.Advisor2small.act2", "advisor2small.featurize", "advisor2small.Advisor2small.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.store": [[132, 136], ["advisor2small.featurize", "advisor2small.featurize", "advisor2small.Advisor2small.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.learn": [[137, 145], ["advisor2small.Advisor2small.RL.learn", "advisor2small.Advisor2small.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "            ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.9", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.copy_network": [[146, 148], ["advisor2small.Advisor2small.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.save_model": [[149, 151], ["advisor2small.Advisor2small.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small.act2": [[152, 211], ["tuple", "numpy.array", "advisor2small.Advisor2small.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._djikstra": [[212, 278], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor2small.Advisor2small._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._directions_in_range_of_bomb": [[279, 321], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._find_safe_directions": [[322, 416], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor2small.Advisor2small.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._is_adjacent_enemy": [[417, 424], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._has_bomb": [[425, 428], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._maybe_bomb": [[429, 457], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._nearest_position": [[458, 471], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._get_direction_towards_position": [[472, 486], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._near_enemy": [[487, 493], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._near_good_powerup": [[494, 503], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._near_wood": [[504, 510], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._filter_invalid_directions": [[511, 521], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._filter_unsafe_directions": [[522, 538], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.Advisor2small._filter_recently_visited": [[539, 551], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor2small.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor2small.make_np_float", "advisor2small.make_np_float", "advisor2small.make_np_float", "advisor2small.make_np_float", "advisor2small.make_np_float", "advisor2small.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor3", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.7", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "eps", "=", "0.3", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.linear_decay": [[87, 103], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.act": [[108, 137], ["numpy.random.uniform", "advisor3.Advisor3.act2", "advisor3.featurize", "advisor3.Advisor3.RL.choose_action", "numpy.random.uniform", "advisor3.Advisor3.act2", "advisor3.featurize", "advisor3.Advisor3.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "\n", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.store": [[139, 143], ["advisor3.featurize", "advisor3.featurize", "advisor3.Advisor3.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.learn": [[145, 154], ["advisor3.Advisor3.RL.learn", "advisor3.Advisor3.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "learn", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "            ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.9", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eps", "=", "0", "\n", "", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.copy_network": [[154, 156], ["advisor3.Advisor3.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.save_model": [[157, 159], ["advisor3.Advisor3.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3.act2": [[160, 213], ["tuple", "numpy.array", "advisor3.Advisor3.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._djikstra": [[214, 280], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor3.Advisor3._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._directions_in_range_of_bomb": [[281, 323], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._find_safe_directions": [[324, 418], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor3.Advisor3.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._is_adjacent_enemy": [[419, 426], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._has_bomb": [[427, 430], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._maybe_bomb": [[431, 459], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._nearest_position": [[460, 473], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._get_direction_towards_position": [[474, 488], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._near_enemy": [[489, 495], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._near_good_powerup": [[496, 505], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._near_wood": [[506, 512], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._filter_invalid_directions": [[513, 523], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._filter_unsafe_directions": [[524, 540], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.Advisor3._filter_recently_visited": [[541, 553], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor3.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor3.make_np_float", "advisor3.make_np_float", "advisor3.make_np_float", "advisor3.make_np_float", "advisor3.make_np_float", "advisor3.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.__init__": [[65, 81], ["BaseAgent.__init__", "RL_brain_admiraldm.AdmiralDMNetwork"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "epsilon_arbitrary", ",", "sess", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Advisor1", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_recently_visited_positions", "=", "[", "]", "\n", "self", ".", "_recently_visited_length", "=", "6", "\n", "self", ".", "_prev_direction", "=", "None", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "epsilon", "=", "0.3", "\n", "self", ".", "RL", "=", "AdmiralDMNetwork", "(", "sess", ",", "6", ",", "nf", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "memory_size", "=", "2000000", ")", "\n", "\n", "self", ".", "action2", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "eps", "=", "0.9", "\n", "self", ".", "epsilon_arbitrary", "=", "epsilon_arbitrary", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set": [[82, 84], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "action2", ")", ":", "\n", "        ", "self", ".", "action2", "=", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.linear_decay": [[87, 103], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act": [[108, 134], ["numpy.random.uniform", "advisor1.Advisor1.act2", "advisor1.featurize", "advisor1.Advisor1.RL.choose_action", "numpy.random.uniform", "advisor1.Advisor1.act2", "advisor1.featurize", "advisor1.Advisor1.RL.choose_action"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action"], ["", "def", "act", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "if", "self", ".", "epsilon_arbitrary", "==", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<", "20000", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.5", "\n", "", "elif", "(", "self", ".", "counter", ">=", "20000", "and", "self", ".", "counter", "<", "40000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.6", "\n", "", "elif", "(", "self", ".", "counter", ">=", "40000", "and", "self", ".", "counter", "<", "60000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.7", "\n", "", "elif", "(", "self", ".", "counter", ">=", "60000", "and", "self", ".", "counter", "<", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "0.8", "\n", "", "elif", "(", "self", ".", "counter", ">=", "80000", ")", ":", "\n", "                ", "self", ".", "epsilon", "=", "1", "\n", "\n", "", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", ">", "self", ".", "epsilon", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "np", ".", "random", ".", "uniform", "(", ")", "<=", "self", ".", "eps", ")", ":", "\n", "                ", "return", "self", ".", "act2", "(", "obs", ",", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "obs", "=", "featurize", "(", "obs", ")", "\n", "return", "self", ".", "RL", ".", "choose_action", "(", "obs", ",", "self", ".", "action2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.store": [[140, 144], ["advisor1.featurize", "advisor1.featurize", "advisor1.Advisor1.RL.store_transition"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition"], ["", "", "", "def", "store", "(", "self", ",", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", ":", "\n", "        ", "obs", "=", "featurize", "(", "obs", ")", "\n", "obs_", "=", "featurize", "(", "obs_", ")", "\n", "self", ".", "RL", ".", "store_transition", "(", "obs", ",", "act", ",", "act_other", ",", "act_new_other", ",", "reward", ",", "obs_", ",", "act_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.learn": [[145, 153], ["advisor1.Advisor1.RL.learn", "advisor1.Advisor1.linear_decay", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "RL", ".", "learn", "(", ")", "\n", "if", "self", ".", "epsilon_arbitrary", "!=", "True", ":", "\n", "            ", "self", ".", "counter", "=", "self", ".", "counter", "+", "1", "\n", "if", "self", ".", "counter", "<=", "50000", ":", "\n", "                ", "self", ".", "eps", "=", "self", ".", "linear_decay", "(", "self", ".", "counter", ",", "[", "0", ",", "int", "(", "50000", "*", "0.99", ")", ",", "50000", "]", ",", "[", "0.9", ",", "0.2", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "eps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.copy_network": [[154, 156], ["advisor1.Advisor1.RL.copy_network"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network"], ["", "", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "copy_network", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.save_model": [[157, 159], ["advisor1.Advisor1.RL.save_model"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "RL", ".", "save_model", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2": [[160, 231], ["tuple", "numpy.array", "advisor1.Advisor1.act2.convert_bombs"], "methods", ["None"], ["", "def", "act2", "(", "self", ",", "obs", ",", "action_space", ")", ":", "\n", "        ", "def", "convert_bombs", "(", "bomb_map", ")", ":", "\n", "            ", "'''Flatten outs the bomb array'''", "\n", "ret", "=", "[", "]", "\n", "locations", "=", "np", ".", "where", "(", "bomb_map", ">", "0", ")", "\n", "for", "r", ",", "c", "in", "zip", "(", "locations", "[", "0", "]", ",", "locations", "[", "1", "]", ")", ":", "\n", "                ", "ret", ".", "append", "(", "{", "\n", "'position'", ":", "(", "r", ",", "c", ")", ",", "\n", "'blast_strength'", ":", "int", "(", "bomb_map", "[", "(", "r", ",", "c", ")", "]", ")", "\n", "}", ")", "\n", "", "return", "ret", "\n", "\n", "", "my_position", "=", "tuple", "(", "obs", "[", "'position'", "]", ")", "\n", "board", "=", "np", ".", "array", "(", "obs", "[", "'board'", "]", ")", "\n", "bombs", "=", "convert_bombs", "(", "np", ".", "array", "(", "obs", "[", "'bomb_blast_strength'", "]", ")", ")", "\n", "enemies", "=", "[", "constants", ".", "Item", "(", "e", ")", "for", "e", "in", "obs", "[", "'enemies'", "]", "]", "\n", "ammo", "=", "int", "(", "obs", "[", "'ammo'", "]", ")", "\n", "blast_strength", "=", "int", "(", "obs", "[", "'blast_strength'", "]", ")", "\n", "items", ",", "dist", ",", "prev", "=", "self", ".", "_djikstra", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "10", ")", "\n", "\n", "\n", "# Move if we are in an unsafe place.", "\n", "unsafe_directions", "=", "self", ".", "_directions_in_range_of_bomb", "(", "\n", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", "\n", "if", "unsafe_directions", ":", "\n", "            ", "directions", "=", "self", ".", "_find_safe_directions", "(", "\n", "board", ",", "my_position", ",", "unsafe_directions", ",", "bombs", ",", "enemies", ")", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n", "# Lay pomme if we are adjacent to an enemy.", "\n", "", "if", "self", ".", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", "and", "self", ".", "_maybe_bomb", "(", "\n", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "            ", "return", "constants", ".", "Action", ".", "Bomb", ".", "value", "\n", "\n", "# Move towards an enemy if there is one in exactly three reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_enemy", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "3", ")", "\n", "if", "direction", "is", "not", "None", "and", "(", "self", ".", "_prev_direction", "!=", "direction", "or", "\n", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "            ", "self", ".", "_prev_direction", "=", "direction", "\n", "return", "direction", ".", "value", "\n", "\n", "# Move towards a good item if there is one within two reachable spaces.", "\n", "", "direction", "=", "self", ".", "_near_good_powerup", "(", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "2", ")", "\n", "if", "direction", "is", "not", "None", ":", "\n", "            ", "return", "direction", ".", "value", "\n", "\n", "\n", "\n", "# Choose a random but valid direction.", "\n", "", "directions", "=", "[", "\n", "constants", ".", "Action", ".", "Stop", ",", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Right", ",", "constants", ".", "Action", ".", "Up", ",", "constants", ".", "Action", ".", "Down", "\n", "]", "\n", "valid_directions", "=", "self", ".", "_filter_invalid_directions", "(", "\n", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", "\n", "directions", "=", "self", ".", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "\n", "valid_directions", ",", "bombs", ")", "\n", "directions", "=", "self", ".", "_filter_recently_visited", "(", "\n", "directions", ",", "my_position", ",", "self", ".", "_recently_visited_positions", ")", "\n", "if", "len", "(", "directions", ")", ">", "1", ":", "\n", "            ", "directions", "=", "[", "k", "for", "k", "in", "directions", "if", "k", "!=", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "if", "not", "len", "(", "directions", ")", ":", "\n", "            ", "directions", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "# Add this position to the recently visited uninteresting positions so we don't return immediately.", "\n", "", "self", ".", "_recently_visited_positions", ".", "append", "(", "my_position", ")", "\n", "self", ".", "_recently_visited_positions", "=", "self", ".", "_recently_visited_positions", "[", "\n", "-", "self", ".", "_recently_visited_length", ":", "]", "\n", "\n", "return", "random", ".", "choice", "(", "directions", ")", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._djikstra": [[232, 298], ["collections.defaultdict", "queue.Queue", "range", "max", "min", "range", "queue.Queue.empty", "queue.Queue.get", "utility.position_is_passable", "len", "max", "min", "any", "constants.Item", "items[].append", "items[].append", "abs", "abs", "len", "queue.Queue.put", "advisor1.Advisor1._djikstra.out_of_range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_djikstra", "(", "board", ",", "my_position", ",", "bombs", ",", "enemies", ",", "depth", "=", "None", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "assert", "(", "depth", "is", "not", "None", ")", "\n", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "[", "\n", "constants", ".", "Item", ".", "Fog", ",", "constants", ".", "Item", ".", "Rigid", ",", "constants", ".", "Item", ".", "Flames", "\n", "]", "\n", "\n", "", "def", "out_of_range", "(", "p_1", ",", "p_2", ")", ":", "\n", "            ", "'''Determines if two points are out of rang of each other'''", "\n", "x_1", ",", "y_1", "=", "p_1", "\n", "x_2", ",", "y_2", "=", "p_2", "\n", "return", "abs", "(", "y_2", "-", "y_1", ")", "+", "abs", "(", "x_2", "-", "x_1", ")", ">", "depth", "\n", "\n", "", "items", "=", "defaultdict", "(", "list", ")", "\n", "dist", "=", "{", "}", "\n", "prev", "=", "{", "}", "\n", "Q", "=", "queue", ".", "Queue", "(", ")", "\n", "\n", "my_x", ",", "my_y", "=", "my_position", "\n", "for", "r", "in", "range", "(", "max", "(", "0", ",", "my_x", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_x", "+", "depth", ")", ")", ":", "\n", "            ", "for", "c", "in", "range", "(", "max", "(", "0", ",", "my_y", "-", "depth", ")", ",", "min", "(", "len", "(", "board", ")", ",", "my_y", "+", "depth", ")", ")", ":", "\n", "                ", "position", "=", "(", "r", ",", "c", ")", "\n", "if", "any", "(", "[", "\n", "out_of_range", "(", "my_position", ",", "position", ")", ",", "\n", "utility", ".", "position_in_items", "(", "board", ",", "position", ",", "exclude", ")", ",", "\n", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "prev", "[", "position", "]", "=", "None", "\n", "item", "=", "constants", ".", "Item", "(", "board", "[", "position", "]", ")", "\n", "items", "[", "item", "]", ".", "append", "(", "position", ")", "\n", "\n", "if", "position", "==", "my_position", ":", "\n", "                    ", "Q", ".", "put", "(", "position", ")", "\n", "dist", "[", "position", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "dist", "[", "position", "]", "=", "np", ".", "inf", "\n", "\n", "\n", "", "", "", "for", "bomb", "in", "bombs", ":", "\n", "            ", "if", "bomb", "[", "'position'", "]", "==", "my_position", ":", "\n", "                ", "items", "[", "constants", ".", "Item", ".", "Bomb", "]", ".", "append", "(", "my_position", ")", "\n", "\n", "", "", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "            ", "position", "=", "Q", ".", "get", "(", ")", "\n", "\n", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "x", ",", "y", "=", "position", "\n", "val", "=", "dist", "[", "(", "x", ",", "y", ")", "]", "+", "1", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "x", ",", "col", "+", "y", ")", "\n", "if", "new_position", "not", "in", "dist", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "val", "<", "dist", "[", "new_position", "]", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "Q", ".", "put", "(", "new_position", ")", "\n", "", "elif", "(", "val", "==", "dist", "[", "new_position", "]", "and", "random", ".", "random", "(", ")", "<", ".5", ")", ":", "\n", "                        ", "dist", "[", "new_position", "]", "=", "val", "\n", "prev", "[", "new_position", "]", "=", "position", "\n", "\n", "\n", "", "", "", "", "return", "items", ",", "dist", ",", "prev", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._directions_in_range_of_bomb": [[299, 341], ["collections.defaultdict", "dist.get", "max", "max", "max", "max", "max"], "methods", ["None"], ["", "def", "_directions_in_range_of_bomb", "(", "self", ",", "board", ",", "my_position", ",", "bombs", ",", "dist", ")", ":", "\n", "        ", "ret", "=", "defaultdict", "(", "int", ")", "\n", "\n", "x", ",", "y", "=", "my_position", "\n", "for", "bomb", "in", "bombs", ":", "\n", "            ", "position", "=", "bomb", "[", "'position'", "]", "\n", "distance", "=", "dist", ".", "get", "(", "position", ")", "\n", "if", "distance", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "bomb_range", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "distance", ">", "bomb_range", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "my_position", "==", "position", ":", "\n", "# We are on a bomb. All directions are in range of bomb.", "\n", "                ", "for", "direction", "in", "[", "\n", "constants", ".", "Action", ".", "Right", ",", "\n", "constants", ".", "Action", ".", "Left", ",", "\n", "constants", ".", "Action", ".", "Up", ",", "\n", "constants", ".", "Action", ".", "Down", ",", "\n", "]", ":", "\n", "                    ", "ret", "[", "direction", "]", "=", "max", "(", "ret", "[", "direction", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "x", "==", "position", "[", "0", "]", ":", "\n", "                ", "if", "y", "<", "position", "[", "1", "]", ":", "\n", "# Bomb is right.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Right", "]", "=", "max", "(", "\n", "ret", "[", "constants", ".", "Action", ".", "Right", "]", ",", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is left.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Left", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Left", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "elif", "y", "==", "position", "[", "1", "]", ":", "\n", "                ", "if", "x", "<", "position", "[", "0", "]", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Down", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Down", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "else", ":", "\n", "# Bomb is down.", "\n", "                    ", "ret", "[", "constants", ".", "Action", ".", "Up", "]", "=", "max", "(", "ret", "[", "constants", ".", "Action", ".", "Up", "]", ",", "\n", "bomb", "[", "'blast_strength'", "]", ")", "\n", "", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._find_safe_directions": [[342, 436], ["queue.PriorityQueue", "queue.PriorityQueue.put", "advisor1.Advisor1.set"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "def", "_find_safe_directions", "(", "self", ",", "board", ",", "my_position", ",", "unsafe_directions", ",", "\n", "bombs", ",", "enemies", ")", ":", "\n", "\n", "        ", "def", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "enemies", ")", ":", "\n", "            ", "'''Helper function to do determine if the agents next move is possible.'''", "\n", "Q", "=", "queue", ".", "PriorityQueue", "(", ")", "\n", "Q", ".", "put", "(", "(", "0", ",", "next_position", ")", ")", "\n", "seen", "=", "set", "(", ")", "\n", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "is_stuck", "=", "True", "\n", "while", "not", "Q", ".", "empty", "(", ")", ":", "\n", "                ", "dist", ",", "position", "=", "Q", ".", "get", "(", ")", "\n", "seen", ".", "add", "(", "position", ")", "\n", "\n", "position_x", ",", "position_y", "=", "position", "\n", "if", "next_x", "!=", "position_x", "and", "next_y", "!=", "position_y", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "if", "dist", ">", "bomb_range", ":", "\n", "                    ", "is_stuck", "=", "False", "\n", "break", "\n", "\n", "", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "                    ", "new_position", "=", "(", "row", "+", "position_x", ",", "col", "+", "position_y", ")", "\n", "if", "new_position", "in", "seen", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "new_position", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "\n", "new_position", ",", "enemies", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "dist", "=", "abs", "(", "row", "+", "position_x", "-", "next_x", ")", "+", "abs", "(", "col", "+", "position_y", "-", "next_y", ")", "\n", "Q", ".", "put", "(", "(", "dist", ",", "new_position", ")", ")", "\n", "", "", "return", "is_stuck", "\n", "\n", "# All directions are unsafe. Return a position that won't leave us locked.", "\n", "", "safe", "=", "[", "]", "\n", "\n", "if", "len", "(", "unsafe_directions", ")", "==", "4", ":", "\n", "            ", "next_board", "=", "board", ".", "copy", "(", ")", "\n", "next_board", "[", "my_position", "]", "=", "constants", ".", "Item", ".", "Bomb", ".", "value", "\n", "\n", "for", "direction", ",", "bomb_range", "in", "unsafe_directions", ".", "items", "(", ")", ":", "\n", "                ", "next_position", "=", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "\n", "next_x", ",", "next_y", "=", "next_position", "\n", "if", "not", "utility", ".", "position_on_board", "(", "next_board", ",", "next_position", ")", "or", "not", "utility", ".", "position_is_passable", "(", "next_board", ",", "next_position", ",", "enemies", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "is_stuck_direction", "(", "next_position", ",", "bomb_range", ",", "next_board", ",", "\n", "enemies", ")", ":", "\n", "# We found a direction that works. The .items provided", "\n", "# a small bit of randomness. So let's go with this one.", "\n", "                    ", "return", "[", "direction", "]", "\n", "", "", "if", "not", "safe", ":", "\n", "                ", "safe", "=", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "", "return", "safe", "\n", "\n", "", "x", ",", "y", "=", "my_position", "\n", "disallowed", "=", "[", "]", "# The directions that will go off the board.", "\n", "\n", "for", "row", ",", "col", "in", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "0", ",", "-", "1", ")", ",", "(", "0", ",", "1", ")", "]", ":", "\n", "            ", "position", "=", "(", "x", "+", "row", ",", "y", "+", "col", ")", "\n", "direction", "=", "utility", ".", "get_direction", "(", "my_position", ",", "position", ")", "\n", "\n", "# Don't include any direction that will go off of the board.", "\n", "if", "not", "utility", ".", "position_on_board", "(", "board", ",", "position", ")", ":", "\n", "                ", "disallowed", ".", "append", "(", "direction", ")", "\n", "continue", "\n", "\n", "# Don't include any direction that we know is unsafe.", "\n", "", "if", "direction", "in", "unsafe_directions", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "utility", ".", "position_is_passable", "(", "board", ",", "position", ",", "\n", "enemies", ")", "or", "utility", ".", "position_is_fog", "(", "\n", "board", ",", "position", ")", ":", "\n", "                ", "safe", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "safe", ":", "\n", "# We don't have any safe directions, so return something that is allowed.", "\n", "            ", "safe", "=", "[", "k", "for", "k", "in", "unsafe_directions", "if", "k", "not", "in", "disallowed", "]", "\n", "\n", "", "if", "not", "safe", ":", "\n", "# We don't have ANY directions. So return the stop choice.", "\n", "            ", "return", "[", "constants", ".", "Action", ".", "Stop", "]", "\n", "\n", "", "return", "safe", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._is_adjacent_enemy": [[437, 444], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_adjacent_enemy", "(", "items", ",", "dist", ",", "enemies", ")", ":", "\n", "        ", "for", "enemy", "in", "enemies", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "enemy", ",", "[", "]", ")", ":", "\n", "                ", "if", "dist", "[", "position", "]", "==", "1", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._has_bomb": [[445, 448], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_has_bomb", "(", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "'ammo'", "]", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._maybe_bomb": [[449, 477], ["items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_maybe_bomb", "(", "ammo", ",", "blast_strength", ",", "items", ",", "dist", ",", "my_position", ")", ":", "\n", "        ", "\"\"\"Returns whether we can safely bomb right now.\n\n        Decides this based on:\n        1. Do we have ammo?\n        2. If we laid a bomb right now, will we be stuck?\n        \"\"\"", "\n", "# Do we have ammo?", "\n", "if", "ammo", "<", "1", ":", "\n", "            ", "return", "False", "\n", "\n", "# Will we be stuck?", "\n", "", "x", ",", "y", "=", "my_position", "\n", "for", "position", "in", "items", ".", "get", "(", "constants", ".", "Item", ".", "Passage", ")", ":", "\n", "            ", "if", "dist", "[", "position", "]", "==", "np", ".", "inf", ":", "\n", "                ", "continue", "\n", "\n", "# We can reach a passage that's outside of the bomb strength.", "\n", "", "if", "dist", "[", "position", "]", ">", "blast_strength", ":", "\n", "                ", "return", "True", "\n", "\n", "# We can reach a passage that's outside of the bomb scope.", "\n", "", "position_x", ",", "position_y", "=", "position", "\n", "if", "position_x", "!=", "x", "and", "position_y", "!=", "y", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position": [[478, 491], ["max", "dist.values", "items.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", ":", "\n", "        ", "nearest", "=", "None", "\n", "dist_to", "=", "max", "(", "dist", ".", "values", "(", ")", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "            ", "for", "position", "in", "items", ".", "get", "(", "obj", ",", "[", "]", ")", ":", "\n", "                ", "d", "=", "dist", "[", "position", "]", "\n", "if", "d", "<=", "radius", "and", "d", "<=", "dist_to", ":", "\n", "                    ", "nearest", "=", "position", "\n", "dist_to", "=", "d", "\n", "\n", "", "", "", "return", "nearest", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position": [[492, 506], ["utility.get_direction"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.get_direction"], ["", "@", "staticmethod", "\n", "def", "_get_direction_towards_position", "(", "my_position", ",", "position", ",", "prev", ")", ":", "\n", "        ", "if", "not", "position", ":", "\n", "            ", "return", "None", "\n", "\n", "", "next_position", "=", "position", "\n", "\n", "if", "prev", "[", "next_position", "]", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "prev", "[", "next_position", "]", "!=", "my_position", ":", "\n", "            ", "next_position", "=", "prev", "[", "next_position", "]", "\n", "\n", "", "return", "utility", ".", "get_direction", "(", "my_position", ",", "next_position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._near_enemy": [[507, 513], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_enemy", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "enemies", ",", "radius", ")", ":", "\n", "        ", "nearest_enemy_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "enemies", ",", "items", ",", "\n", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_enemy_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._near_good_powerup": [[514, 523], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_good_powerup", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "\n", "constants", ".", "Item", ".", "ExtraBomb", ",", "constants", ".", "Item", ".", "IncrRange", ",", "\n", "constants", ".", "Item", ".", "Kick", "\n", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._near_wood": [[524, 530], ["cls._nearest_position", "cls._get_direction_towards_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._nearest_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._get_direction_towards_position"], ["", "@", "classmethod", "\n", "def", "_near_wood", "(", "cls", ",", "my_position", ",", "items", ",", "dist", ",", "prev", ",", "radius", ")", ":", "\n", "        ", "objs", "=", "[", "constants", ".", "Item", ".", "Wood", "]", "\n", "nearest_item_position", "=", "cls", ".", "_nearest_position", "(", "dist", ",", "objs", ",", "items", ",", "radius", ")", "\n", "return", "cls", ".", "_get_direction_towards_position", "(", "my_position", ",", "\n", "nearest_item_position", ",", "prev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._filter_invalid_directions": [[531, 541], ["utility.get_next_position", "utility.position_on_board", "utility.position_is_passable", "ret.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_on_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_passable"], ["", "@", "staticmethod", "\n", "def", "_filter_invalid_directions", "(", "board", ",", "my_position", ",", "directions", ",", "enemies", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "position", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "if", "utility", ".", "position_on_board", "(", "\n", "board", ",", "position", ")", "and", "utility", ".", "position_is_passable", "(", "\n", "board", ",", "position", ",", "enemies", ")", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._filter_unsafe_directions": [[542, 558], ["utility.get_next_position", "ret.append", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_unsafe_directions", "(", "board", ",", "my_position", ",", "directions", ",", "bombs", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "x", ",", "y", "=", "utility", ".", "get_next_position", "(", "my_position", ",", "direction", ")", "\n", "is_bad", "=", "False", "\n", "for", "bomb", "in", "bombs", ":", "\n", "                ", "bomb_x", ",", "bomb_y", "=", "bomb", "[", "'position'", "]", "\n", "blast_strength", "=", "bomb", "[", "'blast_strength'", "]", "\n", "if", "(", "x", "==", "bomb_x", "and", "abs", "(", "bomb_y", "-", "y", ")", "<=", "blast_strength", ")", "or", "(", "y", "==", "bomb_y", "and", "abs", "(", "bomb_x", "-", "x", ")", "<=", "blast_strength", ")", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_bad", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1._filter_recently_visited": [[559, 571], ["ret.append", "utility.get_next_position"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.get_next_position"], ["", "@", "staticmethod", "\n", "def", "_filter_recently_visited", "(", "directions", ",", "my_position", ",", "\n", "recently_visited_positions", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "for", "direction", "in", "directions", ":", "\n", "            ", "if", "not", "utility", ".", "get_next_position", "(", "\n", "my_position", ",", "direction", ")", "in", "recently_visited_positions", ":", "\n", "                ", "ret", ".", "append", "(", "direction", ")", "\n", "\n", "", "", "if", "not", "ret", ":", "\n", "            ", "ret", "=", "directions", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.make_np_float": [[27, 29], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.featurize": [[36, 59], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "advisor1.make_np_float", "advisor1.make_np_float", "advisor1.make_np_float", "advisor1.make_np_float", "advisor1.make_np_float", "advisor1.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme.__init__": [[24, 40], ["kwargs.get", "kwargs.get", "v0.Pomme.__init__"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_radio_vocab_size", "=", "kwargs", ".", "get", "(", "'radio_vocab_size'", ")", "\n", "self", ".", "_radio_num_words", "=", "kwargs", ".", "get", "(", "'radio_num_words'", ")", "\n", "if", "(", "self", ".", "_radio_vocab_size", "and", "\n", "not", "self", ".", "_radio_num_words", ")", "or", "(", "not", "self", ".", "_radio_vocab_size", "and", "\n", "self", ".", "_radio_num_words", ")", ":", "\n", "            ", "assert", "(", "\"Include both radio_vocab_size and radio_num_words.\"", ")", "\n", "\n", "", "self", ".", "_radio_from_agent", "=", "{", "\n", "agent", ":", "(", "0", ",", "0", ")", "\n", "for", "agent", "in", "[", "\n", "constants", ".", "Item", ".", "Agent0", ",", "constants", ".", "Item", ".", "Agent1", ",", "\n", "constants", ".", "Item", ".", "Agent2", ",", "constants", ".", "Item", ".", "Agent3", "\n", "]", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme._set_action_space": [[41, 46], ["gym.spaces.Tuple", "tuple", "gym.spaces.Discrete", "gym.spaces.Discrete"], "methods", ["None"], ["", "def", "_set_action_space", "(", "self", ")", ":", "\n", "        ", "self", ".", "action_space", "=", "spaces", ".", "Tuple", "(", "\n", "tuple", "(", "[", "spaces", ".", "Discrete", "(", "6", ")", "]", "+", "\n", "[", "spaces", ".", "Discrete", "(", "self", ".", "_radio_vocab_size", "\n", ")", "]", "*", "self", ".", "_radio_num_words", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme._set_observation_space": [[47, 73], ["min_obs.extend", "max_obs.extend", "gym.spaces.Box", "numpy.array", "numpy.array", "len"], "methods", ["None"], ["", "def", "_set_observation_space", "(", "self", ")", ":", "\n", "        ", "\"\"\"The Observation Space for each agent.\n\n        Total observatiosn: 3*board_size^2 + 12 + radio_vocab_size * radio_num_words:\n        - all of the board (board_size^2)\n        - bomb blast strength (board_size^2).\n        - bomb life (board_size^2)\n        - agent's position (2)\n        - player ammo counts (1)\n        - blast strength (1)\n        - can_kick (1)\n        - teammate (one of {AgentDummy.value, Agent3.value}).\n        - enemies (three of {AgentDummy.value, Agent3.value}).\n        - radio (radio_vocab_size * radio_num_words)\n        \"\"\"", "\n", "bss", "=", "self", ".", "_board_size", "**", "2", "\n", "min_obs", "=", "[", "0", "]", "*", "3", "*", "bss", "+", "[", "0", "]", "*", "5", "+", "[", "constants", ".", "Item", ".", "AgentDummy", ".", "value", "\n", "]", "*", "4", "\n", "max_obs", "=", "[", "len", "(", "constants", ".", "Item", ")", "]", "*", "bss", "+", "[", "self", ".", "_board_size", "\n", "]", "*", "bss", "+", "[", "25", "]", "*", "bss", "\n", "max_obs", "+=", "[", "self", ".", "_board_size", "]", "*", "2", "+", "[", "self", ".", "_num_items", "]", "*", "2", "+", "[", "1", "]", "\n", "max_obs", "+=", "[", "constants", ".", "Item", ".", "Agent3", ".", "value", "]", "*", "4", "\n", "min_obs", ".", "extend", "(", "[", "0", "]", "*", "self", ".", "_radio_vocab_size", "*", "self", ".", "_radio_num_words", ")", "\n", "max_obs", ".", "extend", "(", "[", "1", "]", "*", "self", ".", "_radio_vocab_size", "*", "self", ".", "_radio_num_words", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "np", ".", "array", "(", "min_obs", ")", ",", "np", ".", "array", "(", "max_obs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme.get_observations": [[74, 81], ["super().get_observations"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations"], ["", "def", "get_observations", "(", "self", ")", ":", "\n", "        ", "observations", "=", "super", "(", ")", ".", "get_observations", "(", ")", "\n", "for", "obs", "in", "observations", ":", "\n", "            ", "obs", "[", "'message'", "]", "=", "self", ".", "_radio_from_agent", "[", "obs", "[", "'teammate'", "]", "]", "\n", "\n", "", "self", ".", "observations", "=", "observations", "\n", "return", "observations", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme.step": [[82, 100], ["zip", "super().step", "personal_actions.append", "radio_actions.append", "type", "type", "personal_actions.append", "radio_actions.append", "getattr", "tuple"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "personal_actions", "=", "[", "]", "\n", "radio_actions", "=", "[", "]", "\n", "for", "agent_actions", ",", "agent", "in", "zip", "(", "actions", ",", "self", ".", "_agents", ")", ":", "\n", "            ", "if", "type", "(", "agent_actions", ")", "==", "int", "or", "not", "agent", ".", "is_alive", ":", "\n", "                ", "personal_actions", ".", "append", "(", "agent_actions", ")", "\n", "radio_actions", ".", "append", "(", "(", "0", ",", "0", ")", ")", "\n", "", "elif", "type", "(", "agent_actions", ")", "in", "[", "tuple", ",", "list", "]", ":", "\n", "                ", "personal_actions", ".", "append", "(", "agent_actions", "[", "0", "]", ")", "\n", "radio_actions", ".", "append", "(", "\n", "tuple", "(", "agent_actions", "[", "1", ":", "(", "1", "+", "self", ".", "_radio_num_words", ")", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "self", ".", "_radio_from_agent", "[", "getattr", "(", "\n", "constants", ".", "Item", ",", "'Agent%d'", "%", "agent", ".", "agent_id", ")", "]", "=", "radio_actions", "[", "-", "1", "]", "\n", "\n", "", "return", "super", "(", ")", ".", "step", "(", "personal_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme.featurize": [[101, 107], ["super().featurize", "utility.make_np_float", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "@", "staticmethod", "\n", "def", "featurize", "(", "obs", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "featurize", "(", "obs", ")", "\n", "message", "=", "obs", "[", "'message'", "]", "\n", "message", "=", "utility", ".", "make_np_float", "(", "message", ")", "\n", "return", "np", ".", "concatenate", "(", "(", "ret", ",", "message", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme.get_json_info": [[108, 117], ["super().get_json_info", "json.dumps", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.get_json_info"], ["", "def", "get_json_info", "(", "self", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "get_json_info", "(", ")", "\n", "ret", "[", "'radio_vocab_size'", "]", "=", "json", ".", "dumps", "(", "\n", "self", ".", "_radio_vocab_size", ",", "cls", "=", "json_encoder", ")", "\n", "ret", "[", "'radio_num_words'", "]", "=", "json", ".", "dumps", "(", "\n", "self", ".", "_radio_num_words", ",", "cls", "=", "json_encoder", ")", "\n", "ret", "[", "'_radio_from_agent'", "]", "=", "json", ".", "dumps", "(", "\n", "self", ".", "_radio_from_agent", ",", "cls", "=", "json_encoder", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v2.Pomme.set_json_info": [[118, 126], ["super().set_json_info", "json.loads", "json.loads", "json.loads"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.set_json_info"], ["", "def", "set_json_info", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_json_info", "(", ")", "\n", "self", ".", "radio_vocab_size", "=", "json", ".", "loads", "(", "\n", "self", ".", "_init_game_state", "[", "'radio_vocab_size'", "]", ")", "\n", "self", ".", "radio_num_words", "=", "json", ".", "loads", "(", "\n", "self", ".", "_init_game_state", "[", "'radio_num_words'", "]", ")", "\n", "self", ".", "_radio_from_agent", "=", "json", ".", "loads", "(", "\n", "self", ".", "_init_game_state", "[", "'_radio_from_agent'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.__init__": [[28, 68], ["forward_model.ForwardModel", "v0.Pomme._set_action_space", "v0.Pomme._set_observation_space"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._set_action_space", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._set_observation_space"], ["def", "__init__", "(", "self", ",", "\n", "render_fps", "=", "None", ",", "\n", "game_type", "=", "None", ",", "\n", "board_size", "=", "None", ",", "\n", "agent_view_size", "=", "None", ",", "\n", "num_rigid", "=", "None", ",", "\n", "num_wood", "=", "None", ",", "\n", "num_items", "=", "None", ",", "\n", "max_steps", "=", "1000", ",", "\n", "is_partially_observable", "=", "False", ",", "\n", "env", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_render_fps", "=", "render_fps", "\n", "self", ".", "_intended_actions", "=", "[", "]", "\n", "self", ".", "_agents", "=", "None", "\n", "self", ".", "_game_type", "=", "game_type", "\n", "self", ".", "_board_size", "=", "board_size", "\n", "self", ".", "_agent_view_size", "=", "agent_view_size", "\n", "self", ".", "_num_rigid", "=", "num_rigid", "\n", "self", ".", "_num_wood", "=", "num_wood", "\n", "self", ".", "_num_items", "=", "num_items", "\n", "self", ".", "_max_steps", "=", "max_steps", "\n", "self", ".", "_viewer", "=", "None", "\n", "self", ".", "_is_partially_observable", "=", "is_partially_observable", "\n", "self", ".", "_env", "=", "env", "\n", "\n", "self", ".", "training_agent", "=", "None", "\n", "self", ".", "model", "=", "forward_model", ".", "ForwardModel", "(", ")", "\n", "\n", "# This can be changed through set_render_mode", "\n", "# or from the cli tool using '--render_mode=MODE_TYPE'", "\n", "self", ".", "_mode", "=", "'human'", "\n", "\n", "# Observation and Action Spaces. These are both geared towards a single", "\n", "# agent even though the environment expects actions and returns", "\n", "# observations for all four agents. We do this so that it's clear what", "\n", "# the actions and obs are for a single agent. Wrt the observations,", "\n", "# they are actually returned as a dict for easier understanding.", "\n", "self", ".", "_set_action_space", "(", ")", "\n", "self", ".", "_set_observation_space", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._set_action_space": [[69, 71], ["gym.spaces.Discrete"], "methods", ["None"], ["", "def", "_set_action_space", "(", "self", ")", ":", "\n", "        ", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_render_mode": [[72, 74], ["None"], "methods", ["None"], ["", "def", "set_render_mode", "(", "self", ",", "mode", ")", ":", "\n", "        ", "self", ".", "_mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._set_observation_space": [[75, 98], ["gym.spaces.Box", "numpy.array", "numpy.array", "len"], "methods", ["None"], ["", "def", "_set_observation_space", "(", "self", ")", ":", "\n", "        ", "\"\"\"The Observation Space for each agent.\n\n        There are a total of 3*board_size^2+12 observations:\n        - all of the board (board_size^2)\n        - bomb blast strength (board_size^2).\n        - bomb life (board_size^2)\n        - agent's position (2)\n        - player ammo counts (1)\n        - blast strength (1)\n        - can_kick (1)\n        - teammate (one of {AgentDummy.value, Agent3.value}).\n        - enemies (three of {AgentDummy.value, Agent3.value}).\n        \"\"\"", "\n", "bss", "=", "self", ".", "_board_size", "**", "2", "\n", "min_obs", "=", "[", "0", "]", "*", "3", "*", "bss", "+", "[", "0", "]", "*", "5", "+", "[", "constants", ".", "Item", ".", "AgentDummy", ".", "value", "\n", "]", "*", "4", "\n", "max_obs", "=", "[", "len", "(", "constants", ".", "Item", ")", "]", "*", "bss", "+", "[", "self", ".", "_board_size", "\n", "]", "*", "bss", "+", "[", "25", "]", "*", "bss", "\n", "max_obs", "+=", "[", "self", ".", "_board_size", "]", "*", "2", "+", "[", "self", ".", "_num_items", "]", "*", "2", "+", "[", "1", "]", "\n", "max_obs", "+=", "[", "constants", ".", "Item", ".", "Agent3", ".", "value", "]", "*", "4", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "np", ".", "array", "(", "min_obs", ")", ",", "np", ".", "array", "(", "max_obs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_agents": [[99, 101], ["None"], "methods", ["None"], ["", "def", "set_agents", "(", "self", ",", "agents", ")", ":", "\n", "        ", "self", ".", "_agents", "=", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_training_agent": [[102, 104], ["None"], "methods", ["None"], ["", "def", "set_training_agent", "(", "self", ",", "agent_id", ")", ":", "\n", "        ", "self", ".", "training_agent", "=", "agent_id", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_init_game_state": [[105, 126], ["open", "json.loads", "f.read"], "methods", ["None"], ["", "def", "set_init_game_state", "(", "self", ",", "game_state_file", ")", ":", "\n", "        ", "\"\"\"Set the initial game state.\n\n        The expected game_state_file JSON format is:\n          - agents: list of agents serialized (agent_id, is_alive, position,\n            ammo, blast_strength, can_kick)\n          - board: board matrix topology (board_size^2)\n          - board_size: board size\n          - bombs: list of bombs serialized (position, bomber_id, life,\n            blast_strength, moving_direction)\n          - flames: list of flames serialized (position, life)\n          - items: list of item by position\n          - step_count: step count\n\n        Args:\n          game_state_file: JSON File input.\n        \"\"\"", "\n", "self", ".", "_init_game_state", "=", "None", "\n", "if", "game_state_file", ":", "\n", "            ", "with", "open", "(", "game_state_file", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "self", ".", "_init_game_state", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.make_board": [[127, 130], ["utility.make_board", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.make_board"], ["", "", "", "def", "make_board", "(", "self", ")", ":", "\n", "        ", "self", ".", "_board", "=", "utility", ".", "make_board", "(", "self", ".", "_board_size", ",", "self", ".", "_num_rigid", ",", "\n", "self", ".", "_num_wood", ",", "len", "(", "self", ".", "_agents", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.make_items": [[131, 133], ["utility.make_items"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.make_items"], ["", "def", "make_items", "(", "self", ")", ":", "\n", "        ", "self", ".", "_items", "=", "utility", ".", "make_items", "(", "self", ".", "_board", ",", "self", ".", "_num_items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.act": [[134, 138], ["v0.Pomme.model.act"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act"], ["", "def", "act", "(", "self", ",", "obs", ")", ":", "\n", "        ", "agents", "=", "[", "agent", "for", "agent", "in", "self", ".", "_agents", "if", "agent", ".", "agent_id", "!=", "self", ".", "training_agent", "]", "\n", "return", "self", ".", "model", ".", "act", "(", "agents", ",", "obs", ",", "self", ".", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations": [[139, 147], ["v0.Pomme.model.get_observations"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations"], ["", "def", "get_observations", "(", "self", ")", ":", "\n", "        ", "self", ".", "observations", "=", "self", ".", "model", ".", "get_observations", "(", "\n", "self", ".", "_board", ",", "self", ".", "_agents", ",", "self", ".", "_bombs", ",", "self", ".", "_flames", ",", "\n", "self", ".", "_is_partially_observable", ",", "self", ".", "_agent_view_size", ",", "\n", "self", ".", "_game_type", ",", "self", ".", "_env", ")", "\n", "for", "obs", "in", "self", ".", "observations", ":", "\n", "            ", "obs", "[", "'step_count'", "]", "=", "self", ".", "_step_count", "\n", "", "return", "self", ".", "observations", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._get_rewards": [[148, 151], ["v0.Pomme.model.get_rewards"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_rewards"], ["", "def", "_get_rewards", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "get_rewards", "(", "self", ".", "_agents", ",", "self", ".", "_game_type", ",", "\n", "self", ".", "_step_count", ",", "self", ".", "_max_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._get_done": [[152, 156], ["v0.Pomme.model.get_done"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_done"], ["", "def", "_get_done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "get_done", "(", "self", ".", "_agents", ",", "self", ".", "_step_count", ",", "\n", "self", ".", "_max_steps", ",", "self", ".", "_game_type", ",", "\n", "self", ".", "training_agent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._get_info": [[157, 159], ["v0.Pomme.model.get_info"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.forward_model.ForwardModel.get_info"], ["", "def", "_get_info", "(", "self", ",", "done", ",", "rewards", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "get_info", "(", "done", ",", "rewards", ",", "self", ".", "_game_type", ",", "self", ".", "_agents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.reset": [[160, 180], ["v0.Pomme.get_observations", "v0.Pomme.set_json_info", "v0.Pomme.make_board", "v0.Pomme.make_items", "enumerate", "numpy.where", "agent.set_start_position", "agent.reset", "utility.agent_value"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.set_json_info", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.make_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.make_items", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.set_start_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.agent_value"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "assert", "(", "self", ".", "_agents", "is", "not", "None", ")", "\n", "\n", "if", "self", ".", "_init_game_state", "is", "not", "None", ":", "\n", "            ", "self", ".", "set_json_info", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_step_count", "=", "0", "\n", "self", ".", "make_board", "(", ")", "\n", "self", ".", "make_items", "(", ")", "\n", "self", ".", "_bombs", "=", "[", "]", "\n", "self", ".", "_flames", "=", "[", "]", "\n", "self", ".", "_powerups", "=", "[", "]", "\n", "for", "agent_id", ",", "agent", "in", "enumerate", "(", "self", ".", "_agents", ")", ":", "\n", "                ", "pos", "=", "np", ".", "where", "(", "self", ".", "_board", "==", "utility", ".", "agent_value", "(", "agent_id", ")", ")", "\n", "row", "=", "pos", "[", "0", "]", "[", "0", "]", "\n", "col", "=", "pos", "[", "1", "]", "[", "0", "]", "\n", "agent", ".", "set_start_position", "(", "(", "row", ",", "col", ")", ")", "\n", "agent", ".", "reset", "(", ")", "\n", "\n", "", "", "return", "self", ".", "get_observations", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed": [[181, 184], ["gym.utils.seeding.np_random"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "np_random", ",", "seed", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "return", "[", "seed", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.step": [[185, 212], ["v0.Pomme.model.step", "v0.Pomme._get_done", "v0.Pomme.get_observations", "v0.Pomme._get_rewards", "v0.Pomme._get_info", "agent.episode_end"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._get_done", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_observations", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._get_rewards", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme._get_info", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.episode_end"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "_intended_actions", "=", "actions", "\n", "\n", "max_blast_strength", "=", "self", ".", "_agent_view_size", "or", "10", "\n", "result", "=", "self", ".", "model", ".", "step", "(", "\n", "actions", ",", "\n", "self", ".", "_board", ",", "\n", "self", ".", "_agents", ",", "\n", "self", ".", "_bombs", ",", "\n", "self", ".", "_items", ",", "\n", "self", ".", "_flames", ",", "\n", "max_blast_strength", "=", "max_blast_strength", ")", "\n", "self", ".", "_board", ",", "self", ".", "_agents", ",", "self", ".", "_bombs", ",", "self", ".", "_items", ",", "self", ".", "_flames", "=", "result", "[", ":", "5", "]", "\n", "\n", "done", "=", "self", ".", "_get_done", "(", ")", "\n", "obs", "=", "self", ".", "get_observations", "(", ")", "\n", "reward", "=", "self", ".", "_get_rewards", "(", ")", "\n", "info", "=", "self", ".", "_get_info", "(", "done", ",", "reward", ")", "\n", "\n", "if", "done", ":", "\n", "# Callback to let the agents know that the game has ended.", "\n", "            ", "for", "agent", "in", "self", ".", "_agents", ":", "\n", "                ", "agent", ".", "episode_end", "(", "reward", "[", "agent", ".", "agent_id", "]", ")", "\n", "\n", "", "", "self", ".", "_step_count", "+=", "1", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.render": [[213, 273], ["v0.Pomme.close", "graphics.PixelViewer.rgb_array", "v0.Pomme._viewer.set_board", "v0.Pomme._viewer.set_agents", "v0.Pomme._viewer.set_step", "v0.Pomme._viewer.set_bombs", "v0.Pomme._viewer.render", "v0.Pomme._viewer.set_board", "v0.Pomme._viewer.set_agents", "v0.Pomme._viewer.set_step", "v0.Pomme._viewer.set_bombs", "v0.Pomme._viewer.render", "v0.Pomme._viewer.save", "v0.Pomme.save_json", "time.sleep", "graphics.PixelViewer", "graphics.PommeViewer", "agent.has_user_input", "v0.Pomme._viewer.window.push_handlers"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.PixelViewer.rgb_array", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_agents", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_bombs", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_board", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_agents", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.set_bombs", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.save_json", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.has_user_input"], ["", "def", "render", "(", "self", ",", "\n", "mode", "=", "None", ",", "\n", "close", "=", "False", ",", "\n", "record_pngs_dir", "=", "None", ",", "\n", "record_json_dir", "=", "None", ",", "\n", "do_sleep", "=", "True", ")", ":", "\n", "        ", "if", "close", ":", "\n", "            ", "self", ".", "close", "(", ")", "\n", "return", "\n", "\n", "", "mode", "=", "mode", "or", "self", ".", "_mode", "or", "'human'", "\n", "\n", "if", "mode", "==", "'rgb_array'", ":", "\n", "            ", "rgb_array", "=", "graphics", ".", "PixelViewer", ".", "rgb_array", "(", "\n", "self", ".", "_board", ",", "self", ".", "_board_size", ",", "self", ".", "_agents", ",", "\n", "self", ".", "_is_partially_observable", ",", "self", ".", "_agent_view_size", ")", "\n", "return", "rgb_array", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "_viewer", "is", "None", ":", "\n", "            ", "if", "mode", "==", "'rgb_pixel'", ":", "\n", "                ", "self", ".", "_viewer", "=", "graphics", ".", "PixelViewer", "(", "\n", "board_size", "=", "self", ".", "_board_size", ",", "\n", "agents", "=", "self", ".", "_agents", ",", "\n", "agent_view_size", "=", "self", ".", "_agent_view_size", ",", "\n", "partially_observable", "=", "self", ".", "_is_partially_observable", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_viewer", "=", "graphics", ".", "PommeViewer", "(", "\n", "board_size", "=", "self", ".", "_board_size", ",", "\n", "agents", "=", "self", ".", "_agents", ",", "\n", "partially_observable", "=", "self", ".", "_is_partially_observable", ",", "\n", "agent_view_size", "=", "self", ".", "_agent_view_size", ",", "\n", "game_type", "=", "self", ".", "_game_type", ")", "\n", "\n", "", "self", ".", "_viewer", ".", "set_board", "(", "self", ".", "_board", ")", "\n", "self", ".", "_viewer", ".", "set_agents", "(", "self", ".", "_agents", ")", "\n", "self", ".", "_viewer", ".", "set_step", "(", "self", ".", "_step_count", ")", "\n", "self", ".", "_viewer", ".", "set_bombs", "(", "self", ".", "_bombs", ")", "\n", "self", ".", "_viewer", ".", "render", "(", ")", "\n", "\n", "# Register all agents which need human input with Pyglet.", "\n", "# This needs to be done here as the first `imshow` creates the", "\n", "# window. Using `push_handlers` allows for easily creating agents", "\n", "# that use other Pyglet inputs such as joystick, for example.", "\n", "for", "agent", "in", "self", ".", "_agents", ":", "\n", "                ", "if", "agent", ".", "has_user_input", "(", ")", ":", "\n", "                    ", "self", ".", "_viewer", ".", "window", ".", "push_handlers", "(", "agent", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_viewer", ".", "set_board", "(", "self", ".", "_board", ")", "\n", "self", ".", "_viewer", ".", "set_agents", "(", "self", ".", "_agents", ")", "\n", "self", ".", "_viewer", ".", "set_step", "(", "self", ".", "_step_count", ")", "\n", "self", ".", "_viewer", ".", "set_bombs", "(", "self", ".", "_bombs", ")", "\n", "self", ".", "_viewer", ".", "render", "(", ")", "\n", "\n", "", "if", "record_pngs_dir", ":", "\n", "            ", "self", ".", "_viewer", ".", "save", "(", "record_pngs_dir", ")", "\n", "", "if", "record_json_dir", ":", "\n", "            ", "self", ".", "save_json", "(", "record_json_dir", ")", "\n", "\n", "", "if", "do_sleep", ":", "\n", "            ", "time", ".", "sleep", "(", "1.0", "/", "self", ".", "_render_fps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close": [[274, 281], ["v0.Pomme._viewer.close", "agent.shutdown"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.shutdown"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_viewer", "is", "not", "None", ":", "\n", "            ", "self", ".", "_viewer", ".", "close", "(", ")", "\n", "self", ".", "_viewer", "=", "None", "\n", "\n", "", "for", "agent", "in", "self", ".", "_agents", ":", "\n", "            ", "agent", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.featurize": [[282, 298], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "utility.make_np_float", "utility.make_np_float", "utility.make_np_float", "utility.make_np_float", "utility.make_np_float", "utility.make_np_float", "numpy.concatenate", "obs[].reshape", "obs[].reshape", "obs[].reshape"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "", "@", "staticmethod", "\n", "def", "featurize", "(", "obs", ")", ":", "\n", "        ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "utility", ".", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "utility", ".", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "utility", ".", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "utility", ".", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "utility", ".", "make_np_float", "(", "[", "obs", "[", "\"teammate\"", "]", ".", "value", "]", ")", "\n", "enemies", "=", "utility", ".", "make_np_float", "(", "[", "e", ".", "value", "for", "e", "in", "obs", "[", "\"enemies\"", "]", "]", ")", "\n", "return", "np", ".", "concatenate", "(", "\n", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "\n", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.save_json": [[299, 306], ["v0.Pomme.get_json_info", "os.path.join", "open", "f.write", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.get_json_info"], ["", "def", "save_json", "(", "self", ",", "record_json_dir", ")", ":", "\n", "        ", "info", "=", "self", ".", "get_json_info", "(", ")", "\n", "count", "=", "\"{0:0=3d}\"", ".", "format", "(", "self", ".", "_step_count", ")", "\n", "suffix", "=", "count", "+", "'.json'", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "record_json_dir", ",", "suffix", ")", "\n", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "info", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.get_json_info": [[307, 322], ["ret.items", "json.dumps", "v0.Pomme._items.items"], "methods", ["None"], ["", "", "def", "get_json_info", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns a json snapshot of the current game state.\"\"\"", "\n", "ret", "=", "{", "\n", "'board_size'", ":", "self", ".", "_board_size", ",", "\n", "'step_count'", ":", "self", ".", "_step_count", ",", "\n", "'board'", ":", "self", ".", "_board", ",", "\n", "'agents'", ":", "self", ".", "_agents", ",", "\n", "'bombs'", ":", "self", ".", "_bombs", ",", "\n", "'flames'", ":", "self", ".", "_flames", ",", "\n", "'items'", ":", "[", "[", "k", ",", "i", "]", "for", "k", ",", "i", "in", "self", ".", "_items", ".", "items", "(", ")", "]", ",", "\n", "'intended_actions'", ":", "self", ".", "_intended_actions", "\n", "}", "\n", "for", "key", ",", "value", "in", "ret", ".", "items", "(", ")", ":", "\n", "            ", "ret", "[", "key", "]", "=", "json", ".", "dumps", "(", "value", ",", "cls", "=", "utility", ".", "PommermanJSONEncoder", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.set_json_info": [[323, 367], ["int", "int", "json.loads", "numpy.ones().astype", "range", "json.loads", "json.loads", "json.loads", "json.loads", "range", "next", "next.set_start_position", "next.reset", "next", "v0.Pomme._bombs.append", "v0.Pomme._flames.append", "numpy.ones", "int", "bool", "int", "bool", "constants.Action", "characters.Bomb", "characters.Flame", "tuple", "tuple", "int", "int", "tuple"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomber.set_start_position", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset"], ["", "def", "set_json_info", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets the game state as the init_game_state.\"\"\"", "\n", "board_size", "=", "int", "(", "self", ".", "_init_game_state", "[", "'board_size'", "]", ")", "\n", "self", ".", "_board_size", "=", "board_size", "\n", "self", ".", "_step_count", "=", "int", "(", "self", ".", "_init_game_state", "[", "'step_count'", "]", ")", "\n", "\n", "board_array", "=", "json", ".", "loads", "(", "self", ".", "_init_game_state", "[", "'board'", "]", ")", "\n", "self", ".", "_board", "=", "np", ".", "ones", "(", "(", "board_size", ",", "board_size", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "self", ".", "_board", "*=", "constants", ".", "Item", ".", "Passage", ".", "value", "\n", "for", "x", "in", "range", "(", "self", ".", "_board_size", ")", ":", "\n", "            ", "for", "y", "in", "range", "(", "self", ".", "_board_size", ")", ":", "\n", "                ", "self", ".", "_board", "[", "x", ",", "y", "]", "=", "board_array", "[", "x", "]", "[", "y", "]", "\n", "\n", "", "", "self", ".", "_items", "=", "{", "}", "\n", "item_array", "=", "json", ".", "loads", "(", "self", ".", "_init_game_state", "[", "'items'", "]", ")", "\n", "for", "i", "in", "item_array", ":", "\n", "            ", "self", ".", "_items", "[", "tuple", "(", "i", "[", "0", "]", ")", "]", "=", "i", "[", "1", "]", "\n", "\n", "", "agent_array", "=", "json", ".", "loads", "(", "self", ".", "_init_game_state", "[", "'agents'", "]", ")", "\n", "for", "a", "in", "agent_array", ":", "\n", "            ", "agent", "=", "next", "(", "x", "for", "x", "in", "self", ".", "_agents", "if", "x", ".", "agent_id", "==", "a", "[", "'agent_id'", "]", ")", "\n", "agent", ".", "set_start_position", "(", "(", "a", "[", "'position'", "]", "[", "0", "]", ",", "a", "[", "'position'", "]", "[", "1", "]", ")", ")", "\n", "agent", ".", "reset", "(", "\n", "int", "(", "a", "[", "'ammo'", "]", ")", ",", "bool", "(", "a", "[", "'is_alive'", "]", ")", ",", "int", "(", "a", "[", "'blast_strength'", "]", ")", ",", "\n", "bool", "(", "a", "[", "'can_kick'", "]", ")", ")", "\n", "\n", "", "self", ".", "_bombs", "=", "[", "]", "\n", "bomb_array", "=", "json", ".", "loads", "(", "self", ".", "_init_game_state", "[", "'bombs'", "]", ")", "\n", "for", "b", "in", "bomb_array", ":", "\n", "            ", "bomber", "=", "next", "(", "x", "for", "x", "in", "self", ".", "_agents", "if", "x", ".", "agent_id", "==", "b", "[", "'bomber_id'", "]", ")", "\n", "moving_direction", "=", "b", "[", "'moving_direction'", "]", "\n", "if", "moving_direction", "is", "not", "None", ":", "\n", "                ", "moving_direction", "=", "constants", ".", "Action", "(", "moving_direction", ")", "\n", "", "self", ".", "_bombs", ".", "append", "(", "\n", "characters", ".", "Bomb", "(", "bomber", ",", "tuple", "(", "b", "[", "'position'", "]", ")", ",", "int", "(", "b", "[", "'life'", "]", ")", ",", "\n", "int", "(", "b", "[", "'blast_strength'", "]", ")", ",", "moving_direction", ")", ")", "\n", "\n", "", "self", ".", "_flames", "=", "[", "]", "\n", "flame_array", "=", "json", ".", "loads", "(", "self", ".", "_init_game_state", "[", "'flames'", "]", ")", "\n", "for", "f", "in", "flame_array", ":", "\n", "            ", "self", ".", "_flames", ".", "append", "(", "\n", "characters", ".", "Flame", "(", "tuple", "(", "f", "[", "'position'", "]", ")", ",", "f", "[", "'life'", "]", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.__init__": [[30, 36], ["v0.Pomme.__init__", "kwargs.get", "list", "range", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "first_collapse", "=", "kwargs", ".", "get", "(", "'first_collapse'", ")", "\n", "self", ".", "collapses", "=", "list", "(", "\n", "range", "(", "first_collapse", ",", "self", ".", "_max_steps", ",", "\n", "int", "(", "(", "self", ".", "_max_steps", "-", "first_collapse", ")", "/", "4", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme._collapse_board": [[37, 88], ["v1.Pomme._board.copy", "range", "utility.position_is_agent", "utility.position_is_bomb", "utility.position_is_flames", "v1.Pomme._collapse_board.collapse"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_agent", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_bomb", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.utility.position_is_flames"], ["", "def", "_collapse_board", "(", "self", ",", "ring", ")", ":", "\n", "        ", "\"\"\"Collapses the board at a certain ring radius.\n\n        For example, if the board is 13x13 and ring is 0, then the the ring of\n        the first row, last row, first column, and last column is all going to\n        be turned into rigid walls. All agents in that ring die and all bombs\n        are removed without detonating.\n        \n        For further rings, the values get closer to the center.\n\n        Args:\n          ring: Integer value of which cells to collapse.\n        \"\"\"", "\n", "board", "=", "self", ".", "_board", ".", "copy", "(", ")", "\n", "\n", "def", "collapse", "(", "r", ",", "c", ")", ":", "\n", "            ", "'''Handles the collapsing of the board. Will\n            kill of remove any item/agent that is on the\n            collapsing tile.'''", "\n", "if", "utility", ".", "position_is_agent", "(", "board", ",", "(", "r", ",", "c", ")", ")", ":", "\n", "# Agent. Kill it.", "\n", "                ", "num_agent", "=", "board", "[", "r", "]", "[", "c", "]", "-", "constants", ".", "Item", ".", "Agent0", ".", "value", "\n", "agent", "=", "self", ".", "_agents", "[", "num_agent", "]", "\n", "agent", ".", "die", "(", ")", "\n", "", "if", "utility", ".", "position_is_bomb", "(", "self", ".", "_bombs", ",", "(", "r", ",", "c", ")", ")", ":", "\n", "# Bomb. Remove the bomb. Update agent's ammo tally.", "\n", "                ", "new_bombs", "=", "[", "]", "\n", "for", "b", "in", "self", ".", "_bombs", ":", "\n", "                    ", "if", "b", ".", "position", "==", "(", "r", ",", "c", ")", ":", "\n", "                        ", "b", ".", "bomber", ".", "incr_ammo", "(", ")", "\n", "", "else", ":", "\n", "                        ", "new_bombs", ".", "append", "(", "b", ")", "\n", "", "", "self", ".", "_bombs", "=", "new_bombs", "\n", "", "if", "utility", ".", "position_is_flames", "(", "board", ",", "(", "r", ",", "c", ")", ")", ":", "\n", "                ", "self", ".", "_flames", "=", "[", "f", "for", "f", "in", "self", ".", "_flames", "if", "f", ".", "position", "!=", "(", "r", ",", "c", ")", "]", "\n", "", "if", "(", "r", ",", "c", ")", "in", "self", ".", "_items", ":", "\n", "# Item. Remove the item.", "\n", "                ", "del", "self", ".", "_items", "[", "(", "r", ",", "c", ")", "]", "\n", "", "board", "[", "r", "]", "[", "c", "]", "=", "constants", ".", "Item", ".", "Rigid", ".", "value", "\n", "\n", "", "for", "cell", "in", "range", "(", "ring", ",", "self", ".", "_board_size", "-", "ring", ")", ":", "\n", "            ", "collapse", "(", "ring", ",", "cell", ")", "\n", "if", "ring", "!=", "cell", ":", "\n", "                ", "collapse", "(", "cell", ",", "ring", ")", "\n", "\n", "", "end", "=", "self", ".", "_board_size", "-", "ring", "-", "1", "\n", "collapse", "(", "end", ",", "cell", ")", "\n", "if", "end", "!=", "cell", ":", "\n", "                ", "collapse", "(", "cell", ",", "end", ")", "\n", "\n", "", "", "return", "board", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.get_json_info": [[89, 93], ["super().get_json_info", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.get_json_info"], ["", "def", "get_json_info", "(", "self", ")", ":", "\n", "        ", "ret", "=", "super", "(", ")", ".", "get_json_info", "(", ")", "\n", "ret", "[", "'collapses'", "]", "=", "json", ".", "dumps", "(", "self", ".", "collapses", ",", "cls", "=", "json_encoder", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.set_json_info": [[94, 97], ["super().set_json_info", "json.loads"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.set_json_info"], ["", "def", "set_json_info", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "set_json_info", "(", ")", "\n", "self", ".", "collapses", "=", "json", ".", "loads", "(", "self", ".", "_init_game_state", "[", "'collapses'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme.step": [[98, 107], ["super().step", "enumerate", "v1.Pomme._collapse_board"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v1.Pomme._collapse_board"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "obs", ",", "reward", ",", "done", ",", "info", "=", "super", "(", ")", ".", "step", "(", "actions", ")", "\n", "\n", "for", "ring", ",", "collapse", "in", "enumerate", "(", "self", ".", "collapses", ")", ":", "\n", "            ", "if", "self", ".", "_step_count", "==", "collapse", ":", "\n", "                ", "self", ".", "_board", "=", "self", ".", "_collapse_board", "(", "ring", ")", "\n", "break", "\n", "\n", "", "", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.helpers.__init__.make_agent_from_string": [[11, 46], ["agent_string.split", "agents.PlayerAgent", "agents.PlayerAgentBlocking", "agents.SimpleAgent", "agents.RandomAgent", "agents.DockerAgent", "agent_control.split", "agents.HttpAgent", "eval", "agents.TensorForceAgent"], "function", ["None"], ["\n", "gym", ".", "logger", ".", "set_level", "(", "40", ")", "\n", "REGISTRY", "=", "None", "\n", "\n", "\n", "def", "_register", "(", ")", ":", "\n", "    ", "global", "REGISTRY", "\n", "REGISTRY", "=", "[", "]", "\n", "for", "name", ",", "f", "in", "inspect", ".", "getmembers", "(", "configs", ",", "inspect", ".", "isfunction", ")", ":", "\n", "        ", "if", "not", "name", ".", "endswith", "(", "'_env'", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "config", "=", "f", "(", ")", "\n", "gym", ".", "envs", ".", "registration", ".", "register", "(", "\n", "id", "=", "config", "[", "'env_id'", "]", ",", "\n", "entry_point", "=", "config", "[", "'env_entry_point'", "]", ",", "\n", "kwargs", "=", "config", "[", "'env_kwargs'", "]", "\n", ")", "\n", "REGISTRY", ".", "append", "(", "config", "[", "'env_id'", "]", ")", "\n", "\n", "\n", "# Register environments with gym", "\n", "", "", "_register", "(", ")", "\n", "\n", "def", "make", "(", "config_id", ",", "agent_list", ",", "game_state_file", "=", "None", ",", "render_mode", "=", "'human'", ")", ":", "\n", "    ", "'''Makes the pommerman env and registers it with gym'''", "\n", "assert", "config_id", "in", "REGISTRY", ",", "\"Unknown configuration '{}'. \"", "\"Possible values: {}\"", ".", "format", "(", "config_id", ",", "REGISTRY", ")", "\n", "env", "=", "gym", ".", "make", "(", "config_id", ")", "\n", "\n", "for", "id_", ",", "agent", "in", "enumerate", "(", "agent_list", ")", ":", "\n", "        ", "assert", "isinstance", "(", "agent", ",", "agents", ".", "BaseAgent", ")", "\n", "# NOTE: This is IMPORTANT so that the agent character is initialized", "\n", "agent", ".", "init_agent", "(", "id_", ",", "env", ".", "spec", ".", "_kwargs", "[", "'game_type'", "]", ")", "\n", "\n", "", "env", ".", "set_agents", "(", "agent_list", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act": [[18, 22], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "act", "(", "self", ",", "observation", ",", "action_space", ")", ":", "\n", "        ", "\"\"\"Given an observation, returns the action the agent should\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run": [[23, 80], ["flask.Flask", "flask.Flask.route", "flask.Flask.route", "flask.Flask.route", "flask.Flask.route", "flask.Flask.route", "LOGGER.info", "flask.Flask.run", "flask.request.get_json", "flask.request.get_json.get", "json.loads", "constants.Item", "range", "tuple", "numpy.array", "numpy.array", "numpy.array", "flask.request.get_json.get", "json.loads", "docker_agent_runner.DockerAgentRunner.act", "flask.jsonify", "flask.request.get_json", "flask.request.get_json.get", "json.loads", "flask.request.get_json.get", "constants.GameType", "docker_agent_runner.DockerAgentRunner.init_agent", "flask.jsonify", "docker_agent_runner.DockerAgentRunner.shutdown", "flask.jsonify", "flask.request.get_json", "flask.request.get_json.get", "json.loads", "docker_agent_runner.DockerAgentRunner.episode_end", "flask.jsonify", "flask.jsonify", "len", "constants.Item", "json.loads"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.init_agent", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.shutdown", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.base_agent.BaseAgent.episode_end"], ["", "def", "run", "(", "self", ",", "host", "=", "\"0.0.0.0\"", ",", "port", "=", "10080", ")", ":", "\n", "        ", "\"\"\"Runs the agent by creating a webserver that handles action requests.\"\"\"", "\n", "app", "=", "Flask", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n", "@", "app", ".", "route", "(", "\"/action\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "action", "(", ")", ":", "#pylint: disable=W0612", "\n", "            ", "'''handles an action over http'''", "\n", "data", "=", "request", ".", "get_json", "(", ")", "\n", "observation", "=", "data", ".", "get", "(", "\"obs\"", ")", "\n", "observation", "=", "json", ".", "loads", "(", "observation", ")", "\n", "\n", "observation", "[", "'teammate'", "]", "=", "constants", ".", "Item", "(", "observation", "[", "'teammate'", "]", ")", "\n", "for", "enemy_id", "in", "range", "(", "len", "(", "observation", "[", "'enemies'", "]", ")", ")", ":", "\n", "                ", "observation", "[", "'enemies'", "]", "[", "enemy_id", "]", "=", "constants", ".", "Item", "(", "observation", "[", "'enemies'", "]", "[", "enemy_id", "]", ")", "\n", "", "observation", "[", "'position'", "]", "=", "tuple", "(", "observation", "[", "'position'", "]", ")", "\n", "observation", "[", "'board'", "]", "=", "np", ".", "array", "(", "observation", "[", "'board'", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "observation", "[", "'bomb_life'", "]", "=", "np", ".", "array", "(", "observation", "[", "'bomb_life'", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "observation", "[", "'bomb_blast_strength'", "]", "=", "np", ".", "array", "(", "observation", "[", "'bomb_blast_strength'", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "action_space", "=", "data", ".", "get", "(", "\"action_space\"", ")", "\n", "action_space", "=", "json", ".", "loads", "(", "action_space", ")", "\n", "action", "=", "self", ".", "act", "(", "observation", ",", "action_space", ")", "\n", "return", "jsonify", "(", "{", "\"action\"", ":", "action", "}", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "\"/init_agent\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "init_agent", "(", ")", ":", "#pylint: disable=W0612", "\n", "            ", "'''initiates agent over http'''", "\n", "data", "=", "request", ".", "get_json", "(", ")", "\n", "id", "=", "data", ".", "get", "(", "\"id\"", ")", "\n", "id", "=", "json", ".", "loads", "(", "id", ")", "\n", "game_type", "=", "data", ".", "get", "(", "\"game_type\"", ")", "\n", "game_type", "=", "constants", ".", "GameType", "(", "json", ".", "loads", "(", "game_type", ")", ")", "\n", "self", ".", "init_agent", "(", "id", ",", "game_type", ")", "\n", "return", "jsonify", "(", "success", "=", "True", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "\"/shutdown\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "shutdown", "(", ")", ":", "#pylint: disable=W0612", "\n", "            ", "'''Requests destruction of any created objects'''", "\n", "self", ".", "shutdown", "(", ")", "\n", "return", "jsonify", "(", "success", "=", "True", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "\"/episode_end\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "episode_end", "(", ")", ":", "#pylint: disable=W0612", "\n", "            ", "'''Info about end of a game'''", "\n", "data", "=", "request", ".", "get_json", "(", ")", "\n", "reward", "=", "data", ".", "get", "(", "\"reward\"", ")", "\n", "reward", "=", "json", ".", "loads", "(", "reward", ")", "\n", "self", ".", "episode_end", "(", "reward", ")", "\n", "return", "jsonify", "(", "success", "=", "True", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "\"/ping\"", ",", "methods", "=", "[", "\"GET\"", "]", ")", "\n", "def", "ping", "(", ")", ":", "#pylint: disable=W0612", "\n", "            ", "'''Basic agent health check'''", "\n", "return", "jsonify", "(", "success", "=", "True", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "\"Starting agent server on port %d\"", ",", "port", ")", "\n", "app", ".", "run", "(", "host", "=", "host", ",", "port", "=", "port", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_admiraldm2.AdmiralDMNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "5", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Advisorq2_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Advisorq2_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.copy_network": [[53, 58], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork._build_net": [[61, 111], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "1", "]", ",", "name", "=", "'Advisorq2_s'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Advisorq2_Q_target'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiralValue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_eval_net'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Advisorq2_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w1'", ",", "[", "self", ".", "n_features", "+", "1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_lh1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_wh1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_bh1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "1", "]", ",", "name", "=", "'Advisorq2_s_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_target_net'", ")", ":", "\n", "                ", "c_names", "=", "[", "'Advisorq2_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w1'", ",", "[", "self", ".", "n_features", "+", "1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_lh1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_wh1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_bh1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.store_transition": [[112, 131], ["list", "float", "numpy.array.append", "numpy.array", "list", "float", "numpy.array.append", "numpy.array", "numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "a1", ",", "a2", ",", "r", ",", "s_", ",", "a_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "s", "=", "list", "(", "s", ")", "\n", "a1", "=", "float", "(", "a1", ")", "\n", "s", ".", "append", "(", "a1", ")", "\n", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "a2", "=", "float", "(", "a2", ")", "\n", "s_", ".", "append", "(", "a2", ")", "\n", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "\n", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.choose_action": [[132, 147], ["list", "float", "numpy.array.append", "numpy.array", "numpy.random.uniform", "RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "a2", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "list", "(", "observation", ")", "\n", "a2", "=", "float", "(", "a2", ")", "\n", "observation", ".", "append", "(", "a2", ")", "\n", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.learn": [[148, 179], ["RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "q_eval.copy", "batch_memory[].astype", "numpy.arange", "batch_memory[].astype", "RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "RL_brain_admiraldm2.AdmiralDMNetwork.cost_his.append", "RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "(", "self", ".", "n_features", "+", "1", ")", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "1", ")", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "2", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "1", ")", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.save_model": [[181, 186], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.restore_model": [[189, 194], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm2.AdmiralDMNetwork.plot_cost": [[196, 202], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_admiraldm.AdmiralDMNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "9", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Advisorq_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Advisorq_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.copy_network": [[53, 58], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork._build_net": [[61, 113], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorq_s'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Advisorq_Q_target'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiraldmValue'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_eval_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Advisorq_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_loss'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_train'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorq_s_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_target_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", "=", "[", "'Advisorq_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.store_transition": [[114, 137], ["list", "range", "numpy.array", "list", "range", "numpy.array", "numpy.hstack", "hasattr", "len", "float", "numpy.array.append", "len", "float", "float", "numpy.array.append"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "a1", ",", "a1_", ",", "r", ",", "s_", ",", "a_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "s", "=", "list", "(", "s", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1", ")", ")", ":", "\n", "            ", "new_a", "=", "a1", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s", ".", "append", "(", "new_a", ")", "\n", "", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1_", ")", ")", ":", "\n", "            ", "new_a", "=", "float", "(", "a1_", "[", "i", "]", ")", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s_", ".", "append", "(", "new_a", ")", "\n", "", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "\n", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.choose_action": [[138, 154], ["list", "range", "numpy.array", "len", "float", "numpy.array.append", "numpy.random.uniform", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "a2", ")", ":", "\n", "\n", "        ", "observation", "=", "list", "(", "observation", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a2", ")", ")", ":", "\n", "            ", "new_a", "=", "a2", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "observation", ".", "append", "(", "new_a", ")", "\n", "", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.learn": [[155, 187], ["RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "q_eval.copy", "batch_memory[].astype", "numpy.arange", "batch_memory[].astype", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "RL_brain_admiraldm.AdmiralDMNetwork.cost_his.append", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "(", "self", ".", "n_features", "+", "3", ")", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "5", "]", ".", "astype", "(", "int", ")", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "4", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.save_model": [[189, 194], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.restore_model": [[197, 202], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldm.AdmiralDMNetwork.plot_cost": [[204, 210], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.__init__": [[11, 52], ["numpy.zeros", "RL_brain_Deepsarsa.DeepSarsa._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "3", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Sarsa_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Sarsa_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.copy_network": [[55, 60], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa._build_net": [[61, 112], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'Sarsa_s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Sarsa_Q_target_1'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'SarsaValue'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_eval_net_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Sarsa_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_hl_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_loss'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_train'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'Sarsa_s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_target_net_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", "=", "[", "'Sarsa_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_hl_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.store_transition": [[115, 125], ["numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ",", "a_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.choose_action": [[126, 134], ["numpy.random.uniform", "RL_brain_Deepsarsa.DeepSarsa.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ")", ":", "\n", "        ", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.learn": [[135, 168], ["RL_brain_Deepsarsa.DeepSarsa.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "batch_memory[].astype", "RL_brain_Deepsarsa.DeepSarsa.sess.run", "RL_brain_Deepsarsa.DeepSarsa.cost_his.append", "RL_brain_Deepsarsa.DeepSarsa.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "2", "]", ".", "astype", "(", "int", ")", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.save_model": [[169, 174], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.restore_model": [[177, 182], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_Deepsarsa.DeepSarsa.plot_cost": [[185, 191], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.SumTree.__init__": [[13, 20], ["numpy.zeros", "numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "capacity", ",", "permanent_data", "=", "0", ")", ":", "\n", "        ", "self", ".", "capacity", "=", "capacity", "\n", "self", ".", "tree", "=", "np", ".", "zeros", "(", "2", "*", "capacity", "-", "1", ")", "# stores not probabilities but priorities !!!", "\n", "self", ".", "data", "=", "np", ".", "zeros", "(", "capacity", ",", "dtype", "=", "object", ")", "# stores transitions", "\n", "self", ".", "permanent_data", "=", "permanent_data", "# numbers of data which never be replaced, for demo data protection", "\n", "assert", "0", "<=", "self", ".", "permanent_data", "<=", "self", ".", "capacity", "# equal is also illegal", "\n", "self", ".", "full", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.SumTree.__len__": [[21, 23], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "capacity", "if", "self", ".", "full", "else", "self", ".", "data_pointer", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.SumTree.add": [[24, 32], ["Memory.SumTree.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["", "def", "add", "(", "self", ",", "p", ",", "data", ")", ":", "\n", "        ", "tree_idx", "=", "self", ".", "data_pointer", "+", "self", ".", "capacity", "-", "1", "\n", "self", ".", "data", "[", "self", ".", "data_pointer", "]", "=", "data", "\n", "self", ".", "update", "(", "tree_idx", ",", "p", ")", "\n", "self", ".", "data_pointer", "+=", "1", "\n", "if", "self", ".", "data_pointer", ">=", "self", ".", "capacity", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "self", ".", "data_pointer", "=", "self", ".", "data_pointer", "%", "self", ".", "capacity", "+", "self", ".", "permanent_data", "# make sure demo data permanent", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.SumTree.update": [[33, 39], ["None"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "tree_idx", ",", "p", ")", ":", "\n", "        ", "change", "=", "p", "-", "self", ".", "tree", "[", "tree_idx", "]", "\n", "self", ".", "tree", "[", "tree_idx", "]", "=", "p", "\n", "while", "tree_idx", "!=", "0", ":", "\n", "            ", "tree_idx", "=", "(", "tree_idx", "-", "1", ")", "//", "2", "\n", "self", ".", "tree", "[", "tree_idx", "]", "+=", "change", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.SumTree.get_leaf": [[40, 56], ["len"], "methods", ["None"], ["", "", "def", "get_leaf", "(", "self", ",", "v", ")", ":", "\n", "        ", "parent_idx", "=", "0", "\n", "while", "True", ":", "\n", "            ", "left_child_idx", "=", "2", "*", "parent_idx", "+", "1", "\n", "right_child_idx", "=", "left_child_idx", "+", "1", "\n", "if", "left_child_idx", ">=", "len", "(", "self", ".", "tree", ")", ":", "\n", "                ", "leaf_idx", "=", "parent_idx", "\n", "break", "\n", "", "if", "v", "<=", "self", ".", "tree", "[", "left_child_idx", "]", ":", "\n", "                ", "parent_idx", "=", "left_child_idx", "\n", "", "else", ":", "\n", "                ", "v", "-=", "self", ".", "tree", "[", "left_child_idx", "]", "\n", "parent_idx", "=", "right_child_idx", "\n", "\n", "", "", "data_idx", "=", "leaf_idx", "-", "self", ".", "capacity", "+", "1", "\n", "return", "leaf_idx", ",", "self", ".", "tree", "[", "leaf_idx", "]", ",", "self", ".", "data", "[", "data_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.SumTree.total_p": [[57, 60], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "total_p", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tree", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.Memory.__init__": [[71, 74], ["Memory.SumTree"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "capacity", ",", "permanent_data", "=", "0", ")", ":", "\n", "        ", "self", ".", "permanent_data", "=", "permanent_data", "\n", "self", ".", "tree", "=", "SumTree", "(", "capacity", ",", "permanent_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.Memory.__len__": [[75, 77], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tree", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.Memory.full": [[78, 80], ["None"], "methods", ["None"], ["", "def", "full", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tree", ".", "full", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.Memory.store": [[81, 86], ["numpy.max", "Memory.Memory.tree.add"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add"], ["", "def", "store", "(", "self", ",", "transition", ")", ":", "\n", "        ", "max_p", "=", "np", ".", "max", "(", "self", ".", "tree", ".", "tree", "[", "-", "self", ".", "tree", ".", "capacity", ":", "]", ")", "\n", "if", "max_p", "==", "0", ":", "\n", "            ", "max_p", "=", "self", ".", "abs_err_upper", "\n", "", "self", ".", "tree", ".", "add", "(", "max_p", ",", "transition", ")", "# set the max_p for new transition", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.Memory.sample": [[87, 105], ["Memory.Memory.full", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.min", "range", "numpy.min", "numpy.random.uniform", "Memory.Memory.tree.get_leaf", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.get_leaf"], ["", "def", "sample", "(", "self", ",", "n", ")", ":", "\n", "        ", "assert", "self", ".", "full", "(", ")", "\n", "b_idx", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "b_memory", "=", "np", ".", "empty", "(", "(", "n", ",", "self", ".", "tree", ".", "data", "[", "0", "]", ".", "size", ")", ",", "dtype", "=", "object", ")", "\n", "ISWeights", "=", "np", ".", "empty", "(", "(", "n", ",", "1", ")", ")", "\n", "pri_seg", "=", "self", ".", "tree", ".", "total_p", "/", "n", "\n", "self", ".", "beta", "=", "np", ".", "min", "(", "[", "1.", ",", "self", ".", "beta", "+", "self", ".", "beta_increment_per_sampling", "]", ")", "\n", "\n", "min_prob", "=", "np", ".", "min", "(", "self", ".", "tree", ".", "tree", "[", "-", "self", ".", "tree", ".", "capacity", ":", "]", ")", "/", "self", ".", "tree", ".", "total_p", "\n", "assert", "min_prob", ">", "0", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "v", "=", "np", ".", "random", ".", "uniform", "(", "pri_seg", "*", "i", ",", "pri_seg", "*", "(", "i", "+", "1", ")", ")", "\n", "idx", ",", "p", ",", "data", "=", "self", ".", "tree", ".", "get_leaf", "(", "v", ")", "# note: idx is the index in self.tree.tree", "\n", "prob", "=", "p", "/", "self", ".", "tree", ".", "total_p", "\n", "ISWeights", "[", "i", ",", "0", "]", "=", "np", ".", "power", "(", "prob", "/", "min_prob", ",", "-", "self", ".", "beta", ")", "\n", "b_idx", "[", "i", "]", ",", "b_memory", "[", "i", "]", "=", "idx", ",", "data", "\n", "", "return", "b_idx", ",", "b_memory", ",", "ISWeights", "# note: b_idx stores indexes in self.tree.tree, not in self.tree.data !!!", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.Memory.Memory.batch_update": [[107, 115], ["numpy.minimum", "numpy.power", "zip", "Memory.Memory.tree.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["", "def", "batch_update", "(", "self", ",", "tree_idxes", ",", "abs_errors", ")", ":", "\n", "        ", "abs_errors", "[", "self", ".", "tree", ".", "permanent_data", ":", "]", "+=", "self", ".", "epsilon", "\n", "# priorities of demo transitions are given a bonus of demo_epsilon, to boost the frequency that they are sampled", "\n", "abs_errors", "[", ":", "self", ".", "tree", ".", "permanent_data", "]", "+=", "self", ".", "demo_epsilon", "\n", "clipped_errors", "=", "np", ".", "minimum", "(", "abs_errors", ",", "self", ".", "abs_err_upper", ")", "\n", "ps", "=", "np", ".", "power", "(", "clipped_errors", ",", "self", ".", "alpha", ")", "\n", "for", "ti", ",", "p", "in", "zip", "(", "tree_idxes", ",", "ps", ")", ":", "\n", "            ", "self", ".", "tree", ".", "update", "(", "ti", ",", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.teamcompadvisor3admiralaesarsa.main": [[8, 128], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor3admiralaeteamcomp", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor3admiralaeteamcomp", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "action_list_next.append", "action_list_next.append", "action_list_next.append", "action_list_current.append", "action_list_current.append", "action_list_current.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_current_new.append", "action_list_current_new.append", "action_list_current_new.append", "agent_list[].store", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].store", "agent_list[].set", "open", "myfile.write", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert3offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action1_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action2_", "=", "-", "1", "\n", "\n", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action3_", "=", "-", "1", "\n", "\n", "", "action_list_next", "=", "[", "]", "\n", "action_list_next", ".", "append", "(", "actions_", ")", "\n", "action_list_next", ".", "append", "(", "actions2_", ")", "\n", "action_list_next", ".", "append", "(", "actions3_", ")", "\n", "\n", "action_list_current", "=", "[", "]", "\n", "action_list_current", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions0_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions0_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions1_new", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions2_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions3_new", "=", "-", "1", "\n", "\n", "", "action_list_next_new", "=", "[", "]", "\n", "action_list_next_new", ".", "append", "(", "actions0_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions1_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions2_new", ")", "\n", "\n", "action_list_current_new", "=", "[", "]", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list_current", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions1_", ",", "action_list_next", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_next", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list_current_new", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions3_new", ",", "action_list_next_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_next_new", ")", "\n", "\n", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert3offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.teamcompadvisor2admiralaesarsa.main": [[8, 129], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor2admiralaeteamcomp", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor2admiralaeteamcomp", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "action_list_next.append", "action_list_next.append", "action_list_next.append", "action_list_current.append", "action_list_current.append", "action_list_current.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_current_new.append", "action_list_current_new.append", "action_list_current_new.append", "agent_list[].store", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].store", "agent_list[].set", "open", "myfile.write", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert2offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action1_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action2_", "=", "-", "1", "\n", "\n", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action3_", "=", "-", "1", "\n", "\n", "", "action_list_next", "=", "[", "]", "\n", "action_list_next", ".", "append", "(", "actions_", ")", "\n", "action_list_next", ".", "append", "(", "actions2_", ")", "\n", "action_list_next", ".", "append", "(", "actions3_", ")", "\n", "\n", "action_list_current", "=", "[", "]", "\n", "action_list_current", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions0_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions0_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions1_new", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions2_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions3_new", "=", "-", "1", "\n", "\n", "\n", "\n", "", "action_list_next_new", "=", "[", "]", "\n", "action_list_next_new", ".", "append", "(", "actions0_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions1_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions2_new", ")", "\n", "\n", "action_list_current_new", "=", "[", "]", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list_current", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions1_", ",", "action_list_next", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_next", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list_current_new", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions3_new", ",", "action_list_next_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_next_new", ")", "\n", "\n", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert2offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.teamcompadvisor4admiralaesarsa.main": [[8, 129], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor4admiralaeteamcomp", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor4admiralaeteamcomp", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "action_list_next.append", "action_list_next.append", "action_list_next.append", "action_list_current.append", "action_list_current.append", "action_list_current.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_current_new.append", "action_list_current_new.append", "action_list_current_new.append", "agent_list[].store", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].store", "agent_list[].set", "open", "myfile.write", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert4offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action1_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action2_", "=", "-", "1", "\n", "\n", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action3_", "=", "-", "1", "\n", "\n", "\n", "\n", "", "action_list_next", "=", "[", "]", "\n", "action_list_next", ".", "append", "(", "actions_", ")", "\n", "action_list_next", ".", "append", "(", "actions2_", ")", "\n", "action_list_next", ".", "append", "(", "actions3_", ")", "\n", "\n", "action_list_current", "=", "[", "]", "\n", "action_list_current", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions0_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions0_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions1_new", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions2_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions3_new", "=", "-", "1", "\n", "\n", "", "action_list_next_new", "=", "[", "]", "\n", "action_list_next_new", ".", "append", "(", "actions0_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions1_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions2_new", ")", "\n", "\n", "action_list_current_new", "=", "[", "]", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list_current", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions1_", ",", "action_list_next", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_next", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list_current_new", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions3_new", ",", "action_list_next_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_next_new", ")", "\n", "\n", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert4offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.admiraldmvsdeepsarsa_advisor3.main": [[8, 82], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor3", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor3", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "action_list.append", "action_list.append", "action_list.append", "action_list2.append", "action_list2.append", "action_list2.append", "action_list_new.append", "action_list_new.append", "action_list_new.append", "action_list_new2.append", "action_list_new2.append", "action_list_new2.append", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert3.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "action_list_new", "=", "[", "]", "\n", "action_list_new2", "=", "[", "]", "\n", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "3", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "1", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list", ",", "action_list_new", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_new", "[", "1", "]", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list2", ",", "action_list_new2", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions_new", "[", "3", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_new2", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "cumulative_rewards", "[", "2", "]", "=", "cumulative_rewards", "[", "2", "]", "+", "reward", "[", "2", "]", "\n", "cumulative_rewards", "[", "3", "]", "=", "cumulative_rewards", "[", "3", "]", "+", "reward", "[", "3", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert3.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0}, {1}, {2}, {3}, {4}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ",", "cumulative_rewards", "[", "2", "]", ",", "cumulative_rewards", "[", "3", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.admiraldmvsdeepsarsa_advisor1.main": [[9, 83], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor1", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor1", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "action_list.append", "action_list.append", "action_list.append", "action_list2.append", "action_list2.append", "action_list2.append", "action_list_new.append", "action_list_new.append", "action_list_new.append", "action_list_new2.append", "action_list_new2.append", "action_list_new2.append", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert1.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "action_list_new", "=", "[", "]", "\n", "action_list_new2", "=", "[", "]", "\n", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "3", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "1", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list", ",", "action_list_new", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_new", "[", "1", "]", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list2", ",", "action_list_new2", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions_new", "[", "3", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_new2", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "cumulative_rewards", "[", "2", "]", "=", "cumulative_rewards", "[", "2", "]", "+", "reward", "[", "2", "]", "\n", "cumulative_rewards", "[", "3", "]", "=", "cumulative_rewards", "[", "3", "]", "+", "reward", "[", "3", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert1.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0}, {1}, {2}, {3}, {4}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ",", "cumulative_rewards", "[", "2", "]", ",", "cumulative_rewards", "[", "3", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.__init__": [[11, 55], ["numpy.zeros", "tensorflow.placeholder", "tensorflow.one_hot", "RL_brain_CHAT.CHAT._build_net", "RL_brain_CHAT.CHAT._build_confidence_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT._build_confidence_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "1000", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "+", "1", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "4", ")", ")", "\n", "\n", "self", ".", "advisor_act", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ",", "name", "=", "'CHAT_advisor_act'", ")", "\n", "self", ".", "advisor_one_hot", "=", "tf", ".", "one_hot", "(", "self", ".", "advisor_act", ",", "depth", "=", "self", ".", "n_actions", "-", "1", ",", "on_value", "=", "1.0", ",", "off_value", "=", "0.0", ")", "\n", "self", ".", "_build_net", "(", ")", "\n", "self", ".", "_build_confidence_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'CHAT_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'CHAT_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.copy_network": [[58, 63], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT._build_net": [[64, 115], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'CHAT_s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'CHAT_Q_target_1'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'CHATValue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_eval_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'CHAT_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'CHAT_s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_target_net_1'", ")", ":", "\n", "                ", "c_names", "=", "[", "'CHAT_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT._build_confidence_net": [[116, 143], ["tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "", "", "", "def", "_build_confidence_net", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'ConfidenceValue'", ")", ":", "\n", "            ", "self", ".", "name_scope2", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_confidence_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'CHAT_confidence_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_3'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_3'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_3'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_3'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_3'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_3'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_4'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_4'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "-", "1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_4'", ",", "[", "1", ",", "self", ".", "n_actions", "-", "1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_confidence", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_loss2'", ")", ":", "\n", "                ", "self", ".", "loss2", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "advisor_one_hot", ",", "self", ".", "q_confidence", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_train2'", ")", ":", "\n", "                ", "self", ".", "_train_op2", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.store_transition": [[144, 154], ["numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ",", "a_", ",", "advisor_a", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", ",", "advisor_a", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.choose_action": [[155, 165], ["numpy.random.uniform", "RL_brain_CHAT.CHAT.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.get_confidence": [[166, 173], ["RL_brain_CHAT.CHAT.sess.run", "numpy.exp", "sum", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "get_confidence", "(", "self", ",", "observation", ",", "action", ")", ":", "\n", "        ", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "confidence_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_confidence", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "confidence_value", "=", "confidence_value", "[", "0", "]", "\n", "confidence", "=", "np", ".", "exp", "(", "confidence_value", ")", "/", "sum", "(", "np", ".", "exp", "(", "confidence_value", ")", ")", "\n", "action_confidence", "=", "confidence", "[", "action", "]", "\n", "return", "action_confidence", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.learn": [[174, 211], ["RL_brain_CHAT.CHAT.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "batch_memory[].astype", "batch_memory[].astype", "RL_brain_CHAT.CHAT.sess.run", "RL_brain_CHAT.CHAT.cost_his.append", "RL_brain_CHAT.CHAT.sess.run", "RL_brain_CHAT.CHAT.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "2", "]", ".", "astype", "(", "int", ")", "\n", "advisor_a", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "_", ",", "self", ".", "cost2", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op2", ",", "self", ".", "loss2", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "advisor_act", ":", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", "}", ")", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.save_model": [[213, 218], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.restore_model": [[221, 226], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.save_confidence_model": [[227, 232], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_confidence_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.restore_confidence_model": [[235, 240], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_confidence_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_CHAT.CHAT.plot_cost": [[242, 248], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.__init__": [[11, 53], ["numpy.zeros", "RL_brain_admiralae.AdmiralaeNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "9", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Advisorae_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Advisorae_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.copy_network": [[54, 59], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork._build_net": [[62, 114], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorae_s'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Advisorae_Q_target'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiralaeValue'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_eval_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Advisorae_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorae_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorae_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorae_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorae_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_loss'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_train'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorae_s_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_target_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", "=", "[", "'Advisorae_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorae_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorae_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_hl1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorae_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorae_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.store_transition": [[115, 139], ["list", "range", "numpy.array", "list", "range", "numpy.array", "numpy.hstack", "hasattr", "len", "float", "numpy.array.append", "len", "float", "float", "numpy.array.append"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "a1", ",", "r", ",", "s_", ",", "a_", ",", "a1_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "", "s", "=", "list", "(", "s", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1", ")", ")", ":", "\n", "            ", "new_a", "=", "a1", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s", ".", "append", "(", "new_a", ")", "\n", "\n", "", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "a1_", ")", ")", ":", "\n", "            ", "new_a", "=", "float", "(", "a1_", "[", "i", "]", ")", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s_", ".", "append", "(", "new_a", ")", "\n", "", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "\n", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.choose_action": [[140, 157], ["list", "range", "numpy.array", "len", "float", "numpy.array.append", "numpy.random.uniform", "RL_brain_admiralae.AdmiralaeNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "a2", ")", ":", "\n", "\n", "        ", "observation", "=", "list", "(", "observation", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a2", ")", ")", ":", "\n", "            ", "new_a", "=", "a2", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "observation", ".", "append", "(", "new_a", ")", "\n", "", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.learn": [[158, 190], ["RL_brain_admiralae.AdmiralaeNetwork.sess.run", "q_eval.copy", "batch_memory[].astype", "numpy.arange", "batch_memory[].astype", "RL_brain_admiralae.AdmiralaeNetwork.sess.run", "RL_brain_admiralae.AdmiralaeNetwork.cost_his.append", "RL_brain_admiralae.AdmiralaeNetwork.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "(", "self", ".", "n_features", "+", "3", ")", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "5", "]", ".", "astype", "(", "int", ")", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "4", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.save_model": [[192, 197], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.restore_model": [[200, 205], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiralae.AdmiralaeNetwork.plot_cost": [[207, 213], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_DQN.DeepQNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "2", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.copy_network": [[55, 60], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork._build_net": [[61, 111], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Q_target_1'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'DQN_value'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'eval_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_h1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'w_h1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'b_h1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'target_net_1'", ")", ":", "\n", "                ", "c_names", "=", "[", "'target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_h1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'w_h1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'b_h1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.store_transition": [[112, 121], ["numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.choose_action": [[122, 132], ["numpy.random.uniform", "RL_brain_DQN.DeepQNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.learn": [[133, 165], ["RL_brain_DQN.DeepQNetwork.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "RL_brain_DQN.DeepQNetwork.sess.run", "RL_brain_DQN.DeepQNetwork.cost_his.append", "RL_brain_DQN.DeepQNetwork.sess.run", "numpy.random.choice", "numpy.random.choice", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "np", ".", "max", "(", "q_next", ",", "axis", "=", "1", ")", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.save_model": [[166, 171], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.restore_model": [[174, 179], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_DQN.DeepQNetwork.plot_cost": [[182, 188], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Actor.__init__": [[16, 59], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "n_actions", ",", "lr", "=", "0.001", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "a", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "None", ",", "\"Advisorac_act\"", ")", "\n", "self", ".", "td_error", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "\"Advisorac_td_error\"", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Admiraldmacactorvalue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Actor'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "acts_prob", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "n_actions", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "softmax", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_acts_prob'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_exp_v'", ")", ":", "\n", "                ", "log_prob", "=", "tf", ".", "log", "(", "self", ".", "acts_prob", "[", "0", ",", "self", ".", "a", "]", ")", "\n", "self", ".", "exp_v", "=", "tf", ".", "reduce_mean", "(", "log_prob", "*", "self", ".", "td_error", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "-", "self", ".", "exp_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Actor.learn": [[60, 65], ["RL_brain_admiraldmac.Actor.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "", "", "def", "learn", "(", "self", ",", "s", ",", "a", ",", "td", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "s", ",", "self", ".", "a", ":", "a", ",", "self", ".", "td_error", ":", "td", "}", "\n", "_", ",", "exp_v", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "exp_v", "]", ",", "feed_dict", ")", "\n", "return", "exp_v", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Actor.choose_action": [[66, 70], ["RL_brain_admiraldmac.Actor.sess.run", "numpy.random.choice", "numpy.arange", "RL_brain_admiraldmac.Actor.ravel"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "s", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "probs", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "acts_prob", ",", "{", "self", ".", "s", ":", "s", "}", ")", "\n", "return", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "probs", ".", "shape", "[", "1", "]", ")", ",", "p", "=", "probs", ".", "ravel", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Actor.save_model": [[71, 76], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Actor.restore_model": [[77, 82], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Critic.__init__": [[89, 131], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.square", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "lr", "=", "0.01", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "+", "1", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "v_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "1", "]", ",", "\"Advisorac_v_next\"", ")", "\n", "self", ".", "r", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "'Advisorac_r'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiraldmacCritic'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Critic'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "v", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "1", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_V'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'squared_TD_error'", ")", ":", "\n", "                ", "self", ".", "td_error", "=", "self", ".", "r", "+", "GAMMA", "*", "self", ".", "v_", "-", "self", ".", "v", "\n", "self", ".", "loss", "=", "tf", ".", "square", "(", "self", ".", "td_error", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Critic.learn": [[132, 146], ["list", "float", "numpy.array.append", "numpy.array", "list", "float", "numpy.array.append", "numpy.array", "RL_brain_admiraldmac.Critic.sess.run", "RL_brain_admiraldmac.Critic.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "", "", "def", "learn", "(", "self", ",", "s", ",", "opp_a", ",", "r", ",", "s_", ",", "opp_a_", ")", ":", "\n", "        ", "s", "=", "list", "(", "s", ")", "\n", "a1", "=", "float", "(", "opp_a", ")", "\n", "s", ".", "append", "(", "a1", ")", "\n", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "a2", "=", "float", "(", "opp_a_", ")", "\n", "s_", ".", "append", "(", "a2", ")", "\n", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "s", ",", "s_", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", ",", "s_", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "v_", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "v", ",", "{", "self", ".", "s", ":", "s_", "}", ")", "\n", "td_error", ",", "_", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "td_error", ",", "self", ".", "train_op", "]", ",", "\n", "{", "self", ".", "s", ":", "s", ",", "self", ".", "v_", ":", "v_", ",", "self", ".", "r", ":", "r", "}", ")", "\n", "return", "td_error", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Critic.save_model": [[147, 152], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.RL_brain_admiraldmac.Critic.restore_model": [[153, 158], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.__init__": [[26, 59], ["Memory.Memory.Memory", "Memory.Memory.Memory", "DQfD_V3.DQfD.add_demo_to_memory", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.train.Saver", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.save_model", "DQfD_V3.DQfD.restore_model", "tensorflow.global_variables_initializer", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.add_demo_to_memory", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.restore_model"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "nf", ",", "na", ",", "config", ",", "demo_transitions", "=", "None", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "replay_memory", "=", "Memory", "(", "capacity", "=", "self", ".", "config", ".", "replay_buffer_size", ",", "permanent_data", "=", "len", "(", "demo_transitions", ")", ")", "\n", "self", ".", "demo_memory", "=", "Memory", "(", "capacity", "=", "self", ".", "config", ".", "demo_buffer_size", ",", "permanent_data", "=", "self", ".", "config", ".", "demo_buffer_size", ")", "\n", "self", ".", "add_demo_to_memory", "(", "demo_transitions", "=", "demo_transitions", ")", "\n", "self", ".", "time_step", "=", "0", "\n", "self", ".", "epsilon", "=", "self", ".", "config", ".", "INITIAL_EPSILON", "\n", "self", ".", "state_dim", "=", "nf", "\n", "self", ".", "action_dim", "=", "na", "\n", "\n", "self", ".", "action_batch", "=", "tf", ".", "placeholder", "(", "\"int32\"", ",", "[", "None", "]", ")", "\n", "self", ".", "y_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "action_dim", "]", ")", "\n", "self", ".", "ISWeights", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "1", "]", ")", "\n", "self", ".", "n_step_y_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "action_dim", "]", ")", "\n", "self", ".", "isdemo", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", "]", ")", "\n", "self", ".", "eval_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "state_dim", "]", ")", "\n", "self", ".", "select_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "state_dim", "]", ")", "\n", "\n", "self", ".", "Q_eval", "\n", "self", ".", "Q_select", "\n", "\n", "self", ".", "loss", "\n", "self", ".", "optimize", "\n", "self", ".", "update_target_net", "\n", "self", ".", "abs_errors", "\n", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "self", ".", "save_model", "(", ")", "\n", "self", ".", "restore_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.add_demo_to_memory": [[60, 65], ["DQfD_V3.DQfD.demo_memory.store", "DQfD_V3.DQfD.replay_memory.store", "numpy.array", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["", "def", "add_demo_to_memory", "(", "self", ",", "demo_transitions", ")", ":", "\n", "        ", "for", "t", "in", "demo_transitions", ":", "\n", "            ", "self", ".", "demo_memory", ".", "store", "(", "np", ".", "array", "(", "t", ",", "dtype", "=", "object", ")", ")", "\n", "self", ".", "replay_memory", ".", "store", "(", "np", ".", "array", "(", "t", ",", "dtype", "=", "object", ")", ")", "\n", "assert", "len", "(", "t", ")", "==", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.pre_train": [[66, 74], ["print", "range", "print", "DQfD_V3.DQfD.train_Q_network", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network"], ["", "", "def", "pre_train", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Pre-training ...'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "config", ".", "PRETRAIN_STEPS", ")", ":", "\n", "            ", "self", ".", "train_Q_network", "(", "pre_train", "=", "True", ")", "\n", "if", "i", "%", "200", "==", "0", "and", "i", ">", "0", ":", "\n", "                ", "print", "(", "'{} th step of pre-train finish ...'", ".", "format", "(", "i", ")", ")", "\n", "", "", "self", ".", "time_step", "=", "0", "\n", "print", "(", "'All pre-train finish.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.build_layers": [[76, 91], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "build_layers", "(", "self", ",", "state", ",", "c_names", ",", "units_1", ",", "units_2", ",", "w_i", ",", "b_i", ",", "reg", "=", "None", ")", ":", "\n", "        ", "a_d", "=", "self", ".", "action_dim", "\n", "with", "tf", ".", "variable_scope", "(", "'DQfD_l1'", ")", ":", "\n", "            ", "w1", "=", "tf", ".", "get_variable", "(", "'DQfD_w1'", ",", "[", "self", ".", "state_dim", ",", "units_1", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'DQfD_b1'", ",", "[", "1", ",", "units_1", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "state", ",", "w1", ")", "+", "b1", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'DQfD_l2'", ")", ":", "\n", "            ", "w2", "=", "tf", ".", "get_variable", "(", "'DQfD_w2'", ",", "[", "units_1", ",", "units_2", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'DQfD_b2'", ",", "[", "1", ",", "units_2", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense2", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "dense1", ",", "w2", ")", "+", "b2", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'DQfD_l3'", ")", ":", "\n", "            ", "w3", "=", "tf", ".", "get_variable", "(", "'DQfD_w3'", ",", "[", "units_2", ",", "a_d", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b3", "=", "tf", ".", "get_variable", "(", "'DQfD_b3'", ",", "[", "1", ",", "a_d", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense3", "=", "tf", ".", "matmul", "(", "dense2", ",", "w3", ")", "+", "b3", "\n", "", "return", "dense3", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.Q_select": [[92, 100], ["tensorflow.variable_scope", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "tensorflow.keras.regularizers.l2", "DQfD_V3.DQfD.build_layers"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.build_layers"], ["", "@", "lazy_property", "\n", "def", "Q_select", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'DQfD_select_net'", ")", "as", "scope", ":", "\n", "            ", "c_names", "=", "[", "'DQfD_select_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "w_i", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", "\n", "b_i", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "reg", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l", "=", "0.2", ")", "\n", "return", "self", ".", "build_layers", "(", "self", ".", "select_input", ",", "c_names", ",", "24", ",", "24", ",", "w_i", ",", "b_i", ",", "reg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.Q_eval": [[101, 108], ["tensorflow.variable_scope", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "DQfD_V3.DQfD.build_layers"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.build_layers"], ["", "", "@", "lazy_property", "\n", "def", "Q_eval", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'DQfD_eval_net'", ")", "as", "scope", ":", "\n", "            ", "c_names", "=", "[", "'DQfD_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "w_i", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", "\n", "b_i", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "return", "self", ".", "build_layers", "(", "self", ".", "eval_input", ",", "c_names", ",", "24", ",", "24", ",", "w_i", ",", "b_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.loss_l": [[109, 111], ["None"], "methods", ["None"], ["", "", "def", "loss_l", "(", "self", ",", "ae", ",", "a", ")", ":", "\n", "        ", "return", "0.0", "if", "ae", "==", "a", "else", "0.8", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.loss_jeq": [[112, 121], ["range", "float", "range", "tensorflow.maximum", "DQfD_V3.DQfD.loss_l"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_l"], ["", "def", "loss_jeq", "(", "self", ",", "Q_select", ")", ":", "\n", "        ", "jeq", "=", "0.0", "\n", "for", "i", "in", "range", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", ":", "\n", "            ", "ae", "=", "self", ".", "action_batch", "[", "i", "]", "\n", "max_value", "=", "float", "(", "\"-inf\"", ")", "\n", "for", "a", "in", "range", "(", "self", ".", "action_dim", ")", ":", "\n", "                ", "max_value", "=", "tf", ".", "maximum", "(", "Q_select", "[", "i", "]", "[", "a", "]", "+", "self", ".", "loss_l", "(", "ae", ",", "a", ")", ",", "max_value", ")", "\n", "", "jeq", "+=", "self", ".", "isdemo", "[", "i", "]", "*", "(", "max_value", "-", "Q_select", "[", "i", "]", "[", "ae", "]", ")", "\n", "", "return", "jeq", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.loss": [[122, 129], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "DQfD_V3.DQfD.loss_jeq", "tensorflow.reduce_sum", "tensorflow.squared_difference", "tensorflow.squared_difference", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.get_collection", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_jeq"], ["", "@", "lazy_property", "\n", "def", "loss", "(", "self", ")", ":", "\n", "        ", "l_dq", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "Q_select", ",", "self", ".", "y_input", ")", ")", "\n", "l_n_dq", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "Q_select", ",", "self", ".", "n_step_y_input", ")", ")", "\n", "l_jeq", "=", "self", ".", "loss_jeq", "(", "self", ".", "Q_select", ")", "\n", "l_l2", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_mean", "(", "reg_l", ")", "for", "reg_l", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "]", ")", "\n", "return", "self", ".", "ISWeights", "*", "tf", ".", "reduce_sum", "(", "[", "l", "*", "\u03bb", "for", "l", ",", "\u03bb", "in", "zip", "(", "[", "l_dq", ",", "l_n_dq", ",", "l_jeq", ",", "l_l2", "]", ",", "self", ".", "config", ".", "LAMBDA", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.abs_errors": [[130, 133], ["tensorflow.reduce_sum", "tensorflow.abs"], "methods", ["None"], ["", "@", "lazy_property", "\n", "def", "abs_errors", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "self", ".", "y_input", "-", "self", ".", "Q_select", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.optimize": [[134, 138], ["tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize"], "methods", ["None"], ["", "@", "lazy_property", "\n", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "config", ".", "LEARNING_RATE", ")", "\n", "return", "optimizer", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.update_target_net": [[139, 144], ["tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "zip"], "methods", ["None"], ["", "@", "lazy_property", "\n", "def", "update_target_net", "(", "self", ")", ":", "\n", "        ", "select_params", "=", "tf", ".", "get_collection", "(", "'DQfD_select_net_params'", ")", "\n", "eval_params", "=", "tf", ".", "get_collection", "(", "'DQfD_eval_net_params'", ")", "\n", "return", "[", "tf", ".", "assign", "(", "e", ",", "s", ")", "for", "e", ",", "s", "in", "zip", "(", "eval_params", ",", "select_params", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.save_model": [[145, 147], ["print", "DQfD_V3.DQfD.saver.save"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Model saved in : {}\"", ".", "format", "(", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "self", ".", "config", ".", "MODEL_PATH", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.restore_model": [[148, 151], ["DQfD_V3.DQfD.saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "saver", ".", "restore", "(", "self", ".", "sess", ",", "self", ".", "config", ".", "MODEL_PATH", ")", "\n", "print", "(", "\"Model restored.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.perceive": [[152, 154], ["DQfD_V3.DQfD.replay_memory.store", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["", "def", "perceive", "(", "self", ",", "transition", ")", ":", "\n", "        ", "self", ".", "replay_memory", ".", "store", "(", "np", ".", "array", "(", "transition", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.train_Q_network": [[155, 211], ["actual_memory.sample", "numpy.random.shuffle", "DQfD_V3.DQfD.Q_select.eval", "DQfD_V3.DQfD.Q_eval.eval", "DQfD_V3.DQfD.Q_select.eval", "DQfD_V3.DQfD.Q_eval.eval", "numpy.zeros", "numpy.zeros", "range", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.replay_memory.batch_update", "DQfD_V3.DQfD.replay_memory.full", "numpy.copy", "numpy.argmax", "numpy.argmax", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.replay_memory.full", "DQfD_V3.DQfD.Q_select.eval", "int", "state_batch[].reshape", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.batch_update", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full"], ["", "def", "train_Q_network", "(", "self", ",", "pre_train", "=", "False", ",", "update", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        :param pre_train: True means should sample from demo_buffer instead of replay_buffer\n        :param update: True means the action \"update_target_net\" executes outside, and can be ignored in the function\n        \"\"\"", "\n", "if", "not", "pre_train", "and", "not", "self", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "            ", "return", "\n", "", "self", ".", "time_step", "+=", "1", "\n", "\n", "assert", "self", ".", "replay_memory", ".", "full", "(", ")", "or", "pre_train", "\n", "\n", "actual_memory", "=", "self", ".", "demo_memory", "if", "pre_train", "else", "self", ".", "replay_memory", "\n", "tree_idxes", ",", "minibatch", ",", "ISWeights", "=", "actual_memory", ".", "sample", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", "\n", "\n", "np", ".", "random", ".", "shuffle", "(", "minibatch", ")", "\n", "state_batch", "=", "[", "data", "[", "0", "]", "for", "data", "in", "minibatch", "]", "\n", "action_batch", "=", "[", "data", "[", "1", "]", "for", "data", "in", "minibatch", "]", "\n", "reward_batch", "=", "[", "data", "[", "2", "]", "for", "data", "in", "minibatch", "]", "\n", "next_state_batch", "=", "[", "data", "[", "3", "]", "for", "data", "in", "minibatch", "]", "\n", "done_batch", "=", "[", "data", "[", "4", "]", "for", "data", "in", "minibatch", "]", "\n", "demo_data", "=", "[", "data", "[", "5", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_reward_batch", "=", "[", "data", "[", "6", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_state_batch", "=", "[", "data", "[", "7", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_done_batch", "=", "[", "data", "[", "8", "]", "for", "data", "in", "minibatch", "]", "\n", "actual_n", "=", "[", "data", "[", "9", "]", "for", "data", "in", "minibatch", "]", "\n", "\n", "Q_select", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "next_state_batch", "}", ")", "\n", "Q_eval", "=", "self", ".", "Q_eval", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "eval_input", ":", "next_state_batch", "}", ")", "\n", "n_step_Q_select", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "n_step_state_batch", "}", ")", "\n", "n_step_Q_eval", "=", "self", ".", "Q_eval", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "eval_input", ":", "n_step_state_batch", "}", ")", "\n", "\n", "y_batch", "=", "np", ".", "zeros", "(", "(", "self", ".", "config", ".", "BATCH_SIZE", ",", "self", ".", "action_dim", ")", ")", "\n", "n_step_y_batch", "=", "np", ".", "zeros", "(", "(", "self", ".", "config", ".", "BATCH_SIZE", ",", "self", ".", "action_dim", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", ":", "\n", "            ", "temp", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "state_batch", "[", "i", "]", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "state_dim", ")", ")", "}", ")", "[", "0", "]", "\n", "temp_0", "=", "np", ".", "copy", "(", "temp", ")", "\n", "action", "=", "np", ".", "argmax", "(", "Q_select", "[", "i", "]", ")", "\n", "temp", "[", "action_batch", "[", "i", "]", "]", "=", "reward_batch", "[", "i", "]", "+", "(", "1", "-", "int", "(", "done_batch", "[", "i", "]", ")", ")", "*", "self", ".", "config", ".", "GAMMA", "*", "Q_eval", "[", "i", "]", "[", "action", "]", "\n", "y_batch", "[", "i", "]", "=", "temp", "\n", "action", "=", "np", ".", "argmax", "(", "n_step_Q_select", "[", "i", "]", ")", "\n", "q_n_step", "=", "(", "1", "-", "int", "(", "n_step_done_batch", "[", "i", "]", ")", ")", "*", "self", ".", "config", ".", "GAMMA", "**", "actual_n", "[", "i", "]", "*", "n_step_Q_eval", "[", "i", "]", "[", "action", "]", "\n", "temp_0", "[", "action_batch", "[", "i", "]", "]", "=", "n_step_reward_batch", "[", "i", "]", "+", "q_n_step", "\n", "n_step_y_batch", "[", "i", "]", "=", "temp_0", "\n", "\n", "", "_", ",", "abs_errors", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "optimize", ",", "self", ".", "abs_errors", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "y_input", ":", "y_batch", ",", "\n", "self", ".", "n_step_y_input", ":", "n_step_y_batch", ",", "\n", "self", ".", "select_input", ":", "state_batch", ",", "\n", "self", ".", "action_batch", ":", "action_batch", ",", "\n", "self", ".", "isdemo", ":", "demo_data", ",", "\n", "self", ".", "ISWeights", ":", "ISWeights", "}", ")", "\n", "\n", "self", ".", "replay_memory", ".", "batch_update", "(", "tree_idxes", ",", "abs_errors", ")", "\n", "\n", "if", "update", "and", "self", ".", "time_step", "%", "self", ".", "config", ".", "UPDATE_TARGET_NET", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.DQfD.egreedy_action": [[212, 218], ["numpy.argmax", "random.random", "random.randint", "DQfD_V3.DQfD.Q_select.eval"], "methods", ["None"], ["", "", "def", "egreedy_action", "(", "self", ",", "state", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "0", "\n", "", "if", "random", ".", "random", "(", ")", "<=", "self", ".", "epsilon", ":", "\n", "            ", "return", "random", ".", "randint", "(", "0", ",", "self", ".", "action_dim", "-", "1", ")", "\n", "", "return", "np", ".", "argmax", "(", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "[", "state", "]", "}", ")", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.DQfD_V3.lazy_property": [[13, 23], ["functools.wraps", "getattr", "hasattr", "setattr", "func"], "function", ["None"], ["def", "lazy_property", "(", "func", ")", ":", "\n", "    ", "attribute", "=", "'_lazy_'", "+", "func", ".", "__name__", "\n", "\n", "@", "property", "\n", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "attribute", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "attribute", ",", "func", "(", "self", ")", ")", "\n", "", "return", "getattr", "(", "self", ",", "attribute", ")", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.admiraldmvsdeepsarsa_advisor4.main": [[8, 84], ["print", "tensorflow.Session", "tf.Session.run", "pommerman.make", "pommerman.make.seed", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor4", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor4", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "action_list.append", "action_list.append", "action_list.append", "action_list2.append", "action_list2.append", "action_list2.append", "action_list_new.append", "action_list_new.append", "action_list_new.append", "action_list_new2.append", "action_list_new2.append", "action_list_new2.append", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert4.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "400000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "action_list_new", "=", "[", "]", "\n", "action_list_new2", "=", "[", "]", "\n", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "3", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "1", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list", ",", "action_list_new", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_new", "[", "1", "]", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list2", ",", "action_list_new2", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions_new", "[", "3", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_new2", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "cumulative_rewards", "[", "2", "]", "=", "cumulative_rewards", "[", "2", "]", "+", "reward", "[", "2", "]", "\n", "cumulative_rewards", "[", "3", "]", "=", "cumulative_rewards", "[", "3", "]", "+", "reward", "[", "3", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert4.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0}, {1}, {2}, {3}, {4}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ",", "cumulative_rewards", "[", "2", "]", ",", "cumulative_rewards", "[", "3", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.admiraldmvsdeepsarsa_advisor2.main": [[8, 82], ["print", "tensorflow.Session", "tf.Session.run", "pommerman.make", "pommerman.make.seed", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor2", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor2", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "action_list.append", "action_list.append", "action_list.append", "action_list2.append", "action_list2.append", "action_list2.append", "action_list_new.append", "action_list_new.append", "action_list_new.append", "action_list_new2.append", "action_list_new2.append", "action_list_new2.append", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert2.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "action_list_new", "=", "[", "]", "\n", "action_list_new2", "=", "[", "]", "\n", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "action_list_new", ".", "append", "(", "actions_new", "[", "3", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "0", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "1", "]", ")", "\n", "action_list_new2", ".", "append", "(", "actions_new", "[", "2", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list", ",", "action_list_new", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_new", "[", "1", "]", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list2", ",", "action_list_new2", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions_new", "[", "3", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_new2", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "cumulative_rewards", "[", "2", "]", "=", "cumulative_rewards", "[", "2", "]", "+", "reward", "[", "2", "]", "\n", "cumulative_rewards", "[", "3", "]", "=", "cumulative_rewards", "[", "3", "]", "+", "reward", "[", "3", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert2.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0}, {1}, {2}, {3}, {4}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ",", "cumulative_rewards", "[", "2", "]", ",", "cumulative_rewards", "[", "3", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.teamcompetition.teamcompadvisor1admiralaesarsa.main": [[8, 130], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor1admiralaeteamcomp", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor1admiralaeteamcomp", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "action_list_next.append", "action_list_next.append", "action_list_next.append", "action_list_current.append", "action_list_current.append", "action_list_current.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_next_new.append", "action_list_current_new.append", "action_list_current_new.append", "action_list_current_new.append", "agent_list[].store", "agent_list[].store", "agent_list[].store", "agent_list[].set", "agent_list[].store", "agent_list[].set", "open", "myfile.write", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2", "agent_list[].act2"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1admiralaeteamcomp", "(", "372", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert1offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action1_", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action2_", "=", "-", "1", "\n", "\n", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "action3_", "=", "-", "1", "\n", "\n", "", "action_list_next", "=", "[", "]", "\n", "action_list_next", ".", "append", "(", "actions_", ")", "\n", "action_list_next", ".", "append", "(", "actions2_", ")", "\n", "action_list_next", ".", "append", "(", "actions3_", ")", "\n", "\n", "action_list_current", "=", "[", "]", "\n", "action_list_current", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list_current", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "if", "agent_list", "[", "0", "]", ".", "is_alive", ":", "\n", "                ", "actions0_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions0_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "1", "]", ".", "is_alive", ":", "\n", "                ", "actions1_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions1_new", "=", "-", "1", "\n", "\n", "\n", "", "if", "agent_list", "[", "2", "]", ".", "is_alive", ":", "\n", "                ", "actions2_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "2", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions2_new", "=", "-", "1", "\n", "\n", "", "if", "agent_list", "[", "3", "]", ".", "is_alive", ":", "\n", "                ", "actions3_new", "=", "agent_list", "[", "3", "]", ".", "act2", "(", "state_new", "[", "3", "]", ",", "env", ".", "action_space", ")", "\n", "", "else", ":", "\n", "                ", "actions3_new", "=", "-", "1", "\n", "\n", "\n", "\n", "", "action_list_next_new", "=", "[", "]", "\n", "action_list_next_new", ".", "append", "(", "actions0_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions1_new", ")", "\n", "action_list_next_new", ".", "append", "(", "actions2_new", ")", "\n", "\n", "action_list_current_new", "=", "[", "]", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list_current_new", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "action_list_current", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions1_", ",", "action_list_next", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "action_list_next", ")", "\n", "agent_list", "[", "3", "]", ".", "store", "(", "state", "[", "3", "]", ",", "actions", "[", "3", "]", ",", "action_list_current_new", ",", "reward", "[", "3", "]", ",", "state_new", "[", "3", "]", ",", "actions3_new", ",", "action_list_next_new", ")", "\n", "agent_list", "[", "3", "]", ".", "set", "(", "action_list_next_new", ")", "\n", "\n", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "2", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "3", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert1offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor3admiralae.main": [[8, 53], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DQNAgent", "pommerman.agents.Advisor3admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert3offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions2_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert3offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.chatvsadmiraldm.main": [[8, 50], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.Advisor1admiraldm", "pommerman.agents.CHATAgent", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "Advisor1admiraldm", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "CHATAgent", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1chat.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(ExpertQ)\"", ",", "\"Reward2(CHAT)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "50000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "actions", "[", "1", "]", ",", "actions_new", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_new", "[", "1", "]", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "agent_list", "[", "0", "]", ".", "set", "(", "actions_new", "[", "1", "]", ")", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1chat.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_admiraldm2.AdmiralDMNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "5", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Advisorq2_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Advisorq2_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.copy_network": [[53, 58], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork._build_net": [[61, 111], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "1", "]", ",", "name", "=", "'Advisorq2_s'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Advisorq2_Q_target'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiralValue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_eval_net'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Advisorq2_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w1'", ",", "[", "self", ".", "n_features", "+", "1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_lh1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_wh1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_bh1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "1", "]", ",", "name", "=", "'Advisorq2_s_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_target_net'", ")", ":", "\n", "                ", "c_names", "=", "[", "'Advisorq2_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w1'", ",", "[", "self", ".", "n_features", "+", "1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_lh1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_wh1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq2_bh1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq2_l2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq2_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.store_transition": [[112, 131], ["list", "float", "numpy.array.append", "numpy.array", "list", "float", "numpy.array.append", "numpy.array", "numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "a1", ",", "a2", ",", "r", ",", "s_", ",", "a_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "s", "=", "list", "(", "s", ")", "\n", "a1", "=", "float", "(", "a1", ")", "\n", "s", ".", "append", "(", "a1", ")", "\n", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "a2", "=", "float", "(", "a2", ")", "\n", "s_", ".", "append", "(", "a2", ")", "\n", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "\n", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.choose_action": [[132, 147], ["list", "float", "numpy.array.append", "numpy.array", "numpy.random.uniform", "RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "a2", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "list", "(", "observation", ")", "\n", "a2", "=", "float", "(", "a2", ")", "\n", "observation", ".", "append", "(", "a2", ")", "\n", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.learn": [[148, 179], ["RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "q_eval.copy", "batch_memory[].astype", "numpy.arange", "batch_memory[].astype", "RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "RL_brain_admiraldm2.AdmiralDMNetwork.cost_his.append", "RL_brain_admiraldm2.AdmiralDMNetwork.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "(", "self", ".", "n_features", "+", "1", ")", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "1", ")", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "2", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "1", ")", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.save_model": [[181, 186], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.restore_model": [[189, 194], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm2.AdmiralDMNetwork.plot_cost": [[196, 202], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.__init__": [[11, 50], ["numpy.zeros", "RL_brain_admiraldm.AdmiralDMNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "9", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Advisorq_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Advisorq_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.copy_network": [[51, 56], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "self", ".", "cost_his", "=", "[", "]", "\n", "\n", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork._build_net": [[59, 109], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["\n", "\n", "", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorq_s'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Advisorq_Q_target'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiraldmValue'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_eval_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Advisorq_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_loss'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_train'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorq_s_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_target_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", "=", "[", "'Advisorq_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.store_transition": [[110, 133], ["list", "range", "numpy.array", "list", "range", "numpy.array", "numpy.hstack", "hasattr", "len", "float", "numpy.array.append", "len", "float", "float", "numpy.array.append"], "methods", ["None"], ["                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "a1", ",", "a1_", ",", "r", ",", "s_", ",", "a_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "s", "=", "list", "(", "s", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1", ")", ")", ":", "\n", "            ", "new_a", "=", "a1", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s", ".", "append", "(", "new_a", ")", "\n", "", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1_", ")", ")", ":", "\n", "            ", "new_a", "=", "float", "(", "a1_", "[", "i", "]", ")", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s_", ".", "append", "(", "new_a", ")", "\n", "", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "\n", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.choose_action": [[134, 151], ["list", "range", "numpy.array", "len", "float", "numpy.array.append", "numpy.random.uniform", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n", "", "def", "choose_action", "(", "self", ",", "observation", ",", "a2", ")", ":", "\n", "\n", "        ", "observation", "=", "list", "(", "observation", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a2", ")", ")", ":", "\n", "            ", "new_a", "=", "a2", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "observation", ".", "append", "(", "new_a", ")", "\n", "", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.learn": [[152, 185], ["RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "q_eval.copy", "batch_memory[].astype", "numpy.arange", "batch_memory[].astype", "print", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "RL_brain_admiraldm.AdmiralDMNetwork.cost_his.append", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n", "", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "(", "self", ".", "n_features", "+", "3", ")", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "5", "]", ".", "astype", "(", "int", ")", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "4", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.save_model": [[188, 193], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["\n", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.restore_model": [[196, 201], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["\n", "", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldm.AdmiralDMNetwork.plot_cost": [[203, 209], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["\n", "", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.__init__": [[11, 52], ["numpy.zeros", "RL_brain_Deepsarsa.DeepSarsa._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "3", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Sarsa_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Sarsa_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.copy_network": [[55, 60], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa._build_net": [[61, 114], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'Sarsa_s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Sarsa_Q_target_1'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'SarsaValue'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_eval_net_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Sarsa_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_hl_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_loss'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_train'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'Sarsa_s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_target_net_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", "=", "[", "'Sarsa_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_hl_1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Sarsa_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Sarsa_l_2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Sarsa_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Sarsa_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.store_transition": [[115, 125], ["numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ",", "a_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.choose_action": [[126, 136], ["numpy.random.uniform", "RL_brain_Deepsarsa.DeepSarsa.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ")", ":", "\n", "        ", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n", "", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.learn": [[137, 170], ["RL_brain_Deepsarsa.DeepSarsa.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "batch_memory[].astype", "RL_brain_Deepsarsa.DeepSarsa.sess.run", "RL_brain_Deepsarsa.DeepSarsa.cost_his.append", "RL_brain_Deepsarsa.DeepSarsa.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "2", "]", ".", "astype", "(", "int", ")", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.save_model": [[171, 176], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.restore_model": [[179, 184], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_Deepsarsa.DeepSarsa.plot_cost": [[187, 193], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.SumTree.__init__": [[12, 19], ["numpy.zeros", "numpy.zeros"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "capacity", ",", "permanent_data", "=", "0", ")", ":", "\n", "        ", "self", ".", "capacity", "=", "capacity", "\n", "self", ".", "tree", "=", "np", ".", "zeros", "(", "2", "*", "capacity", "-", "1", ")", "# stores not probabilities but priorities !!!", "\n", "self", ".", "data", "=", "np", ".", "zeros", "(", "capacity", ",", "dtype", "=", "object", ")", "# stores transitions", "\n", "self", ".", "permanent_data", "=", "permanent_data", "# numbers of data which never be replaced, for demo data protection", "\n", "assert", "0", "<=", "self", ".", "permanent_data", "<=", "self", ".", "capacity", "# equal is also illegal", "\n", "self", ".", "full", "=", "False", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.SumTree.__len__": [[20, 22], ["None"], "methods", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "capacity", "if", "self", ".", "full", "else", "self", ".", "data_pointer", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.SumTree.add": [[23, 31], ["Memory.SumTree.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["\n", "", "def", "add", "(", "self", ",", "p", ",", "data", ")", ":", "\n", "        ", "tree_idx", "=", "self", ".", "data_pointer", "+", "self", ".", "capacity", "-", "1", "\n", "self", ".", "data", "[", "self", ".", "data_pointer", "]", "=", "data", "\n", "self", ".", "update", "(", "tree_idx", ",", "p", ")", "\n", "self", ".", "data_pointer", "+=", "1", "\n", "if", "self", ".", "data_pointer", ">=", "self", ".", "capacity", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "self", ".", "data_pointer", "=", "self", ".", "data_pointer", "%", "self", ".", "capacity", "+", "self", ".", "permanent_data", "# make sure demo data permanent", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.SumTree.update": [[32, 38], ["None"], "methods", ["None"], ["\n", "", "", "def", "update", "(", "self", ",", "tree_idx", ",", "p", ")", ":", "\n", "        ", "change", "=", "p", "-", "self", ".", "tree", "[", "tree_idx", "]", "\n", "self", ".", "tree", "[", "tree_idx", "]", "=", "p", "\n", "while", "tree_idx", "!=", "0", ":", "\n", "            ", "tree_idx", "=", "(", "tree_idx", "-", "1", ")", "//", "2", "\n", "self", ".", "tree", "[", "tree_idx", "]", "+=", "change", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.SumTree.get_leaf": [[39, 55], ["len"], "methods", ["None"], ["\n", "", "", "def", "get_leaf", "(", "self", ",", "v", ")", ":", "\n", "        ", "parent_idx", "=", "0", "\n", "while", "True", ":", "\n", "            ", "left_child_idx", "=", "2", "*", "parent_idx", "+", "1", "\n", "right_child_idx", "=", "left_child_idx", "+", "1", "\n", "if", "left_child_idx", ">=", "len", "(", "self", ".", "tree", ")", ":", "\n", "                ", "leaf_idx", "=", "parent_idx", "\n", "break", "\n", "", "if", "v", "<=", "self", ".", "tree", "[", "left_child_idx", "]", ":", "\n", "                ", "parent_idx", "=", "left_child_idx", "\n", "", "else", ":", "\n", "                ", "v", "-=", "self", ".", "tree", "[", "left_child_idx", "]", "\n", "parent_idx", "=", "right_child_idx", "\n", "\n", "", "", "data_idx", "=", "leaf_idx", "-", "self", ".", "capacity", "+", "1", "\n", "return", "leaf_idx", ",", "self", ".", "tree", "[", "leaf_idx", "]", ",", "self", ".", "data", "[", "data_idx", "]", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.SumTree.total_p": [[56, 59], ["None"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "total_p", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tree", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.Memory.__init__": [[70, 73], ["Memory.SumTree"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "capacity", ",", "permanent_data", "=", "0", ")", ":", "\n", "        ", "self", ".", "permanent_data", "=", "permanent_data", "\n", "self", ".", "tree", "=", "SumTree", "(", "capacity", ",", "permanent_data", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.Memory.__len__": [[74, 76], ["len"], "methods", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tree", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.Memory.full": [[77, 79], ["None"], "methods", ["None"], ["\n", "", "def", "full", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tree", ".", "full", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.Memory.store": [[80, 85], ["numpy.max", "Memory.Memory.tree.add"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add"], ["\n", "", "def", "store", "(", "self", ",", "transition", ")", ":", "\n", "        ", "max_p", "=", "np", ".", "max", "(", "self", ".", "tree", ".", "tree", "[", "-", "self", ".", "tree", ".", "capacity", ":", "]", ")", "\n", "if", "max_p", "==", "0", ":", "\n", "            ", "max_p", "=", "self", ".", "abs_err_upper", "\n", "", "self", ".", "tree", ".", "add", "(", "max_p", ",", "transition", ")", "# set the max_p for new transition", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.Memory.sample": [[86, 104], ["Memory.Memory.full", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.min", "range", "numpy.min", "numpy.random.uniform", "Memory.Memory.tree.get_leaf", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.get_leaf"], ["\n", "", "def", "sample", "(", "self", ",", "n", ")", ":", "\n", "        ", "assert", "self", ".", "full", "(", ")", "\n", "b_idx", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "b_memory", "=", "np", ".", "empty", "(", "(", "n", ",", "self", ".", "tree", ".", "data", "[", "0", "]", ".", "size", ")", ",", "dtype", "=", "object", ")", "\n", "ISWeights", "=", "np", ".", "empty", "(", "(", "n", ",", "1", ")", ")", "\n", "pri_seg", "=", "self", ".", "tree", ".", "total_p", "/", "n", "\n", "self", ".", "beta", "=", "np", ".", "min", "(", "[", "1.", ",", "self", ".", "beta", "+", "self", ".", "beta_increment_per_sampling", "]", ")", "\n", "\n", "min_prob", "=", "np", ".", "min", "(", "self", ".", "tree", ".", "tree", "[", "-", "self", ".", "tree", ".", "capacity", ":", "]", ")", "/", "self", ".", "tree", ".", "total_p", "\n", "assert", "min_prob", ">", "0", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "v", "=", "np", ".", "random", ".", "uniform", "(", "pri_seg", "*", "i", ",", "pri_seg", "*", "(", "i", "+", "1", ")", ")", "\n", "idx", ",", "p", ",", "data", "=", "self", ".", "tree", ".", "get_leaf", "(", "v", ")", "# note: idx is the index in self.tree.tree", "\n", "prob", "=", "p", "/", "self", ".", "tree", ".", "total_p", "\n", "ISWeights", "[", "i", ",", "0", "]", "=", "np", ".", "power", "(", "prob", "/", "min_prob", ",", "-", "self", ".", "beta", ")", "\n", "b_idx", "[", "i", "]", ",", "b_memory", "[", "i", "]", "=", "idx", ",", "data", "\n", "", "return", "b_idx", ",", "b_memory", ",", "ISWeights", "# note: b_idx stores indexes in self.tree.tree, not in self.tree.data !!!", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.Memory.Memory.batch_update": [[106, 114], ["numpy.minimum", "numpy.power", "zip", "Memory.Memory.tree.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["# update priority", "\n", "", "def", "batch_update", "(", "self", ",", "tree_idxes", ",", "abs_errors", ")", ":", "\n", "        ", "abs_errors", "[", "self", ".", "tree", ".", "permanent_data", ":", "]", "+=", "self", ".", "epsilon", "\n", "# priorities of demo transitions are given a bonus of demo_epsilon, to boost the frequency that they are sampled", "\n", "abs_errors", "[", ":", "self", ".", "tree", ".", "permanent_data", "]", "+=", "self", ".", "demo_epsilon", "\n", "clipped_errors", "=", "np", ".", "minimum", "(", "abs_errors", ",", "self", ".", "abs_err_upper", ")", "\n", "ps", "=", "np", ".", "power", "(", "clipped_errors", ",", "self", ".", "alpha", ")", "\n", "for", "ti", ",", "p", "in", "zip", "(", "tree_idxes", ",", "ps", ")", ":", "\n", "            ", "self", ".", "tree", ".", "update", "(", "ti", ",", "p", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldmac.make_np_float": [[14, 16], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldmac.featurize": [[23, 46], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "dqfdvsadmiraldmac.make_np_float", "dqfdvsadmiraldmac.make_np_float", "dqfdvsadmiraldmac.make_np_float", "dqfdvsadmiraldmac.make_np_float", "dqfdvsadmiraldmac.make_np_float", "dqfdvsadmiraldmac.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldmac.set_n_step": [[55, 64], ["list", "sum", "range", "len", "min", "t_list[].extend", "enumerate", "len", "min", "len", "Config.Config.trajectory_n", "Config.Config.trajectory_n"], "function", ["None"], ["", "def", "set_n_step", "(", "container", ",", "n", ")", ":", "\n", "    ", "t_list", "=", "list", "(", "container", ")", "\n", "n_step_reward", "=", "sum", "(", "[", "t", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "i", "for", "i", ",", "t", "in", "enumerate", "(", "t_list", "[", "0", ":", "min", "(", "len", "(", "t_list", ")", ",", "n", ")", "-", "1", "]", ")", "]", ")", "\n", "for", "begin", "in", "range", "(", "len", "(", "t_list", ")", ")", ":", "\n", "        ", "end", "=", "min", "(", "len", "(", "t_list", ")", "-", "1", ",", "begin", "+", "Config", ".", "trajectory_n", "-", "1", ")", "\n", "n_step_reward", "+=", "t_list", "[", "end", "]", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "(", "end", "-", "begin", ")", "\n", "t_list", "[", "begin", "]", ".", "extend", "(", "[", "n_step_reward", ",", "t_list", "[", "end", "]", "[", "3", "]", ",", "t_list", "[", "end", "]", "[", "4", "]", ",", "end", "-", "begin", "+", "1", "]", ")", "\n", "n_step_reward", "=", "(", "n_step_reward", "-", "t_list", "[", "begin", "]", "[", "2", "]", ")", "/", "Config", ".", "GAMMA", "\n", "", "return", "t_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldmac.get_demo_data": [[71, 115], ["pommerman.make", "pommerman.make.seed", "collections.deque", "pommerman.agents.SimpleAgent", "pommerman.agents.SimpleAgent", "pommerman.make.reset", "pommerman.make.act", "open", "pickle.dump", "pommerman.make.step", "dqfdvsadmiraldmac.featurize", "dqfdvsadmiraldmac.featurize", "dqfdvsadmiraldmac.featurize", "dqfdvsadmiraldmac.featurize", "set_n_step.append", "set_n_step.append", "pommerman.make.act", "print", "dqfdvsadmiraldmac.set_n_step", "collections.deque.extend", "dqfdvsadmiraldmac.set_n_step", "collections.deque.extend", "len", "len", "collections.deque", "itertools.islice"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step"], ["", "def", "get_demo_data", "(", ")", ":", "\n", "\n", "    ", "agent_list", "=", "[", "\n", "agents", ".", "SimpleAgent", "(", ")", ",", "\n", "agents", ".", "SimpleAgent", "(", ")", ",", "\n", "]", "\n", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "demo_buffer", "=", "deque", "(", ")", "\n", "e", "=", "0", "\n", "while", "True", ":", "\n", "        ", "done", "=", "False", "\n", "state", "=", "env", ".", "reset", "(", ")", "\n", "demo", "=", "[", "]", "\n", "demo2", "=", "[", "]", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "done", "is", "False", ":", "\n", "            ", "next_state", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "actions", ")", "\n", "obs", "=", "featurize", "(", "state", "[", "0", "]", ")", "\n", "obs2", "=", "featurize", "(", "state", "[", "1", "]", ")", "\n", "obs3", "=", "featurize", "(", "next_state", "[", "0", "]", ")", "\n", "obs4", "=", "featurize", "(", "next_state", "[", "1", "]", ")", "\n", "demo", ".", "append", "(", "[", "obs", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "obs3", ",", "done", ",", "1.0", "]", ")", "\n", "demo2", ".", "append", "(", "[", "obs2", ",", "actions", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "obs4", ",", "done", ",", "1.0", "]", ")", "\n", "state", "=", "next_state", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "", "if", "done", ":", "\n", "            ", "if", "reward", "[", "0", "]", "==", "1", ":", "\n", "                ", "demo", "=", "set_n_step", "(", "demo", ",", "Config", ".", "trajectory_n", ")", "\n", "demo_buffer", ".", "extend", "(", "demo", ")", "\n", "", "else", ":", "\n", "                ", "demo2", "=", "set_n_step", "(", "demo2", ",", "Config", ".", "trajectory_n", ")", "\n", "demo_buffer", ".", "extend", "(", "demo2", ")", "\n", "", "print", "(", "\"episode:\"", ",", "e", ",", "\"  demo_buffer:\"", ",", "len", "(", "demo_buffer", ")", ")", "\n", "if", "len", "(", "demo_buffer", ")", ">=", "Config", ".", "demo_buffer_size", ":", "\n", "                ", "demo_buffer", "=", "deque", "(", "itertools", ".", "islice", "(", "demo_buffer", ",", "0", ",", "Config", ".", "demo_buffer_size", ")", ")", "\n", "break", "\n", "", "", "e", "+=", "1", "\n", "\n", "", "with", "open", "(", "Config", ".", "DEMO_DATA_PATH", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "demo_buffer", ",", "f", ",", "protocol", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldmac.main": [[120, 159], ["print", "dqfdvsadmiraldmac.get_demo_data", "tensorflow.InteractiveSession", "pommerman.make", "pommerman.make.seed", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.Advisor1admiraldmac", "pommerman.agents.DQfDAgent", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].restorevalue", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].learn", "agent_list[].run_DQfD", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.get_demo_data", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.restorevalue", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.run_DQfD"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "get_demo_data", "(", ")", "\n", "\n", "self", ".", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "agent_list", "=", "[", "\n", "agents", ".", "Advisor1admiraldmac", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "DQfDAgent", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1acdqfd.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(Expertac)\"", ",", "\"Reward2(DQfd)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "50000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "learn", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "1", "]", ",", "done", ")", "\n", "agent_list", "[", "1", "]", ".", "run_DQfD", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "done", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "1", "]", ".", "restorevalue", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1acdqfd.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.chatvsadmiraldmac.main": [[8, 49], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.Advisor1admiraldmac", "pommerman.agents.CHATAgent", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].learn", "agent_list[].store", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "Advisor1admiraldmac", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "CHATAgent", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1acchat.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(Expertac)\"", ",", "\"Reward2(CHAT)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "50000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "learn", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "1", "]", ",", "done", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_new", "[", "1", "]", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1acchat.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor1admiralaesarsa.main": [[8, 53], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor1admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicysarsa.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DeepSarsa)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicysarsa.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor4admiralaesarsa.main": [[8, 54], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor4admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert4offpolicysarsa.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DeepSarsa)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert4offpolicysarsa.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor3admiralaesarsa.main": [[8, 53], ["print", "tensorflow.Session", "tf.Session.run", "pommerman.make", "pommerman.make.seed", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor3admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert3offpolicysarsa.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DeepSarsa)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert3offpolicysarsa.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float": [[11, 13], ["numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "make_np_float", "(", "feature", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "feature", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize": [[20, 43], ["obs[].reshape().astype", "obs[].reshape().astype", "obs[].reshape().astype", "dqfdvsadmiraldm.make_np_float", "dqfdvsadmiraldm.make_np_float", "dqfdvsadmiraldm.make_np_float", "dqfdvsadmiraldm.make_np_float", "dqfdvsadmiraldm.make_np_float", "dqfdvsadmiraldm.make_np_float", "numpy.concatenate", "len", "obs[].reshape", "obs[].reshape", "obs[].reshape", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.make_np_float"], ["", "def", "featurize", "(", "obs", ")", ":", "\n", "    ", "board", "=", "obs", "[", "\"board\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_blast_strength", "=", "obs", "[", "\"bomb_blast_strength\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "bomb_life", "=", "obs", "[", "\"bomb_life\"", "]", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "position", "=", "make_np_float", "(", "obs", "[", "\"position\"", "]", ")", "\n", "ammo", "=", "make_np_float", "(", "[", "obs", "[", "\"ammo\"", "]", "]", ")", "\n", "blast_strength", "=", "make_np_float", "(", "[", "obs", "[", "\"blast_strength\"", "]", "]", ")", "\n", "can_kick", "=", "make_np_float", "(", "[", "obs", "[", "\"can_kick\"", "]", "]", ")", "\n", "\n", "teammate", "=", "obs", "[", "\"teammate\"", "]", "\n", "if", "teammate", "is", "not", "None", ":", "\n", "        ", "teammate", "=", "teammate", ".", "value", "\n", "", "else", ":", "\n", "        ", "teammate", "=", "-", "1", "\n", "", "teammate", "=", "make_np_float", "(", "[", "teammate", "]", ")", "\n", "\n", "enemies", "=", "obs", "[", "\"enemies\"", "]", "\n", "enemies", "=", "[", "e", ".", "value", "for", "e", "in", "enemies", "]", "\n", "if", "len", "(", "enemies", ")", "<", "3", ":", "\n", "        ", "enemies", "=", "enemies", "+", "[", "-", "1", "]", "*", "(", "3", "-", "len", "(", "enemies", ")", ")", "\n", "", "enemies", "=", "make_np_float", "(", "enemies", ")", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "board", ",", "bomb_blast_strength", ",", "bomb_life", ",", "position", ",", "ammo", ",", "blast_strength", ",", "can_kick", ",", "teammate", ",", "enemies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.set_n_step": [[52, 61], ["list", "sum", "range", "len", "min", "t_list[].extend", "enumerate", "len", "min", "len", "Config.Config.trajectory_n", "Config.Config.trajectory_n"], "function", ["None"], ["", "def", "set_n_step", "(", "container", ",", "n", ")", ":", "\n", "    ", "t_list", "=", "list", "(", "container", ")", "\n", "n_step_reward", "=", "sum", "(", "[", "t", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "i", "for", "i", ",", "t", "in", "enumerate", "(", "t_list", "[", "0", ":", "min", "(", "len", "(", "t_list", ")", ",", "n", ")", "-", "1", "]", ")", "]", ")", "\n", "for", "begin", "in", "range", "(", "len", "(", "t_list", ")", ")", ":", "\n", "        ", "end", "=", "min", "(", "len", "(", "t_list", ")", "-", "1", ",", "begin", "+", "Config", ".", "trajectory_n", "-", "1", ")", "\n", "n_step_reward", "+=", "t_list", "[", "end", "]", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "(", "end", "-", "begin", ")", "\n", "t_list", "[", "begin", "]", ".", "extend", "(", "[", "n_step_reward", ",", "t_list", "[", "end", "]", "[", "3", "]", ",", "t_list", "[", "end", "]", "[", "4", "]", ",", "end", "-", "begin", "+", "1", "]", ")", "\n", "n_step_reward", "=", "(", "n_step_reward", "-", "t_list", "[", "begin", "]", "[", "2", "]", ")", "/", "Config", ".", "GAMMA", "\n", "", "return", "t_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.get_demo_data": [[68, 112], ["pommerman.make", "pommerman.make.seed", "collections.deque", "pommerman.agents.SimpleAgent", "pommerman.agents.SimpleAgent", "pommerman.make.reset", "pommerman.make.act", "open", "pickle.dump", "pommerman.make.step", "dqfdvsadmiraldm.featurize", "dqfdvsadmiraldm.featurize", "dqfdvsadmiraldm.featurize", "dqfdvsadmiraldm.featurize", "set_n_step.append", "set_n_step.append", "pommerman.make.act", "print", "dqfdvsadmiraldm.set_n_step", "collections.deque.extend", "dqfdvsadmiraldm.set_n_step", "collections.deque.extend", "len", "len", "collections.deque", "itertools.islice"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.featurize", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step"], ["", "def", "get_demo_data", "(", ")", ":", "\n", "\n", "\n", "    ", "agent_list", "=", "[", "\n", "agents", ".", "SimpleAgent", "(", ")", ",", "\n", "agents", ".", "SimpleAgent", "(", ")", ",", "\n", "]", "\n", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "demo_buffer", "=", "deque", "(", ")", "\n", "e", "=", "0", "\n", "while", "True", ":", "\n", "        ", "done", "=", "False", "\n", "state", "=", "env", ".", "reset", "(", ")", "\n", "demo", "=", "[", "]", "\n", "demo2", "=", "[", "]", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "done", "is", "False", ":", "\n", "            ", "next_state", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "actions", ")", "\n", "obs", "=", "featurize", "(", "state", "[", "0", "]", ")", "\n", "obs2", "=", "featurize", "(", "state", "[", "1", "]", ")", "\n", "obs3", "=", "featurize", "(", "next_state", "[", "0", "]", ")", "\n", "obs4", "=", "featurize", "(", "next_state", "[", "1", "]", ")", "\n", "demo", ".", "append", "(", "[", "obs", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "obs3", ",", "done", ",", "1.0", "]", ")", "\n", "demo2", ".", "append", "(", "[", "obs2", ",", "actions", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "obs4", ",", "done", ",", "1.0", "]", ")", "\n", "state", "=", "next_state", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "", "if", "done", ":", "\n", "            ", "if", "reward", "[", "0", "]", "==", "1", ":", "\n", "                ", "demo", "=", "set_n_step", "(", "demo", ",", "Config", ".", "trajectory_n", ")", "\n", "demo_buffer", ".", "extend", "(", "demo", ")", "\n", "", "else", ":", "\n", "                ", "demo2", "=", "set_n_step", "(", "demo2", ",", "Config", ".", "trajectory_n", ")", "\n", "demo_buffer", ".", "extend", "(", "demo2", ")", "\n", "", "print", "(", "\"episode:\"", ",", "e", ",", "\"  demo_buffer:\"", ",", "len", "(", "demo_buffer", ")", ")", "\n", "if", "len", "(", "demo_buffer", ")", ">=", "Config", ".", "demo_buffer_size", ":", "\n", "                ", "demo_buffer", "=", "deque", "(", "itertools", ".", "islice", "(", "demo_buffer", ",", "0", ",", "Config", ".", "demo_buffer_size", ")", ")", "\n", "break", "\n", "", "", "e", "+=", "1", "\n", "\n", "", "with", "open", "(", "Config", ".", "DEMO_DATA_PATH", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "demo_buffer", ",", "f", ",", "protocol", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqfdvsadmiraldm.main": [[117, 161], ["print", "dqfdvsadmiraldm.get_demo_data", "tf.InteractiveSession", "pommerman.make", "pommerman.make.seed", "sess.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.Advisor1admiraldm", "pommerman.agents.DQfDAgent", "tf.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].restorevalue", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].run_DQfD", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.get_demo_data", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.restorevalue", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.run_DQfD", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "get_demo_data", "(", ")", "\n", "\n", "self", ".", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "Advisor1admiraldm", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "DQfDAgent", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1dqfd.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(Expertq)\"", ",", "\"Reward2(DQfd)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "50000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "actions", "[", "1", "]", ",", "actions_new", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "run_DQfD", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "done", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "agent_list", "[", "0", "]", ".", "set", "(", "actions_new", "[", "1", "]", ")", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "restorevalue", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1dqfd.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqnvsadmiraldmac.main": [[8, 50], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.Advisor1admiraldmac", "pommerman.agents.DQNAgent", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].learn", "agent_list[].store", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "Advisor1admiraldmac", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1acdqn.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(Expertac)\"", ",", "\"Reward2(DQN)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "50000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "learn", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "1", "]", ",", "done", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1acdqn.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.admiraldmvsdeepsarsa_advisor3.main": [[8, 51], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor3small", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor3", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert3.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "1", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "2", "]", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.dqnvsadmiraldm.main": [[8, 51], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.Advisor1admiraldm", "pommerman.agents.DQNAgent", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "Advisor1admiraldm", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1dqn.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(ExpertQ)\"", ",", "\"Reward2(DQN)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "50000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "actions", "[", "1", "]", ",", "actions_new", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "agent_list", "[", "0", "]", ".", "set", "(", "actions_new", "[", "1", "]", ")", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1dqn.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.admiraldmvsdeepsarsa_advisor1.main": [[8, 51], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor1small", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["\n", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert1.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "1", "]", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor2admiralaesarsa.main": [[8, 53], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor2admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert2offpolicysarsa.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DeepSarsa)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert2offpolicysarsa.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor1admiralaeadaptive.main": [[8, 52], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DQNAgent", "pommerman.agents.Advisor1admiralaeadaptive", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1admiralaeadaptive", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicyadaptive.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicyadaptive.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor1admiralaenonadaptive.main": [[8, 53], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DQNAgent", "pommerman.agents.Advisor1admiralaenonadaptive", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1admiralaenonadaptive", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicynew.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicynew.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor4admiralae.main": [[8, 54], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DQNAgent", "pommerman.agents.Advisor4admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert4offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "200000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions2_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert4offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.admiraldmacvsadmiraldm.main": [[10, 50], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.Advisor1admiraldm", "pommerman.agents.Advisor1admiraldmac", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].learn", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "Advisor1admiraldm", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1admiraldmac", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1actorcritic.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(ExpertQ)\"", ",", "\"Reward2(ExpertQac)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "50000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "actions", "[", "1", "]", ",", "actions_new", "[", "1", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_new", "[", "0", "]", ",", "done", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "agent_list", "[", "0", "]", ".", "set", "(", "actions_new", "[", "1", "]", ")", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1actorcritic.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor1admiralae.main": [[8, 53], ["print", "tensorflow.Session", "tf.Session.run", "pommerman.make", "pommerman.make.seed", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DQNAgent", "pommerman.agents.Advisor1admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor1admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions2_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert1offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.__init__": [[11, 55], ["numpy.zeros", "tensorflow.placeholder", "tensorflow.one_hot", "RL_brain_CHAT.CHAT._build_net", "RL_brain_CHAT.CHAT._build_confidence_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT._build_confidence_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "1000", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "+", "1", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "4", ")", ")", "\n", "\n", "self", ".", "advisor_act", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ",", "name", "=", "'CHAT_advisor_act'", ")", "\n", "self", ".", "advisor_one_hot", "=", "tf", ".", "one_hot", "(", "self", ".", "advisor_act", ",", "depth", "=", "self", ".", "n_actions", "-", "1", ",", "on_value", "=", "1.0", ",", "off_value", "=", "0.0", ")", "\n", "self", ".", "_build_net", "(", ")", "\n", "self", ".", "_build_confidence_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'CHAT_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'CHAT_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.copy_network": [[58, 63], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT._build_net": [[64, 115], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'CHAT_s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'CHAT_Q_target_1'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'CHATValue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_eval_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'CHAT_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'CHAT_s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_target_net_1'", ")", ":", "\n", "                ", "c_names", "=", "[", "'CHAT_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT._build_confidence_net": [[116, 143], ["tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "", "", "", "def", "_build_confidence_net", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'ConfidenceValue'", ")", ":", "\n", "            ", "self", ".", "name_scope2", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_confidence_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'CHAT_confidence_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_3'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_3'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_3'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_3'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_3'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_3'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_4'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_4'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "-", "1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_4'", ",", "[", "1", ",", "self", ".", "n_actions", "-", "1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_confidence", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_loss2'", ")", ":", "\n", "                ", "self", ".", "loss2", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "advisor_one_hot", ",", "self", ".", "q_confidence", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_train2'", ")", ":", "\n", "                ", "self", ".", "_train_op2", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.store_transition": [[144, 154], ["numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ",", "a_", ",", "advisor_a", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", ",", "advisor_a", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.choose_action": [[155, 165], ["numpy.random.uniform", "RL_brain_CHAT.CHAT.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.get_confidence": [[166, 173], ["RL_brain_CHAT.CHAT.sess.run", "numpy.exp", "sum", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "get_confidence", "(", "self", ",", "observation", ",", "action", ")", ":", "\n", "        ", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "confidence_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_confidence", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "confidence_value", "=", "confidence_value", "[", "0", "]", "\n", "confidence", "=", "np", ".", "exp", "(", "confidence_value", ")", "/", "sum", "(", "np", ".", "exp", "(", "confidence_value", ")", ")", "\n", "action_confidence", "=", "confidence", "[", "action", "]", "\n", "return", "action_confidence", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.learn": [[174, 211], ["RL_brain_CHAT.CHAT.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "batch_memory[].astype", "batch_memory[].astype", "RL_brain_CHAT.CHAT.sess.run", "RL_brain_CHAT.CHAT.cost_his.append", "RL_brain_CHAT.CHAT.sess.run", "RL_brain_CHAT.CHAT.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "2", "]", ".", "astype", "(", "int", ")", "\n", "advisor_a", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "_", ",", "self", ".", "cost2", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op2", ",", "self", ".", "loss2", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "advisor_act", ":", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", "}", ")", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.save_model": [[213, 218], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.restore_model": [[221, 226], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.save_confidence_model": [[227, 232], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_confidence_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.restore_confidence_model": [[235, 240], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_confidence_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_CHAT.CHAT.plot_cost": [[242, 248], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.onevsoneadvisor2admiralae.main": [[8, 53], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DQNAgent", "pommerman.agents.Advisor2admiralae", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].act2", "agent_list[].act2", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.act2", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DQNAgent", "(", "201", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2admiralae", "(", "201", ",", "sess", ")", ",", "\n", "]", "\n", "env", "=", "pommerman", ".", "make", "(", "'OneVsOne-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert2offpolicy.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(ExpertQ)\"", ")", ")", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "actions2_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "0", "]", ",", "env", ".", "action_space", ")", "\n", "actions_", "=", "agent_list", "[", "1", "]", ".", "act2", "(", "state_new", "[", "1", "]", ",", "env", ".", "action_space", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ")", "\n", "agent_list", "[", "1", "]", ".", "store", "(", "state", "[", "1", "]", ",", "actions", "[", "1", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "1", "]", ",", "state_new", "[", "1", "]", ",", "actions_", ",", "actions2_", ")", "\n", "agent_list", "[", "1", "]", ".", "set", "(", "actions2_", ")", "\n", "state", "=", "state_new", "\n", "actions", "=", "actions_new", "\n", "", "agent_list", "[", "0", "]", ".", "learn", "(", ")", "\n", "agent_list", "[", "1", "]", ".", "learn", "(", ")", "\n", "print", "(", "\"The rewards are\"", ",", "reward", ")", "\n", "cumulative_rewards", "[", "0", "]", "=", "cumulative_rewards", "[", "0", "]", "+", "reward", "[", "0", "]", "\n", "cumulative_rewards", "[", "1", "]", "=", "cumulative_rewards", "[", "1", "]", "+", "reward", "[", "1", "]", "\n", "\n", "with", "open", "(", "'pommermanonevsoneexpert2offpolicy.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "i_episode", ",", "cumulative_rewards", "[", "0", "]", ",", "cumulative_rewards", "[", "1", "]", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "i_episode", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_admiralae.AdmiralaeNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "9", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Advisorae_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Advisorae_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.copy_network": [[53, 58], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["\n", "", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork._build_net": [[61, 111], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["\n", "", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorae_s'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Advisorae_Q_target'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiralaeValue'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_eval_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Advisorae_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorae_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorae_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorae_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorae_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_loss'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_train'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorae_s_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_target_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", "=", "[", "'Advisorae_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorae_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorae_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_hl1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorae_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorae_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorae_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.store_transition": [[112, 130], ["list", "float", "numpy.array.append", "numpy.array", "list", "float", "numpy.array.append", "numpy.array", "numpy.hstack", "hasattr"], "methods", ["None"], ["b2", "=", "tf", ".", "get_variable", "(", "'Advisorae_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "a1", ",", "r", ",", "s_", ",", "a_", ",", "a1_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "", "s", "=", "list", "(", "s", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1", ")", ")", ":", "\n", "            ", "new_a", "=", "a1", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s", ".", "append", "(", "new_a", ")", "\n", "\n", "", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "a1_", ")", ")", ":", "\n", "            ", "new_a", "=", "float", "(", "a1_", "[", "i", "]", ")", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s_", ".", "append", "(", "new_a", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.choose_action": [[131, 145], ["list", "float", "numpy.array.append", "numpy.array", "numpy.random.uniform", "RL_brain_admiralae.AdmiralaeNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "\n", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n", "", "def", "choose_action", "(", "self", ",", "observation", ",", "a2", ")", ":", "\n", "\n", "        ", "observation", "=", "list", "(", "observation", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a2", ")", ")", ":", "\n", "            ", "new_a", "=", "a2", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.learn": [[146, 178], ["RL_brain_admiralae.AdmiralaeNetwork.sess.run", "q_eval.copy", "batch_memory[].astype", "numpy.arange", "batch_memory[].astype", "RL_brain_admiralae.AdmiralaeNetwork.sess.run", "RL_brain_admiralae.AdmiralaeNetwork.cost_his.append", "RL_brain_admiralae.AdmiralaeNetwork.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["observation", ".", "append", "(", "new_a", ")", "\n", "", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n", "", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "(", "self", ".", "n_features", "+", "3", ")", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "5", "]", ".", "astype", "(", "int", ")", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.save_model": [[180, 185], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.restore_model": [[188, 193], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n", "\n", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiralae.AdmiralaeNetwork.plot_cost": [[195, 201], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n", "\n", "\n", "", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_DQN.DeepQNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "2", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.copy_network": [[55, 60], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork._build_net": [[61, 111], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Q_target_1'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'DQN_value'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'eval_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_h1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'w_h1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'b_h1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'target_net_1'", ")", ":", "\n", "                ", "c_names", "=", "[", "'target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_h1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'w_h1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'b_h1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.store_transition": [[112, 121], ["numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.choose_action": [[122, 132], ["numpy.random.uniform", "RL_brain_DQN.DeepQNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.learn": [[133, 165], ["RL_brain_DQN.DeepQNetwork.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "RL_brain_DQN.DeepQNetwork.sess.run", "RL_brain_DQN.DeepQNetwork.cost_his.append", "RL_brain_DQN.DeepQNetwork.sess.run", "numpy.random.choice", "numpy.random.choice", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "np", ".", "max", "(", "q_next", ",", "axis", "=", "1", ")", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.save_model": [[166, 171], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.restore_model": [[174, 179], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_DQN.DeepQNetwork.plot_cost": [[182, 188], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Actor.__init__": [[16, 59], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "n_actions", ",", "lr", "=", "0.001", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "a", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "None", ",", "\"Advisorac_act\"", ")", "\n", "self", ".", "td_error", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "\"Advisorac_td_error\"", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Admiraldmacactorvalue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Actor'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "acts_prob", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "n_actions", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "softmax", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_acts_prob'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_exp_v'", ")", ":", "\n", "                ", "log_prob", "=", "tf", ".", "log", "(", "self", ".", "acts_prob", "[", "0", ",", "self", ".", "a", "]", ")", "\n", "self", ".", "exp_v", "=", "tf", ".", "reduce_mean", "(", "log_prob", "*", "self", ".", "td_error", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "-", "self", ".", "exp_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Actor.learn": [[60, 65], ["RL_brain_admiraldmac.Actor.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "", "", "def", "learn", "(", "self", ",", "s", ",", "a", ",", "td", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "s", ",", "self", ".", "a", ":", "a", ",", "self", ".", "td_error", ":", "td", "}", "\n", "_", ",", "exp_v", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "exp_v", "]", ",", "feed_dict", ")", "\n", "return", "exp_v", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Actor.choose_action": [[66, 70], ["RL_brain_admiraldmac.Actor.sess.run", "numpy.random.choice", "numpy.arange", "RL_brain_admiraldmac.Actor.ravel"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "s", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "probs", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "acts_prob", ",", "{", "self", ".", "s", ":", "s", "}", ")", "\n", "return", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "probs", ".", "shape", "[", "1", "]", ")", ",", "p", "=", "probs", ".", "ravel", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Actor.save_model": [[71, 76], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Actor.restore_model": [[77, 82], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Critic.__init__": [[89, 131], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.square", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "lr", "=", "0.01", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "+", "1", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "v_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "1", "]", ",", "\"Advisorac_v_next\"", ")", "\n", "self", ".", "r", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "'Advisorac_r'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiraldmacCritic'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Critic'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "v", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "1", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_V'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'squared_TD_error'", ")", ":", "\n", "                ", "self", ".", "td_error", "=", "self", ".", "r", "+", "GAMMA", "*", "self", ".", "v_", "-", "self", ".", "v", "\n", "self", ".", "loss", "=", "tf", ".", "square", "(", "self", ".", "td_error", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Critic.learn": [[132, 146], ["list", "float", "numpy.array.append", "numpy.array", "list", "float", "numpy.array.append", "numpy.array", "RL_brain_admiraldmac.Critic.sess.run", "RL_brain_admiraldmac.Critic.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "", "", "def", "learn", "(", "self", ",", "s", ",", "opp_a", ",", "r", ",", "s_", ",", "opp_a_", ")", ":", "\n", "        ", "s", "=", "list", "(", "s", ")", "\n", "a1", "=", "float", "(", "opp_a", ")", "\n", "s", ".", "append", "(", "a1", ")", "\n", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "a2", "=", "float", "(", "opp_a_", ")", "\n", "s_", ".", "append", "(", "a2", ")", "\n", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "s", ",", "s_", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", ",", "s_", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "v_", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "v", ",", "{", "self", ".", "s", ":", "s_", "}", ")", "\n", "td_error", ",", "_", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "td_error", ",", "self", ".", "train_op", "]", ",", "\n", "{", "self", ".", "s", ":", "s", ",", "self", ".", "v_", ":", "v_", ",", "self", ".", "r", ":", "r", "}", ")", "\n", "return", "td_error", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Critic.save_model": [[147, 152], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.RL_brain_admiraldmac.Critic.restore_model": [[153, 158], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.__init__": [[27, 60], ["Memory.Memory.Memory", "Memory.Memory.Memory", "DQfD_V3.DQfD.add_demo_to_memory", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.train.Saver", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.save_model", "DQfD_V3.DQfD.restore_model", "tensorflow.global_variables_initializer", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.add_demo_to_memory", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.restore_model"], ["        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "replay_memory", "=", "Memory", "(", "capacity", "=", "self", ".", "config", ".", "replay_buffer_size", ",", "permanent_data", "=", "len", "(", "demo_transitions", ")", ")", "\n", "self", ".", "demo_memory", "=", "Memory", "(", "capacity", "=", "self", ".", "config", ".", "demo_buffer_size", ",", "permanent_data", "=", "self", ".", "config", ".", "demo_buffer_size", ")", "\n", "self", ".", "add_demo_to_memory", "(", "demo_transitions", "=", "demo_transitions", ")", "\n", "self", ".", "time_step", "=", "0", "\n", "self", ".", "epsilon", "=", "self", ".", "config", ".", "INITIAL_EPSILON", "\n", "self", ".", "state_dim", "=", "nf", "\n", "self", ".", "action_dim", "=", "na", "\n", "\n", "self", ".", "action_batch", "=", "tf", ".", "placeholder", "(", "\"int32\"", ",", "[", "None", "]", ")", "\n", "self", ".", "y_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "action_dim", "]", ")", "\n", "self", ".", "ISWeights", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "1", "]", ")", "\n", "self", ".", "n_step_y_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "action_dim", "]", ")", "\n", "self", ".", "isdemo", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", "]", ")", "\n", "self", ".", "eval_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "state_dim", "]", ")", "\n", "self", ".", "select_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "state_dim", "]", ")", "\n", "\n", "self", ".", "Q_eval", "\n", "self", ".", "Q_select", "\n", "\n", "self", ".", "loss", "\n", "self", ".", "optimize", "\n", "self", ".", "update_target_net", "\n", "self", ".", "abs_errors", "\n", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "self", ".", "save_model", "(", ")", "\n", "self", ".", "restore_model", "(", ")", "\n", "\n", "", "def", "add_demo_to_memory", "(", "self", ",", "demo_transitions", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.add_demo_to_memory": [[61, 66], ["DQfD_V3.DQfD.demo_memory.store", "DQfD_V3.DQfD.replay_memory.store", "numpy.array", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["        ", "for", "t", "in", "demo_transitions", ":", "\n", "            ", "self", ".", "demo_memory", ".", "store", "(", "np", ".", "array", "(", "t", ",", "dtype", "=", "object", ")", ")", "\n", "self", ".", "replay_memory", ".", "store", "(", "np", ".", "array", "(", "t", ",", "dtype", "=", "object", ")", ")", "\n", "assert", "len", "(", "t", ")", "==", "10", "\n", "\n", "", "", "def", "pre_train", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.pre_train": [[67, 75], ["print", "range", "print", "DQfD_V3.DQfD.train_Q_network", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network"], ["        ", "print", "(", "'Pre-training ...'", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "config", ".", "PRETRAIN_STEPS", ")", ":", "\n", "            ", "self", ".", "train_Q_network", "(", "pre_train", "=", "True", ")", "\n", "if", "i", "%", "200", "==", "0", "and", "i", ">", "0", ":", "\n", "                ", "print", "(", "'{} th step of pre-train finish ...'", ".", "format", "(", "i", ")", ")", "\n", "", "", "self", ".", "time_step", "=", "0", "\n", "print", "(", "'All pre-train finish.'", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.build_layers": [[77, 92], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["        ", "a_d", "=", "self", ".", "action_dim", "\n", "with", "tf", ".", "variable_scope", "(", "'DQfD_l1'", ")", ":", "\n", "            ", "w1", "=", "tf", ".", "get_variable", "(", "'DQfD_w1'", ",", "[", "self", ".", "state_dim", ",", "units_1", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'DQfD_b1'", ",", "[", "1", ",", "units_1", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "state", ",", "w1", ")", "+", "b1", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'DQfD_l2'", ")", ":", "\n", "            ", "w2", "=", "tf", ".", "get_variable", "(", "'DQfD_w2'", ",", "[", "units_1", ",", "units_2", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'DQfD_b2'", ",", "[", "1", ",", "units_2", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense2", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "dense1", ",", "w2", ")", "+", "b2", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'DQfD_l3'", ")", ":", "\n", "            ", "w3", "=", "tf", ".", "get_variable", "(", "'DQfD_w3'", ",", "[", "units_2", ",", "a_d", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b3", "=", "tf", ".", "get_variable", "(", "'DQfD_b3'", ",", "[", "1", ",", "a_d", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense3", "=", "tf", ".", "matmul", "(", "dense2", ",", "w3", ")", "+", "b3", "\n", "", "return", "dense3", "\n", "\n", "", "@", "lazy_property", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.Q_select": [[93, 101], ["tensorflow.variable_scope", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "tensorflow.keras.regularizers.l2", "DQfD_V3.DQfD.build_layers"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.build_layers"], ["def", "Q_select", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'DQfD_select_net'", ")", "as", "scope", ":", "\n", "            ", "c_names", "=", "[", "'DQfD_select_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "w_i", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", "\n", "b_i", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "reg", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l", "=", "0.2", ")", "\n", "return", "self", ".", "build_layers", "(", "self", ".", "select_input", ",", "c_names", ",", "24", ",", "24", ",", "w_i", ",", "b_i", ",", "reg", ")", "\n", "\n", "", "", "@", "lazy_property", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.Q_eval": [[102, 109], ["tensorflow.variable_scope", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "DQfD_V3.DQfD.build_layers"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.build_layers"], ["def", "Q_eval", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'DQfD_eval_net'", ")", "as", "scope", ":", "\n", "            ", "c_names", "=", "[", "'DQfD_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "w_i", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", "\n", "b_i", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "return", "self", ".", "build_layers", "(", "self", ".", "eval_input", ",", "c_names", ",", "24", ",", "24", ",", "w_i", ",", "b_i", ")", "\n", "\n", "", "", "def", "loss_l", "(", "self", ",", "ae", ",", "a", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.loss_l": [[110, 112], ["None"], "methods", ["None"], ["        ", "return", "0.0", "if", "ae", "==", "a", "else", "0.8", "\n", "\n", "", "def", "loss_jeq", "(", "self", ",", "Q_select", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.loss_jeq": [[113, 122], ["range", "float", "range", "tensorflow.maximum", "DQfD_V3.DQfD.loss_l"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_l"], ["        ", "jeq", "=", "0.0", "\n", "for", "i", "in", "range", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", ":", "\n", "            ", "ae", "=", "self", ".", "action_batch", "[", "i", "]", "\n", "max_value", "=", "float", "(", "\"-inf\"", ")", "\n", "for", "a", "in", "range", "(", "self", ".", "action_dim", ")", ":", "\n", "                ", "max_value", "=", "tf", ".", "maximum", "(", "Q_select", "[", "i", "]", "[", "a", "]", "+", "self", ".", "loss_l", "(", "ae", ",", "a", ")", ",", "max_value", ")", "\n", "", "jeq", "+=", "self", ".", "isdemo", "[", "i", "]", "*", "(", "max_value", "-", "Q_select", "[", "i", "]", "[", "ae", "]", ")", "\n", "", "return", "jeq", "\n", "\n", "", "@", "lazy_property", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.loss": [[123, 130], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "DQfD_V3.DQfD.loss_jeq", "tensorflow.reduce_sum", "tensorflow.squared_difference", "tensorflow.squared_difference", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.get_collection", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_jeq"], ["def", "loss", "(", "self", ")", ":", "\n", "        ", "l_dq", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "Q_select", ",", "self", ".", "y_input", ")", ")", "\n", "l_n_dq", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "Q_select", ",", "self", ".", "n_step_y_input", ")", ")", "\n", "l_jeq", "=", "self", ".", "loss_jeq", "(", "self", ".", "Q_select", ")", "\n", "l_l2", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_mean", "(", "reg_l", ")", "for", "reg_l", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "]", ")", "\n", "return", "self", ".", "ISWeights", "*", "tf", ".", "reduce_sum", "(", "[", "l", "*", "\u03bb", "for", "l", ",", "\u03bb", "in", "zip", "(", "[", "l_dq", ",", "l_n_dq", ",", "l_jeq", ",", "l_l2", "]", ",", "self", ".", "config", ".", "LAMBDA", ")", "]", ")", "\n", "\n", "", "@", "lazy_property", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.abs_errors": [[131, 134], ["tensorflow.reduce_sum", "tensorflow.abs"], "methods", ["None"], ["def", "abs_errors", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "self", ".", "y_input", "-", "self", ".", "Q_select", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "@", "lazy_property", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.optimize": [[135, 139], ["tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize"], "methods", ["None"], ["def", "optimize", "(", "self", ")", ":", "\n", "        ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "config", ".", "LEARNING_RATE", ")", "\n", "return", "optimizer", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "", "@", "lazy_property", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.update_target_net": [[140, 145], ["tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "zip"], "methods", ["None"], ["def", "update_target_net", "(", "self", ")", ":", "\n", "        ", "select_params", "=", "tf", ".", "get_collection", "(", "'DQfD_select_net_params'", ")", "\n", "eval_params", "=", "tf", ".", "get_collection", "(", "'DQfD_eval_net_params'", ")", "\n", "return", "[", "tf", ".", "assign", "(", "e", ",", "s", ")", "for", "e", ",", "s", "in", "zip", "(", "eval_params", ",", "select_params", ")", "]", "\n", "\n", "", "def", "save_model", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.save_model": [[146, 148], ["print", "DQfD_V3.DQfD.saver.save"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["        ", "print", "(", "\"Model saved in : {}\"", ".", "format", "(", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "self", ".", "config", ".", "MODEL_PATH", ")", ")", ")", "\n", "\n", "", "def", "restore_model", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.restore_model": [[149, 152], ["DQfD_V3.DQfD.saver.restore", "print"], "methods", ["None"], ["        ", "self", ".", "saver", ".", "restore", "(", "self", ".", "sess", ",", "self", ".", "config", ".", "MODEL_PATH", ")", "\n", "print", "(", "\"Model restored.\"", ")", "\n", "\n", "", "def", "perceive", "(", "self", ",", "transition", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.perceive": [[153, 155], ["DQfD_V3.DQfD.replay_memory.store", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["        ", "self", ".", "replay_memory", ".", "store", "(", "np", ".", "array", "(", "transition", ")", ")", "\n", "\n", "", "def", "train_Q_network", "(", "self", ",", "pre_train", "=", "False", ",", "update", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.train_Q_network": [[156, 212], ["actual_memory.sample", "numpy.random.shuffle", "DQfD_V3.DQfD.Q_select.eval", "DQfD_V3.DQfD.Q_eval.eval", "DQfD_V3.DQfD.Q_select.eval", "DQfD_V3.DQfD.Q_eval.eval", "numpy.zeros", "numpy.zeros", "range", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.replay_memory.batch_update", "DQfD_V3.DQfD.replay_memory.full", "numpy.copy", "numpy.argmax", "numpy.argmax", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.replay_memory.full", "DQfD_V3.DQfD.Q_select.eval", "int", "state_batch[].reshape", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.batch_update", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full"], ["        ", "\"\"\"\n        :param pre_train: True means should sample from demo_buffer instead of replay_buffer\n        :param update: True means the action \"update_target_net\" executes outside, and can be ignored in the function\n        \"\"\"", "\n", "if", "not", "pre_train", "and", "not", "self", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "            ", "return", "\n", "", "self", ".", "time_step", "+=", "1", "\n", "\n", "assert", "self", ".", "replay_memory", ".", "full", "(", ")", "or", "pre_train", "\n", "\n", "actual_memory", "=", "self", ".", "demo_memory", "if", "pre_train", "else", "self", ".", "replay_memory", "\n", "tree_idxes", ",", "minibatch", ",", "ISWeights", "=", "actual_memory", ".", "sample", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", "\n", "\n", "np", ".", "random", ".", "shuffle", "(", "minibatch", ")", "\n", "state_batch", "=", "[", "data", "[", "0", "]", "for", "data", "in", "minibatch", "]", "\n", "action_batch", "=", "[", "data", "[", "1", "]", "for", "data", "in", "minibatch", "]", "\n", "reward_batch", "=", "[", "data", "[", "2", "]", "for", "data", "in", "minibatch", "]", "\n", "next_state_batch", "=", "[", "data", "[", "3", "]", "for", "data", "in", "minibatch", "]", "\n", "done_batch", "=", "[", "data", "[", "4", "]", "for", "data", "in", "minibatch", "]", "\n", "demo_data", "=", "[", "data", "[", "5", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_reward_batch", "=", "[", "data", "[", "6", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_state_batch", "=", "[", "data", "[", "7", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_done_batch", "=", "[", "data", "[", "8", "]", "for", "data", "in", "minibatch", "]", "\n", "actual_n", "=", "[", "data", "[", "9", "]", "for", "data", "in", "minibatch", "]", "\n", "\n", "Q_select", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "next_state_batch", "}", ")", "\n", "Q_eval", "=", "self", ".", "Q_eval", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "eval_input", ":", "next_state_batch", "}", ")", "\n", "n_step_Q_select", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "n_step_state_batch", "}", ")", "\n", "n_step_Q_eval", "=", "self", ".", "Q_eval", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "eval_input", ":", "n_step_state_batch", "}", ")", "\n", "\n", "y_batch", "=", "np", ".", "zeros", "(", "(", "self", ".", "config", ".", "BATCH_SIZE", ",", "self", ".", "action_dim", ")", ")", "\n", "n_step_y_batch", "=", "np", ".", "zeros", "(", "(", "self", ".", "config", ".", "BATCH_SIZE", ",", "self", ".", "action_dim", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", ":", "\n", "            ", "temp", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "state_batch", "[", "i", "]", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "state_dim", ")", ")", "}", ")", "[", "0", "]", "\n", "temp_0", "=", "np", ".", "copy", "(", "temp", ")", "\n", "action", "=", "np", ".", "argmax", "(", "Q_select", "[", "i", "]", ")", "\n", "temp", "[", "action_batch", "[", "i", "]", "]", "=", "reward_batch", "[", "i", "]", "+", "(", "1", "-", "int", "(", "done_batch", "[", "i", "]", ")", ")", "*", "self", ".", "config", ".", "GAMMA", "*", "Q_eval", "[", "i", "]", "[", "action", "]", "\n", "y_batch", "[", "i", "]", "=", "temp", "\n", "action", "=", "np", ".", "argmax", "(", "n_step_Q_select", "[", "i", "]", ")", "\n", "q_n_step", "=", "(", "1", "-", "int", "(", "n_step_done_batch", "[", "i", "]", ")", ")", "*", "self", ".", "config", ".", "GAMMA", "**", "actual_n", "[", "i", "]", "*", "n_step_Q_eval", "[", "i", "]", "[", "action", "]", "\n", "temp_0", "[", "action_batch", "[", "i", "]", "]", "=", "n_step_reward_batch", "[", "i", "]", "+", "q_n_step", "\n", "n_step_y_batch", "[", "i", "]", "=", "temp_0", "\n", "\n", "", "_", ",", "abs_errors", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "optimize", ",", "self", ".", "abs_errors", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "y_input", ":", "y_batch", ",", "\n", "self", ".", "n_step_y_input", ":", "n_step_y_batch", ",", "\n", "self", ".", "select_input", ":", "state_batch", ",", "\n", "self", ".", "action_batch", ":", "action_batch", ",", "\n", "self", ".", "isdemo", ":", "demo_data", ",", "\n", "self", ".", "ISWeights", ":", "ISWeights", "}", ")", "\n", "\n", "self", ".", "replay_memory", ".", "batch_update", "(", "tree_idxes", ",", "abs_errors", ")", "\n", "\n", "if", "update", "and", "self", ".", "time_step", "%", "self", ".", "config", ".", "UPDATE_TARGET_NET", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_net", ")", "\n", "\n", "", "", "def", "egreedy_action", "(", "self", ",", "state", ",", "execution", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.DQfD.egreedy_action": [[213, 219], ["numpy.argmax", "random.random", "random.randint", "DQfD_V3.DQfD.Q_select.eval"], "methods", ["None"], ["        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "0", "\n", "", "if", "random", ".", "random", "(", ")", "<=", "self", ".", "epsilon", ":", "\n", "            ", "return", "random", ".", "randint", "(", "0", ",", "self", ".", "action_dim", "-", "1", ")", "\n", "", "return", "np", ".", "argmax", "(", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "[", "state", "]", "}", ")", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.DQfD_V3.lazy_property": [[14, 24], ["functools.wraps", "getattr", "hasattr", "setattr", "func"], "function", ["None"], ["    ", "attribute", "=", "'_lazy_'", "+", "func", ".", "__name__", "\n", "\n", "@", "property", "\n", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "attribute", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "attribute", ",", "func", "(", "self", ")", ")", "\n", "", "return", "getattr", "(", "self", ",", "attribute", ")", "\n", "", "return", "wrapper", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.admiraldmvsdeepsarsa_advisor4.main": [[8, 51], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor4small", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor4", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert4.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "400000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.onevsone.admiraldmvsdeepsarsa_advisor2.main": [[8, 50], ["print", "tensorflow.Session", "pommerman.make", "pommerman.make.seed", "tf.Session.run", "cumulative_rewards.append", "cumulative_rewards.append", "range", "pommerman.make.close", "pommerman.agents.DeepsarsaAgent", "pommerman.agents.Advisor2small", "tensorflow.global_variables_initializer", "open", "myfile.write", "pommerman.make.reset", "pommerman.make.act", "agent_list[].learn", "agent_list[].learn", "print", "print", "pommerman.make.step", "pommerman.make.act", "agent_list[].store", "agent_list[].store", "agent_list[].set", "open", "myfile.write"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.__init__.make", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.seed", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.envs.v0.Pomme.close", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.act", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.agents.advisor1.Advisor1.set"], ["def", "main", "(", ")", ":", "\n", "    ", "print", "(", "pommerman", ".", "REGISTRY", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "agent_list", "=", "[", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "agents", ".", "DeepsarsaAgent", "(", "372", ",", "sess", ")", ",", "\n", "agents", ".", "Advisor2", "(", "372", ",", "False", ",", "sess", ")", ",", "\n", "]", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "env", "=", "pommerman", ".", "make", "(", "'PommeTeam-v0'", ",", "agent_list", ")", "\n", "\n", "env", ".", "seed", "(", "1", ")", "\n", "\n", "with", "open", "(", "'pommermanteamcompetitionexpert2.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1},{2},{3},{4}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward2(DQNExpert)\"", ",", "\"Reward1(DQN)\"", ",", "\"Reward1(DQNExpert)\"", ")", ")", "\n", "\n", "\n", "", "cumulative_rewards", "=", "[", "]", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "cumulative_rewards", ".", "append", "(", "0", ")", "\n", "for", "i_episode", "in", "range", "(", "100000", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "done", "=", "False", "\n", "actions", "=", "env", ".", "act", "(", "state", ")", "\n", "while", "not", "done", ":", "\n", "            ", "state_new", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "actions_new", "=", "env", ".", "act", "(", "state_new", ")", "\n", "agent_list", "[", "0", "]", ".", "store", "(", "state", "[", "0", "]", ",", "actions", "[", "0", "]", ",", "reward", "[", "0", "]", ",", "state_new", "[", "0", "]", ",", "actions_new", "[", "0", "]", ")", "\n", "agent_list", "[", "2", "]", ".", "store", "(", "state", "[", "2", "]", ",", "actions", "[", "2", "]", ",", "reward", "[", "2", "]", ",", "state_new", "[", "2", "]", ",", "actions_new", "[", "2", "]", ")", "\n", "action_list", "=", "[", "]", "\n", "action_list", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "2", "]", ")", "\n", "action_list", ".", "append", "(", "actions", "[", "3", "]", ")", "\n", "\n", "action_list2", "=", "[", "]", "\n", "action_list2", ".", "append", "(", "actions", "[", "0", "]", ")", "\n", "action_list2", ".", "append", "(", "actions", "[", "1", "]", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_admiraldm.AdmiralDMNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "9", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'Advisorq_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'Advisorq_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.copy_network": [[53, 58], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork._build_net": [[61, 112], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorq_s'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Advisorq_Q_target'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiraldmValue'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_eval_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'Advisorq_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_loss'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_train'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "+", "3", "]", ",", "name", "=", "'Advisorq_s_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_target_net'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "c_names", "=", "[", "'Advisorq_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'Advisorq_w1'", ",", "[", "self", ".", "n_features", "+", "3", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'Advisorq_b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_hl1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hw1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'Advisorq_hb1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorq_l2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'Advisorq_w2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'Advisorq_b2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.store_transition": [[113, 136], ["list", "range", "numpy.array", "list", "range", "numpy.array", "numpy.hstack", "hasattr", "len", "float", "numpy.array.append", "len", "float", "float", "numpy.array.append"], "methods", ["None"], ["\n", "", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "a1", ",", "a1_", ",", "r", ",", "s_", ",", "a_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "s", "=", "list", "(", "s", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1", ")", ")", ":", "\n", "            ", "new_a", "=", "a1", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s", ".", "append", "(", "new_a", ")", "\n", "", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a1_", ")", ")", ":", "\n", "            ", "new_a", "=", "float", "(", "a1_", "[", "i", "]", ")", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "s_", ".", "append", "(", "new_a", ")", "\n", "", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "\n", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.choose_action": [[137, 155], ["list", "range", "numpy.array", "len", "float", "numpy.array.append", "numpy.random.uniform", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\n", "", "def", "choose_action", "(", "self", ",", "observation", ",", "a2", ")", ":", "\n", "\n", "        ", "observation", "=", "list", "(", "observation", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a2", ")", ")", ":", "\n", "            ", "new_a", "=", "a2", "[", "i", "]", "\n", "new_a", "=", "float", "(", "new_a", ")", "\n", "observation", ".", "append", "(", "new_a", ")", "\n", "", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n", "", "def", "learn", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.learn": [[156, 188], ["RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "q_eval.copy", "batch_memory[].astype", "numpy.arange", "batch_memory[].astype", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "RL_brain_admiraldm.AdmiralDMNetwork.cost_his.append", "RL_brain_admiraldm.AdmiralDMNetwork.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "(", "self", ".", "n_features", "+", "3", ")", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "5", "]", ".", "astype", "(", "int", ")", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "4", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "(", "self", ".", "n_features", "+", "3", ")", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.save_model": [[190, 195], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.restore_model": [[198, 203], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldm.AdmiralDMNetwork.plot_cost": [[204, 210], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.__init__": [[12, 19], ["numpy.zeros", "numpy.zeros"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "capacity", ",", "permanent_data", "=", "0", ")", ":", "\n", "        ", "self", ".", "capacity", "=", "capacity", "\n", "self", ".", "tree", "=", "np", ".", "zeros", "(", "2", "*", "capacity", "-", "1", ")", "# stores not probabilities but priorities !!!", "\n", "self", ".", "data", "=", "np", ".", "zeros", "(", "capacity", ",", "dtype", "=", "object", ")", "# stores transitions", "\n", "self", ".", "permanent_data", "=", "permanent_data", "# numbers of data which never be replaced, for demo data protection", "\n", "assert", "0", "<=", "self", ".", "permanent_data", "<=", "self", ".", "capacity", "# equal is also illegal", "\n", "self", ".", "full", "=", "False", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.__len__": [[20, 22], ["None"], "methods", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "capacity", "if", "self", ".", "full", "else", "self", ".", "data_pointer", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add": [[23, 31], ["Memory.SumTree.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["\n", "", "def", "add", "(", "self", ",", "p", ",", "data", ")", ":", "\n", "        ", "tree_idx", "=", "self", ".", "data_pointer", "+", "self", ".", "capacity", "-", "1", "\n", "self", ".", "data", "[", "self", ".", "data_pointer", "]", "=", "data", "\n", "self", ".", "update", "(", "tree_idx", ",", "p", ")", "\n", "self", ".", "data_pointer", "+=", "1", "\n", "if", "self", ".", "data_pointer", ">=", "self", ".", "capacity", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "self", ".", "data_pointer", "=", "self", ".", "data_pointer", "%", "self", ".", "capacity", "+", "self", ".", "permanent_data", "# make sure demo data permanent", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.update": [[32, 38], ["None"], "methods", ["None"], ["\n", "", "", "def", "update", "(", "self", ",", "tree_idx", ",", "p", ")", ":", "\n", "        ", "change", "=", "p", "-", "self", ".", "tree", "[", "tree_idx", "]", "\n", "self", ".", "tree", "[", "tree_idx", "]", "=", "p", "\n", "while", "tree_idx", "!=", "0", ":", "\n", "            ", "tree_idx", "=", "(", "tree_idx", "-", "1", ")", "//", "2", "\n", "self", ".", "tree", "[", "tree_idx", "]", "+=", "change", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.get_leaf": [[39, 55], ["len"], "methods", ["None"], ["\n", "", "", "def", "get_leaf", "(", "self", ",", "v", ")", ":", "\n", "        ", "parent_idx", "=", "0", "\n", "while", "True", ":", "\n", "            ", "left_child_idx", "=", "2", "*", "parent_idx", "+", "1", "\n", "right_child_idx", "=", "left_child_idx", "+", "1", "\n", "if", "left_child_idx", ">=", "len", "(", "self", ".", "tree", ")", ":", "\n", "                ", "leaf_idx", "=", "parent_idx", "\n", "break", "\n", "", "if", "v", "<=", "self", ".", "tree", "[", "left_child_idx", "]", ":", "\n", "                ", "parent_idx", "=", "left_child_idx", "\n", "", "else", ":", "\n", "                ", "v", "-=", "self", ".", "tree", "[", "left_child_idx", "]", "\n", "parent_idx", "=", "right_child_idx", "\n", "\n", "", "", "data_idx", "=", "leaf_idx", "-", "self", ".", "capacity", "+", "1", "\n", "return", "leaf_idx", ",", "self", ".", "tree", "[", "leaf_idx", "]", ",", "self", ".", "data", "[", "data_idx", "]", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.total_p": [[56, 59], ["None"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "total_p", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tree", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.__init__": [[70, 73], ["Memory.SumTree"], "methods", ["None"], ["\n", "def", "__init__", "(", "self", ",", "capacity", ",", "permanent_data", "=", "0", ")", ":", "\n", "        ", "self", ".", "permanent_data", "=", "permanent_data", "\n", "self", ".", "tree", "=", "SumTree", "(", "capacity", ",", "permanent_data", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.__len__": [[74, 76], ["len"], "methods", ["None"], ["\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tree", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full": [[77, 79], ["None"], "methods", ["None"], ["\n", "", "def", "full", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tree", ".", "full", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store": [[80, 85], ["numpy.max", "Memory.Memory.tree.add"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.add"], ["\n", "", "def", "store", "(", "self", ",", "transition", ")", ":", "\n", "        ", "max_p", "=", "np", ".", "max", "(", "self", ".", "tree", ".", "tree", "[", "-", "self", ".", "tree", ".", "capacity", ":", "]", ")", "\n", "if", "max_p", "==", "0", ":", "\n", "            ", "max_p", "=", "self", ".", "abs_err_upper", "\n", "", "self", ".", "tree", ".", "add", "(", "max_p", ",", "transition", ")", "# set the max_p for new transition", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.sample": [[86, 104], ["Memory.Memory.full", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.min", "range", "numpy.min", "numpy.random.uniform", "Memory.Memory.tree.get_leaf", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.SumTree.get_leaf"], ["\n", "", "def", "sample", "(", "self", ",", "n", ")", ":", "\n", "        ", "assert", "self", ".", "full", "(", ")", "\n", "b_idx", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "b_memory", "=", "np", ".", "empty", "(", "(", "n", ",", "self", ".", "tree", ".", "data", "[", "0", "]", ".", "size", ")", ",", "dtype", "=", "object", ")", "\n", "ISWeights", "=", "np", ".", "empty", "(", "(", "n", ",", "1", ")", ")", "\n", "pri_seg", "=", "self", ".", "tree", ".", "total_p", "/", "n", "\n", "self", ".", "beta", "=", "np", ".", "min", "(", "[", "1.", ",", "self", ".", "beta", "+", "self", ".", "beta_increment_per_sampling", "]", ")", "\n", "\n", "min_prob", "=", "np", ".", "min", "(", "self", ".", "tree", ".", "tree", "[", "-", "self", ".", "tree", ".", "capacity", ":", "]", ")", "/", "self", ".", "tree", ".", "total_p", "\n", "assert", "min_prob", ">", "0", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "v", "=", "np", ".", "random", ".", "uniform", "(", "pri_seg", "*", "i", ",", "pri_seg", "*", "(", "i", "+", "1", ")", ")", "\n", "idx", ",", "p", ",", "data", "=", "self", ".", "tree", ".", "get_leaf", "(", "v", ")", "# note: idx is the index in self.tree.tree", "\n", "prob", "=", "p", "/", "self", ".", "tree", ".", "total_p", "\n", "ISWeights", "[", "i", ",", "0", "]", "=", "np", ".", "power", "(", "prob", "/", "min_prob", ",", "-", "self", ".", "beta", ")", "\n", "b_idx", "[", "i", "]", ",", "b_memory", "[", "i", "]", "=", "idx", ",", "data", "\n", "", "return", "b_idx", ",", "b_memory", ",", "ISWeights", "# note: b_idx stores indexes in self.tree.tree, not in self.tree.data !!!", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.batch_update": [[105, 112], ["numpy.minimum", "numpy.power", "zip", "Memory.Memory.tree.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["\n", "# update priority", "\n", "", "def", "batch_update", "(", "self", ",", "tree_idxes", ",", "abs_errors", ")", ":", "\n", "        ", "abs_errors", "[", "self", ".", "tree", ".", "permanent_data", ":", "]", "+=", "self", ".", "epsilon", "\n", "# priorities of demo transitions are given a bonus of demo_epsilon, to boost the frequency that they are sampled", "\n", "abs_errors", "[", ":", "self", ".", "tree", ".", "permanent_data", "]", "+=", "self", ".", "demo_epsilon", "\n", "clipped_errors", "=", "np", ".", "minimum", "(", "abs_errors", ",", "self", ".", "abs_err_upper", ")", "\n", "ps", "=", "np", ".", "power", "(", "clipped_errors", ",", "self", ".", "alpha", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitadmiraldm.change_observation": [[13, 22], ["observation.tolist.tolist", "range", "numpy.array", "len", "range", "len", "range", "len", "new_list.append"], "function", ["None"], ["def", "change_observation", "(", "observation", ")", ":", "\n", "    ", "observation", "=", "observation", ".", "tolist", "(", ")", "\n", "new_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "observation", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "observation", "[", "i", "]", ")", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "observation", "[", "i", "]", "[", "j", "]", ")", ")", ":", "\n", "                ", "new_list", ".", "append", "(", "observation", "[", "i", "]", "[", "j", "]", "[", "k", "]", ")", "\n", "", "", "", "new_observation", "=", "np", ".", "array", "(", "new_list", ")", "\n", "return", "new_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitadmiraldm.linear_decay": [[24, 40], ["enumerate"], "function", ["None"], ["", "def", "linear_decay", "(", "epoch", ",", "x", ",", "y", ")", ":", "\n", "    ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "        ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "        ", "if", "epoch", "<=", "x_i", ":", "\n", "            ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitadmiraldm.run_pursuit": [[43, 119], ["print", "open", "myfile.write", "env.reset", "range", "env.agent_iter", "pettingzoosislpursuitadmiraldm.linear_decay", "print", "len", "action_list[].append", "env.last", "pettingzoosislpursuitadmiraldm.change_observation", "obs_list[].append", "action_list[].append", "reward_list[].append", "open", "myfile.write", "range", "range", "range", "numpy.random.uniform", "RL.choose_action", "range", "RL2.choose_action", "len", "range", "range", "RL2.store_transition", "len", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "env.step", "RL2.learn", "len", "len", "int", "len", "len", "len", "len", "len", "len", "action_opp.append", "action_opp.append", "action_opp_new.append"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.change_observation", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "run_pursuit", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislpursuitadvisorq.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(EQ)\"", ")", ")", "\n", "", "num_episode", "=", "0", "\n", "eps", "=", "0.8", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "accumulated_reward", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "            ", "action_list", "[", "i", "]", ".", "append", "(", "0", ")", "\n", "", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "observation", "=", "change_observation", "(", "observation", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "eps", ":", "\n", "                ", "action", "=", "RL", ".", "choose_action", "(", "observation", ",", "execution", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "action_opp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "agent_num", ":", "\n", "                        ", "action_opp", ".", "append", "(", "action_list", "[", "i", "]", "[", "-", "1", "]", ")", "\n", "\n", "", "", "action", "=", "RL2", ".", "choose_action", "(", "observation", ",", "action_opp", ")", "\n", "\n", "", "action_list", "[", "agent_num", "]", ".", "append", "(", "action", ")", "\n", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "\n", "                ", "action_opp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "agent_num", ":", "\n", "                        ", "action_opp", ".", "append", "(", "action_list", "[", "i", "]", "[", "0", "]", ")", "\n", "\n", "", "", "action_opp_new", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "agent_num", ":", "\n", "                        ", "action_opp_new", ".", "append", "(", "action_list", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "RL2", ".", "store_transition", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "1", "]", ",", "action_opp", ",", "action_opp_new", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ",", "action_list", "[", "agent_num", "]", "[", "2", "]", ")", "\n", "\n", "", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "if", "(", "step", ">", "200", ")", "and", "(", "step", "%", "5", "==", "0", ")", ":", "\n", "                ", "RL2", ".", "learn", "(", ")", "\n", "\n", "", "agent_num", "=", "agent_num", "+", "1", "\n", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'pettingzoosislpursuitadvisorq.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "eps", "=", "linear_decay", "(", "num_episode", ",", "[", "0", ",", "int", "(", "1000", "*", "0.99", ")", ",", "1000", "]", ",", "[", "0.8", ",", "0.2", ",", "0.01", "]", ")", "\n", "print", "(", "\"We are now in episode\"", ",", "num_episode", ")", "\n", "", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.change_observation": [[28, 37], ["observation.tolist.tolist", "range", "numpy.array", "len", "range", "len", "range", "len", "new_list.append"], "function", ["None"], ["def", "change_observation", "(", "observation", ")", ":", "\n", "    ", "observation", "=", "observation", ".", "tolist", "(", ")", "\n", "new_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "observation", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "observation", "[", "i", "]", ")", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "observation", "[", "i", "]", "[", "j", "]", ")", ")", ":", "\n", "                ", "new_list", ".", "append", "(", "observation", "[", "i", "]", "[", "j", "]", "[", "k", "]", ")", "\n", "", "", "", "new_observation", "=", "np", ".", "array", "(", "new_list", ")", "\n", "return", "new_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step": [[38, 47], ["list", "sum", "range", "len", "min", "t_list[].extend", "enumerate", "len", "min", "len", "Config.Config.trajectory_n", "Config.Config.trajectory_n"], "function", ["None"], ["", "def", "set_n_step", "(", "container", ",", "n", ")", ":", "\n", "    ", "t_list", "=", "list", "(", "container", ")", "\n", "n_step_reward", "=", "sum", "(", "[", "t", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "i", "for", "i", ",", "t", "in", "enumerate", "(", "t_list", "[", "0", ":", "min", "(", "len", "(", "t_list", ")", ",", "n", ")", "-", "1", "]", ")", "]", ")", "\n", "for", "begin", "in", "range", "(", "len", "(", "t_list", ")", ")", ":", "\n", "        ", "end", "=", "min", "(", "len", "(", "t_list", ")", "-", "1", ",", "begin", "+", "Config", ".", "trajectory_n", "-", "1", ")", "\n", "n_step_reward", "+=", "t_list", "[", "end", "]", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "(", "end", "-", "begin", ")", "\n", "t_list", "[", "begin", "]", ".", "extend", "(", "[", "n_step_reward", ",", "t_list", "[", "end", "]", "[", "3", "]", ",", "t_list", "[", "end", "]", "[", "4", "]", ",", "end", "-", "begin", "+", "1", "]", ")", "\n", "n_step_reward", "=", "(", "n_step_reward", "-", "t_list", "[", "begin", "]", "[", "2", "]", ")", "/", "Config", ".", "GAMMA", "\n", "", "return", "t_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.restorevalue": [[49, 59], ["collections.deque"], "function", ["None"], ["", "def", "restorevalue", "(", ")", ":", "\n", "\n", "\n", "    ", "global", "score", "\n", "global", "n_step_reward", "\n", "global", "t_q", "\n", "\n", "score", "=", "0", "\n", "n_step_reward", "=", "None", "\n", "t_q", "=", "deque", "(", "maxlen", "=", "Config", ".", "trajectory_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.get_demo_data": [[60, 107], ["collections.deque", "env.reset", "env.agent_iter", "open", "pickle.dump", "env.last", "pettingzoosislpursuitDQfD.change_observation", "obs_list[].append", "RL.choose_action", "action_list[].append", "reward_list[].append", "pettingzoosislpursuitDQfD.set_n_step", "collections.deque.extend", "print", "range", "range", "range", "len", "set_n_step.append", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "env.step", "len", "len", "len", "collections.deque", "len", "len", "len", "itertools.islice"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.change_observation", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["", "def", "get_demo_data", "(", ")", ":", "\n", "\n", "\n", "    ", "demo_buffer", "=", "deque", "(", ")", "\n", "e", "=", "0", "\n", "step", "=", "0", "\n", "while", "True", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "accumulated_reward", "=", "0", "\n", "demo", "=", "[", "]", "\n", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "observation", "=", "change_observation", "(", "observation", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "action", "=", "RL", ".", "choose_action", "(", "observation", ",", "execution", "=", "True", ")", "\n", "action_list", "[", "agent_num", "]", ".", "append", "(", "action", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "demo", ".", "append", "(", "[", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "0", "]", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ",", "done", ",", "1.0", "]", ")", "\n", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "", "step", "+=", "1", "\n", "agent_num", "=", "agent_num", "+", "1", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "done", ":", "\n", "            ", "demo", "=", "set_n_step", "(", "demo", ",", "Config", ".", "trajectory_n", ")", "\n", "demo_buffer", ".", "extend", "(", "demo", ")", "\n", "print", "(", "\"episode:\"", ",", "e", ",", "\"  demo_buffer:\"", ",", "len", "(", "demo_buffer", ")", ")", "\n", "if", "len", "(", "demo_buffer", ")", ">=", "Config", ".", "demo_buffer_size", ":", "\n", "                ", "demo_buffer", "=", "deque", "(", "itertools", ".", "islice", "(", "demo_buffer", ",", "0", ",", "Config", ".", "demo_buffer_size", ")", ")", "\n", "break", "\n", "", "", "e", "+=", "1", "\n", "\n", "", "with", "open", "(", "Config", ".", "DEMO_DATA_PATH", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "demo_buffer", ",", "f", ",", "protocol", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.run_DQfD": [[110, 146], ["t_q.append", "t_q.popleft", "pettingzoosislpursuitDQfD.set_n_step", "agent.replay_memory.full", "len", "t_q[].extend", "agent.perceive", "agent.replay_memory.full", "agent.perceive", "agent.replay_memory.full", "scores.append", "agent.sess.run", "len", "sum", "agent.train_Q_network", "agent.train_Q_network", "enumerate"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.set_n_step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.perceive", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.perceive", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network"], ["", "", "def", "run_DQfD", "(", "state", ",", "action", ",", "reward", ",", "next_state", ",", "done", ")", ":", "\n", "\n", "    ", "global", "scores", "\n", "global", "score", "\n", "global", "n_step_reward", "\n", "global", "t_q", "\n", "global", "e", "\n", "global", "replay_full_episode", "\n", "if", "done", "is", "False", ":", "\n", "        ", "score", "+=", "reward", "\n", "reward_to_sub", "=", "0.", "if", "len", "(", "t_q", ")", "<", "t_q", ".", "maxlen", "else", "t_q", "[", "0", "]", "[", "2", "]", "\n", "t_q", ".", "append", "(", "[", "state", ",", "action", ",", "reward", ",", "next_state", ",", "done", ",", "0.0", "]", ")", "\n", "if", "len", "(", "t_q", ")", "==", "t_q", ".", "maxlen", ":", "\n", "            ", "if", "n_step_reward", "is", "None", ":", "\n", "                ", "n_step_reward", "=", "sum", "(", "[", "t", "[", "2", "]", "*", "Config", ".", "GAMMA", "**", "i", "for", "i", ",", "t", "in", "enumerate", "(", "t_q", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "n_step_reward", "=", "(", "n_step_reward", "-", "reward_to_sub", ")", "/", "Config", ".", "GAMMA", "\n", "n_step_reward", "+=", "reward", "*", "Config", ".", "GAMMA", "**", "(", "Config", ".", "trajectory_n", "-", "1", ")", "\n", "", "t_q", "[", "0", "]", ".", "extend", "(", "[", "n_step_reward", ",", "next_state", ",", "done", ",", "t_q", ".", "maxlen", "]", ")", "\n", "agent", ".", "perceive", "(", "t_q", "[", "0", "]", ")", "\n", "if", "agent", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "                ", "agent", ".", "train_Q_network", "(", ")", "\n", "replay_full_episode", "=", "replay_full_episode", "or", "e", "\n", "", "", "", "if", "done", ":", "\n", "        ", "t_q", ".", "popleft", "(", ")", "\n", "transitions", "=", "set_n_step", "(", "t_q", ",", "Config", ".", "trajectory_n", ")", "\n", "for", "t", "in", "transitions", ":", "\n", "            ", "agent", ".", "perceive", "(", "t", ")", "\n", "if", "agent", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "                ", "agent", ".", "train_Q_network", "(", ")", "\n", "replay_full_episode", "=", "replay_full_episode", "or", "e", "\n", "", "", "if", "agent", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "            ", "scores", ".", "append", "(", "score", ")", "\n", "agent", ".", "sess", ".", "run", "(", "agent", ".", "update_target_net", ")", "\n", "\n", "", "e", "=", "e", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.run_pursuit": [[148, 191], ["print", "open", "myfile.write", "env.reset", "env.agent_iter", "pettingzoosislpursuitDQfD.restorevalue", "print", "env.last", "pettingzoosislpursuitDQfD.change_observation", "obs_list[].append", "agent.egreedy_action", "action_list[].append", "reward_list[].append", "open", "myfile.write", "range", "range", "range", "len", "pettingzoosislpursuitDQfD.run_DQfD", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "env.step", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.restorevalue", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.change_observation", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.egreedy_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQfD.run_DQfD", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["", "", "def", "run_pursuit", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislpursuitDQfD.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(DQfD)\"", ")", ")", "\n", "\n", "", "num_episode", "=", "0", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "accumulated_reward", "=", "0", "\n", "for", "agent_iter", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "observation", "=", "change_observation", "(", "observation", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "action", "=", "agent", ".", "egreedy_action", "(", "observation", ")", "\n", "action_list", "[", "agent_num", "]", ".", "append", "(", "action", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "run_DQfD", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "0", "]", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ",", "done", ")", "\n", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "", "agent_num", "=", "agent_num", "+", "1", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "restorevalue", "(", ")", "\n", "\n", "with", "open", "(", "'pettingzoosislpursuitDQfD.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "print", "(", "\"The episode now is\"", ",", "num_episode", ")", "\n", "", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQN.change_observation": [[12, 21], ["observation.tolist.tolist", "range", "numpy.array", "len", "range", "len", "range", "len", "new_list.append"], "function", ["None"], ["def", "change_observation", "(", "observation", ")", ":", "\n", "    ", "observation", "=", "observation", ".", "tolist", "(", ")", "\n", "new_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "observation", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "observation", "[", "i", "]", ")", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "observation", "[", "i", "]", "[", "j", "]", ")", ")", ":", "\n", "                ", "new_list", ".", "append", "(", "observation", "[", "i", "]", "[", "j", "]", "[", "k", "]", ")", "\n", "", "", "", "new_observation", "=", "np", ".", "array", "(", "new_list", ")", "\n", "return", "new_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitDQN.run_pursuit": [[24, 131], ["RL.save_model", "RL.restore_model", "print", "open", "myfile.write", "env.reset", "env.agent_iter", "print", "env.last", "pettingzoosislpursuitDQN.change_observation", "obs_list[].append", "RL.choose_action", "action_list[].append", "reward_list[].append", "open", "myfile.write", "range", "range", "range", "len", "RL.store_transition", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "env.step", "RL.learn", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.restore_model", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.change_observation", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "run_pursuit", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislpursuitDQN.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(DQN)\"", ")", ")", "\n", "\n", "", "num_episode", "=", "0", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "accumulated_reward", "=", "0", "\n", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "observation", "=", "change_observation", "(", "observation", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "action", "=", "RL", ".", "choose_action", "(", "observation", ")", "\n", "action_list", "[", "agent_num", "]", ".", "append", "(", "action", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "RL", ".", "store_transition", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "0", "]", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ")", "\n", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "", "step", "+=", "1", "\n", "if", "(", "step", ">", "200", ")", "and", "(", "step", "%", "5", "==", "0", ")", ":", "\n", "                ", "RL", ".", "learn", "(", ")", "\n", "", "agent_num", "=", "agent_num", "+", "1", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'pettingzoosislpursuitDQN.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "print", "(", "\"The episode now is\"", ",", "num_episode", ")", "\n", "\n", "\n", "#Code for loop that does both training and execution ", "\n", "#while num_episode < 1100:", "\n", "#    agent_num = 0", "\n", "#    env.reset()", "\n", "#    # initial observation", "\n", "#    obs_list = [[] for _ in range(len(env.agents))]", "\n", "#    action_list = [[] for _ in range(len(env.agents))]", "\n", "#    reward_list = [[] for _ in range(len(env.agents))]", "\n", "#    accumulated_reward = 0", "\n", "#    for agent in env.agent_iter():", "\n", "#        observation, reward, done, info = env.last()", "\n", "#        observation = change_observation(observation)", "\n", "#        accumulated_reward = accumulated_reward + reward", "\n", "#        # RL choose action based on observation", "\n", "#        obs_list[agent_num].append(observation)", "\n", "#        ", "\n", "#        if num_episode >= 1000: ", "\n", "#            action = RL.choose_action(observation, execution=True)", "\n", "#        else: ", "\n", "#            action = RL.choose_action(observation)", "\n", "#        action_list[agent_num].append(action)", "\n", "#        reward_list[agent_num].append(reward)", "\n", "#        ", "\n", "#        if num_episode < 1000:", "\n", "#            if len(obs_list[agent_num]) == 2:", "\n", "#                RL.store_transition(obs_list[agent_num][0], action_list[agent_num][0], reward_list[agent_num][0], obs_list[agent_num][1])", "\n", "#                obs_list[agent_num].pop(0)", "\n", "#                action_list[agent_num].pop(0)", "\n", "#                reward_list[agent_num].pop(0)", "\n", "#                ", "\n", "#                ", "\n", "#        if done == False:", "\n", "#            env.step(action)", "\n", "#        ", "\n", "#        step += 1", "\n", "#        ", "\n", "#        if num_episode < 1000:", "\n", "#            if (step > 200) and (step % 5 == 0):", "\n", "#                RL.learn()", "\n", "#        ", "\n", "#        agent_num = agent_num + 1", "\n", "#        ", "\n", "#        ", "\n", "#        if agent_num == len(env.agents):", "\n", "#            agent_num = 0", "\n", "#        if done:", "\n", "#            break", "\n", "#        ", "\n", "#    with open('pettingzoosislpursuitDQN.csv', 'a') as myfile:", "\n", "#        accumulated_reward = accumulated_reward/len(env.agents)", "\n", "#        myfile.write('{0},{1}\\n'.format(num_episode, accumulated_reward))", "\n", "#    num_episode = num_episode + 1            ", "\n", "#    print(\"The episode now is\", num_episode) ", "\n", "\n", "\n", "\n", "", "RL", ".", "save_model", "(", "\"./tmp/dqnmodel.ckpt\"", ")", "\n", "RL", ".", "restore_model", "(", "\"./tmp/dqnmodel.ckpt\"", ")", "\n", "\n", "\n", "# end of game", "\n", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.__init__": [[11, 55], ["numpy.zeros", "tensorflow.placeholder", "tensorflow.one_hot", "RL_brain_CHAT.CHAT._build_net", "RL_brain_CHAT.CHAT._build_confidence_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT._build_confidence_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "1000", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "+", "1", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "4", ")", ")", "\n", "\n", "self", ".", "advisor_act", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ",", ")", ",", "name", "=", "'CHAT_advisor_act'", ")", "\n", "self", ".", "advisor_one_hot", "=", "tf", ".", "one_hot", "(", "self", ".", "advisor_act", ",", "depth", "=", "self", ".", "n_actions", "-", "1", ",", "on_value", "=", "1.0", ",", "off_value", "=", "0.0", ")", "\n", "self", ".", "_build_net", "(", ")", "\n", "self", ".", "_build_confidence_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'CHAT_target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'CHAT_eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.copy_network": [[58, 63], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT._build_net": [[64, 114], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'CHAT_s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'CHAT_Q_target_1'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'CHATValue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_eval_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'CHAT_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'CHAT_s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_target_net_1'", ")", ":", "\n", "                ", "c_names", "=", "[", "'CHAT_target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT._build_confidence_net": [[115, 142], ["tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["\n", "", "", "", "", "def", "_build_confidence_net", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'ConfidenceValue'", ")", ":", "\n", "            ", "self", ".", "name_scope2", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_confidence_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'CHAT_confidence_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_3'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'CHAT_w_3'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'CHAT_b_3'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_hl_3'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hw_3'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'CHAT_hb_3'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_l_4'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'CHAT_w_4'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "-", "1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'CHAT_b_4'", ",", "[", "1", ",", "self", ".", "n_actions", "-", "1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_confidence", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_loss2'", ")", ":", "\n", "                ", "self", ".", "loss2", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "advisor_one_hot", ",", "self", ".", "q_confidence", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'CHAT_train2'", ")", ":", "\n", "                ", "self", ".", "_train_op2", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss2", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.store_transition": [[143, 153], ["numpy.hstack", "hasattr"], "methods", ["None"], ["\n", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ",", "a_", ",", "advisor_a", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", ",", "a_", ",", "advisor_a", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "\n", "self", ".", "memory_counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.choose_action": [[154, 164], ["numpy.random.uniform", "RL_brain_CHAT.CHAT.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\n", "", "def", "choose_action", "(", "self", ",", "observation", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.get_confidence": [[165, 172], ["RL_brain_CHAT.CHAT.sess.run", "numpy.exp", "sum", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\n", "", "def", "get_confidence", "(", "self", ",", "observation", ",", "action", ")", ":", "\n", "        ", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "confidence_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_confidence", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "confidence_value", "=", "confidence_value", "[", "0", "]", "\n", "confidence", "=", "np", ".", "exp", "(", "confidence_value", ")", "/", "sum", "(", "np", ".", "exp", "(", "confidence_value", ")", ")", "\n", "action_confidence", "=", "confidence", "[", "action", "]", "\n", "return", "action_confidence", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.learn": [[173, 210], ["RL_brain_CHAT.CHAT.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "batch_memory[].astype", "batch_memory[].astype", "RL_brain_CHAT.CHAT.sess.run", "RL_brain_CHAT.CHAT.cost_his.append", "RL_brain_CHAT.CHAT.sess.run", "RL_brain_CHAT.CHAT.sess.run", "numpy.random.choice", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\n", "", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "a_", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "2", "]", ".", "astype", "(", "int", ")", "\n", "advisor_a", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", ".", "astype", "(", "int", ")", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "q_next", "[", "0", "]", "[", "a_", "]", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "_", ",", "self", ".", "cost2", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op2", ",", "self", ".", "loss2", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "advisor_act", ":", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "3", "]", "}", ")", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.save_model": [[212, 217], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["\n", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.restore_model": [[220, 225], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["\n", "", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.save_confidence_model": [[226, 231], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["\n", "", "def", "save_confidence_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.restore_confidence_model": [[234, 239], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["\n", "", "def", "restore_confidence_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.plot_cost": [[241, 247], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["\n", "", "def", "plot_cost", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.__init__": [[11, 52], ["numpy.zeros", "RL_brain_DQN.DeepQNetwork._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "tensorflow.summary.FileWriter", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "sess", ",", "\n", "n_actions", ",", "\n", "n_features", ",", "\n", "learning_rate", "=", "0.01", ",", "\n", "reward_decay", "=", "0.9", ",", "\n", "e_greedy", "=", "0.9", ",", "\n", "replace_target_iter", "=", "10", ",", "\n", "memory_size", "=", "500", ",", "\n", "batch_size", "=", "32", ",", "\n", "e_greedy_increment", "=", "None", ",", "\n", "output_graph", "=", "False", ",", "\n", "model_path", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon_max", "=", "e_greedy", "\n", "self", ".", "replace_target_iter", "=", "replace_target_iter", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epsilon_increment", "=", "e_greedy_increment", "\n", "self", ".", "epsilon", "=", "0", "if", "e_greedy_increment", "is", "not", "None", "else", "self", ".", "epsilon_max", "\n", "\n", "self", ".", "learn_step_counter", "=", "0", "\n", "\n", "self", ".", "memory", "=", "np", ".", "zeros", "(", "(", "self", ".", "memory_size", ",", "n_features", "*", "2", "+", "2", ")", ")", "\n", "\n", "self", ".", "_build_net", "(", ")", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "'target_net_params'", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "'eval_net_params'", ")", "\n", "self", ".", "replace_target_op", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "t_params", ",", "e_params", ")", "]", "\n", "\n", "\n", "if", "output_graph", ":", "\n", "            ", "tf", ".", "summary", ".", "FileWriter", "(", "\"logs/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n", "", "self", ".", "cost_his", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.copy_network": [[55, 60], ["tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "copy_network", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"New model copied\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork._build_net": [[61, 111], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.RMSPropOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.squared_difference", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.train.RMSPropOptimizer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_build_net", "(", "self", ")", ":", "\n", "# ------------------ build evaluate_net ------------------", "\n", "        ", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'s_1'", ")", "\n", "self", ".", "q_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_actions", "]", ",", "name", "=", "'Q_target_1'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'DQN_value'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'eval_net_1'", ")", ":", "\n", "                ", "c_names", ",", "n_l1", ",", "w_initializer", ",", "b_initializer", "=", "[", "'eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ",", "50", ",", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_h1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'w_h1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'b_h1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_eval", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'loss'", ")", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "q_target", ",", "self", ".", "q_eval", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'train'", ")", ":", "\n", "                ", "self", ".", "_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "# ------------------ build target_net ------------------", "\n", "", "self", ".", "s_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_features", "]", ",", "name", "=", "'s_1_'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'target_net_1'", ")", ":", "\n", "                ", "c_names", "=", "[", "'target_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'l_1'", ")", ":", "\n", "                    ", "w1", "=", "tf", ".", "get_variable", "(", "'w_1'", ",", "[", "self", ".", "n_features", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'b_1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "l1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "self", ".", "s_", ",", "w1", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_h1'", ")", ":", "\n", "                    ", "wh1", "=", "tf", ".", "get_variable", "(", "'w_h1'", ",", "[", "n_l1", ",", "n_l1", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "bh1", "=", "tf", ".", "get_variable", "(", "'b_h1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "lh1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "l1", ",", "wh1", ")", "+", "bh1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'l_2'", ")", ":", "\n", "                    ", "w2", "=", "tf", ".", "get_variable", "(", "'w_2'", ",", "[", "n_l1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "w_initializer", ",", "collections", "=", "c_names", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'b_2'", ",", "[", "1", ",", "self", ".", "n_actions", "]", ",", "initializer", "=", "b_initializer", ",", "collections", "=", "c_names", ")", "\n", "self", ".", "q_next", "=", "tf", ".", "matmul", "(", "lh1", ",", "w2", ")", "+", "b2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.store_transition": [[112, 121], ["numpy.hstack", "hasattr"], "methods", ["None"], ["", "", "", "", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'memory_counter'", ")", ":", "\n", "            ", "self", ".", "memory_counter", "=", "0", "\n", "\n", "", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "[", "a", ",", "r", "]", ",", "s_", ")", ")", "\n", "\n", "index", "=", "self", ".", "memory_counter", "%", "self", ".", "memory_size", "\n", "self", ".", "memory", "[", "index", ",", ":", "]", "=", "transition", "\n", "self", ".", "memory_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.choose_action": [[122, 132], ["numpy.random.uniform", "RL_brain_DQN.DeepQNetwork.sess.run", "numpy.argmax", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n", "            ", "self", ".", "epsilon", "=", "1", "\n", "", "observation", "=", "observation", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "            ", "actions_value", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "q_eval", ",", "feed_dict", "=", "{", "self", ".", "s", ":", "observation", "}", ")", "\n", "action", "=", "np", ".", "argmax", "(", "actions_value", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_actions", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.learn": [[133, 165], ["RL_brain_DQN.DeepQNetwork.sess.run", "q_eval.copy", "numpy.arange", "batch_memory[].astype", "RL_brain_DQN.DeepQNetwork.sess.run", "RL_brain_DQN.DeepQNetwork.cost_his.append", "RL_brain_DQN.DeepQNetwork.sess.run", "numpy.random.choice", "numpy.random.choice", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "learn_step_counter", "%", "self", ".", "replace_target_iter", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "replace_target_op", ")", "\n", "\n", "", "if", "self", ".", "memory_counter", ">", "self", ".", "memory_size", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_size", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "memory_counter", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "", "batch_memory", "=", "self", ".", "memory", "[", "sample_index", ",", ":", "]", "\n", "\n", "q_next", ",", "q_eval", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "q_next", ",", "self", ".", "q_eval", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "s_", ":", "batch_memory", "[", ":", ",", "-", "self", ".", "n_features", ":", "]", ",", "\n", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "}", ")", "\n", "\n", "q_target", "=", "q_eval", ".", "copy", "(", ")", "\n", "\n", "batch_index", "=", "np", ".", "arange", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "eval_act_index", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "]", ".", "astype", "(", "int", ")", "\n", "reward", "=", "batch_memory", "[", ":", ",", "self", ".", "n_features", "+", "1", "]", "\n", "q_target", "[", "batch_index", ",", "eval_act_index", "]", "=", "reward", "+", "self", ".", "gamma", "*", "np", ".", "max", "(", "q_next", ",", "axis", "=", "1", ")", "\n", "\n", "\n", "_", ",", "self", ".", "cost", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_train_op", ",", "self", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "batch_memory", "[", ":", ",", ":", "self", ".", "n_features", "]", ",", "\n", "self", ".", "q_target", ":", "q_target", "}", ")", "\n", "self", ".", "cost_his", ".", "append", "(", "self", ".", "cost", ")", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "epsilon", "+", "self", ".", "epsilon_increment", "if", "self", ".", "epsilon", "<", "self", ".", "epsilon_max", "else", "self", ".", "epsilon_max", "\n", "self", ".", "learn_step_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.save_model": [[166, 171], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.restore_model": [[174, 179], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_DQN.DeepQNetwork.plot_cost": [[183, 189], ["plt.plot", "plt.ylabel", "plt.xlabel", "plt.show", "numpy.arange", "len"], "methods", ["None"], ["        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "cost_his", ")", ")", ",", "self", ".", "cost_his", ")", "\n", "plt", ".", "ylabel", "(", "'Cost'", ")", "\n", "plt", ".", "xlabel", "(", "'training steps'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Actor.__init__": [[16, 59], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "n_actions", ",", "lr", "=", "0.001", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "a", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "None", ",", "\"Advisorac_act\"", ")", "\n", "self", ".", "td_error", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "\"Advisorac_td_error\"", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Admiraldmacactorvalue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Actor'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "acts_prob", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "n_actions", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "softmax", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_acts_prob'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_exp_v'", ")", ":", "\n", "                ", "log_prob", "=", "tf", ".", "log", "(", "self", ".", "acts_prob", "[", "0", ",", "self", ".", "a", "]", ")", "\n", "self", ".", "exp_v", "=", "tf", ".", "reduce_mean", "(", "log_prob", "*", "self", ".", "td_error", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "-", "self", ".", "exp_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Actor.learn": [[60, 65], ["RL_brain_admiraldmac.Actor.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "", "", "def", "learn", "(", "self", ",", "s", ",", "a", ",", "td", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "s", ",", "self", ".", "a", ":", "a", ",", "self", ".", "td_error", ":", "td", "}", "\n", "_", ",", "exp_v", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "exp_v", "]", ",", "feed_dict", ")", "\n", "return", "exp_v", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Actor.choose_action": [[66, 70], ["RL_brain_admiraldmac.Actor.sess.run", "numpy.random.choice", "numpy.arange", "RL_brain_admiraldmac.Actor.ravel"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "s", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "probs", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "acts_prob", ",", "{", "self", ".", "s", ":", "s", "}", ")", "\n", "return", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "probs", ".", "shape", "[", "1", "]", ")", ",", "p", "=", "probs", ".", "ravel", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Actor.save_model": [[72, 77], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n", "", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Actor.restore_model": [[78, 83], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Critic.__init__": [[89, 131], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.square", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "lr", "=", "0.01", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "+", "1", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "v_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "1", "]", ",", "\"Advisorac_v_next\"", ")", "\n", "self", ".", "r", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "'Advisorac_r'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'AdmiraldmacCritic'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Critic'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "v", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "1", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_V'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'squared_TD_error'", ")", ":", "\n", "                ", "self", ".", "td_error", "=", "self", ".", "r", "+", "GAMMA", "*", "self", ".", "v_", "-", "self", ".", "v", "\n", "self", ".", "loss", "=", "tf", ".", "square", "(", "self", ".", "td_error", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Critic.learn": [[132, 158], ["list", "range", "numpy.array", "list", "range", "numpy.array", "RL_brain_admiraldmac.Critic.sess.run", "RL_brain_admiraldmac.Critic.sess.run", "len", "float", "numpy.array.append", "len", "float", "numpy.array.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "", "", "def", "learn", "(", "self", ",", "s", ",", "opp_a", ",", "r", ",", "s_", ",", "opp_a_", ")", ":", "\n", "        ", "s", "=", "list", "(", "s", ")", "\n", "a1", "=", "float", "(", "opp_a", ")", "\n", "s", ".", "append", "(", "a1", ")", "\n", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "a2", "=", "float", "(", "opp_a_", ")", "\n", "s_", ".", "append", "(", "a2", ")", "\n", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "s", ",", "s_", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", ",", "s_", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "v_", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "v", ",", "{", "self", ".", "s", ":", "s_", "}", ")", "\n", "td_error", ",", "_", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "td_error", ",", "self", ".", "train_op", "]", ",", "\n", "{", "self", ".", "s", ":", "s", ",", "self", ".", "v_", ":", "v_", ",", "self", ".", "r", ":", "r", "}", ")", "\n", "return", "td_error", "\n", "\n", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n", "", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Critic.save_model": [[159, 164], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_admiraldmac.Critic.restore_model": [[165, 170], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitadmiraldmac.change_observation": [[14, 23], ["observation.tolist.tolist", "range", "numpy.array", "len", "range", "len", "range", "len", "new_list.append"], "function", ["None"], ["def", "change_observation", "(", "observation", ")", ":", "\n", "    ", "observation", "=", "observation", ".", "tolist", "(", ")", "\n", "new_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "observation", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "observation", "[", "i", "]", ")", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "observation", "[", "i", "]", "[", "j", "]", ")", ")", ":", "\n", "                ", "new_list", ".", "append", "(", "observation", "[", "i", "]", "[", "j", "]", "[", "k", "]", ")", "\n", "", "", "", "new_observation", "=", "np", ".", "array", "(", "new_list", ")", "\n", "return", "new_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitadmiraldmac.linear_decay": [[25, 41], ["enumerate"], "function", ["None"], ["", "def", "linear_decay", "(", "epoch", ",", "x", ",", "y", ")", ":", "\n", "    ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "        ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "        ", "if", "epoch", "<=", "x_i", ":", "\n", "            ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitadmiraldmac.run_pursuit": [[44, 116], ["print", "open", "myfile.write", "env.reset", "range", "env.agent_iter", "pettingzoosislpursuitadmiraldmac.linear_decay", "print", "len", "action_list[].append", "env.last", "pettingzoosislpursuitadmiraldmac.change_observation", "obs_list[].append", "action_list[].append", "reward_list[].append", "open", "myfile.write", "range", "range", "range", "numpy.random.uniform", "RL.choose_action", "actor.choose_action", "len", "range", "range", "critic.learn", "actor.learn", "len", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "env.step", "len", "len", "int", "len", "len", "len", "len", "len", "action_opp.append", "action_opp_new.append"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.change_observation", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["", "def", "run_pursuit", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislpursuitadvisorac.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(AC)\"", ")", ")", "\n", "", "num_episode", "=", "0", "\n", "eps", "=", "0.8", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "accumulated_reward", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "            ", "action_list", "[", "i", "]", ".", "append", "(", "0", ")", "\n", "", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "observation", "=", "change_observation", "(", "observation", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "eps", ":", "\n", "                ", "action", "=", "RL", ".", "choose_action", "(", "observation", ",", "execution", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "actor", ".", "choose_action", "(", "observation", ")", "\n", "\n", "", "action_list", "[", "agent_num", "]", ".", "append", "(", "action", ")", "\n", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "\n", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "\n", "                ", "action_opp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "agent_num", ":", "\n", "                        ", "action_opp", ".", "append", "(", "action_list", "[", "i", "]", "[", "0", "]", ")", "\n", "\n", "", "", "action_opp_new", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "agent_num", ":", "\n", "                        ", "action_opp_new", ".", "append", "(", "action_list", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "td_error", "=", "critic", ".", "learn", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_opp", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ",", "action_opp_new", ")", "\n", "actor", ".", "learn", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "0", "]", ",", "td_error", ")", "\n", "\n", "", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "\n", "agent_num", "=", "agent_num", "+", "1", "\n", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'pettingzoosislpursuitadvisorac.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "eps", "=", "linear_decay", "(", "num_episode", ",", "[", "0", ",", "int", "(", "1000", "*", "0.99", ")", ",", "1000", "]", ",", "[", "0.8", ",", "0.2", ",", "0.01", "]", ")", "\n", "print", "(", "\"We are now in episode\"", ",", "num_episode", ")", "\n", "", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.__init__": [[28, 61], ["Memory.Memory.Memory", "Memory.Memory.Memory", "DQfD_V3.DQfD.add_demo_to_memory", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.train.Saver", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.save_model", "DQfD_V3.DQfD.restore_model", "tensorflow.global_variables_initializer", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.add_demo_to_memory", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.restore_model"], ["self", ".", "config", "=", "config", "\n", "self", ".", "replay_memory", "=", "Memory", "(", "capacity", "=", "self", ".", "config", ".", "replay_buffer_size", ",", "permanent_data", "=", "len", "(", "demo_transitions", ")", ")", "\n", "self", ".", "demo_memory", "=", "Memory", "(", "capacity", "=", "self", ".", "config", ".", "demo_buffer_size", ",", "permanent_data", "=", "self", ".", "config", ".", "demo_buffer_size", ")", "\n", "self", ".", "add_demo_to_memory", "(", "demo_transitions", "=", "demo_transitions", ")", "\n", "self", ".", "time_step", "=", "0", "\n", "self", ".", "epsilon", "=", "self", ".", "config", ".", "INITIAL_EPSILON", "\n", "self", ".", "state_dim", "=", "nf", "\n", "self", ".", "action_dim", "=", "na", "\n", "\n", "self", ".", "action_batch", "=", "tf", ".", "placeholder", "(", "\"int32\"", ",", "[", "None", "]", ")", "\n", "self", ".", "y_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "action_dim", "]", ")", "\n", "self", ".", "ISWeights", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "1", "]", ")", "\n", "self", ".", "n_step_y_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "action_dim", "]", ")", "\n", "self", ".", "isdemo", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", "]", ")", "\n", "self", ".", "eval_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "state_dim", "]", ")", "\n", "self", ".", "select_input", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "self", ".", "state_dim", "]", ")", "\n", "\n", "self", ".", "Q_eval", "\n", "self", ".", "Q_select", "\n", "\n", "self", ".", "loss", "\n", "self", ".", "optimize", "\n", "self", ".", "update_target_net", "\n", "self", ".", "abs_errors", "\n", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "self", ".", "save_model", "(", ")", "\n", "self", ".", "restore_model", "(", ")", "\n", "\n", "", "def", "add_demo_to_memory", "(", "self", ",", "demo_transitions", ")", ":", "\n", "        ", "for", "t", "in", "demo_transitions", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.add_demo_to_memory": [[62, 67], ["DQfD_V3.DQfD.demo_memory.store", "DQfD_V3.DQfD.replay_memory.store", "numpy.array", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["            ", "self", ".", "demo_memory", ".", "store", "(", "np", ".", "array", "(", "t", ",", "dtype", "=", "object", ")", ")", "\n", "self", ".", "replay_memory", ".", "store", "(", "np", ".", "array", "(", "t", ",", "dtype", "=", "object", ")", ")", "\n", "assert", "len", "(", "t", ")", "==", "10", "\n", "\n", "", "", "def", "pre_train", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Pre-training ...'", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.pre_train": [[68, 76], ["print", "range", "print", "DQfD_V3.DQfD.train_Q_network", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network"], ["for", "i", "in", "range", "(", "self", ".", "config", ".", "PRETRAIN_STEPS", ")", ":", "\n", "            ", "self", ".", "train_Q_network", "(", "pre_train", "=", "True", ")", "\n", "if", "i", "%", "200", "==", "0", "and", "i", ">", "0", ":", "\n", "                ", "print", "(", "'{} th step of pre-train finish ...'", ".", "format", "(", "i", ")", ")", "\n", "", "", "self", ".", "time_step", "=", "0", "\n", "print", "(", "'All pre-train finish.'", ")", "\n", "\n", "\n", "", "def", "build_layers", "(", "self", ",", "state", ",", "c_names", ",", "units_1", ",", "units_2", ",", "w_i", ",", "b_i", ",", "reg", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.build_layers": [[78, 93], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["with", "tf", ".", "variable_scope", "(", "'DQfD_l1'", ")", ":", "\n", "            ", "w1", "=", "tf", ".", "get_variable", "(", "'DQfD_w1'", ",", "[", "self", ".", "state_dim", ",", "units_1", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'DQfD_b1'", ",", "[", "1", ",", "units_1", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense1", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "state", ",", "w1", ")", "+", "b1", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'DQfD_l2'", ")", ":", "\n", "            ", "w2", "=", "tf", ".", "get_variable", "(", "'DQfD_w2'", ",", "[", "units_1", ",", "units_2", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b2", "=", "tf", ".", "get_variable", "(", "'DQfD_b2'", ",", "[", "1", ",", "units_2", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense2", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "dense1", ",", "w2", ")", "+", "b2", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'DQfD_l3'", ")", ":", "\n", "            ", "w3", "=", "tf", ".", "get_variable", "(", "'DQfD_w3'", ",", "[", "units_2", ",", "a_d", "]", ",", "initializer", "=", "w_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "b3", "=", "tf", ".", "get_variable", "(", "'DQfD_b3'", ",", "[", "1", ",", "a_d", "]", ",", "initializer", "=", "b_i", ",", "collections", "=", "c_names", ",", "regularizer", "=", "reg", ")", "\n", "dense3", "=", "tf", ".", "matmul", "(", "dense2", ",", "w3", ")", "+", "b3", "\n", "", "return", "dense3", "\n", "\n", "", "@", "lazy_property", "\n", "def", "Q_select", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.Q_select": [[94, 102], ["tensorflow.variable_scope", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "tensorflow.keras.regularizers.l2", "DQfD_V3.DQfD.build_layers"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.build_layers"], ["        ", "with", "tf", ".", "variable_scope", "(", "'DQfD_select_net'", ")", "as", "scope", ":", "\n", "            ", "c_names", "=", "[", "'DQfD_select_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "w_i", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", "\n", "b_i", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "reg", "=", "tf", ".", "keras", ".", "regularizers", ".", "l2", "(", "l", "=", "0.2", ")", "\n", "return", "self", ".", "build_layers", "(", "self", ".", "select_input", ",", "c_names", ",", "24", ",", "24", ",", "w_i", ",", "b_i", ",", "reg", ")", "\n", "\n", "", "", "@", "lazy_property", "\n", "def", "Q_eval", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.Q_eval": [[103, 110], ["tensorflow.variable_scope", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "DQfD_V3.DQfD.build_layers"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.build_layers"], ["        ", "with", "tf", ".", "variable_scope", "(", "'DQfD_eval_net'", ")", "as", "scope", ":", "\n", "            ", "c_names", "=", "[", "'DQfD_eval_net_params'", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", "\n", "w_i", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", "\n", "b_i", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "return", "self", ".", "build_layers", "(", "self", ".", "eval_input", ",", "c_names", ",", "24", ",", "24", ",", "w_i", ",", "b_i", ")", "\n", "\n", "", "", "def", "loss_l", "(", "self", ",", "ae", ",", "a", ")", ":", "\n", "        ", "return", "0.0", "if", "ae", "==", "a", "else", "0.8", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_l": [[111, 113], ["None"], "methods", ["None"], ["\n", "", "def", "loss_jeq", "(", "self", ",", "Q_select", ")", ":", "\n", "        ", "jeq", "=", "0.0", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_jeq": [[114, 123], ["range", "float", "range", "tensorflow.maximum", "DQfD_V3.DQfD.loss_l"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_l"], ["for", "i", "in", "range", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", ":", "\n", "            ", "ae", "=", "self", ".", "action_batch", "[", "i", "]", "\n", "max_value", "=", "float", "(", "\"-inf\"", ")", "\n", "for", "a", "in", "range", "(", "self", ".", "action_dim", ")", ":", "\n", "                ", "max_value", "=", "tf", ".", "maximum", "(", "Q_select", "[", "i", "]", "[", "a", "]", "+", "self", ".", "loss_l", "(", "ae", ",", "a", ")", ",", "max_value", ")", "\n", "", "jeq", "+=", "self", ".", "isdemo", "[", "i", "]", "*", "(", "max_value", "-", "Q_select", "[", "i", "]", "[", "ae", "]", ")", "\n", "", "return", "jeq", "\n", "\n", "", "@", "lazy_property", "\n", "def", "loss", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss": [[124, 131], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "DQfD_V3.DQfD.loss_jeq", "tensorflow.reduce_sum", "tensorflow.squared_difference", "tensorflow.squared_difference", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.get_collection", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.loss_jeq"], ["        ", "l_dq", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "Q_select", ",", "self", ".", "y_input", ")", ")", "\n", "l_n_dq", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "Q_select", ",", "self", ".", "n_step_y_input", ")", ")", "\n", "l_jeq", "=", "self", ".", "loss_jeq", "(", "self", ".", "Q_select", ")", "\n", "l_l2", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_mean", "(", "reg_l", ")", "for", "reg_l", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "]", ")", "\n", "return", "self", ".", "ISWeights", "*", "tf", ".", "reduce_sum", "(", "[", "l", "*", "\u03bb", "for", "l", ",", "\u03bb", "in", "zip", "(", "[", "l_dq", ",", "l_n_dq", ",", "l_jeq", ",", "l_l2", "]", ",", "self", ".", "config", ".", "LAMBDA", ")", "]", ")", "\n", "\n", "", "@", "lazy_property", "\n", "def", "abs_errors", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.abs_errors": [[132, 135], ["tensorflow.reduce_sum", "tensorflow.abs"], "methods", ["None"], ["        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "self", ".", "y_input", "-", "self", ".", "Q_select", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "@", "lazy_property", "\n", "def", "optimize", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.optimize": [[136, 140], ["tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.minimize"], "methods", ["None"], ["        ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "config", ".", "LEARNING_RATE", ")", "\n", "return", "optimizer", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "", "@", "lazy_property", "\n", "def", "update_target_net", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.update_target_net": [[141, 146], ["tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.assign", "zip"], "methods", ["None"], ["        ", "select_params", "=", "tf", ".", "get_collection", "(", "'DQfD_select_net_params'", ")", "\n", "eval_params", "=", "tf", ".", "get_collection", "(", "'DQfD_eval_net_params'", ")", "\n", "return", "[", "tf", ".", "assign", "(", "e", ",", "s", ")", "for", "e", ",", "s", "in", "zip", "(", "eval_params", ",", "select_params", ")", "]", "\n", "\n", "", "def", "save_model", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Model saved in : {}\"", ".", "format", "(", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "self", ".", "config", ".", "MODEL_PATH", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.save_model": [[147, 149], ["print", "DQfD_V3.DQfD.saver.save"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["\n", "", "def", "restore_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "saver", ".", "restore", "(", "self", ".", "sess", ",", "self", ".", "config", ".", "MODEL_PATH", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.restore_model": [[150, 153], ["DQfD_V3.DQfD.saver.restore", "print"], "methods", ["None"], ["print", "(", "\"Model restored.\"", ")", "\n", "\n", "", "def", "perceive", "(", "self", ",", "transition", ")", ":", "\n", "        ", "self", ".", "replay_memory", ".", "store", "(", "np", ".", "array", "(", "transition", ")", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.perceive": [[154, 156], ["DQfD_V3.DQfD.replay_memory.store", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.store"], ["\n", "", "def", "train_Q_network", "(", "self", ",", "pre_train", "=", "False", ",", "update", "=", "True", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.train_Q_network": [[157, 213], ["actual_memory.sample", "numpy.random.shuffle", "DQfD_V3.DQfD.Q_select.eval", "DQfD_V3.DQfD.Q_eval.eval", "DQfD_V3.DQfD.Q_select.eval", "DQfD_V3.DQfD.Q_eval.eval", "numpy.zeros", "numpy.zeros", "range", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.replay_memory.batch_update", "DQfD_V3.DQfD.replay_memory.full", "numpy.copy", "numpy.argmax", "numpy.argmax", "DQfD_V3.DQfD.sess.run", "DQfD_V3.DQfD.replay_memory.full", "DQfD_V3.DQfD.Q_select.eval", "int", "state_batch[].reshape", "int"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.batch_update", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.Memory.Memory.full"], ["\n", "if", "not", "pre_train", "and", "not", "self", ".", "replay_memory", ".", "full", "(", ")", ":", "\n", "            ", "return", "\n", "", "self", ".", "time_step", "+=", "1", "\n", "\n", "assert", "self", ".", "replay_memory", ".", "full", "(", ")", "or", "pre_train", "\n", "\n", "actual_memory", "=", "self", ".", "demo_memory", "if", "pre_train", "else", "self", ".", "replay_memory", "\n", "tree_idxes", ",", "minibatch", ",", "ISWeights", "=", "actual_memory", ".", "sample", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", "\n", "\n", "np", ".", "random", ".", "shuffle", "(", "minibatch", ")", "\n", "state_batch", "=", "[", "data", "[", "0", "]", "for", "data", "in", "minibatch", "]", "\n", "action_batch", "=", "[", "data", "[", "1", "]", "for", "data", "in", "minibatch", "]", "\n", "reward_batch", "=", "[", "data", "[", "2", "]", "for", "data", "in", "minibatch", "]", "\n", "next_state_batch", "=", "[", "data", "[", "3", "]", "for", "data", "in", "minibatch", "]", "\n", "done_batch", "=", "[", "data", "[", "4", "]", "for", "data", "in", "minibatch", "]", "\n", "demo_data", "=", "[", "data", "[", "5", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_reward_batch", "=", "[", "data", "[", "6", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_state_batch", "=", "[", "data", "[", "7", "]", "for", "data", "in", "minibatch", "]", "\n", "n_step_done_batch", "=", "[", "data", "[", "8", "]", "for", "data", "in", "minibatch", "]", "\n", "actual_n", "=", "[", "data", "[", "9", "]", "for", "data", "in", "minibatch", "]", "\n", "\n", "Q_select", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "next_state_batch", "}", ")", "\n", "Q_eval", "=", "self", ".", "Q_eval", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "eval_input", ":", "next_state_batch", "}", ")", "\n", "n_step_Q_select", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "n_step_state_batch", "}", ")", "\n", "n_step_Q_eval", "=", "self", ".", "Q_eval", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "eval_input", ":", "n_step_state_batch", "}", ")", "\n", "\n", "y_batch", "=", "np", ".", "zeros", "(", "(", "self", ".", "config", ".", "BATCH_SIZE", ",", "self", ".", "action_dim", ")", ")", "\n", "n_step_y_batch", "=", "np", ".", "zeros", "(", "(", "self", ".", "config", ".", "BATCH_SIZE", ",", "self", ".", "action_dim", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "config", ".", "BATCH_SIZE", ")", ":", "\n", "            ", "temp", "=", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "state_batch", "[", "i", "]", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "state_dim", ")", ")", "}", ")", "[", "0", "]", "\n", "temp_0", "=", "np", ".", "copy", "(", "temp", ")", "\n", "action", "=", "np", ".", "argmax", "(", "Q_select", "[", "i", "]", ")", "\n", "temp", "[", "action_batch", "[", "i", "]", "]", "=", "reward_batch", "[", "i", "]", "+", "(", "1", "-", "int", "(", "done_batch", "[", "i", "]", ")", ")", "*", "self", ".", "config", ".", "GAMMA", "*", "Q_eval", "[", "i", "]", "[", "action", "]", "\n", "y_batch", "[", "i", "]", "=", "temp", "\n", "action", "=", "np", ".", "argmax", "(", "n_step_Q_select", "[", "i", "]", ")", "\n", "q_n_step", "=", "(", "1", "-", "int", "(", "n_step_done_batch", "[", "i", "]", ")", ")", "*", "self", ".", "config", ".", "GAMMA", "**", "actual_n", "[", "i", "]", "*", "n_step_Q_eval", "[", "i", "]", "[", "action", "]", "\n", "temp_0", "[", "action_batch", "[", "i", "]", "]", "=", "n_step_reward_batch", "[", "i", "]", "+", "q_n_step", "\n", "n_step_y_batch", "[", "i", "]", "=", "temp_0", "\n", "\n", "", "_", ",", "abs_errors", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "optimize", ",", "self", ".", "abs_errors", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "y_input", ":", "y_batch", ",", "\n", "self", ".", "n_step_y_input", ":", "n_step_y_batch", ",", "\n", "self", ".", "select_input", ":", "state_batch", ",", "\n", "self", ".", "action_batch", ":", "action_batch", ",", "\n", "self", ".", "isdemo", ":", "demo_data", ",", "\n", "self", ".", "ISWeights", ":", "ISWeights", "}", ")", "\n", "\n", "self", ".", "replay_memory", ".", "batch_update", "(", "tree_idxes", ",", "abs_errors", ")", "\n", "\n", "if", "update", "and", "self", ".", "time_step", "%", "self", ".", "config", ".", "UPDATE_TARGET_NET", "==", "0", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_net", ")", "\n", "\n", "", "", "def", "egreedy_action", "(", "self", ",", "state", ",", "execution", "=", "False", ")", ":", "\n", "        ", "if", "execution", "==", "True", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.DQfD.egreedy_action": [[214, 220], ["numpy.argmax", "random.random", "random.randint", "DQfD_V3.DQfD.Q_select.eval"], "methods", ["None"], ["            ", "self", ".", "epsilon", "=", "0", "\n", "", "if", "random", ".", "random", "(", ")", "<=", "self", ".", "epsilon", ":", "\n", "            ", "return", "random", ".", "randint", "(", "0", ",", "self", ".", "action_dim", "-", "1", ")", "\n", "", "return", "np", ".", "argmax", "(", "self", ".", "Q_select", ".", "eval", "(", "feed_dict", "=", "{", "self", ".", "select_input", ":", "[", "state", "]", "}", ")", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.DQfD_V3.lazy_property": [[15, 25], ["functools.wraps", "getattr", "hasattr", "setattr", "func"], "function", ["None"], ["\n", "@", "property", "\n", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "attribute", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "attribute", ",", "func", "(", "self", ")", ")", "\n", "", "return", "getattr", "(", "self", ",", "attribute", ")", "\n", "", "return", "wrapper", "\n", "\n", "\n", "", "class", "DQfD", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.change_observation": [[12, 21], ["observation.tolist.tolist", "range", "numpy.array", "len", "range", "len", "range", "len", "new_list.append"], "function", ["None"], ["def", "change_observation", "(", "observation", ")", ":", "\n", "    ", "observation", "=", "observation", ".", "tolist", "(", ")", "\n", "new_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "observation", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "observation", "[", "i", "]", ")", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "observation", "[", "i", "]", "[", "j", "]", ")", ")", ":", "\n", "                ", "new_list", ".", "append", "(", "observation", "[", "i", "]", "[", "j", "]", "[", "k", "]", ")", "\n", "", "", "", "new_observation", "=", "np", ".", "array", "(", "new_list", ")", "\n", "return", "new_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.run_pursuit": [[24, 76], ["print", "open", "myfile.write", "env.reset", "env.agent_iter", "print", "env.last", "pettingzoosislpursuitCHAT.change_observation", "obs_list[].append", "RL2.choose_action", "RL.choose_action", "action_list[].append", "advisoraction_list[].append", "reward_list[].append", "open", "myfile.write", "range", "range", "range", "range", "RL2.get_confidence", "len", "RL2.store_transition", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "env.step", "RL2.learn", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.pettingzoosislpursuitCHAT.change_observation", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pursuitcode.RL_brain_CHAT.CHAT.get_confidence", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn"], ["", "def", "run_pursuit", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislpursuitCHAT.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(CHAT)\"", ")", ")", "\n", "\n", "", "num_episode", "=", "0", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "advisoraction_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "accumulated_reward", "=", "0", "\n", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "observation", "=", "change_observation", "(", "observation", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "action", "=", "RL2", ".", "choose_action", "(", "observation", ")", "\n", "action2", "=", "RL", ".", "choose_action", "(", "observation", ",", "execution", "=", "True", ")", "\n", "if", "action", "==", "5", ":", "\n", "                ", "action", "=", "action2", "\n", "conf", "=", "RL2", ".", "get_confidence", "(", "observation", ",", "action", ")", "\n", "if", "conf", "<", "0.6", ":", "\n", "                    ", "action", "=", "0", "\n", "", "", "action_list", "[", "agent_num", "]", ".", "append", "(", "action", ")", "\n", "advisoraction_list", "[", "agent_num", "]", ".", "append", "(", "action2", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "RL2", ".", "store_transition", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "0", "]", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ",", "action_list", "[", "agent_num", "]", "[", "1", "]", ",", "advisoraction_list", "[", "agent_num", "]", "[", "0", "]", ")", "\n", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "", "step", "+=", "1", "\n", "if", "(", "step", ">", "200", ")", "and", "(", "step", "%", "5", "==", "0", ")", ":", "\n", "                ", "RL2", ".", "learn", "(", ")", "\n", "", "agent_num", "=", "agent_num", "+", "1", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'pettingzoosislpursuitCHAT.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "print", "(", "\"We are in episode\"", ",", "num_episode", ")", "\n", "", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.pettingzoosislwaterworldadmiraldmac.linear_decay": [[14, 30], ["enumerate"], "function", ["None"], ["def", "linear_decay", "(", "epoch", ",", "x", ",", "y", ")", ":", "\n", "    ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "        ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "        ", "if", "epoch", "<=", "x_i", ":", "\n", "            ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.pettingzoosislwaterworldadmiraldmac.run_waterworld": [[36, 107], ["print", "open", "myfile.write", "env.reset", "range", "env.agent_iter", "print", "pettingzoosislwaterworldadmiraldmac.linear_decay", "len", "action_list[].append", "env.last", "obs_list[].append", "actor.choose_action.tolist", "action_list[].append", "reward_list[].append", "open", "myfile.write", "range", "range", "range", "numpy.random.uniform", "ppo.choose_action", "actor.choose_action", "len", "range", "range", "critic.learn", "actor.learn", "len", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "env.step", "len", "len", "int", "len", "len", "len", "len", "len", "action_opp.append", "action_opp_new.append"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["", "def", "run_waterworld", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislwaterworldadvisorac.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(AC)\"", ")", ")", "\n", "", "num_episode", "=", "0", "\n", "eps", "=", "0.8", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "accumulated_reward", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "            ", "list_new", "=", "[", "0", ",", "0", "]", "\n", "action_list", "[", "i", "]", ".", "append", "(", "list_new", ")", "\n", "", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "eps", ":", "\n", "                ", "action", "=", "ppo", ".", "choose_action", "(", "observation", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "actor", ".", "choose_action", "(", "observation", ")", "\n", "", "curaction_list", "=", "action", ".", "tolist", "(", ")", "\n", "action_list", "[", "agent_num", "]", ".", "append", "(", "curaction_list", ")", "\n", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "\n", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "\n", "                ", "action_opp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "agent_num", ":", "\n", "                        ", "action_opp", ".", "append", "(", "action_list", "[", "i", "]", "[", "0", "]", ")", "\n", "\n", "", "", "action_opp_new", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "agent_num", ":", "\n", "                        ", "action_opp_new", ".", "append", "(", "action_list", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "td_error", "=", "critic", ".", "learn", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_opp", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ",", "action_opp_new", ")", "\n", "actor", ".", "learn", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "0", "]", ",", "td_error", ")", "\n", "\n", "", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "\n", "agent_num", "=", "agent_num", "+", "1", "\n", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'pettingzoosislwaterworldadvisorac.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "print", "(", "\"we are in episode\"", ",", "num_episode", ")", "\n", "eps", "=", "linear_decay", "(", "num_episode", ",", "[", "0", ",", "int", "(", "1000", "*", "0.99", ")", ",", "1000", "]", ",", "[", "0.8", ",", "0.2", ",", "0.01", "]", ")", "\n", "", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.pettingzoosislwaterworldDDPG.run_waterworld": [[29, 89], ["print", "open", "myfile.write", "env.reset", "env.agent_iter", "print", "env.last", "actor.choose_action", "numpy.clip", "obs_list[].append", "action_list[].append", "reward_list[].append", "open", "myfile.write", "range", "range", "range", "numpy.random.normal", "len", "M.store_transition", "obs_list[].pop", "action_list[].pop", "reward_list[].pop", "M.sample", "critic.learn", "actor.learn", "env.step", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["def", "run_waterworld", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislwaterworldDDPG.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(DDPG)\"", ")", ")", "\n", "", "num_episode", "=", "0", "\n", "var", "=", "3", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "step", "=", "0", "\n", "observation_tmp", "=", "[", "]", "\n", "\n", "obs_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "action_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "reward_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "env", ".", "agents", ")", ")", "]", "\n", "\n", "accumulated_reward", "=", "0", "\n", "\n", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "action", "=", "actor", ".", "choose_action", "(", "observation", ")", "\n", "action", "=", "np", ".", "clip", "(", "np", ".", "random", ".", "normal", "(", "action", ",", "var", ")", ",", "-", "action_bound", ",", "action_bound", ")", "\n", "obs_list", "[", "agent_num", "]", ".", "append", "(", "observation", ")", "\n", "action_list", "[", "agent_num", "]", ".", "append", "(", "action", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "append", "(", "reward", ")", "\n", "if", "len", "(", "obs_list", "[", "agent_num", "]", ")", "==", "2", ":", "\n", "                ", "M", ".", "store_transition", "(", "obs_list", "[", "agent_num", "]", "[", "0", "]", ",", "action_list", "[", "agent_num", "]", "[", "0", "]", ",", "reward_list", "[", "agent_num", "]", "[", "0", "]", ",", "obs_list", "[", "agent_num", "]", "[", "1", "]", ")", "\n", "obs_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "action_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "reward_list", "[", "agent_num", "]", ".", "pop", "(", "0", ")", "\n", "\n", "", "if", "M", ".", "pointer", ">", "MEMORY_CAPACITY", ":", "\n", "                ", "var", "*=", ".9995", "\n", "b_M", "=", "M", ".", "sample", "(", "BATCH_SIZE", ")", "\n", "b_s", "=", "b_M", "[", ":", ",", ":", "state_dim", "]", "\n", "b_a", "=", "b_M", "[", ":", ",", "state_dim", ":", "state_dim", "+", "action_dim", "]", "\n", "b_r", "=", "b_M", "[", ":", ",", "-", "state_dim", "-", "1", ":", "-", "state_dim", "]", "\n", "b_s_", "=", "b_M", "[", ":", ",", "-", "state_dim", ":", "]", "\n", "\n", "critic", ".", "learn", "(", "b_s", ",", "b_a", ",", "b_r", ",", "b_s_", ")", "\n", "actor", ".", "learn", "(", "b_s", ")", "\n", "\n", "", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "", "step", "+=", "1", "\n", "agent_num", "=", "agent_num", "+", "1", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'pettingzoosislwaterworldDDPG.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "print", "(", "\"We are in episode\"", ",", "num_episode", ")", "\n", "", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Actor.__init__": [[41, 64], ["tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.variable_scope", "ddpg.Actor._build_net", "ddpg.Actor._build_net", "tensorflow.get_variable_scope", "tensorflow.assign", "tensorflow.assign", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "action_dim", ",", "action_bound", ",", "learning_rate", ",", "replacement", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "a_dim", "=", "action_dim", "\n", "self", ".", "action_bound", "=", "action_bound", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "replacement", "=", "replacement", "\n", "self", ".", "t_replace_counter", "=", "0", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Actor'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "a", "=", "self", ".", "_build_net", "(", "S", ",", "scope", "=", "'eval_net'", ",", "trainable", "=", "True", ")", "\n", "\n", "self", ".", "a_", "=", "self", ".", "_build_net", "(", "S_", ",", "scope", "=", "'target_net'", ",", "trainable", "=", "False", ")", "\n", "\n", "", "self", ".", "e_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'Actor/eval_net'", ")", "\n", "self", ".", "t_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'Actor/target_net'", ")", "\n", "\n", "if", "self", ".", "replacement", "[", "'name'", "]", "==", "'hard'", ":", "\n", "            ", "self", ".", "t_replace_counter", "=", "0", "\n", "self", ".", "hard_replace", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "self", ".", "t_params", ",", "self", ".", "e_params", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "soft_replace", "=", "[", "tf", ".", "assign", "(", "t", ",", "(", "1", "-", "self", ".", "replacement", "[", "'tau'", "]", ")", "*", "t", "+", "self", ".", "replacement", "[", "'tau'", "]", "*", "e", ")", "\n", "for", "t", ",", "e", "in", "zip", "(", "self", ".", "t_params", ",", "self", ".", "e_params", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Actor._build_net": [[65, 77], ["tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.multiply"], "methods", ["None"], ["", "", "def", "_build_net", "(", "self", ",", "s", ",", "scope", ",", "trainable", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "            ", "init_w", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.3", ")", "\n", "init_b", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "net", "=", "tf", ".", "layers", ".", "dense", "(", "s", ",", "30", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "init_w", ",", "bias_initializer", "=", "init_b", ",", "name", "=", "'l1'", ",", "\n", "trainable", "=", "trainable", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'a'", ")", ":", "\n", "                ", "actions", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "self", ".", "a_dim", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ",", "kernel_initializer", "=", "init_w", ",", "\n", "bias_initializer", "=", "init_b", ",", "name", "=", "'a'", ",", "trainable", "=", "trainable", ")", "\n", "scaled_a", "=", "tf", ".", "multiply", "(", "actions", ",", "self", ".", "action_bound", ",", "name", "=", "'scaled_a'", ")", "\n", "", "", "return", "scaled_a", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Actor.learn": [[78, 87], ["ddpg.Actor.sess.run", "ddpg.Actor.sess.run", "ddpg.Actor.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "train_op", ",", "feed_dict", "=", "{", "S", ":", "s", "}", ")", "\n", "\n", "if", "self", ".", "replacement", "[", "'name'", "]", "==", "'soft'", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "soft_replace", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "t_replace_counter", "%", "self", ".", "replacement", "[", "'rep_iter_a'", "]", "==", "0", ":", "\n", "                ", "self", ".", "sess", ".", "run", "(", "self", ".", "hard_replace", ")", "\n", "", "self", ".", "t_replace_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Actor.choose_action": [[88, 92], ["ddpg.Actor.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "", "def", "choose_action", "(", "self", ",", "s", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "action", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "a", ",", "feed_dict", "=", "{", "S", ":", "s", "}", ")", "[", "0", "]", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Actor.add_grad_to_graph": [[93, 100], ["tensorflow.variable_scope", "tensorflow.gradients", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.apply_gradients", "zip"], "methods", ["None"], ["", "def", "add_grad_to_graph", "(", "self", ",", "a_grads", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'policy_grads'", ")", ":", "\n", "            ", "self", ".", "policy_grads", "=", "tf", ".", "gradients", "(", "ys", "=", "self", ".", "a", ",", "xs", "=", "self", ".", "e_params", ",", "grad_ys", "=", "a_grads", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'A_train'", ")", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "-", "self", ".", "lr", ")", "\n", "self", ".", "train_op", "=", "opt", ".", "apply_gradients", "(", "zip", "(", "self", ".", "policy_grads", ",", "self", ".", "e_params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Actor.save_model": [[102, 107], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Actor.restore_model": [[108, 113], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic.__init__": [[120, 156], ["tensorflow.variable_scope", "tensorflow.stop_gradient", "ddpg.Critic._build_net", "ddpg.Critic._build_net", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.squared_difference", "tensorflow.gradients", "tensorflow.assign", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "state_dim", ",", "action_dim", ",", "learning_rate", ",", "gamma", ",", "replacement", ",", "a", ",", "a_", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "s_dim", "=", "state_dim", "\n", "self", ".", "a_dim", "=", "action_dim", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "replacement", "=", "replacement", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Critic'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "a", "=", "tf", ".", "stop_gradient", "(", "a", ")", "\n", "self", ".", "q", "=", "self", ".", "_build_net", "(", "S", ",", "self", ".", "a", ",", "'eval_net'", ",", "trainable", "=", "True", ")", "\n", "\n", "self", ".", "q_", "=", "self", ".", "_build_net", "(", "S_", ",", "a_", ",", "'target_net'", ",", "trainable", "=", "False", ")", "\n", "\n", "self", ".", "e_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'Critic/eval_net'", ")", "\n", "self", ".", "t_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'Critic/target_net'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'target_q'", ")", ":", "\n", "            ", "self", ".", "target_q", "=", "R", "+", "self", ".", "gamma", "*", "self", ".", "q_", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'TD_error'", ")", ":", "\n", "            ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "self", ".", "target_q", ",", "self", ".", "q", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'C_train'", ")", ":", "\n", "            ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'a_grad'", ")", ":", "\n", "            ", "self", ".", "a_grads", "=", "tf", ".", "gradients", "(", "self", ".", "q", ",", "self", ".", "a", ")", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "replacement", "[", "'name'", "]", "==", "'hard'", ":", "\n", "            ", "self", ".", "t_replace_counter", "=", "0", "\n", "self", ".", "hard_replacement", "=", "[", "tf", ".", "assign", "(", "t", ",", "e", ")", "for", "t", ",", "e", "in", "zip", "(", "self", ".", "t_params", ",", "self", ".", "e_params", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "soft_replacement", "=", "[", "tf", ".", "assign", "(", "t", ",", "(", "1", "-", "self", ".", "replacement", "[", "'tau'", "]", ")", "*", "t", "+", "self", ".", "replacement", "[", "'tau'", "]", "*", "e", ")", "\n", "for", "t", ",", "e", "in", "zip", "(", "self", ".", "t_params", ",", "self", ".", "e_params", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic._build_net": [[157, 172], ["tensorflow.variable_scope", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "", "def", "_build_net", "(", "self", ",", "s", ",", "a", ",", "scope", ",", "trainable", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "            ", "init_w", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", "0.1", ")", "\n", "init_b", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'l1'", ")", ":", "\n", "                ", "n_l1", "=", "30", "\n", "w1_s", "=", "tf", ".", "get_variable", "(", "'w1_s'", ",", "[", "self", ".", "s_dim", ",", "n_l1", "]", ",", "initializer", "=", "init_w", ",", "trainable", "=", "trainable", ")", "\n", "w1_a", "=", "tf", ".", "get_variable", "(", "'w1_a'", ",", "[", "self", ".", "a_dim", ",", "n_l1", "]", ",", "initializer", "=", "init_w", ",", "trainable", "=", "trainable", ")", "\n", "b1", "=", "tf", ".", "get_variable", "(", "'b1'", ",", "[", "1", ",", "n_l1", "]", ",", "initializer", "=", "init_b", ",", "trainable", "=", "trainable", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "s", ",", "w1_s", ")", "+", "tf", ".", "matmul", "(", "a", ",", "w1_a", ")", "+", "b1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'q'", ")", ":", "\n", "                ", "q", "=", "tf", ".", "layers", ".", "dense", "(", "net", ",", "1", ",", "kernel_initializer", "=", "init_w", ",", "bias_initializer", "=", "init_b", ",", "trainable", "=", "trainable", ")", "\n", "", "", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic.learn": [[173, 181], ["ddpg.Critic.sess.run", "ddpg.Critic.sess.run", "ddpg.Critic.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "learn", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "train_op", ",", "feed_dict", "=", "{", "S", ":", "s", ",", "self", ".", "a", ":", "a", ",", "R", ":", "r", ",", "S_", ":", "s_", "}", ")", "\n", "if", "self", ".", "replacement", "[", "'name'", "]", "==", "'soft'", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "soft_replacement", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "t_replace_counter", "%", "self", ".", "replacement", "[", "'rep_iter_c'", "]", "==", "0", ":", "\n", "                ", "self", ".", "sess", ".", "run", "(", "self", ".", "hard_replacement", ")", "\n", "", "self", ".", "t_replace_counter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic.save_model": [[183, 188], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Critic.restore_model": [[189, 194], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.__init__": [[201, 205], ["numpy.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ",", "dims", ")", ":", "\n", "        ", "self", ".", "capacity", "=", "capacity", "\n", "self", ".", "data", "=", "np", ".", "zeros", "(", "(", "capacity", ",", "dims", ")", ")", "\n", "self", ".", "pointer", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.store_transition": [[206, 211], ["numpy.hstack"], "methods", ["None"], ["", "def", "store_transition", "(", "self", ",", "s", ",", "a", ",", "r", ",", "s_", ")", ":", "\n", "        ", "transition", "=", "np", ".", "hstack", "(", "(", "s", ",", "a", ",", "[", "r", "]", ",", "s_", ")", ")", "\n", "index", "=", "self", ".", "pointer", "%", "self", ".", "capacity", "\n", "self", ".", "data", "[", "index", ",", ":", "]", "=", "transition", "\n", "self", ".", "pointer", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample": [[212, 216], ["numpy.random.choice"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "n", ")", ":", "\n", "        ", "assert", "self", ".", "pointer", ">=", "self", ".", "capacity", ",", "'Memory has not been fulfilled'", "\n", "indices", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "capacity", ",", "size", "=", "n", ")", "\n", "return", "self", ".", "data", "[", "indices", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.pettingzoosislwaterworldppo.run_waterworld": [[18, 69], ["ppo.save_actor_model", "ppo.save_critic_model", "print", "open", "myfile.write", "env.reset", "env.agent_iter", "print", "env.last", "ppo.choose_action", "buffer_s.append", "buffer_a.append", "buffer_r.append", "open", "myfile.write", "env.step", "len", "ppo.get_v", "discounted_r.reverse", "ppo.update", "len", "discounted_r.append", "numpy.vstack", "numpy.vstack", "numpy.array"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.save_actor_model", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.save_critic_model", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.get_v", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["def", "run_waterworld", "(", ")", ":", "\n", "\n", "    ", "step", "=", "0", "\n", "with", "open", "(", "'pettingzoosislwaterworldPPO.csv'", ",", "'w+'", ")", "as", "myfile", ":", "\n", "        ", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "\"Episode\"", ",", "\"sumofrewards(PPO)\"", ")", ")", "\n", "", "num_episode", "=", "0", "\n", "while", "num_episode", "<", "1000", ":", "\n", "        ", "agent_num", "=", "0", "\n", "env", ".", "reset", "(", ")", "\n", "buffer_s", ",", "buffer_a", ",", "buffer_r", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "step", "=", "0", "\n", "accumulated_reward", "=", "0", "\n", "for", "agent", "in", "env", ".", "agent_iter", "(", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "last", "(", ")", "\n", "accumulated_reward", "=", "accumulated_reward", "+", "reward", "\n", "action", "=", "ppo", ".", "choose_action", "(", "observation", ")", "\n", "if", "done", "==", "False", ":", "\n", "                ", "env", ".", "step", "(", "action", ")", "\n", "", "step", "+=", "1", "\n", "buffer_s", ".", "append", "(", "observation", ")", "\n", "buffer_a", ".", "append", "(", "action", ")", "\n", "buffer_r", ".", "append", "(", "reward", ")", "\n", "agent_num", "=", "agent_num", "+", "1", "\n", "if", "agent_num", "==", "len", "(", "env", ".", "agents", ")", ":", "\n", "                ", "agent_num", "=", "0", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "BATCH", "==", "0", "or", "done", ":", "\n", "\n", "                ", "v_s_", "=", "ppo", ".", "get_v", "(", "observation", ")", "\n", "discounted_r", "=", "[", "]", "\n", "for", "r", "in", "buffer_r", "[", ":", ":", "-", "1", "]", ":", "\n", "                    ", "v_s_", "=", "r", "+", "GAMMA", "*", "v_s_", "\n", "discounted_r", ".", "append", "(", "v_s_", ")", "\n", "", "discounted_r", ".", "reverse", "(", ")", "\n", "\n", "bs", ",", "ba", ",", "br", "=", "np", ".", "vstack", "(", "buffer_s", ")", ",", "np", ".", "vstack", "(", "buffer_a", ")", ",", "np", ".", "array", "(", "discounted_r", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "buffer_s", ",", "buffer_a", ",", "buffer_r", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "ppo", ".", "update", "(", "bs", ",", "ba", ",", "br", ")", "\n", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'pettingzoosislwaterworldPPO.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "accumulated_reward", "=", "accumulated_reward", "/", "len", "(", "env", ".", "agents", ")", "\n", "myfile", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "num_episode", ",", "accumulated_reward", ")", ")", "\n", "", "num_episode", "=", "num_episode", "+", "1", "\n", "print", "(", "\"We are in episode\"", ",", "num_episode", ")", "\n", "", "ppo", ".", "save_actor_model", "(", "\"./tmp/actor/ppomodel.ckpt\"", ")", "\n", "ppo", ".", "save_critic_model", "(", "\"./tmp/critic/ppomodel.ckpt\"", ")", "\n", "\n", "print", "(", "'game over'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Actor.__init__": [[14, 74], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.Variable", "tensorflow.distributions.Normal", "tensorflow.clip_by_value", "tensorflow.variable_scope", "RL_brain_admiraldmac.Actor.normal_dist.log_prob", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.squeeze", "tensorflow.squeeze", "RL_brain_admiraldmac.Actor.normal_dist.sample", "RL_brain_admiraldmac.Actor.normal_dist.entropy", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["\n", "class", "Actor", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "n_actions", ",", "lr", "=", "0.001", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "a", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "None", ",", "\"Advisorac_act\"", ")", "\n", "self", ".", "td_error", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "\"Advisorac_td_error\"", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Admiraldmacactorvalue'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Actor'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "acts_prob", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "n_actions", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "softmax", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_acts_prob'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_exp_v'", ")", ":", "\n", "                ", "log_prob", "=", "tf", ".", "log", "(", "self", ".", "acts_prob", "[", "0", ",", "self", ".", "a", "]", ")", "\n", "self", ".", "exp_v", "=", "tf", ".", "reduce_mean", "(", "log_prob", "*", "self", ".", "td_error", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "-", "self", ".", "exp_v", ")", "\n", "\n", "", "", "", "def", "learn", "(", "self", ",", "s", ",", "a", ",", "td", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "feed_dict", "=", "{", "self", ".", "s", ":", "s", ",", "self", ".", "a", ":", "a", ",", "self", ".", "td_error", ":", "td", "}", "\n", "_", ",", "exp_v", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "exp_v", "]", ",", "feed_dict", ")", "\n", "return", "exp_v", "\n", "\n", "", "def", "choose_action", "(", "self", ",", "s", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "probs", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "acts_prob", ",", "{", "self", ".", "s", ":", "s", "}", ")", "\n", "return", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "probs", ".", "shape", "[", "1", "]", ")", ",", "p", "=", "probs", ".", "ravel", "(", ")", ")", "\n", "\n", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Actor.learn": [[76, 81], ["RL_brain_admiraldmac.Actor.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\n", "", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Actor.choose_action": [[82, 87], ["RL_brain_admiraldmac.Actor.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\n", "\n", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Actor.save_model": [[89, 94], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "n_features", ",", "lr", "=", "0.01", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "\n", "self", ".", "s", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "n_features", "+", "1", "]", ",", "\"Advisorac_state\"", ")", "\n", "self", ".", "v_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "1", "]", ",", "\"Advisorac_v_next\"", ")", "\n", "self", ".", "r", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "'Advisorac_r'", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Actor.restore_model": [[95, 100], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["\n", "with", "tf", ".", "variable_scope", "(", "'AdmiraldmacCritic'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "'Advisorac_Critic'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "self", ".", "s", ",", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.__init__": [[103, 145], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.square", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_l1'", "\n", ")", "\n", "\n", "l2", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l1", ",", "\n", "units", "=", "50", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_lh1'", "\n", ")", "\n", "\n", "self", ".", "v", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", "=", "l2", ",", "\n", "units", "=", "1", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0.", ",", ".1", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "name", "=", "'Advisorac_V'", "\n", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'squared_TD_error'", ")", ":", "\n", "                ", "self", ".", "td_error", "=", "self", ".", "r", "+", "GAMMA", "*", "self", ".", "v_", "-", "self", ".", "v", "\n", "self", ".", "loss", "=", "tf", ".", "square", "(", "self", ".", "td_error", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Advisorac_train'", ")", ":", "\n", "                ", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "", "", "", "def", "learn", "(", "self", ",", "s", ",", "opp_a", ",", "r", ",", "s_", ",", "opp_a_", ")", ":", "\n", "        ", "s", "=", "list", "(", "s", ")", "\n", "a1", "=", "float", "(", "opp_a", ")", "\n", "s", ".", "append", "(", "a1", ")", "\n", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "s_", "=", "list", "(", "s_", ")", "\n", "a2", "=", "float", "(", "opp_a_", ")", "\n", "s_", ".", "append", "(", "a2", ")", "\n", "s_", "=", "np", ".", "array", "(", "s_", ")", "\n", "s", ",", "s_", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", ",", "s_", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "v_", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "v", ",", "{", "self", ".", "s", ":", "s_", "}", ")", "\n", "td_error", ",", "_", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "td_error", ",", "self", ".", "train_op", "]", ",", "\n", "{", "self", ".", "s", ":", "s", ",", "self", ".", "v_", ":", "v_", ",", "self", ".", "r", ":", "r", "}", ")", "\n", "return", "td_error", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.learn": [[146, 166], ["list", "range", "numpy.array", "list", "range", "numpy.array", "RL_brain_admiraldmac.Critic.sess.run", "RL_brain_admiraldmac.Critic.sess.run", "len", "range", "len", "range", "len", "float", "numpy.array.append", "len", "float", "numpy.array.append"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["\n", "", "def", "save_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n", "", "def", "restore_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.save_model": [[168, 173], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.RL_brain_admiraldmac.Critic.restore_model": [[174, 179], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], []], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.__init__": [[28, 70], ["tensorflow.placeholder", "tensorflow.summary.FileWriter", "tensorflow.variable_scope", "ppo.PPO._build_anet", "ppo.PPO._build_anet", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.placeholder", "tensorflow.reduce_mean", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.variable_scope", "tensorflow.squeeze", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.square", "pi.sample", "oldp.assign", "tensorflow.variable_scope", "tensorflow.exp", "tensorflow.placeholder", "tensorflow.distributions.kl_divergence", "tensorflow.reduce_mean", "tensorflow.train.AdamOptimizer", "zip", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.train.AdamOptimizer", "pi.log_prob", "oldpi.log_prob", "tensorflow.minimum", "tensorflow.clip_by_value"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO._build_anet", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO._build_anet", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ddpg.Memory.sample"], ["    ", "def", "__init__", "(", "self", ",", "sess", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "tfs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "S_DIM", "]", ",", "'state'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Value'", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'critic'", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "self", ".", "tfs", ",", "100", ",", "tf", ".", "nn", ".", "relu", ")", "\n", "self", ".", "v", "=", "tf", ".", "layers", ".", "dense", "(", "l1", ",", "1", ")", "\n", "self", ".", "tfdc_r", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", "]", ",", "'discounted_r'", ")", "\n", "self", ".", "advantage", "=", "self", ".", "tfdc_r", "-", "self", ".", "v", "\n", "self", ".", "closs", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "advantage", ")", ")", "\n", "self", ".", "ctrain_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "C_LR", ")", ".", "minimize", "(", "self", ".", "closs", ")", "\n", "\n", "", "pi", ",", "pi_params", "=", "self", ".", "_build_anet", "(", "'pi'", ",", "trainable", "=", "True", ")", "\n", "oldpi", ",", "oldpi_params", "=", "self", ".", "_build_anet", "(", "'oldpi'", ",", "trainable", "=", "False", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'sample_action'", ")", ":", "\n", "                ", "self", ".", "sample_op", "=", "tf", ".", "squeeze", "(", "pi", ".", "sample", "(", "1", ")", ",", "axis", "=", "0", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'update_oldpi'", ")", ":", "\n", "                ", "self", ".", "update_oldpi_op", "=", "[", "oldp", ".", "assign", "(", "p", ")", "for", "p", ",", "oldp", "in", "zip", "(", "pi_params", ",", "oldpi_params", ")", "]", "\n", "\n", "", "self", ".", "tfa", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "A_DIM", "]", ",", "'action'", ")", "\n", "self", ".", "tfadv", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "1", "]", ",", "'advantage'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'loss'", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'surrogate'", ")", ":", "\n", "                    ", "ratio", "=", "tf", ".", "exp", "(", "pi", ".", "log_prob", "(", "self", ".", "tfa", ")", "-", "oldpi", ".", "log_prob", "(", "self", ".", "tfa", ")", ")", "\n", "surr", "=", "ratio", "*", "self", ".", "tfadv", "\n", "", "if", "METHOD", "[", "'name'", "]", "==", "'kl_pen'", ":", "\n", "                    ", "self", ".", "tflam", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "None", ",", "'lambda'", ")", "\n", "kl", "=", "tf", ".", "distributions", ".", "kl_divergence", "(", "oldpi", ",", "pi", ")", "\n", "self", ".", "kl_mean", "=", "tf", ".", "reduce_mean", "(", "kl", ")", "\n", "self", ".", "aloss", "=", "-", "(", "tf", ".", "reduce_mean", "(", "surr", "-", "self", ".", "tflam", "*", "kl", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "aloss", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "minimum", "(", "\n", "surr", ",", "\n", "tf", ".", "clip_by_value", "(", "ratio", ",", "1.", "-", "METHOD", "[", "'epsilon'", "]", ",", "1.", "+", "METHOD", "[", "'epsilon'", "]", ")", "*", "self", ".", "tfadv", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'atrain'", ")", ":", "\n", "                ", "self", ".", "atrain_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "A_LR", ")", ".", "minimize", "(", "self", ".", "aloss", ")", "\n", "\n", "", "", "tf", ".", "summary", ".", "FileWriter", "(", "\"log/\"", ",", "self", ".", "sess", ".", "graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.update": [[72, 92], ["ppo.PPO.sess.run", "ppo.PPO.sess.run", "range", "numpy.clip", "ppo.PPO.sess.run", "ppo.PPO.sess.run", "ppo.PPO.sess.run", "range", "range"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "update", "(", "self", ",", "s", ",", "a", ",", "r", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_oldpi_op", ")", "\n", "adv", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "advantage", ",", "{", "self", ".", "tfs", ":", "s", ",", "self", ".", "tfdc_r", ":", "r", "}", ")", "\n", "\n", "if", "METHOD", "[", "'name'", "]", "==", "'kl_pen'", ":", "\n", "            ", "for", "_", "in", "range", "(", "A_UPDATE_STEPS", ")", ":", "\n", "                ", "_", ",", "kl", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "atrain_op", ",", "self", ".", "kl_mean", "]", ",", "\n", "{", "self", ".", "tfs", ":", "s", ",", "self", ".", "tfa", ":", "a", ",", "self", ".", "tfadv", ":", "adv", ",", "self", ".", "tflam", ":", "METHOD", "[", "'lam'", "]", "}", ")", "\n", "if", "kl", ">", "4", "*", "METHOD", "[", "'kl_target'", "]", ":", "\n", "                    ", "break", "\n", "", "", "if", "kl", "<", "METHOD", "[", "'kl_target'", "]", "/", "1.5", ":", "\n", "                ", "METHOD", "[", "'lam'", "]", "/=", "2", "\n", "", "elif", "kl", ">", "METHOD", "[", "'kl_target'", "]", "*", "1.5", ":", "\n", "                ", "METHOD", "[", "'lam'", "]", "*=", "2", "\n", "", "METHOD", "[", "'lam'", "]", "=", "np", ".", "clip", "(", "METHOD", "[", "'lam'", "]", ",", "1e-4", ",", "10", ")", "\n", "", "else", ":", "\n", "            ", "[", "self", ".", "sess", ".", "run", "(", "self", ".", "atrain_op", ",", "{", "self", ".", "tfs", ":", "s", ",", "self", ".", "tfa", ":", "a", ",", "self", ".", "tfadv", ":", "adv", "}", ")", "for", "_", "in", "range", "(", "A_UPDATE_STEPS", ")", "]", "\n", "\n", "", "[", "self", ".", "sess", ".", "run", "(", "self", ".", "ctrain_op", ",", "{", "self", ".", "tfs", ":", "s", ",", "self", ".", "tfdc_r", ":", "r", "}", ")", "for", "_", "in", "range", "(", "C_UPDATE_STEPS", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO._build_anet": [[93, 103], ["tensorflow.variable_scope", "tensorflow.get_collection", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.distributions.Normal"], "methods", ["None"], ["", "def", "_build_anet", "(", "self", ",", "nam", ",", "trainable", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Policy'", ")", ":", "\n", "            ", "self", ".", "name_scope2", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "with", "tf", ".", "variable_scope", "(", "nam", ")", ":", "\n", "                ", "l1", "=", "tf", ".", "layers", ".", "dense", "(", "self", ".", "tfs", ",", "100", ",", "tf", ".", "nn", ".", "relu", ",", "trainable", "=", "trainable", ")", "\n", "mu", "=", "tf", ".", "layers", ".", "dense", "(", "l1", ",", "A_DIM", ",", "tf", ".", "nn", ".", "tanh", ",", "trainable", "=", "trainable", ")", "\n", "sigma", "=", "tf", ".", "layers", ".", "dense", "(", "l1", ",", "A_DIM", ",", "tf", ".", "nn", ".", "softplus", ",", "trainable", "=", "trainable", ")", "\n", "norm_dist", "=", "tf", ".", "distributions", ".", "Normal", "(", "loc", "=", "mu", ",", "scale", "=", "sigma", ")", "\n", "", "params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "nam", ")", "\n", "", "return", "norm_dist", ",", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.choose_action": [[104, 108], ["numpy.clip", "ppo.PPO.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "choose_action", "(", "self", ",", "s", ")", ":", "\n", "        ", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "a", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "sample_op", ",", "{", "self", ".", "tfs", ":", "s", "}", ")", "[", "0", "]", "\n", "return", "np", ".", "clip", "(", "a", ",", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.get_v": [[109, 112], ["ppo.PPO.sess.run"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.runner.docker_agent_runner.DockerAgentRunner.run"], ["", "def", "get_v", "(", "self", ",", "s", ")", ":", "\n", "        ", "if", "s", ".", "ndim", "<", "2", ":", "s", "=", "s", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "return", "self", ".", "sess", ".", "run", "(", "self", ".", "v", ",", "{", "self", ".", "tfs", ":", "s", "}", ")", "[", "0", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.save_actor_model": [[113, 118], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_actor_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Actor Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.save_critic_model": [[119, 124], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.graphics.Viewer.save"], ["", "def", "save_critic_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "save_path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Critic Model saved in path: %s\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.restore_actor_model": [[125, 130], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_actor_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope2", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Actor Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.waterworldcode.ppo.PPO.restore_critic_model": [[131, 136], ["tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "restore_critic_model", "(", "self", ",", "s", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "s", ")", "\n", "print", "(", "\"Critic Model restored\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.run_this_advisor.update": [[12, 89], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "env.step", "RL.choose_greedy_action", "RL.choose_action", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation_.copy", "observation2_.copy", "observation2_.copy", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.choose_greedy_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "cumulative_reward", "=", "0", "\n", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "\n", "\n", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "\n", "\n", "", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ",", "action_", ",", "action2_", ")", "\n", "\n", "\n", "action", "=", "action_", "\n", "action2", "=", "action2_", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'advisor1.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "episode", ",", "reward", ",", "reward2", ")", ")", "\n", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "\n", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.linear_decay": [[19, 35], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.choose_action": [[37, 69], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor3.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor3.QLearningTable.check_state2_exist", "RL_brain_admiraldm_advisor3.QLearningTable.linear_decay", "RL_brain_admiraldm_advisor3.QLearningTable.linear_decay", "numpy.random.uniform", "RL_brain_admiraldm_advisor3.QLearningTable.advisor_action", "RL_brain_admiraldm_advisor3.QLearningTable.advisor_action", "int", "int", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ",", "episode", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "k", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "0.1", ",", "0.05", ",", "0", "]", ")", "\n", "t", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "self", ".", "epsilon", ",", "0.02", ",", "0", "]", ")", "\n", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "k", ":", "\n", "                ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "", "else", ":", "\n", "                ", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "t", ":", "\n", "                    ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                    ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.choose_greedy_action": [[70, 90], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor3.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor3.QLearningTable.check_state2_exist", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "choose_greedy_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.learn": [[94, 122], ["s.append", "s2.append", "str", "str", "RL_brain_admiraldm_advisor3.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor3.QLearningTable.check_state2_exist", "s_.append", "str", "RL_brain_admiraldm_advisor3.QLearningTable.check_state_exist", "s2_.append", "str", "RL_brain_admiraldm_advisor3.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ",", "a_", ",", "a2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_", ".", "append", "(", "a2_", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "a_", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "s2_", ".", "append", "(", "a_", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "a2_", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.advisor_action": [[127, 142], ["numpy.random.choice"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "\n", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.check_state_exist": [[144, 151], ["RL_brain_admiraldm_advisor3.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor3.QLearningTable.check_state2_exist": [[155, 162], ["RL_brain_admiraldm_advisor3.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_sarsa.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "# a list", "\n", "self", ".", "actions2", "=", "actions2", "# a list", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_sarsa.QLearningTable.linear_decay": [[21, 37], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_sarsa.QLearningTable.choose_action": [[42, 72], ["observation.append", "observation2.append", "str", "str", "RL_brain_sarsa.QLearningTable.check_state_exist", "RL_brain_sarsa.QLearningTable.check_state2_exist", "RL_brain_sarsa.QLearningTable.linear_decay", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "int", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ",", "episode", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "# action selection", "\n", "k", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "self", ".", "epsilon", ",", "0.02", ",", "0", "]", ")", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "k", ":", "\n", "# choose best action", "\n", "                ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "# some actions may have the same value, randomly choose on in these actions", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "# choose random action", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_sarsa.QLearningTable.learn": [[73, 101], ["s.append", "s2.append", "str", "str", "RL_brain_sarsa.QLearningTable.check_state_exist", "RL_brain_sarsa.QLearningTable.check_state2_exist", "s_.append", "str", "RL_brain_sarsa.QLearningTable.check_state_exist", "s2_.append", "str", "RL_brain_sarsa.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ",", "a_", ",", "a2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_", ".", "append", "(", "a2_", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "a_", "]", "# next state is not terminal", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "# next state is terminal", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "# update", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "s2_", ".", "append", "(", "a_", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "a2_", "]", "# next state is not terminal", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "# next state is terminal", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "# update", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_sarsa.QLearningTable.check_state_exist": [[112, 120], ["RL_brain_sarsa.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "# append new state to q table", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_sarsa.QLearningTable.check_state2_exist": [[124, 132], ["RL_brain_sarsa.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "# append new state to q table", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.run_this_advisor4.update": [[8, 77], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "env.step", "RL.choose_greedy_action", "RL.choose_action", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation_.copy", "observation2_.copy", "observation2_.copy", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.choose_greedy_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "cumulative_reward", "=", "0", "\n", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ",", "action_", ",", "action2_", ")", "\n", "\n", "action", "=", "action_", "\n", "action2", "=", "action2_", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "", "", "cumulative_reward", "=", "cumulative_reward", "+", "reward", "\n", "with", "open", "(", "'advisor4.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "episode", ",", "reward", ",", "reward2", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.linear_decay": [[18, 34], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.choose_action": [[38, 70], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor4.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor4.QLearningTable.check_state2_exist", "numpy.random.uniform", "RL_brain_admiraldm_advisor4.QLearningTable.advisor_action", "RL_brain_admiraldm_advisor4.QLearningTable.advisor_action", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ",", "episode", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "k", "=", "0", "\n", "t", "=", "self", ".", "epsilon", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "k", ":", "\n", "                ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "\n", "", "else", ":", "\n", "                ", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "t", ":", "\n", "                    ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                    ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.choose_greedy_action": [[71, 91], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor4.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor4.QLearningTable.check_state2_exist", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "choose_greedy_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.learn": [[95, 123], ["s.append", "s2.append", "str", "str", "RL_brain_admiraldm_advisor4.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor4.QLearningTable.check_state2_exist", "s_.append", "str", "RL_brain_admiraldm_advisor4.QLearningTable.check_state_exist", "s2_.append", "str", "RL_brain_admiraldm_advisor4.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ",", "a_", ",", "a2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_", ".", "append", "(", "a2_", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "a_", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "s2_", ".", "append", "(", "a_", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "a2_", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "#if s_ == 'terminal' or s2_ == 'terminal':", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.advisor_action": [[129, 133], ["numpy.random.choice"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.check_state_exist": [[135, 142], ["RL_brain_admiraldm_advisor4.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor4.QLearningTable.check_state2_exist": [[146, 153], ["RL_brain_admiraldm_advisor4.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.run_this_mse.update": [[12, 94], ["range", "print", "env.destroy", "env.reset", "print", "print", "print", "RL.mean_square_error", "env.render", "env.step", "RL.choose_greedy_action", "RL.choose_action", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "open", "myfile2.write", "observation_.copy", "observation_.copy", "observation2_.copy", "observation2_.copy", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.mean_square_error", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.choose_greedy_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "cumulative_reward", "=", "0", "\n", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "\n", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "\n", "\n", "", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ",", "action_", ",", "action2_", ")", "\n", "\n", "\n", "action", "=", "action_", "\n", "action2", "=", "action2_", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "", "", "print", "(", "\"The reward is\"", ",", "reward", ")", "\n", "print", "(", "\"The reward2 is\"", ",", "reward2", ")", "\n", "\n", "with", "open", "(", "'advisor1.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "episode", ",", "reward", ",", "reward2", ")", ")", "\n", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "mse", "=", "RL", ".", "mean_square_error", "(", ")", "\n", "\n", "with", "open", "(", "'mse.csv'", ",", "'a'", ")", "as", "myfile2", ":", "\n", "            ", "myfile2", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "episode", ",", "mse", ")", ")", "\n", "\n", "", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.__init__": [[9, 21], ["pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "RL_brain_admiraldm_mse.QLearningTable.read_csv"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.read_csv"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table3", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table4", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "self", ".", "read_csv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.linear_decay": [[24, 40], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.choose_action": [[46, 89], ["observation.copy", "observation2.copy", "observation.append", "observation.extend", "str", "observation2.append", "observation2.extend", "str", "RL_brain_admiraldm_mse.QLearningTable.check_state_exist", "RL_brain_admiraldm_mse.QLearningTable.check_state2_exist", "RL_brain_admiraldm_mse.QLearningTable.linear_decay", "RL_brain_admiraldm_mse.QLearningTable.linear_decay", "numpy.random.uniform", "RL_brain_admiraldm_mse.QLearningTable.advisor_action", "RL_brain_admiraldm_mse.QLearningTable.advisor_action", "int", "int", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ",", "episode", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation_tmp", "=", "observation", ".", "copy", "(", ")", "\n", "observation2_tmp", "=", "observation2", ".", "copy", "(", ")", "\n", "observation", ".", "append", "(", "action2", ")", "\n", "observation", ".", "extend", "(", "observation2_tmp", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "observation2", ".", "extend", "(", "observation_tmp", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "\n", "k", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "1", ",", "0.05", ",", "0", "]", ")", "\n", "t", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "self", ".", "epsilon", ",", "0.02", ",", "0", "]", ")", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "k", ":", "\n", "                ", "action", "=", "self", ".", "advisor_action", "(", "observation_tmp", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2_tmp", ")", "\n", "", "else", ":", "\n", "                ", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "t", ":", "\n", "\n", "                    ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "\n", "                    ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "\n", "\n", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.choose_greedy_action": [[91, 118], ["observation.copy", "observation2.copy", "observation.append", "observation.extend", "str", "observation2.append", "observation2.extend", "str", "RL_brain_admiraldm_mse.QLearningTable.check_state_exist", "RL_brain_admiraldm_mse.QLearningTable.check_state2_exist", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "choose_greedy_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation_tmp", "=", "observation", ".", "copy", "(", ")", "\n", "observation2_tmp", "=", "observation2", ".", "copy", "(", ")", "\n", "observation", ".", "append", "(", "action2", ")", "\n", "observation", ".", "extend", "(", "observation2_tmp", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "observation2", ".", "extend", "(", "observation_tmp", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "\n", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.learn": [[123, 160], ["s.copy", "s2.copy", "s.append", "s2.append", "s.extend", "s2.extend", "str", "str", "RL_brain_admiraldm_mse.QLearningTable.check_state_exist", "RL_brain_admiraldm_mse.QLearningTable.check_state2_exist", "s_.copy", "s_.append", "s_.extend", "str", "RL_brain_admiraldm_mse.QLearningTable.check_state_exist", "s2_.append", "s2_.extend", "str", "RL_brain_admiraldm_mse.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ",", "a_", ",", "a2_", ")", ":", "\n", "        ", "s_tmp", "=", "s", ".", "copy", "(", ")", "\n", "s2_tmp", "=", "s2", ".", "copy", "(", ")", "\n", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "s", ".", "extend", "(", "s2_tmp", ")", "\n", "s2", ".", "extend", "(", "s_tmp", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_tmp", "=", "s_", ".", "copy", "(", ")", "\n", "s_", ".", "append", "(", "a2_", ")", "\n", "s_", ".", "extend", "(", "s2_", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "a_", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "\n", "            ", "s2_", ".", "append", "(", "a_", ")", "\n", "s2_", ".", "extend", "(", "s_tmp", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "a2_", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.mean_square_error": [[163, 183], ["RL_brain_admiraldm_mse.QLearningTable.q_table3.iterrows", "print"], "methods", ["None"], ["", "def", "mean_square_error", "(", "self", ")", ":", "\n", "        ", "mse", "=", "0", "\n", "for", "index", ",", "row", "in", "self", ".", "q_table3", ".", "iterrows", "(", ")", ":", "\n", "            ", "if", "row", "[", "0", "]", "in", "self", ".", "q_table", ".", "index", ":", "\n", "                ", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "0", "]", "-", "row", "[", "1", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "1", "]", "-", "row", "[", "2", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "2", "]", "-", "row", "[", "3", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "3", "]", "-", "row", "[", "4", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "", "", "size", "=", "self", ".", "q_table", ".", "size", "*", "4", "\n", "mse", "=", "mse", "/", "size", "\n", "print", "(", "\"the mse is\"", ",", "mse", ")", "\n", "return", "mse", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.write_to_csv": [[185, 190], ["RL_brain_admiraldm_mse.QLearningTable.q_table.to_csv", "RL_brain_admiraldm_mse.QLearningTable.q_table2.to_csv", "print"], "methods", ["None"], ["", "def", "write_to_csv", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "q_table", ".", "to_csv", "(", "'q_table1.csv'", ")", "\n", "self", ".", "q_table2", ".", "to_csv", "(", "'q_table2.csv'", ")", "\n", "print", "(", "\"Files written\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.read_csv": [[191, 195], ["pandas.read_csv", "pandas.read_csv", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.read_csv", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.read_csv"], ["", "def", "read_csv", "(", "self", ")", ":", "\n", "        ", "self", ".", "q_table3", "=", "pd", ".", "read_csv", "(", "'q_table1.csv'", ")", "\n", "self", ".", "q_table4", "=", "pd", ".", "read_csv", "(", "'q_table2.csv'", ")", "\n", "print", "(", "\"Read both the files\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.advisor_action": [[199, 236], ["None"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "if", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "3", "\n", "\n", "", "if", "s", "[", "1", "]", "<", "UNIT", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.check_state_exist": [[238, 246], ["RL_brain_admiraldm_mse.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_mse.QLearningTable.check_state2_exist": [[250, 258], ["RL_brain_admiraldm_mse.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.__init__": [[9, 19], ["pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table3", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table4", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.linear_decay": [[23, 39], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.choose_action": [[45, 79], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor.QLearningTable.check_state2_exist", "RL_brain_admiraldm_advisor.QLearningTable.linear_decay", "RL_brain_admiraldm_advisor.QLearningTable.linear_decay", "numpy.random.uniform", "RL_brain_admiraldm_advisor.QLearningTable.advisor_action", "RL_brain_admiraldm_advisor.QLearningTable.advisor_action", "int", "int", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ",", "episode", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "k", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "1", ",", "0.05", ",", "0", "]", ")", "\n", "t", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "self", ".", "epsilon", ",", "0.02", ",", "0", "]", ")", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "k", ":", "\n", "                ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "", "else", ":", "\n", "                ", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "t", ":", "\n", "                    ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                    ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "\n", "\n", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.choose_greedy_action": [[81, 101], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor.QLearningTable.check_state2_exist", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "choose_greedy_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.learn": [[106, 134], ["s.append", "s2.append", "str", "str", "RL_brain_admiraldm_advisor.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor.QLearningTable.check_state2_exist", "s_.append", "str", "RL_brain_admiraldm_advisor.QLearningTable.check_state_exist", "s2_.append", "str", "RL_brain_admiraldm_advisor.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ",", "a_", ",", "a2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_", ".", "append", "(", "a2_", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "a_", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "s2_", ".", "append", "(", "a_", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "a2_", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.advisor_action": [[146, 183], ["None"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "if", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "3", "\n", "\n", "", "if", "s", "[", "1", "]", "<", "UNIT", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.check_state_exist": [[185, 192], ["RL_brain_admiraldm_advisor.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor.QLearningTable.check_state2_exist": [[196, 203], ["RL_brain_admiraldm_advisor.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.run_this_advisor2.update": [[8, 74], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "env.step", "RL.choose_greedy_action", "RL.choose_action", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation_.copy", "observation2_.copy", "observation2_.copy", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.choose_greedy_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ",", "action_", ",", "action2_", ")", "\n", "\n", "\n", "action", "=", "action_", "\n", "action2", "=", "action2_", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'advisor2.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "episode", ",", "reward", ",", "reward2", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.maze_env.Maze.__init__": [[16, 23], ["super().__init__", "len", "maze_env.Maze.title", "maze_env.Maze.geometry", "maze_env.Maze._build_maze"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze._build_maze"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Maze", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "action_space", "=", "[", "'u'", ",", "'d'", ",", "'l'", ",", "'r'", "]", "\n", "self", ".", "n_actions", "=", "len", "(", "self", ".", "action_space", ")", "\n", "self", ".", "title", "(", "'maze'", ")", "\n", "self", ".", "geometry", "(", "'{0}x{1}'", ".", "format", "(", "MAZE_H", "*", "UNIT", ",", "MAZE_H", "*", "UNIT", ")", ")", "\n", "self", ".", "_build_maze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.maze_env.Maze._build_maze": [[24, 66], ["tk.Canvas", "range", "range", "numpy.array", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_oval", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.pack", "maze_env.Maze.canvas.create_line", "maze_env.Maze.canvas.create_line", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_build_maze", "(", "self", ")", ":", "\n", "        ", "self", ".", "canvas", "=", "tk", ".", "Canvas", "(", "self", ",", "bg", "=", "'white'", ",", "\n", "height", "=", "MAZE_H", "*", "UNIT", ",", "\n", "width", "=", "MAZE_W", "*", "UNIT", ")", "\n", "\n", "for", "c", "in", "range", "(", "0", ",", "MAZE_W", "*", "UNIT", ",", "UNIT", ")", ":", "\n", "            ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "c", ",", "0", ",", "c", ",", "MAZE_H", "*", "UNIT", "\n", "self", ".", "canvas", ".", "create_line", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "", "for", "r", "in", "range", "(", "0", ",", "MAZE_H", "*", "UNIT", ",", "UNIT", ")", ":", "\n", "            ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "0", ",", "r", ",", "MAZE_W", "*", "UNIT", ",", "r", "\n", "self", ".", "canvas", ".", "create_line", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "\n", "", "origin", "=", "np", ".", "array", "(", "[", "20", ",", "20", "]", ")", "\n", "\n", "hell1_center", "=", "origin", "+", "np", ".", "array", "(", "[", "UNIT", "*", "2", ",", "UNIT", "]", ")", "\n", "self", ".", "hell1", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "hell1_center", "[", "0", "]", "-", "15", ",", "hell1_center", "[", "1", "]", "-", "15", ",", "\n", "hell1_center", "[", "0", "]", "+", "15", ",", "hell1_center", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'black'", ")", "\n", "hell2_center", "=", "origin", "+", "np", ".", "array", "(", "[", "UNIT", "*", "2", ",", "UNIT", "*", "3", "]", ")", "\n", "self", ".", "hell2", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "hell2_center", "[", "0", "]", "-", "15", ",", "hell2_center", "[", "1", "]", "-", "15", ",", "\n", "hell2_center", "[", "0", "]", "+", "15", ",", "hell2_center", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'black'", ")", "\n", "\n", "oval_center", "=", "origin", "+", "UNIT", "*", "2", "\n", "self", ".", "oval", "=", "self", ".", "canvas", ".", "create_oval", "(", "\n", "oval_center", "[", "0", "]", "-", "15", ",", "oval_center", "[", "1", "]", "-", "15", ",", "\n", "oval_center", "[", "0", "]", "+", "15", ",", "oval_center", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'yellow'", ")", "\n", "\n", "self", ".", "rect1", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "origin", "[", "0", "]", "-", "15", ",", "origin", "[", "1", "]", "-", "15", ",", "\n", "origin", "[", "0", "]", "+", "15", ",", "origin", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'red'", ")", "\n", "\n", "self", ".", "rect2", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "165.0", ",", "165.0", ",", "\n", "195.0", ",", "195.0", ",", "\n", "fill", "=", "'blue'", ")", "\n", "\n", "self", ".", "canvas", ".", "pack", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.maze_env.Maze.reset": [[67, 84], ["maze_env.Maze.update", "time.sleep", "maze_env.Maze.canvas.delete", "maze_env.Maze.canvas.delete", "numpy.array", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "update", "(", ")", "\n", "time", ".", "sleep", "(", "0.1", ")", "\n", "self", ".", "canvas", ".", "delete", "(", "self", ".", "rect1", ")", "\n", "self", ".", "canvas", ".", "delete", "(", "self", ".", "rect2", ")", "\n", "origin", "=", "np", ".", "array", "(", "[", "20", ",", "20", "]", ")", "\n", "self", ".", "rect1", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "origin", "[", "0", "]", "-", "15", ",", "origin", "[", "1", "]", "-", "15", ",", "\n", "origin", "[", "0", "]", "+", "15", ",", "origin", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'red'", ")", "\n", "\n", "self", ".", "rect2", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "165.0", ",", "165.0", ",", "\n", "195.0", ",", "195.0", ",", "\n", "fill", "=", "'blue'", ")", "\n", "\n", "return", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.maze_env.Maze.step": [[85, 185], ["maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "numpy.array", "numpy.array", "maze_env.Maze.canvas.move", "maze_env.Maze.canvas.move", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.move", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.move"], ["", "def", "step", "(", "self", ",", "action1", ",", "action2", ")", ":", "\n", "        ", "s", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect1", ")", "\n", "s2", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect2", ")", "\n", "base_action1", "=", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", "\n", "base_action2", "=", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", "\n", "\n", "if", "action1", "==", "0", ":", "# up", "\n", "            ", "if", "s", "[", "1", "]", ">", "UNIT", ":", "\n", "                ", "base_action1", "[", "1", "]", "-=", "UNIT", "\n", "", "", "elif", "action1", "==", "1", ":", "# down", "\n", "            ", "if", "s", "[", "1", "]", "<", "(", "MAZE_H", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action1", "[", "1", "]", "+=", "UNIT", "\n", "", "", "elif", "action1", "==", "2", ":", "# right", "\n", "            ", "if", "s", "[", "0", "]", "<", "(", "MAZE_W", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action1", "[", "0", "]", "+=", "UNIT", "\n", "", "", "elif", "action1", "==", "3", ":", "# left", "\n", "            ", "if", "s", "[", "0", "]", ">", "UNIT", ":", "\n", "                ", "base_action1", "[", "0", "]", "-=", "UNIT", "\n", "\n", "", "", "if", "action2", "==", "0", ":", "# up", "\n", "            ", "if", "s2", "[", "1", "]", ">", "UNIT", ":", "\n", "                ", "base_action2", "[", "1", "]", "-=", "UNIT", "\n", "", "", "elif", "action2", "==", "1", ":", "# down", "\n", "            ", "if", "s2", "[", "1", "]", "<", "(", "MAZE_H", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action2", "[", "1", "]", "+=", "UNIT", "\n", "", "", "elif", "action2", "==", "2", ":", "# right", "\n", "            ", "if", "s2", "[", "0", "]", "<", "(", "MAZE_W", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action2", "[", "0", "]", "+=", "UNIT", "\n", "", "", "elif", "action2", "==", "3", ":", "# left", "\n", "            ", "if", "s2", "[", "0", "]", ">", "UNIT", ":", "\n", "                ", "base_action2", "[", "0", "]", "-=", "UNIT", "\n", "", "", "self", ".", "canvas", ".", "move", "(", "self", ".", "rect1", ",", "base_action1", "[", "0", "]", ",", "base_action1", "[", "1", "]", ")", "# move agent", "\n", "self", ".", "canvas", ".", "move", "(", "self", ".", "rect2", ",", "base_action2", "[", "0", "]", ",", "base_action2", "[", "1", "]", ")", "# move agent", "\n", "\n", "s_", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect1", ")", "# next state", "\n", "s2_", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect2", ")", "# next state", "\n", "reward", "=", "0", "\n", "reward2", "=", "0", "\n", "done", "=", "False", "\n", "\n", "if", "s_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", "and", "s2_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", ":", "\n", "            ", "reward", "=", "2", "\n", "reward2", "=", "2", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", "and", "s2_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "-", "2", "\n", "reward2", "=", "-", "2", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "\n", "", "elif", "s_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", "and", "s2_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "1", "\n", "reward2", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s2_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", "and", "s_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "1", "\n", "reward2", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", ":", "\n", "            ", "reward", "=", "1", "\n", "reward2", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "-", "1", "\n", "reward2", "=", "-", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "\n", "", "elif", "s2_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", ":", "\n", "            ", "reward2", "=", "1", "\n", "reward", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s2_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "-", "1", "\n", "reward2", "=", "-", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "\n", "", "return", "s_", ",", "s2_", ",", "reward", ",", "reward2", ",", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.maze_env.Maze.render": [[187, 189], ["maze_env.Maze.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "self", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.maze_env.update": [[191, 200], ["range", "env.reset", "env.render", "env.step"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["", "", "def", "update", "(", ")", ":", "\n", "    ", "for", "t", "in", "range", "(", "10", ")", ":", "\n", "        ", "s", "=", "env", ".", "reset", "(", ")", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "a", "=", "1", "\n", "s", ",", "r", ",", "done", "=", "env", ".", "step", "(", "a", ")", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.run_this_sarsa.update": [[8, 71], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "env.step", "RL.choose_action", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation2_.copy", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "\n", "", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ",", "action_", ",", "action2_", ")", "\n", "\n", "\n", "action", "=", "action_", "\n", "action2", "=", "action2_", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'sarsa.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "episode", ",", "reward", ",", "reward2", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.run_this_advisor3.update": [[8, 76], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "env.step", "RL.choose_greedy_action", "RL.choose_action", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation_.copy", "observation2_.copy", "observation2_.copy", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.choose_greedy_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ",", "action_", ",", "action2_", ")", "\n", "\n", "\n", "action", "=", "action_", "\n", "action2", "=", "action2_", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'advisor3.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "episode", ",", "reward", ",", "reward2", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay": [[18, 34], ["enumerate"], "methods", ["None"], ["", "def", "linear_decay", "(", "self", ",", "epoch", ",", "x", ",", "y", ")", ":", "\n", "        ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "            ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "epoch", "<=", "x_i", ":", "\n", "                ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.choose_action": [[37, 68], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor2.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor2.QLearningTable.check_state2_exist", "RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "numpy.random.uniform", "RL_brain_admiraldm_advisor2.QLearningTable.advisor_action", "RL_brain_admiraldm_advisor2.QLearningTable.advisor_action", "int", "int", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.linear_decay", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ",", "episode", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "k", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "0.3", ",", "0.05", ",", "0", "]", ")", "\n", "t", "=", "self", ".", "linear_decay", "(", "episode", ",", "[", "0", ",", "int", "(", "2000", "*", "0.99", ")", ",", "2000", "]", ",", "[", "self", ".", "epsilon", ",", "0.02", ",", "0", "]", ")", "\n", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "k", ":", "\n", "                ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "", "else", ":", "\n", "                ", "if", "np", ".", "random", ".", "uniform", "(", ")", ">", "t", ":", "\n", "                    ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                    ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.choose_greedy_action": [[70, 90], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiraldm_advisor2.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor2.QLearningTable.check_state2_exist", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "choose_greedy_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "\n", "        ", "if", "observation", "==", "'terminal'", "or", "observation2", "==", "'terminal'", ":", "\n", "            ", "action", "=", "0", "\n", "action2", "=", "0", "\n", "return", "action", ",", "action2", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.learn": [[96, 124], ["s.append", "s2.append", "str", "str", "RL_brain_admiraldm_advisor2.QLearningTable.check_state_exist", "RL_brain_admiraldm_advisor2.QLearningTable.check_state2_exist", "s_.append", "str", "RL_brain_admiraldm_advisor2.QLearningTable.check_state_exist", "s2_.append", "str", "RL_brain_admiraldm_advisor2.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ",", "a_", ",", "a2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_", ".", "append", "(", "a2_", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "a_", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "s2_", ".", "append", "(", "a_", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "a2_", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.advisor_action": [[130, 158], ["numpy.random.choice"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "\n", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "if", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "3", "\n", "\n", "", "if", "s", "[", "1", "]", "<", "UNIT", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.check_state_exist": [[160, 167], ["RL_brain_admiraldm_advisor2.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiraldmmaze.RL_brain_admiraldm_advisor2.QLearningTable.check_state2_exist": [[171, 178], ["RL_brain_admiraldm_advisor2.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_advisor.update": [[10, 55], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "observation.copy", "observation2.copy", "RL.choose_action", "env.step", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["\n", "\n", "", "def", "update", "(", ")", ":", "\n", "    ", "cumulative_reward", "=", "0", "\n", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "\n", "\n", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_qlearning.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.9", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "# a list", "\n", "self", ".", "actions2", "=", "actions2", "# a list", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_qlearning.QLearningTable.choose_action": [[18, 38], ["observation.append", "observation2.append", "str", "str", "RL_brain_qlearning.QLearningTable.check_state_exist", "RL_brain_qlearning.QLearningTable.check_state2_exist", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "        ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "# action selection", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "# choose best action", "\n", "            ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "# some actions may have the same value, randomly choose on in these actions", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "# choose random action", "\n", "            ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_qlearning.QLearningTable.learn": [[39, 67], ["s.append", "s2.append", "str", "str", "RL_brain_qlearning.QLearningTable.check_state_exist", "RL_brain_qlearning.QLearningTable.check_state2_exist", "s_.append", "str", "RL_brain_qlearning.QLearningTable.check_state_exist", "s2_.append", "str", "RL_brain_qlearning.QLearningTable.check_state2_exist", "RL_brain_qlearning.QLearningTable.q_table.loc[].max", "RL_brain_qlearning.QLearningTable.q_table2.loc[].max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_", ".", "append", "(", "a2", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", ":", "]", ".", "max", "(", ")", "# next state is not terminal", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "# next state is terminal", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "# update", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "s2_", ".", "append", "(", "a", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", ":", "]", ".", "max", "(", ")", "# next state is not terminal", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "# next state is terminal", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "# update", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_qlearning.QLearningTable.check_state_exist": [[69, 77], ["RL_brain_qlearning.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "# append new state to q table", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_qlearning.QLearningTable.check_state2_exist": [[81, 89], ["RL_brain_qlearning.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "# append new state to q table", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor.QLearningTable.__init__": [[9, 19], ["pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.9", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table3", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table4", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor.QLearningTable.choose_action": [[23, 43], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiralae_advisor.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor.QLearningTable.check_state2_exist", "numpy.random.uniform", "RL_brain_admiralae_advisor.QLearningTable.advisor_action", "RL_brain_admiralae_advisor.QLearningTable.advisor_action", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "        ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ":", "\n", "            ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "", "else", ":", "\n", "            ", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "                ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor.QLearningTable.learn": [[44, 79], ["s.append", "s2.append", "str", "str", "RL_brain_admiralae_advisor.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor.QLearningTable.check_state2_exist", "RL_brain_admiralae_advisor.QLearningTable.advisor_action", "RL_brain_admiralae_advisor.QLearningTable.advisor_action", "s_.append", "str", "RL_brain_admiralae_advisor.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor.QLearningTable.advisor_action", "RL_brain_admiralae_advisor.QLearningTable.advisor_action", "s2_.append", "str", "RL_brain_admiralae_advisor.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ")", ":", "\n", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "s_", ".", "append", "(", "advisoraction2", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "advisoraction", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "s2_", ".", "append", "(", "advisoraction", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "advisoraction2", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor.QLearningTable.mean_square_error": [[89, 109], ["RL_brain_admiralae_advisor.QLearningTable.q_table3.iterrows", "print"], "methods", ["None"], ["", "def", "mean_square_error", "(", "self", ")", ":", "\n", "        ", "mse", "=", "0", "\n", "for", "index", ",", "row", "in", "self", ".", "q_table3", ".", "iterrows", "(", ")", ":", "\n", "            ", "if", "row", "[", "0", "]", "in", "self", ".", "q_table", ".", "index", ":", "\n", "                ", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "0", "]", "-", "row", "[", "1", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "1", "]", "-", "row", "[", "2", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "0", "]", "-", "row", "[", "3", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "0", "]", "-", "row", "[", "4", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "", "", "size", "=", "self", ".", "q_table", ".", "size", "*", "4", "\n", "mse", "=", "mse", "/", "size", "\n", "print", "(", "\"the mse is\"", ",", "mse", ")", "\n", "return", "mse", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor.QLearningTable.advisor_action": [[112, 149], ["None"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "if", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "3", "\n", "\n", "", "if", "s", "[", "1", "]", "<", "UNIT", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor.QLearningTable.check_state_exist": [[151, 158], ["RL_brain_admiralae_advisor.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor.QLearningTable.check_state2_exist": [[162, 169], ["RL_brain_admiralae_advisor.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_advisormse.update": [[10, 62], ["range", "print", "env.destroy", "env.reset", "RL.mean_square_error", "print", "env.render", "observation.copy", "observation2.copy", "RL.choose_action", "env.step", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile2.write", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.mean_square_error", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "cumulative_reward1", "=", "0", "\n", "cumulative_reward2", "=", "0", "\n", "\n", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "\n", "action", ",", "action2", "=", "RL", ".", "choose_action", "(", "observationcopy", ",", "observation2copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ")", "\n", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "\n", "\n", "", "", "mse", "=", "RL", ".", "mean_square_error", "(", ")", "\n", "\n", "with", "open", "(", "'mse.csv'", ",", "'a'", ")", "as", "myfile2", ":", "\n", "            ", "myfile2", ".", "write", "(", "'{0},{1}\\n'", ".", "format", "(", "episode", ",", "mse", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor2.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.9", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor2.QLearningTable.choose_action": [[18, 38], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiralae_advisor2.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor2.QLearningTable.check_state2_exist", "numpy.random.uniform", "RL_brain_admiralae_advisor2.QLearningTable.advisor_action", "RL_brain_admiralae_advisor2.QLearningTable.advisor_action", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "        ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ":", "\n", "            ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "", "else", ":", "\n", "            ", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "                ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor2.QLearningTable.learn": [[39, 71], ["s.append", "s2.append", "str", "str", "RL_brain_admiralae_advisor2.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor2.QLearningTable.check_state2_exist", "RL_brain_admiralae_advisor2.QLearningTable.advisor_action", "RL_brain_admiralae_advisor2.QLearningTable.advisor_action", "s_.append", "str", "RL_brain_admiralae_advisor2.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor2.QLearningTable.advisor_action", "RL_brain_admiralae_advisor2.QLearningTable.advisor_action", "s2_.append", "str", "RL_brain_admiralae_advisor2.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "s_", ".", "append", "(", "advisoraction2", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "advisoraction", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "s2_", ".", "append", "(", "advisoraction", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "advisoraction2", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor2.QLearningTable.advisor_action": [[81, 109], ["numpy.random.choice"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "\n", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "if", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "3", "\n", "\n", "", "if", "s", "[", "1", "]", "<", "UNIT", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor2.QLearningTable.check_state_exist": [[111, 118], ["RL_brain_admiralae_advisor2.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor2.QLearningTable.check_state2_exist": [[122, 129], ["RL_brain_admiralae_advisor2.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_advisor4.update": [[8, 54], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "observation.copy", "observation2.copy", "RL.choose_action", "env.step", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "cumulative_reward", "=", "0", "\n", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_advisor2.update": [[8, 53], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "observation.copy", "observation2.copy", "RL.choose_action", "env.step", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.__init__": [[16, 23], ["super().__init__", "len", "maze_env.Maze.title", "maze_env.Maze.geometry", "maze_env.Maze._build_maze"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze._build_maze"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Maze", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "action_space", "=", "[", "'u'", ",", "'d'", ",", "'l'", ",", "'r'", "]", "\n", "self", ".", "n_actions", "=", "len", "(", "self", ".", "action_space", ")", "\n", "self", ".", "title", "(", "'maze'", ")", "\n", "self", ".", "geometry", "(", "'{0}x{1}'", ".", "format", "(", "MAZE_H", "*", "UNIT", ",", "MAZE_H", "*", "UNIT", ")", ")", "\n", "self", ".", "_build_maze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze._build_maze": [[24, 67], ["tk.Canvas", "range", "range", "numpy.array", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_oval", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.pack", "maze_env.Maze.canvas.create_line", "maze_env.Maze.canvas.create_line", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_build_maze", "(", "self", ")", ":", "\n", "        ", "self", ".", "canvas", "=", "tk", ".", "Canvas", "(", "self", ",", "bg", "=", "'white'", ",", "\n", "height", "=", "MAZE_H", "*", "UNIT", ",", "\n", "width", "=", "MAZE_W", "*", "UNIT", ")", "\n", "\n", "for", "c", "in", "range", "(", "0", ",", "MAZE_W", "*", "UNIT", ",", "UNIT", ")", ":", "\n", "            ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "c", ",", "0", ",", "c", ",", "MAZE_H", "*", "UNIT", "\n", "self", ".", "canvas", ".", "create_line", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "", "for", "r", "in", "range", "(", "0", ",", "MAZE_H", "*", "UNIT", ",", "UNIT", ")", ":", "\n", "            ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "0", ",", "r", ",", "MAZE_W", "*", "UNIT", ",", "r", "\n", "self", ".", "canvas", ".", "create_line", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "\n", "", "origin", "=", "np", ".", "array", "(", "[", "20", ",", "20", "]", ")", "\n", "\n", "hell1_center", "=", "origin", "+", "np", ".", "array", "(", "[", "UNIT", "*", "2", ",", "UNIT", "]", ")", "\n", "self", ".", "hell1", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "hell1_center", "[", "0", "]", "-", "15", ",", "hell1_center", "[", "1", "]", "-", "15", ",", "\n", "hell1_center", "[", "0", "]", "+", "15", ",", "hell1_center", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'black'", ")", "\n", "hell2_center", "=", "origin", "+", "np", ".", "array", "(", "[", "UNIT", "*", "2", ",", "UNIT", "*", "3", "]", ")", "\n", "self", ".", "hell2", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "hell2_center", "[", "0", "]", "-", "15", ",", "hell2_center", "[", "1", "]", "-", "15", ",", "\n", "hell2_center", "[", "0", "]", "+", "15", ",", "hell2_center", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'black'", ")", "\n", "\n", "oval_center", "=", "origin", "+", "UNIT", "*", "2", "\n", "self", ".", "oval", "=", "self", ".", "canvas", ".", "create_oval", "(", "\n", "oval_center", "[", "0", "]", "-", "15", ",", "oval_center", "[", "1", "]", "-", "15", ",", "\n", "oval_center", "[", "0", "]", "+", "15", ",", "oval_center", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'yellow'", ")", "\n", "\n", "self", ".", "rect1", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "origin", "[", "0", "]", "-", "15", ",", "origin", "[", "1", "]", "-", "15", ",", "\n", "origin", "[", "0", "]", "+", "15", ",", "origin", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'red'", ")", "\n", "\n", "self", ".", "rect2", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "165.0", ",", "165.0", ",", "\n", "195.0", ",", "195.0", ",", "\n", "fill", "=", "'blue'", ")", "\n", "\n", "self", ".", "canvas", ".", "pack", "(", ")", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset": [[68, 85], ["maze_env.Maze.update", "time.sleep", "maze_env.Maze.canvas.delete", "maze_env.Maze.canvas.delete", "numpy.array", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.create_rectangle", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["        ", "self", ".", "update", "(", ")", "\n", "time", ".", "sleep", "(", "0.1", ")", "\n", "self", ".", "canvas", ".", "delete", "(", "self", ".", "rect1", ")", "\n", "self", ".", "canvas", ".", "delete", "(", "self", ".", "rect2", ")", "\n", "origin", "=", "np", ".", "array", "(", "[", "20", ",", "20", "]", ")", "\n", "self", ".", "rect1", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "origin", "[", "0", "]", "-", "15", ",", "origin", "[", "1", "]", "-", "15", ",", "\n", "origin", "[", "0", "]", "+", "15", ",", "origin", "[", "1", "]", "+", "15", ",", "\n", "fill", "=", "'red'", ")", "\n", "\n", "self", ".", "rect2", "=", "self", ".", "canvas", ".", "create_rectangle", "(", "\n", "165.0", ",", "165.0", ",", "\n", "195.0", ",", "195.0", ",", "\n", "fill", "=", "'blue'", ")", "\n", "\n", "return", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect2", ")", "\n", "\n", "", "def", "step", "(", "self", ",", "action1", ",", "action2", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step": [[86, 187], ["maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "numpy.array", "numpy.array", "maze_env.Maze.canvas.move", "maze_env.Maze.canvas.move", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords", "maze_env.Maze.canvas.coords"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.move", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.characters.Bomb.move"], ["        ", "s", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect1", ")", "\n", "s2", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect2", ")", "\n", "base_action1", "=", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", "\n", "base_action2", "=", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", "\n", "\n", "if", "action1", "==", "0", ":", "# up", "\n", "            ", "if", "s", "[", "1", "]", ">", "UNIT", ":", "\n", "                ", "base_action1", "[", "1", "]", "-=", "UNIT", "\n", "", "", "elif", "action1", "==", "1", ":", "# down", "\n", "            ", "if", "s", "[", "1", "]", "<", "(", "MAZE_H", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action1", "[", "1", "]", "+=", "UNIT", "\n", "", "", "elif", "action1", "==", "2", ":", "# right", "\n", "            ", "if", "s", "[", "0", "]", "<", "(", "MAZE_W", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action1", "[", "0", "]", "+=", "UNIT", "\n", "", "", "elif", "action1", "==", "3", ":", "# left", "\n", "            ", "if", "s", "[", "0", "]", ">", "UNIT", ":", "\n", "                ", "base_action1", "[", "0", "]", "-=", "UNIT", "\n", "\n", "", "", "if", "action2", "==", "0", ":", "# up", "\n", "            ", "if", "s2", "[", "1", "]", ">", "UNIT", ":", "\n", "                ", "base_action2", "[", "1", "]", "-=", "UNIT", "\n", "", "", "elif", "action2", "==", "1", ":", "# down", "\n", "            ", "if", "s2", "[", "1", "]", "<", "(", "MAZE_H", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action2", "[", "1", "]", "+=", "UNIT", "\n", "", "", "elif", "action2", "==", "2", ":", "# right", "\n", "            ", "if", "s2", "[", "0", "]", "<", "(", "MAZE_W", "-", "1", ")", "*", "UNIT", ":", "\n", "                ", "base_action2", "[", "0", "]", "+=", "UNIT", "\n", "", "", "elif", "action2", "==", "3", ":", "# left", "\n", "            ", "if", "s2", "[", "0", "]", ">", "UNIT", ":", "\n", "                ", "base_action2", "[", "0", "]", "-=", "UNIT", "\n", "", "", "self", ".", "canvas", ".", "move", "(", "self", ".", "rect1", ",", "base_action1", "[", "0", "]", ",", "base_action1", "[", "1", "]", ")", "# move agent", "\n", "self", ".", "canvas", ".", "move", "(", "self", ".", "rect2", ",", "base_action2", "[", "0", "]", ",", "base_action2", "[", "1", "]", ")", "# move agent", "\n", "\n", "s_", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect1", ")", "# next state", "\n", "s2_", "=", "self", ".", "canvas", ".", "coords", "(", "self", ".", "rect2", ")", "# next state", "\n", "reward", "=", "0", "\n", "reward2", "=", "0", "\n", "done", "=", "False", "\n", "\n", "if", "s_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", "and", "s2_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", ":", "\n", "            ", "reward", "=", "2", "\n", "reward2", "=", "2", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", "and", "s2_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "-", "2", "\n", "reward2", "=", "-", "2", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "\n", "", "elif", "s_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", "and", "s2_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "1", "\n", "reward2", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s2_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", "and", "s_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "1", "\n", "reward2", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", ":", "\n", "            ", "reward", "=", "1", "\n", "reward2", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "-", "1", "\n", "reward2", "=", "-", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "\n", "", "elif", "s2_", "==", "self", ".", "canvas", ".", "coords", "(", "self", ".", "oval", ")", ":", "\n", "            ", "reward2", "=", "1", "\n", "reward", "=", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "", "elif", "s2_", "in", "[", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell1", ")", ",", "self", ".", "canvas", ".", "coords", "(", "self", ".", "hell2", ")", "]", ":", "\n", "            ", "reward", "=", "-", "1", "\n", "reward2", "=", "-", "1", "\n", "done", "=", "True", "\n", "s_", "=", "'terminal'", "\n", "s2_", "=", "'terminal'", "\n", "\n", "\n", "", "return", "s_", ",", "s2_", ",", "reward", ",", "reward2", ",", "done", "\n", "\n", "\n", "", "def", "render", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render": [[189, 191], ["maze_env.Maze.update"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update"], ["\n", "\n", "", "", "def", "update", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.update": [[193, 202], ["range", "env.reset", "env.render", "env.step"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step"], ["        ", "s", "=", "env", ".", "reset", "(", ")", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "a", "=", "1", "\n", "s", ",", "r", ",", "done", "=", "env", ".", "step", "(", "a", ")", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "env", "=", "Maze", "(", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_advisor3.update": [[8, 53], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "observation.copy", "observation2.copy", "RL.choose_action", "env.step", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "action", "=", "0", "\n", "action2", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "\n", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "observation_copy2", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "observation_copy2", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "observation2_copy2", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "observation2_copy2", "=", "observation2_", "\n", "\n", "", "action_greedy", ",", "action2_greedy", "=", "RL", ".", "choose_greedy_action", "(", "observation_copy", ",", "observation2_copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "action_", ",", "action2_", "=", "RL", ".", "choose_action", "(", "observation_copy2", ",", "observation2_copy2", ",", "action_greedy", ",", "action2_greedy", ",", "episode", ")", "\n", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor4.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.9", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor4.QLearningTable.choose_action": [[18, 39], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiralae_advisor4.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor4.QLearningTable.check_state2_exist", "numpy.random.uniform", "RL_brain_admiralae_advisor4.QLearningTable.advisor_action", "RL_brain_admiralae_advisor4.QLearningTable.advisor_action", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "        ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ":", "\n", "            ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "                ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor4.QLearningTable.learn": [[40, 72], ["s.append", "s2.append", "str", "str", "RL_brain_admiralae_advisor4.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor4.QLearningTable.check_state2_exist", "RL_brain_admiralae_advisor4.QLearningTable.advisor_action", "RL_brain_admiralae_advisor4.QLearningTable.advisor_action", "s_.append", "str", "RL_brain_admiralae_advisor4.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor4.QLearningTable.advisor_action", "RL_brain_admiralae_advisor4.QLearningTable.advisor_action", "s2_.append", "str", "RL_brain_admiralae_advisor4.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "s_", ".", "append", "(", "advisoraction2", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "advisoraction", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "s2_", ".", "append", "(", "advisoraction", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "advisoraction2", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor4.QLearningTable.advisor_action": [[81, 85], ["numpy.random.choice"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor4.QLearningTable.check_state_exist": [[87, 94], ["RL_brain_admiralae_advisor4.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor4.QLearningTable.check_state2_exist": [[98, 105], ["RL_brain_admiralae_advisor4.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor3.QLearningTable.__init__": [[9, 17], ["pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.9", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor3.QLearningTable.choose_action": [[18, 39], ["observation.append", "observation2.append", "str", "str", "RL_brain_admiralae_advisor3.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor3.QLearningTable.check_state2_exist", "numpy.random.uniform", "RL_brain_admiralae_advisor3.QLearningTable.advisor_action", "RL_brain_admiralae_advisor3.QLearningTable.advisor_action", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "        ", "observation", ".", "append", "(", "action2", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ":", "\n", "            ", "action", "=", "self", ".", "advisor_action", "(", "observation", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "                ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor3.QLearningTable.learn": [[40, 72], ["s.append", "s2.append", "str", "str", "RL_brain_admiralae_advisor3.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor3.QLearningTable.check_state2_exist", "RL_brain_admiralae_advisor3.QLearningTable.advisor_action", "RL_brain_admiralae_advisor3.QLearningTable.advisor_action", "s_.append", "str", "RL_brain_admiralae_advisor3.QLearningTable.check_state_exist", "RL_brain_admiralae_advisor3.QLearningTable.advisor_action", "RL_brain_admiralae_advisor3.QLearningTable.advisor_action", "s2_.append", "str", "RL_brain_admiralae_advisor3.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ")", ":", "\n", "        ", "s", ".", "append", "(", "a2", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "s_", ".", "append", "(", "advisoraction2", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "advisoraction", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_", ")", "\n", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "s2_", ".", "append", "(", "advisoraction", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "advisoraction2", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor3.QLearningTable.advisor_action": [[82, 97], ["numpy.random.choice"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "\n", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor3.QLearningTable.check_state_exist": [[99, 106], ["RL_brain_admiralae_advisor3.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_advisor3.QLearningTable.check_state2_exist": [[110, 117], ["RL_brain_admiralae_advisor3.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.__init__": [[9, 21], ["pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "RL_brain_admiralae_mse.QLearningTable.read_csv"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.read_csv"], ["    ", "def", "__init__", "(", "self", ",", "actions", ",", "actions2", ",", "learning_rate", "=", "0.01", ",", "reward_decay", "=", "0.9", ",", "e_greedy", "=", "0.9", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "self", ".", "actions2", "=", "actions2", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "epsilon", "=", "e_greedy", "\n", "self", ".", "q_table", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table2", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table3", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "q_table4", "=", "pd", ".", "DataFrame", "(", "columns", "=", "self", ".", "actions2", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "self", ".", "read_csv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action": [[24, 48], ["observation.copy", "observation2.copy", "observation.append", "observation.extend", "str", "observation2.append", "observation2.extend", "str", "RL_brain_admiralae_mse.QLearningTable.check_state_exist", "RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "numpy.random.uniform", "RL_brain_admiralae_mse.QLearningTable.advisor_action", "RL_brain_admiralae_mse.QLearningTable.advisor_action", "numpy.random.uniform", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action"], ["", "def", "choose_action", "(", "self", ",", "observation", ",", "observation2", ",", "action", ",", "action2", ")", ":", "\n", "        ", "observation_tmp", "=", "observation", ".", "copy", "(", ")", "\n", "observation2_tmp", "=", "observation2", ".", "copy", "(", ")", "\n", "observation", ".", "append", "(", "action2", ")", "\n", "observation", ".", "extend", "(", "observation2_tmp", ")", "\n", "strobservation", "=", "str", "(", "observation", ")", "\n", "observation2", ".", "append", "(", "action", ")", "\n", "observation2", ".", "extend", "(", "observation_tmp", ")", "\n", "strobservation2", "=", "str", "(", "observation2", ")", "\n", "self", ".", "check_state_exist", "(", "strobservation", ")", "\n", "self", ".", "check_state2_exist", "(", "strobservation2", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<=", "0.5", ":", "\n", "            ", "action", "=", "self", ".", "advisor_action", "(", "observation_tmp", ")", "\n", "action2", "=", "self", ".", "advisor_action", "(", "observation2_tmp", ")", "\n", "", "else", ":", "\n", "            ", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "self", ".", "epsilon", ":", "\n", "                ", "state_action", "=", "self", ".", "q_table", ".", "loc", "[", "strobservation", ",", ":", "]", "\n", "state_action2", "=", "self", ".", "q_table2", ".", "loc", "[", "strobservation2", ",", ":", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "state_action", "[", "state_action", "==", "np", ".", "max", "(", "state_action", ")", "]", ".", "index", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "state_action2", "[", "state_action2", "==", "np", ".", "max", "(", "state_action2", ")", "]", ".", "index", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions", ")", "\n", "action2", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "actions2", ")", "\n", "", "", "return", "action", ",", "action2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn": [[49, 92], ["s.copy", "s2.copy", "s.append", "s.extend", "s2.append", "s2.extend", "str", "str", "RL_brain_admiralae_mse.QLearningTable.check_state_exist", "RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "s_.copy", "RL_brain_admiralae_mse.QLearningTable.advisor_action", "RL_brain_admiralae_mse.QLearningTable.advisor_action", "s_.append", "s_.extend", "str", "RL_brain_admiralae_mse.QLearningTable.check_state_exist", "RL_brain_admiralae_mse.QLearningTable.advisor_action", "RL_brain_admiralae_mse.QLearningTable.advisor_action", "s2_.append", "s2_.extend", "str", "RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist"], ["", "def", "learn", "(", "self", ",", "s", ",", "s2", ",", "a", ",", "a2", ",", "r", ",", "r2", ",", "s_", ",", "s2_", ")", ":", "\n", "        ", "stmp", "=", "s", ".", "copy", "(", ")", "\n", "s2tmp", "=", "s2", ".", "copy", "(", ")", "\n", "s", ".", "append", "(", "a2", ")", "\n", "s", ".", "extend", "(", "s2tmp", ")", "\n", "s2", ".", "append", "(", "a", ")", "\n", "s2", ".", "extend", "(", "stmp", ")", "\n", "strs", "=", "str", "(", "s", ")", "\n", "strs2", "=", "str", "(", "s2", ")", "\n", "\n", "self", ".", "check_state_exist", "(", "strs", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2", ")", "\n", "q_predict", "=", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "\n", "q_predict2", "=", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "\n", "if", "s_", "!=", "'terminal'", ":", "\n", "            ", "s_tmp", "=", "s_", ".", "copy", "(", ")", "\n", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_tmp", ")", "\n", "s_", ".", "append", "(", "advisoraction2", ")", "\n", "s_", ".", "extend", "(", "s2_", ")", "\n", "strs_", "=", "str", "(", "s_", ")", "\n", "\n", "self", ".", "check_state_exist", "(", "strs_", ")", "\n", "\n", "q_target", "=", "r", "+", "self", ".", "gamma", "*", "self", ".", "q_table", ".", "loc", "[", "strs_", ",", "advisoraction", "]", "\n", "", "else", ":", "\n", "            ", "q_target", "=", "r", "\n", "\n", "", "self", ".", "q_table", ".", "loc", "[", "strs", ",", "a", "]", "+=", "self", ".", "lr", "*", "(", "q_target", "-", "q_predict", ")", "\n", "\n", "\n", "if", "s2_", "!=", "'terminal'", ":", "\n", "            ", "advisoraction", "=", "self", ".", "advisor_action", "(", "s_tmp", ")", "\n", "advisoraction2", "=", "self", ".", "advisor_action", "(", "s2_", ")", "\n", "s2_", ".", "append", "(", "advisoraction", ")", "\n", "s2_", ".", "extend", "(", "s_tmp", ")", "\n", "strs2_", "=", "str", "(", "s2_", ")", "\n", "self", ".", "check_state2_exist", "(", "strs2_", ")", "\n", "q_target2", "=", "r2", "+", "self", ".", "gamma", "*", "self", ".", "q_table2", ".", "loc", "[", "strs2_", ",", "advisoraction2", "]", "\n", "", "else", ":", "\n", "            ", "q_target2", "=", "r2", "\n", "\n", "", "self", ".", "q_table2", ".", "loc", "[", "strs2", ",", "a2", "]", "+=", "self", ".", "lr", "*", "(", "q_target2", "-", "q_predict2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.mean_square_error": [[97, 117], ["RL_brain_admiralae_mse.QLearningTable.q_table3.iterrows", "print"], "methods", ["None"], ["", "def", "mean_square_error", "(", "self", ")", ":", "\n", "        ", "mse", "=", "0", "\n", "for", "index", ",", "row", "in", "self", ".", "q_table3", ".", "iterrows", "(", ")", ":", "\n", "            ", "if", "row", "[", "0", "]", "in", "self", ".", "q_table", ".", "index", ":", "\n", "                ", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "0", "]", "-", "row", "[", "1", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "1", "]", "-", "row", "[", "2", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "2", "]", "-", "row", "[", "3", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "error", "=", "self", ".", "q_table", ".", "loc", "[", "row", "[", "0", "]", ",", "3", "]", "-", "row", "[", "4", "]", "\n", "error", "=", "error", "*", "error", "\n", "mse", "=", "mse", "+", "error", "\n", "", "", "size", "=", "self", ".", "q_table", ".", "size", "*", "4", "\n", "mse", "=", "mse", "/", "size", "\n", "print", "(", "\"the mse is\"", ",", "mse", ")", "\n", "return", "mse", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.write_to_csv": [[119, 124], ["RL_brain_admiralae_mse.QLearningTable.q_table.to_csv", "RL_brain_admiralae_mse.QLearningTable.q_table2.to_csv", "print"], "methods", ["None"], ["", "def", "write_to_csv", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "q_table", ".", "to_csv", "(", "'q_table1.csv'", ")", "\n", "self", ".", "q_table2", ".", "to_csv", "(", "'q_table2.csv'", ")", "\n", "print", "(", "\"Files written\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.read_csv": [[125, 129], ["pandas.read_csv", "pandas.read_csv", "print"], "methods", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.read_csv", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.read_csv"], ["", "def", "read_csv", "(", "self", ")", ":", "\n", "        ", "self", ".", "q_table3", "=", "pd", ".", "read_csv", "(", "'q_table1.csv'", ")", "\n", "self", ".", "q_table4", "=", "pd", ".", "read_csv", "(", "'q_table2.csv'", ")", "\n", "print", "(", "\"Read both the files\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.advisor_action": [[130, 167], ["None"], "methods", ["None"], ["", "def", "advisor_action", "(", "self", ",", "s", ")", ":", "\n", "\n", "        ", "if", "s", "[", "1", "]", ">", "UNIT", "*", "(", "MAZE_H", "-", "1", ")", ":", "\n", "            ", "action", "=", "0", "\n", "", "elif", "s", "[", "0", "]", ">", "UNIT", "*", "(", "MAZE_W", "-", "1", ")", ":", "\n", "            ", "action", "=", "3", "\n", "", "elif", "s", "[", "0", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "2", "\n", "", "elif", "s", "[", "1", "]", "<", "UNIT", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "\n", "", "if", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "3", "\n", "\n", "", "if", "s", "[", "1", "]", "<", "UNIT", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "2", "and", "s", "[", "0", "]", "<", "UNIT", "*", "3", ":", "\n", "            ", "action", "=", "2", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "and", "s", "[", "0", "]", "<", "UNIT", "*", "2", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "and", "s", "[", "1", "]", "<", "UNIT", "*", "2", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "1", "\n", "\n", "", "elif", "s", "[", "1", "]", ">", "UNIT", "*", "3", "and", "s", "[", "1", "]", "<", "UNIT", "*", "4", "and", "s", "[", "0", "]", ">", "UNIT", "*", "3", "and", "s", "[", "0", "]", "<", "UNIT", "*", "4", ":", "\n", "            ", "action", "=", "0", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state_exist": [[169, 176], ["RL_brain_admiralae_mse.QLearningTable.q_table.append", "pandas.Series", "len"], "methods", ["None"], ["", "def", "check_state_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table", ".", "index", ":", "\n", "            ", "self", ".", "q_table", "=", "self", ".", "q_table", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions", ")", ",", "\n", "index", "=", "self", ".", "q_table", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.check_state2_exist": [[180, 187], ["RL_brain_admiralae_mse.QLearningTable.q_table2.append", "pandas.Series", "len"], "methods", ["None"], ["", "", "def", "check_state2_exist", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "state", "not", "in", "self", ".", "q_table2", ".", "index", ":", "\n", "            ", "self", ".", "q_table2", "=", "self", ".", "q_table2", ".", "append", "(", "\n", "pd", ".", "Series", "(", "\n", "[", "0", "]", "*", "len", "(", "self", ".", "actions2", ")", ",", "\n", "index", "=", "self", ".", "q_table2", ".", "columns", ",", "\n", "name", "=", "state", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.run_this_qlearning.update": [[8, 52], ["range", "print", "env.destroy", "env.reset", "print", "env.render", "observation.copy", "observation2.copy", "RL.choose_action", "env.step", "observation.copy", "observation2.copy", "RL.learn", "open", "myfile.write", "observation_.copy", "observation2_.copy"], "function", ["home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.reset", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.render", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.choose_action", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.maze_env.Maze.step", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.admiralaemaze.RL_brain_admiralae_mse.QLearningTable.learn", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy", "home.repos.pwc.inspect_result.sriram94_multiagentadvisorqlearning.pommerman.configs.AttrDict.copy"], ["", "def", "update", "(", ")", ":", "\n", "    ", "for", "episode", "in", "range", "(", "2000", ")", ":", "\n", "        ", "observation", ",", "observation2", "=", "env", ".", "reset", "(", ")", "\n", "action_tmp", "=", "0", "\n", "action2_tmp", "=", "0", "\n", "while", "True", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "\n", "\n", "action", ",", "action2", "=", "RL", ".", "choose_action", "(", "observationcopy", ",", "observation2copy", ",", "action_tmp", ",", "action2_tmp", ")", "\n", "\n", "observation_", ",", "observation2_", ",", "reward", ",", "reward2", ",", "done", "=", "env", ".", "step", "(", "action", ",", "action2", ")", "\n", "\n", "if", "observation_", "!=", "'terminal'", ":", "\n", "                ", "observation_copy", "=", "observation_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation_copy", "=", "observation_", "\n", "\n", "", "if", "observation2_", "!=", "'terminal'", ":", "\n", "                ", "observation2_copy", "=", "observation2_", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "observation2_copy", "=", "observation2_", "\n", "\n", "", "observationcopy", "=", "observation", ".", "copy", "(", ")", "\n", "observation2copy", "=", "observation2", ".", "copy", "(", ")", "\n", "RL", ".", "learn", "(", "observationcopy", ",", "observation2copy", ",", "action", ",", "action2", ",", "reward", ",", "reward2", ",", "observation_copy", ",", "observation2_copy", ")", "\n", "\n", "action_tmp", "=", "action", "\n", "action2_tmp", "=", "action2", "\n", "observation", "=", "observation_", "\n", "observation2", "=", "observation2_", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "open", "(", "'qalg.csv'", ",", "'a'", ")", "as", "myfile", ":", "\n", "            ", "myfile", ".", "write", "(", "'{0},{1},{2}\\n'", ".", "format", "(", "episode", ",", "reward", ",", "reward2", ")", ")", "\n", "", "print", "(", "'Episode {} finished'", ".", "format", "(", "episode", ")", ")", "\n", "\n", "", "print", "(", "'game over'", ")", "\n", "env", ".", "destroy", "(", ")", "\n", "\n"]]}