{"home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.main.test": [[92, 112], ["range", "print", "print", "print", "env.reset", "agent.select_action", "env.step", "round", "numpy.array"], "function", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.sac.SAC.select_action", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step"], ["", "def", "test", "(", "env", ")", ":", "\n", "    ", "avg_reward", "=", "0.", "\n", "episodes", "=", "10", "\n", "for", "_", "in", "range", "(", "episodes", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "episode_reward", "=", "0", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "            ", "action", "=", "agent", ".", "select_action", "(", "np", ".", "array", "(", "state", ")", ")", "\n", "\n", "next_state", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action", ")", "\n", "episode_reward", "+=", "reward", "\n", "\n", "state", "=", "next_state", "\n", "", "avg_reward", "+=", "episode_reward", "\n", "", "avg_reward", "/=", "episodes", "\n", "\n", "print", "(", "\"----------------------------------------\"", ")", "\n", "print", "(", "\"Test Episodes: {}, Avg. Reward: {}\"", ".", "format", "(", "episodes", ",", "round", "(", "avg_reward", ",", "2", ")", ")", ")", "\n", "print", "(", "\"----------------------------------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.Actor.__init__": [[12, 20], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["\t", "def", "__init__", "(", "self", ",", "state_dim", ",", "action_dim", ",", "max_action", ",", "hidden_size", "=", "256", ")", ":", "\n", "\t\t", "super", "(", "Actor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "l1", "=", "nn", ".", "Linear", "(", "state_dim", ",", "hidden_size", ")", "\n", "self", ".", "l2", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "l3", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "action_dim", ")", "\n", "\n", "self", ".", "max_action", "=", "max_action", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.Actor.forward": [[22, 26], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "TD3.Actor.l1", "TD3.Actor.l2", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "TD3.Actor.l3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ")", ":", "\n", "\t\t", "a", "=", "F", ".", "relu", "(", "self", ".", "l1", "(", "state", ")", ")", "\n", "a", "=", "F", ".", "relu", "(", "self", ".", "l2", "(", "a", ")", ")", "\n", "return", "self", ".", "max_action", "*", "torch", ".", "tanh", "(", "self", ".", "l3", "(", "a", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.Critic.__init__": [[29, 41], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["\t", "def", "__init__", "(", "self", ",", "state_dim", ",", "action_dim", ",", "hidden_size", "=", "256", ")", ":", "\n", "\t\t", "super", "(", "Critic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Q1 architecture", "\n", "self", ".", "l1", "=", "nn", ".", "Linear", "(", "state_dim", "+", "action_dim", ",", "hidden_size", ")", "\n", "self", ".", "l2", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "l3", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "\n", "# Q2 architecture", "\n", "self", ".", "l4", "=", "nn", ".", "Linear", "(", "state_dim", "+", "action_dim", ",", "hidden_size", ")", "\n", "self", ".", "l5", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "l6", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.Critic.forward": [[43, 54], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "TD3.Critic.l3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "TD3.Critic.l6", "TD3.Critic.l1", "TD3.Critic.l2", "TD3.Critic.l4", "TD3.Critic.l5"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "\t\t", "sa", "=", "torch", ".", "cat", "(", "[", "state", ",", "action", "]", ",", "1", ")", "\n", "\n", "q1", "=", "F", ".", "relu", "(", "self", ".", "l1", "(", "sa", ")", ")", "\n", "q1", "=", "F", ".", "relu", "(", "self", ".", "l2", "(", "q1", ")", ")", "\n", "q1", "=", "self", ".", "l3", "(", "q1", ")", "\n", "\n", "q2", "=", "F", ".", "relu", "(", "self", ".", "l4", "(", "sa", ")", ")", "\n", "q2", "=", "F", ".", "relu", "(", "self", ".", "l5", "(", "q2", ")", ")", "\n", "q2", "=", "self", ".", "l6", "(", "q2", ")", "\n", "return", "q1", ",", "q2", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.Critic.Q1": [[56, 63], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "TD3.Critic.l3", "TD3.Critic.l1", "TD3.Critic.l2"], "methods", ["None"], ["", "def", "Q1", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "\t\t", "sa", "=", "torch", ".", "cat", "(", "[", "state", ",", "action", "]", ",", "1", ")", "\n", "\n", "q1", "=", "F", ".", "relu", "(", "self", ".", "l1", "(", "sa", ")", ")", "\n", "q1", "=", "F", ".", "relu", "(", "self", ".", "l2", "(", "q1", ")", ")", "\n", "q1", "=", "self", ".", "l3", "(", "q1", ")", "\n", "return", "q1", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.TD3.__init__": [[66, 104], ["Actor().to", "copy.deepcopy", "copy.deepcopy", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "Critic().to", "copy.deepcopy", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "TD3.TD3.actor.parameters", "TD3.TD3.critic.parameters", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "TD3.Actor", "TD3.Critic", "str"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["\t", "def", "__init__", "(", "\n", "self", ",", "\n", "state_dim", ",", "\n", "action_dim", ",", "\n", "max_action", ",", "\n", "discount", "=", "0.99", ",", "\n", "tau", "=", "0.005", ",", "\n", "policy_noise", "=", "0.2", ",", "\n", "noise_clip", "=", "0.5", ",", "\n", "policy_freq", "=", "2", ",", "\n", "lr", "=", "3e-4", ",", "\n", "hidden_size", "=", "256", ",", "\n", "parameter_noise_mean", "=", "0.01", ",", "\n", "parameter_noise_std", "=", "1", ",", "\n", "cuda", "=", "0", ",", "\n", ")", ":", "\n", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "cuda", ")", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "cuda", ">=", "0", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "self", ".", "actor", "=", "Actor", "(", "state_dim", ",", "action_dim", ",", "max_action", ",", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "actor_target", "=", "copy", ".", "deepcopy", "(", "self", ".", "actor", ")", "\n", "self", ".", "actor_explore", "=", "copy", ".", "deepcopy", "(", "self", ".", "actor", ")", "\n", "self", ".", "actor_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "actor", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "self", ".", "critic", "=", "Critic", "(", "state_dim", ",", "action_dim", ",", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "critic_target", "=", "copy", ".", "deepcopy", "(", "self", ".", "critic", ")", "\n", "self", ".", "critic_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "self", ".", "max_action", "=", "max_action", "\n", "self", ".", "discount", "=", "discount", "\n", "self", ".", "tau", "=", "tau", "\n", "self", ".", "policy_noise", "=", "policy_noise", "\n", "self", ".", "noise_clip", "=", "noise_clip", "\n", "self", ".", "policy_freq", "=", "policy_freq", "\n", "\n", "self", ".", "total_it", "=", "0", "\n", "\n", "self", ".", "parameter_noise_mean", "=", "parameter_noise_mean", "\n", "self", ".", "parameter_noise_std", "=", "parameter_noise_std", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.TD3.hard_update": [[105, 108], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "methods", ["None"], ["", "def", "hard_update", "(", "self", ",", "target", ",", "source", ")", ":", "\n", "\t\t", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "\t\t\t", "target_param", ".", "data", ".", "copy_", "(", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.TD3.select_action": [[109, 112], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "TD3.TD3.actor().cpu().data.numpy().flatten", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "TD3.TD3.actor().cpu().data.numpy", "torch.FloatTensor().to.reshape", "torch.FloatTensor().to.reshape", "torch.FloatTensor().to.reshape", "TD3.TD3.actor().cpu", "TD3.TD3.actor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "", "def", "select_action", "(", "self", ",", "state", ")", ":", "\n", "\t\t", "state", "=", "torch", ".", "FloatTensor", "(", "state", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "self", ".", "actor", "(", "state", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.TD3.select_exploration_action": [[113, 116], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "TD3.TD3.actor_explore().cpu().data.numpy().flatten", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "TD3.TD3.actor_explore().cpu().data.numpy", "torch.FloatTensor().to.reshape", "torch.FloatTensor().to.reshape", "torch.FloatTensor().to.reshape", "TD3.TD3.actor_explore().cpu", "TD3.TD3.actor_explore"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "def", "select_exploration_action", "(", "self", ",", "state", ")", ":", "\n", "\t\t", "state", "=", "torch", ".", "FloatTensor", "(", "state", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "self", ".", "actor_explore", "(", "state", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.TD3.inject_parameter_noise": [[117, 122], ["torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "TD3.TD3.hard_update", "TD3.TD3.actor_explore.parameters", "torch.distributions.normal.Normal.sample().to", "torch.distributions.normal.Normal.sample().to", "torch.distributions.normal.Normal.sample().to", "torch.distributions.normal.Normal.sample", "torch.distributions.normal.Normal.sample", "torch.distributions.normal.Normal.sample"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.hard_update", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample"], ["", "def", "inject_parameter_noise", "(", "self", ")", ":", "\n", "\t\t", "parameter_explore_noise", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "loc", "=", "self", ".", "parameter_noise_mean", ",", "scale", "=", "self", ".", "parameter_noise_std", ")", "\n", "self", ".", "hard_update", "(", "self", ".", "actor_explore", ",", "self", ".", "actor", ")", "\n", "for", "param", "in", "self", ".", "actor_explore", ".", "parameters", "(", ")", ":", "\n", "\t\t\t", "param", ".", "data", "+=", "parameter_explore_noise", ".", "sample", "(", "param", ".", "data", ".", "shape", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.TD3.train": [[123, 172], ["replay_buffer.sample", "TD3.TD3.critic", "TD3.TD3.critic_optimizer.zero_grad", "critic_loss.backward", "TD3.TD3.critic_optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "TD3.TD3.critic_target", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "TD3.TD3.actor_optimizer.zero_grad", "actor_loss.backward", "TD3.TD3.actor_optimizer.step", "zip", "zip", "TD3.TD3.critic.Q1().mean", "TD3.TD3.critic.parameters", "TD3.TD3.critic_target.parameters", "target_param.data.copy_", "TD3.TD3.actor.parameters", "TD3.TD3.actor_target.parameters", "target_param.data.copy_", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "TD3.TD3.actor_target", "TD3.TD3.critic.Q1", "TD3.TD3.actor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.Critic.Q1"], ["", "", "def", "train", "(", "self", ",", "replay_buffer", ",", "batch_size", "=", "100", ")", ":", "\n", "\t\t", "self", ".", "total_it", "+=", "1", "\n", "\n", "# Sample replay buffer ", "\n", "state", ",", "action", ",", "next_state", ",", "reward", ",", "not_done", "=", "replay_buffer", ".", "sample", "(", "batch_size", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Select action according to policy and add clipped noise", "\n", "\t\t\t", "noise", "=", "(", "\n", "torch", ".", "randn_like", "(", "action", ")", "*", "self", ".", "policy_noise", "\n", ")", ".", "clamp", "(", "-", "self", ".", "noise_clip", ",", "self", ".", "noise_clip", ")", "\n", "\n", "next_action", "=", "(", "\n", "self", ".", "actor_target", "(", "next_state", ")", "+", "noise", "\n", ")", ".", "clamp", "(", "-", "self", ".", "max_action", ",", "self", ".", "max_action", ")", "\n", "\n", "# Compute the target Q value", "\n", "target_Q1", ",", "target_Q2", "=", "self", ".", "critic_target", "(", "next_state", ",", "next_action", ")", "\n", "target_Q", "=", "torch", ".", "min", "(", "target_Q1", ",", "target_Q2", ")", "\n", "target_Q", "=", "reward", "+", "not_done", "*", "self", ".", "discount", "*", "target_Q", "\n", "\n", "# Get current Q estimates", "\n", "", "current_Q1", ",", "current_Q2", "=", "self", ".", "critic", "(", "state", ",", "action", ")", "\n", "\n", "# Compute critic loss", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "current_Q1", ",", "target_Q", ")", "+", "F", ".", "mse_loss", "(", "current_Q2", ",", "target_Q", ")", "\n", "\n", "# Optimize the critic", "\n", "self", ".", "critic_optimizer", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_optimizer", ".", "step", "(", ")", "\n", "\n", "# Delayed policy updates", "\n", "if", "self", ".", "total_it", "%", "self", ".", "policy_freq", "==", "0", ":", "\n", "\n", "# Compute actor losse", "\n", "\t\t\t", "actor_loss", "=", "-", "self", ".", "critic", ".", "Q1", "(", "state", ",", "self", ".", "actor", "(", "state", ")", ")", ".", "mean", "(", ")", "\n", "\n", "# Optimize the actor ", "\n", "self", ".", "actor_optimizer", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "self", ".", "actor_optimizer", ".", "step", "(", ")", "\n", "\n", "# Update the frozen target models", "\n", "for", "param", ",", "target_param", "in", "zip", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "self", ".", "critic_target", ".", "parameters", "(", ")", ")", ":", "\n", "\t\t\t\t", "target_param", ".", "data", ".", "copy_", "(", "self", ".", "tau", "*", "param", ".", "data", "+", "(", "1", "-", "self", ".", "tau", ")", "*", "target_param", ".", "data", ")", "\n", "\n", "", "for", "param", ",", "target_param", "in", "zip", "(", "self", ".", "actor", ".", "parameters", "(", ")", ",", "self", ".", "actor_target", ".", "parameters", "(", ")", ")", ":", "\n", "\t\t\t\t", "target_param", ".", "data", ".", "copy_", "(", "self", ".", "tau", "*", "param", ".", "data", "+", "(", "1", "-", "self", ".", "tau", ")", "*", "target_param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.TD3.TD3.save_model": [[174, 182], ["print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "TD3.TD3.actor.state_dict", "TD3.TD3.critic.state_dict"], "methods", ["None"], ["", "", "", "def", "save_model", "(", "self", ",", "save_path", "=", "None", ",", "env_name", "=", "None", ",", "suffix", "=", "None", ")", ":", "\n", "\t\t", "if", "save_path", "is", "None", ":", "\n", "\t\t    ", "save_path", "=", "'./models/'", "\n", "", "actor_path", "=", "'{}actor_{}_{}'", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "critic_path", "=", "\"{}critic_{}_{}\"", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "print", "(", "'Saving models to {}, {}'", ".", "format", "(", "actor_path", ",", "critic_path", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "actor", ".", "state_dict", "(", ")", ",", "actor_path", ")", "\n", "torch", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "critic_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.replay_memory.ReplayBuffer.__init__": [[6, 18], ["int", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "state_dim", ",", "action_dim", ",", "max_size", "=", "int", "(", "1e6", ")", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "ptr", "=", "0", "\n", "self", ".", "size", "=", "0", "\n", "\n", "self", ".", "state", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "state_dim", ")", ")", "\n", "self", ".", "action", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "action_dim", ")", ")", "\n", "self", ".", "next_state", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "state_dim", ")", ")", "\n", "self", ".", "reward", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "1", ")", ")", "\n", "self", ".", "not_done", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "1", ")", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.replay_memory.ReplayBuffer.add": [[19, 28], ["min"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "state", ",", "action", ",", "next_state", ",", "reward", ",", "done", ")", ":", "\n", "\t\t", "self", ".", "state", "[", "self", ".", "ptr", "]", "=", "state", "\n", "self", ".", "action", "[", "self", ".", "ptr", "]", "=", "action", "\n", "self", ".", "next_state", "[", "self", ".", "ptr", "]", "=", "next_state", "\n", "self", ".", "reward", "[", "self", ".", "ptr", "]", "=", "reward", "\n", "self", ".", "not_done", "[", "self", ".", "ptr", "]", "=", "1.", "-", "done", "\n", "\n", "self", ".", "ptr", "=", "(", "self", ".", "ptr", "+", "1", ")", "%", "self", ".", "max_size", "\n", "self", ".", "size", "=", "min", "(", "self", ".", "size", "+", "1", ",", "self", ".", "max_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.replay_memory.ReplayBuffer.sample": [[30, 39], ["numpy.random.randint", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "\t\t", "ind", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "size", ",", "size", "=", "batch_size", ")", "\n", "\n", "return", "(", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "state", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "action", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "next_state", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "reward", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "not_done", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.sacmeta.SAC_META.__init__": [[10, 58], ["modelmeta.MetaQNetwork().to", "torch.optim.Adam", "torch.optim.Adam", "modelmeta.MetaQNetwork().to", "utils.hard_update", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.optim.Adam", "torch.optim.Adam", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "modelmeta.GaussianPolicy().to", "utils.RMSprop", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "sacmeta.SAC_META.critic.parameters", "modelmeta.MetaQNetwork().to", "torch.optim.Adam", "torch.optim.Adam", "modelmeta.ValueNetwork().to", "torch.optim.Adam", "torch.optim.Adam", "modelmeta.ValueNetwork().to", "utils.hard_update", "sacmeta.SAC_META.policy.parameters", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "modelmeta.MetaQNetwork", "modelmeta.MetaQNetwork", "sacmeta.SAC_META.meta_critic.parameters", "sacmeta.SAC_META.meta_v.parameters", "float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "modelmeta.GaussianPolicy", "float", "str", "modelmeta.MetaQNetwork", "modelmeta.ValueNetwork", "modelmeta.ValueNetwork"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.hard_update", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.hard_update"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "action_space", ",", "config", ")", ":", "\n", "\n", "        ", "self", ".", "gamma", "=", "config", "[", "'gamma'", "]", "\n", "self", ".", "tau", "=", "config", "[", "'tau'", "]", "\n", "\n", "self", ".", "target_update_interval", "=", "config", "[", "'target_update_interval'", "]", "\n", "self", ".", "alpha_embedding", "=", "config", "[", "'alpha_embedding'", "]", "\n", "self", ".", "meta_Q", "=", "config", "[", "'meta_Q'", "]", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "config", "[", "'cuda'", "]", ")", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "config", "[", "'cuda'", "]", ">=", "0", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "self", ".", "critic", "=", "MetaQNetwork", "(", "num_inputs", "+", "1", "if", "self", ".", "alpha_embedding", "else", "num_inputs", ",", "\n", "action_space", ".", "shape", "[", "0", "]", ",", "config", "[", "'hidden_size'", "]", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "critic_optim", "=", "Adam", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n", "self", ".", "critic_target", "=", "MetaQNetwork", "(", "num_inputs", "+", "1", "if", "self", ".", "alpha_embedding", "else", "num_inputs", ",", "\n", "action_space", ".", "shape", "[", "0", "]", ",", "config", "[", "'hidden_size'", "]", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "hard_update", "(", "self", ".", "critic_target", ",", "self", ".", "critic", ")", "\n", "\n", "if", "self", ".", "meta_Q", ":", "\n", "            ", "self", ".", "meta_critic", "=", "MetaQNetwork", "(", "num_inputs", ",", "action_space", ".", "shape", "[", "0", "]", ",", "config", "[", "'hidden_size'", "]", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "meta_critic_optim", "=", "Adam", "(", "self", ".", "meta_critic", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n", "self", ".", "meta_v", "=", "ValueNetwork", "(", "num_inputs", ",", "config", "[", "'hidden_size'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "meta_v_optim", "=", "Adam", "(", "self", ".", "meta_v", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n", "self", ".", "meta_v_target", "=", "ValueNetwork", "(", "num_inputs", ",", "config", "[", "'hidden_size'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "hard_update", "(", "self", ".", "meta_v_target", ",", "self", ".", "meta_v", ")", "\n", "\n", "", "self", ".", "meta_train_interval", "=", "config", "[", "'meta_train_interval'", "]", "\n", "self", ".", "meta_grad_decay_coef", "=", "config", "[", "'meta_grad_decay_coef'", "]", "\n", "\n", "self", ".", "log_alpha", "=", "torch", ".", "tensor", "(", "[", "config", "[", "'log_alpha_max'", "]", "]", ",", "dtype", "=", "torch", ".", "float", ",", "requires_grad", "=", "True", ",", "device", "=", "self", ".", "device", ")", "\n", "assert", "config", "[", "'alpha_optim'", "]", "==", "'adam'", "\n", "self", ".", "alpha_optim", "=", "Adam", "(", "[", "self", ".", "log_alpha", "]", ",", "lr", "=", "float", "(", "config", "[", "'meta_lr'", "]", ")", ")", "\n", "\n", "self", ".", "history_meta_grad", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "policy", "=", "GaussianPolicy", "(", "num_inputs", "+", "1", "if", "self", ".", "alpha_embedding", "else", "num_inputs", ",", "\n", "action_space", ".", "shape", "[", "0", "]", ",", "config", "[", "'hidden_size'", "]", ",", "action_space", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "policy_optim", "=", "RMSprop", "(", "self", ".", "policy", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ",", "eps", "=", "float", "(", "config", "[", "'rmsprop_eps'", "]", ")", ")", "\n", "\n", "self", ".", "meta_clip_norm", "=", "config", "[", "'clip_grad_norm'", "]", "\n", "self", ".", "log_alpha_max", "=", "config", "[", "'log_alpha_max'", "]", "\n", "\n", "self", ".", "meta_obj_s0", "=", "config", "[", "'meta_obj_s0'", "]", "\n", "\n", "self", ".", "resample", "=", "config", "[", "'resample'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.sacmeta.SAC_META.select_action": [[59, 77], ["torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "sacmeta.SAC_META.policy.sample", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to.repeat", "torch.FloatTensor().to.repeat", "sacmeta.SAC_META.policy.sample", "action.detach().cpu().numpy", "log_prob.detach().cpu().numpy", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "sacmeta.SAC_META.policy.sample", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "action.detach().cpu", "log_prob.detach().cpu", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "action.detach", "log_prob.detach"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample"], ["", "def", "select_action", "(", "self", ",", "state", ",", "eval", "=", "False", ",", "mode", "=", "None", ")", ":", "\n", "        ", "state", "=", "torch", ".", "FloatTensor", "(", "state", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "eval", "==", "False", ":", "\n", "            ", "alpha", "=", "torch", ".", "exp", "(", "self", ".", "log_alpha", ")", ".", "unsqueeze", "(", "0", ")", "\n", "action", ",", "log_prob", ",", "_", "=", "self", ".", "policy", ".", "sample", "(", "state", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "", "else", ":", "\n", "# zero: use alpha as zero.", "\n", "# running: use alpha as learning alpha.", "\n", "            ", "if", "mode", "==", "'zero'", ":", "\n", "                ", "alpha_", "=", "torch", ".", "FloatTensor", "(", "[", "0", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "alpha", "=", "alpha_", ".", "repeat", "(", "(", "len", "(", "state", ")", ",", "1", ")", ")", "\n", "_", ",", "log_prob", ",", "action", "=", "self", ".", "policy", ".", "sample", "(", "state", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "", "elif", "mode", "==", "'running'", ":", "\n", "                ", "alpha", "=", "torch", ".", "exp", "(", "self", ".", "log_alpha", ")", ".", "unsqueeze", "(", "0", ")", "\n", "_", ",", "log_prob", ",", "action", "=", "self", ".", "policy", ".", "sample", "(", "state", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "\n", "", "", "return", "action", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", ",", "log_prob", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.sacmeta.SAC_META.update_parameters": [[78, 226], ["memory.sample", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "kl_memory.sample", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "sacmeta.SAC_META.critic", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "sacmeta.SAC_META.critic_optim.zero_grad", "torch.mse_loss.backward", "sacmeta.SAC_META.critic_optim.step", "sacmeta.SAC_META.critic_optim.zero_grad", "torch.mse_loss.backward", "sacmeta.SAC_META.critic_optim.step", "sacmeta.SAC_META.policy.sample", "sacmeta.SAC_META.critic", "torch.min", "torch.min", "torch.min", "torch.min", "sacmeta.SAC_META.policy_optim.zero_grad", "policy_loss.backward", "sacmeta.SAC_META.policy_optim.step", "numpy.array", "torch.exp().repeat", "torch.exp().repeat", "torch.exp().repeat", "torch.exp().repeat", "sacmeta.SAC_META.policy.sample", "sacmeta.SAC_META.critic", "torch.min", "torch.min", "torch.min", "torch.min", "sacmeta.SAC_META.policy_optim.zero_grad", "policy_loss.backward", "sacmeta.SAC_META.simulate_rmsprop", "modelmeta.NewGaussianPolicy().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to.repeat", "torch.FloatTensor().to.repeat", "sacmeta.SAC_META.alpha_optim.zero_grad", "new_pg_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "sacmeta.SAC_META.alpha_optim.step", "sacmeta.SAC_META.log_alpha.data.clamp_", "memory.sample", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.exp().repeat", "torch.exp().repeat", "torch.exp().repeat", "torch.exp().repeat", "sacmeta.SAC_META.policy.sample", "sacmeta.SAC_META.critic_target", "torch.min", "torch.min", "torch.min", "torch.min", "utils.soft_update", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to.repeat", "torch.FloatTensor().to.repeat", "sacmeta.SAC_META.meta_critic", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "sacmeta.SAC_META.meta_critic_optim.zero_grad", "torch.mse_loss.backward", "sacmeta.SAC_META.meta_critic_optim.step", "sacmeta.SAC_META.meta_critic_optim.zero_grad", "torch.mse_loss.backward", "sacmeta.SAC_META.meta_critic_optim.step", "sacmeta.SAC_META.meta_v", "torch.mse_loss", "torch.mse_loss", "sacmeta.SAC_META.meta_v_optim.zero_grad", "torch.mse_loss.backward", "sacmeta.SAC_META.meta_v_optim.step", "torch.FloatTensor().to.repeat.detach", "torch.FloatTensor().to.repeat.detach", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "modelmeta.NewGaussianPolicy().to.sample", "modelmeta.NewGaussianPolicy().to.sample", "sacmeta.SAC_META.critic", "torch.min", "torch.min", "torch.min", "torch.min", "utils.soft_update", "sacmeta.SAC_META.log_alpha.item", "torch.mse_loss.item", "torch.mse_loss.item", "policy_loss.item", "new_pg_loss.item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sacmeta.SAC_META.meta_v_target", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "len", "modelmeta.NewGaussianPolicy", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "sacmeta.SAC_META.meta_critic", "sacmeta.SAC_META.meta_v().detach", "sacmeta.SAC_META.critic", "torch.min.mean", "torch.min.mean", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "len", "log_pi.mean().item", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "sacmeta.SAC_META.meta_v", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "log_pi.mean", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.sacmeta.SAC_META.simulate_rmsprop", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.soft_update", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.soft_update", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "def", "update_parameters", "(", "self", ",", "memory", ",", "kl_memory", ",", "batch_size", ",", "updates", ",", "s0_list", "=", "None", ")", ":", "\n", "\n", "# Sample a batch from memory, for SAC update", "\n", "        ", "state_batch", ",", "action_batch", ",", "log_prob_batch", ",", "reward_batch", ",", "next_state_batch", ",", "mask_batch", "=", "memory", ".", "sample", "(", "batch_size", "=", "batch_size", ")", "\n", "state_batch", "=", "torch", ".", "FloatTensor", "(", "state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "next_state_batch", "=", "torch", ".", "FloatTensor", "(", "next_state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "action_batch", "=", "torch", ".", "FloatTensor", "(", "action_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "log_prob_batch", "=", "torch", ".", "FloatTensor", "(", "log_prob_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "reward_batch", "=", "torch", ".", "FloatTensor", "(", "reward_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "mask_batch", "=", "torch", ".", "FloatTensor", "(", "mask_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "kl_state_batch", ",", "kl_action_batch", ",", "kl_log_prob_batch", ",", "kl_reward_batch", ",", "kl_next_state_batch", ",", "kl_mask_batch", "=", "kl_memory", ".", "sample", "(", "batch_size", "=", "batch_size", ")", "\n", "kl_state_batch", "=", "torch", ".", "FloatTensor", "(", "kl_state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "kl_next_state_batch", "=", "torch", ".", "FloatTensor", "(", "kl_next_state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "kl_action_batch", "=", "torch", ".", "FloatTensor", "(", "kl_action_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "kl_log_prob_batch", "=", "torch", ".", "FloatTensor", "(", "kl_log_prob_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "kl_reward_batch", "=", "torch", ".", "FloatTensor", "(", "kl_reward_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "kl_mask_batch", "=", "torch", ".", "FloatTensor", "(", "kl_mask_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "if", "updates", "%", "self", ".", "meta_train_interval", "==", "0", ":", "\n", "            ", "if", "self", ".", "meta_Q", ":", "\n", "                ", "alpha_", "=", "torch", ".", "FloatTensor", "(", "[", "0", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "alpha", "=", "alpha_", ".", "repeat", "(", "(", "len", "(", "kl_next_state_batch", ")", ",", "1", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "next_v", "=", "self", ".", "meta_v_target", "(", "kl_next_state_batch", ")", "\n", "v_target", "=", "kl_reward_batch", "+", "kl_mask_batch", "*", "self", ".", "gamma", "*", "next_v", "\n", "\n", "", "qf1", ",", "qf2", "=", "self", ".", "meta_critic", "(", "kl_state_batch", ",", "kl_action_batch", ",", "alpha", ",", "False", ")", "# Two Q-functions to mitigate positive bias in the policy improvement step", "\n", "qf1_loss", "=", "F", ".", "mse_loss", "(", "qf1", ",", "v_target", ")", "# JQ = \ud835\udd3c(st,at)~D[0.5(Q1(st,at) - r(st,at) - \u03b3(\ud835\udd3cst+1~p[V(st+1)]))^2]", "\n", "qf2_loss", "=", "F", ".", "mse_loss", "(", "qf2", ",", "v_target", ")", "# JQ = \ud835\udd3c(st,at)~D[0.5(Q1(st,at) - r(st,at) - \u03b3(\ud835\udd3cst+1~p[V(st+1)]))^2]", "\n", "\n", "self", ".", "meta_critic_optim", ".", "zero_grad", "(", ")", "\n", "qf1_loss", ".", "backward", "(", ")", "\n", "self", ".", "meta_critic_optim", ".", "step", "(", ")", "\n", "\n", "self", ".", "meta_critic_optim", ".", "zero_grad", "(", ")", "\n", "qf2_loss", ".", "backward", "(", ")", "\n", "self", ".", "meta_critic_optim", ".", "step", "(", ")", "\n", "\n", "v", "=", "self", ".", "meta_v", "(", "kl_state_batch", ")", "\n", "v_loss", "=", "F", ".", "mse_loss", "(", "v", ",", "v_target", ")", "\n", "self", ".", "meta_v_optim", ".", "zero_grad", "(", ")", "\n", "v_loss", ".", "backward", "(", ")", "\n", "self", ".", "meta_v_optim", ".", "step", "(", ")", "\n", "\n", "# compute the new policy loss with meta term", "\n", "", "alpha", "=", "torch", ".", "exp", "(", "self", ".", "log_alpha", ")", ".", "repeat", "(", "(", "len", "(", "next_state_batch", ")", ",", "1", ")", ")", "\n", "\n", "pi", ",", "log_pi", ",", "_", "=", "self", ".", "policy", ".", "sample", "(", "state_batch", ",", "alpha", ".", "detach", "(", ")", ",", "self", ".", "alpha_embedding", ")", "# policy needs to know alpha for sample", "\n", "qf1_pi", ",", "qf2_pi", "=", "self", ".", "critic", "(", "state_batch", ",", "pi", ",", "alpha", ".", "detach", "(", ")", ",", "self", ".", "alpha_embedding", ")", "# Q-value also needs to know alpha", "\n", "min_qf_pi", "=", "torch", ".", "min", "(", "qf1_pi", ",", "qf2_pi", ")", "\n", "policy_loss", "=", "(", "alpha", "*", "log_pi", "-", "min_qf_pi", ")", ".", "mean", "(", ")", "# J\u03c0 = \ud835\udd3cst\u223cD,\u03b5t\u223cN[\u03b1 * log\u03c0(f(\u03b5t;st)|st) \u2212 Q(st,f(\u03b5t;st))]", "\n", "\n", "self", ".", "policy_optim", ".", "zero_grad", "(", ")", "\n", "policy_loss", ".", "backward", "(", "create_graph", "=", "True", ")", "\n", "\n", "# simulate the rmsprop update procedure to get the new policy parameters", "\n", "new_policy_params", "=", "self", ".", "simulate_rmsprop", "(", "self", ".", "policy_optim", ")", "\n", "new_policy_net", "=", "NewGaussianPolicy", "(", "new_policy_params", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# evaluate the new policy using policy gradient objective", "\n", "alpha_", "=", "torch", ".", "FloatTensor", "(", "[", "0", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "alpha", "=", "alpha_", ".", "repeat", "(", "(", "len", "(", "next_state_batch", ")", ",", "1", ")", ")", "\n", "if", "self", ".", "meta_obj_s0", ":", "\n", "                ", "s0_batch", "=", "torch", ".", "FloatTensor", "(", "s0_list", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "a", ",", "log_pi", ",", "mean", "=", "new_policy_net", ".", "sample", "(", "s0_batch", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "if", "self", ".", "meta_Q", ":", "\n", "                    ", "qf1_pi", ",", "qf2_pi", "=", "self", ".", "meta_critic", "(", "s0_batch", ",", "a", ",", "alpha", ",", "False", ")", "\n", "v", "=", "self", ".", "meta_v", "(", "s0_batch", ")", ".", "detach", "(", ")", "\n", "adv", "=", "(", "torch", ".", "min", "(", "qf1_pi", ",", "qf2_pi", ")", "-", "v", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                    ", "qf1_pi", ",", "qf2_pi", "=", "self", ".", "critic", "(", "s0_batch", ",", "mean", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "_", ",", "log_pi", ",", "mean", "=", "new_policy_net", ".", "sample", "(", "state_batch", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "qf1_pi", ",", "qf2_pi", "=", "self", ".", "critic", "(", "state_batch", ",", "mean", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "\n", "", "if", "not", "self", ".", "meta_Q", ":", "\n", "                ", "min_qf_pi", "=", "torch", ".", "min", "(", "qf1_pi", ",", "qf2_pi", ")", "\n", "new_pg_loss", "=", "-", "min_qf_pi", ".", "mean", "(", ")", "# this is the loss for the meta module", "\n", "", "else", ":", "\n", "                ", "new_pg_loss", "=", "-", "(", "log_pi", "*", "adv", ")", ".", "mean", "(", ")", "\n", "\n", "", "self", ".", "alpha_optim", ".", "zero_grad", "(", ")", "\n", "new_pg_loss", ".", "backward", "(", ")", "\n", "\n", "### perform accumulation of the gradient on meta network", "\n", "self", ".", "log_alpha", ".", "grad", "+=", "self", ".", "history_meta_grad", "*", "self", ".", "meta_grad_decay_coef", "\n", "self", ".", "history_meta_grad", "=", "self", ".", "log_alpha", ".", "grad", ".", "data", "\n", "\n", "norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "log_alpha", ",", "self", ".", "meta_clip_norm", ")", "\n", "\n", "self", ".", "alpha_optim", ".", "step", "(", ")", "\n", "self", ".", "log_alpha", ".", "data", ".", "clamp_", "(", "max", "=", "self", ".", "log_alpha_max", ")", "\n", "\n", "# redo the real meta Q network update", "\n", "", "if", "self", ".", "resample", ":", "\n", "            ", "state_batch", ",", "action_batch", ",", "log_prob_batch", ",", "reward_batch", ",", "next_state_batch", ",", "mask_batch", "=", "memory", ".", "sample", "(", "batch_size", "=", "batch_size", ")", "\n", "state_batch", "=", "torch", ".", "FloatTensor", "(", "state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "next_state_batch", "=", "torch", ".", "FloatTensor", "(", "next_state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "action_batch", "=", "torch", ".", "FloatTensor", "(", "action_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "log_prob_batch", "=", "torch", ".", "FloatTensor", "(", "log_prob_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "reward_batch", "=", "torch", ".", "FloatTensor", "(", "reward_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "mask_batch", "=", "torch", ".", "FloatTensor", "(", "mask_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# compute new alpha ", "\n", "            ", "alpha", "=", "torch", ".", "exp", "(", "self", ".", "log_alpha", ")", ".", "repeat", "(", "(", "len", "(", "next_state_batch", ")", ",", "1", ")", ")", "\n", "\n", "next_state_action", ",", "next_state_log_pi", ",", "_", "=", "self", ".", "policy", ".", "sample", "(", "next_state_batch", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "qf1_next_target", ",", "qf2_next_target", "=", "self", ".", "critic_target", "(", "next_state_batch", ",", "next_state_action", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "min_qf_next_target_", "=", "torch", ".", "min", "(", "qf1_next_target", ",", "qf2_next_target", ")", "\n", "min_qf_next_target", "=", "min_qf_next_target_", "-", "alpha", "*", "next_state_log_pi", "\n", "next_q_value", "=", "reward_batch", "+", "mask_batch", "*", "self", ".", "gamma", "*", "(", "min_qf_next_target", ")", "\n", "\n", "", "qf1", ",", "qf2", "=", "self", ".", "critic", "(", "state_batch", ",", "action_batch", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "# Two Q-functions to mitigate positive bias in the policy improvement step", "\n", "qf1_loss", "=", "F", ".", "mse_loss", "(", "qf1", ",", "next_q_value", ")", "# JQ = \ud835\udd3c(st,at)~D[0.5(Q1(st,at) - r(st,at) - \u03b3(\ud835\udd3cst+1~p[V(st+1)]))^2]", "\n", "qf2_loss", "=", "F", ".", "mse_loss", "(", "qf2", ",", "next_q_value", ")", "# JQ = \ud835\udd3c(st,at)~D[0.5(Q1(st,at) - r(st,at) - \u03b3(\ud835\udd3cst+1~p[V(st+1)]))^2]", "\n", "\n", "self", ".", "critic_optim", ".", "zero_grad", "(", ")", "\n", "qf1_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_optim", ".", "step", "(", ")", "\n", "\n", "self", ".", "critic_optim", ".", "zero_grad", "(", ")", "\n", "qf2_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_optim", ".", "step", "(", ")", "\n", "\n", "# redo the real policy update, after the meta module is updated", "\n", "pi", ",", "log_pi", ",", "_", "=", "self", ".", "policy", ".", "sample", "(", "state_batch", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "\n", "qf1_pi", ",", "qf2_pi", "=", "self", ".", "critic", "(", "state_batch", ",", "pi", ",", "alpha", ",", "self", ".", "alpha_embedding", ")", "\n", "min_qf_pi", "=", "torch", ".", "min", "(", "qf1_pi", ",", "qf2_pi", ")", "\n", "\n", "policy_loss", "=", "(", "alpha", "*", "log_pi", "-", "min_qf_pi", ")", ".", "mean", "(", ")", "\n", "self", ".", "policy_optim", ".", "zero_grad", "(", ")", "\n", "policy_loss", ".", "backward", "(", ")", "\n", "self", ".", "policy_optim", ".", "step", "(", ")", "\n", "\n", "if", "updates", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "            ", "soft_update", "(", "self", ".", "critic_target", ",", "self", ".", "critic", ",", "self", ".", "tau", ")", "\n", "if", "self", ".", "meta_Q", ":", "\n", "                ", "soft_update", "(", "self", ".", "meta_v_target", ",", "self", ".", "meta_v", ",", "self", ".", "tau", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "[", "self", ".", "log_alpha", ".", "item", "(", ")", ",", "\n", "qf1_loss", ".", "item", "(", ")", ",", "qf2_loss", ".", "item", "(", ")", ",", "\n", "policy_loss", ".", "item", "(", ")", ",", "new_pg_loss", ".", "item", "(", ")", ",", "\n", "-", "log_pi", ".", "mean", "(", ")", ".", "item", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.sacmeta.SAC_META.save_model": [[228, 244], ["print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "sacmeta.SAC_META.policy.state_dict", "sacmeta.SAC_META.critic.state_dict", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "sacmeta.SAC_META.meta_v.state_dict", "sacmeta.SAC_META.meta_critic.state_dict"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "save_path", "=", "None", ",", "env_name", "=", "None", ",", "suffix", "=", "None", ")", ":", "\n", "        ", "if", "save_path", "is", "None", ":", "\n", "            ", "save_path", "=", "'./models/'", "\n", "\n", "", "actor_path", "=", "'{}actor_{}_{}'", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "critic_path", "=", "\"{}critic_{}_{}\"", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "print", "(", "'Saving models to {}, {}'", ".", "format", "(", "actor_path", ",", "critic_path", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "policy", ".", "state_dict", "(", ")", ",", "actor_path", ")", "\n", "torch", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "critic_path", ")", "\n", "\n", "if", "self", ".", "meta_Q", ":", "\n", "            ", "meta_v_path", "=", "'{}meta_v_{}_{}'", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "meta_q_path", "=", "\"{}meta_q_{}_{}\"", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "print", "(", "'Saving models to {}, {}'", ".", "format", "(", "meta_v_path", ",", "meta_q_path", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "meta_v", ".", "state_dict", "(", ")", ",", "meta_v_path", ")", "\n", "torch", ".", "save", "(", "self", ".", "meta_critic", ".", "state_dict", "(", ")", ",", "meta_q_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.sacmeta.SAC_META.simulate_rmsprop": [[245, 265], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_params.append", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "", "def", "simulate_rmsprop", "(", "self", ",", "optim", ")", ":", "\n", "        ", "new_params", "=", "[", "]", "\n", "for", "group", "in", "optim", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "state", "=", "optim", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'square_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "square_avg", "=", "state", "[", "'square_avg'", "]", "\n", "alpha", "=", "group", "[", "'alpha'", "]", "\n", "grad", "=", "p", ".", "grad", "\n", "square_avg", "=", "square_avg", "*", "alpha", "+", "(", "1", "-", "alpha", ")", "*", "torch", ".", "mul", "(", "grad", ",", "grad", ")", "\n", "avg", "=", "torch", ".", "sqrt", "(", "square_avg", "+", "group", "[", "'eps'", "]", ")", "\n", "new_param", "=", "p", "-", "group", "[", "'lr'", "]", "*", "grad", "/", "avg", "\n", "new_params", ".", "append", "(", "new_param", ")", "\n", "\n", "", "", "return", "new_params", "", "", "", ""]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.mainmeta.test": [[57, 81], ["range", "print", "print", "print", "env.reset", "agent.select_action", "env.step", "round"], "function", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.sac.SAC.select_action", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step"], ["def", "test", "(", "env", ",", "mode", ")", ":", "\n", "    ", "'''\n    mode='zero': use alpha = 0 in policy net.\n    mode='running': use alpha as meta alpha in policy net.\n    '''", "\n", "avg_reward", "=", "0.", "\n", "episodes", "=", "10", "\n", "for", "_", "in", "range", "(", "episodes", ")", ":", "\n", "        ", "state", "=", "env", ".", "reset", "(", ")", "\n", "episode_reward", "=", "0", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "            ", "action", ",", "_", "=", "agent", ".", "select_action", "(", "state", ",", "eval", "=", "True", ",", "mode", "=", "mode", ")", "\n", "\n", "next_state", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action", ")", "\n", "episode_reward", "+=", "reward", "\n", "\n", "state", "=", "next_state", "\n", "", "avg_reward", "+=", "episode_reward", "\n", "", "avg_reward", "/=", "episodes", "\n", "\n", "print", "(", "\"----------------------------------------\"", ")", "\n", "print", "(", "\"Test Episodes: {}, Avg. Reward: {} Mode: {}\"", ".", "format", "(", "episodes", ",", "round", "(", "avg_reward", ",", "2", ")", ",", "mode", ")", ")", "\n", "print", "(", "\"----------------------------------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemory.__init__": [[5, 9], ["None"], "methods", ["None"], ["class", "ReplayBuffer", "(", "object", ")", ":", "\n", "\t", "def", "__init__", "(", "self", ",", "state_dim", ",", "action_dim", ",", "max_size", "=", "int", "(", "1e6", ")", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "ptr", "=", "0", "\n", "self", ".", "size", "=", "0", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemory.push": [[10, 15], ["len", "replay_memory.ReplayMemory.buffer.append"], "methods", ["None"], ["\n", "self", ".", "state", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "state_dim", ")", ")", "\n", "self", ".", "action", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "action_dim", ")", ")", "\n", "self", ".", "next_state", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "state_dim", ")", ")", "\n", "self", ".", "reward", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "1", ")", ")", "\n", "self", ".", "not_done", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemory.sample": [[16, 20], ["random.sample", "map", "zip"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample"], ["\n", "self", ".", "device", "=", "device", "\n", "\n", "", "def", "add", "(", "self", ",", "state", ",", "action", ",", "next_state", ",", "reward", ",", "done", ")", ":", "\n", "\t\t", "self", ".", "state", "[", "self", ".", "ptr", "]", "=", "state", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemory.__len__": [[21, 23], ["len"], "methods", ["None"], ["self", ".", "action", "[", "self", ".", "ptr", "]", "=", "action", "\n", "self", ".", "next_state", "[", "self", ".", "ptr", "]", "=", "next_state", "\n", "self", ".", "reward", "[", "self", ".", "ptr", "]", "=", "reward", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemory.empty": [[24, 27], ["None"], "methods", ["None"], ["self", ".", "not_done", "[", "self", ".", "ptr", "]", "=", "1.", "-", "done", "\n", "\n", "self", ".", "ptr", "=", "(", "self", ".", "ptr", "+", "1", ")", "%", "self", ".", "max_size", "\n", "self", ".", "size", "=", "min", "(", "self", ".", "size", "+", "1", ",", "self", ".", "max_size", ")", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemory.marginal_states": [[28, 30], ["replay_memory.ReplayMemory.sample", "len"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample"], ["\n", "\n", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemoryKL.__init__": [[32, 36], ["None"], "methods", ["None"], ["\n", "return", "(", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "state", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "action", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "next_state", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemoryKL.push": [[37, 42], ["len", "replay_memory.ReplayMemoryKL.buffer.append"], "methods", ["None"], ["torch", ".", "FloatTensor", "(", "self", ".", "reward", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "self", ".", "not_done", "[", "ind", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemoryKL.sample": [[43, 47], ["random.sample", "map", "zip"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample"], []], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.replay_memory.ReplayMemoryKL.__len__": [[48, 50], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.ValueNetwork.__init__": [[18, 26], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "modelmeta.ValueNetwork.apply"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "hidden_dim", ")", ":", "\n", "        ", "super", "(", "ValueNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "num_inputs", ",", "hidden_dim", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.ValueNetwork.forward": [[27, 32], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "modelmeta.ValueNetwork.linear3", "modelmeta.ValueNetwork.linear1", "modelmeta.ValueNetwork.linear2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "linear1", "(", "state", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "linear2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "linear3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.MetaQNetwork.__init__": [[34, 48], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "modelmeta.MetaQNetwork.apply"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_actions", ",", "hidden_dim", ")", ":", "\n", "        ", "super", "(", "MetaQNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Q1 architecture", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "num_inputs", "+", "num_actions", ",", "hidden_dim", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n", "# Q2 architecture", "\n", "self", ".", "linear4", "=", "nn", ".", "Linear", "(", "num_inputs", "+", "num_actions", ",", "hidden_dim", ")", "\n", "self", ".", "linear5", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear6", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.MetaQNetwork.forward": [[49, 63], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "modelmeta.MetaQNetwork.linear3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "modelmeta.MetaQNetwork.linear6", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modelmeta.MetaQNetwork.linear1", "modelmeta.MetaQNetwork.linear2", "modelmeta.MetaQNetwork.linear4", "modelmeta.MetaQNetwork.linear5"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ",", "action", ",", "alpha", ",", "alpha_embedding", ")", ":", "\n", "        ", "if", "alpha_embedding", ":", "\n", "            ", "xu", "=", "torch", ".", "cat", "(", "[", "state", ",", "action", ",", "alpha", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "xu", "=", "torch", ".", "cat", "(", "[", "state", ",", "action", "]", ",", "1", ")", "\n", "", "x1", "=", "F", ".", "relu", "(", "self", ".", "linear1", "(", "xu", ")", ")", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "linear2", "(", "x1", ")", ")", "\n", "x1", "=", "self", ".", "linear3", "(", "x1", ")", "\n", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "linear4", "(", "xu", ")", ")", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "linear5", "(", "x2", ")", ")", "\n", "x2", "=", "self", ".", "linear6", "(", "x2", ")", "\n", "\n", "return", "x1", ",", "x2", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.NewGaussianPolicy.__init__": [[65, 85], ["torch.Module.__init__", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "policy_params", ",", "action_space", "=", "None", ")", ":", "\n", "        ", "super", "(", "NewGaussianPolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear1_weight", "=", "policy_params", "[", "0", "]", "\n", "self", ".", "linear1_bias", "=", "policy_params", "[", "1", "]", "\n", "self", ".", "linear2_weight", "=", "policy_params", "[", "2", "]", "\n", "self", ".", "linear2_bias", "=", "policy_params", "[", "3", "]", "\n", "self", ".", "mean_linear_weight", "=", "policy_params", "[", "4", "]", "\n", "self", ".", "mean_linear_bias", "=", "policy_params", "[", "5", "]", "\n", "self", ".", "log_std_linear_weight", "=", "policy_params", "[", "6", "]", "\n", "self", ".", "log_std_linear_bias", "=", "policy_params", "[", "7", "]", "\n", "assert", "len", "(", "policy_params", ")", "==", "8", "\n", "\n", "if", "action_space", "is", "None", ":", "\n", "            ", "self", ".", "action_scale", "=", "torch", ".", "tensor", "(", "1.", ")", "\n", "self", ".", "action_bias", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "action_scale", "=", "torch", ".", "FloatTensor", "(", "\n", "(", "action_space", ".", "high", "-", "action_space", ".", "low", ")", "/", "2.", ")", "\n", "self", ".", "action_bias", "=", "torch", ".", "FloatTensor", "(", "\n", "(", "action_space", ".", "high", "+", "action_space", ".", "low", ")", "/", "2.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.NewGaussianPolicy.forward": [[86, 97], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "state", ",", "alpha", ",", "alpha_embedding", ")", ":", "\n", "        ", "if", "alpha_embedding", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "[", "state", ",", "alpha", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "state", "\n", "", "x", "=", "F", ".", "relu", "(", "F", ".", "linear", "(", "x", ",", "self", ".", "linear1_weight", ",", "self", ".", "linear1_bias", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "F", ".", "linear", "(", "x", ",", "self", ".", "linear2_weight", ",", "self", ".", "linear2_bias", ")", ")", "\n", "mean", "=", "F", ".", "linear", "(", "x", ",", "self", ".", "mean_linear_weight", ",", "self", ".", "mean_linear_bias", ")", "\n", "log_std", "=", "F", ".", "linear", "(", "x", ",", "self", ".", "log_std_linear_weight", ",", "self", ".", "log_std_linear_bias", ")", "\n", "log_std", "=", "torch", ".", "clamp", "(", "log_std", ",", "min", "=", "LOG_SIG_MIN", ",", "max", "=", "LOG_SIG_MAX", ")", "\n", "return", "mean", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.NewGaussianPolicy.sample": [[98, 111], ["modelmeta.NewGaussianPolicy.forward", "log_std.exp", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "log_prob.sum.sum.sum", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.pow", "torch.tanh.pow", "torch.tanh.pow"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.forward"], ["", "def", "sample", "(", "self", ",", "state", ",", "alpha", ",", "alpha_embedding", ")", ":", "\n", "        ", "mean", ",", "log_std", "=", "self", ".", "forward", "(", "state", ",", "alpha", ",", "alpha_embedding", ")", "\n", "std", "=", "log_std", ".", "exp", "(", ")", "\n", "normal", "=", "Normal", "(", "mean", ",", "std", ")", "\n", "x_t", "=", "normal", ".", "rsample", "(", ")", "# for reparameterization trick (mean + std * N(0,1))", "\n", "y_t", "=", "torch", ".", "tanh", "(", "x_t", ")", "\n", "action", "=", "y_t", "*", "self", ".", "action_scale", "+", "self", ".", "action_bias", "\n", "log_prob", "=", "normal", ".", "log_prob", "(", "x_t", ")", "\n", "# Enforcing Action Bound", "\n", "log_prob", "-=", "torch", ".", "log", "(", "self", ".", "action_scale", "*", "(", "1", "-", "y_t", ".", "pow", "(", "2", ")", ")", "+", "epsilon", ")", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "mean", "=", "torch", ".", "tanh", "(", "mean", ")", "*", "self", ".", "action_scale", "+", "self", ".", "action_bias", "\n", "return", "action", ",", "log_prob", ",", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.NewGaussianPolicy.get_log_prob": [[112, 124], ["modelmeta.NewGaussianPolicy.forward", "log_std.exp", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "log_prob.sum.sum.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.clamp.pow", "torch.clamp.pow", "torch.clamp.pow"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.forward"], ["", "def", "get_log_prob", "(", "self", ",", "state", ",", "action", ",", "alpha", ",", "alpha_embedding", ")", ":", "\n", "        ", "mean", ",", "log_std", "=", "self", ".", "forward", "(", "state", ",", "alpha", ",", "alpha_embedding", ")", "\n", "std", "=", "log_std", ".", "exp", "(", ")", "\n", "normal", "=", "Normal", "(", "mean", ",", "std", ")", "\n", "y_t", "=", "(", "action", "-", "self", ".", "action_bias", ")", "/", "self", ".", "action_scale", "\n", "y_t", "=", "torch", ".", "clamp", "(", "y_t", ",", "min", "=", "-", "1", "+", "epsilon", ",", "max", "=", "1", "-", "epsilon", ")", "\n", "\n", "x_t", "=", "torch", ".", "log", "(", "(", "1", "+", "y_t", ")", "/", "(", "1", "-", "y_t", ")", ")", "/", "2", "\n", "log_prob", "=", "normal", ".", "log_prob", "(", "x_t", ")", "\n", "log_prob", "-=", "torch", ".", "log", "(", "self", ".", "action_scale", "*", "(", "1", "-", "y_t", ".", "pow", "(", "2", ")", ")", "+", "epsilon", ")", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.NewGaussianPolicy.to": [[125, 129], ["modelmeta.NewGaussianPolicy.action_scale.to", "modelmeta.NewGaussianPolicy.action_bias.to", "super().to"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "action_scale", "=", "self", ".", "action_scale", ".", "to", "(", "device", ")", "\n", "self", ".", "action_bias", "=", "self", ".", "action_bias", ".", "to", "(", "device", ")", "\n", "return", "super", "(", "NewGaussianPolicy", ",", "self", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.GaussianPolicy.__init__": [[132, 152], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "modelmeta.GaussianPolicy.apply", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_actions", ",", "hidden_dim", ",", "action_space", "=", "None", ")", ":", "\n", "        ", "super", "(", "GaussianPolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "num_inputs", ",", "hidden_dim", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "\n", "self", ".", "mean_linear", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "num_actions", ")", "\n", "self", ".", "log_std_linear", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "num_actions", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init_", ")", "\n", "\n", "# action rescaling", "\n", "if", "action_space", "is", "None", ":", "\n", "            ", "self", ".", "action_scale", "=", "torch", ".", "tensor", "(", "1.", ")", "\n", "self", ".", "action_bias", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "action_scale", "=", "torch", ".", "FloatTensor", "(", "\n", "(", "action_space", ".", "high", "-", "action_space", ".", "low", ")", "/", "2.", ")", "\n", "self", ".", "action_bias", "=", "torch", ".", "FloatTensor", "(", "\n", "(", "action_space", ".", "high", "+", "action_space", ".", "low", ")", "/", "2.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.GaussianPolicy.forward": [[153, 164], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "modelmeta.GaussianPolicy.mean_linear", "modelmeta.GaussianPolicy.log_std_linear", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modelmeta.GaussianPolicy.linear1", "modelmeta.GaussianPolicy.linear2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "state", ",", "alpha", ",", "alpha_embedding", ")", ":", "\n", "        ", "if", "alpha_embedding", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "[", "state", ",", "alpha", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "state", "\n", "", "x", "=", "F", ".", "relu", "(", "self", ".", "linear1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "linear2", "(", "x", ")", ")", "\n", "mean", "=", "self", ".", "mean_linear", "(", "x", ")", "\n", "log_std", "=", "self", ".", "log_std_linear", "(", "x", ")", "\n", "log_std", "=", "torch", ".", "clamp", "(", "log_std", ",", "min", "=", "LOG_SIG_MIN", ",", "max", "=", "LOG_SIG_MAX", ")", "\n", "return", "mean", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.GaussianPolicy.sample": [[165, 178], ["modelmeta.GaussianPolicy.forward", "log_std.exp", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "log_prob.sum.sum.sum", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.pow", "torch.tanh.pow", "torch.tanh.pow"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.forward"], ["", "def", "sample", "(", "self", ",", "state", ",", "alpha", ",", "alpha_embedding", ")", ":", "\n", "        ", "mean", ",", "log_std", "=", "self", ".", "forward", "(", "state", ",", "alpha", ",", "alpha_embedding", ")", "\n", "std", "=", "log_std", ".", "exp", "(", ")", "\n", "normal", "=", "Normal", "(", "mean", ",", "std", ")", "\n", "x_t", "=", "normal", ".", "rsample", "(", ")", "# for reparameterization trick (mean + std * N(0,1))", "\n", "y_t", "=", "torch", ".", "tanh", "(", "x_t", ")", "\n", "action", "=", "y_t", "*", "self", ".", "action_scale", "+", "self", ".", "action_bias", "\n", "log_prob", "=", "normal", ".", "log_prob", "(", "x_t", ")", "\n", "# Enforcing Action Bound", "\n", "log_prob", "-=", "torch", ".", "log", "(", "self", ".", "action_scale", "*", "(", "1", "-", "y_t", ".", "pow", "(", "2", ")", ")", "+", "epsilon", ")", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "mean", "=", "torch", ".", "tanh", "(", "mean", ")", "*", "self", ".", "action_scale", "+", "self", ".", "action_bias", "\n", "return", "action", ",", "log_prob", ",", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.GaussianPolicy.to": [[179, 183], ["modelmeta.GaussianPolicy.action_scale.to", "modelmeta.GaussianPolicy.action_bias.to", "super().to"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "action_scale", "=", "self", ".", "action_scale", ".", "to", "(", "device", ")", "\n", "self", ".", "action_bias", "=", "self", ".", "action_bias", ".", "to", "(", "device", ")", "\n", "return", "super", "(", "GaussianPolicy", ",", "self", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.GaussianPolicy.get_log_prob": [[184, 196], ["modelmeta.GaussianPolicy.forward", "log_std.exp", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "log_prob.sum.sum.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.clamp.pow", "torch.clamp.pow", "torch.clamp.pow"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.forward"], ["", "def", "get_log_prob", "(", "self", ",", "state", ",", "action", ",", "alpha", ",", "alpha_embedding", ")", ":", "\n", "        ", "mean", ",", "log_std", "=", "self", ".", "forward", "(", "state", ",", "alpha", ",", "alpha_embedding", ")", "\n", "std", "=", "log_std", ".", "exp", "(", ")", "\n", "normal", "=", "Normal", "(", "mean", ",", "std", ")", "\n", "y_t", "=", "(", "action", "-", "self", ".", "action_bias", ")", "/", "self", ".", "action_scale", "\n", "y_t", "=", "torch", ".", "clamp", "(", "y_t", ",", "min", "=", "-", "1", "+", "epsilon", ",", "max", "=", "1", "-", "epsilon", ")", "\n", "\n", "x_t", "=", "torch", ".", "log", "(", "(", "1", "+", "y_t", ")", "/", "(", "1", "-", "y_t", ")", ")", "/", "2", "\n", "log_prob", "=", "normal", ".", "log_prob", "(", "x_t", ")", "\n", "log_prob", "-=", "torch", ".", "log", "(", "self", ".", "action_scale", "*", "(", "1", "-", "y_t", ".", "pow", "(", "2", ")", ")", "+", "epsilon", ")", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.modelmeta.weights_init_": [[12, 16], ["isinstance", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "function", ["None"], ["def", "weights_init_", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ",", "gain", "=", "1", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.__init__": [[58, 72], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-2", ",", "alpha", "=", "0.99", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ",", "momentum", "=", "0", ",", "centered", "=", "False", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "momentum", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid momentum value: {}\"", ".", "format", "(", "momentum", ")", ")", "\n", "", "if", "not", "0.0", "<=", "weight_decay", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid weight_decay value: {}\"", ".", "format", "(", "weight_decay", ")", ")", "\n", "", "if", "not", "0.0", "<=", "alpha", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid alpha value: {}\"", ".", "format", "(", "alpha", ")", ")", "\n", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "momentum", "=", "momentum", ",", "alpha", "=", "alpha", ",", "eps", "=", "eps", ",", "centered", "=", "centered", ",", "weight_decay", "=", "weight_decay", ")", "\n", "super", "(", "RMSprop", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.__setstate__": [[73, 78], ["super().__setstate__", "group.setdefault", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "RMSprop", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'momentum'", ",", "0", ")", "\n", "group", ".", "setdefault", "(", "'centered'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step": [[79, 134], ["closure", "square_avg.mul_().addcmul_", "RuntimeError", "len", "torch.zeros_like", "grad.add.add.add", "grad_avg.mul_().add_", "square_avg.addcmul().sqrt().add_", "square_avg.add_().sqrt", "buf.mul_().addcdiv_", "p.data.add_", "p.data.addcdiv_", "torch.zeros_like", "torch.zeros_like", "square_avg.mul_", "grad_avg.mul_", "square_avg.addcmul().sqrt", "square_avg.add_", "buf.mul_", "square_avg.addcmul"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.TD3.replay_memory.ReplayBuffer.add"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'RMSprop does not support sparse gradients'", ")", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'square_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "if", "group", "[", "'momentum'", "]", ">", "0", ":", "\n", "                        ", "state", "[", "'momentum_buffer'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "", "if", "group", "[", "'centered'", "]", ":", "\n", "                        ", "state", "[", "'grad_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "", "square_avg", "=", "state", "[", "'square_avg'", "]", "\n", "alpha", "=", "group", "[", "'alpha'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "grad", "=", "grad", ".", "add", "(", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "square_avg", ".", "mul_", "(", "alpha", ")", ".", "addcmul_", "(", "1", "-", "alpha", ",", "grad", ",", "grad", ")", "\n", "\n", "if", "group", "[", "'centered'", "]", ":", "\n", "                    ", "grad_avg", "=", "state", "[", "'grad_avg'", "]", "\n", "grad_avg", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "1", "-", "alpha", ",", "grad", ")", "\n", "avg", "=", "square_avg", ".", "addcmul", "(", "-", "1", ",", "grad_avg", ",", "grad_avg", ")", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "", "else", ":", "\n", "# avg = square_avg.sqrt().add_(group['eps'])", "\n", "                    ", "avg", "=", "(", "square_avg", ".", "add_", "(", "group", "[", "'eps'", "]", ")", ")", ".", "sqrt", "(", ")", "\n", "\n", "", "if", "group", "[", "'momentum'", "]", ">", "0", ":", "\n", "                    ", "buf", "=", "state", "[", "'momentum_buffer'", "]", "\n", "buf", ".", "mul_", "(", "group", "[", "'momentum'", "]", ")", ".", "addcdiv_", "(", "grad", ",", "avg", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'lr'", "]", ",", "buf", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "addcdiv_", "(", "-", "group", "[", "'lr'", "]", ",", "grad", ",", "avg", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.create_log_gaussian": [[6, 13], ["math.log", "quadratic.sum", "log_z.sum", "log_std.exp"], "function", ["None"], ["def", "create_log_gaussian", "(", "mean", ",", "log_std", ",", "t", ")", ":", "\n", "    ", "quadratic", "=", "-", "(", "(", "0.5", "*", "(", "t", "-", "mean", ")", "/", "(", "log_std", ".", "exp", "(", ")", ")", ")", ".", "pow", "(", "2", ")", ")", "\n", "l", "=", "mean", ".", "shape", "\n", "log_z", "=", "log_std", "\n", "z", "=", "l", "[", "-", "1", "]", "*", "math", ".", "log", "(", "2", "*", "math", ".", "pi", ")", "\n", "log_p", "=", "quadratic", ".", "sum", "(", "dim", "=", "-", "1", ")", "-", "log_z", ".", "sum", "(", "dim", "=", "-", "1", ")", "-", "0.5", "*", "z", "\n", "return", "log_p", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.logsumexp": [[14, 23], ["torch.max", "inputs.view.view", "outputs.squeeze.squeeze"], "function", ["None"], ["", "def", "logsumexp", "(", "inputs", ",", "dim", "=", "None", ",", "keepdim", "=", "False", ")", ":", "\n", "    ", "if", "dim", "is", "None", ":", "\n", "        ", "inputs", "=", "inputs", ".", "view", "(", "-", "1", ")", "\n", "dim", "=", "0", "\n", "", "s", ",", "_", "=", "torch", ".", "max", "(", "inputs", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "outputs", "=", "s", "+", "(", "inputs", "-", "s", ")", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", ".", "log", "(", ")", "\n", "if", "not", "keepdim", ":", "\n", "        ", "outputs", "=", "outputs", ".", "squeeze", "(", "dim", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.soft_update": [[24, 27], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "function", ["None"], ["", "def", "soft_update", "(", "target", ",", "source", ",", "tau", ")", ":", "\n", "    ", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "target_param", ".", "data", ".", "copy_", "(", "target_param", ".", "data", "*", "(", "1.0", "-", "tau", ")", "+", "param", ".", "data", "*", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.hard_update": [[28, 31], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "function", ["None"], ["", "", "def", "hard_update", "(", "target", ",", "source", ")", ":", "\n", "    ", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "target_param", ".", "data", ".", "copy_", "(", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.sac.SAC.__init__": [[10, 37], ["model.QNetwork().to", "torch.optim.Adam", "torch.optim.Adam", "model.QNetwork().to", "utils.hard_update", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "sac.SAC.critic.parameters", "model.GaussianPolicy().to", "torch.optim.Adam", "torch.optim.Adam", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.QNetwork", "model.QNetwork", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.optim.Adam", "torch.optim.Adam", "sac.SAC.policy.parameters", "str", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "model.GaussianPolicy", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.hard_update", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "action_space", ",", "config", ")", ":", "\n", "\n", "        ", "self", ".", "gamma", "=", "config", "[", "'gamma'", "]", "\n", "self", ".", "tau", "=", "config", "[", "'tau'", "]", "\n", "self", ".", "alpha", "=", "config", "[", "'alpha'", "]", "\n", "\n", "self", ".", "policy_type", "=", "config", "[", "'policy'", "]", "\n", "self", ".", "target_update_interval", "=", "config", "[", "'target_update_interval'", "]", "\n", "self", ".", "automatic_entropy_tuning", "=", "config", "[", "'automatic_entropy_tuning'", "]", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "config", "[", "'cuda'", "]", ")", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "config", "[", "'cuda'", "]", ">=", "0", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "self", ".", "critic", "=", "QNetwork", "(", "num_inputs", ",", "action_space", ".", "shape", "[", "0", "]", ",", "config", "[", "'hidden_size'", "]", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "critic_optim", "=", "Adam", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n", "self", ".", "critic_target", "=", "QNetwork", "(", "num_inputs", ",", "action_space", ".", "shape", "[", "0", "]", ",", "config", "[", "'hidden_size'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "hard_update", "(", "self", ".", "critic_target", ",", "self", ".", "critic", ")", "\n", "\n", "if", "self", ".", "policy_type", "==", "\"Gaussian\"", ":", "\n", "# Target Entropy = \u2212dim(A) (e.g. , -6 for HalfCheetah-v2) as given in the paper", "\n", "            ", "if", "self", ".", "automatic_entropy_tuning", "==", "True", ":", "\n", "                ", "self", ".", "target_entropy", "=", "-", "torch", ".", "prod", "(", "torch", ".", "Tensor", "(", "action_space", ".", "shape", ")", ".", "to", "(", "self", ".", "device", ")", ")", ".", "item", "(", ")", "\n", "self", ".", "log_alpha", "=", "torch", ".", "zeros", "(", "1", ",", "requires_grad", "=", "True", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "alpha_optim", "=", "Adam", "(", "[", "self", ".", "log_alpha", "]", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n", "", "self", ".", "policy", "=", "GaussianPolicy", "(", "num_inputs", ",", "action_space", ".", "shape", "[", "0", "]", ",", "config", "[", "'hidden_size'", "]", ",", "action_space", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "policy_optim", "=", "Adam", "(", "self", ".", "policy", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.sac.SAC.select_action": [[38, 45], ["torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "sac.SAC.policy.sample", "sac.SAC.policy.sample", "action.detach().cpu().numpy", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "action.detach().cpu", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "action.detach"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "", "def", "select_action", "(", "self", ",", "state", ",", "eval", "=", "False", ")", ":", "\n", "        ", "state", "=", "torch", ".", "FloatTensor", "(", "state", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "if", "eval", "==", "False", ":", "\n", "            ", "action", ",", "_", ",", "_", "=", "self", ".", "policy", ".", "sample", "(", "state", ")", "\n", "", "else", ":", "\n", "            ", "_", ",", "_", ",", "action", "=", "self", ".", "policy", ".", "sample", "(", "state", ")", "\n", "", "return", "action", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.sac.SAC.update_parameters": [[46, 103], ["memory.sample", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "torch.FloatTensor().to().unsqueeze", "sac.SAC.critic", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "sac.SAC.policy.sample", "sac.SAC.critic", "torch.min", "torch.min", "torch.min", "torch.min", "sac.SAC.critic_optim.zero_grad", "torch.mse_loss.backward", "sac.SAC.critic_optim.step", "sac.SAC.critic_optim.zero_grad", "torch.mse_loss.backward", "sac.SAC.critic_optim.step", "sac.SAC.policy_optim.zero_grad", "policy_loss.backward", "sac.SAC.policy_optim.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sac.SAC.policy.sample", "sac.SAC.critic_target", "sac.SAC.alpha_optim.zero_grad", "torch.tensor().to.backward", "torch.tensor().to.backward", "sac.SAC.alpha_optim.step", "sac.SAC.log_alpha.exp", "sac.SAC.alpha.clone", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils.soft_update", "torch.mse_loss.item", "torch.mse_loss.item", "policy_loss.item", "torch.tensor().to.item", "torch.tensor().to.item", "torch.tensor.item", "torch.tensor.item", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.min", "torch.min", "torch.min", "torch.min", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.meta_sac.utils.RMSprop.step", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.soft_update", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "def", "update_parameters", "(", "self", ",", "memory", ",", "batch_size", ",", "updates", ")", ":", "\n", "# Sample a batch from memory", "\n", "        ", "state_batch", ",", "action_batch", ",", "reward_batch", ",", "next_state_batch", ",", "mask_batch", "=", "memory", ".", "sample", "(", "batch_size", "=", "batch_size", ")", "\n", "\n", "state_batch", "=", "torch", ".", "FloatTensor", "(", "state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "next_state_batch", "=", "torch", ".", "FloatTensor", "(", "next_state_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "action_batch", "=", "torch", ".", "FloatTensor", "(", "action_batch", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "reward_batch", "=", "torch", ".", "FloatTensor", "(", "reward_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "mask_batch", "=", "torch", ".", "FloatTensor", "(", "mask_batch", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "next_state_action", ",", "next_state_log_pi", ",", "_", "=", "self", ".", "policy", ".", "sample", "(", "next_state_batch", ")", "\n", "qf1_next_target", ",", "qf2_next_target", "=", "self", ".", "critic_target", "(", "next_state_batch", ",", "next_state_action", ")", "\n", "min_qf_next_target", "=", "torch", ".", "min", "(", "qf1_next_target", ",", "qf2_next_target", ")", "-", "self", ".", "alpha", "*", "next_state_log_pi", "\n", "next_q_value", "=", "reward_batch", "+", "mask_batch", "*", "self", ".", "gamma", "*", "(", "min_qf_next_target", ")", "\n", "\n", "", "qf1", ",", "qf2", "=", "self", ".", "critic", "(", "state_batch", ",", "action_batch", ")", "# Two Q-functions to mitigate positive bias in the policy improvement step", "\n", "qf1_loss", "=", "F", ".", "mse_loss", "(", "qf1", ",", "next_q_value", ")", "# JQ = \ud835\udd3c(st,at)~D[0.5(Q1(st,at) - r(st,at) - \u03b3(\ud835\udd3cst+1~p[V(st+1)]))^2]", "\n", "qf2_loss", "=", "F", ".", "mse_loss", "(", "qf2", ",", "next_q_value", ")", "# JQ = \ud835\udd3c(st,at)~D[0.5(Q1(st,at) - r(st,at) - \u03b3(\ud835\udd3cst+1~p[V(st+1)]))^2]", "\n", "\n", "pi", ",", "log_pi", ",", "_", "=", "self", ".", "policy", ".", "sample", "(", "state_batch", ")", "\n", "\n", "qf1_pi", ",", "qf2_pi", "=", "self", ".", "critic", "(", "state_batch", ",", "pi", ")", "\n", "min_qf_pi", "=", "torch", ".", "min", "(", "qf1_pi", ",", "qf2_pi", ")", "\n", "\n", "policy_loss", "=", "(", "(", "self", ".", "alpha", "*", "log_pi", ")", "-", "min_qf_pi", ")", ".", "mean", "(", ")", "# J\u03c0 = \ud835\udd3cst\u223cD,\u03b5t\u223cN[\u03b1 * log\u03c0(f(\u03b5t;st)|st) \u2212 Q(st,f(\u03b5t;st))]", "\n", "\n", "self", ".", "critic_optim", ".", "zero_grad", "(", ")", "\n", "qf1_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_optim", ".", "step", "(", ")", "\n", "\n", "self", ".", "critic_optim", ".", "zero_grad", "(", ")", "\n", "qf2_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_optim", ".", "step", "(", ")", "\n", "\n", "self", ".", "policy_optim", ".", "zero_grad", "(", ")", "\n", "policy_loss", ".", "backward", "(", ")", "\n", "self", ".", "policy_optim", ".", "step", "(", ")", "\n", "\n", "if", "self", ".", "automatic_entropy_tuning", ":", "\n", "            ", "alpha_loss", "=", "-", "(", "self", ".", "log_alpha", "*", "(", "log_pi", "+", "self", ".", "target_entropy", ")", ".", "detach", "(", ")", ")", ".", "mean", "(", ")", "\n", "\n", "self", ".", "alpha_optim", ".", "zero_grad", "(", ")", "\n", "alpha_loss", ".", "backward", "(", ")", "\n", "self", ".", "alpha_optim", ".", "step", "(", ")", "\n", "\n", "self", ".", "alpha", "=", "self", ".", "log_alpha", ".", "exp", "(", ")", "\n", "alpha_tlogs", "=", "self", ".", "alpha", ".", "clone", "(", ")", "# For TensorboardX logs", "\n", "", "else", ":", "\n", "            ", "alpha_loss", "=", "torch", ".", "tensor", "(", "0.", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "alpha_tlogs", "=", "torch", ".", "tensor", "(", "self", ".", "alpha", ")", "# For TensorboardX logs", "\n", "\n", "\n", "", "if", "updates", "%", "self", ".", "target_update_interval", "==", "0", ":", "\n", "            ", "soft_update", "(", "self", ".", "critic_target", ",", "self", ".", "critic", ",", "self", ".", "tau", ")", "\n", "\n", "", "return", "qf1_loss", ".", "item", "(", ")", ",", "qf2_loss", ".", "item", "(", ")", ",", "policy_loss", ".", "item", "(", ")", ",", "alpha_loss", ".", "item", "(", ")", ",", "alpha_tlogs", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.sac.SAC.save_model": [[105, 114], ["print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "sac.SAC.policy.state_dict", "sac.SAC.critic.state_dict"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "save_path", "=", "None", ",", "env_name", "=", "None", ",", "suffix", "=", "None", ")", ":", "\n", "        ", "if", "save_path", "is", "None", ":", "\n", "            ", "save_path", "=", "'./models/'", "\n", "\n", "", "actor_path", "=", "'{}actor_{}_{}'", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "critic_path", "=", "\"{}critic_{}_{}\"", ".", "format", "(", "save_path", ",", "env_name", ",", "suffix", ")", "\n", "print", "(", "'Saving models to {} and {}'", ".", "format", "(", "actor_path", ",", "critic_path", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "policy", ".", "state_dict", "(", ")", ",", "actor_path", ")", "\n", "torch", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "critic_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.replay_memory.ReplayMemory.__init__": [[5, 9], ["None"], "methods", ["None"], ["class", "ReplayBuffer", "(", "object", ")", ":", "\n", "\t", "def", "__init__", "(", "self", ",", "state_dim", ",", "action_dim", ",", "max_size", "=", "int", "(", "1e6", ")", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "ptr", "=", "0", "\n", "self", ".", "size", "=", "0", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.replay_memory.ReplayMemory.push": [[10, 15], ["len", "replay_memory.ReplayMemory.buffer.append"], "methods", ["None"], ["\n", "self", ".", "state", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "state_dim", ")", ")", "\n", "self", ".", "action", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "action_dim", ")", ")", "\n", "self", ".", "next_state", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "state_dim", ")", ")", "\n", "self", ".", "reward", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "1", ")", ")", "\n", "self", ".", "not_done", "=", "np", ".", "zeros", "(", "(", "max_size", ",", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.replay_memory.ReplayMemory.sample": [[16, 20], ["random.sample", "map", "zip"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample"], ["\n", "self", ".", "device", "=", "device", "\n", "\n", "", "def", "add", "(", "self", ",", "state", ",", "action", ",", "next_state", ",", "reward", ",", "done", ")", ":", "\n", "\t\t", "self", ".", "state", "[", "self", ".", "ptr", "]", "=", "state", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.replay_memory.ReplayMemory.__len__": [[21, 23], ["len"], "methods", ["None"], ["self", ".", "action", "[", "self", ".", "ptr", "]", "=", "action", "\n", "self", ".", "next_state", "[", "self", ".", "ptr", "]", "=", "next_state", "\n", "self", ".", "reward", "[", "self", ".", "ptr", "]", "=", "reward", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.ValueNetwork.__init__": [[18, 26], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.ValueNetwork.apply"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "hidden_dim", ")", ":", "\n", "        ", "super", "(", "ValueNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "num_inputs", ",", "hidden_dim", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.ValueNetwork.forward": [[27, 32], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.ValueNetwork.linear3", "model.ValueNetwork.linear1", "model.ValueNetwork.linear2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "linear1", "(", "state", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "linear2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "linear3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.QNetwork.__init__": [[35, 49], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.QNetwork.apply"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_actions", ",", "hidden_dim", ")", ":", "\n", "        ", "super", "(", "QNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Q1 architecture", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "num_inputs", "+", "num_actions", ",", "hidden_dim", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n", "# Q2 architecture", "\n", "self", ".", "linear4", "=", "nn", ".", "Linear", "(", "num_inputs", "+", "num_actions", ",", "hidden_dim", ")", "\n", "self", ".", "linear5", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear6", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.QNetwork.forward": [[50, 62], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.QNetwork.linear3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.QNetwork.linear6", "model.QNetwork.linear1", "model.QNetwork.linear2", "model.QNetwork.linear4", "model.QNetwork.linear5"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "        ", "xu", "=", "torch", ".", "cat", "(", "[", "state", ",", "action", "]", ",", "1", ")", "\n", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "linear1", "(", "xu", ")", ")", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "linear2", "(", "x1", ")", ")", "\n", "x1", "=", "self", ".", "linear3", "(", "x1", ")", "\n", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "linear4", "(", "xu", ")", ")", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "linear5", "(", "x2", ")", ")", "\n", "x2", "=", "self", ".", "linear6", "(", "x2", ")", "\n", "\n", "return", "x1", ",", "x2", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__": [[65, 85], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.GaussianPolicy.apply", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_actions", ",", "hidden_dim", ",", "action_space", "=", "None", ")", ":", "\n", "        ", "super", "(", "GaussianPolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "num_inputs", ",", "hidden_dim", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "\n", "self", ".", "mean_linear", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "num_actions", ")", "\n", "self", ".", "log_std_linear", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "num_actions", ")", "\n", "\n", "self", ".", "apply", "(", "weights_init_", ")", "\n", "\n", "# action rescaling", "\n", "if", "action_space", "is", "None", ":", "\n", "            ", "self", ".", "action_scale", "=", "torch", ".", "tensor", "(", "1.", ")", "\n", "self", ".", "action_bias", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "action_scale", "=", "torch", ".", "FloatTensor", "(", "\n", "(", "action_space", ".", "high", "-", "action_space", ".", "low", ")", "/", "2.", ")", "\n", "self", ".", "action_bias", "=", "torch", ".", "FloatTensor", "(", "\n", "(", "action_space", ".", "high", "+", "action_space", ".", "low", ")", "/", "2.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.forward": [[86, 93], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.GaussianPolicy.mean_linear", "model.GaussianPolicy.log_std_linear", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "model.GaussianPolicy.linear1", "model.GaussianPolicy.linear2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "state", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "linear1", "(", "state", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "linear2", "(", "x", ")", ")", "\n", "mean", "=", "self", ".", "mean_linear", "(", "x", ")", "\n", "log_std", "=", "self", ".", "log_std_linear", "(", "x", ")", "\n", "log_std", "=", "torch", ".", "clamp", "(", "log_std", ",", "min", "=", "LOG_SIG_MIN", ",", "max", "=", "LOG_SIG_MAX", ")", "\n", "return", "mean", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.sample": [[94, 107], ["model.GaussianPolicy.forward", "log_std.exp", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.distributions.Normal.rsample", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.distributions.Normal.log_prob", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "log_prob.sum.sum.sum", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.pow", "torch.tanh.pow", "torch.tanh.pow"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.forward"], ["", "def", "sample", "(", "self", ",", "state", ")", ":", "\n", "        ", "mean", ",", "log_std", "=", "self", ".", "forward", "(", "state", ")", "\n", "std", "=", "log_std", ".", "exp", "(", ")", "\n", "normal", "=", "Normal", "(", "mean", ",", "std", ")", "\n", "x_t", "=", "normal", ".", "rsample", "(", ")", "# for reparameterization trick (mean + std * N(0,1))", "\n", "y_t", "=", "torch", ".", "tanh", "(", "x_t", ")", "\n", "action", "=", "y_t", "*", "self", ".", "action_scale", "+", "self", ".", "action_bias", "\n", "log_prob", "=", "normal", ".", "log_prob", "(", "x_t", ")", "\n", "# Enforcing Action Bound", "\n", "log_prob", "-=", "torch", ".", "log", "(", "self", ".", "action_scale", "*", "(", "1", "-", "y_t", ".", "pow", "(", "2", ")", ")", "+", "epsilon", ")", "\n", "log_prob", "=", "log_prob", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "mean", "=", "torch", ".", "tanh", "(", "mean", ")", "*", "self", ".", "action_scale", "+", "self", ".", "action_bias", "\n", "return", "action", ",", "log_prob", ",", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to": [[108, 112], ["model.GaussianPolicy.action_scale.to", "model.GaussianPolicy.action_bias.to", "super().to"], "methods", ["home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to", "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.GaussianPolicy.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "action_scale", "=", "self", ".", "action_scale", ".", "to", "(", "device", ")", "\n", "self", ".", "action_bias", "=", "self", ".", "action_bias", ".", "to", "(", "device", ")", "\n", "return", "super", "(", "GaussianPolicy", ",", "self", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.model.weights_init_": [[11, 15], ["isinstance", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "function", ["None"], ["def", "weights_init_", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ",", "gain", "=", "1", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.create_log_gaussian": [[5, 12], ["math.log", "quadratic.sum", "log_z.sum", "log_std.exp"], "function", ["None"], ["\n", "def", "create_log_gaussian", "(", "mean", ",", "log_std", ",", "t", ")", ":", "\n", "    ", "quadratic", "=", "-", "(", "(", "0.5", "*", "(", "t", "-", "mean", ")", "/", "(", "log_std", ".", "exp", "(", ")", ")", ")", ".", "pow", "(", "2", ")", ")", "\n", "l", "=", "mean", ".", "shape", "\n", "log_z", "=", "log_std", "\n", "z", "=", "l", "[", "-", "1", "]", "*", "math", ".", "log", "(", "2", "*", "math", ".", "pi", ")", "\n", "log_p", "=", "quadratic", ".", "sum", "(", "dim", "=", "-", "1", ")", "-", "log_z", ".", "sum", "(", "dim", "=", "-", "1", ")", "-", "0.5", "*", "z", "\n", "return", "log_p", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.logsumexp": [[13, 22], ["torch.max", "inputs.view.view", "outputs.squeeze.squeeze"], "function", ["None"], ["\n", "", "def", "logsumexp", "(", "inputs", ",", "dim", "=", "None", ",", "keepdim", "=", "False", ")", ":", "\n", "    ", "if", "dim", "is", "None", ":", "\n", "        ", "inputs", "=", "inputs", ".", "view", "(", "-", "1", ")", "\n", "dim", "=", "0", "\n", "", "s", ",", "_", "=", "torch", ".", "max", "(", "inputs", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "outputs", "=", "s", "+", "(", "inputs", "-", "s", ")", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", ".", "log", "(", ")", "\n", "if", "not", "keepdim", ":", "\n", "        ", "outputs", "=", "outputs", ".", "squeeze", "(", "dim", ")", "\n", "", "return", "outputs", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.soft_update": [[23, 26], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "function", ["None"], ["\n", "", "def", "soft_update", "(", "target", ",", "source", ",", "tau", ")", ":", "\n", "    ", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "target_param", ".", "data", ".", "copy_", "(", "target_param", ".", "data", "*", "(", "1.0", "-", "tau", ")", "+", "param", ".", "data", "*", "tau", ")", "\n"]], "home.repos.pwc.inspect_result.twni2016_Meta-SAC.sac.utils.hard_update": [[27, 30], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "function", ["None"], ["\n", "", "", "def", "hard_update", "(", "target", ",", "source", ")", ":", "\n", "    ", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "target_param", ".", "data", ".", "copy_", "(", "param", ".", "data", ")", "\n"]]}