{"home.repos.pwc.inspect_result.qtli_kemp.None.main.print_opts": [[18, 28], ["print", "print", "print", "print", "print"], "function", ["None"], ["def", "print_opts", "(", "opts", ")", ":", "\n", "    ", "\"\"\"Prints the values of all command-line arguments.\n    \"\"\"", "\n", "print", "(", "'='", "*", "80", ")", "\n", "print", "(", "'Opts'", ".", "center", "(", "80", ")", ")", "\n", "print", "(", "'-'", "*", "80", ")", "\n", "for", "key", "in", "opts", ".", "__dict__", ":", "\n", "        ", "if", "opts", ".", "__dict__", "[", "key", "]", ":", "\n", "            ", "print", "(", "'{:>30}: {:<30}'", ".", "format", "(", "key", ",", "opts", ".", "__dict__", "[", "key", "]", ")", ".", "center", "(", "80", ")", ")", "\n", "", "", "print", "(", "'='", "*", "80", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.None.main.load_params": [[30, 112], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "main.print_opts", "logging.basicConfig", "torch.device", "os.cpu_count", "str", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.None.main.print_opts"], ["", "def", "load_params", "(", ")", ":", "\n", "    ", "if", "(", "os", ".", "cpu_count", "(", ")", ">", "8", ")", ":", "\n", "        ", "USE_CUDA", "=", "True", "\n", "", "else", ":", "\n", "        ", "USE_CUDA", "=", "False", "\n", "\n", "", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"data/kemp_dataset_preproc.json\"", ",", "help", "=", "'processed EmpatheticDialogue dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_path\"", ",", "type", "=", "str", ",", "default", "=", "\"save/test/\"", ",", "help", "=", "'path to save the training files'", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume_path\"", ",", "type", "=", "str", ",", "default", "=", "\"result/\"", ",", "help", "=", "'path to save the checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"data/\"", ",", "help", "=", "'path to tokenization file'", ")", "\n", "parser", ".", "add_argument", "(", "\"--emb_file\"", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'path to glove embedding file'", ")", "\n", "\n", "## training", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "default", "=", "\"seq2seq\"", ",", "help", "=", "'model name, [KEMP, wo_ECE, wo_EDD]'", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_cuda\"", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'gpu is available or not'", ")", "\n", "parser", ".", "add_argument", "(", "\"--cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'use gpu or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--device_id'", ",", "dest", "=", "'device_id'", ",", "type", "=", "str", ",", "default", "=", "\"0\"", ",", "help", "=", "'gpu device id'", ")", "\n", "parser", ".", "add_argument", "(", "'--eps'", ",", "type", "=", "float", ",", "default", "=", "1e-9", ",", "help", "=", "'arg in NoamOpt'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "'training iterations'", ")", "\n", "parser", ".", "add_argument", "(", "'--check_iter'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "'validation iterations'", ")", "\n", "parser", ".", "add_argument", "(", "\"--noam\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'NoamOpt'", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "dest", "=", "'dropout'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'dropout'", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'batch size'", ")", "\n", "parser", ".", "add_argument", "(", "\"--plm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'use pretraining model or not'", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_oov_emb\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "\"--pretrain_emb\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'use pretrained embedding (glove) or not'", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_sharing\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'sharing params between input embedding and output proj'", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_smoothing\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'label smoothing loss'", ")", "\n", "parser", ".", "add_argument", "(", "\"--universal\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'universal transformer'", ")", "\n", "parser", ".", "add_argument", "(", "\"--act\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'arg in universal transformer, adaptive computation time'", ")", "\n", "parser", ".", "add_argument", "(", "\"--act_loss_weight\"", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'arg in universal transformer'", ")", "\n", "parser", ".", "add_argument", "(", "\"--specify_model\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'arg for resuming training'", ")", "\n", "\n", "\n", "## testing", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'true for inference, false for training'", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_then_test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'test model if the training finishes'", ")", "\n", "parser", ".", "add_argument", "(", "\"--beam_search\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'beam decoding'", ")", "\n", "parser", ".", "add_argument", "(", "\"--beam_size\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'beam size'", ")", "\n", "parser", ".", "add_argument", "(", "\"--topk\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'topk sampling'", ")", "\n", "\n", "## transformer", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'hidden size'", ")", "\n", "parser", ".", "add_argument", "(", "\"--emb_dim\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "\"--hop\"", ",", "type", "=", "int", ",", "default", "=", "6", ",", "help", "=", "'number of transformer layers'", ")", "\n", "parser", ".", "add_argument", "(", "\"--heads\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of attention heads'", ")", "\n", "parser", ".", "add_argument", "(", "\"--depth\"", ",", "type", "=", "int", ",", "default", "=", "40", ",", "help", "=", "'size of last dimension of keys/values. Must be divisible by number of heads'", ")", "\n", "parser", ".", "add_argument", "(", "\"--filter\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'hidden size of the middle layer in FFN.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--project\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'project the input of decoder from embedding dimension to hidden dimension'", ")", "\n", "parser", ".", "add_argument", "(", "\"--concept_num\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'the maximum number of external concepts injection for a word.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--total_concept_num\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'the maximum number of external concepts injection for a sentence.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'max sequence length (required for timing signal)'", ")", "\n", "parser", ".", "add_argument", "(", "\"--pointer_gen\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'copy mechanism'", ")", "\n", "parser", ".", "add_argument", "(", "\"--attn_loss\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"emotional attention loss\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--emotion_feature\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"emotional feature\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print_opts", "(", "args", ")", "\n", "\n", "args", ".", "emb_file", "=", "args", ".", "emb_file", "or", "\"data/glove.6B.{}d.txt\"", ".", "format", "(", "str", "(", "args", ".", "emb_dim", ")", ")", "\n", "if", "(", "not", "args", ".", "test", ")", ":", "\n", "        ", "args", ".", "save_path_dataset", "=", "args", ".", "save_path", "\n", "\n", "", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ",", "format", "=", "'%(asctime)s %(message)s'", ",", "\n", "datefmt", "=", "'%m-%d %H:%M'", ")", "# ,filename='save/logs/{}.log'.format(str(name)))", "\n", "args", ".", "collect_stats", "=", "False", "\n", "\n", "args", ".", "UNK_idx", "=", "0", "\n", "args", ".", "PAD_idx", "=", "1", "\n", "args", ".", "EOS_idx", "=", "2", "\n", "args", ".", "SOS_idx", "=", "3", "\n", "args", ".", "USR_idx", "=", "4", "# speak state", "\n", "args", ".", "SYS_idx", "=", "5", "# listener state", "\n", "args", ".", "KG_idx", "=", "6", "# concept state", "\n", "args", ".", "CLS_idx", "=", "7", "\n", "args", ".", "SEP_idx", "=", "8", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "USE_CUDA", "=", "USE_CUDA", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.result.cal_metrics._get_ngrams": [[9, 25], ["collections.Counter", "range", "range", "tuple", "len"], "function", ["None"], ["def", "_get_ngrams", "(", "segment", ",", "max_order", ")", ":", "\n", "    ", "\"\"\"Extracts all n-grams upto a given maximum order from an input segment.\n    Args:\n        segment: text segment from which n-grams will be extracted.\n        max_order: maximum length in tokens of the n-grams returned by this\n        methods.\n    Returns:\n        The Counter containing all n-grams upto max_order in segment\n        with a count of how many times each n-gram occurred.\n    \"\"\"", "\n", "ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "segment", ")", "-", "order", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "segment", "[", "i", ":", "i", "+", "order", "]", ")", "\n", "ngram_counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "ngram_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.result.cal_metrics._compute_bleu": [[27, 88], ["zip", "range", "min", "len", "collections.Counter", "cal_metrics._get_ngrams", "range", "min", "sum", "math.exp", "float", "math.exp", "cal_metrics._get_ngrams", "len", "len", "float", "math.log", "len"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.common._get_ngrams", "home.repos.pwc.inspect_result.qtli_kemp.code.common._get_ngrams"], ["", "def", "_compute_bleu", "(", "reference_corpus", ",", "translation_corpus", ",", "max_order", "=", "4", ",", "smooth", "=", "False", ")", ":", "\n", "    ", "\"\"\"Computes BLEU score of translated segments against one or more references.\n    Args:\n        reference_corpus: list of lists of references for each translation. Each\n            reference should be tokenized into a list of tokens.\n        translation_corpus: list of translations to score. Each translation\n            should be tokenized into a list of tokens.\n        max_order: Maximum n-gram order to use when computing BLEU score.\n        smooth: Whether or not to apply Lin et al. 2004 smoothing.\n    Returns:\n        3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n            precisions and brevity penalty.\n    \"\"\"", "\n", "matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "possible_matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "reference_length", "=", "0", "\n", "translation_length", "=", "0", "\n", "for", "(", "references", ",", "translation", ")", "in", "zip", "(", "reference_corpus", ",", "translation_corpus", ")", ":", "\n", "        ", "reference_length", "+=", "min", "(", "len", "(", "r", ")", "for", "r", "in", "references", ")", "\n", "translation_length", "+=", "len", "(", "translation", ")", "\n", "\n", "merged_ref_ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "reference", "in", "references", ":", "\n", "            ", "merged_ref_ngram_counts", "|=", "_get_ngrams", "(", "reference", ",", "max_order", ")", "\n", "", "translation_ngram_counts", "=", "_get_ngrams", "(", "translation", ",", "max_order", ")", "\n", "overlap", "=", "translation_ngram_counts", "&", "merged_ref_ngram_counts", "\n", "for", "ngram", "in", "overlap", ":", "\n", "            ", "matches_by_order", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "overlap", "[", "ngram", "]", "\n", "", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "            ", "possible_matches", "=", "len", "(", "translation", ")", "-", "order", "+", "1", "\n", "if", "possible_matches", ">", "0", ":", "\n", "                ", "possible_matches_by_order", "[", "order", "-", "1", "]", "+=", "possible_matches", "\n", "\n", "", "", "", "precisions", "=", "[", "0", "]", "*", "max_order", "\n", "for", "i", "in", "range", "(", "0", ",", "max_order", ")", ":", "\n", "        ", "if", "smooth", ":", "\n", "            ", "precisions", "[", "i", "]", "=", "(", "(", "matches_by_order", "[", "i", "]", "+", "1.", ")", "/", "\n", "(", "possible_matches_by_order", "[", "i", "]", "+", "1.", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "possible_matches_by_order", "[", "i", "]", ">", "0", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "(", "float", "(", "matches_by_order", "[", "i", "]", ")", "/", "\n", "possible_matches_by_order", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "0.0", "\n", "\n", "", "", "", "if", "min", "(", "precisions", ")", ">", "0", ":", "\n", "        ", "p_log_sum", "=", "sum", "(", "(", "1.", "/", "max_order", ")", "*", "math", ".", "log", "(", "p", ")", "for", "p", "in", "precisions", ")", "\n", "geo_mean", "=", "math", ".", "exp", "(", "p_log_sum", ")", "\n", "", "else", ":", "\n", "        ", "geo_mean", "=", "0", "\n", "\n", "", "ratio", "=", "float", "(", "translation_length", ")", "/", "reference_length", "\n", "\n", "if", "ratio", ">", "1.0", ":", "\n", "        ", "bp", "=", "1.", "\n", "", "else", ":", "\n", "        ", "bp", "=", "math", ".", "exp", "(", "1", "-", "1.", "/", "ratio", ")", "\n", "\n", "", "bleu", "=", "geo_mean", "*", "bp", "\n", "\n", "return", "(", "bleu", ",", "precisions", ",", "bp", ",", "ratio", ",", "translation_length", ",", "reference_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.result.cal_metrics.get_dist": [[90, 114], ["res.items", "len", "len", "len", "float", "len", "float", "bgs.append", "len", "float", "len", "float", "set", "len", "set", "len", "len", "set", "set", "len", "len"], "function", ["None"], ["", "def", "get_dist", "(", "res", ")", ":", "\n", "    ", "unigrams", "=", "[", "]", "\n", "bigrams", "=", "[", "]", "\n", "avg_len", "=", "0.", "\n", "ma_dist1", ",", "ma_dist2", "=", "0.", ",", "0.", "\n", "for", "q", ",", "r", "in", "res", ".", "items", "(", ")", ":", "\n", "        ", "ugs", "=", "r", "\n", "bgs", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "ugs", ")", "-", "1", ":", "\n", "            ", "bgs", ".", "append", "(", "ugs", "[", "i", "]", "+", "ugs", "[", "i", "+", "1", "]", ")", "\n", "i", "+=", "1", "\n", "", "unigrams", "+=", "ugs", "\n", "bigrams", "+=", "bgs", "\n", "ma_dist1", "+=", "len", "(", "set", "(", "ugs", ")", ")", "/", "(", "float", ")", "(", "len", "(", "ugs", ")", "+", "1e-16", ")", "\n", "ma_dist2", "+=", "len", "(", "set", "(", "bgs", ")", ")", "/", "(", "float", ")", "(", "len", "(", "bgs", ")", "+", "1e-16", ")", "\n", "avg_len", "+=", "len", "(", "ugs", ")", "\n", "", "n", "=", "len", "(", "res", ")", "\n", "ma_dist1", "/=", "n", "\n", "ma_dist2", "/=", "n", "\n", "mi_dist1", "=", "len", "(", "set", "(", "unigrams", ")", ")", "/", "(", "float", ")", "(", "len", "(", "unigrams", ")", ")", "\n", "mi_dist2", "=", "len", "(", "set", "(", "bigrams", ")", ")", "/", "(", "float", ")", "(", "len", "(", "bigrams", ")", ")", "\n", "avg_len", "/=", "n", "\n", "return", "ma_dist1", ",", "ma_dist2", ",", "mi_dist1", ",", "mi_dist2", ",", "avg_len", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.result.cal_metrics.cal_one_model": [[117, 162], ["print", "open.write", "cal_metrics.get_dist", "print", "print", "print", "print", "open.write", "open.write", "open.write", "open", "open", "open", "f.readlines", "cal_metrics._compute_bleu", "cal_metrics._compute_bleu", "cal_metrics._compute_bleu", "str", "line.startswith", "line.startswith", "round", "round", "round", "file.rstrip", "line.strip().strip", "line.strip().strip", "line.strip().strip.split", "target.append", "line.strip().strip.split", "pred.append", "line.strip", "line.strip"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.common.get_dist", "home.repos.pwc.inspect_result.qtli_kemp.result.cal_metrics._compute_bleu", "home.repos.pwc.inspect_result.qtli_kemp.result.cal_metrics._compute_bleu", "home.repos.pwc.inspect_result.qtli_kemp.result.cal_metrics._compute_bleu"], ["", "def", "cal_one_model", "(", "file", ",", "opt", "=", "''", ")", ":", "\n", "    ", "if", "opt", "!=", "''", ":", "\n", "        ", "opt_f", "=", "open", "(", "opt", ",", "'w'", ")", "\n", "", "else", ":", "\n", "        ", "opt_f", "=", "open", "(", "file", ".", "rstrip", "(", "'.txt'", ")", "+", "'_metric.txt'", ",", "'w'", ")", "\n", "\n", "", "print", "(", "file", ")", "\n", "opt_f", ".", "write", "(", "file", "+", "'\\n'", ")", "\n", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "target", "=", "[", "]", "\n", "pred", "=", "[", "]", "\n", "\n", "res", "=", "{", "}", "\n", "itr", "=", "0", "\n", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "'Pred:'", ")", ":", "\n", "                ", "p", "=", "line", ".", "strip", "(", "'Pred:'", ")", ".", "strip", "(", ")", "\n", "# p = re.sub(r'([a-zA-Z])([,;?.!:\\'/])', r\"\\1 \\2\", p)", "\n", "", "if", "line", ".", "startswith", "(", "'Ref:'", ")", ":", "\n", "                ", "t", "=", "line", ".", "strip", "(", "'Ref:'", ")", ".", "strip", "(", ")", "\n", "tls", "=", "t", ".", "split", "(", ")", "\n", "target", ".", "append", "(", "[", "tls", "]", ")", "\n", "pls", "=", "p", ".", "split", "(", ")", "\n", "pred", ".", "append", "(", "pls", ")", "\n", "res", "[", "itr", "]", "=", "pls", "\n", "itr", "+=", "1", "\n", "", "", "bleu1", "=", "_compute_bleu", "(", "target", ",", "pred", ",", "max_order", "=", "1", ")", "\n", "bleu2", "=", "_compute_bleu", "(", "target", ",", "pred", ",", "max_order", "=", "2", ")", "\n", "bleu4", "=", "_compute_bleu", "(", "target", ",", "pred", ",", "max_order", "=", "4", ")", "\n", "result", "=", "{", "\n", "\"blue1\"", ":", "round", "(", "bleu1", "[", "0", "]", "*", "100", ",", "2", ")", ",", "\n", "\"blue2\"", ":", "round", "(", "bleu2", "[", "0", "]", "*", "100", ",", "2", ")", ",", "\n", "\"bleu4\"", ":", "round", "(", "bleu4", "[", "0", "]", "*", "100", ",", "2", ")", ",", "\n", "}", "\n", "\n", "", "ma_dist1", ",", "ma_dist2", ",", "mi_dist1", ",", "mi_dist2", ",", "avg_len", "=", "get_dist", "(", "res", ")", "\n", "print", "(", "\"Dist-1\\tDist-2\"", ")", "\n", "print", "(", "\n", "\"{:.2f}\\t{:.2f}\"", ".", "format", "(", "mi_dist1", "*", "100", ",", "mi_dist2", "*", "100", ")", ")", "\n", "print", "(", "result", ")", "\n", "print", "(", "'\\n\\n'", ")", "\n", "\n", "opt_f", ".", "write", "(", "\"Dist-1\\tDist-2\"", "+", "'\\n'", ")", "\n", "opt_f", ".", "write", "(", "\"{:.2f}\\t{:.2f}\\n\"", ".", "format", "(", "mi_dist1", "*", "100", ",", "mi_dist2", "*", "100", ")", ")", "\n", "opt_f", ".", "write", "(", "str", "(", "result", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean": [[19, 25], ["sentence.replace.lower", "word_pairs.items", "nltk.word_tokenize", "sentence.replace.replace"], "function", ["None"], ["def", "clean", "(", "sentence", ",", "word_pairs", ")", ":", "\n", "    ", "sentence", "=", "sentence", ".", "lower", "(", ")", "\n", "for", "k", ",", "v", "in", "word_pairs", ".", "items", "(", ")", ":", "\n", "        ", "sentence", "=", "sentence", ".", "replace", "(", "k", ",", "v", ")", "\n", "", "sentence", "=", "nltk", ".", "word_tokenize", "(", "sentence", ")", "\n", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_word": [[52, 61], ["len"], "function", ["None"], ["def", "index_word", "(", "word", ")", ":", "\n", "    ", "n_words", "=", "len", "(", "word2index", ")", "# Count default tokens", "\n", "if", "word", "not", "in", "word2index", ":", "\n", "        ", "word2index", "[", "word", "]", "=", "n_words", "\n", "word2count", "[", "word", "]", "=", "1", "\n", "index2word", "[", "n_words", "]", "=", "word", "\n", "n_words", "+=", "1", "\n", "", "else", ":", "\n", "        ", "word2count", "[", "word", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words": [[62, 65], ["preprocess.index_word", "word.strip"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_word"], ["", "", "def", "index_words", "(", "sentence", ")", ":", "\n", "    ", "for", "word", "in", "sentence", ":", "\n", "        ", "index_word", "(", "word", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.read_emp_dataset": [[66, 155], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "print", "data_train[].append", "preprocess.clean", "data_train[].append", "preprocess.index_words", "preprocess.clean", "data_train[].append", "preprocess.index_words", "data_train[].append", "len", "len", "len", "len", "data_dev[].append", "preprocess.clean", "data_dev[].append", "preprocess.index_words", "preprocess.clean", "data_dev[].append", "preprocess.index_words", "data_dev[].append", "len", "len", "len", "len", "data_test[].append", "preprocess.clean", "data_test[].append", "preprocess.index_words", "preprocess.clean", "data_test[].append", "preprocess.index_words", "data_test[].append", "len", "len", "len", "len", "len", "len", "preprocess.clean", "u_list.append", "preprocess.index_words", "preprocess.clean", "u_list.append", "preprocess.index_words", "preprocess.clean", "u_list.append", "preprocess.index_words"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.clean", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.index_words"], ["", "", "def", "read_emp_dataset", "(", ")", ":", "\n", "    ", "word_pairs", "=", "{", "\"it's\"", ":", "\"it is\"", ",", "\"don't\"", ":", "\"do not\"", ",", "\"doesn't\"", ":", "\"does not\"", ",", "\"didn't\"", ":", "\"did not\"", ",", "\"you'd\"", ":", "\"you would\"", ",", "\n", "\"you're\"", ":", "\"you are\"", ",", "\"you'll\"", ":", "\"you will\"", ",", "\"i'm\"", ":", "\"i am\"", ",", "\"they're\"", ":", "\"they are\"", ",", "\"that's\"", ":", "\"that is\"", ",", "\n", "\"what's\"", ":", "\"what is\"", ",", "\"couldn't\"", ":", "\"could not\"", ",", "\"i've\"", ":", "\"i have\"", ",", "\"we've\"", ":", "\"we have\"", ",", "\"can't\"", ":", "\"cannot\"", ",", "\n", "\"i'd\"", ":", "\"i would\"", ",", "\"i'd\"", ":", "\"i would\"", ",", "\"aren't\"", ":", "\"are not\"", ",", "\"isn't\"", ":", "\"is not\"", ",", "\"wasn't\"", ":", "\"was not\"", ",", "\n", "\"weren't\"", ":", "\"were not\"", ",", "\"won't\"", ":", "\"will not\"", ",", "\"there's\"", ":", "\"there is\"", ",", "\"there're\"", ":", "\"there are\"", "}", "\n", "train_context", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_dialog_texts.train.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "train_target", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_target_texts.train.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "train_emotion", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_emotion_texts.train.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "train_situation", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_situation_texts.train.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "dev_context", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_dialog_texts.dev.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "dev_target", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_target_texts.dev.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "dev_emotion", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_emotion_texts.dev.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "dev_situation", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_situation_texts.dev.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "test_context", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_dialog_texts.test.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "test_target", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_target_texts.test.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "test_emotion", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_emotion_texts.test.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "test_situation", "=", "np", ".", "load", "(", "'EmpatheticDialogue/sys_situation_texts.test.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "data_train", "=", "{", "'context'", ":", "[", "]", ",", "'target'", ":", "[", "]", ",", "'emotion'", ":", "[", "]", ",", "'situation'", ":", "[", "]", "}", "\n", "data_dev", "=", "{", "'context'", ":", "[", "]", ",", "'target'", ":", "[", "]", ",", "'emotion'", ":", "[", "]", ",", "'situation'", ":", "[", "]", "}", "\n", "data_test", "=", "{", "'context'", ":", "[", "]", ",", "'target'", ":", "[", "]", ",", "'emotion'", ":", "[", "]", ",", "'situation'", ":", "[", "]", "}", "\n", "\n", "\n", "\n", "for", "context", "in", "train_context", ":", "\n", "        ", "u_list", "=", "[", "]", "\n", "for", "u", "in", "context", ":", "\n", "            ", "u", "=", "clean", "(", "u", ",", "word_pairs", ")", "\n", "u_list", ".", "append", "(", "u", ")", "\n", "index_words", "(", "u", ")", "\n", "", "data_train", "[", "'context'", "]", ".", "append", "(", "u_list", ")", "\n", "", "for", "target", "in", "train_target", ":", "\n", "        ", "target", "=", "clean", "(", "target", ",", "word_pairs", ")", "\n", "data_train", "[", "'target'", "]", ".", "append", "(", "target", ")", "\n", "index_words", "(", "target", ")", "\n", "", "for", "situation", "in", "train_situation", ":", "\n", "        ", "situation", "=", "clean", "(", "situation", ",", "word_pairs", ")", "\n", "data_train", "[", "'situation'", "]", ".", "append", "(", "situation", ")", "\n", "index_words", "(", "situation", ")", "\n", "", "for", "emotion", "in", "train_emotion", ":", "\n", "        ", "data_train", "[", "'emotion'", "]", ".", "append", "(", "emotion", ")", "\n", "", "assert", "len", "(", "data_train", "[", "'context'", "]", ")", "==", "len", "(", "data_train", "[", "'target'", "]", ")", "==", "len", "(", "data_train", "[", "'emotion'", "]", ")", "==", "len", "(", "\n", "data_train", "[", "'situation'", "]", ")", "\n", "\n", "for", "context", "in", "dev_context", ":", "\n", "        ", "u_list", "=", "[", "]", "\n", "for", "u", "in", "context", ":", "\n", "            ", "u", "=", "clean", "(", "u", ",", "word_pairs", ")", "\n", "u_list", ".", "append", "(", "u", ")", "\n", "index_words", "(", "u", ")", "\n", "", "data_dev", "[", "'context'", "]", ".", "append", "(", "u_list", ")", "\n", "", "for", "target", "in", "dev_target", ":", "\n", "        ", "target", "=", "clean", "(", "target", ",", "word_pairs", ")", "\n", "data_dev", "[", "'target'", "]", ".", "append", "(", "target", ")", "\n", "index_words", "(", "target", ")", "\n", "", "for", "situation", "in", "dev_situation", ":", "\n", "        ", "situation", "=", "clean", "(", "situation", ",", "word_pairs", ")", "\n", "data_dev", "[", "'situation'", "]", ".", "append", "(", "situation", ")", "\n", "index_words", "(", "situation", ")", "\n", "", "for", "emotion", "in", "dev_emotion", ":", "\n", "        ", "data_dev", "[", "'emotion'", "]", ".", "append", "(", "emotion", ")", "\n", "", "assert", "len", "(", "data_dev", "[", "'context'", "]", ")", "==", "len", "(", "data_dev", "[", "'target'", "]", ")", "==", "len", "(", "data_dev", "[", "'emotion'", "]", ")", "==", "len", "(", "data_dev", "[", "'situation'", "]", ")", "\n", "\n", "for", "context", "in", "test_context", ":", "\n", "        ", "u_list", "=", "[", "]", "\n", "for", "u", "in", "context", ":", "\n", "            ", "u", "=", "clean", "(", "u", ",", "word_pairs", ")", "\n", "u_list", ".", "append", "(", "u", ")", "\n", "index_words", "(", "u", ")", "\n", "", "data_test", "[", "'context'", "]", ".", "append", "(", "u_list", ")", "\n", "", "for", "target", "in", "test_target", ":", "\n", "        ", "target", "=", "clean", "(", "target", ",", "word_pairs", ")", "\n", "data_test", "[", "'target'", "]", ".", "append", "(", "target", ")", "\n", "index_words", "(", "target", ")", "\n", "", "for", "situation", "in", "test_situation", ":", "\n", "        ", "situation", "=", "clean", "(", "situation", ",", "word_pairs", ")", "\n", "data_test", "[", "'situation'", "]", ".", "append", "(", "situation", ")", "\n", "index_words", "(", "situation", ")", "\n", "", "for", "emotion", "in", "test_emotion", ":", "\n", "        ", "data_test", "[", "'emotion'", "]", ".", "append", "(", "emotion", ")", "\n", "", "assert", "len", "(", "data_test", "[", "'context'", "]", ")", "==", "len", "(", "data_test", "[", "'target'", "]", ")", "==", "len", "(", "data_test", "[", "'emotion'", "]", ")", "==", "len", "(", "\n", "data_test", "[", "'situation'", "]", ")", "\n", "\n", "vocab", "=", "[", "word2index", ",", "word2count", ",", "index2word", ",", "len", "(", "word2index", ")", "]", "\n", "print", "(", "'n_words: '", ",", "len", "(", "word2index", ")", ")", "\n", "return", "data_train", ",", "data_dev", ",", "data_test", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.gen_embeddings": [[157, 178], ["print", "numpy.random.randn", "print", "open().readlines", "print", "line.split", "open", "len", "print", "float"], "function", ["None"], ["", "def", "gen_embeddings", "(", "n_words", ",", "word2index", ",", "emb_dim", "=", "300", ",", "emb_file", "=", "'glove.6B.300d.txt'", ")", ":", "\n", "    ", "\"\"\"\n        Generate an initial embedding matrix for `word_dict`.\n        If an embedding file is not given or a word is not in the embedding file,\n        a randomly initialized vector will be used.\n    \"\"\"", "\n", "embeddings", "=", "np", ".", "random", ".", "randn", "(", "n_words", ",", "emb_dim", ")", "*", "0.01", "\n", "print", "(", "'Embeddings: %d x %d'", "%", "(", "n_words", ",", "emb_dim", ")", ")", "\n", "if", "emb_file", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading embedding file: %s'", "%", "emb_file", ")", "\n", "pre_trained", "=", "0", "\n", "for", "line", "in", "open", "(", "emb_file", ")", ".", "readlines", "(", ")", ":", "\n", "            ", "sp", "=", "line", ".", "split", "(", ")", "\n", "if", "(", "len", "(", "sp", ")", "==", "emb_dim", "+", "1", ")", ":", "\n", "                ", "if", "sp", "[", "0", "]", "in", "word2index", ":", "\n", "                    ", "pre_trained", "+=", "1", "\n", "embeddings", "[", "word2index", "[", "sp", "[", "0", "]", "]", "]", "=", "[", "float", "(", "x", ")", "for", "x", "in", "sp", "[", "1", ":", "]", "]", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "sp", "[", "0", "]", ")", "\n", "", "", "print", "(", "'Pre-trained: %d (%.2f%%)'", "%", "(", "pre_trained", ",", "pre_trained", "*", "100.0", "/", "n_words", ")", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity": [[180, 190], ["numpy.linalg.norm", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "emotion_intensity", "(", "NRC", ",", "word", ")", ":", "\n", "    ", "'''\n    Function to calculate emotion intensity (Eq. 1 in our paper)\n    :param NRC: NRC_VAD vectors\n    :param word: query word\n    :return:\n    '''", "\n", "v", ",", "a", ",", "d", "=", "NRC", "[", "word", "]", "\n", "a", "=", "a", "/", "2", "\n", "return", "(", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "[", "v", ",", "a", "]", ")", "-", "np", ".", "array", "(", "[", "0.5", ",", "0", "]", ")", ")", "-", "0.06467", ")", "/", "0.607468", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.get_concept_dict": [[192, 269], ["preprocess.gen_embeddings", "json.load", "csv.reader", "open", "open", "enumerate", "print", "json.dump", "sorted", "json.dump", "open", "json.load", "open", "open", "len", "sorted.items", "print", "items[].split", "items[].split", "wnl.lemmatize", "wnl.lemmatize", "len", "print", "items[].split", "items[].split", "items[].split", "ast.literal_eval", "wnl.lemmatize.isalpha", "wnl.lemmatize.isalpha", "torch.Tensor", "torch.Tensor", "torch.cosine_similarity().item", "row[].strip", "torch.cosine_similarity", "preprocess.emotion_intensity", "preprocess.emotion_intensity", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.gen_embeddings", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity"], ["", "def", "get_concept_dict", "(", ")", ":", "\n", "    ", "'''\n    Retrieve concepts from ConceptNet using the EmpatheticDialogue tokens as queries\n    :return:\n    '''", "\n", "with", "open", "(", "'EmpatheticDialogue/dataset_preproc.json'", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "[", "data_tra", ",", "data_val", ",", "data_tst", ",", "vocab", "]", "=", "json", ".", "load", "(", "f", ")", "\n", "word2index", ",", "word2count", ",", "index2word", ",", "n_words", "=", "vocab", "\n", "\n", "", "embeddings", "=", "gen_embeddings", "(", "n_words", ",", "word2index", ")", "\n", "\n", "VAD", "=", "json", ".", "load", "(", "open", "(", "\"VAD.json\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "# NRC_VAD", "\n", "CN", "=", "csv", ".", "reader", "(", "open", "(", "\"assertions.csv\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "# ConceptNet raw file", "\n", "\n", "concept_dict", "=", "{", "}", "\n", "concept_file", "=", "open", "(", "\"ConceptNet.json\"", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n", "relation_dict", "=", "{", "}", "\n", "rd", "=", "open", "(", "\"relation.json\"", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "CN", ")", ":", "\n", "        ", "if", "i", "%", "1000000", "==", "0", ":", "\n", "            ", "print", "(", "\"Processed {} rows\"", ".", "format", "(", "i", ")", ")", "\n", "", "items", "=", "\"\"", ".", "join", "(", "row", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "c1_lang", "=", "items", "[", "2", "]", ".", "split", "(", "\"/\"", ")", "[", "2", "]", "\n", "c2_lang", "=", "items", "[", "2", "]", ".", "split", "(", "\"/\"", ")", "[", "2", "]", "\n", "if", "c1_lang", "==", "\"en\"", "and", "c2_lang", "==", "\"en\"", ":", "\n", "            ", "if", "len", "(", "items", ")", "!=", "5", ":", "\n", "                ", "print", "(", "\"concept error!\"", ")", "\n", "", "relation", "=", "items", "[", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "2", "]", "\n", "c1", "=", "items", "[", "2", "]", ".", "split", "(", "\"/\"", ")", "[", "3", "]", "\n", "c2", "=", "items", "[", "3", "]", ".", "split", "(", "\"/\"", ")", "[", "3", "]", "\n", "c1", "=", "wnl", ".", "lemmatize", "(", "c1", ")", "\n", "c2", "=", "wnl", ".", "lemmatize", "(", "c2", ")", "\n", "weight", "=", "literal_eval", "(", "\"{\"", "+", "row", "[", "-", "1", "]", ".", "strip", "(", ")", ")", "[", "\"weight\"", "]", "\n", "\n", "if", "weight", "<", "1.0", ":", "# filter tuples where confidence score is smaller than 1.0", "\n", "                ", "continue", "\n", "", "if", "c1", "in", "word2index", "and", "c2", "in", "word2index", "and", "c1", "!=", "c2", "and", "c1", ".", "isalpha", "(", ")", "and", "c2", ".", "isalpha", "(", ")", ":", "\n", "                ", "if", "relation", "not", "in", "word2index", ":", "\n", "                    ", "if", "relation", "in", "relation_dict", ":", "\n", "                        ", "relation_dict", "[", "relation", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "relation_dict", "[", "relation", "]", "=", "0", "\n", "", "", "c1_vector", "=", "torch", ".", "Tensor", "(", "embeddings", "[", "word2index", "[", "c1", "]", "]", ")", "\n", "c2_vector", "=", "torch", ".", "Tensor", "(", "embeddings", "[", "word2index", "[", "c2", "]", "]", ")", "\n", "c1_c2_sim", "=", "torch", ".", "cosine_similarity", "(", "c1_vector", ",", "c2_vector", ",", "dim", "=", "0", ")", ".", "item", "(", ")", "\n", "\n", "v1", ",", "a1", ",", "d1", "=", "VAD", "[", "c1", "]", "if", "c1", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "\n", "v2", ",", "a2", ",", "d2", "=", "VAD", "[", "c2", "]", "if", "c2", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "\n", "emotion_gap", "=", "1", "-", "(", "abs", "(", "v1", "-", "v2", ")", "+", "abs", "(", "a1", "-", "a2", ")", ")", "/", "2", "\n", "# <c1 relation c2>", "\n", "if", "c2", "not", "in", "stop_words", ":", "\n", "                    ", "c2_vad", "=", "emotion_intensity", "(", "VAD", ",", "c2", ")", "if", "c2", "in", "VAD", "else", "0.0", "\n", "# score = c2_vad + c1_c2_sim + (weight - 1) / (10.0 - 1.0) + emotion_gap", "\n", "score", "=", "c2_vad", "+", "emotion_gap", "\n", "if", "c1", "in", "concept_dict", ":", "\n", "                        ", "concept_dict", "[", "c1", "]", "[", "c2", "]", "=", "[", "relation", ",", "c2_vad", ",", "c1_c2_sim", ",", "weight", ",", "emotion_gap", ",", "score", "]", "\n", "", "else", ":", "\n", "                        ", "concept_dict", "[", "c1", "]", "=", "{", "}", "\n", "concept_dict", "[", "c1", "]", "[", "c2", "]", "=", "[", "relation", ",", "c2_vad", ",", "c1_c2_sim", ",", "weight", ",", "emotion_gap", ",", "score", "]", "\n", "# reverse relation  <c2 relation c1>", "\n", "", "", "if", "c1", "not", "in", "stop_words", ":", "\n", "                    ", "c1_vad", "=", "emotion_intensity", "(", "VAD", ",", "c1", ")", "if", "c1", "in", "VAD", "else", "0.0", "\n", "# score = c1_vad + c1_c2_sim + (weight - 1) / (10.0 - 1.0) + emotion_gap", "\n", "score", "=", "c1_vad", "+", "emotion_gap", "\n", "if", "c2", "in", "concept_dict", ":", "\n", "                        ", "concept_dict", "[", "c2", "]", "[", "c1", "]", "=", "[", "relation", ",", "c1_vad", ",", "c1_c2_sim", ",", "weight", ",", "emotion_gap", ",", "score", "]", "\n", "", "else", ":", "\n", "                        ", "concept_dict", "[", "c2", "]", "=", "{", "}", "\n", "concept_dict", "[", "c2", "]", "[", "c1", "]", "=", "[", "relation", ",", "c1_vad", ",", "c1_c2_sim", ",", "weight", ",", "emotion_gap", ",", "score", "]", "\n", "\n", "", "", "", "", "", "print", "(", "\"concept num: \"", ",", "len", "(", "concept_dict", ")", ")", "\n", "json", ".", "dump", "(", "concept_dict", ",", "concept_file", ")", "\n", "\n", "relation_dict", "=", "sorted", "(", "relation_dict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "json", ".", "dump", "(", "relation_dict", ",", "rd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.rank_concept_dict": [[271, 281], ["json.load", "open", "json.dump", "open", "dict", "sorted", "concept_dict[].items"], "function", ["None"], ["", "def", "rank_concept_dict", "(", ")", ":", "\n", "    ", "concept_dict", "=", "json", ".", "load", "(", "open", "(", "\"ConceptNet.json\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "rank_concept_file", "=", "open", "(", "'ConceptNet_VAD_dict.json'", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "rank_concept", "=", "{", "}", "\n", "for", "i", "in", "concept_dict", ":", "\n", "# [relation, c1_vad, c1_c2_sim, weight, emotion_gap, score]   relation, weight, score", "\n", "        ", "rank_concept", "[", "i", "]", "=", "dict", "(", "sorted", "(", "concept_dict", "[", "i", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", "[", "5", "]", ",", "reverse", "=", "True", ")", ")", "# \u6839\u636evad\u7531\u5927\u5230\u5c0f\u6392\u5e8f", "\n", "rank_concept", "[", "i", "]", "=", "[", "[", "l", ",", "concept_dict", "[", "i", "]", "[", "l", "]", "[", "0", "]", ",", "concept_dict", "[", "i", "]", "[", "l", "]", "[", "1", "]", ",", "concept_dict", "[", "i", "]", "[", "l", "]", "[", "2", "]", ",", "concept_dict", "[", "i", "]", "[", "l", "]", "[", "3", "]", ",", "concept_dict", "[", "i", "]", "[", "l", "]", "[", "4", "]", ",", "concept_dict", "[", "i", "]", "[", "l", "]", "[", "5", "]", "]", "for", "l", "in", "concept_dict", "[", "i", "]", "]", "\n", "", "json", ".", "dump", "(", "rank_concept", ",", "rank_concept_file", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.get_wordnet_pos": [[287, 298], ["tag.startswith", "tag.startswith", "tag.startswith", "tag.startswith"], "function", ["None"], ["def", "get_wordnet_pos", "(", "tag", ")", ":", "\n", "    ", "if", "tag", ".", "startswith", "(", "'J'", ")", ":", "\n", "        ", "return", "wordnet", ".", "ADJ", "\n", "", "elif", "tag", ".", "startswith", "(", "'V'", ")", ":", "\n", "        ", "return", "wordnet", ".", "VERB", "\n", "", "elif", "tag", ".", "startswith", "(", "'N'", ")", ":", "\n", "        ", "return", "wordnet", ".", "NOUN", "\n", "", "elif", "tag", ".", "startswith", "(", "'R'", ")", ":", "\n", "        ", "return", "wordnet", ".", "ADV", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.wordCate": [[299, 305], ["preprocess.get_wordnet_pos"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.get_wordnet_pos"], ["", "", "def", "wordCate", "(", "word_pos", ")", ":", "\n", "    ", "w_p", "=", "get_wordnet_pos", "(", "word_pos", "[", "1", "]", ")", "\n", "if", "w_p", "==", "wordnet", ".", "NOUN", "or", "w_p", "==", "wordnet", ".", "ADV", "or", "w_p", "==", "wordnet", ".", "ADJ", "or", "w_p", "==", "wordnet", ".", "VERB", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.read_our_dataset": [[306, 507], ["json.load", "json.load", "enumerate", "enumerate", "print", "enumerate", "enumerate", "print", "enumerate", "enumerate", "print", "open", "json.load", "open", "open", "enumerate", "data_tra[].append", "data_tra[].append", "data_tra[].append", "data_tra[].append", "data_tra[].append", "data_tra[].append", "enumerate", "data_val[].append", "data_tra[].append", "data_val[].append", "data_val[].append", "data_val[].append", "data_val[].append", "enumerate", "data_tst[].append", "data_tra[].append", "data_tst[].append", "data_tst[].append", "data_tst[].append", "data_tst[].append", "nltk.pos_tag", "vads.append", "vad.append", "enumerate", "concepts.append", "nltk.pos_tag", "vads.append", "vad.append", "enumerate", "concepts.append", "nltk.pos_tag", "vads.append", "vad.append", "enumerate", "concepts.append", "sentence_concept_words.append", "sentence_concept_vads.append", "sentence_concept_vad.append", "sentence_concept_words.append", "sentence_concept_vads.append", "sentence_concept_vad.append", "sentence_concept_words.append", "sentence_concept_vads.append", "sentence_concept_vad.append", "enumerate", "preprocess.emotion_intensity", "enumerate", "preprocess.emotion_intensity", "enumerate", "preprocess.emotion_intensity", "preprocess.emotion_intensity", "preprocess.wordCate", "preprocess.emotion_intensity", "preprocess.wordCate", "preprocess.emotion_intensity", "preprocess.wordCate", "concept_words.append", "concept_vads.append", "concept_vad.append", "total_concepts.append", "total_concepts_tid.append", "concept_words.append", "concept_vads.append", "concept_vad.append", "total_concepts.append", "total_concepts_tid.append", "concept_words.append", "concept_vads.append", "concept_vad.append", "total_concepts.append", "total_concepts_tid.append", "preprocess.emotion_intensity", "preprocess.emotion_intensity", "preprocess.emotion_intensity", "preprocess.emotion_intensity", "preprocess.emotion_intensity", "preprocess.emotion_intensity"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.wordCate", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.wordCate", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.wordCate", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity", "home.repos.pwc.inspect_result.qtli_kemp.data.preprocess.emotion_intensity"], ["", "", "def", "read_our_dataset", "(", "concept_num", "=", "3", ",", "total_concept_num", "=", "10", ",", ")", ":", "\n", "    ", "with", "open", "(", "'EmpatheticDialogue/dataset_preproc.json'", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "[", "data_tra", ",", "data_val", ",", "data_tst", ",", "vocab", "]", "=", "json", ".", "load", "(", "f", ")", "\n", "word2index", ",", "word2count", ",", "index2word", ",", "n_words", "=", "vocab", "\n", "\n", "", "VAD", "=", "json", ".", "load", "(", "open", "(", "\"VAD.json\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "concept", "=", "json", ".", "load", "(", "open", "(", "\"ConceptNet_VAD_dict.json\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "\n", "data_tra", "[", "'concepts'", "]", ",", "data_val", "[", "'concepts'", "]", ",", "data_tst", "[", "'concepts'", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "data_tra", "[", "'sample_concepts'", "]", ",", "data_val", "[", "'sample_concepts'", "]", ",", "data_tst", "[", "'sample_concepts'", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "data_tra", "[", "'vads'", "]", ",", "data_val", "[", "'vads'", "]", ",", "data_tst", "[", "'vads'", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# each sentence's vad vectors", "\n", "data_tra", "[", "'vad'", "]", ",", "data_val", "[", "'vad'", "]", ",", "data_tst", "[", "'vad'", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# each word's emotion intensity", "\n", "data_tra", "[", "'target_vad'", "]", ",", "data_val", "[", "'target_vad'", "]", ",", "data_tst", "[", "'target_vad'", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# each target word's emotion intensity", "\n", "data_tra", "[", "'target_vads'", "]", ",", "data_val", "[", "'target_vads'", "]", ",", "data_tst", "[", "'target_vads'", "]", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# each target word's vad vectors", "\n", "\n", "# train", "\n", "train_contexts", "=", "data_tra", "[", "'context'", "]", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "train_contexts", ")", ":", "\n", "        ", "vads", "=", "[", "]", "# each item is sentence, each sentence contains a list word' vad vectors", "\n", "vad", "=", "[", "]", "\n", "concepts", "=", "[", "]", "# concepts of each sample", "\n", "total_concepts", "=", "[", "]", "\n", "total_concepts_tid", "=", "[", "]", "\n", "for", "j", ",", "sentence", "in", "enumerate", "(", "sample", ")", ":", "\n", "            ", "words_pos", "=", "nltk", ".", "pos_tag", "(", "sentence", ")", "\n", "\n", "vads", ".", "append", "(", "[", "VAD", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "for", "word", "in", "sentence", "]", ")", "\n", "vad", ".", "append", "(", "[", "emotion_intensity", "(", "VAD", ",", "word", ")", "if", "word", "in", "VAD", "else", "0.0", "for", "word", "in", "sentence", "]", ")", "\n", "\n", "sentence_concepts", "=", "[", "\n", "concept", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "not", "in", "stop_words", "and", "word", "in", "concept", "and", "wordCate", "(", "words_pos", "[", "wi", "]", ")", "else", "[", "]", "\n", "for", "wi", ",", "word", "in", "enumerate", "(", "sentence", ")", "]", "\n", "\n", "sentence_concept_words", "=", "[", "]", "# for each sentence", "\n", "sentence_concept_vads", "=", "[", "]", "\n", "sentence_concept_vad", "=", "[", "]", "\n", "\n", "for", "cti", ",", "uc", "in", "enumerate", "(", "sentence_concepts", ")", ":", "# filter concepts of each token, complete their VAD value, select top total_concept_num.", "\n", "                ", "concept_words", "=", "[", "]", "# for each token", "\n", "concept_vads", "=", "[", "]", "\n", "concept_vad", "=", "[", "]", "\n", "if", "uc", "!=", "[", "]", ":", "# this token has concepts", "\n", "                    ", "for", "c", "in", "uc", ":", "# iterate the concept lists [c,r,w] of each token", "\n", "                        ", "if", "c", "[", "1", "]", "not", "in", "REMOVE_RELATIONS", "and", "c", "[", "0", "]", "not", "in", "stop_words", "and", "c", "[", "0", "]", "in", "word2index", ":", "# remove concpets that are stopwords or not in the dict", "\n", "                            ", "if", "c", "[", "0", "]", "in", "VAD", "and", "emotion_intensity", "(", "VAD", ",", "c", "[", "0", "]", ")", ">=", "0.6", ":", "\n", "                                ", "concept_words", ".", "append", "(", "c", "[", "0", "]", ")", "\n", "concept_vads", ".", "append", "(", "VAD", "[", "c", "[", "0", "]", "]", ")", "\n", "concept_vad", ".", "append", "(", "emotion_intensity", "(", "VAD", ",", "c", "[", "0", "]", ")", ")", "\n", "total_concepts", ".", "append", "(", "c", "[", "0", "]", ")", "# all concepts of a sentence", "\n", "total_concepts_tid", ".", "append", "(", "[", "j", ",", "cti", "]", ")", "# the token that each concept belongs to", "\n", "\n", "# concept_words = concept_words[:5]", "\n", "# concept_vads = concept_vads[:5]", "\n", "# concept_vad = concept_vad[:5]", "\n", "", "", "", "concept_words", "=", "concept_words", "[", ":", "concept_num", "]", "\n", "concept_vads", "=", "concept_vads", "[", ":", "concept_num", "]", "\n", "concept_vad", "=", "concept_vad", "[", ":", "concept_num", "]", "\n", "\n", "", "sentence_concept_words", ".", "append", "(", "concept_words", ")", "\n", "sentence_concept_vads", ".", "append", "(", "concept_vads", ")", "\n", "sentence_concept_vad", ".", "append", "(", "concept_vad", ")", "\n", "\n", "", "sentence_concepts", "=", "[", "sentence_concept_words", ",", "sentence_concept_vads", ",", "sentence_concept_vad", "]", "\n", "concepts", ".", "append", "(", "sentence_concepts", ")", "\n", "", "data_tra", "[", "'concepts'", "]", ".", "append", "(", "concepts", ")", "\n", "data_tra", "[", "'sample_concepts'", "]", ".", "append", "(", "[", "total_concepts", ",", "total_concepts_tid", "]", ")", "\n", "data_tra", "[", "'vads'", "]", ".", "append", "(", "vads", ")", "\n", "data_tra", "[", "'vad'", "]", ".", "append", "(", "vad", ")", "\n", "\n", "", "train_targets", "=", "data_tra", "[", "'target'", "]", "\n", "for", "i", ",", "target", "in", "enumerate", "(", "train_targets", ")", ":", "\n", "# each item is the VAD info list of each target token", "\n", "        ", "data_tra", "[", "'target_vads'", "]", ".", "append", "(", "[", "VAD", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "for", "word", "in", "target", "]", ")", "\n", "data_tra", "[", "'target_vad'", "]", ".", "append", "(", "[", "emotion_intensity", "(", "VAD", ",", "word", ")", "if", "word", "in", "VAD", "and", "word", "in", "word2index", "else", "0.0", "for", "word", "in", "target", "]", ")", "\n", "", "print", "(", "\"trainset finish.\"", ")", "\n", "\n", "# valid", "\n", "valid_contexts", "=", "data_val", "[", "'context'", "]", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "valid_contexts", ")", ":", "\n", "        ", "vads", "=", "[", "]", "# each item is sentence, each sentence contains a list word' vad vectors", "\n", "vad", "=", "[", "]", "\n", "concepts", "=", "[", "]", "\n", "total_concepts", "=", "[", "]", "\n", "total_concepts_tid", "=", "[", "]", "\n", "\n", "for", "j", ",", "sentence", "in", "enumerate", "(", "sample", ")", ":", "\n", "            ", "words_pos", "=", "nltk", ".", "pos_tag", "(", "sentence", ")", "\n", "\n", "vads", ".", "append", "(", "\n", "[", "VAD", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "for", "word", "in", "sentence", "]", ")", "\n", "vad", ".", "append", "(", "[", "emotion_intensity", "(", "VAD", ",", "word", ")", "if", "word", "in", "VAD", "else", "0.0", "for", "word", "in", "sentence", "]", ")", "\n", "\n", "sentence_concepts", "=", "[", "\n", "concept", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "not", "in", "stop_words", "and", "word", "in", "concept", "and", "wordCate", "(", "\n", "words_pos", "[", "wi", "]", ")", "else", "[", "]", "\n", "for", "wi", ",", "word", "in", "enumerate", "(", "sentence", ")", "]", "\n", "\n", "sentence_concept_words", "=", "[", "]", "# for each sentence", "\n", "sentence_concept_vads", "=", "[", "]", "\n", "sentence_concept_vad", "=", "[", "]", "\n", "\n", "for", "cti", ",", "uc", "in", "enumerate", "(", "sentence_concepts", ")", ":", "\n", "                ", "concept_words", "=", "[", "]", "# for each token", "\n", "concept_vads", "=", "[", "]", "\n", "concept_vad", "=", "[", "]", "\n", "if", "uc", "!=", "[", "]", ":", "\n", "                    ", "for", "c", "in", "uc", ":", "\n", "                        ", "if", "c", "[", "1", "]", "not", "in", "REMOVE_RELATIONS", "and", "c", "[", "0", "]", "not", "in", "stop_words", "and", "c", "[", "0", "]", "in", "word2index", ":", "\n", "                            ", "if", "c", "[", "0", "]", "in", "VAD", "and", "emotion_intensity", "(", "VAD", ",", "c", "[", "0", "]", ")", ">=", "0.6", ":", "\n", "                                ", "concept_words", ".", "append", "(", "c", "[", "0", "]", ")", "\n", "concept_vads", ".", "append", "(", "VAD", "[", "c", "[", "0", "]", "]", ")", "\n", "concept_vad", ".", "append", "(", "emotion_intensity", "(", "VAD", ",", "c", "[", "0", "]", ")", ")", "\n", "\n", "total_concepts", ".", "append", "(", "c", "[", "0", "]", ")", "\n", "total_concepts_tid", ".", "append", "(", "[", "j", ",", "cti", "]", ")", "\n", "\n", "", "", "", "concept_words", "=", "concept_words", "[", ":", "concept_num", "]", "\n", "concept_vads", "=", "concept_vads", "[", ":", "concept_num", "]", "\n", "concept_vad", "=", "concept_vad", "[", ":", "concept_num", "]", "\n", "\n", "", "sentence_concept_words", ".", "append", "(", "concept_words", ")", "\n", "sentence_concept_vads", ".", "append", "(", "concept_vads", ")", "\n", "sentence_concept_vad", ".", "append", "(", "concept_vad", ")", "\n", "\n", "", "sentence_concepts", "=", "[", "sentence_concept_words", ",", "sentence_concept_vads", ",", "sentence_concept_vad", "]", "\n", "concepts", ".", "append", "(", "sentence_concepts", ")", "\n", "\n", "", "data_val", "[", "'concepts'", "]", ".", "append", "(", "concepts", ")", "\n", "data_tra", "[", "'sample_concepts'", "]", ".", "append", "(", "[", "total_concepts", ",", "total_concepts_tid", "]", ")", "\n", "data_val", "[", "'vads'", "]", ".", "append", "(", "vads", ")", "\n", "data_val", "[", "'vad'", "]", ".", "append", "(", "vad", ")", "\n", "\n", "", "valid_targets", "=", "data_val", "[", "'target'", "]", "\n", "for", "i", ",", "target", "in", "enumerate", "(", "valid_targets", ")", ":", "\n", "        ", "data_val", "[", "'target_vads'", "]", ".", "append", "(", "[", "VAD", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "for", "word", "in", "target", "]", ")", "\n", "data_val", "[", "'target_vad'", "]", ".", "append", "(", "[", "emotion_intensity", "(", "VAD", ",", "word", ")", "if", "word", "in", "VAD", "and", "word", "in", "word2index", "else", "0.0", "for", "word", "in", "target", "]", ")", "\n", "", "print", "(", "'validset finish.'", ")", "\n", "\n", "# test", "\n", "test_contexts", "=", "data_tst", "[", "'context'", "]", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "test_contexts", ")", ":", "\n", "        ", "vads", "=", "[", "]", "# each item is sentence, each sentence contains a list word' vad vectors", "\n", "vad", "=", "[", "]", "\n", "concepts", "=", "[", "]", "\n", "total_concepts", "=", "[", "]", "\n", "total_concepts_tid", "=", "[", "]", "\n", "for", "j", ",", "sentence", "in", "enumerate", "(", "sample", ")", ":", "\n", "            ", "words_pos", "=", "nltk", ".", "pos_tag", "(", "sentence", ")", "\n", "\n", "vads", ".", "append", "(", "\n", "[", "VAD", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "for", "word", "in", "sentence", "]", ")", "\n", "vad", ".", "append", "(", "[", "emotion_intensity", "(", "VAD", ",", "word", ")", "if", "word", "in", "VAD", "else", "0.0", "for", "word", "in", "sentence", "]", ")", "\n", "\n", "sentence_concepts", "=", "[", "\n", "concept", "[", "\n", "word", "]", "if", "word", "in", "word2index", "and", "word", "not", "in", "stop_words", "and", "word", "in", "concept", "and", "wordCate", "(", "\n", "words_pos", "[", "wi", "]", ")", "else", "[", "]", "\n", "for", "wi", ",", "word", "in", "enumerate", "(", "sentence", ")", "]", "\n", "\n", "sentence_concept_words", "=", "[", "]", "# for each sentence", "\n", "sentence_concept_vads", "=", "[", "]", "\n", "sentence_concept_vad", "=", "[", "]", "\n", "\n", "for", "cti", ",", "uc", "in", "enumerate", "(", "sentence_concepts", ")", ":", "\n", "                ", "concept_words", "=", "[", "]", "# for each token", "\n", "concept_vads", "=", "[", "]", "\n", "concept_vad", "=", "[", "]", "\n", "if", "uc", "!=", "[", "]", ":", "\n", "                    ", "for", "c", "in", "uc", ":", "\n", "                        ", "if", "c", "[", "1", "]", "not", "in", "REMOVE_RELATIONS", "and", "c", "[", "0", "]", "not", "in", "stop_words", "and", "c", "[", "0", "]", "in", "word2index", ":", "\n", "                            ", "if", "c", "[", "0", "]", "in", "VAD", "and", "emotion_intensity", "(", "VAD", ",", "c", "[", "0", "]", ")", ">=", "0.6", ":", "\n", "                                ", "concept_words", ".", "append", "(", "c", "[", "0", "]", ")", "\n", "concept_vads", ".", "append", "(", "VAD", "[", "c", "[", "0", "]", "]", ")", "\n", "concept_vad", ".", "append", "(", "emotion_intensity", "(", "VAD", ",", "c", "[", "0", "]", ")", ")", "\n", "\n", "total_concepts", ".", "append", "(", "c", "[", "0", "]", ")", "\n", "total_concepts_tid", ".", "append", "(", "[", "j", ",", "cti", "]", ")", "\n", "\n", "", "", "", "concept_words", "=", "concept_words", "[", ":", "concept_num", "]", "\n", "concept_vads", "=", "concept_vads", "[", ":", "concept_num", "]", "\n", "concept_vad", "=", "concept_vad", "[", ":", "concept_num", "]", "\n", "\n", "", "sentence_concept_words", ".", "append", "(", "concept_words", ")", "\n", "sentence_concept_vads", ".", "append", "(", "concept_vads", ")", "\n", "sentence_concept_vad", ".", "append", "(", "concept_vad", ")", "\n", "\n", "", "sentence_concepts", "=", "[", "sentence_concept_words", ",", "sentence_concept_vads", ",", "sentence_concept_vad", "]", "\n", "concepts", ".", "append", "(", "sentence_concepts", ")", "\n", "\n", "", "data_tst", "[", "'concepts'", "]", ".", "append", "(", "concepts", ")", "\n", "data_tra", "[", "'sample_concepts'", "]", ".", "append", "(", "[", "total_concepts", ",", "total_concepts_tid", "]", ")", "\n", "data_tst", "[", "'vads'", "]", ".", "append", "(", "vads", ")", "\n", "data_tst", "[", "'vad'", "]", ".", "append", "(", "vad", ")", "\n", "\n", "", "test_targets", "=", "data_tst", "[", "'target'", "]", "\n", "for", "i", ",", "target", "in", "enumerate", "(", "test_targets", ")", ":", "\n", "        ", "data_tst", "[", "'target_vads'", "]", ".", "append", "(", "[", "VAD", "[", "word", "]", "if", "word", "in", "word2index", "and", "word", "in", "VAD", "else", "[", "0.5", ",", "0.0", ",", "0.5", "]", "for", "word", "in", "target", "]", ")", "\n", "data_tst", "[", "'target_vad'", "]", ".", "append", "(", "[", "emotion_intensity", "(", "VAD", ",", "word", ")", "if", "word", "in", "VAD", "and", "word", "in", "word2index", "else", "0.0", "for", "word", "in", "target", "]", ")", "\n", "", "print", "(", "'testset finish.'", ")", "\n", "\n", "return", "data_tra", ",", "data_val", ",", "data_tst", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.__init__": [[20, 35], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "args", ",", "size", ",", "device", "=", "False", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "_done", "=", "False", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "torch", ".", "zeros", "(", "(", "size", ",", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "args", ".", "device", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "torch", ".", "full", "(", "(", "size", ",", ")", ",", "args", ".", "PAD_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "args", ".", "SOS_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.get_current_state": [[36, 39], ["common.Beam.get_tentative_hypothesis"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.get_tentative_hypothesis"], ["", "def", "get_current_state", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n", "return", "self", ".", "get_tentative_hypothesis", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.get_current_origin": [[40, 43], ["None"], "methods", ["None"], ["", "def", "get_current_origin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n", "return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.done": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_done", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.advance": [[48, 78], ["word_prob.size", "beam_lk.view", "beam_lk.view.topk", "beam_lk.view.topk", "common.Beam.all_scores.append", "common.Beam.prev_ks.append", "common.Beam.next_ys.append", "len", "[].item", "common.Beam.all_scores.append", "common.Beam.scores.unsqueeze().expand_as", "common.Beam.scores.unsqueeze"], "methods", ["None"], ["", "def", "advance", "(", "self", ",", "word_prob", ")", ":", "\n", "        ", "\"Update beam status and check if finished or not.\"", "\n", "num_words", "=", "word_prob", ".", "size", "(", "1", ")", "\n", "\n", "# Sum the previous scores.", "\n", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_lk", "=", "word_prob", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "word_prob", ")", "\n", "", "else", ":", "\n", "            ", "beam_lk", "=", "word_prob", "[", "0", "]", "\n", "\n", "", "flat_beam_lk", "=", "beam_lk", ".", "view", "(", "-", "1", ")", "\n", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_lk", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "True", ",", "True", ")", "# 1st sort", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_lk", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "True", ",", "True", ")", "# 2nd sort", "\n", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# bestScoresId is flattened as a (beam x word) array,", "\n", "# so we need to calculate which word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "next_ys", ".", "append", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", "\n", "\n", "# End condition is when top-of-beam is EOS.", "\n", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", ".", "item", "(", ")", "==", "self", ".", "args", ".", "EOS_idx", ":", "\n", "            ", "self", ".", "_done", "=", "True", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "\n", "", "return", "self", ".", "_done", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.sort_scores": [[79, 82], ["torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort"], "methods", ["None"], ["", "def", "sort_scores", "(", "self", ")", ":", "\n", "        ", "\"Sort the scores.\"", "\n", "return", "torch", ".", "sort", "(", "self", ".", "scores", ",", "0", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.get_the_best_score_and_idx": [[83, 87], ["common.Beam.sort_scores"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.sort_scores"], ["", "def", "get_the_best_score_and_idx", "(", "self", ")", ":", "\n", "        ", "\"Get the score of the best in the beam.\"", "\n", "scores", ",", "ids", "=", "self", ".", "sort_scores", "(", ")", "\n", "return", "scores", "[", "1", "]", ",", "ids", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.get_tentative_hypothesis": [[88, 100], ["len", "common.Beam.next_ys[].unsqueeze", "common.Beam.sort_scores", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "common.Beam.get_hypothesis"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.sort_scores", "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.get_hypothesis"], ["", "def", "get_tentative_hypothesis", "(", "self", ")", ":", "\n", "        ", "\"Get the decoded sequence for the current timestep.\"", "\n", "\n", "if", "len", "(", "self", ".", "next_ys", ")", "==", "1", ":", "\n", "            ", "dec_seq", "=", "self", ".", "next_ys", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "_", ",", "keys", "=", "self", ".", "sort_scores", "(", ")", "\n", "hyps", "=", "[", "self", ".", "get_hypothesis", "(", "k", ")", "for", "k", "in", "keys", "]", "\n", "hyps", "=", "[", "[", "self", ".", "args", ".", "SOS_idx", "]", "+", "h", "for", "h", "in", "hyps", "]", "\n", "dec_seq", "=", "torch", ".", "LongTensor", "(", "hyps", ")", "\n", "\n", "", "return", "dec_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Beam.get_hypothesis": [[101, 109], ["range", "list", "hyp.append", "map", "len", "x.item"], "methods", ["None"], ["", "def", "get_hypothesis", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\" Walk back to construct the full hypothesis. \"\"\"", "\n", "hyp", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "item", "(", ")", ",", "hyp", "[", ":", ":", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Translator.__init__": [[114, 121], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "args", ",", "model", ",", "lang", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "lang", "=", "lang", "\n", "self", ".", "vocab_size", "=", "lang", ".", "n_words", "\n", "self", ".", "beam_size", "=", "args", ".", "beam_size", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "args", ".", "USE_CUDA", "else", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Translator.beam_search": [[122, 289], ["common.Translator.beam_search.collect_hypothesis_and_scores"], "methods", ["None"], ["", "def", "beam_search", "(", "self", ",", "batch", ",", "max_dec_step", ")", ":", "\n", "        ", "''' Translation work in one batch '''", "\n", "\n", "def", "get_inst_idx_to_tensor_position_map", "(", "inst_idx_list", ")", ":", "\n", "            ", "''' Indicate the position of an instance in a tensor. '''", "\n", "return", "{", "inst_idx", ":", "tensor_position", "for", "tensor_position", ",", "inst_idx", "in", "enumerate", "(", "inst_idx_list", ")", "}", "\n", "\n", "", "def", "collect_active_part", "(", "beamed_tensor", ",", "curr_active_inst_idx", ",", "n_prev_active_inst", ",", "n_bm", ")", ":", "\n", "            ", "''' Collect tensor parts associated to active instances. '''", "\n", "\n", "_", ",", "*", "d_hs", "=", "beamed_tensor", ".", "size", "(", ")", "\n", "n_curr_active_inst", "=", "len", "(", "curr_active_inst_idx", ")", "\n", "new_shape", "=", "(", "n_curr_active_inst", "*", "n_bm", ",", "*", "d_hs", ")", "\n", "\n", "beamed_tensor", "=", "beamed_tensor", ".", "view", "(", "n_prev_active_inst", ",", "-", "1", ")", "\n", "beamed_tensor", "=", "beamed_tensor", ".", "index_select", "(", "0", ",", "curr_active_inst_idx", ")", "\n", "beamed_tensor", "=", "beamed_tensor", ".", "view", "(", "*", "new_shape", ")", "\n", "\n", "return", "beamed_tensor", "\n", "\n", "", "def", "collate_active_info", "(", "src_seq", ",", "encoder_db", ",", "src_enc", ",", "inst_idx_to_position_map", ",", "active_inst_idx_list", ")", ":", "\n", "# Sentences which are still active are collected,", "\n", "# so the decoder will not run on completed sentences.", "\n", "            ", "n_prev_active_inst", "=", "len", "(", "inst_idx_to_position_map", ")", "\n", "active_inst_idx", "=", "[", "inst_idx_to_position_map", "[", "k", "]", "for", "k", "in", "active_inst_idx_list", "]", "\n", "active_inst_idx", "=", "torch", ".", "LongTensor", "(", "active_inst_idx", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "active_src_seq", "=", "collect_active_part", "(", "src_seq", ",", "active_inst_idx", ",", "n_prev_active_inst", ",", "n_bm", ")", "\n", "active_src_enc", "=", "collect_active_part", "(", "src_enc", ",", "active_inst_idx", ",", "n_prev_active_inst", ",", "n_bm", ")", "\n", "\n", "active_encoder_db", "=", "None", "\n", "\n", "active_inst_idx_to_position_map", "=", "get_inst_idx_to_tensor_position_map", "(", "active_inst_idx_list", ")", "\n", "\n", "return", "active_src_seq", ",", "active_encoder_db", ",", "active_src_enc", ",", "active_inst_idx_to_position_map", "\n", "\n", "", "def", "beam_decode_step", "(", "inst_dec_beams", ",", "len_dec_seq", ",", "src_seq", ",", "enc_output", ",", "inst_idx_to_position_map", ",", "n_bm", ",", "\n", "enc_batch_extend_vocab", ",", "extra_zeros", ",", "mask_src", ",", "encoder_db", ",", "mask_transformer_db", ",", "\n", "DB_ext_vocab_batch", ")", ":", "\n", "            ", "''' Decode and update beam status, and then return active beam idx '''", "\n", "\n", "def", "prepare_beam_dec_seq", "(", "inst_dec_beams", ",", "len_dec_seq", ")", ":", "\n", "                ", "dec_partial_seq", "=", "[", "b", ".", "get_current_state", "(", ")", "for", "b", "in", "inst_dec_beams", "if", "not", "b", ".", "done", "]", "\n", "dec_partial_seq", "=", "torch", ".", "stack", "(", "dec_partial_seq", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dec_partial_seq", "=", "dec_partial_seq", ".", "view", "(", "-", "1", ",", "len_dec_seq", ")", "\n", "return", "dec_partial_seq", "\n", "\n", "", "def", "prepare_beam_dec_pos", "(", "len_dec_seq", ",", "n_active_inst", ",", "n_bm", ")", ":", "\n", "                ", "dec_partial_pos", "=", "torch", ".", "arange", "(", "1", ",", "len_dec_seq", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "dec_partial_pos", "=", "dec_partial_pos", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "n_active_inst", "*", "n_bm", ",", "1", ")", "\n", "return", "dec_partial_pos", "\n", "\n", "", "def", "predict_word", "(", "dec_seq", ",", "dec_pos", ",", "src_seq", ",", "enc_output", ",", "n_active_inst", ",", "n_bm", ",", "enc_batch_extend_vocab", ",", "\n", "extra_zeros", ",", "mask_src", ",", "encoder_db", ",", "mask_transformer_db", ",", "DB_ext_vocab_batch", ")", ":", "\n", "## masking", "\n", "                ", "mask_trg", "=", "dec_seq", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "\n", "mask_src", "=", "torch", ".", "cat", "(", "[", "mask_src", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", "]", "*", "mask_trg", ".", "size", "(", "0", ")", ",", "0", ")", "\n", "dec_output", ",", "attn_dist", "=", "self", ".", "model", ".", "decoder", "(", "self", ".", "model", ".", "embedding", "(", "dec_seq", ")", ",", "enc_output", ",", "\n", "(", "mask_src", ",", "mask_trg", ")", ")", "\n", "\n", "db_dist", "=", "None", "\n", "\n", "prob", "=", "self", ".", "model", ".", "generator", "(", "dec_output", ",", "attn_dist", ",", "enc_batch_extend_vocab", ",", "extra_zeros", ",", "1", ",", "True", ",", "\n", "attn_dist_db", "=", "db_dist", ")", "\n", "# prob = F.log_softmax(prob,dim=-1) #fix the name later", "\n", "word_prob", "=", "prob", "[", ":", ",", "-", "1", "]", "\n", "word_prob", "=", "word_prob", ".", "view", "(", "n_active_inst", ",", "n_bm", ",", "-", "1", ")", "\n", "return", "word_prob", "\n", "\n", "", "def", "collect_active_inst_idx_list", "(", "inst_beams", ",", "word_prob", ",", "inst_idx_to_position_map", ")", ":", "\n", "                ", "active_inst_idx_list", "=", "[", "]", "\n", "for", "inst_idx", ",", "inst_position", "in", "inst_idx_to_position_map", ".", "items", "(", ")", ":", "\n", "                    ", "is_inst_complete", "=", "inst_beams", "[", "inst_idx", "]", ".", "advance", "(", "word_prob", "[", "inst_position", "]", ")", "\n", "if", "not", "is_inst_complete", ":", "\n", "                        ", "active_inst_idx_list", "+=", "[", "inst_idx", "]", "\n", "", "", "return", "active_inst_idx_list", "\n", "\n", "", "n_active_inst", "=", "len", "(", "inst_idx_to_position_map", ")", "\n", "\n", "dec_seq", "=", "prepare_beam_dec_seq", "(", "inst_dec_beams", ",", "len_dec_seq", ")", "\n", "dec_pos", "=", "prepare_beam_dec_pos", "(", "len_dec_seq", ",", "n_active_inst", ",", "n_bm", ")", "\n", "word_prob", "=", "predict_word", "(", "dec_seq", ",", "dec_pos", ",", "src_seq", ",", "enc_output", ",", "n_active_inst", ",", "n_bm", ",", "enc_batch_extend_vocab", ",", "\n", "extra_zeros", ",", "mask_src", ",", "encoder_db", ",", "mask_transformer_db", ",", "DB_ext_vocab_batch", ")", "\n", "\n", "# Update the beam with predicted word prob information and collect incomplete instances", "\n", "active_inst_idx_list", "=", "collect_active_inst_idx_list", "(", "inst_dec_beams", ",", "word_prob", ",", "inst_idx_to_position_map", ")", "\n", "\n", "return", "active_inst_idx_list", "\n", "\n", "", "def", "collect_hypothesis_and_scores", "(", "inst_dec_beams", ",", "n_best", ")", ":", "\n", "            ", "all_hyp", ",", "all_scores", "=", "[", "]", ",", "[", "]", "\n", "for", "inst_idx", "in", "range", "(", "len", "(", "inst_dec_beams", ")", ")", ":", "\n", "                ", "scores", ",", "tail_idxs", "=", "inst_dec_beams", "[", "inst_idx", "]", ".", "sort_scores", "(", ")", "\n", "all_scores", "+=", "[", "scores", "[", ":", "n_best", "]", "]", "\n", "\n", "hyps", "=", "[", "inst_dec_beams", "[", "inst_idx", "]", ".", "get_hypothesis", "(", "i", ")", "for", "i", "in", "tail_idxs", "[", ":", "n_best", "]", "]", "\n", "all_hyp", "+=", "[", "hyps", "]", "\n", "", "return", "all_hyp", ",", "all_scores", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# -- Encode", "\n", "            ", "context_input", "=", "batch", "[", "\"context_batch\"", "]", "# (bsz, max_context_len)", "\n", "concept_input", "=", "batch", "[", "\"concept_batch\"", "]", "# (bsz, max_concept_len)", "\n", "\n", "## Embedding", "\n", "semantic_embed", "=", "self", ".", "model", ".", "embedding", "(", "context_input", ")", "# (bsz, max_context_len, emb_dim)", "\n", "concept_semantic_embed", "=", "self", ".", "model", ".", "embedding", "(", "concept_input", ")", "# (bsz, max_concept_len, emb_dim)", "\n", "\n", "# Knowledge Update", "\n", "concept_context", "=", "self", ".", "model", ".", "concept_graph", "(", "semantic_embed", ",", "concept_semantic_embed", ",", "\n", "batch", "[", "\"adjacency_mask_batch\"", "]", ")", "# (bsz, context+concept, emb_dim)", "\n", "\n", "# Encode", "\n", "concept_context", "=", "concept_context", ".", "transpose", "(", "0", ",", "1", ")", "\n", "concept_context_mask", "=", "torch", ".", "cat", "(", "(", "batch", "[", "\"mask_context\"", "]", ",", "batch", "[", "\"mask_concept\"", "]", ")", ",", "dim", "=", "1", ")", "\n", "concept_context_mask", "=", "concept_context_mask", ".", "transpose", "(", "0", ",", "1", ")", "\n", "context_resp", "=", "self", ".", "model", ".", "encoder", "(", "concept_context", ",", "\n", "concept_context_mask", ")", "# (context_len+concept_len, bsz, emb_dim)", "\n", "\n", "# Identify", "\n", "ROOT_resp", "=", "context_resp", "[", "0", ",", ":", ",", ":", "]", "# (bsz, emb_dim)", "\n", "emotion_logit", "=", "self", ".", "model", ".", "identify", "(", "ROOT_resp", ")", "# (bsz, emotion_num)", "\n", "\n", "encoder_db", "=", "None", "\n", "mask_transformer_db", "=", "None", "\n", "DB_ext_vocab_batch", "=", "None", "\n", "\n", "# -- Repeat data for beam search", "\n", "n_bm", "=", "self", ".", "beam_size", "# 5", "\n", "len_s", ",", "n_inst", ",", "d_h", "=", "context_resp", ".", "size", "(", ")", "# (src_len, bsz, emb_dim)", "\n", "# src_seq = enc_batch.repeat(1, n_bm).view(n_inst * n_bm, len_s)", "\n", "src_enc", "=", "context_resp", ".", "repeat", "(", "1", ",", "n_bm", ",", "1", ")", ".", "view", "(", "n_inst", "*", "n_bm", ",", "len_s", ",", "d_h", ")", "\n", "\n", "\n", "\n", "\n", "\n", "# -- Prepare beams", "\n", "inst_dec_beams", "=", "[", "Beam", "(", "n_bm", ",", "device", "=", "self", ".", "device", ")", "for", "_", "in", "range", "(", "n_inst", ")", "]", "\n", "\n", "# -- Bookkeeping for active or not", "\n", "active_inst_idx_list", "=", "list", "(", "range", "(", "n_inst", ")", ")", "\n", "inst_idx_to_position_map", "=", "get_inst_idx_to_tensor_position_map", "(", "active_inst_idx_list", ")", "\n", "\n", "# -- Decode", "\n", "for", "len_dec_seq", "in", "range", "(", "1", ",", "max_dec_step", "+", "1", ")", ":", "\n", "\n", "                ", "active_inst_idx_list", "=", "beam_decode_step", "(", "inst_dec_beams", ",", "len_dec_seq", ",", "src_seq", ",", "src_enc", ",", "\n", "inst_idx_to_position_map", ",", "n_bm", ",", "None", ",", "\n", "None", ",", "None", ",", "encoder_db", ",", "mask_transformer_db", ",", "\n", "DB_ext_vocab_batch", ")", "\n", "\n", "if", "not", "active_inst_idx_list", ":", "\n", "                    ", "break", "# all instances have finished their path to <EOS>", "\n", "\n", "", "src_seq", ",", "encoder_db", ",", "src_enc", ",", "inst_idx_to_position_map", "=", "collate_active_info", "(", "src_seq", ",", "encoder_db", ",", "\n", "src_enc", ",", "\n", "inst_idx_to_position_map", ",", "\n", "active_inst_idx_list", ")", "\n", "\n", "", "", "batch_hyp", ",", "batch_scores", "=", "collect_hypothesis_and_scores", "(", "inst_dec_beams", ",", "1", ")", "\n", "\n", "ret_sentences", "=", "[", "]", "\n", "for", "d", "in", "batch_hyp", ":", "\n", "            ", "ret_sentences", ".", "append", "(", "' '", ".", "join", "(", "[", "self", ".", "model", ".", "vocab", ".", "index2word", "[", "idx", "]", "for", "idx", "in", "d", "[", "0", "]", "]", ")", ".", "replace", "(", "'EOS'", ",", "''", ")", ")", "\n", "\n", "", "return", "ret_sentences", "# , batch_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.LabelSmoothing.__init__": [[562, 570], ["torch.Module.__init__", "torch.KLDivLoss", "torch.KLDivLoss", "torch.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "padding_idx", ",", "smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "LabelSmoothing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'sum'", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "true_dist", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.LabelSmoothing.forward": [[571, 582], ["x.data.clone", "x.data.clone.fill_", "x.data.clone.scatter_", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "common.LabelSmoothing.criterion", "x.size", "target.data.unsqueeze", "x.data.clone.index_fill_", "torch.nonzero.size", "torch.nonzero.size", "torch.nonzero.size", "torch.nonzero.squeeze", "torch.nonzero.squeeze", "torch.nonzero.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "assert", "x", ".", "size", "(", "1", ")", "==", "self", ".", "size", "\n", "true_dist", "=", "x", ".", "data", ".", "clone", "(", ")", "\n", "true_dist", ".", "fill_", "(", "self", ".", "smoothing", "/", "(", "self", ".", "size", "-", "2", ")", ")", "\n", "true_dist", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "true_dist", "[", ":", ",", "self", ".", "padding_idx", "]", "=", "0", "\n", "mask", "=", "torch", ".", "nonzero", "(", "target", ".", "data", "==", "self", ".", "padding_idx", ")", "\n", "if", "mask", ".", "size", "(", ")", "[", "0", "]", ">", "0", ":", "\n", "            ", "true_dist", ".", "index_fill_", "(", "0", ",", "mask", ".", "squeeze", "(", ")", ",", "0.0", ")", "\n", "", "self", ".", "true_dist", "=", "true_dist", "\n", "return", "self", ".", "criterion", "(", "x", ",", "true_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Embeddings.__init__": [[594, 598], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "d_model", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lut", "=", "nn", ".", "Embedding", "(", "vocab", ",", "d_model", ",", "padding_idx", "=", "padding_idx", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.Embeddings.forward": [[599, 601], ["common.Embeddings.lut", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "lut", "(", "x", ")", "*", "math", ".", "sqrt", "(", "self", ".", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.NoamOpt.__init__": [[635, 642], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_size", ",", "factor", ",", "warmup", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "warmup", "=", "warmup", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "model_size", "=", "model_size", "\n", "self", ".", "_rate", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.NoamOpt.state_dict": [[643, 645], ["common.NoamOpt.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.NoamOpt.step": [[646, 654], ["common.NoamOpt.rate", "common.NoamOpt.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.rate", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Update parameters and rate\"", "\n", "self", ".", "_step", "+=", "1", "\n", "rate", "=", "self", ".", "rate", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "p", "[", "'lr'", "]", "=", "rate", "\n", "", "self", ".", "_rate", "=", "rate", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.NoamOpt.rate": [[655, 662], ["min"], "methods", ["None"], ["", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"Implement `lrate` above\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "", "return", "self", ".", "factor", "*", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "self", ".", "warmup", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.print_custum": [[291, 300], ["print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "", "def", "print_custum", "(", "emotion", ",", "dial", ",", "concept", ",", "ref", ",", "hyp_g", ",", "hyp_b", ")", ":", "\n", "    ", "print", "(", "\"Emotion:{}\"", ".", "format", "(", "emotion", ")", ")", "\n", "print", "(", "\"Context:{}\"", ".", "format", "(", "dial", ")", ")", "\n", "print", "(", "\"Concept:{}\"", ".", "format", "(", "concept", ")", ")", "\n", "print", "(", "\"Beam: {}\"", ".", "format", "(", "hyp_b", ")", ")", "\n", "print", "(", "\"Greedy:{}\"", ".", "format", "(", "hyp_g", ")", ")", "\n", "print", "(", "\"Ref:{}\"", ".", "format", "(", "ref", ")", ")", "\n", "print", "(", "\"----------------------------------------------------------------------\"", ")", "\n", "print", "(", "\"----------------------------------------------------------------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.sequence_mask": [[302, 314], ["sequence_length.size", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long.unsqueeze().expand", "sequence_length.unsqueeze().expand_as", "sequence_length.data.max", "seq_range_expand.to.to", "torch.arange", "torch.arange", "torch.arange", "torch.arange().long.unsqueeze", "sequence_length.unsqueeze"], "function", ["None"], ["", "def", "sequence_mask", "(", "args", ",", "sequence_length", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "if", "max_len", "is", "None", ":", "\n", "        ", "max_len", "=", "sequence_length", ".", "data", ".", "max", "(", ")", "\n", "", "batch_size", "=", "sequence_length", ".", "size", "(", "0", ")", "\n", "seq_range", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "long", "(", ")", "\n", "seq_range_expand", "=", "seq_range", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", "\n", "seq_range_expand", "=", "seq_range_expand", "\n", "if", "sequence_length", ".", "is_cuda", ":", "\n", "        ", "seq_range_expand", "=", "seq_range_expand", ".", "to", "(", "args", ".", "device", ")", "\n", "", "seq_length_expand", "=", "(", "sequence_length", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand_as", "(", "seq_range_expand", ")", ")", "\n", "return", "seq_range_expand", "<", "seq_length_expand", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.distinctEval": [[316, 330], ["set", "set", "sum", "list", "len", "len", "len", "len", "set.add", "nltk.bigrams", "set.add"], "function", ["None"], ["", "def", "distinctEval", "(", "preds", ")", ":", "\n", "    ", "response_ugm", "=", "set", "(", "[", "]", ")", "\n", "response_bgm", "=", "set", "(", "[", "]", ")", "\n", "response_len", "=", "sum", "(", "[", "len", "(", "p", ")", "for", "p", "in", "preds", "]", ")", "\n", "\n", "for", "path", "in", "preds", ":", "\n", "        ", "for", "u", "in", "path", ":", "\n", "            ", "response_ugm", ".", "add", "(", "u", ")", "\n", "", "for", "b", "in", "list", "(", "nltk", ".", "bigrams", "(", "path", ")", ")", ":", "\n", "            ", "response_bgm", ".", "add", "(", "b", ")", "\n", "", "", "response_len_ave", "=", "response_len", "/", "len", "(", "preds", ")", "\n", "distinctOne", "=", "len", "(", "response_ugm", ")", "/", "response_len", "\n", "distinctTwo", "=", "len", "(", "response_bgm", ")", "/", "response_len", "\n", "return", "distinctOne", ",", "distinctTwo", ",", "response_len_ave", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.get_dist": [[332, 356], ["res.items", "len", "len", "len", "float", "len", "float", "bgs.append", "len", "float", "len", "float", "set", "len", "set", "len", "len", "set", "set", "len", "len"], "function", ["None"], ["", "def", "get_dist", "(", "res", ")", ":", "\n", "    ", "unigrams", "=", "[", "]", "\n", "bigrams", "=", "[", "]", "\n", "avg_len", "=", "0.", "\n", "ma_dist1", ",", "ma_dist2", "=", "0.", ",", "0.", "\n", "for", "q", ",", "r", "in", "res", ".", "items", "(", ")", ":", "\n", "        ", "ugs", "=", "r", "\n", "bgs", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "ugs", ")", "-", "1", ":", "\n", "            ", "bgs", ".", "append", "(", "ugs", "[", "i", "]", "+", "ugs", "[", "i", "+", "1", "]", ")", "\n", "i", "+=", "1", "\n", "", "unigrams", "+=", "ugs", "\n", "bigrams", "+=", "bgs", "\n", "ma_dist1", "+=", "len", "(", "set", "(", "ugs", ")", ")", "/", "(", "float", ")", "(", "len", "(", "ugs", ")", "+", "1e-16", ")", "\n", "ma_dist2", "+=", "len", "(", "set", "(", "bgs", ")", ")", "/", "(", "float", ")", "(", "len", "(", "bgs", ")", "+", "1e-16", ")", "\n", "avg_len", "+=", "len", "(", "ugs", ")", "\n", "", "n", "=", "len", "(", "res", ")", "\n", "ma_dist1", "/=", "n", "\n", "ma_dist2", "/=", "n", "\n", "mi_dist1", "=", "len", "(", "set", "(", "unigrams", ")", ")", "/", "(", "float", ")", "(", "len", "(", "unigrams", ")", ")", "\n", "mi_dist2", "=", "len", "(", "set", "(", "bigrams", ")", ")", "/", "(", "float", ")", "(", "len", "(", "bigrams", ")", ")", "\n", "avg_len", "/=", "n", "\n", "return", "ma_dist1", ",", "ma_dist2", ",", "mi_dist1", ",", "mi_dist2", ",", "avg_len", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common._get_ngrams": [[358, 376], ["collections.Counter", "range", "range", "tuple", "len"], "function", ["None"], ["", "def", "_get_ngrams", "(", "segment", ",", "max_order", ")", ":", "\n", "    ", "\"\"\"Extracts all n-grams upto a given maximum order from an input segment.\n\n    Args:\n      segment: text segment from which n-grams will be extracted.\n      max_order: maximum length in tokens of the n-grams returned by this\n          methods.\n\n    Returns:\n      The Counter containing all n-grams upto max_order in segment\n      with a count of how many times each n-gram occurred.\n    \"\"\"", "\n", "ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "segment", ")", "-", "order", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "segment", "[", "i", ":", "i", "+", "order", "]", ")", "\n", "ngram_counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "ngram_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.compute_bleu": [[378, 442], ["zip", "range", "min", "len", "collections.Counter", "common._get_ngrams", "range", "min", "sum", "math.exp", "float", "math.exp", "common._get_ngrams", "len", "len", "float", "math.log", "len"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.common._get_ngrams", "home.repos.pwc.inspect_result.qtli_kemp.code.common._get_ngrams"], ["", "def", "compute_bleu", "(", "reference_corpus", ",", "translation_corpus", ",", "max_order", "=", "4", ",", "smooth", "=", "False", ")", ":", "\n", "    ", "\"\"\"Computes BLEU score of translated segments against one or more references.\n\n    Args:\n      reference_corpus: list of lists of references for each translation. Each\n          reference should be tokenized into a list of tokens.\n      translation_corpus: list of translations to score. Each translation\n          should be tokenized into a list of tokens.\n      max_order: Maximum n-gram order to use when computing BLEU score.\n      smooth: Whether or not to apply Lin et al. 2004 smoothing.\n\n    Returns:\n      3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n      precisions and brevity penalty.\n    \"\"\"", "\n", "matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "possible_matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "reference_length", "=", "0", "\n", "translation_length", "=", "0", "\n", "for", "(", "references", ",", "translation", ")", "in", "zip", "(", "reference_corpus", ",", "\n", "translation_corpus", ")", ":", "\n", "        ", "reference_length", "+=", "min", "(", "len", "(", "r", ")", "for", "r", "in", "references", ")", "\n", "translation_length", "+=", "len", "(", "translation", ")", "\n", "\n", "merged_ref_ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "reference", "in", "references", ":", "\n", "            ", "merged_ref_ngram_counts", "|=", "_get_ngrams", "(", "reference", ",", "max_order", ")", "\n", "", "translation_ngram_counts", "=", "_get_ngrams", "(", "translation", ",", "max_order", ")", "\n", "overlap", "=", "translation_ngram_counts", "&", "merged_ref_ngram_counts", "\n", "for", "ngram", "in", "overlap", ":", "\n", "            ", "matches_by_order", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "overlap", "[", "ngram", "]", "\n", "", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "            ", "possible_matches", "=", "len", "(", "translation", ")", "-", "order", "+", "1", "\n", "if", "possible_matches", ">", "0", ":", "\n", "                ", "possible_matches_by_order", "[", "order", "-", "1", "]", "+=", "possible_matches", "\n", "\n", "", "", "", "precisions", "=", "[", "0", "]", "*", "max_order", "\n", "for", "i", "in", "range", "(", "0", ",", "max_order", ")", ":", "\n", "        ", "if", "smooth", ":", "\n", "            ", "precisions", "[", "i", "]", "=", "(", "(", "matches_by_order", "[", "i", "]", "+", "1.", ")", "/", "\n", "(", "possible_matches_by_order", "[", "i", "]", "+", "1.", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "possible_matches_by_order", "[", "i", "]", ">", "0", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "(", "float", "(", "matches_by_order", "[", "i", "]", ")", "/", "\n", "possible_matches_by_order", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "0.0", "\n", "\n", "", "", "", "if", "min", "(", "precisions", ")", ">", "0", ":", "\n", "        ", "p_log_sum", "=", "sum", "(", "(", "1.", "/", "max_order", ")", "*", "math", ".", "log", "(", "p", ")", "for", "p", "in", "precisions", ")", "\n", "geo_mean", "=", "math", ".", "exp", "(", "p_log_sum", ")", "\n", "", "else", ":", "\n", "        ", "geo_mean", "=", "0", "\n", "\n", "", "ratio", "=", "float", "(", "translation_length", ")", "/", "reference_length", "\n", "\n", "if", "ratio", ">", "1.0", ":", "\n", "        ", "bp", "=", "1.", "\n", "", "else", ":", "\n", "        ", "bp", "=", "math", ".", "exp", "(", "1", "-", "1.", "/", "(", "ratio", "+", "1e-16", ")", ")", "\n", "\n", "", "bleu", "=", "geo_mean", "*", "bp", "\n", "\n", "return", "(", "bleu", ",", "precisions", ",", "bp", ",", "ratio", ",", "translation_length", ",", "reference_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.get_bleu": [[444, 476], ["res.items", "len", "common.compute_bleu", "len", "len", "ref_lst.append", "hyp_lst.append", "common.compute_bleu"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.common.compute_bleu", "home.repos.pwc.inspect_result.qtli_kemp.code.common.compute_bleu"], ["", "def", "get_bleu", "(", "res", ",", "gdn", ")", ":", "\n", "    ", "assert", "len", "(", "res", ")", "==", "len", "(", "gdn", ")", "\n", "\n", "ma_bleu", "=", "0.", "\n", "ma_bleu1", "=", "0.", "\n", "ma_bleu2", "=", "0.", "\n", "ma_bleu3", "=", "0.", "\n", "ma_bleu4", "=", "0.", "\n", "ref_lst", "=", "[", "]", "\n", "hyp_lst", "=", "[", "]", "\n", "for", "q", ",", "r", "in", "res", ".", "items", "(", ")", ":", "\n", "        ", "references", "=", "gdn", "[", "q", "]", "\n", "hypothesis", "=", "r", "\n", "ref_lst", ".", "append", "(", "references", ")", "\n", "hyp_lst", ".", "append", "(", "hypothesis", ")", "\n", "bleu", ",", "precisions", ",", "_", ",", "_", ",", "_", ",", "_", "=", "compute_bleu", "(", "[", "references", "]", ",", "[", "hypothesis", "]", ",", "smooth", "=", "False", ")", "\n", "ma_bleu", "+=", "bleu", "\n", "ma_bleu1", "+=", "precisions", "[", "0", "]", "\n", "ma_bleu2", "+=", "precisions", "[", "1", "]", "\n", "ma_bleu3", "+=", "precisions", "[", "2", "]", "\n", "ma_bleu4", "+=", "precisions", "[", "3", "]", "\n", "", "n", "=", "len", "(", "res", ")", "\n", "ma_bleu", "/=", "n", "\n", "ma_bleu1", "/=", "n", "\n", "ma_bleu2", "/=", "n", "\n", "ma_bleu3", "/=", "n", "\n", "ma_bleu4", "/=", "n", "\n", "\n", "mi_bleu", ",", "precisions", ",", "_", ",", "_", ",", "_", ",", "_", "=", "compute_bleu", "(", "ref_lst", ",", "hyp_lst", ",", "smooth", "=", "False", ")", "\n", "mi_bleu1", ",", "mi_bleu2", ",", "mi_bleu3", ",", "mi_bleu4", "=", "precisions", "[", "0", "]", ",", "precisions", "[", "1", "]", ",", "precisions", "[", "2", "]", ",", "precisions", "[", "3", "]", "\n", "return", "ma_bleu", ",", "ma_bleu1", ",", "ma_bleu2", ",", "ma_bleu3", ",", "ma_bleu4", ",", "mi_bleu", ",", "mi_bleu1", ",", "mi_bleu2", ",", "mi_bleu3", ",", "mi_bleu4", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.evaluate": [[478, 555], ["os.path.join", "open", "model.to.eval", "model.to.to", "tqdm.tqdm", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "print", "print", "os.path.exists", "os.makedirs", "os.path.join", "print", "enumerate", "model.to.train_one_batch", "l.append", "p.append", "np.mean.append", "np.mean.append", "tqdm.tqdm.set_description", "common.get_dist", "common.get_bleu", "print", "print", "print", "print", "print", "print", "math.exp", "len", "model.to.decoder_greedy", "enumerate", "math.exp", "hyp_g.append", "ref.append", "greedy_sent.split", "common.print_custum", "open.write", "open.write", "open.write", "open.write", "open.write", "numpy.mean", "math.exp", "numpy.mean", "str"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.train_one_batch", "home.repos.pwc.inspect_result.qtli_kemp.code.common.get_dist", "home.repos.pwc.inspect_result.qtli_kemp.code.common.get_bleu", "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.decoder_greedy", "home.repos.pwc.inspect_result.qtli_kemp.code.common.print_custum"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "data", ",", "ty", "=", "'valid'", ",", "max_dec_step", "=", "30", ",", "print_file", "=", "None", ")", ":", "\n", "    ", "pred_save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'prediction'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "pred_save_path", ")", "is", "False", ":", "\n", "        ", "os", ".", "makedirs", "(", "pred_save_path", ")", "\n", "", "outputs", "=", "open", "(", "os", ".", "path", ".", "join", "(", "pred_save_path", ",", "'output.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "model", "=", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "__id__logger", "=", "0", "\n", "ref", ",", "hyp_g", ",", "hyp_b", ",", "hyp_t", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "ty", "==", "\"test\"", ":", "\n", "        ", "print", "(", "\"testing generation:\"", ",", "file", "=", "print_file", ")", "\n", "", "l", "=", "[", "]", "\n", "p", "=", "[", "]", "\n", "bce", "=", "[", "]", "\n", "acc", "=", "[", "]", "\n", "res", "=", "{", "}", "\n", "gdn", "=", "{", "}", "\n", "itr", "=", "0", "\n", "pbar", "=", "tqdm", "(", "enumerate", "(", "data", ")", ",", "total", "=", "len", "(", "data", ")", ")", "\n", "for", "j", ",", "batch", "in", "pbar", ":", "\n", "        ", "loss", ",", "ppl", ",", "bce_prog", ",", "acc_prog", "=", "model", ".", "train_one_batch", "(", "batch", ",", "0", ",", "train", "=", "False", ")", "\n", "l", ".", "append", "(", "loss", ")", "\n", "p", ".", "append", "(", "ppl", ")", "\n", "bce", ".", "append", "(", "bce_prog", ")", "\n", "acc", ".", "append", "(", "acc_prog", ")", "\n", "if", "ty", "==", "\"test\"", ":", "\n", "            ", "sent_g", "=", "model", ".", "decoder_greedy", "(", "batch", ",", "max_dec_step", "=", "max_dec_step", ")", "# sentences list, each sentence is a string.", "\n", "for", "i", ",", "greedy_sent", "in", "enumerate", "(", "sent_g", ")", ":", "\n", "                ", "rf", "=", "\" \"", ".", "join", "(", "batch", "[", "\"target_txt\"", "]", "[", "i", "]", ")", "\n", "hyp_g", ".", "append", "(", "greedy_sent", ")", "\n", "ref", ".", "append", "(", "rf", ")", "\n", "res", "[", "itr", "]", "=", "greedy_sent", ".", "split", "(", ")", "\n", "gdn", "[", "itr", "]", "=", "batch", "[", "\"target_txt\"", "]", "[", "i", "]", "# targets.split()", "\n", "itr", "+=", "1", "\n", "print_custum", "(", "emotion", "=", "batch", "[", "\"emotion_txt\"", "]", "[", "i", "]", ",", "\n", "dial", "=", "[", "\" \"", ".", "join", "(", "s", ")", "for", "s", "in", "batch", "[", "'context_txt'", "]", "[", "i", "]", "]", ",", "\n", "concept", "=", "str", "(", "batch", "[", "'concept_txt'", "]", "[", "i", "]", ")", ",", "\n", "ref", "=", "rf", ",", "\n", "hyp_g", "=", "greedy_sent", ",", "\n", "hyp_b", "=", "[", "]", ")", "\n", "outputs", ".", "write", "(", "\"Emotion:{} \\n\"", ".", "format", "(", "batch", "[", "\"emotion_txt\"", "]", "[", "i", "]", ")", ")", "\n", "outputs", ".", "write", "(", "\"Context:{} \\n\"", ".", "format", "(", "\n", "[", "\" \"", ".", "join", "(", "s", ")", "for", "s", "in", "batch", "[", "'context_txt'", "]", "[", "i", "]", "]", ")", ")", "\n", "outputs", ".", "write", "(", "\"Concept:{} \\n\"", ".", "format", "(", "batch", "[", "\"concept_txt\"", "]", ")", ")", "\n", "outputs", ".", "write", "(", "\"Pred:{} \\n\"", ".", "format", "(", "greedy_sent", ")", ")", "\n", "outputs", ".", "write", "(", "\"Ref:{} \\n\"", ".", "format", "(", "rf", ")", ")", "\n", "\n", "", "", "pbar", ".", "set_description", "(", "\"loss:{:.4f} ppl:{:.1f}\"", ".", "format", "(", "np", ".", "mean", "(", "l", ")", ",", "math", ".", "exp", "(", "np", ".", "mean", "(", "l", ")", ")", ")", ")", "\n", "\n", "", "loss", "=", "np", ".", "mean", "(", "l", ")", "\n", "ppl", "=", "np", ".", "mean", "(", "p", ")", "\n", "bce", "=", "np", ".", "mean", "(", "bce", ")", "\n", "acc", "=", "np", ".", "mean", "(", "acc", ")", "\n", "\n", "if", "ty", "==", "\"test\"", ":", "\n", "        ", "ma_dist1", ",", "ma_dist2", ",", "mi_dist1", ",", "mi_dist2", ",", "avg_len", "=", "get_dist", "(", "res", ")", "# ma_dist1, ma_dist2, mi_dist1, mi_dist2, avg_len", "\n", "ma_bleu", ",", "ma_bleu1", ",", "ma_bleu2", ",", "ma_bleu3", ",", "ma_bleu4", ",", "mi_bleu", ",", "mi_bleu1", ",", "mi_bleu2", ",", "mi_bleu3", ",", "mi_bleu4", "=", "get_bleu", "(", "res", ",", "gdn", ")", "\n", "\n", "", "print", "(", "\"EVAL\\tLoss\\tPPL\\tAccuracy\"", ",", "file", "=", "print_file", ")", "\n", "print", "(", "\n", "\"{}\\t{:.4f}\\t{:.4f}\\t{:.4f}\"", ".", "format", "(", "ty", ",", "loss", ",", "math", ".", "exp", "(", "loss", ")", ",", "acc", ")", ",", "file", "=", "print_file", ")", "\n", "\n", "if", "ty", "==", "\"test\"", ":", "\n", "        ", "print", "(", "\"ma_dist1\\tma_dist2\\tmi_dist1\\tmi_dist2\\tavg_len\"", ",", "file", "=", "print_file", ")", "\n", "print", "(", "\n", "\"{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\"", ".", "format", "(", "ma_dist1", ",", "ma_dist2", ",", "mi_dist1", ",", "mi_dist2", ",", "avg_len", ")", ",", "\n", "file", "=", "print_file", ")", "\n", "print", "(", "\"ma_bleu\\tma_bleu1\\tma_bleu2\\tma_bleu3\\tma_bleu4\"", ",", "file", "=", "print_file", ")", "\n", "print", "(", "\n", "\"{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\"", ".", "format", "(", "ma_bleu", ",", "ma_bleu1", ",", "ma_bleu2", ",", "ma_bleu3", ",", "ma_bleu4", ")", ",", "file", "=", "print_file", ")", "\n", "\n", "print", "(", "\"mi_bleu\\tmi_bleu1\\tmi_bleu2\\tmi_bleu3\\tmi_bleu4\"", ",", "file", "=", "print_file", ")", "\n", "print", "(", "\n", "\"{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\"", ".", "format", "(", "mi_bleu", ",", "mi_bleu1", ",", "mi_bleu2", ",", "mi_bleu3", ",", "mi_bleu4", ")", ",", "file", "=", "print_file", ")", "\n", "\n", "", "return", "loss", ",", "math", ".", "exp", "(", "loss", ")", ",", "bce", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.count_parameters": [[556, 558], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.gleu": [[584, 587], ["torch.erf", "torch.erf", "torch.erf", "math.sqrt"], "function", ["None"], ["", "", "def", "gleu", "(", "x", ")", ":", "\n", "    ", "cdf", "=", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "cdf", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.make_infinite": [[588, 592], ["None"], "function", ["None"], ["", "def", "make_infinite", "(", "dataloader", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "for", "x", "in", "dataloader", ":", "\n", "            ", "yield", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.gen_embeddings": [[602, 623], ["print", "numpy.random.randn", "print", "open().readlines", "print", "line.split", "open", "len", "print", "float"], "function", ["None"], ["", "", "def", "gen_embeddings", "(", "args", ",", "n_words", ",", "word2index", ")", ":", "\n", "    ", "\"\"\"\n        Generate an initial embedding matrix for `word_dict`.\n        If an embedding file is not given or a word is not in the embedding file,\n        a randomly initialized vector will be used.\n    \"\"\"", "\n", "embeddings", "=", "np", ".", "random", ".", "randn", "(", "n_words", ",", "args", ".", "emb_dim", ")", "*", "0.01", "\n", "print", "(", "'Embeddings: %d x %d'", "%", "(", "n_words", ",", "args", ".", "emb_dim", ")", ")", "\n", "if", "args", ".", "emb_file", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading embedding file: %s'", "%", "args", ".", "emb_file", ")", "\n", "pre_trained", "=", "0", "\n", "for", "line", "in", "open", "(", "args", ".", "emb_file", ")", ".", "readlines", "(", ")", ":", "\n", "            ", "sp", "=", "line", ".", "split", "(", ")", "\n", "if", "(", "len", "(", "sp", ")", "==", "args", ".", "emb_dim", "+", "1", ")", ":", "\n", "                ", "if", "sp", "[", "0", "]", "in", "word2index", ":", "\n", "                    ", "pre_trained", "+=", "1", "\n", "embeddings", "[", "word2index", "[", "sp", "[", "0", "]", "]", "]", "=", "[", "float", "(", "x", ")", "for", "x", "in", "sp", "[", "1", ":", "]", "]", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "sp", "[", "0", "]", ")", "\n", "", "", "print", "(", "'Pre-trained: %d (%.2f%%)'", "%", "(", "pre_trained", ",", "pre_trained", "*", "100.0", "/", "n_words", ")", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.share_embedding": [[624, 631], ["common.Embeddings", "common.gen_embeddings", "Embeddings.lut.weight.data.copy_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.gen_embeddings"], ["", "def", "share_embedding", "(", "args", ",", "n_words", ",", "word2index", ",", "pretrain", "=", "True", ")", ":", "\n", "    ", "embedding", "=", "Embeddings", "(", "n_words", ",", "args", ".", "emb_dim", ",", "padding_idx", "=", "args", ".", "PAD_idx", ")", "\n", "if", "pretrain", ":", "\n", "        ", "pre_embedding", "=", "gen_embeddings", "(", "args", ",", "n_words", ",", "word2index", ")", "\n", "embedding", ".", "lut", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "FloatTensor", "(", "pre_embedding", ")", ")", "\n", "embedding", ".", "lut", ".", "weight", ".", "data", ".", "requires_grad", "=", "True", "\n", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common.wordlist2oov": [[663, 676], ["ids.append", "oovs.index", "ids.append", "oovs.append"], "function", ["None"], ["", "", "def", "wordlist2oov", "(", "args", ",", "src_words", ")", ":", "\n", "    ", "ids", "=", "[", "]", "# store vocab ids and oov ids", "\n", "oovs", "=", "[", "]", "# store oov word in the src", "\n", "for", "w", "in", "src_words", ":", "\n", "        ", "if", "w", "in", "args", ".", "w2id", ":", "\n", "            ", "i", "=", "args", ".", "w2id", "[", "w", "]", "\n", "ids", ".", "append", "(", "i", ")", "\n", "", "else", ":", "# If w is OOV", "\n", "            ", "if", "w", "not", "in", "oovs", ":", "# Add to list of OOVs", "\n", "                ", "oovs", ".", "append", "(", "w", ")", "\n", "", "oov_num", "=", "oovs", ".", "index", "(", "w", ")", "# This is 0 for the first article OOV, 1 for the second article OOV...", "\n", "ids", ".", "append", "(", "args", ".", "vocab_size", "+", "oov_num", ")", "# This is e.g. 50000 for the first article OOV, 50001 for the second...", "\n", "", "", "return", "ids", ",", "oovs", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.EncoderLayer.__init__": [[30, 57], ["torch.Module.__init__", "common_layer.MultiHeadAttention", "common_layer.PositionwiseFeedForward", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "common_layer.LayerNorm", "common_layer.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "total_key_depth", ",", "total_value_depth", ",", "filter_size", ",", "num_heads", ",", "\n", "bias_mask", "=", "None", ",", "layer_dropout", "=", "0.0", ",", "attention_dropout", "=", "0.0", ",", "relu_dropout", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            hidden_size: Hidden size\n            total_key_depth: Size of last dimension of keys. Must be divisible by num_head\n            total_value_depth: Size of last dimension of values. Must be divisible by num_head\n            output_depth: Size last dimension of the final output\n            filter_size: Hidden size of the middle layer in FFN\n            num_heads: Number of attention heads\n            bias_mask: Masking tensor to prevent connections to future elements\n            layer_dropout: Dropout for this layer\n            attention_dropout: Dropout probability after attention (Should be non-zero only during training)\n            relu_dropout: Dropout probability after relu in FFN (Should be non-zero only during training)\n        \"\"\"", "\n", "\n", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "multi_head_attention", "=", "MultiHeadAttention", "(", "hidden_size", ",", "total_key_depth", ",", "total_value_depth", ",", "\n", "hidden_size", ",", "num_heads", ",", "bias_mask", ",", "attention_dropout", ")", "\n", "\n", "self", ".", "positionwise_feed_forward", "=", "PositionwiseFeedForward", "(", "hidden_size", ",", "filter_size", ",", "hidden_size", ",", "\n", "layer_config", "=", "'cc'", ",", "padding", "=", "'both'", ",", "\n", "dropout", "=", "relu_dropout", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "layer_dropout", ")", "\n", "self", ".", "layer_norm_mha", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "self", ".", "layer_norm_ffn", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "# self.layer_norm_end = LayerNorm(hidden_size)", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.EncoderLayer.forward": [[59, 82], ["common_layer.EncoderLayer.layer_norm_mha", "common_layer.EncoderLayer.multi_head_attention", "common_layer.EncoderLayer.dropout", "common_layer.EncoderLayer.layer_norm_ffn", "common_layer.EncoderLayer.positionwise_feed_forward", "common_layer.EncoderLayer.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "\n", "# Layer Normalization", "\n", "x_norm", "=", "self", ".", "layer_norm_mha", "(", "x", ")", "\n", "\n", "# Multi-head attention", "\n", "y", ",", "_", "=", "self", ".", "multi_head_attention", "(", "x_norm", ",", "x_norm", ",", "x_norm", ",", "mask", ")", "\n", "\n", "# Dropout and residual", "\n", "x", "=", "self", ".", "dropout", "(", "x", "+", "y", ")", "\n", "\n", "# Layer Normalization", "\n", "x_norm", "=", "self", ".", "layer_norm_ffn", "(", "x", ")", "\n", "\n", "# Positionwise Feedforward", "\n", "y", "=", "self", ".", "positionwise_feed_forward", "(", "x_norm", ")", "\n", "\n", "# Dropout and residual", "\n", "y", "=", "self", ".", "dropout", "(", "x", "+", "y", ")", "\n", "\n", "# y = self.layer_norm_end(y)", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.GraphLayer.__init__": [[91, 119], ["torch.Module.__init__", "common_layer.MultiHeadAttention", "common_layer.PositionwiseFeedForward", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "common_layer.LayerNorm", "common_layer.LayerNorm", "common_layer.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "total_key_depth", ",", "total_value_depth", ",", "filter_size", ",", "num_heads", ",", "\n", "bias_mask", ",", "layer_dropout", "=", "0.0", ",", "attention_dropout", "=", "0.0", ",", "relu_dropout", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            hidden_size: Hidden size\n            total_key_depth: Size of last dimension of keys. Must be divisible by num_head\n            total_value_depth: Size of last dimension of values. Must be divisible by num_head\n            output_depth: Size last dimension of the final output\n            filter_size: Hidden size of the middle layer in FFN\n            num_heads: Number of attention heads\n            bias_mask: Masking tensor to prevent connections to future elements\n            layer_dropout: Dropout for this layer\n            attention_dropout: Dropout probability after attention (Should be non-zero only during training)\n            relu_dropout: Dropout probability after relu in FFN (Should be non-zero only during training)\n        \"\"\"", "\n", "\n", "super", "(", "GraphLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "multi_head_attention_enc_dec", "=", "MultiHeadAttention", "(", "hidden_size", ",", "total_key_depth", ",", "total_value_depth", ",", "\n", "hidden_size", ",", "num_heads", ",", "None", ",", "attention_dropout", ")", "\n", "\n", "self", ".", "positionwise_feed_forward", "=", "PositionwiseFeedForward", "(", "hidden_size", ",", "filter_size", ",", "hidden_size", ",", "\n", "layer_config", "=", "'cc'", ",", "padding", "=", "'left'", ",", "\n", "dropout", "=", "relu_dropout", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "layer_dropout", ")", "\n", "self", ".", "layer_norm_mha_dec", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "self", ".", "layer_norm_mha_enc", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "self", ".", "layer_norm_ffn", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "# self.layer_norm_end = LayerNorm(hidden_size)", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.GraphLayer.forward": [[121, 150], ["common_layer.GraphLayer.layer_norm_mha_enc", "common_layer.GraphLayer.multi_head_attention_enc_dec", "common_layer.GraphLayer.dropout", "common_layer.GraphLayer.layer_norm_ffn", "common_layer.GraphLayer.positionwise_feed_forward", "common_layer.GraphLayer.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: Inputs is a tuple consisting of decoder inputs and encoder output\n        \"\"\"", "\n", "\n", "x", ",", "encoder_outputs", ",", "attention_weight", ",", "mask_src", "=", "inputs", "\n", "\n", "# Layer Normalization before encoder-decoder attention", "\n", "x_norm", "=", "self", ".", "layer_norm_mha_enc", "(", "x", ")", "\n", "\n", "# Multi-head encoder-decoder attention", "\n", "y", ",", "attention_weight", "=", "self", ".", "multi_head_attention_enc_dec", "(", "x_norm", ",", "encoder_outputs", ",", "encoder_outputs", ",", "mask_src", ")", "\n", "\n", "# Dropout and residual after encoder-decoder attention", "\n", "x", "=", "self", ".", "dropout", "(", "x", "+", "y", ")", "\n", "\n", "# Layer Normalization", "\n", "x_norm", "=", "self", ".", "layer_norm_ffn", "(", "x", ")", "\n", "\n", "# Positionwise Feedforward", "\n", "y", "=", "self", ".", "positionwise_feed_forward", "(", "x_norm", ")", "\n", "\n", "# Dropout and residual after positionwise feed forward layer", "\n", "y", "=", "self", ".", "dropout", "(", "x", "+", "y", ")", "\n", "\n", "# y = self.layer_norm_end(y)", "\n", "\n", "# Return encoder outputs as well to work with nn.Sequential", "\n", "return", "y", ",", "encoder_outputs", ",", "attention_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.DecoderLayer.__init__": [[159, 190], ["torch.Module.__init__", "common_layer.MultiHeadAttention", "common_layer.MultiHeadAttention", "common_layer.PositionwiseFeedForward", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "common_layer.LayerNorm", "common_layer.LayerNorm", "common_layer.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "hidden_size", ",", "total_key_depth", ",", "total_value_depth", ",", "filter_size", ",", "num_heads", ",", "\n", "bias_mask", ",", "layer_dropout", "=", "0.0", ",", "attention_dropout", "=", "0.0", ",", "relu_dropout", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            hidden_size: Hidden size\n            total_key_depth: Size of last dimension of keys. Must be divisible by num_head\n            total_value_depth: Size of last dimension of values. Must be divisible by num_head\n            output_depth: Size last dimension of the final output\n            filter_size: Hidden size of the middle layer in FFN\n            num_heads: Number of attention heads\n            bias_mask: Masking tensor to prevent connections to future elements\n            layer_dropout: Dropout for this layer\n            attention_dropout: Dropout probability after attention (Should be non-zero only during training)\n            relu_dropout: Dropout probability after relu in FFN (Should be non-zero only during training)\n        \"\"\"", "\n", "\n", "super", "(", "DecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "multi_head_attention_dec", "=", "MultiHeadAttention", "(", "hidden_size", ",", "total_key_depth", ",", "total_value_depth", ",", "\n", "hidden_size", ",", "num_heads", ",", "bias_mask", ",", "attention_dropout", ")", "\n", "\n", "self", ".", "multi_head_attention_enc_dec", "=", "MultiHeadAttention", "(", "hidden_size", ",", "total_key_depth", ",", "total_value_depth", ",", "\n", "hidden_size", ",", "num_heads", ",", "None", ",", "attention_dropout", ")", "\n", "\n", "self", ".", "positionwise_feed_forward", "=", "PositionwiseFeedForward", "(", "hidden_size", ",", "filter_size", ",", "hidden_size", ",", "\n", "layer_config", "=", "'cc'", ",", "padding", "=", "'left'", ",", "\n", "dropout", "=", "relu_dropout", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "layer_dropout", ")", "\n", "self", ".", "layer_norm_mha_dec", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "self", ".", "layer_norm_mha_enc", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "self", ".", "layer_norm_ffn", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "# self.layer_norm_end = LayerNorm(hidden_size)", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.DecoderLayer.forward": [[192, 238], ["common_layer.DecoderLayer.layer_norm_mha_dec", "common_layer.DecoderLayer.multi_head_attention_dec", "common_layer.DecoderLayer.dropout", "common_layer.DecoderLayer.layer_norm_mha_enc", "common_layer.DecoderLayer.multi_head_attention_enc_dec", "common_layer.DecoderLayer.dropout", "common_layer.DecoderLayer.layer_norm_ffn", "common_layer.DecoderLayer.positionwise_feed_forward", "common_layer.DecoderLayer.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: Inputs is a tuple consisting of decoder inputs and encoder output\n        \"\"\"", "\n", "if", "self", ".", "args", ".", "model", "not", "in", "[", "\"KEMP\"", ",", "\"wo_ECE\"", ",", "\"wo_EDD\"", "]", ":", "\n", "            ", "x", ",", "encoder_outputs", ",", "attention_weight", ",", "mask", ",", "=", "inputs", "\n", "pred_emotion", ",", "emotion_contexts", "=", "None", ",", "None", "\n", "", "else", ":", "\n", "            ", "x", ",", "encoder_outputs", ",", "pred_emotion", ",", "emotion_contexts", ",", "attention_weight", ",", "mask", ",", "=", "inputs", "\n", "", "mask_src", ",", "dec_mask", "=", "mask", "\n", "\n", "# Layer Normalization before decoder self attention", "\n", "x_norm", "=", "self", ".", "layer_norm_mha_dec", "(", "x", ")", "\n", "\n", "# Masked Multi-head attention", "\n", "y", ",", "_", "=", "self", ".", "multi_head_attention_dec", "(", "x_norm", ",", "x_norm", ",", "x_norm", ",", "dec_mask", ")", "\n", "\n", "# Dropout and residual after self-attention", "\n", "x", "=", "self", ".", "dropout", "(", "x", "+", "y", ")", "\n", "\n", "# Layer Normalization before encoder-decoder attention", "\n", "x_norm", "=", "self", ".", "layer_norm_mha_enc", "(", "x", ")", "\n", "\n", "# Multi-head encoder-decoder attention E-CatM", "\n", "y", ",", "attention_weight", "=", "self", ".", "multi_head_attention_enc_dec", "(", "x_norm", ",", "\n", "encoder_outputs", ",", "\n", "encoder_outputs", ",", "\n", "mask_src", ",", "\n", "emotion_contexts", "=", "emotion_contexts", ",", ")", "\n", "\n", "# Dropout and residual after encoder-decoder attention", "\n", "x", "=", "self", ".", "dropout", "(", "x", "+", "y", ")", "\n", "\n", "# Layer Normalization", "\n", "x_norm", "=", "self", ".", "layer_norm_ffn", "(", "x", ")", "\n", "\n", "# Positionwise Feedforward", "\n", "y", "=", "self", ".", "positionwise_feed_forward", "(", "x_norm", ")", "\n", "\n", "# Dropout and residual after positionwise feed forward layer", "\n", "y", "=", "self", ".", "dropout", "(", "x", "+", "y", ")", "\n", "\n", "# y = self.layer_norm_end(y)", "\n", "\n", "# Return encoder outputs as well to work with nn.Sequential", "\n", "return", "y", ",", "encoder_outputs", ",", "pred_emotion", ",", "emotion_contexts", ",", "attention_weight", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention.__init__": [[246, 292], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "print", "print", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "input_depth", ",", "total_key_depth", ",", "total_value_depth", ",", "output_depth", ",", "\n", "num_heads", ",", "bias_mask", "=", "None", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            input_depth: Size of last dimension of input \u5c31\u662fhidden states\n            total_key_depth: Size of last dimension of keys. Must be divisible by num_head\n            total_value_depth: Size of last dimension of values. Must be divisible by num_head\n            output_depth: Size last dimension of the final output\n            num_heads: Number of attention heads\n            bias_mask: Masking tensor to prevent connections to future elements\n            dropout: Dropout probability (Should be non-zero only during training)\n        \"\"\"", "\n", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Checks borrowed from", "\n", "# https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py", "\n", "# if total_key_depth % num_heads != 0:", "\n", "#     raise ValueError(\"Key depth (%d) must be divisible by the number of \"", "\n", "#                      \"attention heads (%d).\" % (total_key_depth, num_heads))", "\n", "# if total_value_depth % num_heads != 0:", "\n", "#     raise ValueError(\"Value depth (%d) must be divisible by the number of \"", "\n", "#                      \"attention heads (%d).\" % (total_value_depth, num_heads))", "\n", "if", "total_key_depth", "%", "num_heads", "!=", "0", ":", "\n", "            ", "print", "(", "\"Key depth (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "total_key_depth", ",", "num_heads", ")", ")", "\n", "total_key_depth", "=", "total_key_depth", "-", "(", "total_key_depth", "%", "num_heads", ")", "\n", "", "if", "total_value_depth", "%", "num_heads", "!=", "0", ":", "\n", "            ", "print", "(", "\"Value depth (%d) must be divisible by the number of \"", "\n", "\"attention heads (%d).\"", "%", "(", "total_value_depth", ",", "num_heads", ")", ")", "\n", "total_value_depth", "=", "total_value_depth", "-", "(", "total_value_depth", "%", "num_heads", ")", "\n", "\n", "", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "query_scale", "=", "(", "total_key_depth", "//", "num_heads", ")", "**", "-", "0.5", "## sqrt", "\n", "self", ".", "bias_mask", "=", "bias_mask", "\n", "\n", "# Key and query depth will be same", "\n", "self", ".", "query_linear", "=", "nn", ".", "Linear", "(", "input_depth", ",", "total_key_depth", ",", "bias", "=", "False", ")", "\n", "self", ".", "key_linear", "=", "nn", ".", "Linear", "(", "input_depth", ",", "total_key_depth", ",", "bias", "=", "False", ")", "\n", "self", ".", "value_linear", "=", "nn", ".", "Linear", "(", "input_depth", ",", "total_value_depth", ",", "bias", "=", "False", ")", "\n", "self", ".", "output_linear", "=", "nn", ".", "Linear", "(", "total_value_depth", ",", "output_depth", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "emotion_output_linear", "=", "nn", ".", "Linear", "(", "2", "*", "output_depth", ",", "output_depth", ",", "bias", "=", "False", ")", "\n", "\n", "\n", "self", ".", "W_vad", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention._split_heads": [[293, 305], ["x.view().permute", "len", "ValueError", "x.view"], "methods", ["None"], ["", "def", "_split_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Split x such to add an extra num_heads dimension\n        Input:\n            x: a Tensor with shape [batch_size, seq_length, depth]\n        Returns:\n            A Tensor with shape [batch_size, num_heads, seq_length, depth/num_heads]\n        \"\"\"", "\n", "if", "len", "(", "x", ".", "shape", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"x must have rank 3\"", ")", "\n", "", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "view", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "self", ".", "num_heads", ",", "shape", "[", "2", "]", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention._merge_heads": [[306, 318], ["x.permute().contiguous().view", "len", "ValueError", "x.permute().contiguous", "x.permute"], "methods", ["None"], ["", "def", "_merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Merge the extra num_heads into the last dimension\n        Input:\n            x: a Tensor with shape [batch_size, num_heads, seq_length, depth/num_heads]\n        Returns:\n            A Tensor with shape [batch_size, seq_length, depth]\n        \"\"\"", "\n", "if", "len", "(", "x", ".", "shape", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\"x must have rank 4\"", ")", "\n", "", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "shape", "[", "0", "]", ",", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", "*", "self", ".", "num_heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention.forward": [[319, 372], ["common_layer.MultiHeadAttention.query_linear", "common_layer.MultiHeadAttention.key_linear", "common_layer.MultiHeadAttention.value_linear", "common_layer.MultiHeadAttention._split_heads", "common_layer.MultiHeadAttention._split_heads", "common_layer.MultiHeadAttention._split_heads", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "common_layer.MultiHeadAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "common_layer.MultiHeadAttention._merge_heads", "common_layer.MultiHeadAttention.output_linear", "common_layer.MultiHeadAttention.permute", "vad.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "vad.unsqueeze().unsqueeze.unsqueeze().unsqueeze.repeat", "mask.unsqueeze.unsqueeze.unsqueeze", "logits.masked_fill.masked_fill.masked_fill", "logits.masked_fill.masked_fill.sum", "emotion_contexts.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "common_layer.MultiHeadAttention.emotion_output_linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "logits.masked_fill.masked_fill.size", "common_layer.MultiHeadAttention.size", "vad.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "emotion_contexts.unsqueeze().repeat.unsqueeze().repeat.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention._split_heads", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention._split_heads", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention._split_heads", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.MultiHeadAttention._merge_heads"], ["", "def", "forward", "(", "self", ",", "queries", ",", "keys", ",", "values", ",", "mask", ",", "vad", "=", "None", ",", "emotion_contexts", "=", "None", ")", ":", "\n", "\n", "# Do a linear for each component", "\n", "        ", "queries", "=", "self", ".", "query_linear", "(", "queries", ")", "\n", "keys", "=", "self", ".", "key_linear", "(", "keys", ")", "\n", "values", "=", "self", ".", "value_linear", "(", "values", ")", "\n", "\n", "# Split into multiple heads", "\n", "queries", "=", "self", ".", "_split_heads", "(", "queries", ")", "# (bsz, heads, len, key_depth-20)", "\n", "keys", "=", "self", ".", "_split_heads", "(", "keys", ")", "\n", "values", "=", "self", ".", "_split_heads", "(", "values", ")", "\n", "\n", "# Scale queries", "\n", "queries", "*=", "self", ".", "query_scale", "\n", "\n", "# Combine queries and keys", "\n", "logits", "=", "torch", ".", "matmul", "(", "queries", ",", "keys", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ")", ")", "# (bsz, head, tgt_len, src_len)", "\n", "\n", "if", "vad", "is", "not", "None", ":", "# (bsz, src_len)", "\n", "            ", "vad", "=", "vad", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "vad_weights", "=", "vad", ".", "repeat", "(", "1", ",", "self", ".", "num_heads", ",", "logits", ".", "size", "(", "2", ")", ",", "1", ")", "# (bsz, head, tgt_len, src_len)", "\n", "logits", "+=", "self", ".", "W_vad", "*", "vad_weights", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# [B, 1, 1, T_values]", "\n", "logits", "=", "logits", ".", "masked_fill", "(", "mask", ",", "-", "1e18", ")", "\n", "\n", "## attention weights", "\n", "", "attetion_weights", "=", "logits", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "num_heads", "# (bsz, tgt_len, src_len)", "\n", "\n", "# Convert to probabilites", "\n", "weights", "=", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "# (bsz, 2, tgt_len, src_len)", "\n", "\n", "# Dropout", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ")", "\n", "\n", "# Combine with values to get context", "\n", "contexts", "=", "torch", ".", "matmul", "(", "weights", ",", "values", ")", "\n", "\n", "# Merge heads -> context vector", "\n", "contexts", "=", "self", ".", "_merge_heads", "(", "contexts", ")", "\n", "# contexts = torch.tanh(contexts)", "\n", "\n", "# Linear to get output", "\n", "outputs", "=", "self", ".", "output_linear", "(", "contexts", ")", "# 50 -> 300", "\n", "\n", "if", "emotion_contexts", "is", "not", "None", ":", "\n", "            ", "emotion_contexts", "=", "emotion_contexts", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "outputs", ".", "size", "(", "1", ")", ",", "1", ")", "\n", "outputs", "=", "torch", ".", "cat", "(", "(", "outputs", ",", "emotion_contexts", ")", ",", "dim", "=", "2", ")", "\n", "outputs", "=", "self", ".", "emotion_output_linear", "(", "outputs", ")", "\n", "\n", "# return outputs, attetion_weights", "\n", "", "return", "outputs", ",", "torch", ".", "softmax", "(", "attetion_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.Conv.__init__": [[380, 393], ["torch.Module.__init__", "torch.ConstantPad1d", "torch.ConstantPad1d", "torch.ConstantPad1d", "torch.ConstantPad1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "kernel_size", ",", "pad_type", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            input_size: Input feature size\n            output_size: Output feature size\n            kernel_size: Kernel width\n            pad_type: left -> pad on the left side (to mask future data),\n                      both -> pad on both sides\n        \"\"\"", "\n", "super", "(", "Conv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "padding", "=", "(", "kernel_size", "-", "1", ",", "0", ")", "if", "pad_type", "==", "'left'", "else", "(", "kernel_size", "//", "2", ",", "(", "kernel_size", "-", "1", ")", "//", "2", ")", "\n", "self", ".", "pad", "=", "nn", ".", "ConstantPad1d", "(", "padding", ",", "0", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "input_size", ",", "output_size", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.Conv.forward": [[394, 399], ["common_layer.Conv.pad", "common_layer.Conv.conv().permute", "common_layer.Conv.permute", "common_layer.Conv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "pad", "(", "inputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "outputs", "=", "self", ".", "conv", "(", "inputs", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.PositionwiseFeedForward.__init__": [[406, 436], ["torch.Module.__init__", "zip", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "list", "layers.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "layers.append", "ValueError", "len", "common_layer.Conv"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "input_depth", ",", "filter_size", ",", "output_depth", ",", "layer_config", "=", "'ll'", ",", "padding", "=", "'left'", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            input_depth: Size of last dimension of input\n            filter_size: Hidden size of the middle layer\n            output_depth: Size last dimension of the final output\n            layer_config: ll -> linear + ReLU + linear\n                          cc -> conv + ReLU + conv etc.\n            padding: left -> pad on the left side (to mask future data),\n                     both -> pad on both sides\n            dropout: Dropout probability (Should be non-zero only during training)\n        \"\"\"", "\n", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "sizes", "=", "(", "[", "(", "input_depth", ",", "filter_size", ")", "]", "+", "\n", "[", "(", "filter_size", ",", "filter_size", ")", "]", "*", "(", "len", "(", "layer_config", ")", "-", "2", ")", "+", "\n", "[", "(", "filter_size", ",", "output_depth", ")", "]", ")", "\n", "\n", "for", "lc", ",", "s", "in", "zip", "(", "list", "(", "layer_config", ")", ",", "sizes", ")", ":", "\n", "            ", "if", "lc", "==", "'l'", ":", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "*", "s", ")", ")", "\n", "", "elif", "lc", "==", "'c'", ":", "\n", "                ", "layers", ".", "append", "(", "Conv", "(", "*", "s", ",", "kernel_size", "=", "3", ",", "pad_type", "=", "padding", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown layer type {}\"", ".", "format", "(", "lc", ")", ")", "\n", "\n", "", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "layers", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.PositionwiseFeedForward.forward": [[437, 446], ["enumerate", "layer", "len", "common_layer.PositionwiseFeedForward.relu", "common_layer.PositionwiseFeedForward.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "if", "i", "<", "len", "(", "self", ".", "layers", ")", ":", "\n", "                ", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.LayerNorm.__init__": [[451, 456], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.LayerNorm.forward": [[457, 461], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "gamma", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.Embeddings.__init__": [[532, 536], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "d_model", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lut", "=", "nn", ".", "Embedding", "(", "vocab", ",", "d_model", ",", "padding_idx", "=", "padding_idx", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.Embeddings.forward": [[537, 539], ["common_layer.Embeddings.lut", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "lut", "(", "x", ")", "*", "math", ".", "sqrt", "(", "self", ".", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.LabelSmoothing.__init__": [[551, 559], ["torch.Module.__init__", "torch.KLDivLoss", "torch.KLDivLoss", "torch.KLDivLoss", "torch.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "padding_idx", ",", "smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "LabelSmoothing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'sum'", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "true_dist", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.LabelSmoothing.forward": [[560, 571], ["x.data.clone", "x.data.clone.fill_", "x.data.clone.scatter_", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "common_layer.LabelSmoothing.criterion", "x.size", "target.data.unsqueeze", "x.data.clone.index_fill_", "torch.nonzero.size", "torch.nonzero.size", "torch.nonzero.size", "torch.nonzero.size", "torch.nonzero.squeeze", "torch.nonzero.squeeze", "torch.nonzero.squeeze", "torch.nonzero.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "assert", "x", ".", "size", "(", "1", ")", "==", "self", ".", "size", "\n", "true_dist", "=", "x", ".", "data", ".", "clone", "(", ")", "\n", "true_dist", ".", "fill_", "(", "self", ".", "smoothing", "/", "(", "self", ".", "size", "-", "2", ")", ")", "\n", "true_dist", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "true_dist", "[", ":", ",", "self", ".", "padding_idx", "]", "=", "0", "\n", "mask", "=", "torch", ".", "nonzero", "(", "target", ".", "data", "==", "self", ".", "padding_idx", ")", "\n", "if", "mask", ".", "size", "(", ")", "[", "0", "]", ">", "0", ":", "\n", "            ", "true_dist", ".", "index_fill_", "(", "0", ",", "mask", ".", "squeeze", "(", ")", ",", "0.0", ")", "\n", "", "self", ".", "true_dist", "=", "true_dist", "\n", "return", "self", ".", "criterion", "(", "x", ",", "true_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.__init__": [[576, 583], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_size", ",", "factor", ",", "warmup", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "warmup", "=", "warmup", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "model_size", "=", "model_size", "\n", "self", ".", "_rate", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict": [[584, 586], ["common_layer.NoamOpt.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.step": [[587, 595], ["common_layer.NoamOpt.rate", "common_layer.NoamOpt.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.rate", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Update parameters and rate\"", "\n", "self", ".", "_step", "+=", "1", "\n", "rate", "=", "self", ".", "rate", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "p", "[", "'lr'", "]", "=", "rate", "\n", "", "self", ".", "_rate", "=", "rate", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.rate": [[596, 603], ["min"], "methods", ["None"], ["", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"Implement `lrate` above\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "", "return", "self", ".", "factor", "*", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "self", ".", "warmup", "**", "(", "-", "1.5", ")", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_bias_mask": [[463, 471], ["numpy.triu", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type.unsqueeze().unsqueeze", "numpy.full", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().type.unsqueeze"], "function", ["None"], ["", "", "def", "_gen_bias_mask", "(", "max_length", ")", ":", "\n", "    ", "\"\"\"\n    Generates bias values (-Inf) to mask future timesteps during attention\n    \"\"\"", "\n", "np_mask", "=", "np", ".", "triu", "(", "np", ".", "full", "(", "[", "max_length", ",", "max_length", "]", ",", "-", "np", ".", "inf", ")", ",", "1", ")", "\n", "torch_mask", "=", "torch", ".", "from_numpy", "(", "np_mask", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n", "return", "torch_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_timing_signal": [[473, 490], ["numpy.arange", "numpy.concatenate", "numpy.pad", "signal.reshape.reshape", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "math.log", "numpy.exp", "numpy.expand_dims", "numpy.expand_dims", "float", "numpy.sin", "numpy.cos", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "float", "float", "numpy.arange().astype", "numpy.arange"], "function", ["None"], ["", "def", "_gen_timing_signal", "(", "length", ",", "channels", ",", "min_timescale", "=", "1.0", ",", "max_timescale", "=", "1.0e4", ")", ":", "\n", "    ", "\"\"\"\n    Generates a [1, length, channels] timing signal consisting of sinusoids\n    Adapted from:\n    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n    \"\"\"", "\n", "position", "=", "np", ".", "arange", "(", "length", ")", "\n", "num_timescales", "=", "channels", "//", "2", "\n", "log_timescale_increment", "=", "(", "math", ".", "log", "(", "float", "(", "max_timescale", ")", "/", "float", "(", "min_timescale", ")", ")", "/", "(", "float", "(", "num_timescales", ")", "-", "1", ")", ")", "\n", "inv_timescales", "=", "min_timescale", "*", "np", ".", "exp", "(", "np", ".", "arange", "(", "num_timescales", ")", ".", "astype", "(", "np", ".", "float", ")", "*", "-", "log_timescale_increment", ")", "\n", "scaled_time", "=", "np", ".", "expand_dims", "(", "position", ",", "1", ")", "*", "np", ".", "expand_dims", "(", "inv_timescales", ",", "0", ")", "\n", "\n", "signal", "=", "np", ".", "concatenate", "(", "[", "np", ".", "sin", "(", "scaled_time", ")", ",", "np", ".", "cos", "(", "scaled_time", ")", "]", ",", "axis", "=", "1", ")", "\n", "signal", "=", "np", ".", "pad", "(", "signal", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "channels", "%", "2", "]", "]", ",", "'constant'", ",", "constant_values", "=", "[", "0.0", ",", "0.0", "]", ")", "\n", "signal", "=", "signal", ".", "reshape", "(", "[", "1", ",", "length", ",", "channels", "]", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "signal", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._get_attn_subsequent_mask": [[492, 508], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.to", "numpy.triu", "numpy.ones"], "function", ["None"], ["", "def", "_get_attn_subsequent_mask", "(", "args", ",", "size", ")", ":", "\n", "    ", "\"\"\"\n    Get an attention mask to avoid using the subsequent info.\n    Args:\n        size: int\n    Returns:\n        (`LongTensor`):\n        * subsequent_mask `[1 x size x size]`\n    \"\"\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "subsequent_mask", "=", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "\n", "if", "(", "args", ".", "USE_CUDA", ")", ":", "\n", "        ", "return", "subsequent_mask", ".", "to", "(", "args", ".", "device", ")", "\n", "", "else", ":", "\n", "        ", "return", "subsequent_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.gen_embeddings": [[509, 530], ["print", "numpy.random.randn", "print", "open().readlines", "print", "line.split", "open", "len", "print", "float"], "function", ["None"], ["", "", "def", "gen_embeddings", "(", "args", ",", "n_words", ",", "word2index", ")", ":", "\n", "    ", "\"\"\"\n        Generate an initial embedding matrix for `word_dict`.\n        If an embedding file is not given or a word is not in the embedding file,\n        a randomly initialized vector will be used.\n    \"\"\"", "\n", "embeddings", "=", "np", ".", "random", ".", "randn", "(", "n_words", ",", "args", ".", "emb_dim", ")", "*", "0.01", "\n", "print", "(", "'Embeddings: %d x %d'", "%", "(", "n_words", ",", "args", ".", "emb_dim", ")", ")", "\n", "if", "args", ".", "emb_file", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading embedding file: %s'", "%", "args", ".", "emb_file", ")", "\n", "pre_trained", "=", "0", "\n", "for", "line", "in", "open", "(", "args", ".", "emb_file", ")", ".", "readlines", "(", ")", ":", "\n", "            ", "sp", "=", "line", ".", "split", "(", ")", "\n", "if", "(", "len", "(", "sp", ")", "==", "args", ".", "emb_dim", "+", "1", ")", ":", "\n", "                ", "if", "sp", "[", "0", "]", "in", "word2index", ":", "\n", "                    ", "pre_trained", "+=", "1", "\n", "embeddings", "[", "word2index", "[", "sp", "[", "0", "]", "]", "]", "=", "[", "float", "(", "x", ")", "for", "x", "in", "sp", "[", "1", ":", "]", "]", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "sp", "[", "0", "]", ")", "\n", "", "", "print", "(", "'Pre-trained: %d (%.2f%%)'", "%", "(", "pre_trained", ",", "pre_trained", "*", "100.0", "/", "n_words", ")", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.share_embedding": [[540, 547], ["common_layer.Embeddings", "common_layer.gen_embeddings", "Embeddings.lut.weight.data.copy_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.gen_embeddings"], ["", "", "def", "share_embedding", "(", "args", ",", "n_words", ",", "word2index", ",", "pretrain", "=", "True", ")", ":", "\n", "    ", "embedding", "=", "Embeddings", "(", "n_words", ",", "args", ".", "emb_dim", ",", "padding_idx", "=", "args", ".", "PAD_idx", ")", "\n", "if", "(", "pretrain", ")", "and", "args", ".", "emb_dim", "in", "[", "50", ",", "200", ",", "300", "]", ":", "\n", "        ", "pre_embedding", "=", "gen_embeddings", "(", "args", ",", "n_words", ",", "word2index", ")", "\n", "embedding", ".", "lut", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "FloatTensor", "(", "pre_embedding", ")", ")", "\n", "embedding", ".", "lut", ".", "weight", ".", "data", ".", "requires_grad", "=", "True", "\n", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.Encoder.__init__": [[34, 83], ["torch.Module.__init__", "code.common_layer._gen_timing_signal", "torch.Linear", "torch.Linear", "torch.Linear", "code.common_layer.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "code.common_layer._gen_timing_signal", "code.common_layer.EncoderLayer", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "code.common_layer._gen_bias_mask", "code.common_layer.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_timing_signal", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_timing_signal", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_bias_mask"], ["def", "__init__", "(", "self", ",", "args", ",", "embedding_size", ",", "hidden_size", ",", "num_layers", ",", "num_heads", ",", "total_key_depth", ",", "total_value_depth", ",", "\n", "filter_size", ",", "max_length", "=", "1000", ",", "input_dropout", "=", "0.0", ",", "layer_dropout", "=", "0.0", ",", "\n", "attention_dropout", "=", "0.0", ",", "relu_dropout", "=", "0.0", ",", "use_mask", "=", "False", ",", "universal", "=", "False", ",", "concept", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            embedding_size: Size of embeddings\n            hidden_size: Hidden size\n            num_layers: Total layers in the Encoder  2\n            num_heads: Number of attention heads   2\n            total_key_depth: Size of last dimension of keys. Must be divisible by num_head   40\n            total_value_depth: Size of last dimension of values. Must be divisible by num_head  40\n            output_depth: Size last dimension of the final output\n            filter_size: Hidden size of the middle layer in FFN  50\n            max_length: Max sequence length (required for timing signal)\n            input_dropout: Dropout just after embedding\n            layer_dropout: Dropout for each layer\n            attention_dropout: Dropout probability after attention (Should be non-zero only during training)\n            relu_dropout: Dropout probability after relu in FFN (Should be non-zero only during training)\n            use_mask: Set to True to turn on future value masking\n        \"\"\"", "\n", "\n", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "universal", "=", "universal", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "timing_signal", "=", "_gen_timing_signal", "(", "max_length", ",", "hidden_size", ")", "\n", "\n", "if", "(", "self", ".", "universal", ")", ":", "\n", "## for t", "\n", "            ", "self", ".", "position_signal", "=", "_gen_timing_signal", "(", "num_layers", ",", "hidden_size", ")", "\n", "\n", "", "params", "=", "(", "hidden_size", ",", "\n", "total_key_depth", "or", "hidden_size", ",", "\n", "total_value_depth", "or", "hidden_size", ",", "\n", "filter_size", ",", "\n", "num_heads", ",", "\n", "_gen_bias_mask", "(", "max_length", ")", "if", "use_mask", "else", "None", ",", "\n", "layer_dropout", ",", "\n", "attention_dropout", ",", "\n", "relu_dropout", ")", "\n", "\n", "self", ".", "embedding_proj", "=", "nn", ".", "Linear", "(", "embedding_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "if", "(", "self", ".", "universal", ")", ":", "\n", "            ", "self", ".", "enc", "=", "EncoderLayer", "(", "*", "params", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "enc", "=", "nn", ".", "ModuleList", "(", "[", "EncoderLayer", "(", "*", "params", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "", "self", ".", "layer_norm", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "self", ".", "input_dropout", "=", "nn", ".", "Dropout", "(", "input_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.Encoder.forward": [[84, 110], ["KEMP.Encoder.input_dropout", "KEMP.Encoder.embedding_proj", "KEMP.Encoder.timing_signal[].type_as", "range", "KEMP.Encoder.layer_norm", "KEMP.Encoder.act_fn", "KEMP.Encoder.layer_norm", "range", "KEMP.Encoder.layer_norm", "KEMP.Encoder.timing_signal[].type_as", "KEMP.Encoder.position_signal[].unsqueeze().repeat().type_as", "KEMP.Encoder.enc", "KEMP.Encoder.position_signal[].unsqueeze().repeat", "KEMP.Encoder.position_signal[].unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "mask", ")", ":", "\n", "#Add input dropout", "\n", "        ", "x", "=", "self", ".", "input_dropout", "(", "inputs", ")", "\n", "\n", "# Project to hidden size", "\n", "x", "=", "self", ".", "embedding_proj", "(", "x", ")", "\n", "\n", "if", "(", "self", ".", "universal", ")", ":", "\n", "            ", "if", "(", "self", ".", "args", ".", "act", ")", ":", "# Adaptive Computation Time", "\n", "                ", "x", ",", "(", "self", ".", "remainders", ",", "self", ".", "n_updates", ")", "=", "self", ".", "act_fn", "(", "x", ",", "inputs", ",", "self", ".", "enc", ",", "self", ".", "timing_signal", ",", "self", ".", "position_signal", ",", "self", ".", "num_layers", ")", "\n", "y", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "for", "l", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "                    ", "x", "+=", "self", ".", "timing_signal", "[", ":", ",", ":", "inputs", ".", "shape", "[", "1", "]", ",", ":", "]", ".", "type_as", "(", "inputs", ".", "data", ")", "\n", "x", "+=", "self", ".", "position_signal", "[", ":", ",", "l", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "inputs", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "type_as", "(", "inputs", ".", "data", ")", "\n", "x", "=", "self", ".", "enc", "(", "x", ",", "mask", "=", "mask", ")", "\n", "", "y", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "", "else", ":", "\n", "# Add timing signal", "\n", "            ", "x", "+=", "self", ".", "timing_signal", "[", ":", ",", ":", "inputs", ".", "shape", "[", "1", "]", ",", ":", "]", ".", "type_as", "(", "inputs", ".", "data", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "                ", "x", "=", "self", ".", "enc", "[", "i", "]", "(", "x", ",", "mask", ")", "\n", "\n", "", "y", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.Decoder.__init__": [[119, 171], ["torch.Module.__init__", "code.common_layer._gen_timing_signal", "code.common_layer._get_attn_subsequent_mask", "torch.Linear", "torch.Linear", "torch.Linear", "code.common_layer.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "code.common_layer._gen_timing_signal", "code.common_layer._gen_bias_mask", "code.common_layer.DecoderLayer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "code.common_layer.DecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_timing_signal", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._get_attn_subsequent_mask", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_timing_signal", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer._gen_bias_mask"], ["def", "__init__", "(", "self", ",", "args", ",", "embedding_size", ",", "hidden_size", ",", "num_layers", ",", "num_heads", ",", "total_key_depth", ",", "total_value_depth", ",", "\n", "filter_size", ",", "max_length", "=", "1000", ",", "input_dropout", "=", "0.0", ",", "layer_dropout", "=", "0.0", ",", "\n", "attention_dropout", "=", "0.0", ",", "relu_dropout", "=", "0.0", ",", "universal", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            embedding_size: Size of embeddings\n            hidden_size: Hidden size\n            num_layers: Total layers in the Encoder\n            num_heads: Number of attention heads\n            total_key_depth: Size of last dimension of keys. Must be divisible by num_head\n            total_value_depth: Size of last dimension of values. Must be divisible by num_head\n            output_depth: Size last dimension of the final output\n            filter_size: Hidden size of the middle layer in FFN\n            max_length: Max sequence length (required for timing signal)\n            input_dropout: Dropout just after embedding\n            layer_dropout: Dropout for each layer\n            attention_dropout: Dropout probability after attention (Should be non-zero only during training)\n            relu_dropout: Dropout probability after relu in FFN (Should be non-zero only during training)\n        \"\"\"", "\n", "\n", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "universal", "=", "universal", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "timing_signal", "=", "_gen_timing_signal", "(", "max_length", ",", "hidden_size", ")", "\n", "\n", "if", "(", "self", ".", "universal", ")", ":", "\n", "## for t", "\n", "            ", "self", ".", "position_signal", "=", "_gen_timing_signal", "(", "num_layers", ",", "hidden_size", ")", "\n", "\n", "", "self", ".", "mask", "=", "_get_attn_subsequent_mask", "(", "self", ".", "args", ",", "max_length", ")", "\n", "\n", "params", "=", "(", "args", ",", "\n", "hidden_size", ",", "\n", "total_key_depth", "or", "hidden_size", ",", "\n", "total_value_depth", "or", "hidden_size", ",", "\n", "filter_size", ",", "\n", "num_heads", ",", "\n", "_gen_bias_mask", "(", "max_length", ")", ",", "# mandatory", "\n", "layer_dropout", ",", "\n", "attention_dropout", ",", "\n", "relu_dropout", ")", "\n", "\n", "if", "(", "self", ".", "universal", ")", ":", "\n", "            ", "self", ".", "dec", "=", "DecoderLayer", "(", "*", "params", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dec", "=", "nn", ".", "Sequential", "(", "*", "[", "DecoderLayer", "(", "*", "params", ")", "for", "l", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "", "self", ".", "embedding_proj", "=", "nn", ".", "Linear", "(", "embedding_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "hidden_size", ")", "\n", "self", ".", "input_dropout", "=", "nn", ".", "Dropout", "(", "input_dropout", ")", "\n", "self", ".", "attn_loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.Decoder.forward": [[172, 215], ["torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "KEMP.Decoder.input_dropout", "KEMP.Decoder.embedding_proj", "KEMP.Decoder.timing_signal[].type_as", "KEMP.Decoder.dec", "KEMP.Decoder.layer_norm", "mask_trg.bool", "KEMP.Decoder.mask[].bool", "KEMP.Decoder.act_fn", "KEMP.Decoder.layer_norm", "KEMP.Decoder.timing_signal[].type_as", "range", "KEMP.Decoder.layer_norm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "KEMP.Decoder.attn_loss", "KEMP.Decoder.position_signal[].unsqueeze().repeat().type_as", "KEMP.Decoder.dec", "KEMP.Decoder.position_signal[].unsqueeze().repeat", "mask_trg.size", "mask_trg.size", "KEMP.Decoder.position_signal[].unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "encoder_output", ",", "mask", "=", "None", ",", "pred_emotion", "=", "None", ",", "emotion_contexts", "=", "None", ",", "context_vad", "=", "None", ")", ":", "\n", "        ", "'''\n        inputs: (bsz, tgt_len)\n        encoder_output: (bsz, src_len), src_len=dialog_len+concept_len\n        mask: (bsz, src_len)\n        pred_emotion: (bdz, emotion_type)\n        emotion_contexts: (bsz, emb_dim)\n        context_vad: (bsz, src_len) emotion intensity values\n        '''", "\n", "mask_src", ",", "mask_trg", "=", "mask", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "mask_trg", ".", "bool", "(", ")", "+", "self", ".", "mask", "[", ":", ",", ":", "mask_trg", ".", "size", "(", "-", "1", ")", ",", ":", "mask_trg", ".", "size", "(", "-", "1", ")", "]", ".", "bool", "(", ")", ",", "0", ")", "\n", "#Add input dropout", "\n", "x", "=", "self", ".", "input_dropout", "(", "inputs", ")", "\n", "x", "=", "self", ".", "embedding_proj", "(", "x", ")", "\n", "loss_att", "=", "0.0", "\n", "attn_dist", "=", "None", "\n", "if", "(", "self", ".", "universal", ")", ":", "\n", "            ", "if", "(", "self", ".", "args", ".", "act", ")", ":", "\n", "                ", "x", ",", "attn_dist", ",", "(", "self", ".", "remainders", ",", "self", ".", "n_updates", ")", "=", "self", ".", "act_fn", "(", "x", ",", "inputs", ",", "self", ".", "dec", ",", "self", ".", "timing_signal", ",", "self", ".", "position_signal", ",", "self", ".", "num_layers", ",", "encoder_output", ",", "decoding", "=", "True", ")", "\n", "y", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "else", ":", "\n", "                ", "x", "+=", "self", ".", "timing_signal", "[", ":", ",", ":", "inputs", ".", "shape", "[", "1", "]", ",", ":", "]", ".", "type_as", "(", "inputs", ".", "data", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "                    ", "x", "+=", "self", ".", "position_signal", "[", ":", ",", "l", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "inputs", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "type_as", "(", "inputs", ".", "data", ")", "\n", "x", ",", "_", ",", "pred_emotion", ",", "emotion_contexts", ",", "attn_dist", ",", "_", "=", "self", ".", "dec", "(", "(", "x", ",", "encoder_output", ",", "pred_emotion", ",", "emotion_contexts", ",", "[", "]", ",", "(", "mask_src", ",", "dec_mask", ")", ")", ")", "\n", "", "y", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "", "else", ":", "\n", "# Add timing signal", "\n", "            ", "x", "+=", "self", ".", "timing_signal", "[", ":", ",", ":", "inputs", ".", "shape", "[", "1", "]", ",", ":", "]", ".", "type_as", "(", "inputs", ".", "data", ")", "\n", "\n", "# Run decoder  y, encoder_outputs, pred_emotion, emotion_contexts, attention_weight, mask", "\n", "y", ",", "_", ",", "pred_emotion", ",", "emotion_contexts", ",", "attn_dist", ",", "_", "=", "self", ".", "dec", "(", "(", "x", ",", "encoder_output", ",", "pred_emotion", ",", "emotion_contexts", ",", "[", "]", ",", "(", "mask_src", ",", "dec_mask", ")", ")", ")", "\n", "\n", "# Emotional attention loss", "\n", "if", "context_vad", "is", "not", "None", ":", "\n", "                ", "src_attn_dist", "=", "torch", ".", "mean", "(", "attn_dist", ",", "dim", "=", "1", ")", "# (bsz, src_len)", "\n", "loss_att", "=", "self", ".", "attn_loss", "(", "src_attn_dist", ",", "context_vad", ")", "\n", "\n", "# Final layer normalization", "\n", "", "y", "=", "self", ".", "layer_norm", "(", "y", ")", "\n", "\n", "", "return", "y", ",", "attn_dist", ",", "loss_att", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.Generator.__init__": [[219, 225], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "d_model", ",", "vocab", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "d_model", ",", "vocab", ")", "\n", "self", ".", "emo_proj", "=", "nn", ".", "Linear", "(", "2", "*", "d_model", ",", "vocab", ")", "\n", "self", ".", "p_gen_linear", "=", "nn", ".", "Linear", "(", "self", ".", "args", ".", "hidden_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.Generator.forward": [[226, 258], ["KEMP.Generator.p_gen_linear", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "pred_emotion.repeat.repeat.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KEMP.Generator.emo_proj", "KEMP.Generator.proj", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.scatter_add", "torch.cat.scatter_add", "torch.cat.scatter_add", "enc_batch_extend_vocab.unsqueeze", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "pred_emotion", "=", "None", ",", "emotion_context", "=", "None", ",", "attn_dist", "=", "None", ",", "enc_batch_extend_vocab", "=", "None", ",", "extra_zeros", "=", "None", ",", "temp", "=", "1", ")", ":", "\n", "# pred_emotion (bsz, 1, embed_dim);  emotion_context: (bsz, emb_dim)", "\n", "        ", "if", "self", ".", "args", ".", "pointer_gen", ":", "\n", "            ", "p_gen", "=", "self", ".", "p_gen_linear", "(", "x", ")", "\n", "alpha", "=", "torch", ".", "sigmoid", "(", "p_gen", ")", "\n", "\n", "", "if", "emotion_context", "is", "not", "None", ":", "\n", "# emotion_context = emotion_context.unsqueeze(1).repeat(1, x.size(1), 1)", "\n", "            ", "pred_emotion", "=", "pred_emotion", ".", "repeat", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "pred_emotion", ")", ",", "dim", "=", "2", ")", "# (bsz, tgt_len, 2 emb_dim)", "\n", "logit", "=", "self", ".", "emo_proj", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "logit", "=", "self", ".", "proj", "(", "x", ")", "# x: (bsz, tgt_len, emb_dim)", "\n", "\n", "", "if", "self", ".", "args", ".", "pointer_gen", ":", "\n", "            ", "vocab_dist", "=", "F", ".", "softmax", "(", "logit", "/", "temp", ",", "dim", "=", "2", ")", "\n", "vocab_dist_", "=", "alpha", "*", "vocab_dist", "\n", "\n", "attn_dist", "=", "F", ".", "softmax", "(", "attn_dist", "/", "temp", ",", "dim", "=", "-", "1", ")", "\n", "attn_dist_", "=", "(", "1", "-", "alpha", ")", "*", "attn_dist", "\n", "enc_batch_extend_vocab_", "=", "torch", ".", "cat", "(", "[", "enc_batch_extend_vocab", ".", "unsqueeze", "(", "1", ")", "]", "*", "x", ".", "size", "(", "1", ")", ",", "1", ")", "## extend for all seq", "\n", "\n", "if", "extra_zeros", "is", "not", "None", ":", "\n", "                ", "extra_zeros", "=", "torch", ".", "cat", "(", "[", "extra_zeros", ".", "unsqueeze", "(", "1", ")", "]", "*", "x", ".", "size", "(", "1", ")", ",", "1", ")", "\n", "vocab_dist_", "=", "torch", ".", "cat", "(", "[", "vocab_dist_", ",", "extra_zeros", "]", ",", "2", ")", "\n", "# if beam_search:", "\n", "#     enc_batch_extend_vocab_ = torch.cat([enc_batch_extend_vocab_[0].unsqueeze(0)]*x.size(0),0) ## extend for all seq", "\n", "\n", "", "logit", "=", "torch", ".", "log", "(", "vocab_dist_", ".", "scatter_add", "(", "2", ",", "enc_batch_extend_vocab_", ",", "attn_dist_", ")", "+", "1e-18", ")", "\n", "return", "logit", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.__init__": [[261, 338], ["torch.Module.__init__", "code.common_layer.share_embedding", "KEMP.Encoder", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "code.common_layer.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Linear", "torch.Linear", "torch.Linear", "KEMP.Decoder", "torch.Linear", "torch.Linear", "torch.Linear", "KEMP.Generator", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.Linear", "torch.Linear", "torch.Linear", "code.common_layer.LabelSmoothing", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss", "KEMP.KEMP.parameters", "code.common_layer.NoamOpt", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "KEMP.KEMP.encoder.load_state_dict", "KEMP.KEMP.decoder.load_state_dict", "KEMP.KEMP.generator.load_state_dict", "KEMP.KEMP.embedding.load_state_dict", "KEMP.KEMP.decoder_key.load_state_dict", "KEMP.KEMP.eval", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "KEMP.KEMP.optimizer.load_state_dict", "KEMP.KEMP.parameters"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.share_embedding"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "vocab", ",", "decoder_number", ",", "model_file_path", "=", "None", ",", "is_eval", "=", "False", ",", "load_optim", "=", "False", ")", ":", "\n", "        ", "super", "(", "KEMP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "vocab", "=", "vocab", "\n", "word2index", ",", "word2count", ",", "index2word", ",", "n_words", "=", "vocab", "\n", "self", ".", "word2index", "=", "word2index", "\n", "self", ".", "word2count", "=", "word2count", "\n", "self", ".", "index2word", "=", "index2word", "\n", "self", ".", "vocab_size", "=", "n_words", "\n", "\n", "self", ".", "embedding", "=", "share_embedding", "(", "args", ",", "n_words", ",", "word2index", ",", "self", ".", "args", ".", "pretrain_emb", ")", "# args, n_words, word2index", "\n", "self", ".", "encoder", "=", "Encoder", "(", "args", ",", "self", ".", "args", ".", "emb_dim", ",", "self", ".", "args", ".", "hidden_dim", ",", "num_layers", "=", "self", ".", "args", ".", "hop", ",", "\n", "num_heads", "=", "self", ".", "args", ".", "heads", ",", "total_key_depth", "=", "self", ".", "args", ".", "depth", ",", "total_value_depth", "=", "self", ".", "args", ".", "depth", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "filter_size", "=", "self", ".", "args", ".", "filter", ",", "universal", "=", "self", ".", "args", ".", "universal", ")", "\n", "\n", "self", ".", "map_emo", "=", "{", "0", ":", "'surprised'", ",", "1", ":", "'excited'", ",", "2", ":", "'annoyed'", ",", "3", ":", "'proud'", ",", "\n", "4", ":", "'angry'", ",", "5", ":", "'sad'", ",", "6", ":", "'grateful'", ",", "7", ":", "'lonely'", ",", "8", ":", "'impressed'", ",", "\n", "9", ":", "'afraid'", ",", "10", ":", "'disgusted'", ",", "11", ":", "'confident'", ",", "12", ":", "'terrified'", ",", "\n", "13", ":", "'hopeful'", ",", "14", ":", "'anxious'", ",", "15", ":", "'disappointed'", ",", "16", ":", "'joyful'", ",", "\n", "17", ":", "'prepared'", ",", "18", ":", "'guilty'", ",", "19", ":", "'furious'", ",", "20", ":", "'nostalgic'", ",", "\n", "21", ":", "'jealous'", ",", "22", ":", "'anticipating'", ",", "23", ":", "'embarrassed'", ",", "24", ":", "'content'", ",", "\n", "25", ":", "'devastated'", ",", "26", ":", "'sentimental'", ",", "27", ":", "'caring'", ",", "28", ":", "'trusting'", ",", "\n", "29", ":", "'ashamed'", ",", "30", ":", "'apprehensive'", ",", "31", ":", "'faithful'", "}", "\n", "\n", "\n", "## GRAPH", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "W_q", "=", "nn", ".", "Linear", "(", "args", ".", "emb_dim", ",", "args", ".", "emb_dim", ")", "\n", "self", ".", "W_k", "=", "nn", ".", "Linear", "(", "args", ".", "emb_dim", ",", "args", ".", "emb_dim", ")", "\n", "self", ".", "W_v", "=", "nn", ".", "Linear", "(", "args", ".", "emb_dim", ",", "args", ".", "emb_dim", ")", "\n", "self", ".", "graph_out", "=", "nn", ".", "Linear", "(", "args", ".", "emb_dim", ",", "args", ".", "emb_dim", ")", "\n", "self", ".", "graph_layer_norm", "=", "LayerNorm", "(", "args", ".", "hidden_dim", ")", "\n", "\n", "## emotional signal distilling", "\n", "self", ".", "identify", "=", "nn", ".", "Linear", "(", "args", ".", "emb_dim", ",", "decoder_number", ",", "bias", "=", "False", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "## multiple decoders", "\n", "self", ".", "emotion_embedding", "=", "nn", ".", "Linear", "(", "decoder_number", ",", "args", ".", "emb_dim", ")", "\n", "self", ".", "decoder", "=", "Decoder", "(", "args", ",", "args", ".", "emb_dim", ",", "hidden_size", "=", "args", ".", "hidden_dim", ",", "num_layers", "=", "args", ".", "hop", ",", "num_heads", "=", "args", ".", "heads", ",", "\n", "total_key_depth", "=", "args", ".", "depth", ",", "total_value_depth", "=", "args", ".", "depth", ",", "filter_size", "=", "args", ".", "filter", ",", "max_length", "=", "args", ".", "max_seq_length", ",", ")", "\n", "\n", "self", ".", "decoder_key", "=", "nn", ".", "Linear", "(", "args", ".", "hidden_dim", ",", "decoder_number", ",", "bias", "=", "False", ")", "\n", "self", ".", "generator", "=", "Generator", "(", "args", ",", "args", ".", "hidden_dim", ",", "self", ".", "vocab_size", ")", "\n", "if", "args", ".", "projection", ":", "\n", "            ", "self", ".", "embedding_proj_in", "=", "nn", ".", "Linear", "(", "args", ".", "emb_dim", ",", "args", ".", "hidden_dim", ",", "bias", "=", "False", ")", "\n", "", "if", "args", ".", "weight_sharing", ":", "\n", "            ", "self", ".", "generator", ".", "proj", ".", "weight", "=", "self", ".", "embedding", ".", "lut", ".", "weight", "\n", "\n", "", "self", ".", "criterion", "=", "nn", ".", "NLLLoss", "(", "ignore_index", "=", "args", ".", "PAD_idx", ")", "\n", "if", "args", ".", "label_smoothing", ":", "\n", "            ", "self", ".", "criterion", "=", "LabelSmoothing", "(", "size", "=", "self", ".", "vocab_size", ",", "padding_idx", "=", "args", ".", "PAD_idx", ",", "smoothing", "=", "0.1", ")", "\n", "self", ".", "criterion_ppl", "=", "nn", ".", "NLLLoss", "(", "ignore_index", "=", "args", ".", "PAD_idx", ")", "\n", "\n", "", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "if", "args", ".", "noam", ":", "\n", "# We used the Adam optimizer here with \u03b21 = 0.9, \u03b22 = 0.98, and \u03f5 = 10^\u22129. We varied the learning rate over the course of training.", "\n", "# This corresponds to increasing the learning rate linearly for the first warmup training steps,", "\n", "# and decreasing it thereafter proportionally to the inverse square root of the step number. We used warmup step = 8000.", "\n", "            ", "self", ".", "optimizer", "=", "NoamOpt", "(", "args", ".", "hidden_dim", ",", "1", ",", "8000", ",", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "0", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", ")", "\n", "\n", "", "if", "model_file_path", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"loading weights\"", ")", "\n", "state", "=", "torch", ".", "load", "(", "model_file_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "state", "[", "'encoder_state_dict'", "]", ")", "\n", "self", ".", "decoder", ".", "load_state_dict", "(", "state", "[", "'decoder_state_dict'", "]", ")", "\n", "self", ".", "generator", ".", "load_state_dict", "(", "state", "[", "'generator_dict'", "]", ")", "\n", "self", ".", "embedding", ".", "load_state_dict", "(", "state", "[", "'embedding_dict'", "]", ")", "\n", "self", ".", "decoder_key", ".", "load_state_dict", "(", "state", "[", "'decoder_key_state_dict'", "]", ")", "\n", "if", "load_optim", ":", "\n", "                ", "self", ".", "optimizer", ".", "load_state_dict", "(", "state", "[", "'optimizer'", "]", ")", "\n", "", "self", ".", "eval", "(", ")", "\n", "\n", "", "self", ".", "model_dir", "=", "args", ".", "save_path", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "model_dir", ")", "\n", "", "self", ".", "best_path", "=", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.save_model": [[339, 353], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "KEMP.KEMP.encoder.state_dict", "KEMP.KEMP.decoder.state_dict", "KEMP.KEMP.generator.state_dict", "KEMP.KEMP.decoder_key.state_dict", "KEMP.KEMP.embedding.state_dict", "KEMP.KEMP.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict", "home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.state_dict"], ["", "def", "save_model", "(", "self", ",", "running_avg_ppl", ",", "iter", ",", "f1_g", ",", "f1_b", ",", "ent_g", ",", "ent_b", ")", ":", "\n", "        ", "state", "=", "{", "\n", "'iter'", ":", "iter", ",", "\n", "'encoder_state_dict'", ":", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "'decoder_state_dict'", ":", "self", ".", "decoder", ".", "state_dict", "(", ")", ",", "\n", "'generator_dict'", ":", "self", ".", "generator", ".", "state_dict", "(", ")", ",", "\n", "'decoder_key_state_dict'", ":", "self", ".", "decoder_key", ".", "state_dict", "(", ")", ",", "\n", "'embedding_dict'", ":", "self", ".", "embedding", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'current_loss'", ":", "running_avg_ppl", "\n", "}", "\n", "model_save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_dir", ",", "'model_{}_{:.4f}_{:.4f}_{:.4f}_{:.4f}_{:.4f}.tar'", ".", "format", "(", "iter", ",", "running_avg_ppl", ",", "f1_g", ",", "f1_b", ",", "ent_g", ",", "ent_b", ")", ")", "\n", "self", ".", "best_path", "=", "model_save_path", "\n", "torch", ".", "save", "(", "state", ",", "model_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.concept_graph": [[354, 393], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KEMP.KEMP.W_q", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "adjacency_mask.bool.bool.bool", "torch.bmm.masked_fill_", "torch.bmm.masked_fill_", "torch.bmm.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "KEMP.KEMP.graph_out", "torch.dropout", "torch.dropout", "torch.dropout", "KEMP.KEMP.graph_layer_norm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KEMP.KEMP.W_k", "KEMP.KEMP.W_v", "k.transpose", "torch.isnan().sum", "torch.isnan().sum", "torch.isnan().sum", "torch.isnan().sum", "torch.isnan().sum", "torch.isnan().sum", "torch.isnan().sum", "torch.isnan().sum", "torch.isnan().sum", "pdb.set_trace", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["None"], ["", "def", "concept_graph", "(", "self", ",", "context", ",", "concept", ",", "adjacency_mask", ")", ":", "\n", "        ", "'''\n\n        :param context: (bsz, max_context_len, embed_dim)\n        :param concept: (bsz, max_concept_len, embed_dim)\n        :param adjacency_mask: (bsz, max_context_len, max_context_len + max_concpet_len)\n        :return:\n        '''", "\n", "# target = self.W_sem_emo(context)  # (bsz, max_context_len, emb_dim)", "\n", "# concept = self.W_sem_emo(concept)", "\n", "target", "=", "context", "\n", "src", "=", "torch", ".", "cat", "(", "(", "target", ",", "concept", ")", ",", "dim", "=", "1", ")", "# (bsz, max_context_len + max_concept_len, emb_dim)", "\n", "\n", "# QK attention", "\n", "q", "=", "self", ".", "W_q", "(", "target", ")", "# (bsz, tgt_len, emb_dim)", "\n", "k", ",", "v", "=", "self", ".", "W_k", "(", "src", ")", ",", "self", ".", "W_v", "(", "src", ")", "# (bsz, src_len, emb_dim); (bsz, src_len, emb_dim)", "\n", "attn_weights_ori", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "# batch matrix multiply (bsz, tgt_len, src_len)", "\n", "\n", "adjacency_mask", "=", "adjacency_mask", ".", "bool", "(", ")", "\n", "attn_weights_ori", ".", "masked_fill_", "(", "\n", "adjacency_mask", ",", "\n", "1e-24", "\n", ")", "# mask PAD", "\n", "attn_weights", "=", "torch", ".", "softmax", "(", "attn_weights_ori", ",", "dim", "=", "-", "1", ")", "# (bsz, tgt_len, src_len)", "\n", "\n", "if", "torch", ".", "isnan", "(", "attn_weights", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "            ", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# weigted sum", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "# (bsz, tgt_len, emb_dim)", "\n", "attn", "=", "self", ".", "graph_out", "(", "attn", ")", "\n", "\n", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "new_context", "=", "self", ".", "graph_layer_norm", "(", "target", "+", "attn", ")", "\n", "\n", "new_context", "=", "torch", ".", "cat", "(", "(", "new_context", ",", "concept", ")", ",", "dim", "=", "1", ")", "\n", "return", "new_context", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.train_one_batch": [[394, 496], ["len", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "enc_batch.data.eq().unsqueeze", "KEMP.KEMP.embedding", "KEMP.KEMP.encoder", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "emotion_context_vad.repeat.repeat.repeat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "KEMP.KEMP.identify", "numpy.argmax", "sklearn.metrics.accuracy_score", "KEMP.KEMP.emotion_embedding().unsqueeze", "KEMP.KEMP.embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dec_batch.data.eq().unsqueeze", "KEMP.KEMP.generator", "KEMP.KEMP.criterion", "KEMP.KEMP.optimizer.optimizer.zero_grad", "KEMP.KEMP.optimizer.zero_grad", "KEMP.KEMP.embedding", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "KEMP.KEMP.detach().cpu().numpy", "batch[].cpu().numpy", "KEMP.KEMP.decoder", "KEMP.KEMP.decoder", "KEMP.KEMP.contiguous().view", "KEMP.KEMP.criterion_ppl().item", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "pdb.set_trace", "KEMP.KEMP.backward", "KEMP.KEMP.optimizer.step", "sorted", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "enc_batch.data.eq", "concept_input.data.eq().unsqueeze", "KEMP.KEMP.embedding", "KEMP.KEMP.concept_graph", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KEMP.KEMP.emotion_embedding", "dec_batch.data.eq", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KEMP.KEMP.size", "dec_batch.contiguous().view", "dec_ext_batch.contiguous().view", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "math.exp", "loss_emotion.item", "KEMP.KEMP.item", "math.exp", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "concept_input.size", "KEMP.KEMP.embedding", "KEMP.KEMP.detach().cpu", "batch[].cpu", "concept_input.size", "KEMP.KEMP.contiguous", "KEMP.KEMP.criterion_ppl", "min", "min", "concept_input.data.eq", "dec_batch.contiguous", "dec_ext_batch.contiguous", "KEMP.KEMP.contiguous().view", "KEMP.KEMP.item", "len", "enc_batch.size", "KEMP.KEMP.detach", "KEMP.KEMP.size", "dec_batch.contiguous().view", "dec_ext_batch.contiguous().view", "KEMP.KEMP.contiguous", "dec_batch.contiguous", "dec_ext_batch.contiguous"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.common_layer.NoamOpt.step", "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.concept_graph"], ["", "def", "train_one_batch", "(", "self", ",", "batch", ",", "iter", ",", "train", "=", "True", ")", ":", "\n", "        ", "enc_batch", "=", "batch", "[", "\"context_batch\"", "]", "\n", "enc_batch_extend_vocab", "=", "batch", "[", "\"context_ext_batch\"", "]", "\n", "enc_vad_batch", "=", "batch", "[", "'context_vad'", "]", "\n", "concept_input", "=", "batch", "[", "\"concept_batch\"", "]", "# (bsz, max_concept_len)", "\n", "concept_ext_input", "=", "batch", "[", "\"concept_ext_batch\"", "]", "\n", "concept_vad_batch", "=", "batch", "[", "'concept_vad_batch'", "]", "\n", "\n", "oovs", "=", "batch", "[", "\"oovs\"", "]", "\n", "max_oov_length", "=", "len", "(", "sorted", "(", "oovs", ",", "key", "=", "lambda", "i", ":", "len", "(", "i", ")", ",", "reverse", "=", "True", ")", "[", "0", "]", ")", "\n", "extra_zeros", "=", "Variable", "(", "torch", ".", "zeros", "(", "(", "enc_batch", ".", "size", "(", "0", ")", ",", "max_oov_length", ")", ")", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "dec_batch", "=", "batch", "[", "\"target_batch\"", "]", "\n", "dec_ext_batch", "=", "batch", "[", "\"target_ext_batch\"", "]", "\n", "\n", "if", "self", ".", "args", ".", "noam", ":", "\n", "            ", "self", ".", "optimizer", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "## Embedding - context", "\n", "", "mask_src", "=", "enc_batch", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "# (bsz, src_len)->(bsz, 1, src_len)", "\n", "emb_mask", "=", "self", ".", "embedding", "(", "batch", "[", "\"mask_context\"", "]", ")", "# dialogue state embedding", "\n", "src_emb", "=", "self", ".", "embedding", "(", "enc_batch", ")", "+", "emb_mask", "\n", "src_vad", "=", "enc_vad_batch", "# (bsz, len, 1)  emotion intensity values", "\n", "\n", "if", "self", ".", "args", ".", "model", "!=", "'wo_ECE'", ":", "# emotional context graph encoding", "\n", "            ", "if", "concept_input", ".", "size", "(", ")", "[", "0", "]", "!=", "0", ":", "\n", "                ", "mask_con", "=", "concept_input", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "# real mask", "\n", "con_mask", "=", "self", ".", "embedding", "(", "batch", "[", "\"mask_concept\"", "]", ")", "# kg embedding", "\n", "con_emb", "=", "self", ".", "embedding", "(", "concept_input", ")", "+", "con_mask", "\n", "\n", "## Knowledge Update", "\n", "src_emb", "=", "self", ".", "concept_graph", "(", "src_emb", ",", "con_emb", ",", "batch", "[", "\"adjacency_mask_batch\"", "]", ")", "# (bsz, context+concept, emb_dim)", "\n", "mask_src", "=", "torch", ".", "cat", "(", "(", "mask_src", ",", "mask_con", ")", ",", "dim", "=", "2", ")", "# (bsz, 1, context+concept)", "\n", "src_vad", "=", "torch", ".", "cat", "(", "(", "enc_vad_batch", ",", "concept_vad_batch", ")", ",", "dim", "=", "1", ")", "# (bsz, len)", "\n", "\n", "## Encode - context & concept", "\n", "", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "src_emb", ",", "mask_src", ")", "# (bsz, src_len, emb_dim)", "\n", "\n", "## emotional signal distilling", "\n", "src_vad", "=", "torch", ".", "softmax", "(", "src_vad", ",", "dim", "=", "-", "1", ")", "\n", "emotion_context_vad", "=", "src_vad", ".", "unsqueeze", "(", "2", ")", "\n", "emotion_context_vad", "=", "emotion_context_vad", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "args", ".", "emb_dim", ")", "# (bsz, len, emb_dim)", "\n", "emotion_context", "=", "torch", ".", "sum", "(", "emotion_context_vad", "*", "encoder_outputs", ",", "dim", "=", "1", ")", "# c_e (bsz, emb_dim)", "\n", "emotion_contexts", "=", "emotion_context_vad", "*", "encoder_outputs", "\n", "\n", "emotion_logit", "=", "self", ".", "identify", "(", "emotion_context", ")", "# e_p (bsz, emotion_num)", "\n", "loss_emotion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", "(", "emotion_logit", ",", "batch", "[", "'emotion_label'", "]", ")", "\n", "\n", "\n", "pred_emotion", "=", "np", ".", "argmax", "(", "emotion_logit", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "emotion_acc", "=", "accuracy_score", "(", "batch", "[", "\"emotion_label\"", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "pred_emotion", ")", "\n", "\n", "# Decode", "\n", "sos_emb", "=", "self", ".", "emotion_embedding", "(", "emotion_logit", ")", ".", "unsqueeze", "(", "1", ")", "# (bsz, 1, emb_dim)", "\n", "dec_emb", "=", "self", ".", "embedding", "(", "dec_batch", "[", ":", ",", ":", "-", "1", "]", ")", "# (bsz, tgt_len, emb_dim)", "\n", "dec_emb", "=", "torch", ".", "cat", "(", "(", "sos_emb", ",", "dec_emb", ")", ",", "dim", "=", "1", ")", "# (bsz, tgt_len, emb_dim)", "\n", "\n", "mask_trg", "=", "dec_batch", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "\n", "if", "\"wo_EDD\"", "in", "self", ".", "args", ".", "model", ":", "\n", "            ", "pre_logit", ",", "attn_dist", ",", "loss_attn", "=", "self", ".", "decoder", "(", "inputs", "=", "dec_emb", ",", "\n", "encoder_output", "=", "encoder_outputs", ",", "\n", "mask", "=", "(", "mask_src", ",", "mask_trg", ")", ",", "\n", "pred_emotion", "=", "None", ",", "\n", "emotion_contexts", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "pre_logit", ",", "attn_dist", ",", "loss_attn", "=", "self", ".", "decoder", "(", "inputs", "=", "dec_emb", ",", "\n", "encoder_output", "=", "encoder_outputs", ",", "\n", "mask", "=", "(", "mask_src", ",", "mask_trg", ")", ",", "\n", "pred_emotion", "=", "None", ",", "\n", "emotion_contexts", "=", "emotion_context", ",", "\n", "context_vad", "=", "src_vad", ")", "\n", "\n", "## compute output dist", "\n", "", "if", "self", ".", "args", ".", "model", "!=", "'wo_ECE'", ":", "# emotional context graph encoding", "\n", "            ", "if", "concept_input", ".", "size", "(", ")", "[", "0", "]", "!=", "0", ":", "\n", "                ", "enc_batch_extend_vocab", "=", "torch", ".", "cat", "(", "(", "enc_batch_extend_vocab", ",", "concept_ext_input", ")", ",", "dim", "=", "1", ")", "\n", "", "", "logit", "=", "self", ".", "generator", "(", "pre_logit", ",", "None", ",", "None", ",", "attn_dist", ",", "enc_batch_extend_vocab", "if", "self", ".", "args", ".", "pointer_gen", "else", "None", ",", "extra_zeros", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "logit", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "logit", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "dec_batch", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "if", "self", ".", "args", ".", "pointer_gen", "else", "dec_ext_batch", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", "+=", "loss_emotion", "\n", "if", "self", ".", "args", ".", "attn_loss", "and", "self", ".", "args", ".", "model", "!=", "\"wo_EDD\"", ":", "\n", "            ", "loss", "+=", "(", "0.1", "*", "loss_attn", ")", "\n", "\n", "", "loss_ppl", "=", "0.0", "\n", "if", "self", ".", "args", ".", "label_smoothing", ":", "\n", "            ", "loss_ppl", "=", "self", ".", "criterion_ppl", "(", "logit", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "logit", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "dec_batch", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "if", "self", ".", "args", ".", "pointer_gen", "else", "dec_ext_batch", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "loss", ")", ")", "!=", "0", ":", "\n", "            ", "print", "(", "'loss is NAN :('", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "", "if", "train", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "label_smoothing", ":", "\n", "            ", "return", "loss_ppl", ",", "math", ".", "exp", "(", "min", "(", "loss_ppl", ",", "100", ")", ")", ",", "loss_emotion", ".", "item", "(", ")", ",", "emotion_acc", "\n", "", "else", ":", "\n", "            ", "return", "loss", ".", "item", "(", ")", ",", "math", ".", "exp", "(", "min", "(", "loss", ".", "item", "(", ")", ",", "100", ")", ")", ",", "0", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.compute_act_loss": [[497, 504], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "p_t.size", "avg_p_t.item", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "p_t.size"], "methods", ["None"], ["", "", "def", "compute_act_loss", "(", "self", ",", "module", ")", ":", "\n", "        ", "R_t", "=", "module", ".", "remainders", "\n", "N_t", "=", "module", ".", "n_updates", "\n", "p_t", "=", "R_t", "+", "N_t", "\n", "avg_p_t", "=", "torch", ".", "sum", "(", "torch", ".", "sum", "(", "p_t", ",", "dim", "=", "1", ")", "/", "p_t", ".", "size", "(", "1", ")", ")", "/", "p_t", ".", "size", "(", "0", ")", "\n", "loss", "=", "self", ".", "args", ".", "act_loss_weight", "*", "avg_p_t", ".", "item", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.decoder_greedy": [[505, 592], ["len", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "enc_batch.data.eq().unsqueeze", "KEMP.KEMP.embedding", "KEMP.KEMP.encoder", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "emotion_context_vad.repeat.repeat.repeat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "KEMP.KEMP.identify", "torch.ones().fill_().long", "torch.ones().fill_().long", "torch.ones().fill_().long", "torch.ones().fill_().long", "torch.ones().fill_().long", "torch.ones().fill_().long", "torch.ones().fill_().long", "torch.ones().fill_().long", "torch.ones().fill_().long", "KEMP.KEMP.emotion_embedding().unsqueeze", "torch.cat.data.eq().unsqueeze", "torch.cat.data.eq().unsqueeze", "torch.cat.data.eq().unsqueeze", "range", "enumerate", "KEMP.KEMP.embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.cuda", "torch.cat.cuda", "torch.cat.cuda", "KEMP.KEMP.generator", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "decoded_words.append", "torch.cat.data.eq().unsqueeze", "torch.cat.data.eq().unsqueeze", "torch.cat.data.eq().unsqueeze", "numpy.transpose", "sent.append", "sorted", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "enc_batch.data.eq", "concept_input.data.eq().unsqueeze", "KEMP.KEMP.embedding", "KEMP.KEMP.concept_graph", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "KEMP.KEMP.emotion_embedding", "torch.cat.data.eq", "torch.cat.data.eq", "torch.cat.data.eq", "KEMP.KEMP.decoder", "KEMP.KEMP.decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.cuda", "torch.cat.cuda", "torch.cat.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "concept_input.size", "KEMP.KEMP.embedding", "concept_input.size", "KEMP.KEMP.embedding_proj_in", "KEMP.KEMP.embedding_proj_in", "torch.cat.data.eq", "torch.cat.data.eq", "torch.cat.data.eq", "concept_input.data.eq", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "next_word.view", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "KEMP.KEMP.embedding", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "KEMP.KEMP.embedding", "len", "enc_batch.size", "ni.item", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_().cuda", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "str", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "ni.item", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long().fill_", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.KEMP.KEMP.concept_graph"], ["", "def", "decoder_greedy", "(", "self", ",", "batch", ",", "max_dec_step", "=", "30", ")", ":", "\n", "        ", "enc_batch_extend_vocab", ",", "extra_zeros", "=", "None", ",", "None", "\n", "enc_batch", "=", "batch", "[", "\"context_batch\"", "]", "\n", "enc_vad_batch", "=", "batch", "[", "'context_vad'", "]", "\n", "enc_batch_extend_vocab", "=", "batch", "[", "\"context_ext_batch\"", "]", "\n", "\n", "concept_input", "=", "batch", "[", "\"concept_batch\"", "]", "# (bsz, max_concept_len)", "\n", "concept_ext_input", "=", "batch", "[", "\"concept_ext_batch\"", "]", "\n", "concept_vad_batch", "=", "batch", "[", "'concept_vad_batch'", "]", "\n", "oovs", "=", "batch", "[", "\"oovs\"", "]", "\n", "max_oov_length", "=", "len", "(", "sorted", "(", "oovs", ",", "key", "=", "lambda", "i", ":", "len", "(", "i", ")", ",", "reverse", "=", "True", ")", "[", "0", "]", ")", "\n", "extra_zeros", "=", "Variable", "(", "torch", ".", "zeros", "(", "(", "enc_batch", ".", "size", "(", "0", ")", ",", "max_oov_length", ")", ")", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "## Encode - context", "\n", "mask_src", "=", "enc_batch", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "# (bsz, src_len)->(bsz, 1, src_len)", "\n", "emb_mask", "=", "self", ".", "embedding", "(", "batch", "[", "\"mask_context\"", "]", ")", "\n", "src_emb", "=", "self", ".", "embedding", "(", "enc_batch", ")", "+", "emb_mask", "\n", "src_vad", "=", "enc_vad_batch", "# (bsz, len, 1)", "\n", "\n", "if", "self", ".", "args", ".", "model", "!=", "'wo_ECE'", ":", "# emotional context graph encoding", "\n", "            ", "if", "concept_input", ".", "size", "(", ")", "[", "0", "]", "!=", "0", ":", "\n", "                ", "mask_con", "=", "concept_input", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "# real mask", "\n", "con_mask", "=", "self", ".", "embedding", "(", "batch", "[", "\"mask_concept\"", "]", ")", "# dialogue state", "\n", "con_emb", "=", "self", ".", "embedding", "(", "concept_input", ")", "+", "con_mask", "\n", "\n", "## Knowledge Update", "\n", "src_emb", "=", "self", ".", "concept_graph", "(", "src_emb", ",", "con_emb", ",", "\n", "batch", "[", "\"adjacency_mask_batch\"", "]", ")", "# (bsz, context+concept, emb_dim)", "\n", "mask_src", "=", "torch", ".", "cat", "(", "(", "mask_src", ",", "mask_con", ")", ",", "dim", "=", "2", ")", "# (bsz, 1, context+concept)", "\n", "\n", "src_vad", "=", "torch", ".", "cat", "(", "(", "enc_vad_batch", ",", "concept_vad_batch", ")", ",", "dim", "=", "1", ")", "# (bsz, len)", "\n", "", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "src_emb", ",", "mask_src", ")", "# (bsz, src_len, emb_dim)", "\n", "\n", "## Identify", "\n", "src_vad", "=", "torch", ".", "softmax", "(", "src_vad", ",", "dim", "=", "-", "1", ")", "\n", "emotion_context_vad", "=", "src_vad", ".", "unsqueeze", "(", "2", ")", "\n", "emotion_context_vad", "=", "emotion_context_vad", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "args", ".", "emb_dim", ")", "# (bsz, len, emb_dim)", "\n", "emotion_context", "=", "torch", ".", "sum", "(", "emotion_context_vad", "*", "encoder_outputs", ",", "dim", "=", "1", ")", "# c_e (bsz, emb_dim)", "\n", "emotion_contexts", "=", "emotion_context_vad", "*", "encoder_outputs", "\n", "\n", "emotion_logit", "=", "self", ".", "identify", "(", "emotion_context", ")", "# (bsz, emotion_num)", "\n", "\n", "if", "concept_input", ".", "size", "(", ")", "[", "0", "]", "!=", "0", "and", "self", ".", "args", ".", "model", "!=", "'wo_ECE'", ":", "\n", "            ", "enc_ext_batch", "=", "torch", ".", "cat", "(", "(", "enc_batch_extend_vocab", ",", "concept_ext_input", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "enc_ext_batch", "=", "enc_batch_extend_vocab", "\n", "\n", "", "ys", "=", "torch", ".", "ones", "(", "1", ",", "1", ")", ".", "fill_", "(", "self", ".", "args", ".", "SOS_idx", ")", ".", "long", "(", ")", "\n", "ys_emb", "=", "self", ".", "emotion_embedding", "(", "emotion_logit", ")", ".", "unsqueeze", "(", "1", ")", "# (bsz, 1, emb_dim)", "\n", "sos_emb", "=", "ys_emb", "\n", "if", "self", ".", "args", ".", "USE_CUDA", ":", "\n", "            ", "ys", "=", "ys", ".", "cuda", "(", ")", "\n", "", "mask_trg", "=", "ys", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "\n", "decoded_words", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "max_dec_step", "+", "1", ")", ":", "\n", "            ", "if", "self", ".", "args", ".", "project", ":", "\n", "                ", "out", ",", "attn_dist", ",", "_", "=", "self", ".", "decoder", "(", "self", ".", "embedding_proj_in", "(", "ys_emb", ")", ",", "self", ".", "embedding_proj_in", "(", "encoder_outputs", ")", ",", "(", "mask_src", ",", "mask_trg", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", ",", "attn_dist", ",", "_", "=", "self", ".", "decoder", "(", "inputs", "=", "ys_emb", ",", "\n", "encoder_output", "=", "encoder_outputs", ",", "\n", "mask", "=", "(", "mask_src", ",", "mask_trg", ")", ",", "\n", "pred_emotion", "=", "None", ",", "\n", "emotion_contexts", "=", "emotion_context", ",", "\n", "context_vad", "=", "src_vad", ")", "\n", "\n", "", "prob", "=", "self", ".", "generator", "(", "out", ",", "None", ",", "None", ",", "attn_dist", ",", "enc_ext_batch", "if", "self", ".", "args", ".", "pointer_gen", "else", "None", ",", "extra_zeros", ")", "\n", "_", ",", "next_word", "=", "torch", ".", "max", "(", "prob", "[", ":", ",", "-", "1", "]", ",", "dim", "=", "1", ")", "\n", "decoded_words", ".", "append", "(", "[", "'<EOS>'", "if", "ni", ".", "item", "(", ")", "==", "self", ".", "args", ".", "EOS_idx", "else", "self", ".", "index2word", "[", "str", "(", "ni", ".", "item", "(", ")", ")", "]", "for", "ni", "in", "next_word", ".", "view", "(", "-", "1", ")", "]", ")", "\n", "next_word", "=", "next_word", ".", "data", "[", "0", "]", "\n", "\n", "if", "self", ".", "args", ".", "use_cuda", ":", "\n", "                ", "ys", "=", "torch", ".", "cat", "(", "[", "ys", ",", "torch", ".", "ones", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "fill_", "(", "next_word", ")", ".", "cuda", "(", ")", "]", ",", "dim", "=", "1", ")", "\n", "ys", "=", "ys", ".", "cuda", "(", ")", "\n", "ys_emb", "=", "torch", ".", "cat", "(", "(", "ys_emb", ",", "self", ".", "embedding", "(", "torch", ".", "ones", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "fill_", "(", "next_word", ")", ".", "cuda", "(", ")", ")", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "ys", "=", "torch", ".", "cat", "(", "[", "ys", ",", "torch", ".", "ones", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "fill_", "(", "next_word", ")", "]", ",", "dim", "=", "1", ")", "\n", "ys_emb", "=", "torch", ".", "cat", "(", "(", "ys_emb", ",", "self", ".", "embedding", "(", "torch", ".", "ones", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "fill_", "(", "next_word", ")", ")", ")", ",", "dim", "=", "1", ")", "\n", "", "mask_trg", "=", "ys", ".", "data", ".", "eq", "(", "self", ".", "args", ".", "PAD_idx", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "sent", "=", "[", "]", "\n", "for", "_", ",", "row", "in", "enumerate", "(", "np", ".", "transpose", "(", "decoded_words", ")", ")", ":", "\n", "            ", "st", "=", "''", "\n", "for", "e", "in", "row", ":", "\n", "                ", "if", "e", "==", "'<EOS>'", ":", "break", "\n", "else", ":", "st", "+=", "e", "+", "' '", "\n", "", "sent", ".", "append", "(", "st", ")", "\n", "", "return", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__init__": [[12, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "word2index", ",", "args", ")", ":", "\n", "        ", "\"\"\"Reads source and target sequences from txt files.\"\"\"", "\n", "self", ".", "word2index", "=", "word2index", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "emo_map", "=", "{", "\n", "'surprised'", ":", "0", ",", "'excited'", ":", "1", ",", "'annoyed'", ":", "2", ",", "'proud'", ":", "3", ",", "'angry'", ":", "4", ",", "'sad'", ":", "5", ",", "'grateful'", ":", "6", ",", "'lonely'", ":", "7", ",", "\n", "'impressed'", ":", "8", ",", "'afraid'", ":", "9", ",", "'disgusted'", ":", "10", ",", "'confident'", ":", "11", ",", "'terrified'", ":", "12", ",", "'hopeful'", ":", "13", ",", "\n", "'anxious'", ":", "14", ",", "'disappointed'", ":", "15", ",", "\n", "'joyful'", ":", "16", ",", "'prepared'", ":", "17", ",", "'guilty'", ":", "18", ",", "'furious'", ":", "19", ",", "'nostalgic'", ":", "20", ",", "'jealous'", ":", "21", ",", "\n", "'anticipating'", ":", "22", ",", "'embarrassed'", ":", "23", ",", "\n", "'content'", ":", "24", ",", "'devastated'", ":", "25", ",", "'sentimental'", ":", "26", ",", "'caring'", ":", "27", ",", "'trusting'", ":", "28", ",", "'ashamed'", ":", "29", ",", "\n", "'apprehensive'", ":", "30", ",", "'faithful'", ":", "31", "}", "\n", "self", ".", "map_emo", "=", "{", "0", ":", "'surprised'", ",", "1", ":", "'excited'", ",", "2", ":", "'annoyed'", ",", "3", ":", "'proud'", ",", "\n", "4", ":", "'angry'", ",", "5", ":", "'sad'", ",", "6", ":", "'grateful'", ",", "7", ":", "'lonely'", ",", "8", ":", "'impressed'", ",", "\n", "9", ":", "'afraid'", ",", "10", ":", "'disgusted'", ",", "11", ":", "'confident'", ",", "12", ":", "'terrified'", ",", "\n", "13", ":", "'hopeful'", ",", "14", ":", "'anxious'", ",", "15", ":", "'disappointed'", ",", "16", ":", "'joyful'", ",", "\n", "17", ":", "'prepared'", ",", "18", ":", "'guilty'", ",", "19", ":", "'furious'", ",", "20", ":", "'nostalgic'", ",", "\n", "21", ":", "'jealous'", ",", "22", ":", "'anticipating'", ",", "23", ":", "'embarrassed'", ",", "24", ":", "'content'", ",", "\n", "25", ":", "'devastated'", ",", "26", ":", "'sentimental'", ",", "27", ":", "'caring'", ",", "28", ":", "'trusting'", ",", "\n", "29", ":", "'ashamed'", ",", "30", ":", "'apprehensive'", ",", "31", ":", "'faithful'", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__getitem__": [[34, 56], ["dataloader.Dataset.preprocess", "dataloader.Dataset.preprocess", "dataloader.Dataset.target_oovs", "dataloader.Dataset.preprocess_emo"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.preprocess", "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.preprocess", "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.target_oovs", "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.preprocess_emo"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns one data pair (source and target).\"\"\"", "\n", "item", "=", "{", "}", "\n", "item", "[", "\"context_text\"", "]", "=", "self", ".", "data", "[", "\"context\"", "]", "[", "index", "]", "\n", "item", "[", "\"target_text\"", "]", "=", "self", ".", "data", "[", "\"target\"", "]", "[", "index", "]", "\n", "item", "[", "\"emotion_text\"", "]", "=", "self", ".", "data", "[", "\"emotion\"", "]", "[", "index", "]", "\n", "\n", "inputs", "=", "self", ".", "preprocess", "(", "[", "self", ".", "data", "[", "\"context\"", "]", "[", "index", "]", ",", "\n", "self", ".", "data", "[", "\"vads\"", "]", "[", "index", "]", ",", "\n", "self", ".", "data", "[", "\"vad\"", "]", "[", "index", "]", ",", "\n", "self", ".", "data", "[", "\"concepts\"", "]", "[", "index", "]", "]", ")", "\n", "item", "[", "\"context\"", "]", ",", "item", "[", "\"context_ext\"", "]", ",", "item", "[", "\"context_mask\"", "]", ",", "item", "[", "\"vads\"", "]", ",", "item", "[", "\"vad\"", "]", ",", "item", "[", "\"concept_text\"", "]", ",", "item", "[", "\"concept\"", "]", ",", "item", "[", "\"concept_ext\"", "]", ",", "item", "[", "\"concept_vads\"", "]", ",", "item", "[", "\"concept_vad\"", "]", ",", "item", "[", "\"oovs\"", "]", "=", "inputs", "\n", "\n", "item", "[", "\"target\"", "]", "=", "self", ".", "preprocess", "(", "item", "[", "\"target_text\"", "]", ",", "anw", "=", "True", ")", "\n", "item", "[", "\"target_ext\"", "]", "=", "self", ".", "target_oovs", "(", "item", "[", "\"target_text\"", "]", ",", "item", "[", "\"oovs\"", "]", ")", "\n", "item", "[", "\"emotion\"", "]", ",", "item", "[", "\"emotion_label\"", "]", "=", "self", ".", "preprocess_emo", "(", "item", "[", "\"emotion_text\"", "]", ",", "\n", "self", ".", "emo_map", ")", "# one-hot and scalor label", "\n", "item", "[", "\"emotion_widx\"", "]", "=", "self", ".", "word2index", "[", "item", "[", "\"emotion_text\"", "]", "]", "\n", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.__len__": [[57, 59], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", "[", "\"target\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.target_oovs": [[60, 72], ["ids.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "ids.append", "ids.append", "ids.append", "len", "oovs.index"], "methods", ["None"], ["", "def", "target_oovs", "(", "self", ",", "target", ",", "oovs", ")", ":", "\n", "        ", "ids", "=", "[", "]", "\n", "for", "w", "in", "target", ":", "\n", "            ", "if", "w", "not", "in", "self", ".", "word2index", ":", "\n", "                ", "if", "w", "in", "oovs", ":", "\n", "                    ", "ids", ".", "append", "(", "len", "(", "self", ".", "word2index", ")", "+", "oovs", ".", "index", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                    ", "ids", ".", "append", "(", "self", ".", "args", ".", "UNK_idx", ")", "\n", "", "", "else", ":", "\n", "                ", "ids", ".", "append", "(", "self", ".", "word2index", "[", "w", "]", ")", "\n", "", "", "ids", ".", "append", "(", "self", ".", "args", ".", "EOS_idx", ")", "\n", "return", "torch", ".", "LongTensor", "(", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.process_oov": [[73, 93], ["enumerate", "ids.append", "oovs.index", "ids.append", "oovs.append", "oovs.append", "len"], "methods", ["None"], ["", "def", "process_oov", "(", "self", ",", "context", ",", "concept", ")", ":", "#", "\n", "        ", "ids", "=", "[", "]", "\n", "oovs", "=", "[", "]", "\n", "for", "si", ",", "sentence", "in", "enumerate", "(", "context", ")", ":", "\n", "            ", "for", "w", "in", "sentence", ":", "\n", "                ", "if", "w", "in", "self", ".", "word2index", ":", "\n", "                    ", "i", "=", "self", ".", "word2index", "[", "w", "]", "\n", "ids", ".", "append", "(", "i", ")", "\n", "", "else", ":", "\n", "                    ", "if", "w", "not", "in", "oovs", ":", "\n", "                        ", "oovs", ".", "append", "(", "w", ")", "\n", "", "oov_num", "=", "oovs", ".", "index", "(", "w", ")", "\n", "ids", ".", "append", "(", "len", "(", "self", ".", "word2index", ")", "+", "oov_num", ")", "\n", "\n", "", "", "", "for", "sentence_concept", "in", "concept", ":", "\n", "            ", "for", "token_concept", "in", "sentence_concept", ":", "\n", "                ", "for", "c", "in", "token_concept", ":", "\n", "                    ", "if", "c", "not", "in", "oovs", "and", "c", "not", "in", "self", ".", "word2index", ":", "\n", "                        ", "oovs", ".", "append", "(", "c", ")", "\n", "", "", "", "", "return", "ids", ",", "oovs", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.preprocess": [[94, 159], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "collections.defaultdict", "dataloader.Dataset.process_oov", "enumerate", "len", "len", "enumerate", "len", "len", "len", "len", "len", "range", "range", "range", "len", "len", "len", "range", "X_concept.append", "X_concept_ext.append", "X_concept_vads.append", "X_concept_vad.append", "X_concept.append", "X_concept_ext.append", "X_concept_vads.append", "X_concept_vad.append", "len", "len", "len", "len", "con_ext.append", "con_ext.append", "con_ext.append", "X_oovs.index", "len"], "methods", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.process_oov"], ["", "def", "preprocess", "(", "self", ",", "arr", ",", "anw", "=", "False", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "if", "anw", ":", "\n", "            ", "sequence", "=", "[", "self", ".", "word2index", "[", "word", "]", "if", "word", "in", "self", ".", "word2index", "else", "self", ".", "args", ".", "UNK_idx", "for", "word", "in", "arr", "]", "+", "[", "self", ".", "args", ".", "EOS_idx", "]", "\n", "return", "torch", ".", "LongTensor", "(", "sequence", ")", "\n", "", "else", ":", "\n", "            ", "context", "=", "arr", "[", "0", "]", "\n", "context_vads", "=", "arr", "[", "1", "]", "\n", "context_vad", "=", "arr", "[", "2", "]", "\n", "concept", "=", "[", "arr", "[", "3", "]", "[", "l", "]", "[", "0", "]", "for", "l", "in", "range", "(", "len", "(", "arr", "[", "3", "]", ")", ")", "]", "\n", "concept_vads", "=", "[", "arr", "[", "3", "]", "[", "l", "]", "[", "1", "]", "for", "l", "in", "range", "(", "len", "(", "arr", "[", "3", "]", ")", ")", "]", "\n", "concept_vad", "=", "[", "arr", "[", "3", "]", "[", "l", "]", "[", "2", "]", "for", "l", "in", "range", "(", "len", "(", "arr", "[", "3", "]", ")", ")", "]", "\n", "\n", "X_dial", "=", "[", "self", ".", "args", ".", "CLS_idx", "]", "\n", "X_dial_ext", "=", "[", "self", ".", "args", ".", "CLS_idx", "]", "\n", "X_mask", "=", "[", "self", ".", "args", ".", "CLS_idx", "]", "# for dialogue state", "\n", "X_vads", "=", "[", "[", "0.5", ",", "0.0", ",", "0.5", "]", "]", "\n", "X_vad", "=", "[", "0.0", "]", "\n", "\n", "X_concept_text", "=", "defaultdict", "(", "list", ")", "\n", "X_concept", "=", "[", "[", "]", "]", "# \u521d\u59cb\u503c\u662fcls token", "\n", "X_concept_ext", "=", "[", "[", "]", "]", "\n", "X_concept_vads", "=", "[", "[", "0.5", ",", "0.0", ",", "0.5", "]", "]", "\n", "X_concept_vad", "=", "[", "0.0", "]", "\n", "assert", "len", "(", "context", ")", "==", "len", "(", "concept", ")", "\n", "\n", "X_ext", ",", "X_oovs", "=", "self", ".", "process_oov", "(", "context", ",", "concept", ")", "\n", "X_dial_ext", "+=", "X_ext", "\n", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "context", ")", ":", "\n", "                ", "X_dial", "+=", "[", "self", ".", "word2index", "[", "word", "]", "if", "word", "in", "self", ".", "word2index", "else", "self", ".", "args", ".", "UNK_idx", "for", "word", "in", "sentence", "]", "\n", "spk", "=", "self", ".", "word2index", "[", "\"[USR]\"", "]", "if", "i", "%", "2", "==", "0", "else", "self", ".", "word2index", "[", "\"[SYS]\"", "]", "\n", "X_mask", "+=", "[", "spk", "for", "_", "in", "range", "(", "len", "(", "sentence", ")", ")", "]", "\n", "X_vads", "+=", "context_vads", "[", "i", "]", "\n", "X_vad", "+=", "context_vad", "[", "i", "]", "\n", "\n", "for", "j", ",", "token_conlist", "in", "enumerate", "(", "concept", "[", "i", "]", ")", ":", "\n", "                    ", "if", "token_conlist", "==", "[", "]", ":", "\n", "                        ", "X_concept", ".", "append", "(", "[", "]", ")", "\n", "X_concept_ext", ".", "append", "(", "[", "]", ")", "\n", "X_concept_vads", ".", "append", "(", "[", "0.5", ",", "0.0", ",", "0.5", "]", ")", "# ??", "\n", "X_concept_vad", ".", "append", "(", "0.0", ")", "\n", "", "else", ":", "\n", "                        ", "X_concept_text", "[", "sentence", "[", "j", "]", "]", "+=", "token_conlist", "[", ":", "self", ".", "args", ".", "concept_num", "]", "\n", "X_concept", ".", "append", "(", "[", "self", ".", "word2index", "[", "con_word", "]", "if", "con_word", "in", "self", ".", "word2index", "else", "self", ".", "args", ".", "UNK_idx", "for", "con_word", "in", "token_conlist", "[", ":", "self", ".", "args", ".", "concept_num", "]", "]", ")", "\n", "\n", "con_ext", "=", "[", "]", "\n", "for", "con_word", "in", "token_conlist", "[", ":", "self", ".", "args", ".", "concept_num", "]", ":", "\n", "                            ", "if", "con_word", "in", "self", ".", "word2index", ":", "\n", "                                ", "con_ext", ".", "append", "(", "self", ".", "word2index", "[", "con_word", "]", ")", "\n", "", "else", ":", "\n", "                                ", "if", "con_word", "in", "X_oovs", ":", "\n", "                                    ", "con_ext", ".", "append", "(", "X_oovs", ".", "index", "(", "con_word", ")", "+", "len", "(", "self", ".", "word2index", ")", ")", "\n", "", "else", ":", "\n", "                                    ", "con_ext", ".", "append", "(", "self", ".", "args", ".", "UNK_idx", ")", "\n", "", "", "", "X_concept_ext", ".", "append", "(", "con_ext", ")", "\n", "X_concept_vads", ".", "append", "(", "concept_vads", "[", "i", "]", "[", "j", "]", "[", ":", "self", ".", "args", ".", "concept_num", "]", ")", "\n", "X_concept_vad", ".", "append", "(", "concept_vad", "[", "i", "]", "[", "j", "]", "[", ":", "self", ".", "args", ".", "concept_num", "]", ")", "\n", "\n", "assert", "len", "(", "[", "self", ".", "word2index", "[", "con_word", "]", "if", "con_word", "in", "self", ".", "word2index", "else", "self", ".", "args", ".", "UNK_idx", "for", "con_word", "in", "token_conlist", "[", ":", "self", ".", "args", ".", "concept_num", "]", "]", ")", "==", "len", "(", "concept_vads", "[", "i", "]", "[", "j", "]", "[", ":", "self", ".", "args", ".", "concept_num", "]", ")", "==", "len", "(", "concept_vad", "[", "i", "]", "[", "j", "]", "[", ":", "self", ".", "args", ".", "concept_num", "]", ")", "\n", "", "", "", "assert", "len", "(", "X_dial", ")", "==", "len", "(", "X_mask", ")", "==", "len", "(", "X_concept", ")", "==", "len", "(", "X_concept_vad", ")", "==", "len", "(", "X_concept_vads", ")", "\n", "\n", "return", "X_dial", ",", "X_dial_ext", ",", "X_mask", ",", "X_vads", ",", "X_vad", ",", "X_concept_text", ",", "X_concept", ",", "X_concept_ext", ",", "X_concept_vads", ",", "X_concept_vad", ",", "X_oovs", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.preprocess_emo": [[160, 164], ["len"], "methods", ["None"], ["", "", "def", "preprocess_emo", "(", "self", ",", "emotion", ",", "emo_map", ")", ":", "\n", "        ", "program", "=", "[", "0", "]", "*", "len", "(", "emo_map", ")", "\n", "program", "[", "emo_map", "[", "emotion", "]", "]", "=", "1", "\n", "return", "program", ",", "emo_map", "[", "emotion", "]", "# one", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.Dataset.collate_fn": [[166, 397], ["batch_data.sort", "batch_data[].keys", "dataloader.Dataset.collate_fn.merge"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch_data", ")", ":", "\n", "        ", "def", "merge", "(", "sequences", ")", ":", "# len(sequences) = bsz", "\n", "            ", "lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "sequences", "]", "\n", "padded_seqs", "=", "torch", ".", "ones", "(", "len", "(", "sequences", ")", ",", "max", "(", "lengths", ")", ")", ".", "long", "(", ")", "## padding index 1 1=True, in mask means padding.", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "                ", "end", "=", "lengths", "[", "i", "]", "\n", "padded_seqs", "[", "i", ",", ":", "end", "]", "=", "torch", ".", "LongTensor", "(", "seq", "[", ":", "end", "]", ")", "\n", "", "return", "padded_seqs", ",", "lengths", "\n", "\n", "", "def", "merge_concept", "(", "samples", ",", "samples_ext", ",", "samples_vads", ",", "samples_vad", ")", ":", "\n", "            ", "concept_lengths", "=", "[", "]", "# \u6bcf\u4e2asample\u7684concepts\u6570\u76ee", "\n", "token_concept_lengths", "=", "[", "]", "# \u6bcf\u4e2asample\u7684\u6bcf\u4e2atoken\u7684concepts\u6570\u76ee", "\n", "concepts_list", "=", "[", "]", "\n", "concepts_ext_list", "=", "[", "]", "\n", "concepts_vads_list", "=", "[", "]", "\n", "concepts_vad_list", "=", "[", "]", "\n", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "\n", "                ", "length", "=", "0", "# \u8bb0\u5f55\u5f53\u524d\u6837\u672c\u603b\u5171\u6709\u591a\u5c11\u4e2aconcept\uff0c", "\n", "sample_concepts", "=", "[", "]", "\n", "sample_concepts_ext", "=", "[", "]", "\n", "token_length", "=", "[", "]", "\n", "vads", "=", "[", "]", "\n", "vad", "=", "[", "]", "\n", "\n", "for", "c", ",", "token", "in", "enumerate", "(", "sample", ")", ":", "\n", "                    ", "if", "token", "==", "[", "]", ":", "# \u8fd9\u4e2atoken\u6ca1\u6709concept", "\n", "                        ", "token_length", ".", "append", "(", "0", ")", "\n", "continue", "\n", "", "length", "+=", "len", "(", "token", ")", "\n", "token_length", ".", "append", "(", "len", "(", "token", ")", ")", "\n", "sample_concepts", "+=", "token", "\n", "sample_concepts_ext", "+=", "samples_ext", "[", "i", "]", "[", "c", "]", "\n", "vads", "+=", "samples_vads", "[", "i", "]", "[", "c", "]", "\n", "vad", "+=", "samples_vad", "[", "i", "]", "[", "c", "]", "\n", "\n", "", "if", "length", ">", "self", ".", "args", ".", "total_concept_num", ":", "\n", "                    ", "value", ",", "rank", "=", "torch", ".", "topk", "(", "torch", ".", "LongTensor", "(", "vad", ")", ",", "k", "=", "self", ".", "args", ".", "total_concept_num", ")", "\n", "\n", "new_length", "=", "1", "\n", "new_sample_concepts", "=", "[", "self", ".", "args", ".", "SEP_idx", "]", "# for each sample", "\n", "new_sample_concepts_ext", "=", "[", "self", ".", "args", ".", "SEP_idx", "]", "\n", "new_token_length", "=", "[", "]", "\n", "new_vads", "=", "[", "[", "0.5", ",", "0.0", ",", "0.5", "]", "]", "\n", "new_vad", "=", "[", "0.0", "]", "\n", "\n", "cur_idx", "=", "0", "\n", "for", "ti", ",", "token", "in", "enumerate", "(", "sample", ")", ":", "\n", "                        ", "if", "token", "==", "[", "]", ":", "\n", "                            ", "new_token_length", ".", "append", "(", "0", ")", "\n", "continue", "\n", "", "top_length", "=", "0", "\n", "for", "ci", ",", "con", "in", "enumerate", "(", "token", ")", ":", "\n", "                            ", "point_idx", "=", "cur_idx", "+", "ci", "\n", "if", "point_idx", "in", "rank", ":", "\n", "                                ", "top_length", "+=", "1", "\n", "new_length", "+=", "1", "\n", "new_sample_concepts", ".", "append", "(", "con", ")", "\n", "new_sample_concepts_ext", ".", "append", "(", "samples_ext", "[", "i", "]", "[", "ti", "]", "[", "ci", "]", ")", "\n", "new_vads", ".", "append", "(", "samples_vads", "[", "i", "]", "[", "ti", "]", "[", "ci", "]", ")", "\n", "new_vad", ".", "append", "(", "samples_vad", "[", "i", "]", "[", "ti", "]", "[", "ci", "]", ")", "\n", "assert", "len", "(", "samples_vads", "[", "i", "]", "[", "ti", "]", "[", "ci", "]", ")", "==", "3", "\n", "\n", "", "", "new_token_length", ".", "append", "(", "top_length", ")", "\n", "cur_idx", "+=", "len", "(", "token", ")", "\n", "\n", "", "new_length", "+=", "1", "# for sep token", "\n", "new_sample_concepts", "=", "[", "self", ".", "args", ".", "SEP_idx", "]", "+", "new_sample_concepts", "\n", "new_sample_concepts_ext", "=", "[", "self", ".", "args", ".", "SEP_idx", "]", "+", "new_sample_concepts_ext", "\n", "new_vads", "=", "[", "[", "0.5", ",", "0.0", ",", "0.5", "]", "]", "+", "new_vads", "\n", "new_vad", "=", "[", "0.0", "]", "+", "new_vad", "\n", "\n", "concept_lengths", ".", "append", "(", "new_length", ")", "# the number of concepts including SEP", "\n", "token_concept_lengths", ".", "append", "(", "new_token_length", ")", "# the number of tokens which have concepts", "\n", "concepts_list", ".", "append", "(", "new_sample_concepts", ")", "\n", "concepts_ext_list", ".", "append", "(", "new_sample_concepts_ext", ")", "\n", "concepts_vads_list", ".", "append", "(", "new_vads", ")", "\n", "concepts_vad_list", ".", "append", "(", "new_vad", ")", "\n", "assert", "len", "(", "new_sample_concepts", ")", "==", "len", "(", "new_vads", ")", "==", "len", "(", "new_vad", ")", "==", "len", "(", "new_sample_concepts_ext", ")", ",", "\"The number of concept tokens, vads [*,*,*], and vad * should be the same.\"", "\n", "assert", "len", "(", "new_token_length", ")", "==", "len", "(", "token_length", ")", "\n", "", "else", ":", "\n", "                    ", "length", "+=", "1", "\n", "sample_concepts", "=", "[", "self", ".", "args", ".", "SEP_idx", "]", "+", "sample_concepts", "\n", "sample_concepts_ext", "=", "[", "self", ".", "args", ".", "SEP_idx", "]", "+", "sample_concepts_ext", "\n", "vads", "=", "[", "[", "0.5", ",", "0.0", ",", "0.5", "]", "]", "+", "vads", "\n", "vad", "=", "[", "0.0", "]", "+", "vad", "\n", "\n", "concept_lengths", ".", "append", "(", "length", ")", "\n", "token_concept_lengths", ".", "append", "(", "token_length", ")", "\n", "concepts_list", ".", "append", "(", "sample_concepts", ")", "\n", "concepts_ext_list", ".", "append", "(", "sample_concepts_ext", ")", "\n", "concepts_vads_list", ".", "append", "(", "vads", ")", "\n", "concepts_vad_list", ".", "append", "(", "vad", ")", "\n", "\n", "", "", "if", "max", "(", "concept_lengths", ")", "!=", "0", ":", "\n", "                ", "padded_concepts", "=", "torch", ".", "ones", "(", "len", "(", "samples", ")", ",", "max", "(", "concept_lengths", ")", ")", ".", "long", "(", ")", "## padding index 1 (bsz, max_concept_len); add 1 for root", "\n", "padded_concepts_ext", "=", "torch", ".", "ones", "(", "len", "(", "samples", ")", ",", "max", "(", "concept_lengths", ")", ")", ".", "long", "(", ")", "## padding index 1 (bsz, max_concept_len)", "\n", "padded_concepts_vads", "=", "torch", ".", "FloatTensor", "(", "[", "[", "[", "0.5", ",", "0.0", ",", "0.5", "]", "]", "]", ")", ".", "repeat", "(", "len", "(", "samples", ")", ",", "max", "(", "concept_lengths", ")", ",", "1", ")", "## padding index 1 (bsz, max_concept_len)", "\n", "padded_concepts_vad", "=", "torch", ".", "FloatTensor", "(", "[", "[", "0.0", "]", "]", ")", ".", "repeat", "(", "len", "(", "samples", ")", ",", "max", "(", "concept_lengths", ")", ")", "## padding index 1 (bsz, max_concept_len)", "\n", "padded_mask", "=", "torch", ".", "ones", "(", "len", "(", "samples", ")", ",", "max", "(", "concept_lengths", ")", ")", ".", "long", "(", ")", "# concept(dialogue) state", "\n", "\n", "for", "j", ",", "concepts", "in", "enumerate", "(", "concepts_list", ")", ":", "\n", "                    ", "end", "=", "concept_lengths", "[", "j", "]", "\n", "if", "end", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "padded_concepts", "[", "j", ",", ":", "end", "]", "=", "torch", ".", "LongTensor", "(", "concepts", "[", ":", "end", "]", ")", "\n", "padded_concepts_ext", "[", "j", ",", ":", "end", "]", "=", "torch", ".", "LongTensor", "(", "concepts_ext_list", "[", "j", "]", "[", ":", "end", "]", ")", "\n", "padded_concepts_vads", "[", "j", ",", ":", "end", ",", ":", "]", "=", "torch", ".", "FloatTensor", "(", "concepts_vads_list", "[", "j", "]", "[", ":", "end", "]", ")", "\n", "padded_concepts_vad", "[", "j", ",", ":", "end", "]", "=", "torch", ".", "FloatTensor", "(", "concepts_vad_list", "[", "j", "]", "[", ":", "end", "]", ")", "\n", "padded_mask", "[", "j", ",", ":", "end", "]", "=", "self", ".", "args", ".", "KG_idx", "# for DIALOGUE STATE", "\n", "\n", "", "return", "padded_concepts", ",", "padded_concepts_ext", ",", "concept_lengths", ",", "padded_mask", ",", "token_concept_lengths", ",", "padded_concepts_vads", ",", "padded_concepts_vad", "\n", "", "else", ":", "# there is no concept in this mini-batch", "\n", "                ", "return", "torch", ".", "Tensor", "(", "[", "]", ")", ",", "torch", ".", "LongTensor", "(", "[", "]", ")", ",", "torch", ".", "LongTensor", "(", "[", "]", ")", ",", "torch", ".", "BoolTensor", "(", "[", "]", ")", ",", "torch", ".", "LongTensor", "(", "[", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "]", ")", "\n", "\n", "", "", "def", "merge_vad", "(", "vads_sequences", ",", "vad_sequences", ")", ":", "# for context", "\n", "            ", "lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "vad_sequences", "]", "\n", "padding_vads", "=", "torch", ".", "FloatTensor", "(", "[", "[", "[", "0.5", ",", "0.0", ",", "0.5", "]", "]", "]", ")", ".", "repeat", "(", "len", "(", "vads_sequences", ")", ",", "max", "(", "lengths", ")", ",", "1", ")", "\n", "padding_vad", "=", "torch", ".", "FloatTensor", "(", "[", "[", "0.5", "]", "]", ")", ".", "repeat", "(", "len", "(", "vads_sequences", ")", ",", "max", "(", "lengths", ")", ")", "\n", "\n", "for", "i", ",", "vads", "in", "enumerate", "(", "vads_sequences", ")", ":", "\n", "                ", "end", "=", "lengths", "[", "i", "]", "# the length of context", "\n", "padding_vads", "[", "i", ",", ":", "end", ",", ":", "]", "=", "torch", ".", "FloatTensor", "(", "vads", "[", ":", "end", "]", ")", "\n", "padding_vad", "[", "i", ",", ":", "end", "]", "=", "torch", ".", "FloatTensor", "(", "vad_sequences", "[", "i", "]", "[", ":", "end", "]", ")", "\n", "", "return", "padding_vads", ",", "padding_vad", "# (bsz, max_context_len, 3); (bsz, max_context_len)", "\n", "\n", "", "def", "adj_mask", "(", "context", ",", "context_lengths", ",", "concepts", ",", "token_concept_lengths", ")", ":", "\n", "            ", "'''\n\n            :param self:\n            :param context: (bsz, max_context_len)\n            :param context_lengths: [] len=bsz\n            :param concepts: (bsz, max_concept_len)\n            :param token_concept_lengths: [] len=bsz;\n            :return:\n            '''", "\n", "bsz", ",", "max_context_len", "=", "context", ".", "size", "(", ")", "\n", "max_concept_len", "=", "concepts", ".", "size", "(", "1", ")", "# include sep token", "\n", "adjacency_size", "=", "max_context_len", "+", "max_concept_len", "\n", "adjacency", "=", "torch", ".", "ones", "(", "bsz", ",", "max_context_len", ",", "adjacency_size", ")", "## todo padding index 1, 1=True", "\n", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "# ROOT -> TOKEN", "\n", "                ", "adjacency", "[", "i", ",", "0", ",", ":", "context_lengths", "[", "i", "]", "]", "=", "0", "\n", "adjacency", "[", "i", ",", ":", "context_lengths", "[", "i", "]", ",", "0", "]", "=", "0", "\n", "\n", "con_idx", "=", "max_context_len", "+", "1", "# add 1 because of sep token", "\n", "for", "j", "in", "range", "(", "context_lengths", "[", "i", "]", ")", ":", "\n", "                    ", "adjacency", "[", "i", ",", "j", ",", "j", "-", "1", "]", "=", "0", "# TOEKN_j -> TOKEN_j-1", "\n", "\n", "token_concepts_length", "=", "token_concept_lengths", "[", "i", "]", "[", "j", "]", "\n", "if", "token_concepts_length", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "adjacency", "[", "i", ",", "j", ",", "con_idx", ":", "con_idx", "+", "token_concepts_length", "]", "=", "0", "\n", "adjacency", "[", "i", ",", "0", ",", "con_idx", ":", "con_idx", "+", "token_concepts_length", "]", "=", "0", "\n", "con_idx", "+=", "token_concepts_length", "\n", "", "", "", "return", "adjacency", "\n", "\n", "", "batch_data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "\"context\"", "]", ")", ",", "reverse", "=", "True", ")", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "batch_data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "batch_data", "]", "\n", "\n", "", "assert", "len", "(", "item_info", "[", "'context'", "]", ")", "==", "len", "(", "item_info", "[", "'vad'", "]", ")", "\n", "\n", "## dialogue context", "\n", "context_batch", ",", "context_lengths", "=", "merge", "(", "item_info", "[", "'context'", "]", ")", "\n", "context_ext_batch", ",", "_", "=", "merge", "(", "item_info", "[", "'context_ext'", "]", ")", "\n", "mask_context", ",", "_", "=", "merge", "(", "item_info", "[", "'context_mask'", "]", ")", "# for dialogue state!", "\n", "\n", "## dialogue context vad", "\n", "context_vads_batch", ",", "context_vad_batch", "=", "merge_vad", "(", "item_info", "[", "'vads'", "]", ",", "item_info", "[", "'vad'", "]", ")", "# (bsz, max_context_len, 3); (bsz, max_context_len)", "\n", "\n", "assert", "context_batch", ".", "size", "(", "1", ")", "==", "context_vad_batch", ".", "size", "(", "1", ")", "\n", "\n", "\n", "## concepts, vads, vad", "\n", "concept_inputs", "=", "merge_concept", "(", "item_info", "[", "'concept'", "]", ",", "\n", "item_info", "[", "'concept_ext'", "]", ",", "\n", "item_info", "[", "\"concept_vads\"", "]", ",", "\n", "item_info", "[", "\"concept_vad\"", "]", ")", "# (bsz, max_concept_len)", "\n", "concept_batch", ",", "concept_ext_batch", ",", "concept_lengths", ",", "mask_concept", ",", "token_concept_lengths", ",", "concepts_vads_batch", ",", "concepts_vad_batch", "=", "concept_inputs", "\n", "\n", "## adja_mask (bsz, max_context_len, max_context_len+max_concept_len)", "\n", "if", "concept_batch", ".", "size", "(", ")", "[", "0", "]", "!=", "0", ":", "\n", "            ", "adjacency_mask_batch", "=", "adj_mask", "(", "context_batch", ",", "context_lengths", ",", "concept_batch", ",", "token_concept_lengths", ")", "\n", "", "else", ":", "\n", "            ", "adjacency_mask_batch", "=", "torch", ".", "Tensor", "(", "[", "]", ")", "\n", "\n", "## target response", "\n", "", "target_batch", ",", "target_lengths", "=", "merge", "(", "item_info", "[", "'target'", "]", ")", "\n", "target_ext_batch", ",", "_", "=", "merge", "(", "item_info", "[", "'target_ext'", "]", ")", "\n", "\n", "d", "=", "{", "}", "\n", "##input", "\n", "d", "[", "\"context_batch\"", "]", "=", "context_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_context_len)", "\n", "d", "[", "\"context_ext_batch\"", "]", "=", "context_ext_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_context_len)", "\n", "d", "[", "\"context_lengths\"", "]", "=", "torch", ".", "LongTensor", "(", "context_lengths", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, )", "\n", "d", "[", "\"mask_context\"", "]", "=", "mask_context", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "d", "[", "\"context_vads\"", "]", "=", "context_vads_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_context_len, 3)", "\n", "d", "[", "\"context_vad\"", "]", "=", "context_vad_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_context_len)", "\n", "\n", "##concept", "\n", "d", "[", "\"concept_batch\"", "]", "=", "concept_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_concept_len)", "\n", "d", "[", "\"concept_ext_batch\"", "]", "=", "concept_ext_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_concept_len)", "\n", "d", "[", "\"concept_lengths\"", "]", "=", "torch", ".", "LongTensor", "(", "concept_lengths", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz)", "\n", "d", "[", "\"mask_concept\"", "]", "=", "mask_concept", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_concept_len)", "\n", "d", "[", "\"concept_vads_batch\"", "]", "=", "concepts_vads_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_concept_len, 3)", "\n", "d", "[", "\"concept_vad_batch\"", "]", "=", "concepts_vad_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_concept_len)", "\n", "d", "[", "\"adjacency_mask_batch\"", "]", "=", "adjacency_mask_batch", ".", "bool", "(", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "##output", "\n", "d", "[", "\"target_batch\"", "]", "=", "target_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz, max_target_len)", "\n", "d", "[", "\"target_ext_batch\"", "]", "=", "target_ext_batch", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "d", "[", "\"target_lengths\"", "]", "=", "torch", ".", "LongTensor", "(", "target_lengths", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz,)", "\n", "\n", "##program", "\n", "d", "[", "\"target_emotion\"", "]", "=", "torch", ".", "LongTensor", "(", "item_info", "[", "'emotion'", "]", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "d", "[", "\"emotion_label\"", "]", "=", "torch", ".", "LongTensor", "(", "item_info", "[", "'emotion_label'", "]", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "# (bsz,)", "\n", "d", "[", "\"emotion_widx\"", "]", "=", "torch", ".", "LongTensor", "(", "item_info", "[", "'emotion_widx'", "]", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "assert", "d", "[", "\"emotion_widx\"", "]", ".", "size", "(", ")", "==", "d", "[", "\"emotion_label\"", "]", ".", "size", "(", ")", "\n", "\n", "##text", "\n", "d", "[", "\"context_txt\"", "]", "=", "item_info", "[", "'context_text'", "]", "\n", "d", "[", "\"target_txt\"", "]", "=", "item_info", "[", "'target_text'", "]", "\n", "d", "[", "\"emotion_txt\"", "]", "=", "item_info", "[", "'emotion_text'", "]", "\n", "d", "[", "\"concept_txt\"", "]", "=", "item_info", "[", "'concept_text'", "]", "\n", "d", "[", "\"oovs\"", "]", "=", "item_info", "[", "\"oovs\"", "]", "\n", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.write_config": [[399, 411], ["os.path.exists", "os.makedirs", "open", "args.__dict__.items", "os.path.join", "os.path.join", "os.path.join", "str", "str", "the_file.write", "the_file.write"], "function", ["None"], ["", "", "def", "write_config", "(", "args", ")", ":", "\n", "    ", "if", "not", "args", ".", "test", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'result'", ",", "args", ".", "model", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'result'", ",", "args", ".", "model", ")", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'result'", ",", "args", ".", "model", ",", "'config.txt'", ")", ",", "'w'", ")", "as", "the_file", ":", "\n", "            ", "for", "k", ",", "v", "in", "args", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "                ", "if", "\"False\"", "in", "str", "(", "v", ")", ":", "\n", "                    ", "pass", "\n", "", "elif", "\"True\"", "in", "str", "(", "v", ")", ":", "\n", "                    ", "the_file", ".", "write", "(", "\"--{} \"", ".", "format", "(", "k", ")", ")", "\n", "", "else", ":", "\n", "                    ", "the_file", ".", "write", "(", "\"--{} {} \"", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.flatten": [[413, 415], ["None"], "function", ["None"], ["", "", "", "", "", "def", "flatten", "(", "t", ")", ":", "\n", "    ", "return", "[", "item", "for", "sublist", "in", "t", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.load_dataset": [[417, 440], ["print", "os.path.exists", "range", "print", "print", "print", "print", "print", "print", "print", "print", "enumerate", "print", "print", "len", "len", "len", "open", "json.load", "print", "dataloader.flatten"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.flatten"], ["", "def", "load_dataset", "(", "args", ")", ":", "\n", "    ", "print", "(", "'file: '", ",", "args", ".", "dataset", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "dataset", ")", ":", "\n", "        ", "print", "(", "\"LOADING empathetic_dialogue\"", ")", "\n", "with", "open", "(", "args", ".", "dataset", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "[", "data_tra", ",", "data_val", ",", "data_tst", ",", "vocab", "]", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"data file not exists !!\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "# print('[situation]:', ' '.join(data_tra['situation'][i]))", "\n", "        ", "print", "(", "'[emotion]:'", ",", "data_tra", "[", "'emotion'", "]", "[", "i", "]", ")", "\n", "print", "(", "'[context]:'", ",", "[", "' '", ".", "join", "(", "u", ")", "for", "u", "in", "data_tra", "[", "'context'", "]", "[", "i", "]", "]", ")", "\n", "print", "(", "'[concept of context]:'", ")", "\n", "for", "si", ",", "sc", "in", "enumerate", "(", "data_tra", "[", "'concepts'", "]", "[", "i", "]", ")", ":", "\n", "            ", "print", "(", "'concept of sentence {} : {}'", ".", "format", "(", "si", ",", "flatten", "(", "sc", "[", "0", "]", ")", ")", ")", "\n", "", "print", "(", "'[target]:'", ",", "' '", ".", "join", "(", "data_tra", "[", "'target'", "]", "[", "i", "]", ")", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "", "print", "(", "\"train length: \"", ",", "len", "(", "data_tra", "[", "'situation'", "]", ")", ")", "\n", "print", "(", "\"valid length: \"", ",", "len", "(", "data_val", "[", "'situation'", "]", ")", ")", "\n", "print", "(", "\"test length: \"", ",", "len", "(", "data_tst", "[", "'situation'", "]", ")", ")", "\n", "return", "data_tra", ",", "data_val", ",", "data_tst", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.prepare_data_seq": [[442, 464], ["dataloader.load_dataset", "logging.info", "dataloader.Dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataloader.Dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataloader.Dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataloader.write_config", "len"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.load_dataset", "home.repos.pwc.inspect_result.qtli_kemp.code.dataloader.write_config"], ["", "def", "prepare_data_seq", "(", "args", ",", "batch_size", "=", "32", ")", ":", "\n", "    ", "pairs_tra", ",", "pairs_val", ",", "pairs_tst", ",", "vocab", "=", "load_dataset", "(", "args", ")", "# read data", "\n", "word2index", ",", "word2count", ",", "index2word", ",", "n_words", "=", "vocab", "\n", "\n", "logging", ".", "info", "(", "\"Vocab  {} \"", ".", "format", "(", "n_words", ")", ")", "\n", "\n", "dataset_train", "=", "Dataset", "(", "pairs_tra", ",", "word2index", ",", "args", ")", "# data, word2index, args", "\n", "data_loader_tra", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset_train", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "collate_fn", "=", "dataset_train", ".", "collate_fn", ")", "\n", "\n", "dataset_valid", "=", "Dataset", "(", "pairs_val", ",", "word2index", ",", "args", ")", "\n", "data_loader_val", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset_valid", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "collate_fn", "=", "dataset_valid", ".", "collate_fn", ")", "\n", "\n", "dataset_test", "=", "Dataset", "(", "pairs_tst", ",", "word2index", ",", "args", ")", "\n", "data_loader_tst", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset_test", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "False", ",", "collate_fn", "=", "dataset_test", ".", "collate_fn", ")", "\n", "write_config", "(", "args", ")", "\n", "return", "data_loader_tra", ",", "data_loader_val", ",", "data_loader_tst", ",", "vocab", ",", "len", "(", "dataset_train", ".", "emo_map", ")", "", "", ""]], "home.repos.pwc.inspect_result.qtli_kemp.code.utils.init_xavier_weight": [[4, 6], ["torch.nn.init.xavier_normal_"], "function", ["None"], ["def", "init_xavier_weight", "(", "w", ")", ":", "\n", "    ", "nn", ".", "init", ".", "xavier_normal_", "(", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.utils.init_bias": [[7, 9], ["torch.nn.init.constant_"], "function", ["None"], ["", "def", "init_bias", "(", "b", ")", ":", "\n", "    ", "nn", ".", "init", ".", "constant_", "(", "b", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.utils.init_linear_weight": [[10, 14], ["utils.init_xavier_weight", "utils.init_bias"], "function", ["home.repos.pwc.inspect_result.qtli_kemp.code.utils.init_xavier_weight", "home.repos.pwc.inspect_result.qtli_kemp.code.utils.init_bias"], ["", "def", "init_linear_weight", "(", "linear", ")", ":", "\n", "    ", "init_xavier_weight", "(", "linear", ".", "weight", ")", "\n", "if", "linear", ".", "bias", "is", "not", "None", ":", "\n", "        ", "init_bias", "(", "linear", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.utils.init_uniform_weight": [[15, 17], ["torch.nn.init.normal_"], "function", ["None"], ["", "", "def", "init_uniform_weight", "(", "w", ")", ":", "\n", "    ", "nn", ".", "init", ".", "normal_", "(", "w", ",", "-", "0.1", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.utils.ave_rouge": [[19, 85], ["result.append", "result.append", "result.append", "all_rouge_1.append", "all_rouge_2.append", "all_rouge_l.append"], "function", ["None"], ["", "def", "ave_rouge", "(", "all_rouges", ")", ":", "\n", "    ", "'''\n    [{\"rouge-1\": {\"f\": 0.49411764217577864,\n              \"p\": 0.5833333333333334,\n              \"r\": 0.42857142857142855},\n  \"rouge-2\": {\"f\": 0.23423422957552154,\n              \"p\": 0.3170731707317073,\n              \"r\": 0.18571428571428572},\n  \"rouge-l\": {\"f\": 0.42751590030718895,\n              \"p\": 0.5277777777777778,\n              \"r\": 0.3877551020408163}}]\n    :param all_rouges:\n    :return:\n    '''", "\n", "all_rouge_1", "=", "[", "]", "\n", "all_rouge_2", "=", "[", "]", "\n", "all_rouge_l", "=", "[", "]", "\n", "\n", "ave_rouge_1", "=", "{", "}", "\n", "ave_rouge_2", "=", "{", "}", "\n", "ave_rouge_l", "=", "{", "}", "\n", "\n", "for", "each_r", "in", "all_rouges", ":", "\n", "        ", "all_rouge_1", ".", "append", "(", "each_r", "[", "0", "]", "[", "\"rouge-1\"", "]", ")", "\n", "all_rouge_2", ".", "append", "(", "each_r", "[", "0", "]", "[", "\"rouge-2\"", "]", ")", "\n", "all_rouge_l", ".", "append", "(", "each_r", "[", "0", "]", "[", "\"rouge-l\"", "]", ")", "\n", "\n", "", "f", "=", "0.0", "\n", "p", "=", "0.0", "\n", "r", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "each", "in", "all_rouge_1", ":", "\n", "        ", "f", "+=", "each", "[", "\"f\"", "]", "\n", "p", "+=", "each", "[", "\"p\"", "]", "\n", "r", "+=", "each", "[", "\"r\"", "]", "\n", "count", "+=", "1", "\n", "", "ave_rouge_1", "[", "\"rouge-1\"", "]", "=", "{", "\"f\"", ":", "f", "/", "count", ",", "\"p\"", ":", "p", "/", "count", ",", "\"r\"", ":", "r", "/", "count", "}", "\n", "\n", "f", "=", "0.0", "\n", "p", "=", "0.0", "\n", "r", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "each", "in", "all_rouge_2", ":", "\n", "        ", "f", "+=", "each", "[", "\"f\"", "]", "\n", "p", "+=", "each", "[", "\"p\"", "]", "\n", "r", "+=", "each", "[", "\"r\"", "]", "\n", "count", "+=", "1", "\n", "", "ave_rouge_2", "[", "\"rouge-2\"", "]", "=", "{", "\"f\"", ":", "f", "/", "count", ",", "\"p\"", ":", "p", "/", "count", ",", "\"r\"", ":", "r", "/", "count", "}", "\n", "\n", "f", "=", "0.0", "\n", "p", "=", "0.0", "\n", "r", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "each", "in", "all_rouge_l", ":", "\n", "        ", "f", "+=", "each", "[", "\"f\"", "]", "\n", "p", "+=", "each", "[", "\"p\"", "]", "\n", "r", "+=", "each", "[", "\"r\"", "]", "\n", "count", "+=", "1", "\n", "", "ave_rouge_l", "[", "\"rouge-l\"", "]", "=", "{", "\"f\"", ":", "f", "/", "count", ",", "\"p\"", ":", "p", "/", "count", ",", "\"r\"", ":", "r", "/", "count", "}", "\n", "\n", "result", "=", "[", "]", "\n", "result", ".", "append", "(", "ave_rouge_1", ")", "\n", "result", ".", "append", "(", "ave_rouge_2", ")", "\n", "result", ".", "append", "(", "ave_rouge_l", ")", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.qtli_kemp.code.utils.distinctEval": [[87, 101], ["set", "set", "sum", "list", "len", "len", "len", "len", "set.add", "nltk.bigrams", "set.add"], "function", ["None"], ["", "def", "distinctEval", "(", "preds", ")", ":", "\n", "    ", "response_ugm", "=", "set", "(", "[", "]", ")", "\n", "response_bgm", "=", "set", "(", "[", "]", ")", "\n", "response_len", "=", "sum", "(", "[", "len", "(", "p", ")", "for", "p", "in", "preds", "]", ")", "# \u53c2\u4e0e\u8ba1\u7b97\u7684\u53e5\u5b50\u7684\u603b\u8bcd\u6570", "\n", "\n", "for", "path", "in", "preds", ":", "\n", "        ", "for", "u", "in", "path", ":", "\n", "            ", "response_ugm", ".", "add", "(", "u", ")", "\n", "", "for", "b", "in", "list", "(", "nltk", ".", "bigrams", "(", "path", ")", ")", ":", "# TODO \u4e2d\u6587distinct", "\n", "            ", "response_bgm", ".", "add", "(", "b", ")", "\n", "", "", "response_len_ave", "=", "response_len", "/", "len", "(", "preds", ")", "\n", "distinctOne", "=", "len", "(", "response_ugm", ")", "/", "response_len", "\n", "distinctTwo", "=", "len", "(", "response_bgm", ")", "/", "response_len", "\n", "return", "distinctOne", ",", "distinctTwo", ",", "response_len_ave", "", "", ""]]}