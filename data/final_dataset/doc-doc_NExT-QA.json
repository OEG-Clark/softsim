{"home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.__init__": [[11, 27], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "train_loader", ",", "val_loader", ",", "glove_embed", ",", "use_bert", ",", "checkpoint_path", ",", "model_type", ",", "\n", "model_prefix", ",", "vis_step", ",", "lr_rate", ",", "batch_size", ",", "epoch_num", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "train_loader", "=", "train_loader", "\n", "self", ".", "val_loader", "=", "val_loader", "\n", "self", ".", "glove_embed", "=", "glove_embed", "\n", "self", ".", "use_bert", "=", "use_bert", "\n", "self", ".", "model_dir", "=", "checkpoint_path", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "model_prefix", "=", "model_prefix", "\n", "self", ".", "vis_step", "=", "vis_step", "\n", "self", ".", "lr_rate", "=", "lr_rate", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epoch_num", "=", "epoch_num", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.build_model": [[28, 110], ["len", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "videoqa.VideoQA.model.to", "networks.embed_loss.MultipleChoiceLoss().to", "networks.EncoderRNN.EncoderVid", "networks.EncoderRNN.EncoderQns", "networks.VQAModel.EVQA.EVQA", "networks.EncoderRNN.EncoderVidSTVQA", "networks.EncoderRNN.EncoderQns", "networks.VQAModel.STVQA.STVQA", "videoqa.VideoQA.model.parameters", "networks.embed_loss.MultipleChoiceLoss", "networks.EncoderRNN.EncoderVidCoMem", "networks.EncoderRNN.EncoderQns", "networks.VQAModel.CoMem.CoMem", "networks.EncoderRNN.EncoderVidCoMem", "networks.EncoderRNN.EncoderQns", "networks.VQAModel.HME.HME", "networks.EncoderRNN.EncoderVidHGA", "networks.EncoderRNN.EncoderQns", "networks.VQAModel.HGA.HGA"], "methods", ["None"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "\n", "        ", "vid_dim", "=", "2048", "+", "2048", "\n", "hidden_dim", "=", "256", "\n", "word_dim", "=", "300", "\n", "vocab_size", "=", "len", "(", "self", ".", "vocab", ")", "\n", "max_ans_len", "=", "7", "\n", "max_vid_len", "=", "16", "\n", "max_qa_len", "=", "37", "\n", "\n", "if", "self", ".", "model_type", "==", "'EVQA'", "or", "self", ".", "model_type", "==", "'BlindQA'", ":", "\n", "#ICCV15, AAAI17", "\n", "            ", "hidden_dim", "=", "256", "\n", "vid_encoder", "=", "EncoderRNN", ".", "EncoderVid", "(", "vid_dim", ",", "hidden_dim", ",", "input_dropout_p", "=", "0.2", ",", "n_layers", "=", "1", ",", "rnn_dropout_p", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "qns_encoder", "=", "EncoderRNN", ".", "EncoderQns", "(", "word_dim", ",", "hidden_dim", ",", "vocab_size", ",", "self", ".", "glove_embed", ",", "self", ".", "use_bert", ",", "n_layers", "=", "1", ",", "\n", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "\n", "self", ".", "model", "=", "EVQA", ".", "EVQA", "(", "vid_encoder", ",", "qns_encoder", ",", "self", ".", "device", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "'STVQA'", ":", "\n", "#CVPR17", "\n", "# vid_dim = 1024  # (64, 1024+2048, 7, 7)", "\n", "            ", "att_dim", "=", "256", "\n", "vid_encoder", "=", "EncoderRNN", ".", "EncoderVidSTVQA", "(", "vid_dim", ",", "hidden_dim", ",", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0", ",", "\n", "n_layers", "=", "1", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "qns_encoder", "=", "EncoderRNN", ".", "EncoderQns", "(", "word_dim", ",", "hidden_dim", ",", "vocab_size", ",", "self", ".", "glove_embed", ",", "self", ".", "use_bert", ",", "\n", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0.5", ",", "n_layers", "=", "2", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "\n", "self", ".", "model", "=", "STVQA", ".", "STVQA", "(", "vid_encoder", ",", "qns_encoder", ",", "att_dim", ",", "self", ".", "device", ")", "\n", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "'CoMem'", ":", "\n", "#CVPR18", "\n", "            ", "app_dim", "=", "2048", "\n", "motion_dim", "=", "2048", "\n", "vid_encoder", "=", "EncoderRNN", ".", "EncoderVidCoMem", "(", "app_dim", ",", "motion_dim", ",", "hidden_dim", ",", "input_dropout_p", "=", "0.2", ",", "\n", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "\n", "qns_encoder", "=", "EncoderRNN", ".", "EncoderQns", "(", "word_dim", ",", "hidden_dim", ",", "vocab_size", ",", "self", ".", "glove_embed", ",", "self", ".", "use_bert", ",", "n_layers", "=", "2", ",", "\n", "rnn_dropout_p", "=", "0.5", ",", "input_dropout_p", "=", "0.2", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "\n", "self", ".", "model", "=", "CoMem", ".", "CoMem", "(", "vid_encoder", ",", "qns_encoder", ",", "max_vid_len", ",", "max_qa_len", ",", "self", ".", "device", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "'HME'", ":", "\n", "#CVPR19", "\n", "            ", "app_dim", "=", "2048", "\n", "motion_dim", "=", "2048", "\n", "vid_encoder", "=", "EncoderRNN", ".", "EncoderVidCoMem", "(", "app_dim", ",", "motion_dim", ",", "hidden_dim", ",", "input_dropout_p", "=", "0.2", ",", "\n", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "\n", "qns_encoder", "=", "EncoderRNN", ".", "EncoderQns", "(", "word_dim", ",", "hidden_dim", ",", "vocab_size", ",", "self", ".", "glove_embed", ",", "self", ".", "use_bert", ",", "n_layers", "=", "2", ",", "\n", "rnn_dropout_p", "=", "0.5", ",", "input_dropout_p", "=", "0.2", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'lstm'", ")", "\n", "\n", "\n", "self", ".", "model", "=", "HME", ".", "HME", "(", "vid_encoder", ",", "qns_encoder", ",", "max_vid_len", ",", "max_qa_len", ",", "self", ".", "device", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "'HGA'", ":", "\n", "#AAAI20", "\n", "            ", "hidden_dim", "=", "256", "#better than 512", "\n", "vid_encoder", "=", "EncoderRNN", ".", "EncoderVidHGA", "(", "vid_dim", ",", "hidden_dim", ",", "input_dropout_p", "=", "0.3", ",", "\n", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'gru'", ")", "\n", "\n", "qns_encoder", "=", "EncoderRNN", ".", "EncoderQns", "(", "word_dim", ",", "hidden_dim", ",", "vocab_size", ",", "self", ".", "glove_embed", ",", "self", ".", "use_bert", ",", "n_layers", "=", "1", ",", "\n", "rnn_dropout_p", "=", "0", ",", "input_dropout_p", "=", "0.3", ",", "bidirectional", "=", "False", ",", "\n", "rnn_cell", "=", "'gru'", ")", "\n", "\n", "self", ".", "model", "=", "HGA", ".", "HGA", "(", "vid_encoder", ",", "qns_encoder", ",", "self", ".", "device", ")", "\n", "\n", "\n", "", "params", "=", "[", "{", "'params'", ":", "self", ".", "model", ".", "parameters", "(", ")", "}", "]", "\n", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", "=", "params", ",", "lr", "=", "self", ".", "lr_rate", ")", "\n", "self", ".", "scheduler", "=", "ReduceLROnPlateau", "(", "self", ".", "optimizer", ",", "'max'", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ",", "verbose", "=", "True", ")", "\n", "# Bugs to be fixed", "\n", "# if torch.cuda.device_count() > 1:", "\n", "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")", "\n", "#     self.model = nn.DataParallel(self.model)", "\n", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "# self.criterion = nn.CrossEntropyLoss() #yield similar results", "\n", "self", ".", "criterion", "=", "embed_loss", ".", "MultipleChoiceLoss", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.save_model": [[112, 115], ["torch.save", "torch.save", "torch.save", "torch.save", "videoqa.VideoQA.model.state_dict", "osp.join"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "epoch", ",", "acc", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "osp", ".", "join", "(", "self", ".", "model_dir", ",", "'{}-{}-{}-{:.2f}.ckpt'", "\n", ".", "format", "(", "self", ".", "model_type", ",", "self", ".", "model_prefix", ",", "epoch", ",", "acc", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.resume": [[116, 133], ["osp.join", "print", "torch.load", "torch.load", "torch.load", "torch.load", "videoqa.VideoQA.model.state_dict().items", "videoqa.VideoQA.model.load_state_dict", "videoqa.VideoQA.model.state_dict"], "methods", ["None"], ["", "def", "resume", "(", "self", ",", "model_file", ")", ":", "\n", "        ", "\"\"\"\n        initialize model with pretrained weights\n        :return:\n        \"\"\"", "\n", "model_path", "=", "osp", ".", "join", "(", "self", ".", "model_dir", ",", "model_file", ")", "\n", "print", "(", "f'Warm-start (or test) with model: {model_path}'", ")", "\n", "model_dict", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "new_model_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "model_dict", ":", "\n", "                ", "v", "=", "model_dict", "[", "k", "]", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "# print(k)", "\n", "", "new_model_dict", "[", "k", "]", "=", "v", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "new_model_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.run": [[135, 153], ["videoqa.VideoQA.build_model", "range", "videoqa.VideoQA.resume", "videoqa.VideoQA.eval", "print", "videoqa.VideoQA.train", "videoqa.VideoQA.eval", "print", "videoqa.VideoQA.scheduler.step", "videoqa.VideoQA.save_model"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.build_model", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.resume", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.eval", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.train", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.eval", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.save_model"], ["", "def", "run", "(", "self", ",", "model_file", ",", "pre_trained", "=", "False", ")", ":", "\n", "        ", "self", ".", "build_model", "(", ")", "\n", "best_eval_score", "=", "0.0", "\n", "if", "pre_trained", ":", "\n", "            ", "self", ".", "resume", "(", "model_file", ")", "\n", "best_eval_score", "=", "self", ".", "eval", "(", "0", ")", "\n", "print", "(", "'Initial Acc {:.2f}'", ".", "format", "(", "best_eval_score", ")", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "epoch_num", ")", ":", "\n", "            ", "train_loss", ",", "train_acc", "=", "self", ".", "train", "(", "epoch", ")", "\n", "eval_score", "=", "self", ".", "eval", "(", "epoch", ")", "\n", "print", "(", "\"==>Epoch:[{}/{}][Train Loss: {:.4f} Train acc: {:.2f} Val acc: {:.2f}]\"", ".", "\n", "format", "(", "epoch", ",", "self", ".", "epoch_num", ",", "train_loss", ",", "train_acc", ",", "eval_score", ")", ")", "\n", "self", ".", "scheduler", ".", "step", "(", "eval_score", ")", "\n", "if", "eval_score", ">", "best_eval_score", ":", "\n", "                ", "best_eval_score", "=", "eval_score", "\n", "if", "epoch", ">", "6", "or", "pre_trained", ":", "\n", "                    ", "self", ".", "save_model", "(", "epoch", ",", "best_eval_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.train": [[155, 186], ["print", "videoqa.VideoQA.model.train", "len", "enumerate", "torch.cat().long().cpu", "torch.cat().long().cpu", "torch.cat().long().cpu", "torch.cat().long().cpu", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "videos.to", "qas.to", "answers.to", "videoqa.VideoQA.model", "videoqa.VideoQA.model.zero_grad", "videoqa.VideoQA.criterion", "videoqa.VideoQA.backward", "videoqa.VideoQA.optimizer.step", "time.strftime", "videoqa.VideoQA.item", "prediction_list.append", "answer_list.append", "time.localtime", "print", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "len", "videoqa.VideoQA.item", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.train"], ["", "", "", "", "def", "train", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "print", "(", "'==>Epoch:[{}/{}][lr_rate: {}]'", ".", "format", "(", "epoch", ",", "self", ".", "epoch_num", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "total_step", "=", "len", "(", "self", ".", "train_loader", ")", "\n", "epoch_loss", "=", "0.0", "\n", "prediction_list", "=", "[", "]", "\n", "answer_list", "=", "[", "]", "\n", "for", "iter", ",", "inputs", "in", "enumerate", "(", "self", ".", "train_loader", ")", ":", "\n", "            ", "videos", ",", "qas", ",", "qas_lengths", ",", "answers", ",", "qns_keys", "=", "inputs", "\n", "video_inputs", "=", "videos", ".", "to", "(", "self", ".", "device", ")", "\n", "qas_inputs", "=", "qas", ".", "to", "(", "self", ".", "device", ")", "\n", "ans_targets", "=", "answers", ".", "to", "(", "self", ".", "device", ")", "\n", "out", ",", "prediction", "=", "self", ".", "model", "(", "video_inputs", ",", "qas_inputs", ",", "qas_lengths", ")", "\n", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "out", ",", "ans_targets", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "cur_time", "=", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "time", ".", "localtime", "(", ")", ")", "\n", "if", "iter", "%", "self", ".", "vis_step", "==", "0", ":", "\n", "                ", "print", "(", "'\\t[{}/{}]-{}-{:.4f}'", ".", "format", "(", "iter", ",", "total_step", ",", "cur_time", ",", "loss", ".", "item", "(", ")", ")", ")", "\n", "", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "prediction_list", ".", "append", "(", "prediction", ")", "\n", "answer_list", ".", "append", "(", "answers", ")", "\n", "\n", "", "predict_answers", "=", "torch", ".", "cat", "(", "prediction_list", ",", "dim", "=", "0", ")", ".", "long", "(", ")", ".", "cpu", "(", ")", "\n", "ref_answers", "=", "torch", ".", "cat", "(", "answer_list", ",", "dim", "=", "0", ")", ".", "long", "(", ")", "\n", "acc_num", "=", "torch", ".", "sum", "(", "predict_answers", "==", "ref_answers", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "epoch_loss", "/", "total_step", ",", "acc_num", "*", "100.0", "/", "len", "(", "ref_answers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.eval": [[188, 210], ["print", "videoqa.VideoQA.model.eval", "len", "torch.cat().long().cpu", "torch.cat().long().cpu", "torch.cat().long().cpu", "torch.cat().long().cpu", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.sum().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "videos.to", "qas.to", "videoqa.VideoQA.model", "prediction_list.append", "answer_list.append", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.eval"], ["", "def", "eval", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "print", "(", "'==>Epoch:[{}/{}][validation stage]'", ".", "format", "(", "epoch", ",", "self", ".", "epoch_num", ")", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "total_step", "=", "len", "(", "self", ".", "val_loader", ")", "\n", "acc_count", "=", "0", "\n", "prediction_list", "=", "[", "]", "\n", "answer_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "iter", ",", "inputs", "in", "enumerate", "(", "self", ".", "val_loader", ")", ":", "\n", "                ", "videos", ",", "qas", ",", "qas_lengths", ",", "answers", ",", "qns_keys", "=", "inputs", "\n", "video_inputs", "=", "videos", ".", "to", "(", "self", ".", "device", ")", "\n", "qas_inputs", "=", "qas", ".", "to", "(", "self", ".", "device", ")", "\n", "out", ",", "prediction", "=", "self", ".", "model", "(", "video_inputs", ",", "qas_inputs", ",", "qas_lengths", ")", "\n", "\n", "prediction_list", ".", "append", "(", "prediction", ")", "\n", "answer_list", ".", "append", "(", "answers", ")", "\n", "\n", "", "", "predict_answers", "=", "torch", ".", "cat", "(", "prediction_list", ",", "dim", "=", "0", ")", ".", "long", "(", ")", ".", "cpu", "(", ")", "\n", "ref_answers", "=", "torch", ".", "cat", "(", "answer_list", ",", "dim", "=", "0", ")", ".", "long", "(", ")", "\n", "acc_num", "=", "torch", ".", "sum", "(", "predict_answers", "==", "ref_answers", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "acc_num", "*", "100.0", "/", "len", "(", "ref_answers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.predict": [[212, 242], ["osp.join", "videoqa.VideoQA.build_model", "videoqa.VideoQA.model.eval", "print", "utils.save_file", "videoqa.VideoQA.resume", "torch.load", "torch.load", "torch.load", "torch.load", "videoqa.VideoQA.model.load_state_dict", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "videos.to", "qas.to", "videoqa.VideoQA.model", "prediction.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "answers.numpy.numpy.numpy", "zip", "prediction.data.cpu().numpy.data.cpu().numpy.data.cpu", "int", "int"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.build_model", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.eval", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.save_file", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.resume"], ["", "def", "predict", "(", "self", ",", "model_file", ",", "result_file", ")", ":", "\n", "        ", "\"\"\"\n        predict the answer with the trained model\n        :param model_file:\n        :return:\n        \"\"\"", "\n", "model_path", "=", "osp", ".", "join", "(", "self", ".", "model_dir", ",", "model_file", ")", "\n", "self", ".", "build_model", "(", ")", "\n", "if", "self", ".", "model_type", "in", "[", "'HGA'", ",", "'STVQA'", "]", ":", "\n", "            ", "self", ".", "resume", "(", "model_file", ")", "\n", "", "else", ":", "\n", "            ", "old_state_dict", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "old_state_dict", ")", "\n", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "results", "=", "{", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "iter", ",", "inputs", "in", "enumerate", "(", "self", ".", "val_loader", ")", ":", "\n", "                ", "videos", ",", "qas", ",", "qas_lengths", ",", "answers", ",", "qns_keys", "=", "inputs", "\n", "video_inputs", "=", "videos", ".", "to", "(", "self", ".", "device", ")", "\n", "qas_inputs", "=", "qas", ".", "to", "(", "self", ".", "device", ")", "\n", "out", ",", "prediction", "=", "self", ".", "model", "(", "video_inputs", ",", "qas_inputs", ",", "qas_lengths", ")", "\n", "prediction", "=", "prediction", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "answers", "=", "answers", ".", "numpy", "(", ")", "\n", "for", "qid", ",", "pred", ",", "ans", "in", "zip", "(", "qns_keys", ",", "prediction", ",", "answers", ")", ":", "\n", "                    ", "results", "[", "qid", "]", "=", "{", "'prediction'", ":", "int", "(", "pred", ")", ",", "'answer'", ":", "int", "(", "ans", ")", "}", "\n", "\n", "\n", "", "", "", "print", "(", "len", "(", "results", ")", ")", "\n", "save_file", "(", "results", ",", "result_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.eval_mc.accuracy_metric": [[6, 55], ["utils.load_file", "utils.load_file.iterrows", "utils.load_file", "group.items", "overall_acc.items", "print", "group_acc.items", "print", "print", "str", "group[].append", "print", "print", "str", "str"], "function", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.load_file", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.load_file"], ["def", "accuracy_metric", "(", "sample_list_file", ",", "result_file", ")", ":", "\n", "\n", "    ", "sample_list", "=", "load_file", "(", "sample_list_file", ")", "\n", "group", "=", "{", "'CW'", ":", "[", "]", ",", "'CH'", ":", "[", "]", ",", "'TN'", ":", "[", "]", ",", "'TC'", ":", "[", "]", ",", "'DC'", ":", "[", "]", ",", "'DL'", ":", "[", "]", ",", "'DO'", ":", "[", "]", "}", "\n", "for", "id", ",", "row", "in", "sample_list", ".", "iterrows", "(", ")", ":", "\n", "        ", "qns_id", "=", "str", "(", "row", "[", "'video'", "]", ")", "+", "'_'", "+", "str", "(", "row", "[", "'qid'", "]", ")", "\n", "qtype", "=", "str", "(", "row", "[", "'type'", "]", ")", "\n", "#(combine temporal qns of previous and next as 'TN')", "\n", "if", "qtype", "==", "'TP'", ":", "qtype", "=", "'TN'", "\n", "group", "[", "qtype", "]", ".", "append", "(", "qns_id", ")", "\n", "\n", "", "preds", "=", "load_file", "(", "result_file", ")", "\n", "group_acc", "=", "{", "'CW'", ":", "0", ",", "'CH'", ":", "0", ",", "'TN'", ":", "0", ",", "'TC'", ":", "0", ",", "'DC'", ":", "0", ",", "'DL'", ":", "0", ",", "'DO'", ":", "0", "}", "\n", "group_cnt", "=", "{", "'CW'", ":", "0", ",", "'CH'", ":", "0", ",", "'TN'", ":", "0", ",", "'TC'", ":", "0", ",", "'DC'", ":", "0", ",", "'DL'", ":", "0", ",", "'DO'", ":", "0", "}", "\n", "overall_acc", "=", "{", "'C'", ":", "0", ",", "'T'", ":", "0", ",", "'D'", ":", "0", "}", "\n", "overall_cnt", "=", "{", "'C'", ":", "0", ",", "'T'", ":", "0", ",", "'D'", ":", "0", "}", "\n", "all_acc", "=", "0", "\n", "all_cnt", "=", "0", "\n", "for", "qtype", ",", "qns_ids", "in", "group", ".", "items", "(", ")", ":", "\n", "        ", "cnt", "=", "0", "\n", "acc", "=", "0", "\n", "for", "qid", "in", "qns_ids", ":", "\n", "\n", "            ", "cnt", "+=", "1", "\n", "answer", "=", "preds", "[", "qid", "]", "[", "'answer'", "]", "\n", "pred", "=", "preds", "[", "qid", "]", "[", "'prediction'", "]", "\n", "\n", "if", "answer", "==", "pred", ":", "\n", "                ", "acc", "+=", "1", "\n", "\n", "", "", "group_cnt", "[", "qtype", "]", "=", "cnt", "\n", "group_acc", "[", "qtype", "]", "+=", "acc", "\n", "overall_acc", "[", "qtype", "[", "0", "]", "]", "+=", "acc", "\n", "overall_cnt", "[", "qtype", "[", "0", "]", "]", "+=", "cnt", "\n", "all_acc", "+=", "acc", "\n", "all_cnt", "+=", "cnt", "\n", "\n", "\n", "", "for", "qtype", ",", "value", "in", "overall_acc", ".", "items", "(", ")", ":", "\n", "        ", "group_acc", "[", "qtype", "]", "=", "value", "\n", "group_cnt", "[", "qtype", "]", "=", "overall_cnt", "[", "qtype", "]", "\n", "\n", "", "for", "qtype", "in", "group_acc", ":", "\n", "        ", "print", "(", "map_name", "[", "qtype", "]", ",", "end", "=", "'\\t'", ")", "\n", "", "print", "(", "''", ")", "\n", "for", "qtype", ",", "acc", "in", "group_acc", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "'{:.2f}'", ".", "format", "(", "acc", "*", "100.0", "/", "group_cnt", "[", "qtype", "]", ")", ",", "end", "=", "'\\t'", ")", "\n", "", "print", "(", "''", ")", "\n", "print", "(", "'Acc: {:.2f}'", ".", "format", "(", "all_acc", "*", "100.0", "/", "all_cnt", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.eval_mc.main": [[57, 64], ["os.join", "print", "eval_mc.accuracy_metric"], "function", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.eval_mc.accuracy_metric"], ["", "def", "main", "(", "result_file", ",", "mode", "=", "'val'", ")", ":", "\n", "    ", "dataset_dir", "=", "'dataset/nextqa/'", "\n", "data_set", "=", "mode", "\n", "sample_list_file", "=", "osp", ".", "join", "(", "dataset_dir", ",", "data_set", "+", "'.csv'", ")", "\n", "print", "(", "'Evaluating {}'", ".", "format", "(", "result_file", ")", ")", "\n", "\n", "accuracy_metric", "(", "sample_list_file", ",", "result_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.__init__": [[12, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "{", "}", "\n", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.add_word": [[17, 22], ["None"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "not", "word", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "word2idx", "[", "word", "]", "=", "self", ".", "idx", "\n", "self", ".", "idx2word", "[", "self", ".", "idx", "]", "=", "word", "\n", "self", ".", "idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.__call__": [[23, 27], ["None"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "not", "word", "in", "self", ".", "word2idx", ":", "\n", "            ", "return", "self", ".", "word2idx", "[", "'<unk>'", "]", "\n", "", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.build_vocab": [[32, 63], ["utils.load_file", "print", "collections.Counter", "zip", "sorted", "utils.save_file", "print", "build_vocab.Vocabulary", "build_vocab.Vocabulary.add_word", "build_vocab.Vocabulary.add_word", "build_vocab.Vocabulary.add_word", "build_vocab.Vocabulary.add_word", "enumerate", "len", "nltk.tokenize.word_tokenize", "sorted.update", "sorted.items", "dict", "len", "build_vocab.Vocabulary.add_word", "str", "text.lower", "str"], "function", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.load_file", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.save_file", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.Vocabulary.add_word"], ["", "", "def", "build_vocab", "(", "anno_file", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Build a simple vocabulary wrapper.\"\"\"", "\n", "\n", "annos", "=", "load_file", "(", "anno_file", ")", "\n", "print", "(", "'total QA pairs'", ",", "len", "(", "annos", ")", ")", "\n", "counter", "=", "Counter", "(", ")", "\n", "\n", "for", "(", "qns", ",", "ans", ")", "in", "zip", "(", "annos", "[", "'question'", "]", ",", "annos", "[", "'answer'", "]", ")", ":", "\n", "# qns, ans = vqa['question'], vqa['answer']", "\n", "# text = qns # qns +' ' +ans", "\n", "        ", "text", "=", "str", "(", "qns", ")", "+", "' '", "+", "str", "(", "ans", ")", "\n", "tokens", "=", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "text", ".", "lower", "(", ")", ")", "\n", "counter", ".", "update", "(", "tokens", ")", "\n", "\n", "", "counter", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "save_file", "(", "dict", "(", "counter", ")", ",", "'dataset/VideoQA/word_count.json'", ")", "\n", "# If the word frequency is less than 'threshold', then the word is discarded.", "\n", "words", "=", "[", "item", "[", "0", "]", "for", "item", "in", "counter", "if", "item", "[", "1", "]", ">=", "threshold", "]", "\n", "print", "(", "len", "(", "words", ")", ")", "\n", "# Create a vocab wrapper and add some special tokens.", "\n", "vocab", "=", "Vocabulary", "(", ")", "\n", "vocab", ".", "add_word", "(", "'<pad>'", ")", "\n", "vocab", ".", "add_word", "(", "'<start>'", ")", "\n", "vocab", ".", "add_word", "(", "'<end>'", ")", "\n", "vocab", ".", "add_word", "(", "'<unk>'", ")", "\n", "\n", "# Add the words to the vocabulary.", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "        ", "vocab", ".", "add_word", "(", "word", ")", "\n", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.main": [[65, 72], ["build_vocab.build_vocab", "print", "print", "len"], "function", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.build_vocab.build_vocab"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "vocab", "=", "build_vocab", "(", "args", ".", "caption_path", ",", "args", ".", "threshold", ")", "\n", "vocab_path", "=", "args", ".", "vocab_path", "\n", "# with open(vocab_path, 'wb') as f:", "\n", "#     pickle.dump(vocab, f)", "\n", "print", "(", "\"Total vocabulary size: {}\"", ".", "format", "(", "len", "(", "vocab", ")", ")", ")", "\n", "print", "(", "\"Saved the vocabulary wrapper to '{}'\"", ".", "format", "(", "vocab_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.main_qa.main": [[9, 57], ["utils.pkload", "dataloader.QALoader", "dataloader.QALoader.run", "videoqa.VideoQA", "videoqa.VideoQA.predict", "eval_mc.main", "videoqa.VideoQA.run"], "function", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.pkload", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.run", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.videoqa.VideoQA.predict", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.main_qa.main", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.run"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "mode", "=", "args", ".", "mode", "\n", "if", "mode", "==", "'train'", ":", "\n", "        ", "batch_size", "=", "64", "\n", "num_worker", "=", "8", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "4", "\n", "num_worker", "=", "4", "\n", "\n", "", "video_feature_cache", "=", "'../data/feats/cache/'", "\n", "video_feature_path", "=", "'../data/feats/'", "\n", "\n", "dataset", "=", "'nextqa'", "\n", "sample_list_path", "=", "'dataset/{}/'", ".", "format", "(", "dataset", ")", "\n", "vocab", "=", "pkload", "(", "'dataset/{}/vocab.pkl'", ".", "format", "(", "dataset", ")", ")", "\n", "\n", "glove_embed", "=", "'dataset/{}/glove_embed.npy'", ".", "format", "(", "dataset", ")", "\n", "use_bert", "=", "True", "#Otherwise GloVe", "\n", "checkpoint_path", "=", "'models'", "\n", "model_type", "=", "'HGA'", "#(EVQA, STVQA, CoMem, HME, HGA)", "\n", "model_prefix", "=", "'bert-ft-h256'", "\n", "\n", "vis_step", "=", "106", "\n", "lr_rate", "=", "5e-5", "if", "use_bert", "else", "1e-4", "\n", "epoch_num", "=", "50", "\n", "\n", "data_loader", "=", "dataloader", ".", "QALoader", "(", "batch_size", ",", "num_worker", ",", "video_feature_path", ",", "video_feature_cache", ",", "\n", "sample_list_path", ",", "vocab", ",", "use_bert", ",", "True", ",", "False", ")", "\n", "\n", "train_loader", ",", "val_loader", "=", "data_loader", ".", "run", "(", "mode", "=", "mode", ")", "\n", "\n", "vqa", "=", "VideoQA", "(", "vocab", ",", "train_loader", ",", "val_loader", ",", "glove_embed", ",", "use_bert", ",", "checkpoint_path", ",", "model_type", ",", "model_prefix", ",", "\n", "vis_step", ",", "lr_rate", ",", "batch_size", ",", "epoch_num", ")", "\n", "\n", "ep", "=", "39", "\n", "acc", "=", "49.64", "\n", "\n", "model_file", "=", "f'{model_type}-{model_prefix}-{ep}-{acc:.2f}.ckpt'", "\n", "\n", "if", "mode", "!=", "'train'", ":", "\n", "        ", "result_file", "=", "f'results/{model_type}-{model_prefix}-{mode}.json'", "\n", "vqa", ".", "predict", "(", "model_file", ",", "result_file", ")", "\n", "eval_mc", ".", "main", "(", "result_file", ",", "mode", ")", "\n", "", "else", ":", "\n", "#Model for resume-training.", "\n", "        ", "model_file", "=", "f'{model_type}-{model_prefix}-0-00.00.ckpt'", "\n", "vqa", ".", "run", "(", "model_file", ",", "pre_trained", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.utils.set_gpu_devices": [[8, 13], ["str"], "function", ["None"], ["def", "set_gpu_devices", "(", "gpu_id", ")", ":", "\n", "    ", "gpu", "=", "''", "\n", "if", "gpu_id", "!=", "-", "1", ":", "\n", "        ", "gpu", "=", "str", "(", "gpu_id", ")", "\n", "", "os", ".", "environ", "[", "'CUDA_VOSIBLE_DEVICES'", "]", "=", "gpu", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.utils.load_file": [[15, 35], ["os.exists", "print", "pandas.read_csv", "open", "os.splitext", "fp.readlines", "os.splitext", "c.rstrip", "json.load", "os.splitext"], "function", ["None"], ["", "def", "load_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n    load obj from filename\n    :param filename:\n    :return:\n    \"\"\"", "\n", "cont", "=", "None", "\n", "if", "not", "osp", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "print", "(", "'{} not exist'", ".", "format", "(", "filename", ")", ")", "\n", "return", "cont", "\n", "", "if", "osp", ".", "splitext", "(", "filename", ")", "[", "-", "1", "]", "==", "'.csv'", ":", "\n", "# return pd.read_csv(filename, delimiter= '\\t', index_col=0)", "\n", "        ", "return", "pd", ".", "read_csv", "(", "filename", ",", "delimiter", "=", "','", ")", "\n", "", "with", "open", "(", "filename", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "if", "osp", ".", "splitext", "(", "filename", ")", "[", "1", "]", "==", "'.txt'", ":", "\n", "            ", "cont", "=", "fp", ".", "readlines", "(", ")", "\n", "cont", "=", "[", "c", ".", "rstrip", "(", "'\\n'", ")", "for", "c", "in", "cont", "]", "\n", "", "elif", "osp", ".", "splitext", "(", "filename", ")", "[", "1", "]", "==", "'.json'", ":", "\n", "            ", "cont", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "", "return", "cont", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.utils.save_file": [[37, 50], ["os.dirname", "os.makedirs", "os.makedirs", "os.exists", "open", "json.dump"], "function", ["None"], ["", "def", "save_file", "(", "obj", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n    save obj to filename\n    :param obj:\n    :param filename:\n    :return:\n    \"\"\"", "\n", "filepath", "=", "osp", ".", "dirname", "(", "filename", ")", "\n", "if", "filepath", "!=", "''", "and", "not", "osp", ".", "exists", "(", "filepath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "filepath", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "obj", ",", "fp", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.utils.pkload": [[52, 59], ["os.exists", "os.getsize", "open", "pickle.load"], "function", ["None"], ["", "", "", "def", "pkload", "(", "file", ")", ":", "\n", "    ", "data", "=", "None", "\n", "if", "osp", ".", "exists", "(", "file", ")", "and", "osp", ".", "getsize", "(", "file", ")", ">", "0", ":", "\n", "        ", "with", "open", "(", "file", ",", "'rb'", ")", "as", "fp", ":", "\n", "            ", "data", "=", "pkl", ".", "load", "(", "fp", ")", "\n", "# print('{} does not exist'.format(file))", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.None.utils.pkdump": [[61, 67], ["os.dirname", "os.exists", "os.makedirs", "os.makedirs", "open", "pickle.dump"], "function", ["None"], ["", "def", "pkdump", "(", "data", ",", "file", ")", ":", "\n", "    ", "dirname", "=", "osp", ".", "dirname", "(", "file", ")", "\n", "if", "not", "osp", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "", "with", "open", "(", "file", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pkl", ".", "dump", "(", "data", ",", "fp", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.__init__": [[12, 48], ["os.join", "util.load_file", "os.join", "os.join", "print", "os.join", "print", "h5py.File", "enumerate", "h5py.File", "enumerate", "zip", "zip", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.load_file"], ["def", "__init__", "(", "self", ",", "video_feature_path", ",", "video_feature_cache", ",", "sample_list_path", ",", "vocab", ",", "use_bert", ",", "mode", ")", ":", "\n", "        ", "self", ".", "video_feature_path", "=", "video_feature_path", "\n", "self", ".", "vocab", "=", "vocab", "\n", "sample_list_file", "=", "osp", ".", "join", "(", "sample_list_path", ",", "'{}.csv'", ".", "format", "(", "mode", ")", ")", "\n", "self", ".", "sample_list", "=", "load_file", "(", "sample_list_file", ")", "\n", "self", ".", "max_qa_length", "=", "37", "\n", "self", ".", "use_bert", "=", "use_bert", "\n", "self", ".", "use_frame", "=", "True", "# False for STVQA", "\n", "self", ".", "use_mot", "=", "True", "# False for STVQA", "\n", "self", ".", "use_spatial", "=", "False", "#True for STVQA", "\n", "if", "self", ".", "use_bert", ":", "\n", "            ", "self", ".", "bert_file", "=", "osp", ".", "join", "(", "video_feature_path", ",", "'qas_bert/bert_ft_{}.h5'", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "use_spatial", ":", "\n", "            ", "vid_feat_file", "=", "osp", ".", "join", "(", "video_feature_path", ",", "'vid_feat/app_mot_{}.h5'", ".", "format", "(", "mode", ")", ")", "\n", "print", "(", "'Load {}...'", ".", "format", "(", "vid_feat_file", ")", ")", "\n", "self", ".", "frame_feats", "=", "{", "}", "\n", "self", ".", "mot_feats", "=", "{", "}", "\n", "with", "h5py", ".", "File", "(", "vid_feat_file", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "vids", "=", "fp", "[", "'ids'", "]", "\n", "feats", "=", "fp", "[", "'feat'", "]", "\n", "for", "id", ",", "(", "vid", ",", "feat", ")", "in", "enumerate", "(", "zip", "(", "vids", ",", "feats", ")", ")", ":", "\n", "                    ", "if", "self", ".", "use_frame", ":", "\n", "                        ", "self", ".", "frame_feats", "[", "str", "(", "vid", ")", "]", "=", "feat", "[", ":", ",", ":", "2048", "]", "# (16, 2048)", "\n", "", "if", "self", ".", "use_mot", ":", "\n", "                        ", "self", ".", "mot_feats", "[", "str", "(", "vid", ")", "]", "=", "feat", "[", ":", ",", "2048", ":", "]", "# (16, 2048)", "\n", "", "", "", "", "else", ":", "\n", "# if you don't have enough memory(>60G), you can read feature from hdf5 at each iteration", "\n", "            ", "vid_feat_file", "=", "osp", ".", "join", "(", "video_feature_path", ",", "'spatial_feat/feat_maps_{}.h5'", ".", "format", "(", "mode", ")", ")", "\n", "print", "(", "'Load large file {}...'", ".", "format", "(", "vid_feat_file", ")", ")", "\n", "self", ".", "spatial_feats", "=", "{", "}", "\n", "with", "h5py", ".", "File", "(", "vid_feat_file", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "vids", "=", "fp", "[", "'ids'", "]", "\n", "feats", "=", "fp", "[", "'feat'", "]", "\n", "for", "id", ",", "(", "vid", ",", "feat", ")", "in", "enumerate", "(", "zip", "(", "vids", ",", "feats", ")", ")", ":", "\n", "                    ", "self", ".", "spatial_feats", "[", "str", "(", "vid", ")", "]", "=", "feat", "# (*, 4096, 7, 7) (obtained by np.concatenate((app, mot), axis=1)", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sample_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.get_video_feature": [[54, 71], ["torch.from_numpy().type", "numpy.concatenate", "torch.from_numpy"], "methods", ["None"], ["", "def", "get_video_feature", "(", "self", ",", "video_name", ")", ":", "\n", "        ", "\"\"\"\n        :param video_name:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "use_spatial", ":", "\n", "            ", "video_feature", "=", "self", ".", "spatial_feats", "[", "video_name", "]", "#(16, 4096, 7 ,7)", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "use_frame", ":", "\n", "                ", "app_feat", "=", "self", ".", "frame_feats", "[", "video_name", "]", "\n", "video_feature", "=", "app_feat", "# (16, 2048)", "\n", "", "if", "self", ".", "use_mot", ":", "\n", "                ", "mot_feat", "=", "self", ".", "mot_feats", "[", "video_name", "]", "\n", "video_feature", "=", "np", ".", "concatenate", "(", "(", "video_feature", ",", "mot_feat", ")", ",", "axis", "=", "1", ")", "#(16, 4096)", "\n", "\n", "# print(video_feature.shape)", "\n", "", "", "return", "torch", ".", "from_numpy", "(", "video_feature", ")", ".", "type", "(", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.get_word_idx": [[73, 80], ["nltk.tokenize.word_tokenize", "str().lower", "sample_loader.VidQADataset.vocab", "enumerate", "str"], "methods", ["None"], ["", "def", "get_word_idx", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "tokens", "=", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "str", "(", "text", ")", ".", "lower", "(", ")", ")", "\n", "token_ids", "=", "[", "self", ".", "vocab", "(", "token", ")", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", "if", "i", "<", "25", "]", "\n", "\n", "return", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.get_trans_matrix": [[81, 90], ["torch.zeros().long", "range", "len", "torch.Tensor", "torch.zeros"], "methods", ["None"], ["", "def", "get_trans_matrix", "(", "self", ",", "candidates", ")", ":", "\n", "\n", "        ", "qa_lengths", "=", "[", "len", "(", "qa", ")", "for", "qa", "in", "candidates", "]", "\n", "candidates_matrix", "=", "torch", ".", "zeros", "(", "[", "5", ",", "self", ".", "max_qa_length", "]", ")", ".", "long", "(", ")", "\n", "for", "k", "in", "range", "(", "5", ")", ":", "\n", "            ", "sentence", "=", "candidates", "[", "k", "]", "\n", "candidates_matrix", "[", "k", ",", ":", "qa_lengths", "[", "k", "]", "]", "=", "torch", ".", "Tensor", "(", "sentence", ")", "\n", "\n", "", "return", "candidates_matrix", ",", "qa_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.__getitem__": [[92, 119], ["range", "sample_loader.VidQADataset.get_trans_matrix", "sample_loader.VidQADataset.get_video_feature", "torch.tensor", "str", "str", "int", "str", "torch.from_numpy().type.append", "range", "sample_loader.VidQADataset.get_word_idx", "sample_loader.VidQADataset.vocab", "sample_loader.VidQADataset.get_word_idx", "h5py.File", "torch.from_numpy().type", "sample_loader.nozero_row", "sample_loader.VidQADataset.vocab", "sample_loader.VidQADataset.vocab", "str", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.get_trans_matrix", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.get_video_feature", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.get_word_idx", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.VidQADataset.get_word_idx", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.nozero_row"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "cur_sample", "=", "self", ".", "sample_list", ".", "loc", "[", "idx", "]", "\n", "video_name", ",", "qns", ",", "ans", ",", "qid", "=", "str", "(", "cur_sample", "[", "'video'", "]", ")", ",", "str", "(", "cur_sample", "[", "'question'", "]", ")", ",", "int", "(", "cur_sample", "[", "'answer'", "]", ")", ",", "str", "(", "cur_sample", "[", "'qid'", "]", ")", "\n", "candidate_qas", "=", "[", "]", "\n", "qns2ids", "=", "[", "self", ".", "vocab", "(", "'<start>'", ")", "]", "+", "self", ".", "get_word_idx", "(", "qns", ")", "+", "[", "self", ".", "vocab", "(", "'<end>'", ")", "]", "\n", "for", "id", "in", "range", "(", "5", ")", ":", "\n", "            ", "cand_ans", "=", "cur_sample", "[", "'a'", "+", "str", "(", "id", ")", "]", "\n", "ans2id", "=", "self", ".", "get_word_idx", "(", "cand_ans", ")", "+", "[", "self", ".", "vocab", "(", "'<end>'", ")", "]", "\n", "candidate_qas", ".", "append", "(", "qns2ids", "+", "ans2id", ")", "\n", "\n", "", "candidate_qas", ",", "qa_lengths", "=", "self", ".", "get_trans_matrix", "(", "candidate_qas", ")", "\n", "if", "self", ".", "use_bert", ":", "\n", "            ", "with", "h5py", ".", "File", "(", "self", ".", "bert_file", ",", "'r'", ")", "as", "fp", ":", "\n", "                ", "temp_feat", "=", "fp", "[", "'feat'", "]", "[", "idx", "]", "\n", "candidate_qas", "=", "torch", ".", "from_numpy", "(", "temp_feat", ")", ".", "type", "(", "torch", ".", "float32", ")", "\n", "", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "                ", "valid_row", "=", "nozero_row", "(", "candidate_qas", "[", "i", "]", ")", "\n", "qa_lengths", "[", "i", "]", "=", "valid_row", "\n", "\n", "", "", "video_feature", "=", "self", ".", "get_video_feature", "(", "video_name", ")", "\n", "qns_key", "=", "video_name", "+", "'_'", "+", "qid", "\n", "qa_lengths", "=", "torch", ".", "tensor", "(", "qa_lengths", ")", "\n", "\n", "return", "video_feature", ",", "candidate_qas", ",", "qa_lengths", ",", "ans", ",", "qns_key", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.__init__": [[134, 146], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "num_worker", ",", "video_feature_path", ",", "video_feature_cache", ",", "\n", "sample_list_path", ",", "vocab", ",", "use_bert", ",", "train_shuffle", "=", "True", ",", "val_shuffle", "=", "False", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_worker", "=", "num_worker", "\n", "self", ".", "video_feature_path", "=", "video_feature_path", "\n", "self", ".", "video_feature_cache", "=", "video_feature_cache", "\n", "self", ".", "sample_list_path", "=", "sample_list_path", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "use_bert", "=", "use_bert", "\n", "\n", "self", ".", "train_shuffle", "=", "train_shuffle", "\n", "self", ".", "val_shuffle", "=", "val_shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.run": [[148, 156], ["sample_loader.QALoader.validate", "sample_loader.QALoader.train", "sample_loader.QALoader.validate"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.validate", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.train", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.validate"], ["", "def", "run", "(", "self", ",", "mode", "=", "''", ")", ":", "\n", "        ", "if", "mode", "!=", "'train'", ":", "\n", "            ", "train_loader", "=", "''", "\n", "val_loader", "=", "self", ".", "validate", "(", "mode", ")", "\n", "", "else", ":", "\n", "            ", "train_loader", "=", "self", ".", "train", "(", "'train'", ")", "\n", "val_loader", "=", "self", ".", "validate", "(", "'val'", ")", "\n", "", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.train": [[158, 172], ["sample_loader.VidQADataset", "print", "torch.utils.data.DataLoader", "len"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "mode", ")", ":", "\n", "\n", "        ", "training_set", "=", "VidQADataset", "(", "self", ".", "video_feature_path", ",", "self", ".", "video_feature_cache", ",", "self", ".", "sample_list_path", ",", "\n", "self", ".", "vocab", ",", "self", ".", "use_bert", ",", "mode", ")", "\n", "\n", "print", "(", "'Eligible video-qa pairs for training : {}'", ".", "format", "(", "len", "(", "training_set", ")", ")", ")", "\n", "train_loader", "=", "DataLoader", "(", "\n", "dataset", "=", "training_set", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "self", ".", "train_shuffle", ",", "\n", "num_workers", "=", "self", ".", "num_worker", "\n", ")", "\n", "\n", "return", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.QALoader.validate": [[174, 188], ["sample_loader.VidQADataset", "print", "torch.utils.data.DataLoader", "len"], "methods", ["None"], ["", "def", "validate", "(", "self", ",", "mode", ")", ":", "\n", "\n", "        ", "validation_set", "=", "VidQADataset", "(", "self", ".", "video_feature_path", ",", "self", ".", "video_feature_cache", ",", "self", ".", "sample_list_path", ",", "\n", "self", ".", "vocab", ",", "self", ".", "use_bert", ",", "mode", ")", "\n", "\n", "print", "(", "'Eligible video-qa pairs for validation : {}'", ".", "format", "(", "len", "(", "validation_set", ")", ")", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "dataset", "=", "validation_set", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "self", ".", "val_shuffle", ",", "\n", "num_workers", "=", "self", ".", "num_worker", "\n", ")", "\n", "\n", "return", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.sample_loader.nozero_row": [[122, 130], ["row.sum"], "function", ["None"], ["", "", "def", "nozero_row", "(", "A", ")", ":", "\n", "    ", "i", "=", "0", "\n", "for", "row", "in", "A", ":", "\n", "        ", "if", "row", ".", "sum", "(", ")", "==", "0", ":", "\n", "            ", "break", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.load_file": [[8, 20], ["pandas.read_csv", "open", "os.splitext", "fp.readlines", "json.load", "os.splitext", "line.rstrip", "os.splitext"], "function", ["None"], ["def", "load_file", "(", "file_name", ")", ":", "\n", "    ", "annos", "=", "None", "\n", "if", "osp", ".", "splitext", "(", "file_name", ")", "[", "-", "1", "]", "==", "'.csv'", ":", "\n", "        ", "return", "pd", ".", "read_csv", "(", "file_name", ")", "\n", "", "with", "open", "(", "file_name", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "if", "osp", ".", "splitext", "(", "file_name", ")", "[", "1", "]", "==", "'.txt'", ":", "\n", "            ", "annos", "=", "fp", ".", "readlines", "(", ")", "\n", "annos", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "annos", "]", "\n", "", "if", "osp", ".", "splitext", "(", "file_name", ")", "[", "1", "]", "==", "'.json'", ":", "\n", "            ", "annos", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "", "return", "annos", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.save_file": [[21, 34], ["os.dirname", "os.makedirs", "os.makedirs", "os.exists", "open", "json.dump"], "function", ["None"], ["", "def", "save_file", "(", "obj", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n    save obj to filename\n    :param obj:\n    :param filename:\n    :return:\n    \"\"\"", "\n", "filepath", "=", "osp", ".", "dirname", "(", "filename", ")", "\n", "if", "filepath", "!=", "''", "and", "not", "osp", ".", "exists", "(", "filepath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "filepath", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'w'", ")", "as", "fp", ":", "\n", "            ", "json", ".", "dump", "(", "obj", ",", "fp", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.pkload": [[35, 42], ["os.exists", "os.getsize", "open", "pickle.load"], "function", ["None"], ["", "", "", "def", "pkload", "(", "file", ")", ":", "\n", "    ", "data", "=", "None", "\n", "if", "osp", ".", "exists", "(", "file", ")", "and", "osp", ".", "getsize", "(", "file", ")", ">", "0", ":", "\n", "        ", "with", "open", "(", "file", ",", "'rb'", ")", "as", "fp", ":", "\n", "            ", "data", "=", "pkl", ".", "load", "(", "fp", ")", "\n", "# print('{} does not exist'.format(file))", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.dataloader.util.pkdump": [[44, 50], ["os.dirname", "os.exists", "os.makedirs", "os.makedirs", "open", "pickle.dump"], "function", ["None"], ["", "def", "pkdump", "(", "data", ",", "file", ")", ":", "\n", "    ", "dirname", "=", "osp", ".", "dirname", "(", "file", ")", "\n", "if", "not", "osp", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "", "with", "open", "(", "file", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pkl", ".", "dump", "(", "data", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.PositionalEncoding.__init__": [[64, 86], ["torch.Module.__init__", "numpy.array", "numpy.sin", "numpy.cos", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "range", "numpy.power", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "max_seq_len", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "\n", "position_encoding", "=", "np", ".", "array", "(", "\n", "[", "\n", "[", "\n", "pos", "/", "np", ".", "power", "(", "10000", ",", "2.0", "*", "(", "j", "//", "2", ")", "/", "d_model", ")", "\n", "for", "j", "in", "range", "(", "d_model", ")", "\n", "]", "\n", "for", "pos", "in", "range", "(", "max_seq_len", ")", "\n", "]", ")", "\n", "position_encoding", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "position_encoding", "[", ":", ",", "0", ":", ":", "2", "]", ")", "\n", "position_encoding", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "position_encoding", "[", ":", ",", "1", ":", ":", "2", "]", ")", "\n", "\n", "pad_row", "=", "torch", ".", "zeros", "(", "[", "1", ",", "d_model", "]", ")", "\n", "position_encoding", "=", "torch", ".", "cat", "(", "\n", "(", "pad_row", ",", "torch", ".", "from_numpy", "(", "position_encoding", ")", ".", "float", "(", ")", ")", ")", "\n", "\n", "self", ".", "position_encoding", "=", "nn", ".", "Embedding", "(", "max_seq_len", "+", "1", ",", "d_model", ")", "\n", "self", ".", "position_encoding", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "position_encoding", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.PositionalEncoding.forward": [[87, 97], ["tensor", "q_v_transformer.PositionalEncoding.position_encoding", "list", "range", "l.item"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_len", ")", ":", "\n", "# max_len = torch.max(input_len)", "\n", "        ", "max_len", "=", "self", ".", "max_seq_len", "\n", "tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "if", "input_len", ".", "is_cuda", "else", "torch", ".", "LongTensor", "\n", "input_pos", "=", "[", "\n", "list", "(", "range", "(", "1", ",", "l", "+", "1", ")", ")", "+", "[", "0", "]", "*", "(", "max_len", "-", "l", ".", "item", "(", ")", ")", "\n", "for", "l", "in", "input_len", "\n", "]", "\n", "input_pos", "=", "tensor", "(", "input_pos", ")", "\n", "return", "self", ".", "position_encoding", "(", "input_pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.PositionalWiseFeedForward.__init__": [[101, 107], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "ffn_dim", "=", "512", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "PositionalWiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w1", "=", "nn", ".", "Conv1d", "(", "model_dim", ",", "ffn_dim", ",", "1", ")", "\n", "self", ".", "w2", "=", "nn", ".", "Conv1d", "(", "model_dim", ",", "ffn_dim", ",", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "model_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.PositionalWiseFeedForward.forward": [[108, 117], ["x.transpose", "q_v_transformer.PositionalWiseFeedForward.w2", "q_v_transformer.PositionalWiseFeedForward.dropout", "q_v_transformer.PositionalWiseFeedForward.layer_norm", "torch.relu", "torch.relu", "torch.relu", "q_v_transformer.PositionalWiseFeedForward.transpose", "q_v_transformer.PositionalWiseFeedForward.w1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# x of shape (bs, seq_len, hs)", "\n", "        ", "output", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "output", "=", "self", ".", "w2", "(", "F", ".", "relu", "(", "self", ".", "w1", "(", "output", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "# add residual and norm layer", "\n", "output", "=", "self", ".", "layer_norm", "(", "x", "+", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedPositionalWiseFeedForward.__init__": [[121, 127], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "ffn_dim", "=", "2048", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w1", "=", "nn", ".", "Linear", "(", "model_dim", ",", "ffn_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "w2", "=", "nn", ".", "Linear", "(", "ffn_dim", ",", "model_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "model_dim", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedPositionalWiseFeedForward.forward": [[128, 136], ["q_v_transformer.MaskedPositionalWiseFeedForward.w2", "q_v_transformer.MaskedPositionalWiseFeedForward.dropout", "q_v_transformer.MaskedPositionalWiseFeedForward.layer_norm", "torch.relu", "torch.relu", "torch.relu", "q_v_transformer.MaskedPositionalWiseFeedForward.w1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# x of shape (bs, seq_len, hs)", "\n", "        ", "output", "=", "self", ".", "w2", "(", "F", ".", "relu", "(", "self", ".", "w1", "(", "x", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "\n", "# add residual and norm layer", "\n", "output", "=", "self", ".", "layer_norm", "(", "x", "+", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.ScaledDotProductAttention.__init__": [[141, 145], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["def", "__init__", "(", "self", ",", "attention_dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "ScaledDotProductAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attention_dropout", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.ScaledDotProductAttention.forward": [[146, 162], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "q_v_transformer.ScaledDotProductAttention.softmax", "q_v_transformer.ScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "attention.masked_fill.masked_fill.masked_fill"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "scale", "=", "None", ",", "attn_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            q: [B, L_q, D_q]\n            k: [B, L_k, D_k]\n            v: [B, L_v, D_v]\n        \"\"\"", "\n", "attention", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", "*", "scale", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", ".", "masked_fill", "(", "attn_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attention", "=", "self", ".", "softmax", "(", "attention", ")", "\n", "attention", "=", "self", ".", "dropout", "(", "attention", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attention", ",", "v", ")", "\n", "return", "output", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedScaledDotProductAttention.__init__": [[167, 171], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["def", "__init__", "(", "self", ",", "attention_dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attention_dropout", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedScaledDotProductAttention.forward": [[172, 189], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "q_v_transformer.MaskedScaledDotProductAttention.softmax", "attention.masked_fill.masked_fill.masked_fill", "q_v_transformer.MaskedScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "attention.masked_fill.masked_fill.masked_fill"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "scale", "=", "None", ",", "attn_mask", "=", "None", ",", "softmax_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            q: [B, L_q, D_q]\n            k: [B, L_k, D_k]\n            v: [B, L_v, D_v]\n        \"\"\"", "\n", "attention", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", "*", "scale", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", ".", "masked_fill", "(", "attn_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attention", "=", "self", ".", "softmax", "(", "attention", ")", "\n", "attention", "=", "attention", ".", "masked_fill", "(", "softmax_mask", ",", "0.", ")", "\n", "attention", "=", "self", ".", "dropout", "(", "attention", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attention", ",", "v", ")", "\n", "return", "output", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MultiHeadAttention.__init__": [[193, 209], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "q_v_transformer.ScaledDotProductAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "num_heads", "=", "8", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "num_heads", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "linear_k", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_q", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dot_product_attention", "=", "ScaledDotProductAttention", "(", "dropout", ")", "\n", "self", ".", "linear_final", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "model_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MultiHeadAttention.forward": [[210, 248], ["key.view.view.size", "q_v_transformer.MultiHeadAttention.linear_k", "q_v_transformer.MultiHeadAttention.linear_v", "q_v_transformer.MultiHeadAttention.linear_q", "key.view.view.view", "value.view.view.view", "query.view.view.view", "q_v_transformer.MultiHeadAttention.dot_product_attention", "context.view.view.view", "q_v_transformer.MultiHeadAttention.linear_final", "q_v_transformer.MultiHeadAttention.dropout", "q_v_transformer.MultiHeadAttention.layer_norm", "attn_mask.repeat.repeat.repeat", "key.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "attn_mask", "=", "None", ")", ":", "\n", "        ", "residual", "=", "query", "\n", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "num_heads", "=", "self", ".", "num_heads", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "\n", "# linear projection", "\n", "key", "=", "self", ".", "linear_k", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_v", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_q", "(", "query", ")", "\n", "\n", "# split by heads", "\n", "key", "=", "key", ".", "view", "(", "batch_size", "*", "num_heads", ",", "-", "1", ",", "dim_per_head", ")", "\n", "value", "=", "value", ".", "view", "(", "batch_size", "*", "num_heads", ",", "-", "1", ",", "dim_per_head", ")", "\n", "query", "=", "query", ".", "view", "(", "batch_size", "*", "num_heads", ",", "-", "1", ",", "dim_per_head", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "repeat", "(", "num_heads", ",", "1", ",", "1", ")", "\n", "\n", "# scaled dot product attention", "\n", "", "scale", "=", "(", "key", ".", "size", "(", "-", "1", ")", "//", "num_heads", ")", "**", "-", "0.5", "\n", "context", ",", "attention", "=", "self", ".", "dot_product_attention", "(", "\n", "query", ",", "key", ",", "value", ",", "scale", ",", "attn_mask", ")", "\n", "\n", "# concat heads", "\n", "context", "=", "context", ".", "view", "(", "batch_size", ",", "-", "1", ",", "dim_per_head", "*", "num_heads", ")", "\n", "\n", "# final linear projection", "\n", "output", "=", "self", ".", "linear_final", "(", "context", ")", "\n", "\n", "# dropout", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "\n", "# add residual and norm layer", "\n", "output", "=", "self", ".", "layer_norm", "(", "residual", "+", "output", ")", "\n", "\n", "return", "output", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedMultiHeadAttention.__init__": [[252, 268], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "q_v_transformer.MaskedScaledDotProductAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "num_heads", "=", "8", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "num_heads", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "linear_k", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_q", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dot_product_attention", "=", "MaskedScaledDotProductAttention", "(", "dropout", ")", "\n", "self", ".", "linear_final", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "model_dim", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedMultiHeadAttention.forward": [[269, 312], ["key.view().transpose.view().transpose.size", "q_v_transformer.MaskedMultiHeadAttention.linear_k", "q_v_transformer.MaskedMultiHeadAttention.linear_v", "q_v_transformer.MaskedMultiHeadAttention.linear_q", "key.view().transpose.view().transpose.view().transpose", "value.view().transpose.view().transpose.view().transpose", "query.view().transpose.view().transpose.view().transpose", "q_v_transformer.MaskedMultiHeadAttention.dot_product_attention", "context.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "q_v_transformer.MaskedMultiHeadAttention.linear_final", "q_v_transformer.MaskedMultiHeadAttention.dropout", "q_v_transformer.MaskedMultiHeadAttention.layer_norm", "attn_mask.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "softmax_mask.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "key.view().transpose.view().transpose.size", "key.view().transpose.view().transpose.view", "value.view().transpose.view().transpose.view", "query.view().transpose.view().transpose.view", "context.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "attn_mask.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "softmax_mask.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "context.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "attn_mask", "=", "None", ",", "softmax_mask", "=", "None", ")", ":", "\n", "        ", "residual", "=", "query", "\n", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "num_heads", "=", "self", ".", "num_heads", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "\n", "# linear projection", "\n", "key", "=", "self", ".", "linear_k", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_v", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_q", "(", "query", ")", "\n", "\n", "# split by heads", "\n", "key", "=", "key", ".", "view", "(", "batch_size", ",", "-", "1", ",", "num_heads", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "value", "=", "value", ".", "view", "(", "batch_size", ",", "-", "1", ",", "num_heads", ",", "\n", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "query", "=", "query", ".", "view", "(", "batch_size", ",", "-", "1", ",", "num_heads", ",", "\n", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_heads", ",", "1", ",", "1", ")", "\n", "", "if", "softmax_mask", "is", "not", "None", ":", "\n", "            ", "softmax_mask", "=", "softmax_mask", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_heads", ",", "1", ",", "1", ")", "\n", "# scaled dot product attention", "\n", "# key.size(-1) is 64?", "\n", "", "scale", "=", "key", ".", "size", "(", "-", "1", ")", "**", "-", "0.5", "\n", "context", ",", "attention", "=", "self", ".", "dot_product_attention", "(", "\n", "query", ",", "key", ",", "value", ",", "scale", ",", "attn_mask", ",", "softmax_mask", ")", "\n", "\n", "# concat heads", "\n", "context", "=", "context", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", ",", "-", "1", ",", "dim_per_head", "*", "num_heads", ")", "\n", "\n", "# final linear projection", "\n", "output", "=", "self", ".", "linear_final", "(", "context", ")", "\n", "\n", "# dropout", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "\n", "# add residual and norm layer", "\n", "output", "=", "self", ".", "layer_norm", "(", "residual", "+", "output", ")", "\n", "\n", "return", "output", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfTransformerLayer.__init__": [[316, 323], ["torch.Module.__init__", "q_v_transformer.MaskedMultiHeadAttention", "q_v_transformer.MaskedPositionalWiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "num_heads", "=", "8", ",", "ffn_dim", "=", "2048", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transformer", "=", "MaskedMultiHeadAttention", "(", "\n", "model_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "MaskedPositionalWiseFeedForward", "(", "\n", "model_dim", ",", "ffn_dim", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfTransformerLayer.forward": [[324, 331], ["q_v_transformer.SelfTransformerLayer.transformer", "q_v_transformer.SelfTransformerLayer.feed_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "attn_mask", "=", "None", ",", "sf_mask", "=", "None", ")", ":", "\n", "        ", "output", ",", "attention", "=", "self", ".", "transformer", "(", "\n", "input", ",", "input", ",", "input", ",", "attn_mask", ",", "sf_mask", ")", "\n", "# feed forward network", "\n", "output", "=", "self", ".", "feed_forward", "(", "output", ")", "\n", "\n", "return", "output", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfTransformer.__init__": [[335, 356], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.PositionalEncoding", "q_v_transformer.SelfTransformerLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "max_len", "=", "35", ",", "\n", "num_layers", "=", "2", ",", "\n", "model_dim", "=", "512", ",", "\n", "num_heads", "=", "8", ",", "\n", "ffn_dim", "=", "2048", ",", "\n", "dropout", "=", "0.0", ",", "\n", "position", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "position", "=", "position", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "SelfTransformerLayer", "(", "model_dim", ",", "num_heads", ",", "ffn_dim", ",", "dropout", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "\n", "]", ")", "\n", "\n", "# max_seq_len is 35 or 80", "\n", "self", ".", "pos_embedding", "=", "PositionalEncoding", "(", "model_dim", ",", "max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfTransformer.forward": [[357, 371], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "encoder", "attentions.append", "q_v_transformer.SelfTransformer.pos_embedding", "input.size"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "input", ",", "input_length", ")", ":", "\n", "# q_length of shape (batch, ), each item is the length of the seq", "\n", "        ", "if", "self", ".", "position", ":", "\n", "            ", "input", "+=", "self", ".", "pos_embedding", "(", "input_length", ")", "[", ":", ",", ":", "input", ".", "size", "(", ")", "[", "1", "]", ",", ":", "]", "\n", "\n", "", "attention_mask", "=", "padding_mask_k", "(", "input", ",", "input", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "input", ",", "input", ")", "\n", "\n", "attentions", "=", "[", "]", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "input", ",", "attention", "=", "encoder", "(", "input", ",", "attention_mask", ",", "softmax_mask", ")", "\n", "attentions", ".", "append", "(", "attention", ")", "\n", "\n", "", "return", "input", ",", "attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfAttentionLayer.__init__": [[375, 391], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_p", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "linear_k", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_q", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "linear_final", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfAttentionLayer.forward": [[392, 425], ["q_v_transformer.SelfAttentionLayer.linear_k", "q_v_transformer.SelfAttentionLayer.linear_v", "q_v_transformer.SelfAttentionLayer.linear_q", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.SelfAttentionLayer.softmax", "attention.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.SelfAttentionLayer.linear_final", "q_v_transformer.SelfAttentionLayer.layer_norm", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.SelfAttentionLayer.size", "q_v_transformer.SelfAttentionLayer.transpose", "attention.masked_fill.masked_fill.masked_fill"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "scale", "=", "None", ",", "attn_mask", "=", "None", ",", "softmax_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            q: [B, L_q, D_q]\n            k: [B, L_k, D_k]\n            v: [B, L_v, D_v]\n        \"\"\"", "\n", "residual", "=", "q", "\n", "\n", "if", "attn_mask", "is", "None", "or", "softmax_mask", "is", "None", ":", "\n", "            ", "attn_mask", "=", "padding_mask_k", "(", "q", ",", "k", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "q", ",", "k", ")", "\n", "\n", "# linear projection", "\n", "", "k", "=", "self", ".", "linear_k", "(", "k", ")", "\n", "v", "=", "self", ".", "linear_v", "(", "v", ")", "\n", "q", "=", "self", ".", "linear_q", "(", "q", ")", "\n", "\n", "scale", "=", "k", ".", "size", "(", "-", "1", ")", "**", "-", "0.5", "\n", "\n", "attention", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", "*", "scale", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", ".", "masked_fill", "(", "attn_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attention", "=", "self", ".", "softmax", "(", "attention", ")", "\n", "attention", "=", "attention", ".", "masked_fill", "(", "softmax_mask", ",", "0.", ")", "\n", "\n", "# attention = self.dropout(attention)", "\n", "output", "=", "torch", ".", "bmm", "(", "attention", ",", "v", ")", "\n", "output", "=", "self", ".", "linear_final", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "residual", ")", "\n", "return", "output", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfAttention.__init__": [[429, 436], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.SelfAttentionLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "SelfAttentionLayer", "(", "hidden_size", ",", "dropout_p", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfAttention.forward": [[438, 456], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "encoder", "attentions.append"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "\n", "# q_attention_mask of shape (bs, q_len, v_len)", "\n", "        ", "attn_mask", "=", "padding_mask_k", "(", "input", ",", "input", ")", "\n", "# v_attention_mask of shape (bs, v_len, q_len)", "\n", "softmax_mask", "=", "padding_mask_q", "(", "input", ",", "input", ")", "\n", "\n", "attentions", "=", "[", "]", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "input", ",", "attention", "=", "encoder", "(", "\n", "input", ",", "\n", "input", ",", "\n", "input", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", "softmax_mask", "=", "softmax_mask", ")", "\n", "attentions", ".", "append", "(", "attention", ")", "\n", "\n", "", "return", "input", ",", "attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoAttentionLayer.__init__": [[460, 481], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_p", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "linear_question", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_video", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v_question", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v_video", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "linear_final_qv", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_final_vq", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm_qv", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "self", ".", "layer_norm_vq", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoAttentionLayer.forward": [[482, 540], ["q_v_transformer.CoAttentionLayer.linear_question", "q_v_transformer.CoAttentionLayer.linear_video", "q_v_transformer.CoAttentionLayer.linear_v_question", "q_v_transformer.CoAttentionLayer.linear_v_video", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoAttentionLayer.softmax", "attention_qv.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoAttentionLayer.softmax", "attention_vq.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoAttentionLayer.linear_final_qv", "q_v_transformer.CoAttentionLayer.layer_norm_qv", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoAttentionLayer.linear_final_vq", "q_v_transformer.CoAttentionLayer.layer_norm_vq", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.CoAttentionLayer.size", "q_v_transformer.CoAttentionLayer.transpose", "attention_qv.masked_fill.masked_fill.masked_fill", "q_v_transformer.CoAttentionLayer.transpose", "attention_vq.masked_fill.masked_fill.masked_fill"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "question", ",", "\n", "video", ",", "\n", "scale", "=", "None", ",", "\n", "attn_mask", "=", "None", ",", "\n", "softmax_mask", "=", "None", ",", "\n", "attn_mask_", "=", "None", ",", "\n", "softmax_mask_", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            q: [B, L_q, D_q]\n            k: [B, L_k, D_k]\n            v: [B, L_v, D_v]\n        \"\"\"", "\n", "q", "=", "question", "\n", "v", "=", "video", "\n", "\n", "if", "attn_mask", "is", "None", "or", "softmax_mask", "is", "None", ":", "\n", "            ", "attn_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "question", ",", "video", ")", "\n", "", "if", "attn_mask_", "is", "None", "or", "softmax_mask_", "is", "None", ":", "\n", "            ", "attn_mask_", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "softmax_mask_", "=", "padding_mask_q", "(", "video", ",", "question", ")", "\n", "\n", "# linear projection", "\n", "", "question_q", "=", "self", ".", "linear_question", "(", "question", ")", "\n", "video_k", "=", "self", ".", "linear_video", "(", "video", ")", "\n", "question", "=", "self", ".", "linear_v_question", "(", "question", ")", "\n", "video", "=", "self", ".", "linear_v_video", "(", "video", ")", "\n", "\n", "scale", "=", "video", ".", "size", "(", "-", "1", ")", "**", "-", "0.5", "\n", "\n", "attention_qv", "=", "torch", ".", "bmm", "(", "question_q", ",", "video_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention_qv", "=", "attention_qv", "*", "scale", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attention_qv", "=", "attention_qv", ".", "masked_fill", "(", "attn_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attention_qv", "=", "self", ".", "softmax", "(", "attention_qv", ")", "\n", "attention_qv", "=", "attention_qv", ".", "masked_fill", "(", "softmax_mask", ",", "0.", ")", "\n", "\n", "attention_vq", "=", "torch", ".", "bmm", "(", "video_k", ",", "question_q", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention_vq", "=", "attention_vq", "*", "scale", "\n", "", "if", "attn_mask_", "is", "not", "None", ":", "\n", "            ", "attention_vq", "=", "attention_vq", ".", "masked_fill", "(", "attn_mask_", ",", "-", "np", ".", "inf", ")", "\n", "", "attention_vq", "=", "self", ".", "softmax", "(", "attention_vq", ")", "\n", "attention_vq", "=", "attention_vq", ".", "masked_fill", "(", "softmax_mask_", ",", "0.", ")", "\n", "\n", "# attention = self.dropout(attention)", "\n", "output_qv", "=", "torch", ".", "bmm", "(", "attention_qv", ",", "video", ")", "\n", "output_qv", "=", "self", ".", "linear_final_qv", "(", "output_qv", ")", "\n", "output_q", "=", "self", ".", "layer_norm_qv", "(", "output_qv", "+", "q", ")", "\n", "\n", "output_vq", "=", "torch", ".", "bmm", "(", "attention_vq", ",", "question", ")", "\n", "output_vq", "=", "self", ".", "linear_final_vq", "(", "output_vq", ")", "\n", "output_v", "=", "self", ".", "layer_norm_vq", "(", "output_vq", "+", "v", ")", "\n", "return", "output_q", ",", "output_v", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoAttention.__init__": [[544, 549], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.CoAttentionLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "CoAttentionLayer", "(", "hidden_size", ",", "dropout_p", ")", "for", "_", "in", "range", "(", "n_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoAttention.forward": [[550, 566], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "encoder"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "question", ",", "video", ")", ":", "\n", "        ", "attn_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "question", ",", "video", ")", "\n", "attn_mask_", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "softmax_mask_", "=", "padding_mask_q", "(", "video", ",", "question", ")", "\n", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "question", ",", "video", "=", "encoder", "(", "\n", "question", ",", "\n", "video", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", "softmax_mask", "=", "softmax_mask", ",", "\n", "attn_mask_", "=", "attn_mask_", ",", "\n", "softmax_mask_", "=", "softmax_mask_", ")", "\n", "\n", "", "return", "question", ",", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoConcatAttentionLayer.__init__": [[570, 603], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torchnlp_nn.WeightDropLinear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torchnlp_nn.WeightDropLinear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_p", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "linear_question", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_video", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v_question", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v_video", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "linear_final_qv", "=", "nn", ".", "Sequential", "(", "\n", "nlpnn", ".", "WeightDropLinear", "(", "\n", "2", "*", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "weight_dropout", "=", "dropout_p", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "linear_final_vq", "=", "nn", ".", "Sequential", "(", "\n", "nlpnn", ".", "WeightDropLinear", "(", "\n", "2", "*", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "weight_dropout", "=", "dropout_p", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", ")", "\n", "\n", "self", ".", "layer_norm_qv", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "self", ".", "layer_norm_vq", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoConcatAttentionLayer.forward": [[604, 664], ["q_v_transformer.CoConcatAttentionLayer.linear_question", "q_v_transformer.CoConcatAttentionLayer.linear_video", "q_v_transformer.CoConcatAttentionLayer.linear_v_question", "q_v_transformer.CoConcatAttentionLayer.linear_v_video", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoConcatAttentionLayer.softmax", "attention_qv.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoConcatAttentionLayer.softmax", "attention_vq.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoConcatAttentionLayer.linear_final_qv", "q_v_transformer.CoConcatAttentionLayer.layer_norm_qv", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoConcatAttentionLayer.linear_final_vq", "q_v_transformer.CoConcatAttentionLayer.layer_norm_vq", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.CoConcatAttentionLayer.size", "q_v_transformer.CoConcatAttentionLayer.transpose", "attention_qv.masked_fill.masked_fill.masked_fill", "q_v_transformer.CoConcatAttentionLayer.transpose", "attention_vq.masked_fill.masked_fill.masked_fill", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "question", ",", "\n", "video", ",", "\n", "scale", "=", "None", ",", "\n", "attn_mask", "=", "None", ",", "\n", "softmax_mask", "=", "None", ",", "\n", "attn_mask_", "=", "None", ",", "\n", "softmax_mask_", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            q: [B, L_q, D_q]\n            k: [B, L_k, D_k]\n            v: [B, L_v, D_v]\n        \"\"\"", "\n", "q", "=", "question", "\n", "v", "=", "video", "\n", "\n", "if", "attn_mask", "is", "None", "or", "softmax_mask", "is", "None", ":", "\n", "            ", "attn_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "question", ",", "video", ")", "\n", "", "if", "attn_mask_", "is", "None", "or", "softmax_mask_", "is", "None", ":", "\n", "            ", "attn_mask_", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "softmax_mask_", "=", "padding_mask_q", "(", "video", ",", "question", ")", "\n", "\n", "# linear projection", "\n", "", "question_q", "=", "self", ".", "linear_question", "(", "question", ")", "\n", "video_k", "=", "self", ".", "linear_video", "(", "video", ")", "\n", "question", "=", "self", ".", "linear_v_question", "(", "question", ")", "\n", "video", "=", "self", ".", "linear_v_video", "(", "video", ")", "\n", "\n", "scale", "=", "video", ".", "size", "(", "-", "1", ")", "**", "-", "0.5", "\n", "\n", "attention_qv", "=", "torch", ".", "bmm", "(", "question_q", ",", "video_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention_qv", "=", "attention_qv", "*", "scale", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attention_qv", "=", "attention_qv", ".", "masked_fill", "(", "attn_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attention_qv", "=", "self", ".", "softmax", "(", "attention_qv", ")", "\n", "attention_qv", "=", "attention_qv", ".", "masked_fill", "(", "softmax_mask", ",", "0.", ")", "\n", "\n", "attention_vq", "=", "torch", ".", "bmm", "(", "video_k", ",", "question_q", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention_vq", "=", "attention_vq", "*", "scale", "\n", "", "if", "attn_mask_", "is", "not", "None", ":", "\n", "            ", "attention_vq", "=", "attention_vq", ".", "masked_fill", "(", "attn_mask_", ",", "-", "np", ".", "inf", ")", "\n", "", "attention_vq", "=", "self", ".", "softmax", "(", "attention_vq", ")", "\n", "attention_vq", "=", "attention_vq", ".", "masked_fill", "(", "softmax_mask_", ",", "0.", ")", "\n", "\n", "# attention = self.dropout(attention)", "\n", "output_qv", "=", "torch", ".", "bmm", "(", "attention_qv", ",", "video", ")", "\n", "output_qv", "=", "self", ".", "linear_final_qv", "(", "torch", ".", "cat", "(", "(", "output_qv", ",", "q", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "# output_q = self.layer_norm_qv(output_qv + q)", "\n", "output_q", "=", "self", ".", "layer_norm_qv", "(", "output_qv", ")", "\n", "\n", "output_vq", "=", "torch", ".", "bmm", "(", "attention_vq", ",", "question", ")", "\n", "output_vq", "=", "self", ".", "linear_final_vq", "(", "torch", ".", "cat", "(", "(", "output_vq", ",", "v", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "# output_v = self.layer_norm_vq(output_vq + v)", "\n", "output_v", "=", "self", ".", "layer_norm_vq", "(", "output_vq", ")", "\n", "return", "output_q", ",", "output_v", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoConcatAttention.__init__": [[668, 675], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.CoConcatAttentionLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "CoConcatAttentionLayer", "(", "hidden_size", ",", "dropout_p", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoConcatAttention.forward": [[677, 693], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "encoder"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "question", ",", "video", ")", ":", "\n", "        ", "attn_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "question", ",", "video", ")", "\n", "attn_mask_", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "softmax_mask_", "=", "padding_mask_q", "(", "video", ",", "question", ")", "\n", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "question", ",", "video", "=", "encoder", "(", "\n", "question", ",", "\n", "video", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", "softmax_mask", "=", "softmax_mask", ",", "\n", "attn_mask_", "=", "attn_mask_", ",", "\n", "softmax_mask_", "=", "softmax_mask_", ")", "\n", "\n", "", "return", "question", ",", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoSiameseAttentionLayer.__init__": [[697, 722], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torchnlp_nn.WeightDropLinear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torchnlp_nn.WeightDropLinear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_p", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "linear_question", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_video", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v_question", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v_video", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "linear_final", "=", "nn", ".", "Sequential", "(", "\n", "nlpnn", ".", "WeightDropLinear", "(", "\n", "2", "*", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "weight_dropout", "=", "dropout_p", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", ")", "\n", "\n", "self", ".", "layer_norm_qv", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "self", ".", "layer_norm_vq", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoSiameseAttentionLayer.forward": [[723, 783], ["q_v_transformer.CoSiameseAttentionLayer.linear_question", "q_v_transformer.CoSiameseAttentionLayer.linear_video", "q_v_transformer.CoSiameseAttentionLayer.linear_v_question", "q_v_transformer.CoSiameseAttentionLayer.linear_v_video", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoSiameseAttentionLayer.softmax", "attention_qv.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoSiameseAttentionLayer.softmax", "attention_vq.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoSiameseAttentionLayer.linear_final", "q_v_transformer.CoSiameseAttentionLayer.layer_norm_qv", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.CoSiameseAttentionLayer.linear_final", "q_v_transformer.CoSiameseAttentionLayer.layer_norm_vq", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.CoSiameseAttentionLayer.size", "q_v_transformer.CoSiameseAttentionLayer.transpose", "attention_qv.masked_fill.masked_fill.masked_fill", "q_v_transformer.CoSiameseAttentionLayer.transpose", "attention_vq.masked_fill.masked_fill.masked_fill", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "question", ",", "\n", "video", ",", "\n", "scale", "=", "None", ",", "\n", "attn_mask", "=", "None", ",", "\n", "softmax_mask", "=", "None", ",", "\n", "attn_mask_", "=", "None", ",", "\n", "softmax_mask_", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            q: [B, L_q, D_q]\n            k: [B, L_k, D_k]\n            v: [B, L_v, D_v]\n        \"\"\"", "\n", "q", "=", "question", "\n", "v", "=", "video", "\n", "\n", "if", "attn_mask", "is", "None", "or", "softmax_mask", "is", "None", ":", "\n", "            ", "attn_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "question", ",", "video", ")", "\n", "", "if", "attn_mask_", "is", "None", "or", "softmax_mask_", "is", "None", ":", "\n", "            ", "attn_mask_", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "softmax_mask_", "=", "padding_mask_q", "(", "video", ",", "question", ")", "\n", "\n", "# linear projection", "\n", "", "question_q", "=", "self", ".", "linear_question", "(", "question", ")", "\n", "video_k", "=", "self", ".", "linear_video", "(", "video", ")", "\n", "question", "=", "self", ".", "linear_v_question", "(", "question", ")", "\n", "video", "=", "self", ".", "linear_v_video", "(", "video", ")", "\n", "\n", "scale", "=", "video", ".", "size", "(", "-", "1", ")", "**", "-", "0.5", "\n", "\n", "attention_qv", "=", "torch", ".", "bmm", "(", "question_q", ",", "video_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention_qv", "=", "attention_qv", "*", "scale", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attention_qv", "=", "attention_qv", ".", "masked_fill", "(", "attn_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attention_qv", "=", "self", ".", "softmax", "(", "attention_qv", ")", "\n", "attention_qv", "=", "attention_qv", ".", "masked_fill", "(", "softmax_mask", ",", "0.", ")", "\n", "\n", "attention_vq", "=", "torch", ".", "bmm", "(", "video_k", ",", "question_q", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention_vq", "=", "attention_vq", "*", "scale", "\n", "", "if", "attn_mask_", "is", "not", "None", ":", "\n", "            ", "attention_vq", "=", "attention_vq", ".", "masked_fill", "(", "attn_mask_", ",", "-", "np", ".", "inf", ")", "\n", "", "attention_vq", "=", "self", ".", "softmax", "(", "attention_vq", ")", "\n", "attention_vq", "=", "attention_vq", ".", "masked_fill", "(", "softmax_mask_", ",", "0.", ")", "\n", "\n", "# attention = self.dropout(attention)", "\n", "output_qv", "=", "torch", ".", "bmm", "(", "attention_qv", ",", "video", ")", "\n", "output_qv", "=", "self", ".", "linear_final", "(", "torch", ".", "cat", "(", "(", "output_qv", ",", "q", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "# output_q = self.layer_norm_qv(output_qv + q)", "\n", "output_q", "=", "self", ".", "layer_norm_qv", "(", "output_qv", ")", "\n", "\n", "output_vq", "=", "torch", ".", "bmm", "(", "attention_vq", ",", "question", ")", "\n", "output_vq", "=", "self", ".", "linear_final", "(", "torch", ".", "cat", "(", "(", "output_vq", ",", "v", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "# output_v = self.layer_norm_vq(output_vq + v)", "\n", "output_v", "=", "self", ".", "layer_norm_vq", "(", "output_vq", ")", "\n", "return", "output_q", ",", "output_v", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoSiameseAttention.__init__": [[787, 794], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.CoSiameseAttentionLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "CoSiameseAttentionLayer", "(", "hidden_size", ",", "dropout_p", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CoSiameseAttention.forward": [[796, 812], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "encoder"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "question", ",", "video", ")", ":", "\n", "        ", "attn_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "question", ",", "video", ")", "\n", "attn_mask_", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "softmax_mask_", "=", "padding_mask_q", "(", "video", ",", "question", ")", "\n", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "question", ",", "video", "=", "encoder", "(", "\n", "question", ",", "\n", "video", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", "softmax_mask", "=", "softmax_mask", ",", "\n", "attn_mask_", "=", "attn_mask_", ",", "\n", "softmax_mask_", "=", "softmax_mask_", ")", "\n", "\n", "", "return", "question", ",", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SingleAttentionLayer.__init__": [[816, 832], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_p", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "self", ".", "linear_q", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_k", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "linear_final", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "hidden_size", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SingleAttentionLayer.forward": [[833, 867], ["q_v_transformer.SingleAttentionLayer.linear_q", "q_v_transformer.SingleAttentionLayer.linear_k", "q_v_transformer.SingleAttentionLayer.linear_v", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.SingleAttentionLayer.softmax", "attention.masked_fill.masked_fill.masked_fill", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "q_v_transformer.SingleAttentionLayer.linear_final", "q_v_transformer.SingleAttentionLayer.layer_norm", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.SingleAttentionLayer.size", "q_v_transformer.SingleAttentionLayer.transpose", "attention.masked_fill.masked_fill.masked_fill"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "scale", "=", "None", ",", "attn_mask", "=", "None", ",", "softmax_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            q: [B, L_q, D_q]\n            k: [B, L_k, D_k]\n            v: [B, L_v, D_v]\n        Return: Same shape to q, but in 'v' space, soft knn\n        \"\"\"", "\n", "\n", "if", "attn_mask", "is", "None", "or", "softmax_mask", "is", "None", ":", "\n", "            ", "attn_mask", "=", "padding_mask_k", "(", "q", ",", "k", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "q", ",", "k", ")", "\n", "\n", "# linear projection", "\n", "", "q", "=", "self", ".", "linear_q", "(", "q", ")", "\n", "k", "=", "self", ".", "linear_k", "(", "k", ")", "\n", "v", "=", "self", ".", "linear_v", "(", "v", ")", "\n", "\n", "scale", "=", "v", ".", "size", "(", "-", "1", ")", "**", "-", "0.5", "\n", "\n", "attention", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", "*", "scale", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attention", "=", "attention", ".", "masked_fill", "(", "attn_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attention", "=", "self", ".", "softmax", "(", "attention", ")", "\n", "attention", "=", "attention", ".", "masked_fill", "(", "softmax_mask", ",", "0.", ")", "\n", "\n", "# attention = self.dropout(attention)", "\n", "output", "=", "torch", ".", "bmm", "(", "attention", ",", "v", ")", "\n", "output", "=", "self", ".", "linear_final", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "q", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SingleAttention.__init__": [[871, 878], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.SingleAttentionLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "SingleAttentionLayer", "(", "hidden_size", ",", "dropout_p", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SingleAttention.forward": [[880, 888], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "encoder"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "q", ",", "v", ")", ":", "\n", "        ", "attn_mask", "=", "padding_mask_k", "(", "q", ",", "v", ")", "\n", "softmax_mask", "=", "padding_mask_q", "(", "q", ",", "v", ")", "\n", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "q", "=", "encoder", "(", "q", ",", "v", ",", "v", ",", "attn_mask", "=", "attn_mask", ",", "softmax_mask", "=", "softmax_mask", ")", "\n", "\n", "", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SoftKNN.__init__": [[892, 905], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "q_v_transformer.ScaledDotProductAttention"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "num_heads", "=", "1", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "num_heads", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "linear_k", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_v", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_q", "=", "nn", ".", "Linear", "(", "\n", "model_dim", ",", "self", ".", "dim_per_head", "*", "num_heads", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "dot_product_attention", "=", "ScaledDotProductAttention", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SoftKNN.forward": [[906, 933], ["key.view.view.size", "q_v_transformer.SoftKNN.linear_k", "q_v_transformer.SoftKNN.linear_v", "q_v_transformer.SoftKNN.linear_q", "key.view.view.view", "value.view.view.view", "query.view.view.view", "q_v_transformer.SoftKNN.dot_product_attention", "context.view", "attn_mask.repeat.repeat.repeat", "key.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "attn_mask", "=", "None", ")", ":", "\n", "\n", "        ", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "num_heads", "=", "self", ".", "num_heads", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "\n", "# linear projection", "\n", "key", "=", "self", ".", "linear_k", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_v", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_q", "(", "query", ")", "\n", "\n", "# split by heads", "\n", "key", "=", "key", ".", "view", "(", "batch_size", "*", "num_heads", ",", "-", "1", ",", "dim_per_head", ")", "\n", "value", "=", "value", ".", "view", "(", "batch_size", "*", "num_heads", ",", "-", "1", ",", "dim_per_head", ")", "\n", "query", "=", "query", ".", "view", "(", "batch_size", "*", "num_heads", ",", "-", "1", ",", "dim_per_head", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "repeat", "(", "num_heads", ",", "1", ",", "1", ")", "\n", "# scaled dot product attention", "\n", "", "scale", "=", "(", "key", ".", "size", "(", "-", "1", ")", "//", "num_heads", ")", "**", "-", "0.5", "\n", "context", ",", "attention", "=", "self", ".", "dot_product_attention", "(", "\n", "query", ",", "key", ",", "value", ",", "scale", ",", "attn_mask", ")", "\n", "\n", "# concat heads", "\n", "output", "=", "context", ".", "view", "(", "batch_size", ",", "-", "1", ",", "dim_per_head", "*", "num_heads", ")", "\n", "\n", "return", "output", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CrossoverTransformerLayer.__init__": [[937, 946], ["torch.Module.__init__", "q_v_transformer.MultiHeadAttention", "q_v_transformer.MultiHeadAttention", "q_v_transformer.PositionalWiseFeedForward", "q_v_transformer.PositionalWiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "num_heads", "=", "8", ",", "ffn_dim", "=", "2048", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "v_transformer", "=", "MultiHeadAttention", "(", "model_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "q_transformer", "=", "MultiHeadAttention", "(", "model_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "v_feed_forward", "=", "PositionalWiseFeedForward", "(", "\n", "model_dim", ",", "ffn_dim", ",", "dropout", ")", "\n", "self", ".", "q_feed_forward", "=", "PositionalWiseFeedForward", "(", "\n", "model_dim", ",", "ffn_dim", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CrossoverTransformerLayer.forward": [[947, 961], ["q_v_transformer.CrossoverTransformerLayer.v_transformer", "q_v_transformer.CrossoverTransformerLayer.v_feed_forward", "q_v_transformer.CrossoverTransformerLayer.q_transformer", "q_v_transformer.CrossoverTransformerLayer.q_feed_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "question", ",", "video", ",", "q_mask", "=", "None", ",", "v_mask", "=", "None", ")", ":", "\n", "# self attention, v_attention of shape (bs, v_len, q_len)", "\n", "        ", "video_", ",", "v_attention", "=", "self", ".", "v_transformer", "(", "\n", "video", ",", "question", ",", "question", ",", "v_mask", ")", "\n", "# feed forward network", "\n", "video_", "=", "self", ".", "v_feed_forward", "(", "video_", ")", "\n", "\n", "# self attention, q_attention of shape (bs, q_len, v_len)", "\n", "question_", ",", "q_attention", "=", "self", ".", "q_transformer", "(", "\n", "question", ",", "video", ",", "video", ",", "q_mask", ")", "\n", "# feed forward network", "\n", "question_", "=", "self", ".", "q_feed_forward", "(", "question_", ")", "\n", "\n", "return", "video_", ",", "question_", ",", "v_attention", ",", "q_attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CrossoverTransformer.__init__": [[965, 986], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.PositionalEncoding", "q_v_transformer.PositionalEncoding", "q_v_transformer.CrossoverTransformerLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "q_max_len", "=", "35", ",", "\n", "v_max_len", "=", "80", ",", "\n", "num_layers", "=", "2", ",", "\n", "model_dim", "=", "512", ",", "\n", "num_heads", "=", "8", ",", "\n", "ffn_dim", "=", "2048", ",", "\n", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "CrossoverTransformerLayer", "(", "\n", "model_dim", ",", "num_heads", ",", "ffn_dim", ",", "dropout", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "\n", "]", ")", "\n", "\n", "# max_seq_len is 35 or 80", "\n", "self", ".", "q_pos_embedding", "=", "PositionalEncoding", "(", "model_dim", ",", "q_max_len", ")", "\n", "self", ".", "v_pos_embedding", "=", "PositionalEncoding", "(", "model_dim", ",", "v_max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.CrossoverTransformer.forward": [[987, 1006], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_k", "q_v_transformer.CrossoverTransformer.q_pos_embedding", "q_v_transformer.CrossoverTransformer.v_pos_embedding", "encoder", "q_attentions.append", "v_attentions.append", "question.size", "video.size"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k"], ["", "def", "forward", "(", "self", ",", "question", ",", "video", ",", "q_length", ",", "v_length", ")", ":", "\n", "# q_length of shape (batch, ), each item is the length of the seq", "\n", "        ", "question", "+=", "self", ".", "q_pos_embedding", "(", "q_length", ")", "[", ":", ",", ":", "question", ".", "size", "(", ")", "[", "1", "]", ",", ":", "]", "\n", "video", "+=", "self", ".", "v_pos_embedding", "(", "v_length", ")", "[", ":", ",", ":", "video", ".", "size", "(", ")", "[", "1", "]", ",", ":", "]", "\n", "\n", "# q_attention_mask of shape (bs, q_len, v_len)", "\n", "q_attention_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "# v_attention_mask of shape (bs, v_len, q_len)", "\n", "v_attention_mask", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "\n", "q_attentions", "=", "[", "]", "\n", "v_attentions", "=", "[", "]", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "video", ",", "question", ",", "v_attention", ",", "q_attention", "=", "encoder", "(", "\n", "question", ",", "video", ",", "q_attention_mask", ",", "v_attention_mask", ")", "\n", "q_attentions", ".", "append", "(", "q_attention", ")", "\n", "v_attentions", ".", "append", "(", "v_attention", ")", "\n", "\n", "", "return", "question", ",", "video", ",", "q_attentions", ",", "v_attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedCrossoverTransformerLayer.__init__": [[1010, 1021], ["torch.Module.__init__", "q_v_transformer.MaskedMultiHeadAttention", "q_v_transformer.MaskedMultiHeadAttention", "q_v_transformer.MaskedPositionalWiseFeedForward", "q_v_transformer.MaskedPositionalWiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_dim", "=", "512", ",", "num_heads", "=", "8", ",", "ffn_dim", "=", "2048", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "v_transformer", "=", "MaskedMultiHeadAttention", "(", "\n", "model_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "q_transformer", "=", "MaskedMultiHeadAttention", "(", "\n", "model_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "v_feed_forward", "=", "MaskedPositionalWiseFeedForward", "(", "\n", "model_dim", ",", "ffn_dim", ",", "dropout", ")", "\n", "self", ".", "q_feed_forward", "=", "MaskedPositionalWiseFeedForward", "(", "\n", "model_dim", ",", "ffn_dim", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedCrossoverTransformerLayer.forward": [[1022, 1043], ["q_v_transformer.MaskedCrossoverTransformerLayer.v_transformer", "q_v_transformer.MaskedCrossoverTransformerLayer.v_feed_forward", "q_v_transformer.MaskedCrossoverTransformerLayer.q_transformer", "q_v_transformer.MaskedCrossoverTransformerLayer.q_feed_forward"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "question", ",", "\n", "video", ",", "\n", "q_mask", "=", "None", ",", "\n", "v_mask", "=", "None", ",", "\n", "q_sf_mask", "=", "None", ",", "\n", "v_sf_mask", "=", "None", ")", ":", "\n", "# self attention, v_attention of shape (bs, v_len, q_len)", "\n", "        ", "video_", ",", "v_attention", "=", "self", ".", "v_transformer", "(", "\n", "video", ",", "question", ",", "question", ",", "v_mask", ",", "v_sf_mask", ")", "\n", "# feed forward network", "\n", "video_", "=", "self", ".", "v_feed_forward", "(", "video_", ")", "\n", "\n", "# self attention, q_attention of shape (bs, q_len, v_len)", "\n", "question_", ",", "q_attention", "=", "self", ".", "q_transformer", "(", "\n", "question", ",", "video", ",", "video", ",", "q_mask", ",", "q_sf_mask", ")", "\n", "# feed forward network", "\n", "question_", "=", "self", ".", "q_feed_forward", "(", "question_", ")", "\n", "\n", "return", "video_", ",", "question_", ",", "v_attention", ",", "q_attention", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedCrossoverTransformer.__init__": [[1047, 1071], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "q_v_transformer.PositionalEncoding", "q_v_transformer.PositionalEncoding", "q_v_transformer.MaskedCrossoverTransformerLayer", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "q_max_len", "=", "35", ",", "\n", "v_max_len", "=", "80", ",", "\n", "num_layers", "=", "2", ",", "\n", "model_dim", "=", "512", ",", "\n", "num_heads", "=", "8", ",", "\n", "ffn_dim", "=", "2048", ",", "\n", "dropout", "=", "0.0", ",", "\n", "position", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "position", "=", "position", "\n", "\n", "self", ".", "encoder_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "MaskedCrossoverTransformerLayer", "(", "\n", "model_dim", ",", "num_heads", ",", "ffn_dim", ",", "dropout", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "\n", "]", ")", "\n", "\n", "# max_seq_len is 35 or 80", "\n", "self", ".", "q_pos_embedding", "=", "PositionalEncoding", "(", "model_dim", ",", "q_max_len", ")", "\n", "self", ".", "v_pos_embedding", "=", "PositionalEncoding", "(", "model_dim", ",", "v_max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.MaskedCrossoverTransformer.forward": [[1072, 1094], ["q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "q_v_transformer.padding_mask_k", "q_v_transformer.padding_mask_q", "encoder", "q_attentions.append", "v_attentions.append", "q_v_transformer.MaskedCrossoverTransformer.q_pos_embedding", "q_v_transformer.MaskedCrossoverTransformer.v_pos_embedding", "question.size", "video.size"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "question", ",", "video", ",", "q_length", ",", "v_length", ")", ":", "\n", "# q_length of shape (batch, ), each item is the length of the seq", "\n", "        ", "if", "self", ".", "position", ":", "\n", "            ", "question", "+=", "self", ".", "q_pos_embedding", "(", "\n", "q_length", ")", "[", ":", ",", ":", "question", ".", "size", "(", ")", "[", "1", "]", ",", ":", "]", "\n", "video", "+=", "self", ".", "v_pos_embedding", "(", "v_length", ")", "[", ":", ",", ":", "video", ".", "size", "(", ")", "[", "1", "]", ",", ":", "]", "\n", "\n", "", "q_attention_mask", "=", "padding_mask_k", "(", "question", ",", "video", ")", "\n", "q_softmax_mask", "=", "padding_mask_q", "(", "question", ",", "video", ")", "\n", "v_attention_mask", "=", "padding_mask_k", "(", "video", ",", "question", ")", "\n", "v_softmax_mask", "=", "padding_mask_q", "(", "video", ",", "question", ")", "\n", "\n", "q_attentions", "=", "[", "]", "\n", "v_attentions", "=", "[", "]", "\n", "for", "encoder", "in", "self", ".", "encoder_layers", ":", "\n", "            ", "video", ",", "question", ",", "v_attention", ",", "q_attention", "=", "encoder", "(", "\n", "question", ",", "video", ",", "q_attention_mask", ",", "v_attention_mask", ",", "\n", "q_softmax_mask", ",", "v_softmax_mask", ")", "\n", "q_attentions", ".", "append", "(", "q_attention", ")", "\n", "v_attentions", ".", "append", "(", "v_attention", ")", "\n", "\n", "", "return", "question", ",", "video", ",", "q_attentions", ",", "v_attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfTransformerEncoder.__init__": [[1098, 1137], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "torchnlp_nn.WeightDropLinear", "q_v_transformer.PositionalEncoding", "q_v_transformer.PositionalEncoding"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "hidden_size", ",", "\n", "n_layers", ",", "\n", "dropout_p", ",", "\n", "vocab_size", ",", "\n", "q_max_len", ",", "\n", "v_max_len", ",", "\n", "embedding", "=", "None", ",", "\n", "update_embedding", "=", "True", ",", "\n", "position", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_p", ")", "\n", "self", ".", "ln_q", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "self", ".", "ln_v", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "position", "=", "position", "\n", "\n", "embedding_dim", "=", "embedding", ".", "shape", "[", "\n", "1", "]", "if", "embedding", "is", "not", "None", "else", "hidden_size", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ",", "padding_idx", "=", "0", ")", "\n", "\n", "# ! no embedding init", "\n", "# if embedding is not None:", "\n", "#     # self.embedding.weight.data.copy_(torch.from_numpy(embedding))", "\n", "#     self.embedding.weight = nn.Parameter(", "\n", "#         torch.from_numpy(embedding).float())", "\n", "self", ".", "upcompress_embedding", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "embedding_dim", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "self", ".", "embedding", ".", "weight", ".", "requires_grad", "=", "update_embedding", "\n", "\n", "self", ".", "project_c3d", "=", "nlpnn", ".", "WeightDropLinear", "(", "4096", ",", "2048", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "project_resnet_and_c3d", "=", "nlpnn", ".", "WeightDropLinear", "(", "\n", "4096", ",", "hidden_size", ",", "weight_dropout", "=", "dropout_p", ",", "bias", "=", "False", ")", "\n", "\n", "# max_seq_len is 35 or 80", "\n", "self", ".", "q_pos_embedding", "=", "PositionalEncoding", "(", "hidden_size", ",", "q_max_len", ")", "\n", "self", ".", "v_pos_embedding", "=", "PositionalEncoding", "(", "hidden_size", ",", "v_max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.SelfTransformerEncoder.forward": [[1138, 1159], ["q_v_transformer.SelfTransformerEncoder.embedding", "q_v_transformer.SelfTransformerEncoder.dropout", "torch.relu", "torch.relu", "torch.relu", "q_v_transformer.SelfTransformerEncoder.project_c3d", "torch.relu", "torch.relu", "torch.relu", "q_v_transformer.SelfTransformerEncoder.upcompress_embedding", "q_v_transformer.SelfTransformerEncoder.project_resnet_and_c3d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "q_v_transformer.SelfTransformerEncoder.q_pos_embedding", "q_v_transformer.SelfTransformerEncoder.v_pos_embedding", "torch.relu.size", "torch.relu.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "question", ",", "resnet", ",", "c3d", ",", "q_length", ",", "v_length", ")", ":", "\n", "### question", "\n", "        ", "embedded", "=", "self", ".", "embedding", "(", "question", ")", "\n", "embedded", "=", "self", ".", "dropout", "(", "embedded", ")", "\n", "question", "=", "F", ".", "relu", "(", "self", ".", "upcompress_embedding", "(", "embedded", ")", ")", "\n", "\n", "### video", "\n", "# ! no relu", "\n", "c3d", "=", "self", ".", "project_c3d", "(", "c3d", ")", "\n", "video", "=", "F", ".", "relu", "(", "\n", "self", ".", "project_resnet_and_c3d", "(", "torch", ".", "cat", "(", "(", "resnet", ",", "c3d", ")", ",", "dim", "=", "2", ")", ")", ")", "\n", "\n", "### position encoding", "\n", "if", "self", ".", "position", ":", "\n", "            ", "question", "+=", "self", ".", "q_pos_embedding", "(", "\n", "q_length", ")", "[", ":", ",", ":", "question", ".", "size", "(", ")", "[", "1", "]", ",", ":", "]", "\n", "video", "+=", "self", ".", "v_pos_embedding", "(", "v_length", ")", "[", ":", ",", ":", "video", ".", "size", "(", ")", "[", "1", "]", ",", ":", "]", "\n", "\n", "# question = self.ln_q(question)", "\n", "# video = self.ln_v(video)", "\n", "", "return", "question", ",", "video", "\n", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.padding_mask": [[8, 15], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "pad_mask.eq.eq", "torch.unsqueeze.transpose"], "function", ["None"], ["def", "padding_mask", "(", "seq_q", ",", "seq_k", ")", ":", "\n", "# seq_k of shape (batch, k_len) and seq_q (batch, q_len), not embedded. q and k are padded with 0.", "\n", "    ", "seq_q", "=", "torch", ".", "unsqueeze", "(", "seq_q", ",", "2", ")", "\n", "seq_k", "=", "torch", ".", "unsqueeze", "(", "seq_k", ",", "2", ")", "\n", "pad_mask", "=", "torch", ".", "bmm", "(", "seq_q", ",", "seq_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "pad_mask", "=", "pad_mask", ".", "eq", "(", "0", ")", "\n", "return", "pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.padding_mask_transformer": [[17, 25], ["seq_q.size", "seq_k.eq", "pad_mask.unsqueeze().expand.unsqueeze().expand", "pad_mask.unsqueeze().expand.unsqueeze"], "function", ["None"], ["", "def", "padding_mask_transformer", "(", "seq_q", ",", "seq_k", ")", ":", "\n", "# original padding_mask in transformer, for masking out the padding part of key sequence.", "\n", "    ", "len_q", "=", "seq_q", ".", "size", "(", "1", ")", "\n", "# `PAD` is 0", "\n", "pad_mask", "=", "seq_k", ".", "eq", "(", "0", ")", "\n", "pad_mask", "=", "pad_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "-", "1", ",", "len_q", ",", "-", "1", ")", "# shape [B, L_q, L_k]", "\n", "return", "pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.padding_mask_embedded": [[27, 32], ["torch.bmm", "torch.bmm", "torch.bmm", "pad_mask.eq.eq", "seq_k.transpose"], "function", ["None"], ["", "def", "padding_mask_embedded", "(", "seq_q", ",", "seq_k", ")", ":", "\n", "# seq_k of shape (batch, k_len, k_feat) and seq_q (batch, q_len, q_feat). q and k are padded with 0. pad_mask is (batch, q_len, k_len)", "\n", "    ", "pad_mask", "=", "torch", ".", "bmm", "(", "seq_q", ",", "seq_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "pad_mask", "=", "pad_mask", ".", "eq", "(", "0", ")", "\n", "return", "pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.padding_mask_k": [[34, 46], ["torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.bmm", "torch.bmm", "torch.bmm", "pad_mask.eq.eq", "seq_k.transpose"], "function", ["None"], ["", "def", "padding_mask_k", "(", "seq_q", ",", "seq_k", ")", ":", "\n", "    ", "\"\"\" seq_k of shape (batch, k_len, k_feat) and seq_q (batch, q_len, q_feat). q and k are padded with 0. pad_mask is (batch, q_len, k_len).\n    In batch 0:\n    [[x x x 0]     [[0 0 0 1]\n     [x x x 0]->    [0 0 0 1]\n     [x x x 0]]     [0 0 0 1]] uint8\n    \"\"\"", "\n", "fake_q", "=", "torch", ".", "ones_like", "(", "seq_q", ")", "\n", "pad_mask", "=", "torch", ".", "bmm", "(", "fake_q", ",", "seq_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "pad_mask", "=", "pad_mask", ".", "eq", "(", "0", ")", "\n", "# pad_mask = pad_mask.lt(1e-3)", "\n", "return", "pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.q_v_transformer.padding_mask_q": [[48, 60], ["torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.bmm", "torch.bmm", "torch.bmm", "pad_mask.eq.eq", "torch.ones_like.transpose"], "function", ["None"], ["", "def", "padding_mask_q", "(", "seq_q", ",", "seq_k", ")", ":", "\n", "    ", "\"\"\" seq_k of shape (batch, k_len, k_feat) and seq_q (batch, q_len, q_feat). q and k are padded with 0. pad_mask is (batch, q_len, k_len).\n    In batch 0:\n    [[x x x x]      [[0 0 0 0]\n     [x x x x]  ->   [0 0 0 0]\n     [0 0 0 0]]      [1 1 1 1]] uint8\n    \"\"\"", "\n", "fake_k", "=", "torch", ".", "ones_like", "(", "seq_k", ")", "\n", "pad_mask", "=", "torch", ".", "bmm", "(", "seq_q", ",", "fake_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "pad_mask", "=", "pad_mask", ".", "eq", "(", "0", ")", "\n", "# pad_mask = pad_mask.lt(1e-3)", "\n", "return", "pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn.weight_drop.__init__": [[10, 21], ["getattr", "module.register_parameter", "torch.nn.Parameter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "weights", ",", "dropout", ")", ":", "\n", "        ", "for", "name_w", "in", "weights", ":", "\n", "            ", "w", "=", "getattr", "(", "module", ",", "name_w", ")", "\n", "del", "module", ".", "_parameters", "[", "name_w", "]", "\n", "module", ".", "register_parameter", "(", "name_w", "+", "'_raw'", ",", "Parameter", "(", "w", ")", ")", "\n", "\n", "", "self", ".", "original_module_forward", "=", "module", ".", "forward", "\n", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn.weight_drop.__call__": [[22, 31], ["torchnlp_nn.weight_drop.original_module_forward", "getattr", "torch.nn.functional.dropout", "setattr", "torch.nn.Parameter"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "raw_w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", "+", "'_raw'", ")", "\n", "w", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "\n", "raw_w", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "module", ".", "training", ")", "\n", "# module.register_parameter(name_w, Parameter(w))", "\n", "setattr", "(", "self", ".", "module", ",", "name_w", ",", "Parameter", "(", "w", ")", ")", "\n", "\n", "", "return", "self", ".", "original_module_forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn.WeightDrop.__init__": [[91, 95], ["super().__init__", "torchnlp_nn._weight_drop"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn._weight_drop"], ["def", "__init__", "(", "self", ",", "module", ",", "weights", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "WeightDrop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "_weight_drop", "(", "module", ",", "weights", ",", "dropout", ")", "\n", "self", ".", "forward", "=", "module", ".", "forward", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn.WeightDropLSTM.__init__": [[104, 108], ["super().__init__", "torchnlp_nn._weight_drop", "str", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn._weight_drop"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "weight_dropout", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "weights", "=", "[", "'weight_hh_l'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "_weight_drop", "(", "self", ",", "weights", ",", "weight_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn.WeightDropGRU.__init__": [[117, 121], ["super().__init__", "torchnlp_nn._weight_drop", "str", "range"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn._weight_drop"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "weight_dropout", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "weights", "=", "[", "'weight_hh_l'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "_weight_drop", "(", "self", ",", "weights", ",", "weight_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn.WeightDropLinear.__init__": [[130, 134], ["super().__init__", "torchnlp_nn._weight_drop"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn._weight_drop"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "weight_dropout", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "weights", "=", "[", "'weight'", "]", "\n", "_weight_drop", "(", "self", ",", "weights", ",", "weight_dropout", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.torchnlp_nn._weight_drop": [[33, 35], ["setattr", "torchnlp_nn.weight_drop"], "function", ["None"], ["", "", "def", "_weight_drop", "(", "module", ",", "weights", ",", "dropout", ")", ":", "\n", "    ", "setattr", "(", "module", ",", "'forward'", ",", "weight_drop", "(", "module", ",", "weights", ",", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.embed_loss.MultipleChoiceLoss.__init__": [[10, 15], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_option", "=", "5", ",", "margin", "=", "1", ",", "size_average", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultipleChoiceLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "num_option", "=", "num_option", "\n", "self", ".", "size_average", "=", "size_average", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.embed_loss.MultipleChoiceLoss.forward": [[18, 44], ["score.size", "score.size", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "range", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "score", ",", "target", ")", ":", "\n", "        ", "N", "=", "score", ".", "size", "(", "0", ")", "\n", "C", "=", "score", ".", "size", "(", "1", ")", "\n", "assert", "self", ".", "num_option", "==", "C", "\n", "\n", "loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "cuda", "(", ")", "\n", "zero", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "cuda", "(", ")", "\n", "\n", "cnt", "=", "0", "\n", "#print(N,C)", "\n", "for", "b", "in", "range", "(", "N", ")", ":", "\n", "# loop over incorrect answer, check if correct answer's score larger than a margin", "\n", "            ", "c0", "=", "target", "[", "b", "]", "\n", "for", "c", "in", "range", "(", "C", ")", ":", "\n", "                ", "if", "c", "==", "c0", ":", "\n", "                    ", "continue", "\n", "\n", "# right class and wrong class should have score difference larger than a margin", "\n", "# see formula under paper Eq(4)", "\n", "", "loss", "+=", "torch", ".", "max", "(", "zero", ",", "1.0", "+", "score", "[", "b", ",", "c", "]", "-", "score", "[", "b", ",", "c0", "]", ")", "\n", "cnt", "+=", "1", "\n", "\n", "", "", "if", "cnt", "==", "0", ":", "\n", "            ", "return", "loss", "\n", "\n", "", "return", "loss", "/", "cnt", "if", "self", ".", "size_average", "else", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderQns.__init__": [[7, 40], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "EncoderRNN.EncoderQns.rnn_cell", "rnn_cell.lower", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "rnn_cell.lower", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim_embed", ",", "dim_hidden", ",", "vocab_size", ",", "glove_embed", ",", "use_bert", "=", "True", ",", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0", ",", "\n", "n_layers", "=", "1", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'gru'", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "super", "(", "EncoderQns", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim_hidden", "=", "dim_hidden", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "glove_embed", "=", "glove_embed", "\n", "self", ".", "input_dropout_p", "=", "input_dropout_p", "\n", "self", ".", "rnn_dropout_p", "=", "rnn_dropout_p", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n", "\n", "self", ".", "input_dropout", "=", "nn", ".", "Dropout", "(", "input_dropout_p", ")", "\n", "\n", "if", "rnn_cell", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "LSTM", "\n", "", "elif", "rnn_cell", ".", "lower", "(", ")", "==", "'gru'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "GRU", "\n", "\n", "", "input_dim", "=", "dim_embed", "\n", "self", ".", "use_bert", "=", "use_bert", "\n", "if", "self", ".", "use_bert", ":", "\n", "            ", "input_dim", "=", "768", "\n", "self", ".", "embedding", "=", "nn", ".", "Linear", "(", "input_dim", ",", "dim_embed", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "dim_embed", ")", "\n", "word_mat", "=", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "self", ".", "glove_embed", ")", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "word_mat", ",", "freeze", "=", "False", ")", "\n", "\n", "", "self", ".", "rnn", "=", "self", ".", "rnn_cell", "(", "dim_embed", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderQns.forward": [[42, 55], ["EncoderRNN.EncoderQns.embedding", "EncoderRNN.EncoderQns.input_dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "EncoderRNN.EncoderQns.rnn", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "qns", ",", "qns_lengths", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n         encode question\n        :param qns:\n        :param qns_lengths:\n        :return:\n        \"\"\"", "\n", "qns_embed", "=", "self", ".", "embedding", "(", "qns", ")", "\n", "qns_embed", "=", "self", ".", "input_dropout", "(", "qns_embed", ")", "\n", "packed", "=", "pack_padded_sequence", "(", "qns_embed", ",", "qns_lengths", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", ")", "\n", "packed_output", ",", "hidden", "=", "self", ".", "rnn", "(", "packed", ",", "hidden", ")", "\n", "output", ",", "_", "=", "pad_packed_sequence", "(", "packed_output", ",", "batch_first", "=", "True", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVid.__init__": [[58, 80], ["torch.Module.__init__", "EncoderRNN.EncoderVid.rnn_cell", "rnn_cell.lower", "rnn_cell.lower"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim_vid", ",", "dim_hidden", ",", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0", ",", "\n", "n_layers", "=", "1", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'gru'", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "super", "(", "EncoderVid", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim_vid", "=", "dim_vid", "\n", "self", ".", "dim_app", "=", "2048", "\n", "self", ".", "dim_motion", "=", "4096", "\n", "self", ".", "dim_hidden", "=", "dim_hidden", "\n", "self", ".", "input_dropout_p", "=", "input_dropout_p", "\n", "self", ".", "rnn_dropout_p", "=", "rnn_dropout_p", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n", "\n", "if", "rnn_cell", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "LSTM", "\n", "", "elif", "rnn_cell", ".", "lower", "(", ")", "==", "'gru'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "GRU", "\n", "\n", "", "self", ".", "rnn", "=", "self", ".", "rnn_cell", "(", "dim_vid", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVid.forward": [[82, 88], ["EncoderRNN.EncoderVid.rnn.flatten_parameters", "EncoderRNN.EncoderVid.rnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vid_feats", ")", ":", "\n", "\n", "        ", "self", ".", "rnn", ".", "flatten_parameters", "(", ")", "\n", "foutput", ",", "fhidden", "=", "self", ".", "rnn", "(", "vid_feats", ")", "\n", "\n", "return", "foutput", ",", "fhidden", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVidSTVQA.__init__": [[91, 115], ["torch.Module.__init__", "EncoderRNN.EncoderVidSTVQA.rnn_cell", "EncoderRNN.EncoderVidSTVQA.rnn_cell", "rnn_cell.lower", "rnn_cell.lower"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "dim_hidden", ",", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0", ",", "\n", "n_layers", "=", "1", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'gru'", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "super", "(", "EncoderVidSTVQA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "dim_hidden", "=", "dim_hidden", "\n", "self", ".", "input_dropout_p", "=", "input_dropout_p", "\n", "self", ".", "rnn_dropout_p", "=", "rnn_dropout_p", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n", "\n", "\n", "if", "rnn_cell", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "LSTM", "\n", "", "elif", "rnn_cell", ".", "lower", "(", ")", "==", "'gru'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "GRU", "\n", "\n", "", "self", ".", "rnn1", "=", "self", ".", "rnn_cell", "(", "input_dim", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "\n", "self", ".", "rnn2", "=", "self", ".", "rnn_cell", "(", "dim_hidden", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVidSTVQA.forward": [[117, 133], ["EncoderRNN.EncoderVidSTVQA.rnn1.flatten_parameters", "EncoderRNN.EncoderVidSTVQA.rnn1", "EncoderRNN.EncoderVidSTVQA.rnn2.flatten_parameters", "EncoderRNN.EncoderVidSTVQA.rnn2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vid_feats", ")", ":", "\n", "        ", "\"\"\"\n        Dual-layer LSTM\n        \"\"\"", "\n", "\n", "self", ".", "rnn1", ".", "flatten_parameters", "(", ")", "\n", "\n", "foutput_1", ",", "fhidden_1", "=", "self", ".", "rnn1", "(", "vid_feats", ")", "\n", "self", ".", "rnn2", ".", "flatten_parameters", "(", ")", "\n", "foutput_2", ",", "fhidden_2", "=", "self", ".", "rnn2", "(", "foutput_1", ")", "\n", "\n", "foutput", "=", "torch", ".", "cat", "(", "(", "foutput_1", ",", "foutput_2", ")", ",", "dim", "=", "2", ")", "\n", "fhidden", "=", "(", "torch", ".", "cat", "(", "(", "fhidden_1", "[", "0", "]", ",", "fhidden_2", "[", "0", "]", ")", ",", "dim", "=", "0", ")", ",", "\n", "torch", ".", "cat", "(", "(", "fhidden_1", "[", "1", "]", ",", "fhidden_2", "[", "1", "]", ")", ",", "dim", "=", "0", ")", ")", "\n", "\n", "return", "foutput", ",", "fhidden", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVidCoMem.__init__": [[136, 164], ["torch.Module.__init__", "EncoderRNN.EncoderVidCoMem.rnn_cell", "EncoderRNN.EncoderVidCoMem.rnn_cell", "EncoderRNN.EncoderVidCoMem.rnn_cell", "EncoderRNN.EncoderVidCoMem.rnn_cell", "rnn_cell.lower", "rnn_cell.lower"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim_app", ",", "dim_motion", ",", "dim_hidden", ",", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0", ",", "\n", "n_layers", "=", "1", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'gru'", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "super", "(", "EncoderVidCoMem", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim_app", "=", "dim_app", "\n", "self", ".", "dim_motion", "=", "dim_motion", "\n", "self", ".", "dim_hidden", "=", "dim_hidden", "\n", "self", ".", "input_dropout_p", "=", "input_dropout_p", "\n", "self", ".", "rnn_dropout_p", "=", "rnn_dropout_p", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n", "\n", "if", "rnn_cell", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "LSTM", "\n", "", "elif", "rnn_cell", ".", "lower", "(", ")", "==", "'gru'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "GRU", "\n", "\n", "", "self", ".", "rnn_app_l1", "=", "self", ".", "rnn_cell", "(", "self", ".", "dim_app", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "self", ".", "rnn_app_l2", "=", "self", ".", "rnn_cell", "(", "dim_hidden", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "\n", "self", ".", "rnn_motion_l1", "=", "self", ".", "rnn_cell", "(", "self", ".", "dim_motion", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "self", ".", "rnn_motion_l2", "=", "self", ".", "rnn_cell", "(", "dim_hidden", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVidCoMem.forward": [[166, 183], ["EncoderRNN.EncoderVidCoMem.rnn_app_l1", "EncoderRNN.EncoderVidCoMem.rnn_app_l2", "EncoderRNN.EncoderVidCoMem.rnn_motion_l1", "EncoderRNN.EncoderVidCoMem.rnn_motion_l2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vid_feats", ")", ":", "\n", "        ", "\"\"\"\n        two separate LSTM to encode app and motion feature\n        :param vid_feats:\n        :return:\n        \"\"\"", "\n", "vid_app", "=", "vid_feats", "[", ":", ",", ":", ",", "0", ":", "self", ".", "dim_app", "]", "\n", "vid_motion", "=", "vid_feats", "[", ":", ",", ":", ",", "self", ".", "dim_app", ":", "]", "\n", "\n", "app_output_l1", ",", "app_hidden_l1", "=", "self", ".", "rnn_app_l1", "(", "vid_app", ")", "\n", "app_output_l2", ",", "app_hidden_l2", "=", "self", ".", "rnn_app_l2", "(", "app_output_l1", ")", "\n", "\n", "\n", "motion_output_l1", ",", "motion_hidden_l1", "=", "self", ".", "rnn_motion_l1", "(", "vid_motion", ")", "\n", "motion_output_l2", ",", "motion_hidden_l2", "=", "self", ".", "rnn_motion_l2", "(", "motion_output_l1", ")", "\n", "\n", "return", "app_output_l1", ",", "app_output_l2", ",", "motion_output_l1", ",", "motion_output_l2", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVidHGA.__init__": [[186, 214], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "EncoderRNN.EncoderVidHGA.rnn_cell", "EncoderRNN.EncoderVidHGA._init_weight", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "rnn_cell.lower", "rnn_cell.lower"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttentionHis._init_weight"], ["    ", "def", "__init__", "(", "self", ",", "dim_vid", ",", "dim_hidden", ",", "input_dropout_p", "=", "0.2", ",", "rnn_dropout_p", "=", "0", ",", "\n", "n_layers", "=", "1", ",", "bidirectional", "=", "False", ",", "rnn_cell", "=", "'gru'", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "super", "(", "EncoderVidHGA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim_vid", "=", "dim_vid", "\n", "self", ".", "dim_hidden", "=", "dim_hidden", "\n", "self", ".", "input_dropout_p", "=", "input_dropout_p", "\n", "self", ".", "rnn_dropout_p", "=", "rnn_dropout_p", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n", "\n", "\n", "self", ".", "vid2hid", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "dim_vid", ",", "dim_hidden", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "input_dropout_p", ")", ")", "\n", "\n", "\n", "if", "rnn_cell", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "LSTM", "\n", "", "elif", "rnn_cell", ".", "lower", "(", ")", "==", "'gru'", ":", "\n", "            ", "self", ".", "rnn_cell", "=", "nn", ".", "GRU", "\n", "\n", "", "self", ".", "rnn", "=", "self", ".", "rnn_cell", "(", "dim_hidden", ",", "dim_hidden", ",", "n_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "self", ".", "rnn_dropout_p", ")", "\n", "\n", "self", ".", "_init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVidHGA._init_weight": [[216, 218], ["torch.init.xavier_normal_", "torch.init.xavier_normal_"], "methods", ["None"], ["", "def", "_init_weight", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "vid2hid", "[", "0", "]", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.EncoderRNN.EncoderVidHGA.forward": [[220, 231], ["EncoderRNN.EncoderVidHGA.view.size", "EncoderRNN.EncoderVidHGA.vid2hid", "EncoderRNN.EncoderVidHGA.view", "EncoderRNN.EncoderVidHGA.rnn.flatten_parameters", "EncoderRNN.EncoderVidHGA.rnn", "EncoderRNN.EncoderVidHGA.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vid_feats", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "batch_size", ",", "seq_len", ",", "dim_vid", "=", "vid_feats", ".", "size", "(", ")", "\n", "vid_feats_trans", "=", "self", ".", "vid2hid", "(", "vid_feats", ".", "view", "(", "-", "1", ",", "self", ".", "dim_vid", ")", ")", "\n", "vid_feats", "=", "vid_feats_trans", ".", "view", "(", "batch_size", ",", "seq_len", ",", "-", "1", ")", "\n", "\n", "self", ".", "rnn", ".", "flatten_parameters", "(", ")", "\n", "foutput", ",", "fhidden", "=", "self", ".", "rnn", "(", "vid_feats", ")", "\n", "\n", "return", "foutput", ",", "fhidden", "", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttention.__init__": [[11, 18], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "Attention.TempAttention._init_weight"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttentionHis._init_weight"], ["def", "__init__", "(", "self", ",", "text_dim", ",", "visual_dim", ",", "hidden_dim", ")", ":", "\n", "        ", "super", "(", "TempAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "linear_text", "=", "nn", ".", "Linear", "(", "text_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear_visual", "=", "nn", ".", "Linear", "(", "visual_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear_att", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "_init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttention._init_weight": [[19, 23], ["torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_"], "methods", ["None"], ["", "def", "_init_weight", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_text", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_visual", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_att", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttention.forward": [[24, 50], ["Attention.TempAttention.linear_text", "vid_outputs.size", "vid_outputs.contiguous().view", "Attention.TempAttention.linear_visual", "vid_outputs_trans.view.view.view", "qns_embed_trans.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "Attention.TempAttention.linear_att", "Attention.TempAttention.view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "vid_outputs.contiguous", "qns_embed_trans.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "qns_embed", ",", "vid_outputs", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            qns_embed {Variable} -- batch_size x dim\n            vid_outputs {Variable} -- batch_size x seq_len x dim\n\n        Returns:\n            context -- context vector of size batch_size x dim\n        \"\"\"", "\n", "qns_embed_trans", "=", "self", ".", "linear_text", "(", "qns_embed", ")", "\n", "\n", "batch_size", ",", "seq_len", ",", "visual_dim", "=", "vid_outputs", ".", "size", "(", ")", "\n", "vid_outputs_temp", "=", "vid_outputs", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "seq_len", ",", "visual_dim", ")", "\n", "vid_outputs_trans", "=", "self", ".", "linear_visual", "(", "vid_outputs_temp", ")", "\n", "vid_outputs_trans", "=", "vid_outputs_trans", ".", "view", "(", "batch_size", ",", "seq_len", ",", "self", ".", "hidden_dim", ")", "\n", "\n", "qns_embed_trans", "=", "qns_embed_trans", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "seq_len", ",", "1", ")", "\n", "\n", "\n", "o", "=", "self", ".", "linear_att", "(", "torch", ".", "tanh", "(", "qns_embed_trans", "+", "vid_outputs_trans", ")", ")", "\n", "\n", "e", "=", "o", ".", "view", "(", "batch_size", ",", "seq_len", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "e", ",", "dim", "=", "1", ")", "\n", "context", "=", "torch", ".", "bmm", "(", "beta", ".", "unsqueeze", "(", "1", ")", ",", "vid_outputs", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "context", ",", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.SpatialAttention.__init__": [[57, 67], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Dropout", "Attention.SpatialAttention._init_weight"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttentionHis._init_weight"], ["def", "__init__", "(", "self", ",", "text_dim", "=", "1024", ",", "vid_dim", "=", "3072", ",", "hidden_dim", "=", "512", ",", "input_dropout_p", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "SpatialAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear_v", "=", "nn", ".", "Linear", "(", "vid_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear_q", "=", "nn", ".", "Linear", "(", "text_dim", ",", "hidden_dim", ")", "\n", "self", ".", "linear_att", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "input_dropout_p", ")", "\n", "self", ".", "_init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.SpatialAttention._init_weight": [[68, 72], ["torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_"], "methods", ["None"], ["", "def", "_init_weight", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_v", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_q", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_att", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.SpatialAttention.forward": [[73, 105], ["vid_feats.view.view.permute", "vid_feats.view.view.size", "vid_feats.view.view.contiguous().view", "Attention.SpatialAttention.linear_v", "vid_feats_trans.view.view.view", "Attention.SpatialAttention.linear_q", "qns_feat_trans.repeat.repeat.repeat", "Attention.SpatialAttention.linear_att", "Attention.SpatialAttention.view", "Attention.SpatialAttention.softmax", "alpha.unsqueeze.unsqueeze.unsqueeze", "vid_feats.view.view.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "Attention.SpatialAttention.dropout", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "vid_feats.view.view.contiguous", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "qns_feat", ",", "vid_feats", ")", ":", "\n", "        ", "\"\"\"\n        Apply question feature as semantic clue to guide feature aggregation at each frame\n        :param vid_feats: fnum x feat_dim x 7 x 7\n        :param qns_feat: dim_hidden*2\n        :return:\n        \"\"\"", "\n", "# print(qns_feat.size(), vid_feats.size())", "\n", "# permute to fnum x 7 x 7 x feat_dim", "\n", "vid_feats", "=", "vid_feats", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "fnum", ",", "width", ",", "height", ",", "feat_dim", "=", "vid_feats", ".", "size", "(", ")", "\n", "vid_feats", "=", "vid_feats", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "feat_dim", ")", "\n", "vid_feats_trans", "=", "self", ".", "linear_v", "(", "vid_feats", ")", "\n", "\n", "vid_feats_trans", "=", "vid_feats_trans", ".", "view", "(", "fnum", ",", "width", "*", "height", ",", "-", "1", ")", "\n", "region_num", "=", "vid_feats_trans", ".", "shape", "[", "1", "]", "\n", "\n", "qns_feat_trans", "=", "self", ".", "linear_q", "(", "qns_feat", ")", "\n", "\n", "qns_feat_trans", "=", "qns_feat_trans", ".", "repeat", "(", "fnum", ",", "region_num", ",", "1", ")", "\n", "# print(vid_feats_trans.shape, qns_feat_trans.shape)", "\n", "\n", "vid_qns", "=", "self", ".", "linear_att", "(", "torch", ".", "tanh", "(", "vid_feats_trans", "+", "qns_feat_trans", ")", ")", "\n", "\n", "vid_qns_o", "=", "vid_qns", ".", "view", "(", "fnum", ",", "region_num", ")", "\n", "alpha", "=", "self", ".", "softmax", "(", "vid_qns_o", ")", "\n", "alpha", "=", "alpha", ".", "unsqueeze", "(", "1", ")", "\n", "vid_feats", "=", "vid_feats", ".", "view", "(", "fnum", ",", "region_num", ",", "-", "1", ")", "\n", "feature", "=", "torch", ".", "bmm", "(", "alpha", ",", "vid_feats", ")", ".", "squeeze", "(", "1", ")", "\n", "feature", "=", "self", ".", "dropout", "(", "feature", ")", "\n", "# print(feature.size())", "\n", "return", "feature", ",", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttentionHis.__init__": [[112, 122], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "Attention.TempAttentionHis._init_weight"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttentionHis._init_weight"], ["def", "__init__", "(", "self", ",", "visual_dim", ",", "text_dim", ",", "his_dim", ",", "mem_dim", ")", ":", "\n", "        ", "super", "(", "TempAttentionHis", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# self.dim = dim", "\n", "self", ".", "mem_dim", "=", "mem_dim", "\n", "self", ".", "linear_v", "=", "nn", ".", "Linear", "(", "visual_dim", ",", "self", ".", "mem_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_q", "=", "nn", ".", "Linear", "(", "text_dim", ",", "self", ".", "mem_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_his1", "=", "nn", ".", "Linear", "(", "his_dim", ",", "self", ".", "mem_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_his2", "=", "nn", ".", "Linear", "(", "his_dim", ",", "self", ".", "mem_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_att", "=", "nn", ".", "Linear", "(", "self", ".", "mem_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "_init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttentionHis._init_weight": [[124, 130], ["torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_"], "methods", ["None"], ["", "def", "_init_weight", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_v", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_q", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_his1", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_his2", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear_att", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.TempAttentionHis.forward": [[132, 162], ["vid_outputs.size", "Attention.TempAttentionHis.linear_v", "vid_outputs_trans.view.view.view", "Attention.TempAttentionHis.linear_q", "qns_embed_trans.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "Attention.TempAttentionHis.linear_his1", "his_trans.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "Attention.TempAttentionHis.linear_att", "Attention.TempAttentionHis.view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "vid_outputs.contiguous().view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "Attention.TempAttentionHis.linear_his2", "qns_embed_trans.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "his_trans.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "vid_outputs.contiguous", "torch.softmax.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "qns_embed", ",", "vid_outputs", ",", "his", ")", ":", "\n", "        ", "\"\"\"\n        :param qns_embed: batch_size x 1024\n        :param vid_outputs: batch_size x seq_num x feat_dim\n        :param his: batch_size x 512\n        :return:\n        \"\"\"", "\n", "\n", "batch_size", ",", "seq_len", ",", "feat_dim", "=", "vid_outputs", ".", "size", "(", ")", "\n", "vid_outputs_trans", "=", "self", ".", "linear_v", "(", "vid_outputs", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "seq_len", ",", "feat_dim", ")", ")", "\n", "vid_outputs_trans", "=", "vid_outputs_trans", ".", "view", "(", "batch_size", ",", "seq_len", ",", "self", ".", "mem_dim", ")", "\n", "\n", "qns_embed_trans", "=", "self", ".", "linear_q", "(", "qns_embed", ")", "\n", "qns_embed_trans", "=", "qns_embed_trans", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "seq_len", ",", "1", ")", "\n", "\n", "\n", "his_trans", "=", "self", ".", "linear_his1", "(", "his", ")", "\n", "his_trans", "=", "his_trans", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "seq_len", ",", "1", ")", "\n", "\n", "o", "=", "self", ".", "linear_att", "(", "torch", ".", "tanh", "(", "qns_embed_trans", "+", "vid_outputs_trans", "+", "his_trans", ")", ")", "\n", "\n", "e", "=", "o", ".", "view", "(", "batch_size", ",", "seq_len", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "e", ",", "dim", "=", "1", ")", "\n", "context", "=", "torch", ".", "bmm", "(", "beta", ".", "unsqueeze", "(", "1", ")", ",", "vid_outputs_trans", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "his_acc", "=", "torch", ".", "tanh", "(", "self", ".", "linear_his2", "(", "his", ")", ")", "\n", "\n", "context", "+=", "his_acc", "\n", "\n", "return", "context", ",", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.MultiModalAttentionModule.__init__": [[166, 200], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "Attention.MultiModalAttentionModule.init_weights", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", "=", "512", ",", "simple", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set the hyper-parameters and build the layers.\"\"\"", "\n", "super", "(", "MultiModalAttentionModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "simple", "=", "simple", "\n", "\n", "# alignment model", "\n", "# see appendices A.1.2 of neural machine translation", "\n", "\n", "self", ".", "Wav", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Wat", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Uav", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Uat", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Vav", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Vat", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bav", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bat", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "self", ".", "Whh", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Wvh", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Wth", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bh", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "self", ".", "video_sum_encoder", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "question_sum_encoder", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "Wb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Vbv", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Vbt", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bbv", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bbt", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "wb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.MultiModalAttentionModule.init_weights": [[201, 223], ["Attention.MultiModalAttentionModule.Wav.data.normal_", "Attention.MultiModalAttentionModule.Wat.data.normal_", "Attention.MultiModalAttentionModule.Uav.data.normal_", "Attention.MultiModalAttentionModule.Uat.data.normal_", "Attention.MultiModalAttentionModule.Vav.data.normal_", "Attention.MultiModalAttentionModule.Vat.data.normal_", "Attention.MultiModalAttentionModule.bav.data.fill_", "Attention.MultiModalAttentionModule.bat.data.fill_", "Attention.MultiModalAttentionModule.Whh.data.normal_", "Attention.MultiModalAttentionModule.Wvh.data.normal_", "Attention.MultiModalAttentionModule.Wth.data.normal_", "Attention.MultiModalAttentionModule.bh.data.fill_", "Attention.MultiModalAttentionModule.Wb.data.normal_", "Attention.MultiModalAttentionModule.Vbv.data.normal_", "Attention.MultiModalAttentionModule.Vbt.data.normal_", "Attention.MultiModalAttentionModule.wb.data.normal_", "Attention.MultiModalAttentionModule.bbv.data.fill_", "Attention.MultiModalAttentionModule.bbt.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "Wav", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Wat", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Uav", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Uat", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Vav", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Vat", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "bav", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "bat", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "self", ".", "Whh", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Wvh", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Wth", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "bh", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "self", ".", "Wb", ".", "data", ".", "normal_", "(", "0.0", ",", "0.01", ")", "\n", "self", ".", "Vbv", ".", "data", ".", "normal_", "(", "0.0", ",", "0.01", ")", "\n", "self", ".", "Vbt", ".", "data", ".", "normal_", "(", "0.0", ",", "0.01", ")", "\n", "self", ".", "wb", ".", "data", ".", "normal_", "(", "0.0", ",", "0.01", ")", "\n", "\n", "self", ".", "bbv", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "bbt", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.Attention.MultiModalAttentionModule.forward": [[224, 275], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Uhv.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Uht.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "att_vec_v.view.view.view", "att_vec_t.view.view.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "Attention.MultiModalAttentionModule.video_sum_encoder", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "Attention.MultiModalAttentionModule.question_sum_encoder", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "output.view.view.view", "Uhv.view.view.size", "Uhv.view.view.size", "Uht.view.view.size", "Uht.view.view.size", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "att_vec_v.view.view.size", "att_vec_v.view.view.size", "att_vec_t.view.view.size", "att_vec_t.view.view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.view.view.size", "output.view.view.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "hidden_frames", ",", "hidden_text", ",", "inv_attention", "=", "False", ")", ":", "\n", "# print self.Uav", "\n", "# hidden_text:  1 x T1 x 1024 (looks like a two layer one-directional LSTM, combining each layer's hidden)", "\n", "# hidden_frame: 1 x T2 x 1024 (from video encoder output, 1024 is similar from above)", "\n", "\n", "# print hidden_frames.size(),hidden_text.size()", "\n", "        ", "Uhv", "=", "torch", ".", "matmul", "(", "h", ",", "self", ".", "Uav", ")", "# (1,512)", "\n", "Uhv", "=", "Uhv", ".", "view", "(", "Uhv", ".", "size", "(", "0", ")", ",", "1", ",", "Uhv", ".", "size", "(", "1", ")", ")", "# (1,1,512)", "\n", "\n", "Uht", "=", "torch", ".", "matmul", "(", "h", ",", "self", ".", "Uat", ")", "# (1,512)", "\n", "Uht", "=", "Uht", ".", "view", "(", "Uht", ".", "size", "(", "0", ")", ",", "1", ",", "Uht", ".", "size", "(", "1", ")", ")", "# (1,1,512)", "\n", "\n", "# print Uhv.size(),Uht.size()", "\n", "\n", "Wsv", "=", "torch", ".", "matmul", "(", "hidden_frames", ",", "self", ".", "Wav", ")", "# (1,T,512)", "\n", "# print Wsv.size()", "\n", "att_vec_v", "=", "torch", ".", "matmul", "(", "torch", ".", "tanh", "(", "Wsv", "+", "Uhv", "+", "self", ".", "bav", ")", ",", "self", ".", "Vav", ")", "\n", "\n", "Wst", "=", "torch", ".", "matmul", "(", "hidden_text", ",", "self", ".", "Wat", ")", "# (1,T,512)", "\n", "att_vec_t", "=", "torch", ".", "matmul", "(", "torch", ".", "tanh", "(", "Wst", "+", "Uht", "+", "self", ".", "bat", ")", ",", "self", ".", "Vat", ")", "\n", "\n", "if", "inv_attention", "==", "True", ":", "\n", "            ", "att_vec_v", "=", "-", "att_vec_v", "\n", "att_vec_t", "=", "-", "att_vec_t", "\n", "\n", "", "att_vec_v", "=", "torch", ".", "softmax", "(", "att_vec_v", ",", "dim", "=", "1", ")", "\n", "att_vec_t", "=", "torch", ".", "softmax", "(", "att_vec_t", ",", "dim", "=", "1", ")", "\n", "\n", "att_vec_v", "=", "att_vec_v", ".", "view", "(", "att_vec_v", ".", "size", "(", "0", ")", ",", "att_vec_v", ".", "size", "(", "1", ")", ",", "1", ")", "# expand att_vec from 1xT to 1xTx1", "\n", "att_vec_t", "=", "att_vec_t", ".", "view", "(", "att_vec_t", ".", "size", "(", "0", ")", ",", "att_vec_t", ".", "size", "(", "1", ")", ",", "1", ")", "# expand att_vec from 1xT to 1xTx1", "\n", "\n", "hv_weighted", "=", "att_vec_v", "*", "hidden_frames", "\n", "hv_sum", "=", "torch", ".", "sum", "(", "hv_weighted", ",", "dim", "=", "1", ")", "\n", "hv_sum2", "=", "self", ".", "video_sum_encoder", "(", "hv_sum", ")", "\n", "\n", "ht_weighted", "=", "att_vec_t", "*", "hidden_text", "\n", "ht_sum", "=", "torch", ".", "sum", "(", "ht_weighted", ",", "dim", "=", "1", ")", "\n", "ht_sum2", "=", "self", ".", "question_sum_encoder", "(", "ht_sum", ")", "\n", "\n", "Wbs", "=", "torch", ".", "matmul", "(", "h", ",", "self", ".", "Wb", ")", "\n", "mt1", "=", "torch", ".", "matmul", "(", "ht_sum", ",", "self", ".", "Vbt", ")", "+", "self", ".", "bbt", "+", "Wbs", "\n", "mv1", "=", "torch", ".", "matmul", "(", "hv_sum", ",", "self", ".", "Vbv", ")", "+", "self", ".", "bbv", "+", "Wbs", "\n", "mtv", "=", "torch", ".", "tanh", "(", "torch", ".", "cat", "(", "[", "mv1", ",", "mt1", "]", ",", "dim", "=", "0", ")", ")", "\n", "mtv2", "=", "torch", ".", "matmul", "(", "mtv", ",", "self", ".", "wb", ")", "\n", "beta", "=", "torch", ".", "softmax", "(", "mtv2", ",", "dim", "=", "0", ")", "\n", "\n", "output", "=", "torch", ".", "tanh", "(", "torch", ".", "matmul", "(", "h", ",", "self", ".", "Whh", ")", "+", "beta", "[", "0", "]", "*", "hv_sum2", "+", "\n", "beta", "[", "1", "]", "*", "ht_sum2", "+", "self", ".", "bh", ")", "\n", "output", "=", "output", ".", "view", "(", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "\n", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.GraphConvolution.__init__": [[43, 47], ["torch.nn.modules.module.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ")", ":", "\n", "        ", "super", "(", "GraphConvolution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "False", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "out_features", ",", "elementwise_affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.GraphConvolution.forward": [[48, 54], ["gcn.GraphConvolution.weight", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "gcn.GraphConvolution.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "adj", ")", ":", "\n", "# self.weight of shape (hidden_size, hidden_size)", "\n", "        ", "support", "=", "self", ".", "weight", "(", "input", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "adj", ",", "support", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.GraphAttention.__init__": [[61, 92], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "torch.Tensor().type", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "dropout", ",", "alpha", ",", "concat", "=", "True", ")", ":", "\n", "        ", "super", "(", "GraphAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "concat", "=", "concat", "\n", "\n", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "\n", "torch", ".", "Tensor", "(", "in_features", ",", "out_features", ")", ".", "type", "(", "\n", "torch", ".", "cuda", ".", "FloatTensor", "if", "torch", ".", "cuda", ".", "is_available", "(", "\n", ")", "else", "torch", ".", "FloatTensor", ")", ",", "\n", "gain", "=", "np", ".", "sqrt", "(", "2.0", ")", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "a1", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "\n", "torch", ".", "Tensor", "(", "out_features", ",", "1", ")", ".", "type", "(", "\n", "torch", ".", "cuda", ".", "FloatTensor", "if", "torch", ".", "cuda", ".", "is_available", "(", "\n", ")", "else", "torch", ".", "FloatTensor", ")", ",", "\n", "gain", "=", "np", ".", "sqrt", "(", "2.0", ")", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "a2", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "\n", "torch", ".", "Tensor", "(", "out_features", ",", "1", ")", ".", "type", "(", "\n", "torch", ".", "cuda", ".", "FloatTensor", "if", "torch", ".", "cuda", ".", "is_available", "(", "\n", ")", "else", "torch", ".", "FloatTensor", ")", ",", "\n", "gain", "=", "np", ".", "sqrt", "(", "2.0", ")", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "\n", "self", ".", "leakyrelu", "=", "nn", ".", "LeakyReLU", "(", "self", ".", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.GraphAttention.forward": [[93, 111], ["torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "gcn.GraphAttention.leakyrelu", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.mm.size", "torch.mm.size", "torch.mm.size", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.elu", "torch.elu", "torch.elu", "torch.matmul.transpose", "torch.matmul.transpose", "torch.matmul.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "adj", ")", ":", "\n", "        ", "h", "=", "torch", ".", "mm", "(", "input", ",", "self", ".", "W", ")", "\n", "N", "=", "h", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "f_1", "=", "torch", ".", "matmul", "(", "h", ",", "self", ".", "a1", ")", "\n", "f_2", "=", "torch", ".", "matmul", "(", "h", ",", "self", ".", "a2", ")", "\n", "e", "=", "self", ".", "leakyrelu", "(", "f_1", "+", "f_2", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n", "zero_vec", "=", "-", "9e15", "*", "torch", ".", "ones_like", "(", "e", ")", "\n", "attention", "=", "torch", ".", "where", "(", "adj", ">", "0", ",", "e", ",", "zero_vec", ")", "\n", "attention", "=", "F", ".", "softmax", "(", "attention", ",", "dim", "=", "1", ")", "\n", "attention", "=", "F", ".", "dropout", "(", "attention", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "h_prime", "=", "torch", ".", "matmul", "(", "attention", ",", "h", ")", "\n", "\n", "if", "self", ".", "concat", ":", "\n", "            ", "return", "F", ".", "elu", "(", "h_prime", ")", "\n", "", "else", ":", "\n", "            ", "return", "h_prime", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.GCN.__init__": [[115, 125], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "gcn.GCN.layers.append", "range", "gcn.GCN.layers.append", "torch.Dropout", "torch.Dropout", "torch.Dropout", "gcn.GraphConvolution", "gcn.GCN.layers.append", "gcn.GraphConvolution", "gcn.GraphConvolution"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "input_size", ",", "hidden_size", ",", "num_classes", ",", "num_layers", "=", "1", ",", "\n", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "GCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layers", ".", "append", "(", "GraphConvolution", "(", "input_size", ",", "hidden_size", ")", ")", "\n", "for", "i", "in", "range", "(", "num_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "GraphConvolution", "(", "hidden_size", ",", "hidden_size", ")", ")", "\n", "", "self", ".", "layers", ".", "append", "(", "GraphConvolution", "(", "hidden_size", ",", "num_classes", ")", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.GCN.forward": [[126, 132], ["enumerate", "gcn.GCN.dropout", "torch.relu", "torch.relu", "torch.relu", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "adj", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "F", ".", "relu", "(", "layer", "(", "x", ",", "adj", ")", ")", ")", "\n", "\n", "# x of shape (bs, q_v_len, num_classes)", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.AdjLearner.__init__": [[136, 153], ["torch.nn.modules.module.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_feature_dim", ",", "hidden_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "'''\n        ## Variables:\n        - in_feature_dim: dimensionality of input features\n        - hidden_size: dimensionality of the joint hidden embedding\n        - K: number of graph nodes/objects on the image\n        '''", "\n", "\n", "# Embedding layers. Padded 0 => 0", "\n", "self", ".", "edge_layer_1", "=", "nn", ".", "Linear", "(", "in_feature_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "edge_layer_2", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "\n", "# Regularisation", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "edge_layer_1", "=", "nn", ".", "utils", ".", "weight_norm", "(", "self", ".", "edge_layer_1", ")", "\n", "self", ".", "edge_layer_2", "=", "nn", ".", "utils", ".", "weight_norm", "(", "self", ".", "edge_layer_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.AdjLearner.forward": [[154, 177], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gcn.AdjLearner.edge_layer_1", "torch.relu", "torch.relu", "torch.relu", "gcn.AdjLearner.edge_layer_2", "torch.relu", "torch.relu", "torch.relu", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.relu.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "questions", ",", "videos", ")", ":", "\n", "        ", "'''\n        ## Inputs:\n        ## Returns:\n        - adjacency matrix (batch_size, q_v_len, q_v_len)\n        '''", "\n", "# graph_nodes (batch_size, q_v_len, in_feat_dim): input features", "\n", "graph_nodes", "=", "torch", ".", "cat", "(", "(", "questions", ",", "videos", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# layer 1", "\n", "h", "=", "self", ".", "edge_layer_1", "(", "graph_nodes", ")", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "\n", "# layer 2", "\n", "h", "=", "self", ".", "edge_layer_2", "(", "h", ")", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "# h * sigmoid(Wh)", "\n", "# h = F.tanh(h)", "\n", "\n", "# outer product", "\n", "adjacency_matrix", "=", "torch", ".", "bmm", "(", "h", ",", "h", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "return", "adjacency_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.EvoAdjLearner.__init__": [[181, 200], ["torch.nn.modules.module.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_feature_dim", ",", "hidden_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "'''\n        ## Variables:\n        - in_feature_dim: dimensionality of input features\n        - hidden_size: dimensionality of the joint hidden embedding\n        - K: number of graph nodes/objects on the image\n        '''", "\n", "\n", "# Embedding layers. Padded 0 => 0", "\n", "self", ".", "edge_layer_1", "=", "nn", ".", "Linear", "(", "in_feature_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "edge_layer_2", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "edge_layer_3", "=", "nn", ".", "Linear", "(", "in_feature_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "edge_layer_4", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "\n", "# Regularisation", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "edge_layer_1", "=", "nn", ".", "utils", ".", "weight_norm", "(", "self", ".", "edge_layer_1", ")", "\n", "self", ".", "edge_layer_2", "=", "nn", ".", "utils", ".", "weight_norm", "(", "self", ".", "edge_layer_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.EvoAdjLearner.forward": [[201, 236], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gcn.padding_mask_k", "gcn.padding_mask_q", "gcn.EvoAdjLearner.edge_layer_1", "torch.relu", "torch.relu", "torch.relu", "gcn.EvoAdjLearner.edge_layer_2", "gcn.EvoAdjLearner.edge_layer_3", "torch.relu", "torch.relu", "torch.relu", "gcn.EvoAdjLearner.edge_layer_4", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "gcn.EvoAdjLearner.transpose"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q"], ["", "def", "forward", "(", "self", ",", "questions", ",", "videos", ")", ":", "\n", "        ", "'''\n        ## Inputs:\n        ## Returns:\n        - adjacency matrix (batch_size, q_v_len, q_v_len)\n        '''", "\n", "# graph_nodes (batch_size, q_v_len, in_feat_dim): input features", "\n", "graph_nodes", "=", "torch", ".", "cat", "(", "(", "questions", ",", "videos", ")", ",", "dim", "=", "1", ")", "\n", "\n", "attn_mask", "=", "padding_mask_k", "(", "graph_nodes", ",", "graph_nodes", ")", "\n", "sf_mask", "=", "padding_mask_q", "(", "graph_nodes", ",", "graph_nodes", ")", "\n", "\n", "# layer 1", "\n", "h", "=", "self", ".", "edge_layer_1", "(", "graph_nodes", ")", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "# layer 2", "\n", "h", "=", "self", ".", "edge_layer_2", "(", "h", ")", "\n", "# h = F.relu(h)", "\n", "\n", "# layer 1", "\n", "h_", "=", "self", ".", "edge_layer_3", "(", "graph_nodes", ")", "\n", "h_", "=", "F", ".", "relu", "(", "h_", ")", "\n", "# layer 2", "\n", "h_", "=", "self", ".", "edge_layer_4", "(", "h_", ")", "\n", "# h_ = F.relu(h_)", "\n", "\n", "# outer product", "\n", "adjacency_matrix", "=", "torch", ".", "bmm", "(", "h", ",", "h_", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "# adjacency_matrix = adjacency_matrix.masked_fill(attn_mask, -np.inf)", "\n", "\n", "# softmaxed_adj = F.softmax(adjacency_matrix, dim=-1)", "\n", "\n", "# softmaxed_adj = softmaxed_adj.masked_fill(sf_mask, 0.)", "\n", "\n", "return", "adjacency_matrix", "", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_k": [[10, 22], ["torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.bmm", "torch.bmm", "torch.bmm", "pad_mask.eq.eq", "seq_k.transpose"], "function", ["None"], ["def", "padding_mask_k", "(", "seq_q", ",", "seq_k", ")", ":", "\n", "    ", "\"\"\" seq_k of shape (batch, k_len, k_feat) and seq_q (batch, q_len, q_feat). q and k are padded with 0. pad_mask is (batch, q_len, k_len).\n    In batch 0:\n    [[x x x 0]     [[0 0 0 1]\n     [x x x 0]->    [0 0 0 1]\n     [x x x 0]]     [0 0 0 1]] uint8\n    \"\"\"", "\n", "fake_q", "=", "torch", ".", "ones_like", "(", "seq_q", ")", "\n", "pad_mask", "=", "torch", ".", "bmm", "(", "fake_q", ",", "seq_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "pad_mask", "=", "pad_mask", ".", "eq", "(", "0", ")", "\n", "# pad_mask = pad_mask.lt(1e-3)", "\n", "return", "pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.gcn.padding_mask_q": [[24, 36], ["torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.bmm", "torch.bmm", "torch.bmm", "pad_mask.eq.eq", "torch.ones_like.transpose"], "function", ["None"], ["", "def", "padding_mask_q", "(", "seq_q", ",", "seq_k", ")", ":", "\n", "    ", "\"\"\" seq_k of shape (batch, k_len, k_feat) and seq_q (batch, q_len, q_feat). q and k are padded with 0. pad_mask is (batch, q_len, k_len).\n    In batch 0:\n    [[x x x x]      [[0 0 0 0]\n     [x x x x]  ->   [0 0 0 0]\n     [0 0 0 0]]      [1 1 1 1]] uint8\n    \"\"\"", "\n", "fake_k", "=", "torch", ".", "ones_like", "(", "seq_k", ")", "\n", "pad_mask", "=", "torch", ".", "bmm", "(", "seq_q", ",", "fake_k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "pad_mask", "=", "pad_mask", ".", "eq", "(", "0", ")", "\n", "# pad_mask = pad_mask.lt(1e-3)", "\n", "return", "pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MemoryRamModule.__init__": [[8, 32], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "memory_rand.MemoryRamModule.init_weights", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "input_size", "=", "1024", ",", "hidden_size", "=", "512", ",", "memory_bank_size", "=", "100", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"Set the hyper-parameters and build the layers.\"\"\"", "\n", "super", "(", "MemoryRamModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "memory_bank_size", "=", "memory_bank_size", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "hidden_to_content", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", "\n", "#self.read_to_hidden = nn.Linear(hidden_size+input_size, 1)  ", "\n", "self", ".", "write_gate", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "1", ")", "\n", "self", ".", "write_prob", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "memory_bank_size", ")", "\n", "\n", "self", ".", "read_gate", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "1", ")", "\n", "self", ".", "read_prob", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "memory_bank_size", ")", "\n", "\n", "\n", "self", ".", "Wxh", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "input_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Wrh", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "Whh", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bh", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "hidden_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MemoryRamModule.init_weights": [[34, 39], ["memory_rand.MemoryRamModule.Wxh.data.normal_", "memory_rand.MemoryRamModule.Wrh.data.normal_", "memory_rand.MemoryRamModule.Whh.data.normal_", "memory_rand.MemoryRamModule.bh.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "Wxh", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Wrh", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "Whh", ".", "data", ".", "normal_", "(", "0.0", ",", "0.1", ")", "\n", "self", ".", "bh", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MemoryRamModule.forward": [[41, 81], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to.fill_", "torch.FloatTensor().to.fill_", "torch.FloatTensor().to.fill_", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "aw.view.view.view", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "memory_rand.MemoryRamModule.read_prob", "memory_rand.MemoryRamModule.read_gate", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "memory_rand.MemoryRamModule.hidden_to_content", "memory_rand.MemoryRamModule.write_prob", "memory_rand.MemoryRamModule.write_gate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_frames", ",", "nImg", ")", ":", "\n", "\n", "        ", "memory_ram", "=", "torch", ".", "FloatTensor", "(", "self", ".", "memory_bank_size", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "memory_ram", ".", "fill_", "(", "0", ")", "\n", "\n", "h_t", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "hiddens", "=", "torch", ".", "FloatTensor", "(", "nImg", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "t", "in", "range", "(", "nImg", ")", ":", "\n", "            ", "x_t", "=", "hidden_frames", "[", "t", ":", "t", "+", "1", ",", ":", "]", "\n", "\n", "x_h_t", "=", "torch", ".", "cat", "(", "[", "x_t", ",", "h_t", "]", ",", "dim", "=", "1", ")", "\n", "\n", "############# read ############", "\n", "ar", "=", "torch", ".", "softmax", "(", "self", ".", "read_prob", "(", "x_h_t", ")", ",", "dim", "=", "1", ")", "# read prob from memories", "\n", "go", "=", "torch", ".", "sigmoid", "(", "self", ".", "read_gate", "(", "x_h_t", ")", ")", "# read gate", "\n", "r", "=", "go", "*", "torch", ".", "matmul", "(", "ar", ",", "memory_ram", ")", "# read vector", "\n", "\n", "######### h_t #########", "\n", "# Eq (17)", "\n", "m1", "=", "torch", ".", "matmul", "(", "x_t", ",", "self", ".", "Wxh", ")", "\n", "m2", "=", "torch", ".", "matmul", "(", "r", ",", "self", ".", "Wrh", ")", "\n", "m3", "=", "torch", ".", "matmul", "(", "h_t", ",", "self", ".", "Whh", ")", "\n", "h_t_p1", "=", "F", ".", "relu", "(", "m1", "+", "m2", "+", "m3", "+", "self", ".", "bh", ")", "# Eq(17)", "\n", "\n", "\n", "############# write ############            ", "\n", "c_t", "=", "F", ".", "relu", "(", "self", ".", "hidden_to_content", "(", "x_h_t", ")", ")", "# Eq(15), content vector", "\n", "aw", "=", "torch", ".", "softmax", "(", "self", ".", "write_prob", "(", "x_h_t", ")", ",", "dim", "=", "1", ")", "# write prob to memories", "\n", "aw", "=", "aw", ".", "view", "(", "self", ".", "memory_bank_size", ",", "1", ")", "\n", "gw", "=", "torch", ".", "sigmoid", "(", "self", ".", "write_gate", "(", "x_h_t", ")", ")", "# write gate", "\n", "#print gw.size(),aw.size(),c_t.size(),memory_ram.size()", "\n", "memory_ram", "=", "gw", "*", "aw", "*", "c_t", "+", "(", "1.0", "-", "aw", ")", "*", "memory_ram", "# Eq(16)", "\n", "\n", "h_t", "=", "h_t_p1", "\n", "hiddens", "[", "t", ",", ":", "]", "=", "h_t", "\n", "\n", "#return memory_ram", "\n", "", "return", "hiddens", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MemoryRamTwoStreamModule.__init__": [[85, 107], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "memory_rand.MemoryRamTwoStreamModule.init_weights"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", "=", "512", ",", "memory_bank_size", "=", "100", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"Set the hyper-parameters and build the layers.\"\"\"", "\n", "super", "(", "MemoryRamTwoStreamModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "memory_bank_size", "=", "memory_bank_size", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "hidden_to_content_a", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "hidden_to_content_m", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "write_prob", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "3", ",", "3", ")", "\n", "self", ".", "write_prob_a", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "memory_bank_size", ")", "\n", "self", ".", "write_prob_m", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "memory_bank_size", ")", "\n", "\n", "self", ".", "read_prob", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "3", ",", "memory_bank_size", ")", "\n", "\n", "self", ".", "read_to_hidden", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "hidden_size", ")", "\n", "self", ".", "read_to_hidden_a", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", "+", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "read_to_hidden_m", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", "+", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MemoryRamTwoStreamModule.init_weights": [[108, 110], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MemoryRamTwoStreamModule.forward": [[112, 176], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to.fill_", "torch.FloatTensor().to.fill_", "torch.FloatTensor().to.fill_", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "aw_a.view.view.view", "aw_m.view.view.view", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "memory_rand.MemoryRamTwoStreamModule.read_prob", "memory_rand.MemoryRamTwoStreamModule.read_to_hidden", "memory_rand.MemoryRamTwoStreamModule.read_to_hidden_a", "memory_rand.MemoryRamTwoStreamModule.read_to_hidden_m", "memory_rand.MemoryRamTwoStreamModule.write_prob", "memory_rand.MemoryRamTwoStreamModule.hidden_to_content_a", "memory_rand.MemoryRamTwoStreamModule.hidden_to_content_m", "memory_rand.MemoryRamTwoStreamModule.write_prob_a", "memory_rand.MemoryRamTwoStreamModule.write_prob_m"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_out_a", ",", "hidden_out_m", ",", "nImg", ")", ":", "\n", "\n", "\n", "        ", "memory_ram", "=", "torch", ".", "FloatTensor", "(", "self", ".", "memory_bank_size", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "memory_ram", ".", "fill_", "(", "0", ")", "\n", "\n", "h_t_a", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "h_t_m", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "h_t", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "hiddens", "=", "torch", ".", "FloatTensor", "(", "nImg", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "t", "in", "range", "(", "nImg", ")", ":", "\n", "            ", "x_t_a", "=", "hidden_out_a", "[", "t", ":", "t", "+", "1", ",", ":", "]", "\n", "x_t_m", "=", "hidden_out_m", "[", "t", ":", "t", "+", "1", ",", ":", "]", "\n", "\n", "\n", "############# read ############", "\n", "x_h_t_am", "=", "torch", ".", "cat", "(", "[", "h_t_a", ",", "h_t_m", ",", "h_t", "]", ",", "dim", "=", "1", ")", "\n", "ar", "=", "torch", ".", "softmax", "(", "self", ".", "read_prob", "(", "x_h_t_am", ")", ",", "dim", "=", "1", ")", "# read prob from memories", "\n", "r", "=", "torch", ".", "matmul", "(", "ar", ",", "memory_ram", ")", "# read vector", "\n", "\n", "\n", "######### h_t #########", "\n", "# Eq (17)", "\n", "f_0", "=", "torch", ".", "cat", "(", "[", "r", ",", "h_t", "]", ",", "dim", "=", "1", ")", "\n", "f_a", "=", "torch", ".", "cat", "(", "[", "x_t_a", ",", "r", ",", "h_t_a", "]", ",", "dim", "=", "1", ")", "\n", "f_m", "=", "torch", ".", "cat", "(", "[", "x_t_m", ",", "r", ",", "h_t_m", "]", ",", "dim", "=", "1", ")", "\n", "\n", "h_t_1", "=", "F", ".", "relu", "(", "self", ".", "read_to_hidden", "(", "f_0", ")", ")", "\n", "h_t_a1", "=", "F", ".", "relu", "(", "self", ".", "read_to_hidden_a", "(", "f_a", ")", ")", "\n", "h_t_m1", "=", "F", ".", "relu", "(", "self", ".", "read_to_hidden_m", "(", "f_m", ")", ")", "\n", "\n", "\n", "############# write ############            ", "\n", "\n", "# write probability of [keep, write appearance, write motion]", "\n", "aw", "=", "torch", ".", "softmax", "(", "self", ".", "write_prob", "(", "x_h_t_am", ")", ",", "dim", "=", "1", ")", "# write prob to memories", "\n", "x_h_ta", "=", "torch", ".", "cat", "(", "[", "h_t_a", ",", "x_t_a", "]", ",", "dim", "=", "1", ")", "\n", "x_h_tm", "=", "torch", ".", "cat", "(", "[", "h_t_m", ",", "x_t_m", "]", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "# write content", "\n", "c_t_a", "=", "F", ".", "relu", "(", "self", ".", "hidden_to_content_a", "(", "x_h_ta", ")", ")", "# Eq(15), content vector", "\n", "c_t_m", "=", "F", ".", "relu", "(", "self", ".", "hidden_to_content_m", "(", "x_h_tm", ")", ")", "# Eq(15), content vector", "\n", "\n", "aw_a", "=", "torch", ".", "softmax", "(", "self", ".", "write_prob_a", "(", "x_h_ta", ")", ",", "dim", "=", "1", ")", "# write prob to memories", "\n", "aw_m", "=", "torch", ".", "softmax", "(", "self", ".", "write_prob_m", "(", "x_h_tm", ")", ",", "dim", "=", "1", ")", "# write prob to memories", "\n", "\n", "\n", "aw_a", "=", "aw_a", ".", "view", "(", "self", ".", "memory_bank_size", ",", "1", ")", "\n", "aw_m", "=", "aw_m", ".", "view", "(", "self", ".", "memory_bank_size", ",", "1", ")", "\n", "\n", "memory_ram", "=", "aw", "[", "0", ",", "0", "]", "*", "memory_ram", "+", "aw", "[", "0", ",", "1", "]", "*", "aw_a", "*", "c_t_a", "+", "aw", "[", "0", ",", "2", "]", "*", "aw_m", "*", "c_t_m", "\n", "\n", "\n", "h_t", "=", "h_t_1", "\n", "h_t_a", "=", "h_t_a1", "\n", "h_t_m", "=", "h_t_m1", "\n", "\n", "hiddens", "[", "t", ",", ":", "]", "=", "h_t", "\n", "\n", "\n", "", "return", "hiddens", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MMModule.__init__": [[178, 190], ["torch.Module.__init__", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "Attention.MultiModalAttentionModule", "memory_rand.MMModule.init_weights"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__", "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "input_drop_p", ",", "device", ")", ":", "\n", "        ", "\"\"\"Set the hyper-parameters and build the layers.\"\"\"", "\n", "super", "(", "MMModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "dim", "\n", "self", ".", "lstm_mm_1", "=", "nn", ".", "LSTMCell", "(", "dim", ",", "dim", ")", "\n", "self", ".", "lstm_mm_2", "=", "nn", ".", "LSTMCell", "(", "dim", ",", "dim", ")", "\n", "self", ".", "hidden_encoder_1", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ")", "\n", "self", ".", "hidden_encoder_2", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "input_drop_p", ")", "\n", "self", ".", "mm_att", "=", "MultiModalAttentionModule", "(", "dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MMModule.init_weights": [[192, 196], ["torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "memory_rand.MMModule.init_hiddens"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MMModule.init_hiddens"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "hidden_encoder_1", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "hidden_encoder_2", ".", "weight", ")", "\n", "self", ".", "init_hiddens", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MMModule.init_hiddens": [[197, 203], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hiddens", "(", "self", ")", ":", "\n", "        ", "s_t", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "s_t2", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "c_t", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "c_t2", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "s_t", ",", "s_t2", ",", "c_t", ",", "c_t2", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MMModule.forward": [[204, 228], ["memory_rand.MMModule.init_hiddens", "memory_rand.MMModule.dropout", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "memory_rand.MMModule.lstm_mm_1", "memory_rand.MMModule.lstm_mm_2", "memory_rand.MMModule.mm_att", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "memory_rand.MMModule.dropout", "memory_rand.MMModule.hidden_encoder_1", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "memory_rand.MMModule.hidden_encoder_2"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_rand.MMModule.init_hiddens"], ["", "def", "forward", "(", "self", ",", "svt_tmp", ",", "memory_ram_vid", ",", "memory_ram_txt", ",", "loop", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n\n        :param svt_tmp:\n        :param memory_ram_vid:\n        :param memory_ram_txt:\n        :param loop:\n        :return:\n        \"\"\"", "\n", "\n", "sm_q1", ",", "sm_q2", ",", "cm_q1", ",", "cm_q2", "=", "self", ".", "init_hiddens", "(", ")", "\n", "mm_oo", "=", "self", ".", "dropout", "(", "torch", ".", "tanh", "(", "self", ".", "hidden_encoder_1", "(", "svt_tmp", ")", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "loop", ")", ":", "\n", "            ", "sm_q1", ",", "cm_q1", "=", "self", ".", "lstm_mm_1", "(", "mm_oo", ",", "(", "sm_q1", ",", "cm_q1", ")", ")", "\n", "sm_q2", ",", "cm_q2", "=", "self", ".", "lstm_mm_2", "(", "sm_q1", ",", "(", "sm_q2", ",", "cm_q2", ")", ")", "\n", "\n", "mm_o1", "=", "self", ".", "mm_att", "(", "sm_q2", ",", "memory_ram_vid", ",", "memory_ram_txt", ")", "\n", "mm_o2", "=", "torch", ".", "cat", "(", "(", "sm_q2", ",", "mm_o1", ")", ",", "dim", "=", "1", ")", "\n", "mm_oo", "=", "self", ".", "dropout", "(", "torch", ".", "tanh", "(", "self", ".", "hidden_encoder_2", "(", "mm_o2", ")", ")", ")", "\n", "\n", "", "smq", "=", "torch", ".", "cat", "(", "(", "sm_q1", ",", "sm_q2", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "smq", "", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.AttentionGRUCell.__init__": [[13, 20], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "AttentionGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "Wr", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "Ur", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "U", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.AttentionGRUCell.init_weights": [[21, 30], ["memory_module.AttentionGRUCell.Wr.weight.data.normal_", "memory_module.AttentionGRUCell.Wr.bias.data.fill_", "memory_module.AttentionGRUCell.Ur.weight.data.normal_", "memory_module.AttentionGRUCell.Ur.bias.data.fill_", "memory_module.AttentionGRUCell.W.weight.data.normal_", "memory_module.AttentionGRUCell.W.bias.data.fill_", "memory_module.AttentionGRUCell.U.weight.data.normal_", "memory_module.AttentionGRUCell.U.bias.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "Wr", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "self", ".", "Wr", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "Ur", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "self", ".", "Ur", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "W", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "self", ".", "W", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "U", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "self", ".", "U", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.AttentionGRUCell.forward": [[31, 45], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "g.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "memory_module.AttentionGRUCell.Wr", "memory_module.AttentionGRUCell.Ur", "memory_module.AttentionGRUCell.W", "g.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "memory_module.AttentionGRUCell.U"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "fact", ",", "C", ",", "g", ")", ":", "\n", "        ", "'''\n        fact.size() -> (#batch, #hidden = #embedding)\n        c.size() -> (#hidden, ) -> (#batch, #hidden = #embedding)\n        r.size() -> (#batch, #hidden = #embedding)\n        h_tilda.size() -> (#batch, #hidden = #embedding)\n        g.size() -> (#batch, )\n        '''", "\n", "\n", "r", "=", "torch", ".", "sigmoid", "(", "self", ".", "Wr", "(", "fact", ")", "+", "self", ".", "Ur", "(", "C", ")", ")", "\n", "h_tilda", "=", "torch", ".", "tanh", "(", "self", ".", "W", "(", "fact", ")", "+", "r", "*", "self", ".", "U", "(", "C", ")", ")", "\n", "g", "=", "g", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "h_tilda", ")", "\n", "h", "=", "g", "*", "h_tilda", "+", "(", "1", "-", "g", ")", "*", "C", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.AttentionGRU.__init__": [[51, 55], ["torch.Module.__init__", "memory_module.AttentionGRUCell"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "AttentionGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "AGRUCell", "=", "AttentionGRUCell", "(", "input_size", ",", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.AttentionGRU.init_weights": [[56, 58], ["memory_module.AttentionGRU.AGRUCell.init_weights"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.init_weights"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "AGRUCell", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.AttentionGRU.forward": [[59, 76], ["facts.size", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "memory_module.AttentionGRU.AGRUCell", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "C.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "C.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "facts", ",", "G", ")", ":", "\n", "        ", "'''\n        facts.size() -> (#batch, #sentence, #hidden = #embedding)\n        fact.size() -> (#batch, #hidden = #embedding)\n        G.size() -> (#batch, #sentence)\n        g.size() -> (#batch, )\n        C.size() -> (#batch, #hidden)\n        '''", "\n", "batch_num", ",", "sen_num", ",", "embedding_size", "=", "facts", ".", "size", "(", ")", "\n", "C", "=", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "hidden_size", ")", ")", ".", "cuda", "(", ")", "\n", "for", "sid", "in", "range", "(", "sen_num", ")", ":", "\n", "            ", "fact", "=", "facts", "[", ":", ",", "sid", ",", ":", "]", "\n", "g", "=", "G", "[", ":", ",", "sid", "]", "\n", "if", "sid", "==", "0", ":", "\n", "                ", "C", "=", "C", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "fact", ")", "\n", "", "C", "=", "self", ".", "AGRUCell", "(", "fact", ",", "C", ",", "g", ")", "\n", "", "return", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.__init__": [[82, 88], ["torch.Module.__init__", "memory_module.AttentionGRU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "EpisodicMemory", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "AGRU", "=", "AttentionGRU", "(", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "z1", "=", "nn", ".", "Linear", "(", "4", "*", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "z2", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "next_mem", "=", "nn", ".", "Linear", "(", "3", "*", "hidden_size", ",", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.init_weights": [[90, 98], ["memory_module.EpisodicMemory.z1.weight.data.normal_", "memory_module.EpisodicMemory.z1.bias.data.fill_", "memory_module.EpisodicMemory.z2.weight.data.normal_", "memory_module.EpisodicMemory.z2.bias.data.fill_", "memory_module.EpisodicMemory.next_mem.weight.data.normal_", "memory_module.EpisodicMemory.next_mem.bias.data.fill_", "memory_module.EpisodicMemory.AGRU.init_weights"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.init_weights"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "z1", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "self", ".", "z1", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "z2", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "self", ".", "z2", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "next_mem", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "self", ".", "next_mem", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "AGRU", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.make_interaction": [[100, 133], ["frames.size", "questions.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "z.view.view.view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "memory_module.EpisodicMemory.z2", "torch.softmax.view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "questions.view.view.size", "questions.view.view.size", "memory_module.EpisodicMemory.z1", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "make_interaction", "(", "self", ",", "frames", ",", "questions", ",", "prevM", ")", ":", "\n", "        ", "'''\n        frames.size() -> (#batch, T, #hidden = #embedding)\n        questions.size() -> (#batch, 1, #hidden)\n        prevM.size() -> (#batch, #sentence = 1, #hidden = #embedding)\n        z.size() -> (#batch, T, 4 x #embedding)\n        G.size() -> (#batch, T)\n        '''", "\n", "batch_num", ",", "T", ",", "embedding_size", "=", "frames", ".", "size", "(", ")", "\n", "questions", "=", "questions", ".", "view", "(", "questions", ".", "size", "(", "0", ")", ",", "1", ",", "questions", ".", "size", "(", "1", ")", ")", "\n", "\n", "\n", "#questions = questions.expand_as(frames)", "\n", "#prevM = prevM.expand_as(frames)", "\n", "\n", "#print(questions.size(),prevM.size())", "\n", "\n", "# Eq (8)~(10)", "\n", "z", "=", "torch", ".", "cat", "(", "[", "\n", "frames", "*", "questions", ",", "\n", "frames", "*", "prevM", ",", "\n", "torch", ".", "abs", "(", "frames", "-", "questions", ")", ",", "\n", "torch", ".", "abs", "(", "frames", "-", "prevM", ")", "\n", "]", ",", "dim", "=", "2", ")", "\n", "\n", "z", "=", "z", ".", "view", "(", "-", "1", ",", "4", "*", "embedding_size", ")", "\n", "\n", "G", "=", "torch", ".", "tanh", "(", "self", ".", "z1", "(", "z", ")", ")", "\n", "G", "=", "self", ".", "z2", "(", "G", ")", "\n", "G", "=", "G", ".", "view", "(", "batch_num", ",", "-", "1", ")", "\n", "G", "=", "F", ".", "softmax", "(", "G", ",", "dim", "=", "1", ")", "\n", "#print('G size',G.size())", "\n", "return", "G", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.forward": [[134, 160], ["memory_module.EpisodicMemory.make_interaction", "memory_module.EpisodicMemory.AGRU", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "next_mem.unsqueeze.unsqueeze.unsqueeze", "memory_module.EpisodicMemory.next_mem", "prevM.squeeze", "questions.squeeze"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.networks.memory_module.EpisodicMemory.make_interaction"], ["", "def", "forward", "(", "self", ",", "frames", ",", "questions", ",", "prevM", ")", ":", "\n", "        ", "'''\n        frames.size() -> (#batch, #sentence, #hidden = #embedding)\n        questions.size() -> (#batch, #sentence = 1, #hidden)\n        prevM.size() -> (#batch, #sentence = 1, #hidden = #embedding)\n        G.size() -> (#batch, #sentence)\n        C.size() -> (#batch, #hidden)\n        concat.size() -> (#batch, 3 x #embedding)\n        '''", "\n", "\n", "'''\n        section 3.3 - Attention based GRU\n        input: F and q, as frames and questions\n        then get gates g\n        then (c,m,g) feed into memory update module Eq(13)\n        output new memory state\n        '''", "\n", "# print(frames.shape, questions.shape, prevM.shape)", "\n", "\n", "G", "=", "self", ".", "make_interaction", "(", "frames", ",", "questions", ",", "prevM", ")", "\n", "C", "=", "self", ".", "AGRU", "(", "frames", ",", "G", ")", "\n", "concat", "=", "torch", ".", "cat", "(", "[", "prevM", ".", "squeeze", "(", "1", ")", ",", "C", ",", "questions", ".", "squeeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "next_mem", "=", "F", ".", "relu", "(", "self", ".", "next_mem", "(", "concat", ")", ")", "\n", "#print(next_mem.size())", "\n", "next_mem", "=", "next_mem", ".", "unsqueeze", "(", "1", ")", "\n", "return", "next_mem", "\n", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.CoMem.CoMem.__init__": [[9, 32], ["torch.Module.__init__", "memory_module.EpisodicMemory", "memory_module.EpisodicMemory", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vid_encoder", ",", "qns_encoder", ",", "max_len_v", ",", "max_len_q", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        motion-appearance co-memory networks for video question answering (CVPR18)\n        :param vid_encoder:\n        :param qns_encoder:\n        :param ans_decoder:\n        :param device:\n        \"\"\"", "\n", "super", "(", "CoMem", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vid_encoder", "=", "vid_encoder", "\n", "self", ".", "qns_encoder", "=", "qns_encoder", "\n", "\n", "dim", "=", "qns_encoder", ".", "dim_hidden", "\n", "\n", "self", ".", "epm_app", "=", "EpisodicMemory", "(", "dim", "*", "2", ")", "\n", "self", ".", "epm_mot", "=", "EpisodicMemory", "(", "dim", "*", "2", ")", "\n", "\n", "self", ".", "linear_ma", "=", "nn", ".", "Linear", "(", "dim", "*", "2", "*", "3", ",", "dim", "*", "2", ")", "\n", "self", ".", "linear_mb", "=", "nn", ".", "Linear", "(", "dim", "*", "2", "*", "3", ",", "dim", "*", "2", ")", "\n", "\n", "self", ".", "vq2word", "=", "nn", ".", "Linear", "(", "dim", "*", "2", "*", "2", ",", "1", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.CoMem.CoMem.forward": [[33, 60], ["qas_lengths.permute", "CoMem.CoMem.vid_encoder", "enumerate", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.max", "torch.max", "torch.max", "torch.max", "qas.permute", "qas.permute", "CoMem.CoMem.vq_encoder", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.vq_encoder"], ["", "def", "forward", "(", "self", ",", "vid_feats", ",", "qas", ",", "qas_lengths", ")", ":", "\n", "        ", "\"\"\"\n\n        :param vid_feats:\n        :param qns:\n        :param qns_lengths:\n        :param mode:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "qns_encoder", ".", "use_bert", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "# for BERT", "\n", "", "else", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "", "cand_len", "=", "qas_lengths", ".", "permute", "(", "1", ",", "0", ")", "\n", "outputs_app_l1", ",", "outputs_app_l2", ",", "outputs_motion_l1", ",", "outputs_motion_l2", "=", "self", ".", "vid_encoder", "(", "vid_feats", ")", "\n", "vid_feats", "=", "(", "outputs_app_l1", ",", "outputs_app_l2", ",", "outputs_motion_l1", ",", "outputs_motion_l2", ")", "\n", "out", "=", "[", "]", "\n", "for", "idx", ",", "qa", "in", "enumerate", "(", "cand_qas", ")", ":", "\n", "            ", "encoder_out", "=", "self", ".", "vq_encoder", "(", "vid_feats", ",", "qa", ",", "cand_len", "[", "idx", "]", ")", "\n", "out", ".", "append", "(", "encoder_out", ")", "\n", "\n", "", "out", "=", "torch", ".", "stack", "(", "out", ",", "0", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "_", ",", "predict_idx", "=", "torch", ".", "max", "(", "out", ",", "1", ")", "\n", "\n", "\n", "return", "out", ",", "predict_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.CoMem.CoMem.vq_encoder": [[61, 102], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "CoMem.CoMem.qns_encoder", "qns_output.size", "qns_hidden[].permute().contiguous().view", "CoMem.CoMem.unsqueeze", "CoMem.CoMem.unsqueeze", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "CoMem.CoMem.vq2word().squeeze", "CoMem.CoMem.detach", "CoMem.CoMem.detach", "CoMem.CoMem.epm_app", "CoMem.CoMem.epm_mot", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "qns_hidden[].permute().contiguous", "CoMem.CoMem.linear_ma", "CoMem.CoMem.linear_mb", "CoMem.CoMem.vq2word", "CoMem.CoMem.squeeze", "CoMem.CoMem.squeeze", "qns_hidden[].permute"], "methods", ["None"], ["", "def", "vq_encoder", "(", "self", ",", "vid_feats", ",", "qns", ",", "qns_lengths", ",", "iter_num", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Co-memory network\n        :param vid_feats:\n        :param qns:\n        :param qns_lengths:\n        :param ans:\n        :param ans_lengths:\n        :return:\n        \"\"\"", "\n", "\n", "outputs_app_l1", ",", "outputs_app_l2", ",", "outputs_motion_l1", ",", "outputs_motion_l2", "=", "vid_feats", "\n", "\n", "outputs_app", "=", "torch", ".", "cat", "(", "(", "outputs_app_l1", ",", "outputs_app_l2", ")", ",", "dim", "=", "-", "1", ")", "\n", "outputs_motion", "=", "torch", ".", "cat", "(", "(", "outputs_motion_l1", ",", "outputs_motion_l2", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "qns_output", ",", "qns_hidden", "=", "self", ".", "qns_encoder", "(", "qns", ",", "qns_lengths", ")", "\n", "\n", "# qns_output = qns_output.permute(1, 0, 2)", "\n", "batch_size", ",", "seq_len", ",", "qns_feat_dim", "=", "qns_output", ".", "size", "(", ")", "\n", "\n", "qns_embed", "=", "qns_hidden", "[", "0", "]", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "#(batch_size, feat_dim)", "\n", "\n", "m_app", "=", "outputs_app", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "m_mot", "=", "outputs_motion", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "ma", ",", "mb", "=", "m_app", ".", "detach", "(", ")", ",", "m_mot", ".", "detach", "(", ")", "\n", "m_app", "=", "m_app", ".", "unsqueeze", "(", "1", ")", "\n", "m_mot", "=", "m_mot", ".", "unsqueeze", "(", "1", ")", "\n", "for", "_", "in", "range", "(", "iter_num", ")", ":", "\n", "            ", "mm", "=", "ma", "+", "mb", "\n", "m_app", "=", "self", ".", "epm_app", "(", "outputs_app", ",", "mm", ",", "m_app", ")", "\n", "m_mot", "=", "self", ".", "epm_mot", "(", "outputs_motion", ",", "mm", ",", "m_mot", ")", "\n", "ma_q", "=", "torch", ".", "cat", "(", "(", "ma", ",", "m_app", ".", "squeeze", "(", "1", ")", ",", "qns_embed", ")", ",", "dim", "=", "1", ")", "\n", "mb_q", "=", "torch", ".", "cat", "(", "(", "mb", ",", "m_mot", ".", "squeeze", "(", "1", ")", ",", "qns_embed", ")", ",", "dim", "=", "1", ")", "\n", "ma", "=", "torch", ".", "tanh", "(", "self", ".", "linear_ma", "(", "ma_q", ")", ")", "\n", "mb", "=", "torch", ".", "tanh", "(", "self", ".", "linear_mb", "(", "mb_q", ")", ")", "\n", "\n", "", "mem", "=", "torch", ".", "cat", "(", "(", "ma", ",", "mb", ")", ",", "dim", "=", "1", ")", "\n", "outputs", "=", "self", ".", "vq2word", "(", "mem", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.EVQA.EVQA.__init__": [[6, 19], ["torch.Module.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vid_encoder", ",", "qns_encoder", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n\n        :param vid_encoder:\n        :param qns_encoder:\n        :param ans_decoder:\n        :param device:\n        \"\"\"", "\n", "super", "(", "EVQA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vid_encoder", "=", "vid_encoder", "\n", "self", ".", "qns_encoder", "=", "qns_encoder", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "FC", "=", "nn", ".", "Linear", "(", "qns_encoder", ".", "dim_hidden", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.EVQA.EVQA.forward": [[20, 45], ["qas_lengths.permute", "enumerate", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.max", "torch.max", "torch.max", "torch.max", "qas.permute", "qas.permute", "EVQA.EVQA.vq_encoder", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.vq_encoder"], ["", "def", "forward", "(", "self", ",", "vid_feats", ",", "qas", ",", "qas_lengths", ")", ":", "\n", "        ", "\"\"\"\n\n        :param vid_feats:\n        :param qns:\n        :param qns_lengths:\n        :param mode:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "qns_encoder", ".", "use_bert", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "# for BERT", "\n", "", "else", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "", "cand_len", "=", "qas_lengths", ".", "permute", "(", "1", ",", "0", ")", "\n", "out", "=", "[", "]", "\n", "for", "idx", ",", "qa", "in", "enumerate", "(", "cand_qas", ")", ":", "\n", "            ", "encoder_out", "=", "self", ".", "vq_encoder", "(", "vid_feats", ",", "qa", ",", "cand_len", "[", "idx", "]", ")", "\n", "out", ".", "append", "(", "encoder_out", ")", "\n", "\n", "", "out", "=", "torch", ".", "stack", "(", "out", ",", "0", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "_", ",", "predict_idx", "=", "torch", ".", "max", "(", "out", ",", "1", ")", "\n", "\n", "\n", "return", "out", ",", "predict_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.EVQA.EVQA.vq_encoder": [[46, 60], ["EVQA.EVQA.vid_encoder", "EVQA.EVQA.qns_encoder", "qns_hidden[].squeeze", "vid_hidden[].squeeze", "EVQA.EVQA.FC().squeeze", "EVQA.EVQA.FC"], "methods", ["None"], ["", "def", "vq_encoder", "(", "self", ",", "vid_feats", ",", "qns", ",", "qns_lengths", ")", ":", "\n", "\n", "        ", "vid_outputs", ",", "vid_hidden", "=", "self", ".", "vid_encoder", "(", "vid_feats", ")", "\n", "qns_outputs", ",", "qns_hidden", "=", "self", ".", "qns_encoder", "(", "qns", ",", "qns_lengths", ")", "\n", "\n", "\n", "qns_embed", "=", "qns_hidden", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "vid_embed", "=", "vid_hidden", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "\n", "fuse", "=", "qns_embed", "+", "vid_embed", "\n", "\n", "outputs", "=", "self", ".", "FC", "(", "fuse", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HGA.HGA.__init__": [[11, 51], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "q_v_transformer.CoAttention", "gcn.AdjLearner", "gcn.GCN", "torch.Sequential", "torch.Sequential", "block.fusions.Block", "block.fusions.Block", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vid_encoder", ",", "qns_encoder", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        Reasoning with Heterogeneous Graph Alignment for Video Question Answering (AAAI2020)\n        :param vid_encoder:\n        :param qns_encoder:\n        :param device:\n        \"\"\"", "\n", "super", "(", "HGA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vid_encoder", "=", "vid_encoder", "\n", "self", ".", "qns_encoder", "=", "qns_encoder", "\n", "self", ".", "device", "=", "device", "\n", "hidden_size", "=", "vid_encoder", ".", "dim_hidden", "\n", "input_dropout_p", "=", "vid_encoder", ".", "input_dropout_p", "\n", "\n", "self", ".", "q_input_ln", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "self", ".", "v_input_ln", "=", "nn", ".", "LayerNorm", "(", "hidden_size", ",", "elementwise_affine", "=", "False", ")", "\n", "\n", "self", ".", "co_attn", "=", "CoAttention", "(", "\n", "hidden_size", ",", "n_layers", "=", "vid_encoder", ".", "n_layers", ",", "dropout_p", "=", "input_dropout_p", ")", "\n", "\n", "self", ".", "adj_learner", "=", "AdjLearner", "(", "\n", "hidden_size", ",", "hidden_size", ",", "dropout", "=", "input_dropout_p", ")", "\n", "\n", "self", ".", "gcn", "=", "GCN", "(", "\n", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "\n", "dropout", "=", "input_dropout_p", ")", "\n", "\n", "self", ".", "gcn_atten_pool", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", "//", "2", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_size", "//", "2", ",", "1", ")", ",", "\n", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", ")", "#change to dim=-2 for attention-pooling otherwise sum-pooling", "\n", "\n", "self", ".", "global_fusion", "=", "fusions", ".", "Block", "(", "\n", "[", "hidden_size", ",", "hidden_size", "]", ",", "hidden_size", ",", "dropout_input", "=", "input_dropout_p", ")", "\n", "\n", "self", ".", "fusion", "=", "fusions", ".", "Block", "(", "[", "hidden_size", ",", "hidden_size", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HGA.HGA.forward": [[53, 80], ["qas_lengths.permute", "HGA.HGA.vid_encoder", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "enumerate", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.max", "torch.max", "torch.max", "torch.max", "qas.permute", "qas.permute", "HGA.HGA.vq_encoder", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.vq_encoder"], ["", "def", "forward", "(", "self", ",", "vid_feats", ",", "qas", ",", "qas_lengths", ")", ":", "\n", "        ", "\"\"\"\n        :param vid_feats:\n        :param qns:\n        :param qns_lengths:\n        :param mode:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "qns_encoder", ".", "use_bert", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "# for BERT", "\n", "", "else", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "", "cand_len", "=", "qas_lengths", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "v_output", ",", "v_hidden", "=", "self", ".", "vid_encoder", "(", "vid_feats", ")", "\n", "v_last_hidden", "=", "torch", ".", "squeeze", "(", "v_hidden", ")", "\n", "\n", "out", "=", "[", "]", "\n", "for", "idx", ",", "qa", "in", "enumerate", "(", "cand_qas", ")", ":", "\n", "            ", "encoder_out", "=", "self", ".", "vq_encoder", "(", "v_output", ",", "v_last_hidden", ",", "qa", ",", "cand_len", "[", "idx", "]", ")", "\n", "out", ".", "append", "(", "encoder_out", ")", "\n", "\n", "", "out", "=", "torch", ".", "stack", "(", "out", ",", "0", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "_", ",", "predict_idx", "=", "torch", ".", "max", "(", "out", ",", "1", ")", "\n", "\n", "\n", "return", "out", ",", "predict_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HGA.HGA.vq_encoder": [[82, 117], ["HGA.HGA.qns_encoder", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "HGA.HGA.q_input_ln", "HGA.HGA.v_input_ln", "HGA.HGA.co_attn", "HGA.HGA.adj_learner", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HGA.HGA.gcn", "HGA.HGA.gcn_atten_pool", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "HGA.HGA.global_fusion", "HGA.HGA.fusion().squeeze", "HGA.HGA.fusion"], "methods", ["None"], ["", "def", "vq_encoder", "(", "self", ",", "v_output", ",", "v_last_hidden", ",", "qas", ",", "qas_lengths", ")", ":", "\n", "        ", "\"\"\"\n        :param vid_feats:\n        :param qas:\n        :param qas_lengths:\n        :return:\n        \"\"\"", "\n", "q_output", ",", "s_hidden", "=", "self", ".", "qns_encoder", "(", "qas", ",", "qas_lengths", ")", "\n", "qns_last_hidden", "=", "torch", ".", "squeeze", "(", "s_hidden", ")", "\n", "\n", "q_output", "=", "self", ".", "q_input_ln", "(", "q_output", ")", "\n", "v_output", "=", "self", ".", "v_input_ln", "(", "v_output", ")", "\n", "\n", "q_output", ",", "v_output", "=", "self", ".", "co_attn", "(", "q_output", ",", "v_output", ")", "\n", "\n", "### GCN", "\n", "adj", "=", "self", ".", "adj_learner", "(", "q_output", ",", "v_output", ")", "\n", "# q_v_inputs of shape (batch_size, q_v_len, hidden_size)", "\n", "q_v_inputs", "=", "torch", ".", "cat", "(", "(", "q_output", ",", "v_output", ")", ",", "dim", "=", "1", ")", "\n", "# q_v_output of shape (batch_size, q_v_len, hidden_size)", "\n", "q_v_output", "=", "self", ".", "gcn", "(", "q_v_inputs", ",", "adj", ")", "\n", "\n", "## attention pool", "\n", "local_attn", "=", "self", ".", "gcn_atten_pool", "(", "q_v_output", ")", "\n", "# print(local_attn)", "\n", "local_out", "=", "torch", ".", "sum", "(", "q_v_output", "*", "local_attn", ",", "dim", "=", "1", ")", "\n", "\n", "# print(qns_last_hidden.shape, vid_last_hidden.shape)", "\n", "# qns_embed = qns_last_hidden.permute(1, 0, 2).contiguous().view(vid_feats.shape[0], -1)", "\n", "global_out", "=", "self", ".", "global_fusion", "(", "(", "qns_last_hidden", ",", "v_last_hidden", ")", ")", "\n", "\n", "\n", "out", "=", "self", ".", "fusion", "(", "(", "global_out", ",", "local_out", ")", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.STVQA.STVQA.__init__": [[8, 26], ["torch.Module.__init__", "Attention.SpatialAttention", "Attention.TempAttention", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vid_encoder", ",", "qns_encoder", ",", "att_dim", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\n        :param vid_encoder:\n        :param qns_encoder:\n        :param att_dim:\n        :param device:\n        \"\"\"", "\n", "super", "(", "STVQA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vid_encoder", "=", "vid_encoder", "\n", "self", ".", "qns_encoder", "=", "qns_encoder", "\n", "self", ".", "att_dim", "=", "att_dim", "\n", "\n", "self", ".", "spatial_att", "=", "SpatialAttention", "(", "qns_encoder", ".", "dim_hidden", "*", "2", ",", "vid_encoder", ".", "input_dim", ",", "hidden_dim", "=", "self", ".", "att_dim", ")", "\n", "self", ".", "temp_att", "=", "TempAttention", "(", "qns_encoder", ".", "dim_hidden", "*", "2", ",", "vid_encoder", ".", "dim_hidden", "*", "2", ",", "hidden_dim", "=", "self", ".", "att_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "FC", "=", "nn", ".", "Linear", "(", "qns_encoder", ".", "dim_hidden", "*", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.STVQA.STVQA.forward": [[28, 50], ["qas_lengths.permute", "enumerate", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.max", "torch.max", "torch.max", "torch.max", "qas.permute", "qas.permute", "STVQA.STVQA.vq_encoder", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.vq_encoder"], ["", "def", "forward", "(", "self", ",", "vid_feats", ",", "qas", ",", "qas_lengths", ")", ":", "\n", "        ", "\"\"\"\n        :param vid_feats:\n        :param qns:\n        :param qns_lengths:\n        :param mode:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "qns_encoder", ".", "use_bert", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "# for BERT", "\n", "", "else", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "", "cand_len", "=", "qas_lengths", ".", "permute", "(", "1", ",", "0", ")", "\n", "out", "=", "[", "]", "\n", "for", "idx", ",", "qa", "in", "enumerate", "(", "cand_qas", ")", ":", "\n", "            ", "encoder_out", "=", "self", ".", "vq_encoder", "(", "vid_feats", ",", "qa", ",", "cand_len", "[", "idx", "]", ")", "\n", "out", ".", "append", "(", "encoder_out", ")", "\n", "\n", "", "out", "=", "torch", ".", "stack", "(", "out", ",", "0", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "_", ",", "predict_idx", "=", "torch", ".", "max", "(", "out", ",", "1", ")", "\n", "\n", "return", "out", ",", "predict_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.STVQA.STVQA.vq_encoder": [[51, 87], ["STVQA.STVQA.qns_encoder", "qns_hidden_1[].size", "qns_hidden_1[].permute", "qns_hidden[].permute().contiguous().view.reshape", "vid_feats.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "STVQA.STVQA.vid_encoder", "STVQA.STVQA.qns_encoder", "qns_hidden[].permute().contiguous().view", "STVQA.STVQA.temp_att", "STVQA.STVQA.FC().squeeze", "STVQA.STVQA.spatial_att", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "qns_hidden[].permute().contiguous", "STVQA.STVQA.FC", "qns_hidden[].permute"], "methods", ["None"], ["", "def", "vq_encoder", "(", "self", ",", "vid_feats", ",", "qns", ",", "qns_lengths", ")", ":", "\n", "        ", "\"\"\"\n        TGIF-QA: Spatial and temporal attention\n        :param vid_feats: (batch_size, fnum, feat_dim, w, h)\n        :param qns:\n        :param qns_lengths:\n        :param ans:\n        :param ans_lengths:\n        :param teacher_force_ratio:\n        :return:\n        \"\"\"", "\n", "qns_output_1", ",", "qns_hidden_1", "=", "self", ".", "qns_encoder", "(", "qns", ",", "qns_lengths", ")", "\n", "n_layers", ",", "batch_size", ",", "qns_dim", "=", "qns_hidden_1", "[", "0", "]", ".", "size", "(", ")", "\n", "\n", "# Concatenate the dual-layer hidden as qns embedding", "\n", "qns_embed", "=", "qns_hidden_1", "[", "0", "]", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# batch first", "\n", "qns_embed", "=", "qns_embed", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "#(batch_size, feat_dim*2)", "\n", "batch_size", ",", "fnum", ",", "vid_dim", ",", "w", ",", "h", "=", "vid_feats", ".", "size", "(", ")", "\n", "\n", "# Apply spatial attention", "\n", "vid_att_feats", "=", "torch", ".", "zeros", "(", "batch_size", ",", "fnum", ",", "vid_dim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "bs", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "vid_att_feats", "[", "bs", "]", ",", "alpha", "=", "self", ".", "spatial_att", "(", "qns_embed", "[", "bs", "]", ",", "vid_feats", "[", "bs", "]", ")", "\n", "\n", "", "vid_outputs", ",", "vid_hidden", "=", "self", ".", "vid_encoder", "(", "vid_att_feats", ")", "\n", "\n", "qns_output", ",", "qns_hidden", "=", "self", ".", "qns_encoder", "(", "qns", ",", "qns_lengths", ",", "vid_hidden", ")", "\n", "\n", "qns_embed", "=", "qns_hidden", "[", "0", "]", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "#(batch_size, feat_dim)", "\n", "\n", "# Apply temporal attention", "\n", "temp_att_outputs", ",", "beta", "=", "self", ".", "temp_att", "(", "qns_embed", ",", "vid_outputs", ")", "\n", "encoder_outputs", "=", "(", "qns_embed", "+", "temp_att_outputs", ")", "\n", "outputs", "=", "self", ".", "FC", "(", "encoder_outputs", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__": [[11, 38], ["torch.Module.__init__", "Attention.TempAttention", "Attention.TempAttention", "memory_rand.MemoryRamTwoStreamModule", "memory_rand.MemoryRamModule", "memory_rand.MMModule", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vid_encoder", ",", "qns_encoder", ",", "max_len_v", ",", "max_len_q", ",", "device", ",", "input_drop_p", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n        Heterogeneous memory enhanced multimodal attention model for video question answering (CVPR19)\n        :param vid_encoder:\n        :param qns_encoder:\n        :param ans_decoder:\n        :param device:\n        \"\"\"", "\n", "super", "(", "HME", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vid_encoder", "=", "vid_encoder", "\n", "self", ".", "qns_encoder", "=", "qns_encoder", "\n", "\n", "\n", "dim", "=", "qns_encoder", ".", "dim_hidden", "\n", "\n", "self", ".", "temp_att_a", "=", "TempAttention", "(", "dim", "*", "2", ",", "dim", "*", "2", ",", "hidden_dim", "=", "256", ")", "\n", "self", ".", "temp_att_m", "=", "TempAttention", "(", "dim", "*", "2", ",", "dim", "*", "2", ",", "hidden_dim", "=", "256", ")", "\n", "self", ".", "mrm_vid", "=", "MemoryRamTwoStreamModule", "(", "dim", ",", "dim", ",", "max_len_v", ",", "device", ")", "\n", "self", ".", "mrm_txt", "=", "MemoryRamModule", "(", "dim", ",", "dim", ",", "max_len_q", ",", "device", ")", "\n", "\n", "self", ".", "mm_module_v1", "=", "MMModule", "(", "dim", ",", "input_drop_p", ",", "device", ")", "\n", "\n", "self", ".", "linear_vid", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ")", "\n", "self", ".", "linear_qns", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ")", "\n", "self", ".", "linear_mem", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ")", "\n", "self", ".", "vq2word_hme", "=", "nn", ".", "Linear", "(", "dim", "*", "3", ",", "1", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.forward": [[39, 66], ["qas_lengths.permute", "HME.HME.vid_encoder", "enumerate", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.max", "torch.max", "torch.max", "torch.max", "qas.permute", "qas.permute", "HME.HME.vq_encoder", "torch.stack().transpose.append", "torch.stack().transpose.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.vq_encoder"], ["", "def", "forward", "(", "self", ",", "vid_feats", ",", "qas", ",", "qas_lengths", ")", ":", "\n", "        ", "\"\"\"\n\n        :param vid_feats:\n        :param qns:\n        :param qns_lengths:\n        :param mode:\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "qns_encoder", ".", "use_bert", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "# for BERT", "\n", "", "else", ":", "\n", "            ", "cand_qas", "=", "qas", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "", "cand_len", "=", "qas_lengths", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "outputs_app_l1", ",", "outputs_app_l2", ",", "outputs_motion_l1", ",", "outputs_motion_l2", "=", "self", ".", "vid_encoder", "(", "vid_feats", ")", "\n", "vid_feats", "=", "(", "outputs_app_l1", ",", "outputs_app_l2", ",", "outputs_motion_l1", ",", "outputs_motion_l2", ")", "\n", "out", "=", "[", "]", "\n", "for", "idx", ",", "qa", "in", "enumerate", "(", "cand_qas", ")", ":", "\n", "            ", "encoder_out", "=", "self", ".", "vq_encoder", "(", "vid_feats", ",", "qa", ",", "cand_len", "[", "idx", "]", ")", "\n", "out", ".", "append", "(", "encoder_out", ")", "\n", "\n", "", "out", "=", "torch", ".", "stack", "(", "out", ",", "0", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "_", ",", "predict_idx", "=", "torch", ".", "max", "(", "out", ",", "1", ")", "\n", "\n", "return", "out", ",", "predict_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.doc-doc_NExT-QA.VQAModel.HME.HME.vq_encoder": [[67, 114], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "HME.HME.qns_encoder", "qns_output.size", "qns_hidden[].permute().contiguous().view", "HME.HME.temp_att_a", "HME.HME.temp_att_m", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "HME.HME.vq2word_hme().squeeze", "HME.HME.mrm_vid", "HME.HME.mrm_txt", "HME.HME.mm_module_v1", "HME.HME.linear_vid", "HME.HME.linear_vid", "HME.HME.linear_mem", "qns_hidden[].permute().contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "tmp_app_motion[].unsqueeze", "HME.HME.vq2word_hme", "qns_hidden[].permute"], "methods", ["None"], ["", "def", "vq_encoder", "(", "self", ",", "vid_feats", ",", "qns", ",", "qns_lengths", ",", "iter_num", "=", "3", ")", ":", "\n", "\n", "        ", "\"\"\"\n        :param vid_feats:\n        :param qns:\n        :param qns_lengths:\n        :param ans:\n        :param ans_lengths:\n        :return:\n        \"\"\"", "\n", "\n", "outputs_app_l1", ",", "outputs_app_l2", ",", "outputs_motion_l1", ",", "outputs_motion_l2", "=", "vid_feats", "\n", "outputs_app", "=", "torch", ".", "cat", "(", "(", "outputs_app_l1", ",", "outputs_app_l2", ")", ",", "dim", "=", "-", "1", ")", "\n", "outputs_motion", "=", "torch", ".", "cat", "(", "(", "outputs_motion_l1", ",", "outputs_motion_l2", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "batch_size", ",", "fnum", ",", "vid_feat_dim", "=", "outputs_app", ".", "size", "(", ")", "\n", "\n", "qns_output", ",", "qns_hidden", "=", "self", ".", "qns_encoder", "(", "qns", ",", "qns_lengths", ")", "\n", "# print(qns_output.shape, qns_hidden[0].shape) #torch.Size([10, 23, 256]) torch.Size([2, 10, 256])", "\n", "\n", "\n", "# qns_output = qns_output.permute(1, 0, 2)", "\n", "batch_size", ",", "seq_len", ",", "qns_feat_dim", "=", "qns_output", ".", "size", "(", ")", "\n", "\n", "qns_embed", "=", "qns_hidden", "[", "0", "]", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "#(batch_size, feat_dim)", "\n", "\n", "# Apply temporal attention", "\n", "att_app", ",", "beta_app", "=", "self", ".", "temp_att_a", "(", "qns_embed", ",", "outputs_app", ")", "\n", "att_motion", ",", "beta_motion", "=", "self", ".", "temp_att_m", "(", "qns_embed", ",", "outputs_motion", ")", "\n", "tmp_app_motion", "=", "torch", ".", "cat", "(", "(", "outputs_app_l2", "[", ":", ",", "-", "1", ",", ":", "]", ",", "outputs_motion_l2", "[", ":", ",", "-", "1", ",", ":", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "mem_output", "=", "torch", ".", "zeros", "(", "batch_size", ",", "vid_feat_dim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "bs", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "mem_ram_vid", "=", "self", ".", "mrm_vid", "(", "outputs_app_l2", "[", "bs", "]", ",", "outputs_motion_l2", "[", "bs", "]", ",", "fnum", ")", "\n", "cur_qns", "=", "qns_output", "[", "bs", "]", "[", ":", "qns_lengths", "[", "bs", "]", "]", "\n", "mem_ram_txt", "=", "self", ".", "mrm_txt", "(", "cur_qns", ",", "qns_lengths", "[", "bs", "]", ")", "#should remove padded zeros", "\n", "mem_output", "[", "bs", "]", "=", "self", ".", "mm_module_v1", "(", "tmp_app_motion", "[", "bs", "]", ".", "unsqueeze", "(", "0", ")", ",", "mem_ram_vid", ",", "mem_ram_txt", ",", "iter_num", ")", "\n", "\n", "", "app_trans", "=", "torch", ".", "tanh", "(", "self", ".", "linear_vid", "(", "att_app", ")", ")", "\n", "motion_trans", "=", "torch", ".", "tanh", "(", "self", ".", "linear_vid", "(", "att_motion", ")", ")", "\n", "mem_trans", "=", "torch", ".", "tanh", "(", "self", ".", "linear_mem", "(", "mem_output", ")", ")", "\n", "\n", "encoder_outputs", "=", "torch", ".", "cat", "(", "(", "app_trans", ",", "motion_trans", ",", "mem_trans", ")", ",", "dim", "=", "1", ")", "\n", "outputs", "=", "self", ".", "vq2word_hme", "(", "encoder_outputs", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "outputs", "", "", "", ""]]}