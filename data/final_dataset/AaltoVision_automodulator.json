{"home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.__init__": [[31, 50], ["int", "h5py.File", "range", "numpy.floor", "int", "int", "h5tool.HDF5Exporter.h5_file.create_dataset", "h5tool.HDF5Exporter.h5_lods.append", "h5tool.HDF5Exporter.buffers.append", "h5tool.HDF5Exporter.buffer_sizes.append", "numpy.log2", "numpy.ceil", "numpy.ceil", "numpy.zeros", "numpy.exp2"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "h5_filename", ",", "resolution", ",", "channels", "=", "3", ")", ":", "\n", "        ", "rlog2", "=", "int", "(", "np", ".", "floor", "(", "np", ".", "log2", "(", "resolution", ")", ")", ")", "\n", "assert", "resolution", "==", "2", "**", "rlog2", "\n", "self", ".", "resolution", "=", "resolution", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "h5_file", "=", "h5py", ".", "File", "(", "h5_filename", ",", "'w'", ")", "\n", "self", ".", "h5_lods", "=", "[", "]", "\n", "self", ".", "buffers", "=", "[", "]", "\n", "self", ".", "buffer_sizes", "=", "[", "]", "\n", "for", "lod", "in", "range", "(", "rlog2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "r", "=", "2", "**", "lod", ";", "c", "=", "channels", "\n", "bytes_per_item", "=", "c", "*", "(", "r", "**", "2", ")", "\n", "chunk_size", "=", "int", "(", "np", ".", "ceil", "(", "128.0", "/", "bytes_per_item", ")", ")", "\n", "buffer_size", "=", "int", "(", "np", ".", "ceil", "(", "512.0", "*", "np", ".", "exp2", "(", "20", ")", "/", "bytes_per_item", ")", ")", "\n", "lod", "=", "self", ".", "h5_file", ".", "create_dataset", "(", "'data%dx%d'", "%", "(", "r", ",", "r", ")", ",", "shape", "=", "(", "0", ",", "c", ",", "r", ",", "r", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "\n", "maxshape", "=", "(", "None", ",", "c", ",", "r", ",", "r", ")", ",", "chunks", "=", "(", "chunk_size", ",", "c", ",", "r", ",", "r", ")", ",", "compression", "=", "'gzip'", ",", "compression_opts", "=", "4", ")", "\n", "self", ".", "h5_lods", ".", "append", "(", "lod", ")", "\n", "self", ".", "buffers", ".", "append", "(", "np", ".", "zeros", "(", "(", "buffer_size", ",", "c", ",", "r", ",", "r", ")", ",", "dtype", "=", "np", ".", "uint8", ")", ")", "\n", "self", ".", "buffer_sizes", ".", "append", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close": [[51, 55], ["range", "h5tool.HDF5Exporter.h5_file.close", "len", "h5tool.HDF5Exporter.flush_lod"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.flush_lod"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "for", "lod", "in", "range", "(", "len", "(", "self", ".", "h5_lods", ")", ")", ":", "\n", "            ", "self", ".", "flush_lod", "(", "lod", ")", "\n", "", "self", ".", "h5_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.add_images": [[56, 72], ["range", "len", "numpy.uint8", "img.astype.astype.astype", "numpy.clip", "min", "int", "numpy.round", "h5tool.HDF5Exporter.flush_lod", "numpy.floor", "numpy.log2"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.flush_lod"], ["", "def", "add_images", "(", "self", ",", "img", ")", ":", "\n", "        ", "assert", "img", ".", "ndim", "==", "4", "and", "img", ".", "shape", "[", "1", "]", "==", "self", ".", "channels", "and", "img", ".", "shape", "[", "2", "]", "==", "img", ".", "shape", "[", "3", "]", "\n", "assert", "img", ".", "shape", "[", "2", "]", ">=", "self", ".", "resolution", "and", "img", ".", "shape", "[", "2", "]", "==", "2", "**", "int", "(", "np", ".", "floor", "(", "np", ".", "log2", "(", "img", ".", "shape", "[", "2", "]", ")", ")", ")", "\n", "for", "lod", "in", "range", "(", "len", "(", "self", ".", "h5_lods", ")", ")", ":", "\n", "            ", "while", "img", ".", "shape", "[", "2", "]", ">", "self", ".", "resolution", "/", "(", "2", "**", "lod", ")", ":", "\n", "                ", "img", "=", "img", ".", "astype", "(", "np", ".", "float32", ")", "\n", "img", "=", "(", "img", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "+", "img", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "+", "img", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "+", "img", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", ")", "*", "0.25", "\n", "", "quant", "=", "np", ".", "uint8", "(", "np", ".", "clip", "(", "np", ".", "round", "(", "img", ")", ",", "0", ",", "255", ")", ")", "\n", "ofs", "=", "0", "\n", "while", "ofs", "<", "quant", ".", "shape", "[", "0", "]", ":", "\n", "                ", "num", "=", "min", "(", "quant", ".", "shape", "[", "0", "]", "-", "ofs", ",", "self", ".", "buffers", "[", "lod", "]", ".", "shape", "[", "0", "]", "-", "self", ".", "buffer_sizes", "[", "lod", "]", ")", "\n", "self", ".", "buffers", "[", "lod", "]", "[", "self", ".", "buffer_sizes", "[", "lod", "]", ":", "self", ".", "buffer_sizes", "[", "lod", "]", "+", "num", "]", "=", "quant", "[", "ofs", ":", "ofs", "+", "num", "]", "\n", "self", ".", "buffer_sizes", "[", "lod", "]", "+=", "num", "\n", "if", "self", ".", "buffer_sizes", "[", "lod", "]", "==", "self", ".", "buffers", "[", "lod", "]", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "self", ".", "flush_lod", "(", "lod", ")", "\n", "", "ofs", "+=", "num", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.num_images": [[73, 75], ["None"], "methods", ["None"], ["", "", "", "def", "num_images", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "h5_lods", "[", "0", "]", ".", "shape", "[", "0", "]", "+", "self", ".", "buffer_sizes", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.flush_lod": [[76, 82], ["h5tool.HDF5Exporter.h5_lods[].resize"], "methods", ["None"], ["", "def", "flush_lod", "(", "self", ",", "lod", ")", ":", "\n", "        ", "num", "=", "self", ".", "buffer_sizes", "[", "lod", "]", "\n", "if", "num", ">", "0", ":", "\n", "            ", "self", ".", "h5_lods", "[", "lod", "]", ".", "resize", "(", "self", ".", "h5_lods", "[", "lod", "]", ".", "shape", "[", "0", "]", "+", "num", ",", "axis", "=", "0", ")", "\n", "self", ".", "h5_lods", "[", "lod", "]", "[", "-", "num", ":", "]", "=", "self", ".", "buffers", "[", "lod", "]", "[", ":", "num", "]", "\n", "self", ".", "buffer_sizes", "[", "lod", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ExceptionInfo.__init__": [[86, 89], ["traceback.format_exc", "sys.exc_info"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "type", ",", "self", ".", "value", "=", "sys", ".", "exc_info", "(", ")", "[", ":", "2", "]", "\n", "self", ".", "traceback", "=", "traceback", ".", "format_exc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.WorkerThread.__init__": [[93, 96], ["threading.Thread.__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_queue", ")", ":", "\n", "        ", "threading", ".", "Thread", ".", "__init__", "(", "self", ")", "\n", "self", ".", "task_queue", "=", "task_queue", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.WorkerThread.run": [[97, 107], ["h5tool.WorkerThread.task_queue.get", "result_queue.put", "func", "h5tool.ExceptionInfo"], "methods", ["None"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "func", ",", "args", ",", "result_queue", "=", "self", ".", "task_queue", ".", "get", "(", ")", "\n", "if", "func", "is", "None", ":", "\n", "                ", "break", "\n", "", "try", ":", "\n", "                ", "result", "=", "func", "(", "*", "args", ")", "\n", "", "except", ":", "\n", "                ", "result", "=", "ExceptionInfo", "(", ")", "\n", "", "result_queue", ".", "put", "(", "(", "result", ",", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.__init__": [[111, 120], ["queue.Queue", "dict", "range", "h5tool.WorkerThread", "WorkerThread.start"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_threads", ")", ":", "\n", "        ", "assert", "num_threads", ">=", "1", "\n", "self", ".", "task_queue", "=", "queue", ".", "Queue", "(", ")", "\n", "self", ".", "result_queues", "=", "dict", "(", ")", "\n", "self", ".", "num_threads", "=", "num_threads", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_threads", ")", ":", "\n", "            ", "thread", "=", "WorkerThread", "(", "self", ".", "task_queue", ")", "\n", "thread", ".", "daemon", "=", "True", "\n", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.add_task": [[121, 126], ["hasattr", "h5tool.ThreadPool.task_queue.put", "queue.Queue"], "methods", ["None"], ["", "", "def", "add_task", "(", "self", ",", "func", ",", "args", "=", "(", ")", ")", ":", "\n", "        ", "assert", "hasattr", "(", "func", ",", "'__call__'", ")", "# must be a function", "\n", "if", "func", "not", "in", "self", ".", "result_queues", ":", "\n", "            ", "self", ".", "result_queues", "[", "func", "]", "=", "queue", ".", "Queue", "(", ")", "\n", "", "self", ".", "task_queue", ".", "put", "(", "(", "func", ",", "args", ",", "self", ".", "result_queues", "[", "func", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.get_result": [[127, 134], ["h5tool.ThreadPool.result_queues[].get", "isinstance", "Exception", "print"], "methods", ["None"], ["", "def", "get_result", "(", "self", ",", "func", ",", "verbose_exceptions", "=", "True", ")", ":", "# returns (result, args)", "\n", "        ", "result", ",", "args", "=", "self", ".", "result_queues", "[", "func", "]", ".", "get", "(", ")", "\n", "if", "isinstance", "(", "result", ",", "ExceptionInfo", ")", ":", "\n", "            ", "if", "verbose_exceptions", ":", "\n", "                ", "print", "(", "(", "'\\n\\nWorker thread caught an exception:\\n'", "+", "result", ".", "traceback", "+", "'\\n'", ")", ")", "\n", "", "raise", "Exception", "(", "'%s, %s'", "%", "(", "result", ".", "type", ",", "result", ".", "value", ")", ")", "\n", "", "return", "result", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.finish": [[135, 138], ["range", "h5tool.ThreadPool.task_queue.put"], "methods", ["None"], ["", "def", "finish", "(", "self", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "self", ".", "num_threads", ")", ":", "\n", "            ", "self", ".", "task_queue", ".", "put", "(", "(", "None", ",", "(", ")", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.__enter__": [[139, 141], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "# for 'with' statement", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.__exit__": [[142, 144], ["h5tool.ThreadPool.finish"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.finish"], ["", "def", "__exit__", "(", "self", ",", "*", "excinfo", ")", ":", "\n", "        ", "self", ".", "finish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.process_items_concurrently": [[145, 170], ["enumerate", "process_func", "h5tool.ThreadPool.get_result", "pre_func", "results.append", "h5tool.ThreadPool.add_task", "len", "h5tool.ThreadPool.process_items_concurrently.retire_result"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.get_result", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.ThreadPool.add_task"], ["", "def", "process_items_concurrently", "(", "self", ",", "item_iterator", ",", "process_func", "=", "lambda", "x", ":", "x", ",", "pre_func", "=", "lambda", "x", ":", "x", ",", "post_func", "=", "lambda", "x", ":", "x", ",", "max_items_in_flight", "=", "None", ")", ":", "\n", "        ", "if", "max_items_in_flight", "is", "None", ":", "max_items_in_flight", "=", "self", ".", "num_threads", "*", "4", "\n", "assert", "max_items_in_flight", ">=", "1", "\n", "results", "=", "[", "]", "\n", "retire_idx", "=", "[", "0", "]", "\n", "\n", "def", "task_func", "(", "prepared", ",", "idx", ")", ":", "\n", "            ", "return", "process_func", "(", "prepared", ")", "\n", "\n", "", "def", "retire_result", "(", ")", ":", "\n", "            ", "processed", ",", "(", "prepared", ",", "idx", ")", "=", "self", ".", "get_result", "(", "task_func", ")", "\n", "results", "[", "idx", "]", "=", "processed", "\n", "while", "retire_idx", "[", "0", "]", "<", "len", "(", "results", ")", "and", "results", "[", "retire_idx", "[", "0", "]", "]", "is", "not", "None", ":", "\n", "                ", "yield", "post_func", "(", "results", "[", "retire_idx", "[", "0", "]", "]", ")", "\n", "results", "[", "retire_idx", "[", "0", "]", "]", "=", "None", "\n", "retire_idx", "[", "0", "]", "+=", "1", "\n", "\n", "", "", "for", "idx", ",", "item", "in", "enumerate", "(", "item_iterator", ")", ":", "\n", "            ", "prepared", "=", "pre_func", "(", "item", ")", "\n", "results", ".", "append", "(", "None", ")", "\n", "self", ".", "add_task", "(", "func", "=", "task_func", ",", "args", "=", "(", "prepared", ",", "idx", ")", ")", "\n", "while", "retire_idx", "[", "0", "]", "<", "idx", "-", "max_items_in_flight", "+", "2", ":", "\n", "                ", "for", "res", "in", "retire_result", "(", ")", ":", "yield", "res", "\n", "", "", "while", "retire_idx", "[", "0", "]", "<", "len", "(", "results", ")", ":", "\n", "            ", "for", "res", "in", "retire_result", "(", ")", ":", "yield", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.inspect": [[173, 193], ["print", "print", "h5py.File", "sorted", "h5py.File.close", "print", "print", "print", "print", "any", "os.stat", "len", "print", "print", "print", "int", "h5py.File.items", "key.startswith", "numpy.log2", "float", "numpy.exp2", "numpy.exp2", "float"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close"], ["", "", "", "def", "inspect", "(", "h5_filename", ")", ":", "\n", "    ", "print", "(", "(", "'%-20s%s'", "%", "(", "'HDF5 filename'", ",", "h5_filename", ")", ")", ")", "\n", "file_size", "=", "os", ".", "stat", "(", "h5_filename", ")", ".", "st_size", "\n", "print", "(", "(", "'%-20s%.2f GB'", "%", "(", "'Total size'", ",", "float", "(", "file_size", ")", "/", "np", ".", "exp2", "(", "30", ")", ")", ")", ")", "\n", "\n", "h5", "=", "h5py", ".", "File", "(", "h5_filename", ",", "'r'", ")", "\n", "lods", "=", "sorted", "(", "[", "value", "for", "key", ",", "value", "in", "h5", ".", "items", "(", ")", "if", "key", ".", "startswith", "(", "'data'", ")", "]", ",", "key", "=", "lambda", "lod", ":", "-", "lod", ".", "shape", "[", "3", "]", ")", "\n", "shapes", "=", "[", "lod", ".", "shape", "for", "lod", "in", "lods", "]", "\n", "shape", "=", "shapes", "[", "0", "]", "\n", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-20s%d'", "%", "(", "'Total images'", ",", "shape", "[", "0", "]", ")", ")", ")", "\n", "print", "(", "(", "'%-20s%dx%d'", "%", "(", "'Resolution'", ",", "shape", "[", "3", "]", ",", "shape", "[", "2", "]", ")", ")", ")", "\n", "print", "(", "(", "'%-20s%d'", "%", "(", "'Color channels'", ",", "shape", "[", "1", "]", ")", ")", ")", "\n", "print", "(", "(", "'%-20s%.2f KB'", "%", "(", "'Size per image'", ",", "float", "(", "file_size", ")", "/", "shape", "[", "0", "]", "/", "np", ".", "exp2", "(", "10", ")", ")", ")", ")", "\n", "\n", "if", "len", "(", "lods", ")", "!=", "int", "(", "np", ".", "log2", "(", "shape", "[", "3", "]", ")", ")", "+", "1", ":", "\n", "        ", "print", "(", "'Warning: The HDF5 file contains incorrect number of LODs'", ")", "\n", "", "if", "any", "(", "s", "[", "0", "]", "!=", "shape", "[", "0", "]", "for", "s", "in", "shapes", ")", ":", "\n", "        ", "print", "(", "'Warning: The HDF5 file contains inconsistent number of images in different LODs'", ")", "\n", "print", "(", "'Perhaps the dataset creation script was terminated abruptly?'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.compare": [[196, 227], ["print", "h5py.File", "h5py.File", "sorted", "sorted", "h5py.File.close", "h5py.File.close", "print", "print", "min", "range", "h5py.File.items", "key.startswith", "h5py.File.items", "key.startswith", "print", "numpy.any", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close"], ["", "", "def", "compare", "(", "first_h5", ",", "second_h5", ")", ":", "\n", "    ", "print", "(", "(", "'Comparing %s vs. %s'", "%", "(", "first_h5", ",", "second_h5", ")", ")", ")", "\n", "h5_a", "=", "h5py", ".", "File", "(", "first_h5", ",", "'r'", ")", "\n", "h5_b", "=", "h5py", ".", "File", "(", "second_h5", ",", "'r'", ")", "\n", "lods_a", "=", "sorted", "(", "[", "value", "for", "key", ",", "value", "in", "h5_a", ".", "items", "(", ")", "if", "key", ".", "startswith", "(", "'data'", ")", "]", ",", "key", "=", "lambda", "lod", ":", "-", "lod", ".", "shape", "[", "3", "]", ")", "\n", "lods_b", "=", "sorted", "(", "[", "value", "for", "key", ",", "value", "in", "h5_b", ".", "items", "(", ")", "if", "key", ".", "startswith", "(", "'data'", ")", "]", ",", "key", "=", "lambda", "lod", ":", "-", "lod", ".", "shape", "[", "3", "]", ")", "\n", "shape_a", "=", "lods_a", "[", "0", "]", ".", "shape", "\n", "shape_b", "=", "lods_b", "[", "0", "]", ".", "shape", "\n", "\n", "if", "shape_a", "[", "1", "]", "!=", "shape_b", "[", "1", "]", ":", "\n", "        ", "print", "(", "(", "'The datasets have different number of color channels: %d vs. %d'", "%", "(", "shape_a", "[", "1", "]", ",", "shape_b", "[", "1", "]", ")", ")", ")", "\n", "", "elif", "shape_a", "[", "3", "]", "!=", "shape_b", "[", "3", "]", "or", "shape_a", "[", "2", "]", "!=", "shape_b", "[", "2", "]", ":", "\n", "        ", "print", "(", "(", "'The datasets have different resolution: %dx%d vs. %dx%d'", "%", "(", "shape_a", "[", "3", "]", ",", "shape_a", "[", "2", "]", ",", "shape_b", "[", "3", "]", ",", "shape_b", "[", "2", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "min_images", "=", "min", "(", "shape_a", "[", "0", "]", ",", "shape_b", "[", "0", "]", ")", "\n", "num_diffs", "=", "0", "\n", "for", "idx", "in", "range", "(", "min_images", ")", ":", "\n", "            ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "idx", ",", "min_images", ")", ")", ")", "\n", "if", "np", ".", "any", "(", "lods_a", "[", "0", "]", "[", "idx", "]", "!=", "lods_b", "[", "0", "]", "[", "idx", "]", ")", ":", "\n", "                ", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "'Different image: %d'", "%", "idx", ")", ")", "\n", "num_diffs", "+=", "1", "\n", "", "", "if", "shape_a", "[", "0", "]", "!=", "shape_b", "[", "0", "]", ":", "\n", "            ", "print", "(", "(", "'The datasets contain different number of images: %d vs. %d'", "%", "(", "shape_a", "[", "0", "]", ",", "shape_b", "[", "0", "]", ")", ")", ")", "\n", "", "if", "num_diffs", "==", "0", ":", "\n", "            ", "print", "(", "(", "'All %d images are identical.'", "%", "min_images", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "(", "'%d images out of %d are different.'", "%", "(", "num_diffs", ",", "min_images", ")", ")", ")", "\n", "\n", "", "", "h5_a", ".", "close", "(", ")", "\n", "h5_b", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.display": [[230, 255], ["print", "h5py.File", "sorted", "list", "cv2.namedWindow", "print", "h5py.File.close", "print", "print", "range", "print", "img.transpose.transpose", "cv2.imshow", "cv2.waitKey", "h5py.File.items", "key.startswith"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close"], ["", "def", "display", "(", "h5_filename", ",", "start", "=", "None", ",", "stop", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "    ", "print", "(", "(", "'Displaying images from %s'", "%", "h5_filename", ")", ")", "\n", "h5", "=", "h5py", ".", "File", "(", "h5_filename", ",", "'r'", ")", "\n", "lods", "=", "sorted", "(", "[", "value", "for", "key", ",", "value", "in", "h5", ".", "items", "(", ")", "if", "key", ".", "startswith", "(", "'data'", ")", "]", ",", "key", "=", "lambda", "lod", ":", "-", "lod", ".", "shape", "[", "3", "]", ")", "\n", "indices", "=", "list", "(", "range", "(", "lods", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ")", "\n", "indices", "=", "indices", "[", "start", ":", "stop", ":", "step", "]", "\n", "\n", "import", "cv2", "# pip install opencv-python", "\n", "window_name", "=", "'h5tool'", "\n", "cv2", ".", "namedWindow", "(", "window_name", ")", "\n", "print", "(", "'Press SPACE or ENTER to advance, ESC to exit.'", ")", "\n", "\n", "for", "idx", "in", "indices", ":", "\n", "        ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "idx", ",", "lods", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "img", "=", "lods", "[", "0", "]", "[", "idx", "]", "\n", "img", "=", "img", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "# CHW => HWC", "\n", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "# RGB => BGR", "\n", "cv2", ".", "imshow", "(", "window_name", ",", "img", ")", "\n", "c", "=", "cv2", ".", "waitKey", "(", ")", "\n", "if", "c", "==", "27", ":", "\n", "            ", "break", "\n", "\n", "", "", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "'Done.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.extract": [[258, 279], ["print", "h5py.File", "sorted", "h5py.File.close", "print", "print", "list", "os.path.isdir", "os.makedirs", "print", "PIL.Image.fromarray.save", "range", "PIL.Image.fromarray", "PIL.Image.fromarray", "os.path.join", "len", "h5py.File.items", "key.startswith", "PIL.Image.fromarray.transpose"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save"], ["", "def", "extract", "(", "h5_filename", ",", "output_dir", ",", "start", "=", "None", ",", "stop", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "    ", "print", "(", "(", "'Extracting images from %s to %s'", "%", "(", "h5_filename", ",", "output_dir", ")", ")", ")", "\n", "h5", "=", "h5py", ".", "File", "(", "h5_filename", ",", "'r'", ")", "\n", "lods", "=", "sorted", "(", "[", "value", "for", "key", ",", "value", "in", "h5", ".", "items", "(", ")", "if", "key", ".", "startswith", "(", "'data'", ")", "]", ",", "key", "=", "lambda", "lod", ":", "-", "lod", ".", "shape", "[", "3", "]", ")", "\n", "shape", "=", "lods", "[", "0", "]", ".", "shape", "\n", "indices", "=", "list", "(", "range", "(", "shape", "[", "0", "]", ")", ")", "[", "start", ":", "stop", ":", "step", "]", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "", "for", "idx", "in", "indices", ":", "\n", "        ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "idx", ",", "shape", "[", "0", "]", ")", ")", ")", "\n", "img", "=", "lods", "[", "0", "]", "[", "idx", "]", "\n", "if", "img", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "img", "=", "PIL", ".", "Image", ".", "fromarray", "(", "img", "[", "0", "]", ",", "'L'", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "PIL", ".", "Image", ".", "fromarray", "(", "img", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ",", "'RGB'", ")", "\n", "", "img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'img%08d.png'", "%", "idx", ")", ")", "\n", "\n", "", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "'Extracted %d images.'", "%", "len", "(", "indices", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.create_custom": [[282, 316], ["print", "os.path.join", "sorted", "numpy.asarray", "h5tool.HDF5Exporter", "range", "print", "h5tool.HDF5Exporter.close", "print", "print", "glob.glob", "len", "print", "PIL.Image.open", "print", "print", "print", "len", "print", "numpy.asarray", "h5tool.HDF5Exporter.add_images", "int", "PIL.Image.open", "img.transpose.transpose", "len", "numpy.floor", "numpy.log2", "len"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.add_images"], ["", "def", "create_custom", "(", "h5_filename", ",", "image_dir", ")", ":", "\n", "    ", "print", "(", "(", "'Creating custom dataset %s from %s'", "%", "(", "h5_filename", ",", "image_dir", ")", ")", ")", "\n", "glob_pattern", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'*'", ")", "\n", "image_filenames", "=", "sorted", "(", "glob", ".", "glob", "(", "glob_pattern", ")", ")", "\n", "if", "len", "(", "image_filenames", ")", "==", "0", ":", "\n", "        ", "print", "(", "(", "'Error: No input images found in %s'", "%", "glob_pattern", ")", ")", "\n", "return", "\n", "\n", "", "img", "=", "np", ".", "asarray", "(", "PIL", ".", "Image", ".", "open", "(", "image_filenames", "[", "0", "]", ")", ")", "\n", "resolution", "=", "img", ".", "shape", "[", "0", "]", "\n", "channels", "=", "img", ".", "shape", "[", "2", "]", "if", "img", ".", "ndim", "==", "3", "else", "1", "\n", "if", "img", ".", "shape", "[", "1", "]", "!=", "resolution", ":", "\n", "        ", "print", "(", "'Error: Input images must have the same width and height'", ")", "\n", "return", "\n", "", "if", "resolution", "!=", "2", "**", "int", "(", "np", ".", "floor", "(", "np", ".", "log2", "(", "resolution", ")", ")", ")", ":", "\n", "        ", "print", "(", "'Error: Input image resolution must be a power-of-two'", ")", "\n", "return", "\n", "", "if", "channels", "not", "in", "[", "1", ",", "3", "]", ":", "\n", "        ", "print", "(", "'Error: Input images must be stored as RGB or grayscale'", ")", "\n", "\n", "", "h5", "=", "HDF5Exporter", "(", "h5_filename", ",", "resolution", ",", "channels", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "image_filenames", ")", ")", ":", "\n", "        ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "idx", ",", "len", "(", "image_filenames", ")", ")", ")", ")", "\n", "img", "=", "np", ".", "asarray", "(", "PIL", ".", "Image", ".", "open", "(", "image_filenames", "[", "idx", "]", ")", ")", "\n", "if", "channels", "==", "1", ":", "\n", "            ", "img", "=", "img", "[", "np", ".", "newaxis", ",", ":", ",", ":", "]", "# HW => CHW", "\n", "", "else", ":", "\n", "            ", "img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# HWC => CHW", "\n", "", "h5", ".", "add_images", "(", "img", "[", "np", ".", "newaxis", "]", ")", "\n", "\n", "", "print", "(", "(", "'%-40s\\r'", "%", "'Flushing data...'", ")", ")", "\n", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "'Added %d images.'", "%", "len", "(", "image_filenames", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.create_mnist": [[319, 345], ["print", "np.frombuffer.reshape", "numpy.pad", "print", "h5tool.HDF5Exporter", "h5tool.HDF5Exporter.add_images", "h5tool.HDF5Exporter.close", "print", "gzip.open", "numpy.frombuffer", "gzip.open", "numpy.frombuffer", "print", "numpy.zeros", "numpy.save", "os.path.join", "file.read", "os.path.join", "file.read", "numpy.min", "numpy.max", "numpy.min", "numpy.max", "os.path.splitext", "numpy.max", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.add_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save"], ["", "def", "create_mnist", "(", "h5_filename", ",", "mnist_dir", ",", "export_labels", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "'Loading MNIST data from %s'", "%", "mnist_dir", ")", ")", "\n", "import", "gzip", "\n", "with", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "mnist_dir", ",", "'train-images-idx3-ubyte.gz'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "images", "=", "np", ".", "frombuffer", "(", "file", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "16", ")", "\n", "", "with", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "mnist_dir", ",", "'train-labels-idx1-ubyte.gz'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "labels", "=", "np", ".", "frombuffer", "(", "file", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "8", ")", "\n", "", "images", "=", "images", ".", "reshape", "(", "-", "1", ",", "1", ",", "28", ",", "28", ")", "\n", "images", "=", "np", ".", "pad", "(", "images", ",", "[", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "2", ",", "2", ")", ",", "(", "2", ",", "2", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "assert", "images", ".", "shape", "==", "(", "60000", ",", "1", ",", "32", ",", "32", ")", "and", "images", ".", "dtype", "==", "np", ".", "uint8", "\n", "assert", "labels", ".", "shape", "==", "(", "60000", ",", ")", "and", "labels", ".", "dtype", "==", "np", ".", "uint8", "\n", "assert", "np", ".", "min", "(", "images", ")", "==", "0", "and", "np", ".", "max", "(", "images", ")", "==", "255", "\n", "assert", "np", ".", "min", "(", "labels", ")", "==", "0", "and", "np", ".", "max", "(", "labels", ")", "==", "9", "\n", "\n", "print", "(", "(", "'Creating %s'", "%", "h5_filename", ")", ")", "\n", "h5", "=", "HDF5Exporter", "(", "h5_filename", ",", "32", ",", "1", ")", "\n", "h5", ".", "add_images", "(", "images", ")", "\n", "h5", ".", "close", "(", ")", "\n", "\n", "if", "export_labels", ":", "\n", "        ", "npy_filename", "=", "os", ".", "path", ".", "splitext", "(", "h5_filename", ")", "[", "0", "]", "+", "'-labels.npy'", "\n", "print", "(", "(", "'Creating %s'", "%", "npy_filename", ")", ")", "\n", "onehot", "=", "np", ".", "zeros", "(", "(", "labels", ".", "size", ",", "np", ".", "max", "(", "labels", ")", "+", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "onehot", "[", "np", ".", "arange", "(", "labels", ".", "size", ")", ",", "labels", "]", "=", "1.0", "\n", "np", ".", "save", "(", "npy_filename", ",", "onehot", ")", "\n", "", "print", "(", "(", "'Added %d images.'", "%", "images", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.create_mnist_rgb": [[348, 370], ["print", "np.frombuffer.reshape", "numpy.pad", "print", "h5tool.HDF5Exporter", "numpy.random.seed", "range", "print", "h5tool.HDF5Exporter.close", "print", "print", "gzip.open", "numpy.frombuffer", "h5tool.HDF5Exporter.add_images", "os.path.join", "file.read", "numpy.min", "numpy.max", "print", "numpy.random.randint"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.add_images"], ["", "def", "create_mnist_rgb", "(", "h5_filename", ",", "mnist_dir", ",", "num_images", "=", "1000000", ",", "random_seed", "=", "123", ")", ":", "\n", "    ", "print", "(", "(", "'Loading MNIST data from %s'", "%", "mnist_dir", ")", ")", "\n", "import", "gzip", "\n", "with", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "mnist_dir", ",", "'train-images-idx3-ubyte.gz'", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "images", "=", "np", ".", "frombuffer", "(", "file", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "16", ")", "\n", "", "images", "=", "images", ".", "reshape", "(", "-", "1", ",", "28", ",", "28", ")", "\n", "images", "=", "np", ".", "pad", "(", "images", ",", "[", "(", "0", ",", "0", ")", ",", "(", "2", ",", "2", ")", ",", "(", "2", ",", "2", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "assert", "images", ".", "shape", "==", "(", "60000", ",", "32", ",", "32", ")", "and", "images", ".", "dtype", "==", "np", ".", "uint8", "\n", "assert", "np", ".", "min", "(", "images", ")", "==", "0", "and", "np", ".", "max", "(", "images", ")", "==", "255", "\n", "\n", "print", "(", "(", "'Creating %s'", "%", "h5_filename", ")", ")", "\n", "h5", "=", "HDF5Exporter", "(", "h5_filename", ",", "32", ",", "3", ")", "\n", "np", ".", "random", ".", "seed", "(", "random_seed", ")", "\n", "for", "idx", "in", "range", "(", "num_images", ")", ":", "\n", "        ", "if", "idx", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "idx", ",", "num_images", ")", ")", ")", "\n", "", "h5", ".", "add_images", "(", "images", "[", "np", ".", "newaxis", ",", "np", ".", "random", ".", "randint", "(", "images", ".", "shape", "[", "0", "]", ",", "size", "=", "3", ")", "]", ")", "\n", "\n", "", "print", "(", "(", "'%-40s\\r'", "%", "'Flushing data...'", ")", ")", "\n", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "'Added %d images.'", "%", "num_images", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.create_cifar10": [[373, 402], ["print", "range", "numpy.concatenate", "numpy.concatenate", "print", "h5tool.HDF5Exporter", "h5tool.HDF5Exporter.add_images", "h5tool.HDF5Exporter.close", "print", "np.concatenate.append", "np.concatenate.append", "print", "numpy.zeros", "numpy.save", "open", "pickle.load", "data[].reshape", "numpy.uint8", "numpy.min", "numpy.max", "numpy.min", "numpy.max", "os.path.join", "os.path.splitext", "numpy.max", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.add_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save"], ["", "def", "create_cifar10", "(", "h5_filename", ",", "cifar10_dir", ",", "export_labels", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "'Loading CIFAR-10 data from %s'", "%", "cifar10_dir", ")", ")", "\n", "images", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "range", "(", "1", ",", "6", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "cifar10_dir", ",", "'data_batch_%d'", "%", "batch", ")", ",", "'rb'", ")", "as", "file", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "file", ")", "\n", "", "images", ".", "append", "(", "data", "[", "'data'", "]", ".", "reshape", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "labels", ".", "append", "(", "np", ".", "uint8", "(", "data", "[", "'labels'", "]", ")", ")", "\n", "", "images", "=", "np", ".", "concatenate", "(", "images", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ")", "\n", "\n", "assert", "images", ".", "shape", "==", "(", "50000", ",", "3", ",", "32", ",", "32", ")", "and", "images", ".", "dtype", "==", "np", ".", "uint8", "\n", "assert", "labels", ".", "shape", "==", "(", "50000", ",", ")", "and", "labels", ".", "dtype", "==", "np", ".", "uint8", "\n", "assert", "np", ".", "min", "(", "images", ")", "==", "0", "and", "np", ".", "max", "(", "images", ")", "==", "255", "\n", "assert", "np", ".", "min", "(", "labels", ")", "==", "0", "and", "np", ".", "max", "(", "labels", ")", "==", "9", "\n", "\n", "print", "(", "(", "'Creating %s'", "%", "h5_filename", ")", ")", "\n", "h5", "=", "HDF5Exporter", "(", "h5_filename", ",", "32", ",", "3", ")", "\n", "h5", ".", "add_images", "(", "images", ")", "\n", "h5", ".", "close", "(", ")", "\n", "\n", "if", "export_labels", ":", "\n", "        ", "npy_filename", "=", "os", ".", "path", ".", "splitext", "(", "h5_filename", ")", "[", "0", "]", "+", "'-labels.npy'", "\n", "print", "(", "(", "'Creating %s'", "%", "npy_filename", ")", ")", "\n", "onehot", "=", "np", ".", "zeros", "(", "(", "labels", ".", "size", ",", "np", ".", "max", "(", "labels", ")", "+", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "onehot", "[", "np", ".", "arange", "(", "labels", ".", "size", ")", ",", "labels", "]", "=", "1.0", "\n", "np", ".", "save", "(", "npy_filename", ",", "onehot", ")", "\n", "", "print", "(", "(", "'Added %d images.'", "%", "images", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.create_lsun": [[405, 444], ["print", "print", "h5tool.HDF5Exporter.num_images", "h5tool.HDF5Exporter.close", "print", "print", "lmdb.open().begin", "h5tool.HDF5Exporter", "enumerate", "txn.stat", "txn.cursor", "print", "lmdb.open", "numpy.min", "PIL.Image.fromarray", "np.asarray.resize", "numpy.asarray", "np.asarray.transpose", "h5tool.HDF5Exporter.add_images", "h5tool.HDF5Exporter.num_images", "cv2.imdecode", "print", "print", "h5tool.HDF5Exporter.num_images", "min", "numpy.fromstring", "IOError", "numpy.asarray", "PIL.Image.open", "sys.exc_info", "io.BytesIO", "h5tool.HDF5Exporter.num_images"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.num_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.add_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.num_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.num_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.num_images"], ["", "def", "create_lsun", "(", "h5_filename", ",", "lmdb_dir", ",", "resolution", "=", "256", ",", "max_images", "=", "None", ")", ":", "\n", "    ", "print", "(", "(", "'Creating LSUN dataset %s from %s'", "%", "(", "h5_filename", ",", "lmdb_dir", ")", ")", ")", "\n", "import", "lmdb", "# pip install lmdb", "\n", "import", "cv2", "# pip install opencv-python", "\n", "with", "lmdb", ".", "open", "(", "lmdb_dir", ",", "readonly", "=", "True", ")", ".", "begin", "(", "write", "=", "False", ")", "as", "txn", ":", "\n", "        ", "total_images", "=", "txn", ".", "stat", "(", ")", "[", "'entries'", "]", "\n", "if", "max_images", "is", "None", ":", "\n", "            ", "max_images", "=", "total_images", "\n", "\n", "", "h5", "=", "HDF5Exporter", "(", "h5_filename", ",", "resolution", ",", "3", ")", "\n", "for", "idx", ",", "(", "key", ",", "value", ")", "in", "enumerate", "(", "txn", ".", "cursor", "(", ")", ")", ":", "\n", "            ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "h5", ".", "num_images", "(", ")", ",", "min", "(", "h5", ".", "num_images", "(", ")", "+", "total_images", "-", "idx", ",", "max_images", ")", ")", ")", ")", "\n", "try", ":", "\n", "                ", "try", ":", "\n", "                    ", "img", "=", "cv2", ".", "imdecode", "(", "np", ".", "fromstring", "(", "value", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "1", ")", "\n", "if", "img", "is", "None", ":", "\n", "                        ", "raise", "IOError", "(", "'cv2.imdecode failed'", ")", "\n", "", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "# BGR => RGB", "\n", "", "except", "IOError", ":", "\n", "                    ", "img", "=", "np", ".", "asarray", "(", "PIL", ".", "Image", ".", "open", "(", "io", ".", "BytesIO", "(", "value", ")", ")", ")", "\n", "", "crop", "=", "np", ".", "min", "(", "img", ".", "shape", "[", ":", "2", "]", ")", "\n", "img", "=", "img", "[", "(", "img", ".", "shape", "[", "0", "]", "-", "crop", ")", "/", "2", ":", "(", "img", ".", "shape", "[", "0", "]", "+", "crop", ")", "/", "2", ",", "(", "img", ".", "shape", "[", "1", "]", "-", "crop", ")", "/", "2", ":", "(", "img", ".", "shape", "[", "1", "]", "+", "crop", ")", "/", "2", "]", "\n", "img", "=", "PIL", ".", "Image", ".", "fromarray", "(", "img", ",", "'RGB'", ")", "\n", "img", "=", "img", ".", "resize", "(", "(", "resolution", ",", "resolution", ")", ",", "PIL", ".", "Image", ".", "ANTIALIAS", ")", "\n", "img", "=", "np", ".", "asarray", "(", "img", ")", "\n", "img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# HWC => CHW", "\n", "h5", ".", "add_images", "(", "img", "[", "np", ".", "newaxis", "]", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "sys", ".", "exc_info", "(", ")", "[", "1", "]", ")", ")", "\n", "raise", "\n", "", "if", "h5", ".", "num_images", "(", ")", "==", "max_images", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "print", "(", "(", "'%-40s\\r'", "%", "'Flushing data...'", ")", ")", "\n", "num_added", "=", "h5", ".", "num_images", "(", ")", "\n", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "'Added %d images.'", "%", "num_added", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.create_celeba": [[447, 469], ["print", "os.path.join", "sorted", "h5tool.HDF5Exporter", "range", "print", "h5tool.HDF5Exporter.close", "print", "print", "glob.glob", "len", "print", "print", "numpy.asarray", "img.transpose.transpose", "h5tool.HDF5Exporter.add_images", "PIL.Image.open"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.add_images"], ["", "def", "create_celeba", "(", "h5_filename", ",", "celeba_dir", ",", "cx", "=", "89", ",", "cy", "=", "121", ")", ":", "\n", "    ", "print", "(", "(", "'Creating CelebA dataset %s from %s'", "%", "(", "h5_filename", ",", "celeba_dir", ")", ")", ")", "\n", "glob_pattern", "=", "os", ".", "path", ".", "join", "(", "celeba_dir", ",", "'img_align_celeba_png'", ",", "'*.png'", ")", "\n", "image_filenames", "=", "sorted", "(", "glob", ".", "glob", "(", "glob_pattern", ")", ")", "\n", "num_images", "=", "202599", "\n", "if", "len", "(", "image_filenames", ")", "<", "num_images", ":", "\n", "        ", "print", "(", "(", "'Error: Expected to find %d images in %s'", "%", "(", "num_images", ",", "glob_pattern", ")", ")", ")", "\n", "return", "\n", "\n", "", "h5", "=", "HDF5Exporter", "(", "h5_filename", ",", "128", ",", "3", ")", "\n", "for", "idx", "in", "range", "(", "num_images", ")", ":", "\n", "        ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "idx", ",", "num_images", ")", ")", ")", "\n", "img", "=", "np", ".", "asarray", "(", "PIL", ".", "Image", ".", "open", "(", "image_filenames", "[", "idx", "]", ")", ")", "\n", "assert", "img", ".", "shape", "==", "(", "218", ",", "178", ",", "3", ")", "\n", "img", "=", "img", "[", "cy", "-", "64", ":", "cy", "+", "64", ",", "cx", "-", "64", ":", "cx", "+", "64", "]", "\n", "img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# HWC => CHW", "\n", "h5", ".", "add_images", "(", "img", "[", "np", ".", "newaxis", "]", ")", "\n", "\n", "", "print", "(", "(", "'%-40s\\r'", "%", "'Flushing data...'", ")", ")", "\n", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "'Added %d images.'", "%", "num_images", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.create_celeba_hq": [[474, 640], ["print", "os.path.join", "os.path.exists", "print", "os.path.join", "print", "print", "h5tool.HDF5Exporter", "print", "h5tool.HDF5Exporter.close", "print", "print", "print", "len", "print", "open", "numpy.float32().reshape", "print", "len", "print", "open", "dict", "enumerate", "numpy.array", "os.path.join", "PIL.Image.open", "numpy.hypot", "max", "h5tool.create_celeba_hq.rot90"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close"], ["def", "create_celeba_hq", "(", "h5_filename", ",", "celeba_dir", ",", "delta_dir", ",", "data_split", ",", "num_threads", "=", "4", ",", "num_tasks", "=", "100", ")", ":", "\n", "    ", "print", "(", "(", "'Loading CelebA data from %s'", "%", "celeba_dir", ")", ")", "\n", "glob_pattern", "=", "os", ".", "path", ".", "join", "(", "celeba_dir", ",", "'img_celeba'", ",", "'*.jpg'", ")", "\n", "glob_expected", "=", "202599", "\n", "if", "len", "(", "glob", ".", "glob", "(", "glob_pattern", ")", ")", "<", "glob_expected", ":", "\n", "        ", "print", "(", "(", "'Error: Expected to find %d images in %s'", "%", "(", "glob_expected", ",", "glob_pattern", ")", ")", ")", "\n", "return", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "celeba_dir", ",", "'Anno'", ",", "'list_landmarks_celeba.txt'", ")", ",", "'rt'", ")", "as", "file", ":", "\n", "        ", "landmarks", "=", "[", "[", "float", "(", "value", ")", "for", "value", "in", "line", ".", "split", "(", ")", "[", "1", ":", "]", "]", "for", "line", "in", "file", ".", "readlines", "(", ")", "[", "2", ":", "]", "]", "\n", "landmarks", "=", "np", ".", "float32", "(", "landmarks", ")", ".", "reshape", "(", "-", "1", ",", "5", ",", "2", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "h5_filename", ")", ":", "\n", "        ", "print", "(", "\"ERROR! That H5 file exists. Will not overwrite by default since this takes a day to generate, yo.\"", ")", "\n", "return", "\n", "\n", "", "print", "(", "(", "'Loading CelebA-HQ deltas from %s'", "%", "delta_dir", ")", ")", "\n", "import", "hashlib", "\n", "import", "bz2", "\n", "import", "zipfile", "\n", "import", "base64", "\n", "import", "cryptography", ".", "hazmat", ".", "primitives", ".", "hashes", "\n", "import", "cryptography", ".", "hazmat", ".", "backends", "\n", "import", "cryptography", ".", "hazmat", ".", "primitives", ".", "kdf", ".", "pbkdf2", "\n", "import", "cryptography", ".", "fernet", "\n", "glob_pattern", "=", "os", ".", "path", ".", "join", "(", "delta_dir", ",", "'delta*.zip'", ")", "\n", "glob_expected", "=", "30", "\n", "\n", "min_idx", "=", "0", "\n", "max_idx", "=", "300000", "\n", "\n", "if", "data_split", "==", "'train'", ":", "\n", "        ", "max_idx", "=", "182636", "# The validation data starts from file name 182638.jpg which corresponds to idx 182637", "\n", "", "elif", "data_split", "==", "'test'", ":", "\n", "        ", "min_idx", "=", "182637", "\n", "", "else", ":", "\n", "        ", "assert", "(", "False", ")", "\n", "\n", "", "print", "(", "\"Only including idx {} to {}\"", ".", "format", "(", "min_idx", ",", "max_idx", ")", ")", "\n", "\n", "if", "len", "(", "glob", ".", "glob", "(", "glob_pattern", ")", ")", "!=", "glob_expected", ":", "\n", "        ", "print", "(", "(", "'Error: Expected to find %d zips in %s'", "%", "(", "glob_expected", ",", "glob_pattern", ")", ")", ")", "\n", "return", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "delta_dir", ",", "'image_list.txt'", ")", ",", "'rt'", ")", "as", "file", ":", "\n", "        ", "lines", "=", "[", "line", ".", "split", "(", ")", "for", "line", "in", "file", "]", "\n", "fields", "=", "dict", "(", ")", "\n", "for", "idx", ",", "field", "in", "enumerate", "(", "lines", "[", "0", "]", ")", ":", "\n", "            ", "type", "=", "int", "if", "field", ".", "endswith", "(", "'idx'", ")", "else", "str", "\n", "fields", "[", "field", "]", "=", "[", "type", "(", "line", "[", "idx", "]", ")", "for", "line", "in", "lines", "[", "1", ":", "]", "]", "\n", "\n", "", "", "def", "rot90", "(", "v", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "-", "v", "[", "1", "]", ",", "v", "[", "0", "]", "]", ")", "\n", "\n", "", "def", "process_func", "(", "idx", ")", ":", "\n", "        ", "global", "ignored", "\n", "\n", "# Load original image.", "\n", "orig_idx", "=", "fields", "[", "'orig_idx'", "]", "[", "idx", "]", "\n", "\n", "if", "(", "orig_idx", ">", "max_idx", "or", "orig_idx", "<", "min_idx", ")", ":", "\n", "            ", "ignored", "+=", "1", "\n", "print", "(", "\"Ignore {}\"", ".", "format", "(", "fields", "[", "'orig_file'", "]", "[", "idx", "]", ")", ")", "\n", "return", "-", "1", ",", "None", "\n", "\n", "", "orig_file", "=", "fields", "[", "'orig_file'", "]", "[", "idx", "]", "\n", "orig_path", "=", "os", ".", "path", ".", "join", "(", "celeba_dir", ",", "'img_celeba'", ",", "orig_file", ")", "\n", "img", "=", "PIL", ".", "Image", ".", "open", "(", "orig_path", ")", "\n", "\n", "# Choose oriented crop rectangle.", "\n", "lm", "=", "landmarks", "[", "orig_idx", "]", "\n", "eye_avg", "=", "(", "lm", "[", "0", "]", "+", "lm", "[", "1", "]", ")", "*", "0.5", "+", "0.5", "\n", "mouth_avg", "=", "(", "lm", "[", "3", "]", "+", "lm", "[", "4", "]", ")", "*", "0.5", "+", "0.5", "\n", "eye_to_eye", "=", "lm", "[", "1", "]", "-", "lm", "[", "0", "]", "\n", "eye_to_mouth", "=", "mouth_avg", "-", "eye_avg", "\n", "x", "=", "eye_to_eye", "-", "rot90", "(", "eye_to_mouth", ")", "\n", "x", "/=", "np", ".", "hypot", "(", "*", "x", ")", "\n", "x", "*=", "max", "(", "np", ".", "hypot", "(", "*", "eye_to_eye", ")", "*", "2.0", ",", "np", ".", "hypot", "(", "*", "eye_to_mouth", ")", "*", "1.8", ")", "\n", "y", "=", "rot90", "(", "x", ")", "\n", "c", "=", "eye_avg", "+", "eye_to_mouth", "*", "0.1", "\n", "quad", "=", "np", ".", "stack", "(", "[", "c", "-", "x", "-", "y", ",", "c", "-", "x", "+", "y", ",", "c", "+", "x", "+", "y", ",", "c", "+", "x", "-", "y", "]", ")", "\n", "zoom", "=", "1024", "/", "(", "np", ".", "hypot", "(", "*", "x", ")", "*", "2", ")", "\n", "\n", "# Shrink.", "\n", "shrink", "=", "int", "(", "np", ".", "floor", "(", "0.5", "/", "zoom", ")", ")", "\n", "if", "shrink", ">", "1", ":", "\n", "            ", "size", "=", "(", "int", "(", "np", ".", "round", "(", "float", "(", "img", ".", "size", "[", "0", "]", ")", "/", "shrink", ")", ")", ",", "int", "(", "np", ".", "round", "(", "float", "(", "img", ".", "size", "[", "1", "]", ")", "/", "shrink", ")", ")", ")", "\n", "img", "=", "img", ".", "resize", "(", "size", ",", "PIL", ".", "Image", ".", "ANTIALIAS", ")", "\n", "quad", "/=", "shrink", "\n", "zoom", "*=", "shrink", "\n", "\n", "# Crop.", "\n", "", "border", "=", "max", "(", "int", "(", "np", ".", "round", "(", "1024", "*", "0.1", "/", "zoom", ")", ")", ",", "3", ")", "\n", "crop", "=", "(", "int", "(", "np", ".", "floor", "(", "min", "(", "quad", "[", ":", ",", "0", "]", ")", ")", ")", ",", "int", "(", "np", ".", "floor", "(", "min", "(", "quad", "[", ":", ",", "1", "]", ")", ")", ")", ",", "int", "(", "np", ".", "ceil", "(", "max", "(", "quad", "[", ":", ",", "0", "]", ")", ")", ")", ",", "int", "(", "np", ".", "ceil", "(", "max", "(", "quad", "[", ":", ",", "1", "]", ")", ")", ")", ")", "\n", "crop", "=", "(", "max", "(", "crop", "[", "0", "]", "-", "border", ",", "0", ")", ",", "max", "(", "crop", "[", "1", "]", "-", "border", ",", "0", ")", ",", "min", "(", "crop", "[", "2", "]", "+", "border", ",", "img", ".", "size", "[", "0", "]", ")", ",", "min", "(", "crop", "[", "3", "]", "+", "border", ",", "img", ".", "size", "[", "1", "]", ")", ")", "\n", "if", "crop", "[", "2", "]", "-", "crop", "[", "0", "]", "<", "img", ".", "size", "[", "0", "]", "or", "crop", "[", "3", "]", "-", "crop", "[", "1", "]", "<", "img", ".", "size", "[", "1", "]", ":", "\n", "            ", "img", "=", "img", ".", "crop", "(", "crop", ")", "\n", "quad", "-=", "crop", "[", "0", ":", "2", "]", "\n", "\n", "# Simulate super-resolution.", "\n", "", "superres", "=", "int", "(", "np", ".", "exp2", "(", "np", ".", "ceil", "(", "np", ".", "log2", "(", "zoom", ")", ")", ")", ")", "\n", "if", "superres", ">", "1", ":", "\n", "            ", "img", "=", "img", ".", "resize", "(", "(", "img", ".", "size", "[", "0", "]", "*", "superres", ",", "img", ".", "size", "[", "1", "]", "*", "superres", ")", ",", "PIL", ".", "Image", ".", "ANTIALIAS", ")", "\n", "quad", "*=", "superres", "\n", "zoom", "/=", "superres", "\n", "\n", "# Pad.", "\n", "", "pad", "=", "(", "int", "(", "np", ".", "floor", "(", "min", "(", "quad", "[", ":", ",", "0", "]", ")", ")", ")", ",", "int", "(", "np", ".", "floor", "(", "min", "(", "quad", "[", ":", ",", "1", "]", ")", ")", ")", ",", "int", "(", "np", ".", "ceil", "(", "max", "(", "quad", "[", ":", ",", "0", "]", ")", ")", ")", ",", "int", "(", "np", ".", "ceil", "(", "max", "(", "quad", "[", ":", ",", "1", "]", ")", ")", ")", ")", "\n", "pad", "=", "(", "max", "(", "-", "pad", "[", "0", "]", "+", "border", ",", "0", ")", ",", "max", "(", "-", "pad", "[", "1", "]", "+", "border", ",", "0", ")", ",", "max", "(", "pad", "[", "2", "]", "-", "img", ".", "size", "[", "0", "]", "+", "border", ",", "0", ")", ",", "max", "(", "pad", "[", "3", "]", "-", "img", ".", "size", "[", "1", "]", "+", "border", ",", "0", ")", ")", "\n", "if", "max", "(", "pad", ")", ">", "border", "-", "4", ":", "\n", "            ", "pad", "=", "np", ".", "maximum", "(", "pad", ",", "int", "(", "np", ".", "round", "(", "1024", "*", "0.3", "/", "zoom", ")", ")", ")", "\n", "img", "=", "np", ".", "pad", "(", "np", ".", "float32", "(", "img", ")", ",", "(", "(", "pad", "[", "1", "]", ",", "pad", "[", "3", "]", ")", ",", "(", "pad", "[", "0", "]", ",", "pad", "[", "2", "]", ")", ",", "(", "0", ",", "0", ")", ")", ",", "'reflect'", ")", "\n", "h", ",", "w", ",", "_", "=", "img", ".", "shape", "\n", "y", ",", "x", ",", "_", "=", "np", ".", "mgrid", "[", ":", "h", ",", ":", "w", ",", ":", "1", "]", "\n", "mask", "=", "1.0", "-", "np", ".", "minimum", "(", "np", ".", "minimum", "(", "np", ".", "float32", "(", "x", ")", "/", "pad", "[", "0", "]", ",", "np", ".", "float32", "(", "y", ")", "/", "pad", "[", "1", "]", ")", ",", "np", ".", "minimum", "(", "np", ".", "float32", "(", "w", "-", "1", "-", "x", ")", "/", "pad", "[", "2", "]", ",", "np", ".", "float32", "(", "h", "-", "1", "-", "y", ")", "/", "pad", "[", "3", "]", ")", ")", "\n", "blur", "=", "1024", "*", "0.02", "/", "zoom", "\n", "img", "+=", "(", "scipy", ".", "ndimage", ".", "gaussian_filter", "(", "img", ",", "[", "blur", ",", "blur", ",", "0", "]", ")", "-", "img", ")", "*", "np", ".", "clip", "(", "mask", "*", "3.0", "+", "1.0", ",", "0.0", ",", "1.0", ")", "\n", "img", "+=", "(", "np", ".", "median", "(", "img", ",", "axis", "=", "(", "0", ",", "1", ")", ")", "-", "img", ")", "*", "np", ".", "clip", "(", "mask", ",", "0.0", ",", "1.0", ")", "\n", "img", "=", "PIL", ".", "Image", ".", "fromarray", "(", "np", ".", "uint8", "(", "np", ".", "clip", "(", "np", ".", "round", "(", "img", ")", ",", "0", ",", "255", ")", ")", ",", "'RGB'", ")", "\n", "quad", "+=", "pad", "[", "0", ":", "2", "]", "\n", "\n", "# Transform.", "\n", "", "img", "=", "img", ".", "transform", "(", "(", "4096", ",", "4096", ")", ",", "PIL", ".", "Image", ".", "QUAD", ",", "(", "quad", "+", "0.5", ")", ".", "flatten", "(", ")", ",", "PIL", ".", "Image", ".", "BILINEAR", ")", "\n", "img", "=", "img", ".", "resize", "(", "(", "1024", ",", "1024", ")", ",", "PIL", ".", "Image", ".", "ANTIALIAS", ")", "\n", "img", "=", "np", ".", "asarray", "(", "img", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "\n", "# Verify MD5.", "\n", "md5", "=", "hashlib", ".", "md5", "(", ")", "\n", "md5", ".", "update", "(", "img", ".", "tobytes", "(", ")", ")", "\n", "# assert md5.hexdigest() == fields['proc_md5'][idx]  # disable md5 verify", "\n", "\n", "# Load delta image and original JPG.", "\n", "with", "zipfile", ".", "ZipFile", "(", "os", ".", "path", ".", "join", "(", "delta_dir", ",", "'deltas%05d.zip'", "%", "(", "idx", "-", "idx", "%", "1000", ")", ")", ",", "'r'", ")", "as", "zip", ":", "\n", "            ", "delta_bytes", "=", "zip", ".", "read", "(", "'delta%05d.dat'", "%", "idx", ")", "\n", "", "with", "open", "(", "orig_path", ",", "'rb'", ")", "as", "file", ":", "\n", "            ", "orig_bytes", "=", "file", ".", "read", "(", ")", "\n", "\n", "# Decrypt delta image, using original JPG data as decryption key.", "\n", "", "algorithm", "=", "cryptography", ".", "hazmat", ".", "primitives", ".", "hashes", ".", "SHA256", "(", ")", "\n", "backend", "=", "cryptography", ".", "hazmat", ".", "backends", ".", "default_backend", "(", ")", "\n", "salt", "=", "bytes", "(", "orig_file", ",", "'ascii'", ")", "\n", "kdf", "=", "cryptography", ".", "hazmat", ".", "primitives", ".", "kdf", ".", "pbkdf2", ".", "PBKDF2HMAC", "(", "algorithm", "=", "algorithm", ",", "length", "=", "32", ",", "salt", "=", "salt", ",", "iterations", "=", "100000", ",", "backend", "=", "backend", ")", "\n", "key", "=", "base64", ".", "urlsafe_b64encode", "(", "kdf", ".", "derive", "(", "orig_bytes", ")", ")", "\n", "delta", "=", "np", ".", "frombuffer", "(", "bz2", ".", "decompress", "(", "cryptography", ".", "fernet", ".", "Fernet", "(", "key", ")", ".", "decrypt", "(", "delta_bytes", ")", ")", ",", "dtype", "=", "np", ".", "uint8", ")", ".", "reshape", "(", "3", ",", "1024", ",", "1024", ")", "\n", "\n", "# Apply delta image.", "\n", "img", "=", "img", "+", "delta", "\n", "\n", "# Verify MD5.", "\n", "md5", "=", "hashlib", ".", "md5", "(", ")", "\n", "md5", ".", "update", "(", "img", ".", "tobytes", "(", ")", ")", "\n", "# assert md5.hexdigest() == fields['final_md5'][idx]  # disable md5 verify", "\n", "return", "idx", ",", "img", "\n", "\n", "", "print", "(", "(", "'Creating %s'", "%", "h5_filename", ")", ")", "\n", "h5", "=", "HDF5Exporter", "(", "h5_filename", ",", "1024", ",", "3", ")", "\n", "with", "ThreadPool", "(", "num_threads", ")", "as", "pool", ":", "\n", "        ", "print", "(", "(", "'%d / %d\\r'", "%", "(", "0", ",", "len", "(", "fields", "[", "'idx'", "]", ")", ")", ")", ")", "\n", "for", "idx", ",", "img", "in", "pool", ".", "process_items_concurrently", "(", "fields", "[", "'idx'", "]", ",", "process_func", "=", "process_func", ",", "max_items_in_flight", "=", "num_tasks", ")", ":", "\n", "            ", "if", "idx", ">=", "0", ":", "\n", "                ", "h5", ".", "add_images", "(", "img", "[", "np", ".", "newaxis", "]", ")", "\n", "print", "(", "(", "'%d / %d\\r'", "%", "(", "idx", "+", "1", ",", "len", "(", "fields", "[", "'idx'", "]", ")", ")", ")", ")", "\n", "\n", "", "", "", "print", "(", "(", "'%-40s\\r'", "%", "'Flushing data...'", ")", ")", "\n", "h5", ".", "close", "(", ")", "\n", "print", "(", "(", "'%-40s\\r'", "%", "''", ")", ")", "\n", "print", "(", "(", "'Added %d images.'", "%", "len", "(", "fields", "[", "'idx'", "]", ")", ")", ")", "\n", "print", "(", "'Ignored: {}'", ".", "format", "(", "ignored", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.execute_cmdline": [[643, 730], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_subparsers", "h5tool.execute_cmdline.add_command"], "function", ["None"], ["", "def", "execute_cmdline", "(", "argv", ")", ":", "\n", "    ", "prog", "=", "argv", "[", "0", "]", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "prog", "=", "prog", ",", "\n", "description", "=", "'Tool for creating, extracting, and visualizing HDF5 datasets.'", ",", "\n", "epilog", "=", "'Type \"%s <command> -h\" for more information.'", "%", "prog", ")", "\n", "\n", "subparsers", "=", "parser", ".", "add_subparsers", "(", "dest", "=", "'command'", ")", "\n", "def", "add_command", "(", "cmd", ",", "desc", ",", "example", "=", "None", ")", ":", "\n", "        ", "epilog", "=", "'Example: %s %s'", "%", "(", "prog", ",", "example", ")", "if", "example", "is", "not", "None", "else", "None", "\n", "return", "subparsers", ".", "add_parser", "(", "cmd", ",", "description", "=", "desc", ",", "help", "=", "desc", ",", "epilog", "=", "epilog", ")", "\n", "\n", "", "p", "=", "add_command", "(", "'inspect'", ",", "'Print information about HDF5 dataset.'", ",", "\n", "'inspect mnist-32x32.h5'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to inspect'", ")", "\n", "\n", "p", "=", "add_command", "(", "'compare'", ",", "'Compare two HDF5 datasets.'", ",", "\n", "'compare mydataset.h5 mnist-32x32.h5'", ")", "\n", "p", ".", "add_argument", "(", "'first_h5'", ",", "help", "=", "'First HDF5 file to compare'", ")", "\n", "p", ".", "add_argument", "(", "'second_h5'", ",", "help", "=", "'Second HDF5 file to compare'", ")", "\n", "\n", "p", "=", "add_command", "(", "'display'", ",", "'Display images in HDF5 dataset.'", ",", "\n", "'display mnist-32x32.h5'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to visualize'", ")", "\n", "p", ".", "add_argument", "(", "'--start'", ",", "help", "=", "'Start index (inclusive)'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "p", ".", "add_argument", "(", "'--stop'", ",", "help", "=", "'Stop index (exclusive)'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "p", ".", "add_argument", "(", "'--step'", ",", "help", "=", "'Step between consecutive indices'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "\n", "p", "=", "add_command", "(", "'extract'", ",", "'Extract images from HDF5 dataset.'", ",", "\n", "'extract mnist-32x32.h5 cifar10-images'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to extract'", ")", "\n", "p", ".", "add_argument", "(", "'output_dir'", ",", "help", "=", "'Directory to extract the images into'", ")", "\n", "p", ".", "add_argument", "(", "'--start'", ",", "help", "=", "'Start index (inclusive)'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "p", ".", "add_argument", "(", "'--stop'", ",", "help", "=", "'Stop index (exclusive)'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "p", ".", "add_argument", "(", "'--step'", ",", "help", "=", "'Step between consecutive indices'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "\n", "p", "=", "add_command", "(", "'create_custom'", ",", "'Create HDF5 dataset for custom images.'", ",", "\n", "'create_custom mydataset.h5 myimagedir'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to create'", ")", "\n", "p", ".", "add_argument", "(", "'image_dir'", ",", "help", "=", "'Directory to read the images from'", ")", "\n", "\n", "p", "=", "add_command", "(", "'create_mnist'", ",", "'Create HDF5 dataset for MNIST.'", ",", "\n", "'create_mnist mnist-32x32.h5 ~/mnist --export_labels'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to create'", ")", "\n", "p", ".", "add_argument", "(", "'mnist_dir'", ",", "help", "=", "'Directory to read MNIST data from'", ")", "\n", "p", ".", "add_argument", "(", "'--export_labels'", ",", "help", "=", "'Create *-labels.npy alongside the HDF5'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "p", "=", "add_command", "(", "'create_mnist_rgb'", ",", "'Create HDF5 dataset for MNIST-RGB.'", ",", "\n", "'create_mnist_rgb mnist-rgb-32x32.h5 ~/mnist'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to create'", ")", "\n", "p", ".", "add_argument", "(", "'mnist_dir'", ",", "help", "=", "'Directory to read MNIST data from'", ")", "\n", "p", ".", "add_argument", "(", "'--num_images'", ",", "help", "=", "'Number of composite images to create (default: 1000000)'", ",", "type", "=", "int", ",", "default", "=", "1000000", ")", "\n", "p", ".", "add_argument", "(", "'--random_seed'", ",", "help", "=", "'Random seed (default: 123)'", ",", "type", "=", "int", ",", "default", "=", "123", ")", "\n", "\n", "p", "=", "add_command", "(", "'create_cifar10'", ",", "'Create HDF5 dataset for CIFAR-10.'", ",", "\n", "'create_cifar10 cifar-10-32x32.h5 ~/cifar10 --export_labels'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to create'", ")", "\n", "p", ".", "add_argument", "(", "'cifar10_dir'", ",", "help", "=", "'Directory to read CIFAR-10 data from'", ")", "\n", "p", ".", "add_argument", "(", "'--export_labels'", ",", "help", "=", "'Create *-labels.npy alongside the HDF5'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "p", "=", "add_command", "(", "'create_lsun'", ",", "'Create HDF5 dataset for single LSUN category.'", ",", "\n", "'create_lsun lsun-airplane-256x256-100k.h5 ~/lsun/airplane_lmdb --resolution 256 --max_images 100000'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to create'", ")", "\n", "p", ".", "add_argument", "(", "'lmdb_dir'", ",", "help", "=", "'Directory to read LMDB database from'", ")", "\n", "p", ".", "add_argument", "(", "'--resolution'", ",", "help", "=", "'Output resolution (default: 256)'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "p", ".", "add_argument", "(", "'--max_images'", ",", "help", "=", "'Maximum number of images (default: none)'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "\n", "p", "=", "add_command", "(", "'create_celeba'", ",", "'Create HDF5 dataset for CelebA.'", ",", "\n", "'create_celeba celeba-128x128.h5 ~/celeba'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to create'", ")", "\n", "p", ".", "add_argument", "(", "'celeba_dir'", ",", "help", "=", "'Directory to read CelebA data from'", ")", "\n", "p", ".", "add_argument", "(", "'--cx'", ",", "help", "=", "'Center X coordinate (default: 89)'", ",", "type", "=", "int", ",", "default", "=", "89", ")", "\n", "p", ".", "add_argument", "(", "'--cy'", ",", "help", "=", "'Center Y coordinate (default: 121)'", ",", "type", "=", "int", ",", "default", "=", "121", ")", "\n", "\n", "p", "=", "add_command", "(", "'create_celeba_hq'", ",", "'Create HDF5 dataset for CelebA-HQ.'", ",", "\n", "'create_celeba_hq celeba-hq-1024x1024.h5 ~/celeba ~/celeba-hq-deltas'", ")", "\n", "p", ".", "add_argument", "(", "'h5_filename'", ",", "help", "=", "'HDF5 file to create'", ")", "\n", "p", ".", "add_argument", "(", "'celeba_dir'", ",", "help", "=", "'Directory to read CelebA data from'", ")", "\n", "p", ".", "add_argument", "(", "'delta_dir'", ",", "help", "=", "'Directory to read CelebA-HQ deltas from'", ")", "\n", "p", ".", "add_argument", "(", "'data_split'", ",", "help", "=", "'[train | test] dataset type to create'", ")", "\n", "p", ".", "add_argument", "(", "'--num_threads'", ",", "help", "=", "'Number of concurrent threads (default: 4)'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "p", ".", "add_argument", "(", "'--num_tasks'", ",", "help", "=", "'Number of concurrent processing tasks (default: 100)'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", "argv", "[", "1", ":", "]", ")", "\n", "func", "=", "globals", "(", ")", "[", "args", ".", "command", "]", "\n", "del", "args", ".", "command", "\n", "func", "(", "**", "vars", "(", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.hubconf.ffhq512": [[6, 18], ["pioneer.session.Session"], "function", ["None"], ["def", "ffhq512", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" The Automodulator FFHQ 512x512 pre-trained model\n    \"\"\"", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint_index", "=", "42420000", "\n", "save_dir", "=", "'https://zenodo.org/record/4298894/files/42420000_state.pth?download=1'", "\n", "", "else", ":", "\n", "        ", "checkpoint_index", "=", "0", "\n", "save_dir", "=", "'ffhq512'", "\n", "\n", "", "return", "pioneer", ".", "session", ".", "Session", "(", "pretrained", "=", "pretrained", ",", "save_dir", "=", "save_dir", ",", "transform_key", "=", "'ffhq512'", ",", "start_iteration", "=", "checkpoint_index", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.hubconf.celebahq256": [[19, 31], ["pioneer.session.Session"], "function", ["None"], ["", "def", "celebahq256", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" The Automodulator CelebA-HQ 256x256 pre-trained model\n    \"\"\"", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint_index", "=", "31877148", "\n", "save_dir", "=", "'https://zenodo.org/record/4298894/files/31877148_state.pth?download=1'", "\n", "", "else", ":", "\n", "        ", "checkpoint_index", "=", "0", "\n", "save_dir", "=", "'celebaHQ256'", "\n", "\n", "", "return", "pioneer", ".", "session", ".", "Session", "(", "pretrained", "=", "pretrained", ",", "save_dir", "=", "save_dir", ",", "start_iteration", "=", "checkpoint_index", ",", "arch", "=", "'small'", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.hubconf.ffhq256": [[32, 44], ["pioneer.session.Session"], "function", ["None"], ["", "def", "ffhq256", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" The Automodulator FFHQ 256x256 pre-trained model\n    \"\"\"", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint_index", "=", "34740000", "\n", "save_dir", "=", "'https://zenodo.org/record/4298894/files/34740000_state.pth?download=1'", "\n", "", "else", ":", "\n", "        ", "checkpoint_index", "=", "0", "\n", "save_dir", "=", "'ffhq256'", "\n", "\n", "", "return", "pioneer", ".", "session", ".", "Session", "(", "pretrained", "=", "pretrained", ",", "save_dir", "=", "save_dir", ",", "start_iteration", "=", "checkpoint_index", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.hubconf.lsuncars256": [[45, 58], ["pioneer.session.Session"], "function", ["None"], ["", "def", "lsuncars256", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" The Automodulator LSUN Cars 256x256 pre-trained model\n    \"\"\"", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint_index", "=", "32057140", "\n", "save_dir", "=", "'https://zenodo.org/record/4298894/files/32057140_state.pth?download=1'", "\n", "", "else", ":", "\n", "        ", "checkpoint_index", "=", "0", "\n", "save_dir", "=", "'lsunCars256'", "\n", "\n", "", "return", "pioneer", ".", "session", ".", "Session", "(", "pretrained", "=", "pretrained", ",", "save_dir", "=", "save_dir", ",", "start_iteration", "=", "checkpoint_index", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.None.hubconf.lsunbedrooms256": [[59, 71], ["pioneer.session.Session"], "function", ["None"], ["", "def", "lsunbedrooms256", "(", "pretrained", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" The Automodulator LSUN Bedrooms 256x256 pre-trained model\n    \"\"\"", "\n", "if", "pretrained", ":", "\n", "        ", "checkpoint_index", "=", "27574284", "\n", "save_dir", "=", "'https://zenodo.org/record/4298894/files/27574284_state.pth?download=1'", "\n", "", "else", ":", "\n", "        ", "checkpoint_index", "=", "0", "\n", "save_dir", "=", "'lsunBedrooms256'", "\n", "\n", "", "return", "pioneer", ".", "session", ".", "Session", "(", "pretrained", "=", "pretrained", ",", "save_dir", "=", "save_dir", ",", "start_iteration", "=", "checkpoint_index", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.parse_args": [[11, 91], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PIONEER'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_path'", ",", "type", "=", "str", ",", "help", "=", "'training dataset root directory or H5 file'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'testing dataset root directory or H5 file'", ")", "\n", "parser", ".", "add_argument", "(", "'--aux_inpath'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Input path of specified dataset to reconstruct or interpolate for'", ")", "\n", "parser", ".", "add_argument", "(", "'--aux_outpath'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Output path of specified dataset to reconstruct or interpolate for'", ")", "\n", "parser", ".", "add_argument", "(", "'--z_inpath'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Input path to bcolz z input'", ")", "\n", "parser", ".", "add_argument", "(", "'--x_outpath'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Output path for the samples generated from z_inpath'", ")", "\n", "parser", ".", "add_argument", "(", "'--testonly'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Run in test mode. Quit after the tests.'", ")", "\n", "parser", ".", "add_argument", "(", "'--import_old_gen_format'", ",", "action", "=", "'store_true'", ",", "help", "=", "''", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--rejection_sampling'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Percentage of test-time random samples to be discarded based on latent reconstruction loss'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--phase_offset'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Use the reloaded model but start fresh from next phase (when manually moving to the next )'", ")", "\n", "parser", ".", "add_argument", "(", "'--step_offset'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Use the reloaded model but ignore the given number of steps (use -1 for all steps)'", ")", "\n", "parser", ".", "add_argument", "(", "'--blurSN'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_LN'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Disable layer noise'", ")", "\n", "parser", ".", "add_argument", "(", "'--small_darch'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Revert to the half-number of channels in high-resolution decoder feature maps'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--randomMixN'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'use 2 here to create a random mix if sample_N>0'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--upsampling'", ",", "default", "=", "'nearest'", ",", "help", "=", "'nearest|bilinear'", ")", "\n", "parser", ".", "add_argument", "(", "'-d'", ",", "'--data'", ",", "default", "=", "'celeba'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'celeba'", ",", "'lsun'", ",", "'cifar10'", ",", "'celebaHQ'", ",", "'ffhq'", "]", ",", "help", "=", "(", "'Specify dataset. '", "\n", "'Currently celeba, lsun and cifar10 are supported'", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--KL'", ",", "default", "=", "'qp'", ",", "help", "=", "'The KL divergence direction [pq|qp]'", ")", "\n", "parser", ".", "add_argument", "(", "'--match_x_metric'", ",", "default", "=", "'robust'", ",", "help", "=", "'none|L1|L2|cos|robust'", ")", "\n", "parser", ".", "add_argument", "(", "'--match_z_metric'", ",", "default", "=", "'cos'", ",", "help", "=", "'none|L1|L2|cos'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise'", ",", "default", "=", "'sphere'", ",", "help", "=", "'normal|sphere'", ")", "\n", "parser", ".", "add_argument", "(", "'--summary_dir'", ",", "default", "=", "'log/pine/runs'", ",", "help", "=", "'Tensorflow summaries directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_dir'", ",", "default", "=", "None", ",", "help", "=", "'folder to output images'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_TB'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Do not create Tensorboard logs'", ")", "\n", "parser", ".", "add_argument", "(", "'--start_iteration'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ")", "\n", "parser", ".", "add_argument", "(", "'--use_ALQ'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Reserved for future use'", ")", "\n", "parser", ".", "add_argument", "(", "'--images_per_stage'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--no_load_SNU'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Do not load the U-matrix of spectral normalization, even if available'", ")", "\n", "parser", ".", "add_argument", "(", "'--hexmode'", ",", "action", "=", "'store_true'", ",", "help", "=", "'If interpolate_N is given, do it in hexagonal mode'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--intermediate_zreco'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--stylefc'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--stylemix_E'", ",", "type", "=", "float", ",", "default", "=", "0.25", ",", "help", "=", "'Style mixing proportion on every round of encoder training. 0.25 should be ok.'", ")", "\n", "parser", ".", "add_argument", "(", "'--stylemix_D'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'Style mixing proportion on every SECOND (in average) round of encoder training. 0.5 should be ok.'", ")", "\n", "parser", ".", "add_argument", "(", "'--match_x'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "''", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--matching_phase_x'", ",", "type", "=", "float", ",", "default", "=", "1.5", ")", "\n", "parser", ".", "add_argument", "(", "'--force_alpha'", ",", "type", "=", "float", ",", "default", "=", "-", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--start_phase'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--max_phase'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'The highest progressive growth phase that we train for, e.g. phase 4 means 64x64. If not given, we use dataset-based defaults.'", ")", "\n", "parser", ".", "add_argument", "(", "'--reset_optimizers'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Even if reloading from a checkpoint, reset the optimizer states.'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_cycle'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "parser", ".", "add_argument", "(", "'--total_kimg'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'The total number of samples to train for. 1 kimg = 1000 samples. Default values should be fine.'", ")", "\n", "parser", ".", "add_argument", "(", "'--manual_seed'", ",", "type", "=", "int", ",", "default", "=", "123", ")", "\n", "parser", ".", "add_argument", "(", "'--no_progression'", ",", "action", "=", "'store_true'", ",", "help", "=", "'No progressive growth. Set the network to the target size from the beginning. Note that the step count starts from non-zero to make the results comparable.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--n_generator'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--gnn'", ",", "action", "=", "'store_true'", ",", "help", "=", "'alpha-fade equalization'", ")", "\n", "# Special modes:", "\n", "parser", ".", "add_argument", "(", "'--dump_trainingset_N'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--dump_trainingset_dir'", ",", "type", "=", "str", ",", "default", "=", "'.'", ")", "\n", "parser", ".", "add_argument", "(", "'--interpolate_N'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Carry out the given number of interpolation runs (between 4 input images)'", ")", "\n", "parser", ".", "add_argument", "(", "'--reconstructions_N'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'The number of reconstructions to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_N'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'The number of random samples to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_dir'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "'Evaluation samples storage location'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--flip_invariance_layer'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'The flip invariance layer (dah). Try 2. -1 is OFF'", ")", "\n", "parser", ".", "add_argument", "(", "'--phi_ada_cotrain'", ",", "action", "=", "'store_true'", ",", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--blur_layer'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'The first layer at which blur is applied. 9 or above is OFF.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lsunm02e'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# These are separate for historical reasons, only their sum is relevant (e.g. 511+1)", "\n", "parser", ".", "add_argument", "(", "'--nz'", ",", "type", "=", "int", ",", "default", "=", "511", ")", "\n", "parser", ".", "add_argument", "(", "'--n_label'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--hub'", ",", "type", "=", "str", ",", "default", "=", "'AaltoVision/automodulator'", ",", "help", "=", "'The hub from which to load the models, unless (local) save_dir is not given. E.g. AaltoVision/automodulator:master'", ")", "\n", "parser", ".", "add_argument", "(", "'--hub_model'", ",", "type", "=", "str", ",", "choices", "=", "[", "'lsunbedrooms256'", ",", "'lsuncars256'", ",", "'celebahq256'", ",", "'ffhq256'", ",", "'ffhq512'", "]", ")", "\n", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.log_args": [[94, 100], ["open", "open.write", "vars().items", "open.close", "open.write", "vars"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close"], ["def", "log_args", "(", "args", ")", ":", "\n", "    ", "f", "=", "open", "(", "'{}/config.txt'", ".", "format", "(", "args", ".", "save_dir", ")", ",", "'a'", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "for", "key", ",", "val", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "        ", "f", ".", "write", "(", "\"{}={}\\n\"", ".", "format", "(", "key", ",", "val", ")", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.init": [[101, 196], ["torch.cuda.device_count", "torch.cuda.is_available", "print", "print", "print", "int", "torch.device", "torch.device", "os.path.exists", "os.listdir", "print", "print", "print", "filename.split", "print", "int", "int"], "function", ["None"], ["", "def", "init", "(", ")", ":", "\n", "    ", "global", "args", "\n", "\n", "args", ".", "run_mode", "=", "RUN_TRAIN", "\n", "if", "args", ".", "dump_trainingset_N", ">", "0", ":", "\n", "        ", "args", ".", "run_mode", "=", "RUN_DUMP", "\n", "", "elif", "args", ".", "testonly", ":", "\n", "        ", "args", ".", "run_mode", "=", "RUN_TEST", "\n", "\n", "", "assert", "(", "args", ".", "run_mode", "!=", "RUN_DUMP", "or", "args", ".", "dump_trainingset_dir", ")", "\n", "assert", "(", "args", ".", "run_mode", "!=", "RUN_TRAIN", "or", "(", "args", ".", "train_path", "and", "args", ".", "test_path", ")", ")", "\n", "# Test path or aux test path is needed if we run tests other than just random-sampling", "\n", "assert", "(", "args", ".", "run_mode", "!=", "RUN_TEST", "or", "args", ".", "test_path", "or", "args", ".", "aux_inpath", "or", "args", ".", "z_inpath", "or", "(", "args", ".", "interpolate_N", "<=", "0", "and", "args", ".", "reconstructions_N", "<=", "0", "and", "args", ".", "sample_N", ">", "0", ")", ")", "\n", "\n", "assert", "(", "args", ".", "step_offset", "!=", "0", "or", "args", ".", "phase_offset", "==", "0", ")", "\n", "\n", "args", ".", "n_critic", "=", "1", "\n", "args", ".", "nc", "=", "3", "\n", "\n", "args", ".", "use_loss_x_reco", "=", "True", "\n", "args", ".", "use_real_x_KL", "=", "True", "\n", "\n", "args", ".", "use_loss_fake_D_KL", "=", "True", "\n", "\n", "args", ".", "use_loss_z_reco", "=", "True", "\n", "args", ".", "use_loss_KL_z", "=", "True", "\n", "\n", "args", ".", "match_z", "=", "100", "\n", "args", ".", "fake_D_KL_scale", "=", "0.1", "\n", "args", ".", "fake_G_KL_scale", "=", "args", ".", "fake_D_KL_scale", "\n", "args", ".", "real_x_KL_scale", "=", "0.1", "\n", "\n", "args", ".", "use_TB", "=", "not", "args", ".", "no_TB", "and", "not", "args", ".", "testonly", "\n", "args", ".", "load_SNU", "=", "not", "args", ".", "no_load_SNU", "\n", "args", ".", "use_layer_noise", "=", "not", "args", ".", "no_LN", "\n", "\n", "args", ".", "sample_mirroring", "=", "True", "\n", "if", "args", ".", "testonly", ":", "\n", "        ", "args", ".", "sample_mirroring", "=", "False", "\n", "print", "(", "\"In test mode, sample mirroring is disabled automatically.\"", ")", "\n", "\n", "", "args", ".", "resize_training_data", "=", "True", "# If you already have the right size, skip resize ops here, e.g. using /data/celeba_3k/train/resize_128", "\n", "\n", "args", ".", "train_mode", "=", "MODE_CYCLIC", "\n", "\n", "if", "args", ".", "images_per_stage", "==", "-", "1", ":", "\n", "        ", "args", ".", "images_per_stage", "=", "2400e3", "#if args.data != 'celebaHQ' else 4800e3", "\n", "\n", "", "if", "args", ".", "max_phase", "==", "-", "1", ":", "\n", "        ", "if", "args", ".", "data", "==", "'celebaHQ'", "or", "args", ".", "data", "==", "'lsun'", ":", "\n", "            ", "args", ".", "max_phase", "=", "6", "\n", "", "elif", "args", ".", "data", "==", "'ffhq'", ":", "\n", "            ", "args", ".", "max_phase", "=", "7", "\n", "", "elif", "args", ".", "data", "!=", "'cifar10'", ":", "\n", "            ", "args", ".", "max_phase", "=", "5", "\n", "", "else", ":", "\n", "            ", "args", ".", "max_phase", "=", "3", "\n", "\n", "# Due to changing batch sizes in different stages, we control the length of training by the total number of samples", "\n", "", "", "if", "args", ".", "total_kimg", "<", "0", ":", "\n", "        ", "args", ".", "total_kimg", "=", "int", "(", "args", ".", "images_per_stage", "*", "(", "args", ".", "max_phase", "+", "2", ")", "/", "1000", ")", "#All stages once, the last stage trained twice.", "\n", "\n", "", "args", ".", "h5", "=", "(", "not", "args", ".", "test_path", "is", "None", ")", "and", "args", ".", "test_path", "[", "-", "3", ":", "]", "==", "'.h5'", "\n", "assert", "(", "args", ".", "data", "==", "'celebaHQ'", "or", "not", "args", ".", "h5", ")", "#only celebaHQ supports .h5 atm.", "\n", "\n", "args", ".", "gpu_count", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "# Set to 1 manually if don't want multi-GPU support", "\n", "\n", "args", ".", "device", "=", "None", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "args", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "print", "(", "args", ")", "\n", "\n", "print", "(", "\"Total training samples up to {}k. Max phase for dataset {} is {}. Once the maximum phase is trained the full round, we continue training that phase.\"", ".", "format", "(", "args", ".", "total_kimg", ",", "args", ".", "data", ",", "args", ".", "max_phase", ")", ")", "\n", "\n", "import", "os", "\n", "# If save_dir is provided but checkpoint ID (start_iteration) is not, we try loading the latest iteration.", "\n", "# If save_dir is not given, both the checkpoint ID and the model are loaded from the Hub", "\n", "if", "args", ".", "start_iteration", "==", "-", "1", "and", "not", "args", ".", "save_dir", "is", "None", ":", "\n", "        ", "cppath", "=", "args", ".", "save_dir", "+", "'/checkpoint'", "\n", "if", "os", ".", "path", ".", "exists", "(", "cppath", ")", ":", "\n", "            ", "for", "filename", "in", "os", ".", "listdir", "(", "cppath", ")", ":", "\n", "                ", "idp", "=", "filename", ".", "split", "(", "'_state'", ")", "\n", "if", "'_state'", "in", "filename", "and", "idp", "[", "0", "]", "[", "0", "]", "!=", "'l'", ":", "# >= '0' and idp[0] <= '9':", "\n", "                    ", "print", "(", "idp", "[", "0", "]", ")", "\n", "if", "int", "(", "idp", "[", "0", "]", ")", ">", "args", ".", "start_iteration", ":", "\n", "                        ", "args", ".", "start_iteration", "=", "int", "(", "idp", "[", "0", "]", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "print", "(", "'Save directory does not exist. Will create.'", ")", "\n", "", "if", "args", ".", "start_iteration", "!=", "-", "1", ":", "\n", "            ", "print", "(", "\"\\nLoading the largest state number {}\\n\"", ".", "format", "(", "args", ".", "start_iteration", ")", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "start_iteration", "=", "0", "\n", "print", "(", "'start_iteration=-1 given which indicates the latest state, but no state found. Starting from step 0.'", ")", ";", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.get_config": [[197, 202], ["config.parse_args"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.parse_args"], ["", "", "", "def", "get_config", "(", ")", ":", "\n", "    ", "global", "args", "\n", "if", "args", "==", "None", ":", "\n", "        ", "args", "=", "parse_args", "(", ")", "\n", "", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.reconstruction_dryrun": [[20, 46], ["generator.eval", "encoder.eval", "pioneer.utils.requires_grad", "pioneer.utils.requires_grad", "session.getReso", "print", "next", "torch.autograd.Variable().to", "range", "encoder.train", "generator.train", "session.getResoPhase", "pioneer.data.Utils.sample_data", "pioneer.data.Utils.sample_data2", "encoder().detach", "pioneer.utils.split_labels_out_of_latent", "generator().detach", "torch.autograd.Variable", "encoder", "generator", "session.getResoPhase"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.split_labels_out_of_latent", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["    ", "def", "reconstruction_dryrun", "(", "generator", ",", "encoder", ",", "loader", ",", "session", ")", ":", "\n", "        ", "generator", ".", "eval", "(", ")", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "utils", ".", "requires_grad", "(", "generator", ",", "False", ")", "\n", "utils", ".", "requires_grad", "(", "encoder", ",", "False", ")", "\n", "\n", "reso", "=", "session", ".", "getReso", "(", ")", "\n", "\n", "warmup_rounds", "=", "200", "\n", "print", "(", "'Warm-up rounds: {}'", ".", "format", "(", "warmup_rounds", ")", ")", "\n", "\n", "if", "session", ".", "getResoPhase", "(", ")", "<", "1", ":", "\n", "            ", "dataset", "=", "data", ".", "Utils", ".", "sample_data", "(", "loader", ",", "4", ",", "reso", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "data", ".", "Utils", ".", "sample_data2", "(", "loader", ",", "4", ",", "reso", ",", "session", ")", "\n", "", "real_image", ",", "_", "=", "next", "(", "dataset", ")", "\n", "x", "=", "Variable", "(", "real_image", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "warmup_rounds", ")", ":", "\n", "            ", "ex", "=", "encoder", "(", "x", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", ".", "detach", "(", ")", "\n", "ex", ",", "label", "=", "utils", ".", "split_labels_out_of_latent", "(", "ex", ")", "\n", "generator", "(", "ex", ",", "label", ",", "session", ".", "phase", ",", "session", ".", "alpha", ")", ".", "detach", "(", ")", "\n", "\n", "", "encoder", ".", "train", "(", ")", "\n", "generator", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.make": [[48, 85], ["pioneer.utils.requires_grad", "bcolz.carray", "print", "print", "range", "os.path.exists", "os.makedirs", "numpy.shape", "numpy.shape", "int", "min", "pioneer.utils.split_labels_out_of_latent", "generator().detach", "enumerate", "torch.from_numpy", "torchvision.utils.save_image", "zrange.astype", "generator", "str"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.split_labels_out_of_latent"], ["", "@", "staticmethod", "\n", "def", "make", "(", "generator", ",", "session", ",", "writer", ")", ":", "\n", "        ", "import", "bcolz", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "x_outpath", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "x_outpath", ")", "\n", "\n", "", "utils", ".", "requires_grad", "(", "generator", ",", "False", ")", "\n", "\n", "z", "=", "bcolz", ".", "carray", "(", "rootdir", "=", "args", ".", "z_inpath", ")", "\n", "print", "(", "\"Loading external z from {}, shape:\"", ".", "format", "(", "args", ".", "z_inpath", ")", ")", "\n", "print", "(", "np", ".", "shape", "(", "z", ")", ")", "\n", "N", "=", "np", ".", "shape", "(", "z", ")", "[", "0", "]", "\n", "\n", "samplesRepeatN", "=", "1", "+", "int", "(", "N", "/", "8", ")", "#Assume large files...", "\n", "samplesDone", "=", "0", "\n", "for", "outer_count", "in", "range", "(", "samplesRepeatN", ")", ":", "\n", "            ", "samplesN", "=", "min", "(", "8", ",", "N", "-", "samplesDone", ")", "\n", "if", "samplesN", "<=", "0", ":", "\n", "                ", "break", "\n", "", "zrange", "=", "z", "[", "samplesDone", ":", "samplesDone", "+", "samplesN", ",", ":", "]", "\n", "myz", ",", "input_class", "=", "utils", ".", "split_labels_out_of_latent", "(", "torch", ".", "from_numpy", "(", "zrange", ".", "astype", "(", "np", ".", "float32", ")", ")", ")", "\n", "new_imgs", "=", "generator", "(", "\n", "myz", ",", "\n", "input_class", ",", "\n", "session", ".", "phase", ",", "\n", "session", ".", "alpha", ")", ".", "detach", "(", ")", "#.data.cpu()", "\n", "\n", "for", "ii", ",", "img", "in", "enumerate", "(", "new_imgs", ")", ":", "\n", "                ", "torchvision", ".", "utils", ".", "save_image", "(", "\n", "img", ",", "\n", "'{}/{}.png'", ".", "format", "(", "args", ".", "x_outpath", ",", "str", "(", "ii", "+", "outer_count", "*", "8", ")", ")", ",", "#.zfill(6)", "\n", "nrow", "=", "args", ".", "n_label", ",", "\n", "normalize", "=", "True", ",", "\n", "range", "=", "(", "-", "1", ",", "1", ")", ",", "\n", "padding", "=", "0", ")", "\n", "\n", "", "samplesDone", "+=", "samplesN", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.generate_intermediate_samples": [[86, 187], ["generator.eval", "generator.train", "torch.no_grad", "pioneer.utils.requires_grad", "session.getReso", "range", "max", "os.path.exists", "os.makedirs", "range", "int", "str().zfill", "min", "min", "range", "images.append", "myzs.append", "range", "torchvision.utils.save_image", "PIL.Image.open", "PIL.Image.open.resize", "Image.open.resize.save", "print", "enumerate", "int", "int", "torch.autograd.Variable().to", "pioneer.utils.normalize", "generator().detach", "print", "pioneer.utils.gen_seq().detach", "int", "session.encoder().detach", "pioneer.utils.mismatchV", "torch.sort", "max", "os.path.exists", "os.makedirs", "str().zfill", "torch.cat", "torchvision.utils.save_image", "str", "numpy.ceil", "numpy.ceil", "torch.cat", "int", "filtered_images.append", "str().zfill", "torch.autograd.Variable", "generator", "pioneer.utils.gen_seq", "len", "session.encoder", "str", "torch.randn", "torch.autograd.Variable", "session.getResoPhase", "len", "str", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatchV", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["", "", "@", "staticmethod", "\n", "def", "generate_intermediate_samples", "(", "generator", ",", "global_i", ",", "session", ",", "writer", "=", "None", ",", "collateImages", "=", "True", ")", ":", "\n", "        ", "generator", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "save_root", "=", "args", ".", "sample_dir", "if", "args", ".", "sample_dir", "!=", "None", "else", "args", ".", "save_dir", "\n", "\n", "utils", ".", "requires_grad", "(", "generator", ",", "False", ")", "\n", "\n", "# Total number is samplesRepeatN * colN * rowN", "\n", "# e.g. for 51200 samples, outcome is 5*80*128. Please only give multiples of 128 here.", "\n", "samplesRepeatN", "=", "max", "(", "1", ",", "int", "(", "args", ".", "sample_N", "/", "128", ")", ")", "if", "not", "collateImages", "else", "1", "\n", "reso", "=", "session", ".", "getReso", "(", ")", "\n", "\n", "if", "not", "collateImages", ":", "\n", "                ", "special_dir", "=", "'{}/sample/{}'", ".", "format", "(", "save_root", ",", "str", "(", "global_i", ")", ".", "zfill", "(", "6", ")", ")", "\n", "while", "os", ".", "path", ".", "exists", "(", "special_dir", ")", ":", "\n", "                    ", "special_dir", "+=", "'_'", "\n", "\n", "", "os", ".", "makedirs", "(", "special_dir", ")", "\n", "\n", "", "for", "outer_count", "in", "range", "(", "samplesRepeatN", ")", ":", "\n", "\n", "                ", "colN", "=", "1", "if", "not", "collateImages", "else", "min", "(", "10", ",", "int", "(", "np", ".", "ceil", "(", "args", ".", "sample_N", "/", "4.0", ")", ")", ")", "\n", "rowN", "=", "128", "if", "not", "collateImages", "else", "min", "(", "5", ",", "int", "(", "np", ".", "ceil", "(", "args", ".", "sample_N", "/", "4.0", ")", ")", ")", "\n", "images", "=", "[", "]", "\n", "myzs", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "rowN", ")", ":", "\n", "                    ", "myz", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                       ", "myz0", "=", "Variable", "(", "torch", ".", "randn", "(", "args", ".", "n_label", "*", "colN", ",", "args", ".", "nz", "+", "1", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "myz", "[", "i", "]", "=", "utils", ".", "normalize", "(", "myz0", ")", "\n", "#myz[i], input_class = utils.split_labels_out_of_latent(myz0)", "\n", "\n", "", "if", "args", ".", "randomMixN", "<=", "1", ":", "\n", "                        ", "new_imgs", "=", "generator", "(", "\n", "myz", "[", "0", "]", ",", "\n", "None", ",", "# input_class,", "\n", "session", ".", "phase", ",", "\n", "session", ".", "alpha", ")", ".", "detach", "(", ")", "#.data.cpu()", "\n", "", "else", ":", "\n", "                        ", "max_i", "=", "session", ".", "phase", "\n", "style_layer_begin", "=", "2", "#np.random.randint(low=1, high=(max_i+1))", "\n", "print", "(", "\"Cut at layer {} for the next {} random samples.\"", ".", "format", "(", "style_layer_begin", ",", "(", "myz", "[", "0", "]", ".", "shape", ")", ")", ")", "\n", "\n", "new_imgs", "=", "utils", ".", "gen_seq", "(", "[", "(", "myz", "[", "0", "]", ",", "0", ",", "style_layer_begin", ")", ",", "\n", "(", "myz", "[", "1", "]", ",", "style_layer_begin", ",", "-", "1", ")", "\n", "]", ",", "generator", ",", "session", ")", ".", "detach", "(", ")", "\n", "\n", "", "images", ".", "append", "(", "new_imgs", ")", "\n", "myzs", ".", "append", "(", "myz", "[", "0", "]", ")", "# TODO: Support mixed latents with rejection sampling", "\n", "\n", "", "if", "args", ".", "rejection_sampling", ">", "0", "and", "not", "collateImages", ":", "\n", "                    ", "filtered_images", "=", "[", "]", "\n", "batch_size", "=", "8", "\n", "for", "b", "in", "range", "(", "int", "(", "len", "(", "images", ")", "/", "batch_size", ")", ")", ":", "\n", "                        ", "img_batch", "=", "images", "[", "b", "*", "batch_size", ":", "(", "b", "+", "1", ")", "*", "batch_size", "]", "\n", "reco_z", "=", "session", ".", "encoder", "(", "Variable", "(", "torch", ".", "cat", "(", "img_batch", ",", "0", ")", ")", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", ".", "detach", "(", ")", "\n", "cost_z", "=", "utils", ".", "mismatchV", "(", "torch", ".", "cat", "(", "myzs", "[", "b", "*", "batch_size", ":", "(", "b", "+", "1", ")", "*", "batch_size", "]", ",", "0", ")", ",", "reco_z", ",", "'cos'", ")", "\n", "_", ",", "ii", "=", "torch", ".", "sort", "(", "cost_z", ")", "\n", "keeper", "=", "args", ".", "rejection_sampling", "/", "100.0", "\n", "keepN", "=", "max", "(", "1", ",", "int", "(", "len", "(", "ii", ")", "*", "keeper", ")", ")", "\n", "for", "iindex", "in", "ii", "[", ":", "keepN", "]", ":", "\n", "                            ", "filtered_images", ".", "append", "(", "img_batch", "[", "iindex", "]", ")", "\n", "#                        filtered_images.append(img_batch[ii[:keepN]] ) #retain the best ones only", "\n", "", "", "images", "=", "filtered_images", "\n", "\n", "", "if", "collateImages", ":", "\n", "                    ", "sample_dir", "=", "'{}/sample'", ".", "format", "(", "save_root", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "sample_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "sample_dir", ")", "\n", "\n", "", "save_path", "=", "'{}/{}.png'", ".", "format", "(", "sample_dir", ",", "str", "(", "global_i", "+", "1", ")", ".", "zfill", "(", "6", ")", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "\n", "torch", ".", "cat", "(", "images", ",", "0", ")", ",", "\n", "save_path", ",", "\n", "nrow", "=", "args", ".", "n_label", "*", "colN", ",", "\n", "normalize", "=", "True", ",", "\n", "range", "=", "(", "-", "1", ",", "1", ")", ",", "\n", "padding", "=", "0", ")", "\n", "# Hacky but this is an easy way to rescale the images to nice big lego format:", "\n", "im", "=", "Image", ".", "open", "(", "save_path", ")", "\n", "im2", "=", "im", ".", "resize", "(", "(", "1024", ",", "512", "if", "reso", "<", "256", "else", "1024", ")", ")", "\n", "im2", ".", "save", "(", "save_path", ")", "\n", "\n", "#if writer:", "\n", "#    writer.add_image('samples_latest_{}'.format(session.phase), torch.cat(images, 0), session.phase)", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"Generating samples at {}...\"", ".", "format", "(", "special_dir", ")", ")", "\n", "for", "ii", ",", "img", "in", "enumerate", "(", "images", ")", ":", "\n", "                        ", "ipath", "=", "'{}/{}_{}.png'", ".", "format", "(", "special_dir", ",", "str", "(", "global_i", "+", "1", ")", ".", "zfill", "(", "6", ")", ",", "ii", "+", "outer_count", "*", "128", ")", "\n", "#print(ipath)", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "\n", "img", ",", "\n", "ipath", ",", "\n", "nrow", "=", "args", ".", "n_label", "*", "colN", ",", "\n", "normalize", "=", "True", ",", "\n", "range", "=", "(", "-", "1", ",", "1", ")", ",", "\n", "padding", "=", "0", ")", "\n", "\n", "", "", "", "", "generator", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.reconstruct": [[190, 216], ["torch.no_grad", "encoder().detach", "style_input[].repeat", "pioneer.utils.gen_seq().detach", "encoder", "encoder().detach.size", "pioneer.utils.gen_seq", "torch.autograd.Variable", "session.getResoPhase"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["@", "staticmethod", "\n", "def", "reconstruct", "(", "input_image", ",", "encoder", ",", "generator", ",", "session", ",", "style_i", "=", "-", "1", ",", "style_layer_begin", "=", "0", ",", "style_layer_end", "=", "-", "1", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "style_input", "=", "encoder", "(", "Variable", "(", "input_image", ")", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", ".", "detach", "(", ")", "\n", "\n", "#replicateStyle = True", "\n", "\n", "#if replicateStyle:", "\n", "z", "=", "style_input", "[", "style_i", "]", ".", "repeat", "(", "style_input", ".", "size", "(", ")", "[", "0", "]", ",", "1", ")", "# Repeat the image #0 for all the image styles", "\n", "#else:", "\n", "#    z = None", "\n", "\n", "#The call would unwrap as follows:", "\n", "#z_w = generator(None,None, session.phase, session.alpha, style_input = z,           style_layer_begin=0, style_layer_end=style_layer_begin).detach()", "\n", "#z_w = generator(z_w, None, session.phase, session.alpha, style_input = style_input, style_layer_begin=style_layer_begin, style_layer_end=style_layer_end)", "\n", "#gex = generator(z_w, None, session.phase, session.alpha, style_input = z,           style_layer_begin=style_layer_end, style_layer_end=-1)", "\n", "\n", "gex", "=", "utils", ".", "gen_seq", "(", "[", "(", "z", ",", "0", ",", "style_layer_begin", ")", ",", "\n", "(", "style_input", ",", "style_layer_begin", ",", "style_layer_end", ")", ",", "\n", "(", "z", ",", "style_layer_end", ",", "-", "1", ")", ",", "\n", "]", ",", "generator", ",", "session", ")", ".", "detach", "(", ")", "\n", "\n", "#            if gex.size()[0] > 1:", "\n", "#                print(\"Norm of diff: {} / {}\".format((gex[0][0] - gex[1][0]).norm(), (gex[0][0] - gex[1][0]).max()   ))", "\n", "\n", "", "return", "gex", ".", "data", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.reconstruct_images": [[217, 324], ["generator.eval", "encoder.eval", "min", "encoder.train", "generator.train", "torch.no_grad", "pioneer.utils.requires_grad", "pioneer.utils.requires_grad", "session.getReso", "print", "range", "print", "next", "range", "session.getResoPhase", "numpy.ceil", "min", "PIL.Image.open", "PIL.Image.open.resize", "Image.open.resize.save", "session.getResoPhase", "pioneer.data.Utils.sample_data", "pioneer.data.Utils.sample_data2", "str().zfill", "os.path.exists", "os.makedirs", "next", "time.time", "evaluate.Utils.reconstruct", "time.time", "torch.FloatTensor", "torchvision.utils.save_image", "torchvision.utils.save_image", "Utils.reconstruction_set_x.size", "session.getResoPhase", "pioneer.data.Utils.sample_data", "pioneer.data.Utils.sample_data2", "session.getResoPhase", "print", "real_image.size", "real_image.size", "real_image.size", "numpy.mean", "len", "numpy.std", "session.getResoPhase", "min", "min", "evaluate.Utils.reconstruct", "torch.FloatTensor", "int", "torchvision.utils.save_image", "int", "str", "real_image.size", "numpy.mean", "len", "Utils.reconstruction_set_x.size", "Utils.reconstruction_set_x.size", "Utils.reconstruction_set_x.size", "Utils.reconstruction_set_x.size", "Utils.reconstruction_set_x.size"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.reconstruct", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.reconstruct"], ["", "@", "staticmethod", "\n", "def", "reconstruct_images", "(", "generator", ",", "encoder", ",", "loader", ",", "global_i", ",", "nr_of_imgs", ",", "prefix", ",", "reals", ",", "reconstructions", ",", "session", ",", "writer", "=", "None", ")", ":", "#of the form\"/[dir]\"", "\n", "        ", "generator", ".", "eval", "(", ")", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "imgs_per_style_mixture_run", "=", "min", "(", "nr_of_imgs", ",", "8", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "utils", ".", "requires_grad", "(", "generator", ",", "False", ")", "\n", "utils", ".", "requires_grad", "(", "encoder", ",", "False", ")", "\n", "\n", "save_root", "=", "args", ".", "sample_dir", "if", "args", ".", "sample_dir", "!=", "None", "else", "args", ".", "save_dir", "\n", "\n", "if", "reconstructions", "and", "nr_of_imgs", ">", "0", ":", "\n", "                ", "reso", "=", "session", ".", "getReso", "(", ")", "\n", "\n", "# First, create the single grid", "\n", "\n", "if", "Utils", ".", "reconstruction_set_x", "is", "None", "or", "Utils", ".", "reconstruction_set_x", ".", "size", "(", "2", ")", "!=", "reso", "or", "(", "session", ".", "getResoPhase", "(", ")", ">=", "1", "and", "session", ".", "alpha", "<", "1.0", ")", ":", "\n", "                    ", "if", "session", ".", "getResoPhase", "(", ")", "<", "1", ":", "\n", "                        ", "dataset", "=", "data", ".", "Utils", ".", "sample_data", "(", "loader", ",", "min", "(", "nr_of_imgs", ",", "16", ")", ",", "reso", ")", "\n", "", "else", ":", "\n", "                        ", "dataset", "=", "data", ".", "Utils", ".", "sample_data2", "(", "loader", ",", "min", "(", "nr_of_imgs", ",", "16", ")", ",", "reso", ",", "session", ")", "\n", "", "Utils", ".", "reconstruction_set_x", ",", "_", "=", "next", "(", "dataset", ")", "\n", "\n", "", "unstyledVersionDone", "=", "False", "\n", "# For 64x64: (0,1), (2,3) and (4,-1)", "\n", "# For 128x128: (2,3) and (3,4) fail (collapse to static image). Find out why.", "\n", "for", "sc", "in", "[", "(", "0", ",", "1", ")", ",", "(", "0", ",", "2", ")", ",", "(", "2", ",", "-", "1", ")", ",", "(", "2", ",", "4", ")", ",", "(", "4", ",", "5", ")", ",", "(", "5", ",", "-", "1", ")", "]", ":", "\n", "                    ", "for", "style_i", "in", "range", "(", "imgs_per_style_mixture_run", ")", ":", "\n", "\n", "                        ", "if", "not", "unstyledVersionDone", ":", "\n", "                            ", "scs", "=", "[", "(", "0", ",", "-", "1", ")", ",", "sc", "]", "\n", "", "else", ":", "\n", "                            ", "scs", "=", "[", "sc", "]", "\n", "\n", "", "for", "(", "style_layer_begin", ",", "style_layer_end", ")", "in", "scs", ":", "\n", "                            ", "reco_image", "=", "Utils", ".", "reconstruct", "(", "Utils", ".", "reconstruction_set_x", ",", "encoder", ",", "generator", ",", "session", ",", "\n", "style_i", "=", "style_i", ",", "style_layer_begin", "=", "style_layer_begin", ",", "style_layer_end", "=", "style_layer_end", ")", "\n", "\n", "\n", "t", "=", "torch", ".", "FloatTensor", "(", "Utils", ".", "reconstruction_set_x", ".", "size", "(", "0", ")", "*", "2", ",", "Utils", ".", "reconstruction_set_x", ".", "size", "(", "1", ")", ",", "\n", "Utils", ".", "reconstruction_set_x", ".", "size", "(", "2", ")", ",", "Utils", ".", "reconstruction_set_x", ".", "size", "(", "3", ")", ")", "\n", "\n", "NN", "=", "int", "(", "Utils", ".", "reconstruction_set_x", ".", "size", "(", "0", ")", "/", "2", ")", "\n", "t", "[", "0", ":", "NN", ",", ":", ",", ":", ",", ":", "]", "=", "Utils", ".", "reconstruction_set_x", "[", ":", "NN", "]", "\n", "t", "[", "NN", ":", "NN", "*", "2", ",", ":", ",", ":", ",", ":", "]", "=", "reco_image", "[", ":", "NN", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "from", "pioneer", ".", "model", "import", "AdaNorm", "\n", "\n", "save_path", "=", "'{}{}/reconstructions_{}_{}_{}_{}_{}_{}-{}.png'", ".", "format", "(", "save_root", ",", "prefix", ",", "session", ".", "phase", ",", "global_i", ",", "session", ".", "alpha", ",", "'X'", "if", "AdaNorm", ".", "disable", "else", "'ADA'", ",", "style_i", ",", "style_layer_begin", ",", "style_layer_end", ")", "\n", "grid", "=", "torchvision", ".", "utils", ".", "save_image", "(", "t", "[", ":", "nr_of_imgs", "]", "/", "2", "+", "0.5", ",", "save_path", ",", "padding", "=", "0", ")", "\n", "", "unstyledVersionDone", "=", "True", "\n", "\n", "# Rescale the images to nice big lego format:", "\n", "", "", "if", "session", ".", "getResoPhase", "(", ")", "<", "4", ":", "\n", "                    ", "h", "=", "np", ".", "ceil", "(", "nr_of_imgs", "/", "8", ")", "\n", "h_scale", "=", "min", "(", "1.0", ",", "h", "/", "8.0", ")", "\n", "im", "=", "Image", ".", "open", "(", "save_path", ")", "\n", "im2", "=", "im", ".", "resize", "(", "(", "1024", ",", "int", "(", "1024", "*", "h_scale", ")", ")", ")", "\n", "im2", ".", "save", "(", "save_path", ")", "\n", "\n", "#if writer:", "\n", "#    writer.add_image('reconstruction_latest_{}'.format(session.phase), t[:nr_of_imgs] / 2 + 0.5, session.phase)", "\n", "\n", "# Second, create the Individual images:", "\n", "", "if", "session", ".", "getResoPhase", "(", ")", "<", "1", ":", "\n", "                    ", "dataset", "=", "data", ".", "Utils", ".", "sample_data", "(", "loader", ",", "1", ",", "reso", ")", "\n", "", "else", ":", "\n", "                    ", "dataset", "=", "data", ".", "Utils", ".", "sample_data2", "(", "loader", ",", "1", ",", "reso", ",", "session", ")", "\n", "\n", "", "special_dir", "=", "'{}/{}'", ".", "format", "(", "save_root", "if", "not", "args", ".", "aux_outpath", "else", "args", ".", "aux_outpath", ",", "str", "(", "global_i", ")", ".", "zfill", "(", "6", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "special_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "special_dir", ")", "\n", "\n", "", "print", "(", "\"Save images: Alpha={}, phase={}, images={}, at {}\"", ".", "format", "(", "session", ".", "alpha", ",", "session", ".", "getResoPhase", "(", ")", ",", "nr_of_imgs", ",", "special_dir", ")", ")", "\n", "\n", "lpips_dist", "=", "0", "\n", "\n", "inf_time", "=", "[", "]", "\n", "n_time", "=", "0", "\n", "\n", "for", "o", "in", "range", "(", "nr_of_imgs", ")", ":", "\n", "                    ", "if", "o", "%", "500", "==", "0", ":", "\n", "                        ", "print", "(", "o", ")", "\n", "\n", "", "real_image", ",", "_", "=", "next", "(", "dataset", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "reco_image", "=", "Utils", ".", "reconstruct", "(", "real_image", ",", "encoder", ",", "generator", ",", "session", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "inf_time", "+=", "[", "(", "end", "-", "start", ")", "]", "\n", "\n", "t", "=", "torch", ".", "FloatTensor", "(", "real_image", ".", "size", "(", "0", ")", "*", "2", ",", "real_image", ".", "size", "(", "1", ")", ",", "\n", "real_image", ".", "size", "(", "2", ")", ",", "real_image", ".", "size", "(", "3", ")", ")", "\n", "\n", "save_path_A", "=", "'{}/{}_orig.png'", ".", "format", "(", "special_dir", ",", "o", ")", "\n", "save_path_B", "=", "'{}/{}_pine.png'", ".", "format", "(", "special_dir", ",", "o", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "real_image", "[", "0", "]", "/", "2", "+", "0.5", ",", "save_path_A", ",", "padding", "=", "0", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "reco_image", "[", "0", "]", "/", "2", "+", "0.5", ",", "save_path_B", ",", "padding", "=", "0", ")", "\n", "\n", "", "print", "(", "\"Mean elaped: {} or {} for bs={} with std={}\"", ".", "format", "(", "np", ".", "mean", "(", "inf_time", ")", ",", "np", ".", "mean", "(", "inf_time", ")", "/", "len", "(", "real_image", ")", ",", "len", "(", "real_image", ")", ",", "np", ".", "std", "(", "inf_time", ")", ")", ")", "\n", "\n", "", "", "encoder", ".", "train", "(", ")", "\n", "generator", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped": [[325, 330], ["img.size"], "methods", ["None"], ["", "def", "face_as_cropped", "(", "img", ")", ":", "\n", "        ", "reso", "=", "img", ".", "size", "(", ")", "[", "2", "]", "\n", "c", "=", "reso", "//", "8", "\n", "\n", "return", "img", "[", ":", ",", ":", ",", "3", "*", "c", ":", "7", "*", "c", ",", "2", "*", "c", ":", "6", "*", "c", "]", "#e.g. for 256x256, this is: 96 <= y < 224, 64 <= x < 192", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.eval_metrics": [[331, 414], ["generator.eval", "encoder.eval", "encoder.train", "generator.train", "torch.no_grad", "pioneer.utils.requires_grad", "pioneer.utils.requires_grad", "session.getReso", "pioneer.LPIPS.PerceptualLoss", "session.getResoPhase", "range", "torch.cat", "torch.cat", "torch.cat", "pioneer.LPIPS.PerceptualLoss.forward", "torch.mean", "pioneer.FID.fid_score.calculate_fid_given_images", "writer.add_scalar", "writer.add_scalar", "print", "torch.autograd.Variable().to", "pioneer.utils.normalize", "pioneer.utils.split_labels_out_of_latent", "generator().detach().data.cpu", "torch.cat.append", "pioneer.data.Utils.sample_data2", "next", "evaluate.Utils.reconstruct", "torch.FloatTensor", "torch.cat.append", "torch.cat.append", "evaluate.Utils.face_as_cropped", "evaluate.Utils.face_as_cropped", "evaluate.Utils.face_as_cropped", "evaluate.Utils.face_as_cropped", "torch.autograd.Variable", "evaluate.Utils.face_as_cropped", "session.getResoPhase", "evaluate.Utils.face_as_cropped", "evaluate.Utils.face_as_cropped", "torch.randn", "generator().detach", "evaluate.Utils.face_as_cropped", "generator"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score.calculate_fid_given_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.split_labels_out_of_latent", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.reconstruct", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.face_as_cropped"], ["", "def", "eval_metrics", "(", "generator", ",", "encoder", ",", "loader", ",", "global_i", ",", "nr_of_imgs", ",", "prefix", ",", "reals", ",", "reconstructions", ",", "session", ",", "\n", "writer", "=", "None", ")", ":", "# of the form\"/[dir]\"", "\n", "        ", "generator", ".", "eval", "(", ")", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "utils", ".", "requires_grad", "(", "generator", ",", "False", ")", "\n", "utils", ".", "requires_grad", "(", "encoder", ",", "False", ")", "\n", "\n", "if", "reconstructions", "and", "nr_of_imgs", ">", "0", ":", "\n", "                ", "reso", "=", "session", ".", "getReso", "(", ")", "\n", "\n", "batch_size", "=", "16", "\n", "n_batches", "=", "(", "nr_of_imgs", "+", "batch_size", "-", "1", ")", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "\n", "\n", "#fid_score = 0", "\n", "lpips_score", "=", "0", "\n", "lpips_model", "=", "lpips", ".", "PerceptualLoss", "(", "model", "=", "'net-lin'", ",", "net", "=", "'alex'", ",", "use_gpu", "=", "False", ")", "\n", "real_images", "=", "[", "]", "\n", "reco_images", "=", "[", "]", "\n", "rand_images", "=", "[", "]", "\n", "\n", "FIDm", "=", "3", "# FID multiplier", "\n", "\n", "if", "session", ".", "getResoPhase", "(", ")", ">=", "3", ":", "\n", "                    ", "for", "o", "in", "range", "(", "n_batches", "*", "FIDm", ")", ":", "\n", "                        ", "myz", "=", "Variable", "(", "torch", ".", "randn", "(", "args", ".", "n_label", "*", "batch_size", ",", "args", ".", "nz", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "myz", "=", "utils", ".", "normalize", "(", "myz", ")", "\n", "myz", ",", "input_class", "=", "utils", ".", "split_labels_out_of_latent", "(", "myz", ")", "\n", "\n", "random_image", "=", "generator", "(", "\n", "myz", ",", "\n", "input_class", ",", "\n", "session", ".", "phase", ",", "\n", "session", ".", "alpha", ")", ".", "detach", "(", ")", ".", "data", ".", "cpu", "(", ")", "\n", "\n", "rand_images", ".", "append", "(", "random_image", ")", "\n", "\n", "if", "o", ">=", "n_batches", ":", "#Reconstructions only up to n_batches, FIDs will take n_batches * 3 samples", "\n", "                             ", "continue", "\n", "\n", "", "dataset", "=", "data", ".", "Utils", ".", "sample_data2", "(", "loader", ",", "batch_size", ",", "reso", ",", "session", ")", "\n", "\n", "real_image", ",", "_", "=", "next", "(", "dataset", ")", "\n", "reco_image", "=", "Utils", ".", "reconstruct", "(", "real_image", ",", "encoder", ",", "generator", ",", "session", ")", "\n", "\n", "t", "=", "torch", ".", "FloatTensor", "(", "real_image", ".", "size", "(", "0", ")", "*", "2", ",", "real_image", ".", "size", "(", "1", ")", ",", "\n", "real_image", ".", "size", "(", "2", ")", ",", "real_image", ".", "size", "(", "3", ")", ")", "\n", "\n", "# compute metrics and write it to tensorboard (if the reso >= 32)", "\n", "\n", "\n", "#lpips_score = \"?\"", "\n", "\n", "crop_needed", "=", "(", "args", ".", "data", "==", "'celeba'", "or", "args", ".", "data", "==", "'celebaHQ'", "or", "args", ".", "data", "==", "'ffhq'", ")", "\n", "\n", "if", "session", ".", "getResoPhase", "(", ")", ">=", "4", "or", "not", "crop_needed", ":", "# 32x32 is minimum for LPIPS", "\n", "                            ", "if", "crop_needed", ":", "\n", "                                ", "real_image", "=", "Utils", ".", "face_as_cropped", "(", "real_image", ")", "\n", "reco_image", "=", "Utils", ".", "face_as_cropped", "(", "reco_image", ")", "\n", "\n", "", "", "real_images", ".", "append", "(", "real_image", ")", "\n", "reco_images", ".", "append", "(", "reco_image", ".", "detach", "(", ")", ".", "data", ".", "cpu", "(", ")", ")", "\n", "\n", "", "real_images", "=", "torch", ".", "cat", "(", "real_images", ",", "0", ")", "\n", "reco_images", "=", "torch", ".", "cat", "(", "reco_images", ",", "0", ")", "\n", "rand_images", "=", "torch", ".", "cat", "(", "rand_images", ",", "0", ")", "\n", "\n", "\n", "lpips_dist", "=", "lpips_model", ".", "forward", "(", "real_images", ",", "reco_images", ")", "\n", "lpips_score", "=", "torch", ".", "mean", "(", "lpips_dist", ")", "\n", "\n", "fid_score", "=", "calculate_fid_given_images", "(", "real_images", ",", "rand_images", ",", "batch_size", "=", "batch_size", ",", "cuda", "=", "False", ",", "dims", "=", "2048", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "'LPIPS'", ",", "lpips_score", ",", "session", ".", "sample_i", ")", "\n", "writer", ".", "add_scalar", "(", "'FID'", ",", "fid_score", ",", "session", ".", "sample_i", ")", "\n", "\n", "print", "(", "\"{}: FID = {}, LPIPS = {}\"", ".", "format", "(", "session", ".", "sample_i", ",", "fid_score", ",", "lpips_score", ")", ")", "\n", "\n", "", "", "", "encoder", ".", "train", "(", ")", "\n", "generator", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp": [[415, 421], ["numpy.arccos", "numpy.sin", "numpy.sin", "numpy.sin", "numpy.sin", "numpy.sqrt", "numpy.dot", "numpy.sqrt", "numpy.dot", "numpy.dot"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "slerp", "(", "p0", ",", "p1", ",", "t", ")", ":", "\n", "        ", "omega", "=", "np", ".", "arccos", "(", "np", ".", "dot", "(", "p0", ",", "p1", ")", "/", "np", ".", "sqrt", "(", "np", ".", "dot", "(", "p0", ",", "p0", ")", ")", "/", "np", ".", "sqrt", "(", "np", ".", "dot", "(", "p1", ",", "p1", ")", ")", ")", "\n", "k1", "=", "np", ".", "sin", "(", "(", "1", "-", "t", ")", "*", "omega", ")", "/", "np", ".", "sin", "(", "omega", ")", "\n", "k2", "=", "np", ".", "sin", "(", "t", "*", "omega", ")", "/", "np", ".", "sin", "(", "omega", ")", "\n", "return", "k1", "*", "p0", "+", "k2", "*", "p1", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.interpolate_images": [[423, 552], ["generator.eval", "encoder.eval", "generator.train", "encoder.train", "torch.no_grad", "pioneer.utils.requires_grad", "pioneer.utils.requires_grad", "session.getReso", "torch.FloatTensor", "range", "range", "torchvision.utils.save_image", "next", "torch.autograd.Variable().to", "encoder().detach", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "torch.zeros().to", "evaluate.Utils.slerp", "evaluate.Utils.slerp", "evaluate.Utils.slerp", "evaluate.Utils.slerp", "evaluate.Utils.slerp", "evaluate.Utils.slerp", "pioneer.utils.normalize", "encoder().detach", "x.size", "x.size", "x.size", "os.path.exists", "os.makedirs", "torchvision.utils.save_image", "pioneer.utils.split_labels_out_of_latent", "generator().detach", "range", "pioneer.utils.split_labels_out_of_latent", "generator().detach", "range", "session.getResoPhase", "PIL.Image.open", "PIL.Image.open.resize", "Image.open.resize.save", "session.getResoPhase", "pioneer.data.Utils.sample_data", "pioneer.data.Utils.sample_data2", "numpy.sqrt", "torchvision.utils.save_image", "torch.autograd.Variable", "range", "evaluate.Utils.slerp", "evaluate.Utils.slerp", "torch.autograd.Variable", "range", "torchvision.utils.save_image", "torch.autograd.Variable", "encoder", "range", "range", "numpy.max", "torch.zeros", "torch.from_numpy().to", "encoder", "generator", "torch.FloatTensor", "float", "z0[].data.cpu().numpy", "z0[].data.cpu().numpy", "z0[].data.cpu().numpy", "z0[].data.cpu().numpy", "torch.FloatTensor", "torch.from_numpy", "generator", "torch.autograd.Variable", "session.getResoPhase", "numpy.power", "numpy.power", "torch.autograd.Variable", "session.getResoPhase", "z0_x0.size", "z0[].size", "float", "evaluate.Utils.slerp", "torch.from_numpy", "z0[].data.cpu", "z0[].data.cpu", "z0[].data.cpu", "z0[].data.cpu", "weights.T.astype"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.split_labels_out_of_latent", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.split_labels_out_of_latent", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.slerp"], ["@", "staticmethod", "\n", "def", "interpolate_images", "(", "generator", ",", "encoder", ",", "loader", ",", "epoch", ",", "prefix", ",", "session", ",", "writer", "=", "None", ")", ":", "\n", "        ", "generator", ".", "eval", "(", ")", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "utils", ".", "requires_grad", "(", "generator", ",", "False", ")", "\n", "utils", ".", "requires_grad", "(", "encoder", ",", "False", ")", "\n", "\n", "nr_of_imgs", "=", "4", "if", "not", "args", ".", "hexmode", "else", "6", "# \"Corners\"", "\n", "reso", "=", "session", ".", "getReso", "(", ")", "\n", "if", "True", ":", "\n", "#if Utils.interpolation_set_x is None or Utils.interpolation_set_x.size(2) != reso or (phase >= 1 and alpha < 1.0):", "\n", "                ", "if", "session", ".", "getResoPhase", "(", ")", "<", "1", ":", "\n", "                    ", "dataset", "=", "data", ".", "Utils", ".", "sample_data", "(", "loader", ",", "nr_of_imgs", ",", "reso", ")", "\n", "", "else", ":", "\n", "                    ", "dataset", "=", "data", ".", "Utils", ".", "sample_data2", "(", "loader", ",", "nr_of_imgs", ",", "reso", ",", "session", ")", "\n", "", "real_image", ",", "_", "=", "next", "(", "dataset", ")", "\n", "Utils", ".", "interpolation_set_x", "=", "Variable", "(", "real_image", ",", "volatile", "=", "True", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "\n", "", "latent_reso_hor", "=", "8", "\n", "latent_reso_ver", "=", "8", "\n", "\n", "x", "=", "Utils", ".", "interpolation_set_x", "\n", "\n", "if", "args", ".", "hexmode", ":", "\n", "                ", "x", "=", "x", "[", ":", "nr_of_imgs", "]", "#Corners", "\n", "z0", "=", "encoder", "(", "Variable", "(", "x", ")", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", ".", "detach", "(", ")", "\n", "\n", "X", "=", "np", ".", "array", "(", "[", "-", "1.7321", ",", "0.0000", ",", "1.7321", ",", "-", "2.5981", ",", "-", "0.8660", ",", "0.8660", ",", "2.5981", ",", "-", "3.4641", ",", "-", "1.7321", ",", "0.0000", ",", "1.7321", ",", "3.4641", ",", "-", "2.5981", ",", "-", "0.8660", ",", "0.8660", ",", "2.5981", ",", "-", "1.7321", ",", "0.0000", ",", "1.7321", "]", ")", "\n", "Y", "=", "np", ".", "array", "(", "[", "-", "3.0000", ",", "-", "3.0000", ",", "-", "3.0000", ",", "-", "1.5000", ",", "-", "1.5000", ",", "-", "1.5000", ",", "-", "1.5000", ",", "0.0000", ",", "0.0000", ",", "0.0000", ",", "0.0000", ",", "0.0000", ",", "1.5000", ",", "1.5000", ",", "1.5000", ",", "1.5000", ",", "3.0000", ",", "3.0000", ",", "3.0000", "]", ")", "\n", "corner_indices", "=", "np", ".", "array", "(", "[", "0", ",", "2", ",", "7", ",", "11", ",", "16", ",", "18", "]", ")", "\n", "inter_indices", "=", "[", "i", "for", "i", "in", "range", "(", "19", ")", "if", "not", "i", "in", "corner_indices", "]", "\n", "edge_indices", "=", "np", ".", "array", "(", "[", "1", ",", "3", ",", "6", ",", "12", ",", "15", ",", "17", "]", ")", "\n", "#distances_to_corners = np.sqrt(np.power(X - X[corner_indices[0]], 2) + np.power(Y - Y[corner_indices[0]], 2))", "\n", "distances_to_corners", "=", "[", "np", ".", "sqrt", "(", "np", ".", "power", "(", "X", "-", "X", "[", "corner_indices", "[", "i", "]", "]", ",", "2", ")", "+", "np", ".", "power", "(", "Y", "-", "Y", "[", "corner_indices", "[", "i", "]", "]", ",", "2", ")", ")", "for", "i", "in", "range", "(", "6", ")", "]", "\n", "weights", "=", "1.0", "-", "distances_to_corners", "/", "np", ".", "max", "(", "distances_to_corners", ")", "\n", "z0_x", "=", "torch", ".", "zeros", "(", "(", "19", ",", "args", ".", "nz", "+", "args", ".", "n_label", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "z0_x", "[", "corner_indices", ",", ":", "]", "=", "z0", "\n", "z0_x", "[", "edge_indices", "[", "0", "]", ",", ":", "]", "=", "Utils", ".", "slerp", "(", "z0", "[", "0", "]", ",", "z0", "[", "1", "]", ",", "0.5", ")", "\n", "z0_x", "[", "edge_indices", "[", "1", "]", ",", ":", "]", "=", "Utils", ".", "slerp", "(", "z0", "[", "0", "]", ",", "z0", "[", "2", "]", ",", "0.5", ")", "\n", "z0_x", "[", "edge_indices", "[", "2", "]", ",", ":", "]", "=", "Utils", ".", "slerp", "(", "z0", "[", "1", "]", ",", "z0", "[", "3", "]", ",", "0.5", ")", "\n", "z0_x", "[", "edge_indices", "[", "3", "]", ",", ":", "]", "=", "Utils", ".", "slerp", "(", "z0", "[", "2", "]", ",", "z0", "[", "4", "]", ",", "0.5", ")", "\n", "z0_x", "[", "edge_indices", "[", "4", "]", ",", ":", "]", "=", "Utils", ".", "slerp", "(", "z0", "[", "3", "]", ",", "z0", "[", "5", "]", ",", "0.5", ")", "\n", "z0_x", "[", "edge_indices", "[", "5", "]", ",", ":", "]", "=", "Utils", ".", "slerp", "(", "z0", "[", "4", "]", ",", "z0", "[", "5", "]", ",", "0.5", ")", "\n", "# Linear:", "\n", "#z0x[inter_indices,:] = (weights.T @ z0)[inter_indices,:]", "\n", "z0_x", "[", "inter_indices", ",", ":", "]", "=", "(", "torch", ".", "from_numpy", "(", "weights", ".", "T", ".", "astype", "(", "np", ".", "float32", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "@", "z0", ")", "[", "inter_indices", ",", ":", "]", "\n", "z0_x", "=", "utils", ".", "normalize", "(", "z0_x", ")", "\n", "", "else", ":", "\n", "                ", "z0", "=", "encoder", "(", "Variable", "(", "x", ")", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", ".", "detach", "(", ")", "\n", "\n", "", "t", "=", "torch", ".", "FloatTensor", "(", "latent_reso_hor", "*", "(", "latent_reso_ver", "+", "1", ")", "+", "nr_of_imgs", ",", "x", ".", "size", "(", "1", ")", ",", "\n", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "t", "[", "0", ":", "nr_of_imgs", "]", "=", "x", ".", "data", "[", ":", "]", "\n", "\n", "save_root", "=", "args", ".", "sample_dir", "if", "args", ".", "sample_dir", "!=", "None", "else", "args", ".", "save_dir", "\n", "special_dir", "=", "save_root", "if", "not", "args", ".", "aux_outpath", "else", "args", ".", "aux_outpath", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "special_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "special_dir", ")", "\n", "\n", "", "for", "o_i", "in", "range", "(", "nr_of_imgs", ")", ":", "\n", "                ", "single_save_path", "=", "'{}{}/hex_interpolations_{}_{}_{}_orig_{}.png'", ".", "format", "(", "special_dir", ",", "prefix", ",", "session", ".", "phase", ",", "epoch", ",", "session", ".", "alpha", ",", "o_i", ")", "\n", "grid", "=", "torchvision", ".", "utils", ".", "save_image", "(", "x", ".", "data", "[", "o_i", "]", "/", "2", "+", "0.5", ",", "single_save_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "#, normalize=True) #range=(-1,1)) #, normalize=True) #, scale_each=True)?", "\n", "\n", "", "if", "args", ".", "hexmode", ":", "\n", "                ", "z0_x", ",", "label", "=", "utils", ".", "split_labels_out_of_latent", "(", "z0_x", ")", "\n", "gex", "=", "generator", "(", "z0_x", ",", "label", ",", "session", ".", "phase", ",", "session", ".", "alpha", ")", ".", "detach", "(", ")", "\n", "\n", "for", "x_i", "in", "range", "(", "19", ")", ":", "\n", "                    ", "single_save_path", "=", "'{}{}/hex_interpolations_{}_{}_{}x{}.png'", ".", "format", "(", "special_dir", ",", "prefix", ",", "session", ".", "phase", ",", "epoch", ",", "session", ".", "alpha", ",", "x_i", ")", "\n", "grid", "=", "torchvision", ".", "utils", ".", "save_image", "(", "gex", ".", "data", "[", "x_i", "]", "/", "2", "+", "0.5", ",", "single_save_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "#, normalize=True) #range=(-1,1)) #, normalize=True) #, scale_each=True)?", "\n", "\n", "", "return", "\n", "\n", "# Origs on the first row here", "\n", "# Corners are: z0[0] ... z0[1]", "\n", "#                .   ", "\n", "#                .", "\n", "#              z0[2] ... z0[3]                ", "\n", "\n", "", "delta_z_ver0", "=", "(", "(", "z0", "[", "2", "]", "-", "z0", "[", "0", "]", ")", "/", "(", "latent_reso_ver", "-", "1", ")", ")", "\n", "delta_z_verN", "=", "(", "(", "z0", "[", "3", "]", "-", "z0", "[", "1", "]", ")", "/", "(", "latent_reso_ver", "-", "1", ")", ")", "\n", "\n", "for", "y_i", "in", "range", "(", "latent_reso_ver", ")", ":", "\n", "                ", "if", "False", ":", "#Linear interpolation", "\n", "                    ", "z0_x0", "=", "z0", "[", "0", "]", "+", "y_i", "*", "delta_z_ver0", "\n", "z0_xN", "=", "z0", "[", "1", "]", "+", "y_i", "*", "delta_z_verN", "\n", "delta_z_hor", "=", "(", "z0_xN", "-", "z0_x0", ")", "/", "(", "latent_reso_hor", "-", "1", ")", "\n", "z0_x", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "latent_reso_hor", ",", "z0_x0", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "for", "x_i", "in", "range", "(", "latent_reso_hor", ")", ":", "\n", "                        ", "z0_x", "[", "x_i", "]", "=", "z0_x0", "+", "x_i", "*", "delta_z_hor", "\n", "\n", "", "", "if", "True", ":", "#Spherical", "\n", "                    ", "t_y", "=", "float", "(", "y_i", ")", "/", "(", "latent_reso_ver", "-", "1", ")", "\n", "#z0_y = Variable(torch.FloatTensor(latent_reso_ver, z0.size(0)))", "\n", "\n", "z0_y1", "=", "Utils", ".", "slerp", "(", "z0", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "z0", "[", "2", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "t_y", ")", "\n", "z0_y2", "=", "Utils", ".", "slerp", "(", "z0", "[", "1", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "z0", "[", "3", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "t_y", ")", "\n", "z0_x", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "latent_reso_hor", ",", "z0", "[", "0", "]", ".", "size", "(", "0", ")", ")", ")", "\n", "for", "x_i", "in", "range", "(", "latent_reso_hor", ")", ":", "\n", "                        ", "t_x", "=", "float", "(", "x_i", ")", "/", "(", "latent_reso_hor", "-", "1", ")", "\n", "z0_x", "[", "x_i", "]", "=", "torch", ".", "from_numpy", "(", "Utils", ".", "slerp", "(", "z0_y1", ",", "z0_y2", ",", "t_x", ")", ")", "\n", "\n", "", "", "z0_x", ",", "label", "=", "utils", ".", "split_labels_out_of_latent", "(", "z0_x", ")", "\n", "gex", "=", "generator", "(", "z0_x", ",", "label", ",", "session", ".", "phase", ",", "session", ".", "alpha", ")", ".", "detach", "(", ")", "\n", "\n", "# Recall that yi=0 is the original's row:", "\n", "t", "[", "(", "y_i", "+", "1", ")", "*", "latent_reso_ver", ":", "(", "y_i", "+", "2", ")", "*", "latent_reso_ver", "]", "=", "gex", ".", "data", "[", ":", "]", "\n", "\n", "for", "x_i", "in", "range", "(", "latent_reso_hor", ")", ":", "\n", "                    ", "single_save_path", "=", "'{}{}/interpolations_{}_{}_{}_{}x{}.png'", ".", "format", "(", "special_dir", ",", "prefix", ",", "session", ".", "phase", ",", "epoch", ",", "session", ".", "alpha", ",", "y_i", ",", "x_i", ")", "\n", "grid", "=", "torchvision", ".", "utils", ".", "save_image", "(", "gex", ".", "data", "[", "x_i", "]", "/", "2", "+", "0.5", ",", "single_save_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "#, normalize=True) #range=(-1,1)) #, normalize=True) #, scale_each=True)?", "\n", "\n", "", "", "save_path", "=", "'{}{}/interpolations_{}_{}_{}.png'", ".", "format", "(", "special_dir", ",", "prefix", ",", "session", ".", "phase", ",", "epoch", ",", "session", ".", "alpha", ")", "\n", "grid", "=", "torchvision", ".", "utils", ".", "save_image", "(", "t", "/", "2", "+", "0.5", ",", "save_path", ",", "nrow", "=", "latent_reso_ver", ",", "padding", "=", "0", ")", "#, normalize=True) #range=(-1,1)) #, normalize=True) #, scale_each=True)?", "\n", "# Hacky but this is an easy way to rescale the images to nice big lego format:", "\n", "if", "session", ".", "getResoPhase", "(", ")", "<", "4", ":", "\n", "                ", "im", "=", "Image", ".", "open", "(", "save_path", ")", "\n", "im2", "=", "im", ".", "resize", "(", "(", "1024", ",", "1024", ")", ")", "\n", "im2", ".", "save", "(", "save_path", ")", "\n", "\n", "#if writer:", "\n", "#    writer.add_image('interpolation_latest_{}'.format(session.phase), t / 2 + 0.5, session.phase)", "\n", "\n", "", "", "generator", ".", "train", "(", ")", "\n", "encoder", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.tests_run": [[553, 575], ["os.makedirs", "evaluate.Utils.make", "range", "range", "evaluate.Utils.generate_intermediate_samples", "print", "evaluate.Utils.generate_intermediate_samples", "print", "os.path.exists", "evaluate.Utils.reconstruct_images", "evaluate.Utils.interpolate_images"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.make", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.generate_intermediate_samples", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.generate_intermediate_samples", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.reconstruct_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.Utils.interpolate_images"], ["", "", "def", "tests_run", "(", "generator_for_testing", ",", "encoder", ",", "test_data_loader", ",", "session", ",", "writer", ",", "reconstruction", "=", "True", ",", "interpolation", "=", "True", ",", "collated_sampling", "=", "True", ",", "individual_sampling", "=", "True", ",", "metric_eval", "=", "True", ")", ":", "\n", "    ", "if", "args", ".", "sample_dir", "and", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "sample_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "sample_dir", ")", "\n", "\n", "", "if", "args", ".", "z_inpath", ":", "\n", "        ", "Utils", ".", "make", "(", "generator_for_testing", ",", "session", "=", "session", ",", "writer", "=", "writer", ")", "\n", "", "if", "reconstruction", ":", "\n", "        ", "for", "_", "in", "range", "(", "1", ")", ":", "\n", "            ", "Utils", ".", "reconstruct_images", "(", "generator_for_testing", ",", "encoder", ",", "test_data_loader", ",", "session", ".", "sample_i", ",", "nr_of_imgs", "=", "args", ".", "reconstructions_N", ",", "prefix", "=", "''", ",", "reals", "=", "False", ",", "reconstructions", "=", "True", ",", "session", "=", "session", ",", "writer", "=", "writer", ")", "\n", "", "", "if", "interpolation", ":", "\n", "        ", "for", "ii", "in", "range", "(", "args", ".", "interpolate_N", ")", ":", "\n", "            ", "Utils", ".", "interpolate_images", "(", "generator_for_testing", ",", "encoder", ",", "test_data_loader", ",", "session", ".", "sample_i", "+", "ii", ",", "prefix", "=", "''", ",", "session", "=", "session", ",", "writer", "=", "writer", ")", "\n", "", "", "if", "collated_sampling", "and", "args", ".", "sample_N", ">", "0", ":", "\n", "        ", "Utils", ".", "generate_intermediate_samples", "(", "\n", "generator_for_testing", ",", "\n", "session", ".", "sample_i", ",", "session", "=", "session", ",", "writer", "=", "writer", ",", "collateImages", "=", "True", ")", "#True)", "\n", "", "if", "individual_sampling", "and", "args", ".", "sample_N", ">", "0", ":", "#Full sample set generation.", "\n", "        ", "print", "(", "\"Full Test samples - generating...\"", ")", "\n", "Utils", ".", "generate_intermediate_samples", "(", "\n", "generator_for_testing", ",", "\n", "session", ".", "sample_i", ",", "session", "=", "session", ",", "collateImages", "=", "False", ")", "\n", "print", "(", "\"Full Test samples generated.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.KLN01Loss.__init__": [[58, 64], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "direction", ",", "minimize", ")", ":", "\n", "        ", "super", "(", "KLN01Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "minimize", "=", "minimize", "\n", "assert", "direction", "in", "[", "'pq'", ",", "'qp'", "]", ",", "'direction?'", "\n", "\n", "self", ".", "direction", "=", "direction", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.KLN01Loss.forward": [[65, 94], ["samples.view.view.view", "torchvision.utils.var", "samples.view.view.mean", "samples.view.view.nelement", "samples.view.view.size", "samples_var.log", "samples.view.view.size", "samples.view.view.size", "samples_var.log", "samples_mean.pow", "samples_var.pow", "samples_mean.pow"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.var"], ["", "def", "forward", "(", "self", ",", "samples", ")", ":", "\n", "\n", "        ", "assert", "samples", ".", "nelement", "(", ")", "==", "samples", ".", "size", "(", "1", ")", "*", "samples", ".", "size", "(", "0", ")", ",", "'?'", "\n", "\n", "samples", "=", "samples", ".", "view", "(", "samples", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "self", ".", "samples_var", "=", "utils", ".", "var", "(", "samples", ")", "\n", "self", ".", "samples_mean", "=", "samples", ".", "mean", "(", "0", ")", "\n", "\n", "samples_mean", "=", "self", ".", "samples_mean", "\n", "samples_var", "=", "self", ".", "samples_var", "\n", "\n", "if", "self", ".", "direction", "==", "'pq'", ":", "\n", "            ", "t1", "=", "(", "1", "+", "samples_mean", ".", "pow", "(", "2", ")", ")", "/", "(", "2", "*", "samples_var", ".", "pow", "(", "2", ")", ")", "\n", "t2", "=", "samples_var", ".", "log", "(", ")", "\n", "\n", "KL", "=", "(", "t1", "+", "t2", "-", "0.5", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "# In the AGE implementation, there is samples_var^2 instead of samples_var^1", "\n", "            ", "t1", "=", "(", "samples_var", "+", "samples_mean", ".", "pow", "(", "2", ")", ")", "/", "2", "\n", "# In the AGE implementation, this did not have the 0.5 scaling factor:", "\n", "t2", "=", "-", "0.5", "*", "samples_var", ".", "log", "(", ")", "\n", "\n", "KL", "=", "(", "t1", "+", "t2", "-", "0.5", ")", ".", "mean", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "minimize", ":", "\n", "            ", "KL", "*=", "-", "1", "\n", "\n", "", "return", "KL", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.setup": [[36, 55], ["pioneer.config.init", "torchvision.utils.make_dirs", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "pioneer.config.log_args", "datetime.datetime.now().strftime", "SummaryWriter", "datetime.datetime.now", "tz.gettz"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.init", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.make_dirs", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.config.log_args"], ["def", "setup", "(", ")", ":", "\n", "    ", "config", ".", "init", "(", ")", "\n", "\n", "utils", ".", "make_dirs", "(", ")", "\n", "if", "not", "args", ".", "testonly", ":", "\n", "        ", "config", ".", "log_args", "(", "args", ")", "\n", "\n", "", "if", "args", ".", "use_TB", ":", "\n", "        ", "from", "dateutil", "import", "tz", "\n", "from", "tensorboardX", "import", "SummaryWriter", "\n", "#        from torch.utils.tensorboard import SummaryWriter", "\n", "\n", "dt", "=", "datetime", ".", "now", "(", "tz", ".", "gettz", "(", "'Europe/Helsinki'", ")", ")", ".", "strftime", "(", "r\"%y%m%d_%H%M\"", ")", "\n", "global", "writer", "\n", "writer", "=", "SummaryWriter", "(", "\"{}/{}/{}\"", ".", "format", "(", "args", ".", "summary_dir", ",", "args", ".", "save_dir", ",", "dt", ")", ")", "\n", "\n", "", "random", ".", "seed", "(", "args", ".", "manual_seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "manual_seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "manual_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.encoder_train": [[97, 251], ["encoder.zero_grad", "generator.zero_grad", "torch.autograd.Variable().to", "train.KLN01Loss", "train.KLN01Loss", "encoder", "session.optimizerD.step", "x_in.clone().detach().requires_grad_().to().flip", "session.getResoPhase", "e_losses.append", "KLN01Loss.samples_mean.data.mean().item", "KLN01Loss.samples_var.data.mean().item", "KL_real.data.item", "torchvision.utils.gen_seq", "torchvision.utils.gen_seq", "loss_flip.backward", "loss_flip.data.item", "loss_flip.data.item", "print", "int", "torch.autograd.Variable().to", "torchvision.utils.populate_z", "generatedImagePool.query.requires_grad_", "encoder", "e_losses.append", "KLN01Loss.samples_mean.data.mean", "KLN01Loss.samples_var.data.mean", "torch.min.data.item", "len", "sum", "sum.backward", "numpy.float32", "session.optimizerA.step", "torch.autograd.Variable", "generator", "err.data.item", "torch.autograd.Variable().to", "torchvision.utils.populate_z", "torch.no_grad", "torch.no_grad", "torchvision.utils.gen_seq().detach", "generatedImagePool.query", "session.getResoPhase", "KLN01Loss.", "torch.min", "torch.min", "KL_fake.data.item", "sum.data.cpu", "b.mod.parameters", "x_in.clone().detach().requires_grad_().to", "KLN01Loss.", "KLN01Loss.samples_mean.data.mean", "KLN01Loss.samples_var.data.mean", "print", "err.backward", "e_losses.append", "b.mod.parameters", "torch.autograd.Variable", "torch.cat", "torch.cat", "numpy.random.randint", "torch.max", "torch.max", "param.requires_grad_", "int", "int", "torchvision.utils.mismatch", "torchvision.utils.mismatch", "torchvision.utils.mismatch", "torchvision.utils.mismatch", "param.requires_grad_", "torch.FloatTensor", "torch.FloatTensor", "torch.autograd.Variable", "torchvision.utils.gen_seq", "x_in.clone().detach().requires_grad_", "int", "int", "KLN01Loss.", "KLN01Loss.", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.FloatTensor", "torch.FloatTensor", "Variable().to.size", "torch.ones_like", "torch.ones_like", "session.adaptive_loss[].lossfun", "session.adaptive_loss[].lossfun", "session.adaptive_loss[].lossfun", "torch.ones_like", "torch.ones_like", "Variable().to.size", "x_in.clone().detach", "Variable().to.size", "Variable().to.size", "Variable().to.size", "x_in.clone", "session.getResoPhase", "x_in.size", "session.getResoPhase", "x_in.clone().detach().requires_grad_().to().flip.size", "session.getResoPhase", "Variable().to.size", "x_in.size", "x_in.size", "x_in.clone().detach().requires_grad_().to().flip.size", "x_in.clone().detach().requires_grad_().to().flip.size", "Variable().to.size", "Variable().to.size"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.backward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.populate_z", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.backward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.populate_z", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.ImagePool.query", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.backward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatch", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatch", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatch", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatch", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.general.lossfun", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.general.lossfun", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.general.lossfun", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["", "", "def", "encoder_train", "(", "session", ",", "real_image", ",", "generatedImagePool", ",", "batch_N", ",", "match_x", ",", "stats", ",", "kls", ",", "margin", ")", ":", "\n", "    ", "encoder", "=", "session", ".", "encoder", "\n", "generator", "=", "session", ".", "generator", "\n", "\n", "encoder", ".", "zero_grad", "(", ")", "\n", "generator", ".", "zero_grad", "(", ")", "\n", "\n", "x", "=", "Variable", "(", "real_image", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "#async=(args.gpu_count>1))", "\n", "KL_maximizer", "=", "KLN01Loss", "(", "direction", "=", "args", ".", "KL", ",", "minimize", "=", "False", ")", "\n", "KL_minimizer", "=", "KLN01Loss", "(", "direction", "=", "args", ".", "KL", ",", "minimize", "=", "True", ")", "\n", "\n", "e_losses", "=", "[", "]", "\n", "\n", "flipInvarianceLayer", "=", "args", ".", "flip_invariance_layer", "\n", "flipX", "=", "flipInvarianceLayer", ">", "-", "1", "and", "session", ".", "phase", ">=", "flipInvarianceLayer", "\n", "\n", "phiAdaCotrain", "=", "args", ".", "phi_ada_cotrain", "\n", "\n", "if", "flipX", ":", "\n", "        ", "phiAdaCotrain", "=", "True", "\n", "\n", "#global adaparams", "\n", "", "if", "phiAdaCotrain", ":", "\n", "        ", "for", "b", "in", "generator", ".", "module", ".", "adanorm_blocks", ":", "\n", "            ", "if", "not", "b", "is", "None", "and", "not", "b", ".", "mod", "is", "None", ":", "\n", "                ", "for", "param", "in", "b", ".", "mod", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "", "", "", "", "if", "flipX", ":", "\n", "        ", "x_in", "=", "x", "[", "0", ":", "int", "(", "x", ".", "size", "(", ")", "[", "0", "]", "/", "2", ")", ",", ":", ",", ":", ",", ":", "]", "\n", "x_mirror", "=", "x_in", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", ".", "flip", "(", "dims", "=", "[", "3", "]", ")", "\n", "x", "[", "int", "(", "x", ".", "size", "(", ")", "[", "0", "]", "/", "2", ")", ":", ",", ":", ",", ":", ",", ":", "]", "=", "x_mirror", "\n", "\n", "", "real_z", "=", "encoder", "(", "x", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", "\n", "\n", "if", "args", ".", "use_real_x_KL", ":", "\n", "# KL_real: - \\Delta( e(X) , Z ) -> max_e", "\n", "        ", "if", "not", "flipX", ":", "\n", "            ", "KL_real", "=", "KL_minimizer", "(", "real_z", ")", "*", "args", ".", "real_x_KL_scale", "\n", "", "else", ":", "# Treat the KL div of each direction of the data as separate distributions", "\n", "            ", "z_in", "=", "real_z", "[", "0", ":", "int", "(", "x", ".", "size", "(", ")", "[", "0", "]", "/", "2", ")", ",", ":", "]", "\n", "z_in_mirror", "=", "real_z", "[", "int", "(", "x", ".", "size", "(", ")", "[", "0", "]", "/", "2", ")", ":", ",", ":", "]", "\n", "KL_real", "=", "(", "KL_minimizer", "(", "z_in", ")", "+", "\n", "KL_minimizer", "(", "z_in_mirror", ")", ")", "*", "args", ".", "real_x_KL_scale", "/", "2", "\n", "", "e_losses", ".", "append", "(", "KL_real", ")", "\n", "\n", "stats", "[", "'real_mean'", "]", "=", "KL_minimizer", ".", "samples_mean", ".", "data", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'real_var'", "]", "=", "KL_minimizer", ".", "samples_var", ".", "data", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'KL_real'", "]", "=", "KL_real", ".", "data", ".", "item", "(", ")", "\n", "kls", "=", "\"{0:.3f}\"", ".", "format", "(", "stats", "[", "'KL_real'", "]", ")", "\n", "\n", "", "if", "flipX", ":", "\n", "        ", "x_reco_in", "=", "utils", ".", "gen_seq", "(", "[", "(", "z_in", ",", "0", ",", "flipInvarianceLayer", ")", ",", "# Rotation of x_in, the ID of x_in_mirror (= the ID of x_in)", "\n", "(", "z_in_mirror", ",", "flipInvarianceLayer", ",", "-", "1", ")", "]", ",", "\n", "session", ".", "generator", ",", "session", ")", "\n", "\n", "x_reco_in_mirror", "=", "utils", ".", "gen_seq", "(", "[", "(", "z_in_mirror", ",", "0", ",", "flipInvarianceLayer", ")", ",", "# Vice versa", "\n", "(", "z_in", ",", "flipInvarianceLayer", ",", "-", "1", ")", "]", ",", "\n", "session", ".", "generator", ",", "session", ")", "\n", "\n", "if", "args", ".", "match_x_metric", "==", "'robust'", ":", "\n", "            ", "loss_flip", "=", "torch", ".", "mean", "(", "session", ".", "adaptive_loss", "[", "session", ".", "getResoPhase", "(", ")", "]", ".", "lossfun", "(", "(", "x_in", "-", "x_reco_in", ")", ".", "view", "(", "-", "1", ",", "x_in", ".", "size", "(", ")", "[", "1", "]", "*", "x_in", ".", "size", "(", ")", "[", "2", "]", "*", "x_in", ".", "size", "(", ")", "[", "3", "]", ")", ")", ")", "*", "match_x", "*", "0.2", "+", "torch", ".", "mean", "(", "session", ".", "adaptive_loss", "[", "session", ".", "getResoPhase", "(", ")", "]", ".", "lossfun", "(", "(", "x_mirror", "-", "x_reco_in_mirror", ")", ".", "view", "(", "-", "1", ",", "x_mirror", ".", "size", "(", ")", "[", "1", "]", "*", "x_mirror", ".", "size", "(", ")", "[", "2", "]", "*", "x_mirror", ".", "size", "(", ")", "[", "3", "]", ")", ")", ")", "*", "match_x", "*", "0.2", "\n", "", "else", ":", "\n", "            ", "loss_flip", "=", "(", "utils", ".", "mismatch", "(", "x_in", ",", "x_reco_in", ",", "args", ".", "match_x_metric", ")", "+", "\n", "utils", ".", "mismatch", "(", "x_mirror", ",", "x_reco_in_mirror", ",", "args", ".", "match_x_metric", ")", ")", "*", "args", ".", "match_x", "\n", "\n", "", "loss_flip", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "stats", "[", "'loss_flip'", "]", "=", "loss_flip", ".", "data", ".", "item", "(", ")", "\n", "stats", "[", "'x_reconstruction_error'", "]", "=", "loss_flip", ".", "data", ".", "item", "(", ")", "\n", "print", "(", "'Flip loss: {}'", ".", "format", "(", "stats", "[", "'loss_flip'", "]", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "use_loss_x_reco", ":", "\n", "            ", "recon_x", "=", "generator", "(", "real_z", ",", "None", ",", "session", ".", "phase", ",", "session", ".", "alpha", ")", "\n", "# match_x: E_x||g(e(x)) - x|| -> min_e", "\n", "\n", "if", "args", ".", "match_x_metric", "==", "'robust'", ":", "\n", "                ", "err_simple", "=", "utils", ".", "mismatch", "(", "recon_x", ",", "x", ",", "'L1'", ")", "*", "match_x", "\n", "err", "=", "torch", ".", "mean", "(", "session", ".", "adaptive_loss", "[", "session", ".", "getResoPhase", "(", ")", "]", ".", "lossfun", "(", "(", "recon_x", "-", "x", ")", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", ")", "[", "1", "]", "*", "x", ".", "size", "(", ")", "[", "2", "]", "*", "x", ".", "size", "(", ")", "[", "3", "]", ")", ")", ")", "*", "match_x", "*", "0.2", "\n", "print", "(", "\"err vs. ROBUST err: {} / {}\"", ".", "format", "(", "err_simple", ",", "err", ")", ")", "\n", "", "else", ":", "\n", "                ", "err_simple", "=", "utils", ".", "mismatch", "(", "recon_x", ",", "x", ",", "args", ".", "match_x_metric", ")", "*", "match_x", "\n", "err", "=", "err_simple", "\n", "\n", "", "if", "phiAdaCotrain", ":", "\n", "                ", "err", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "e_losses", ".", "append", "(", "err", ")", "\n", "", "stats", "[", "'x_reconstruction_error'", "]", "=", "err", ".", "data", ".", "item", "(", ")", "\n", "\n", "", "", "if", "phiAdaCotrain", ":", "\n", "        ", "for", "b", "in", "session", ".", "generator", ".", "module", ".", "adanorm_blocks", ":", "\n", "            ", "if", "not", "b", "is", "None", "and", "not", "b", ".", "mod", "is", "None", ":", "\n", "                ", "for", "param", "in", "b", ".", "mod", ".", "parameters", "(", ")", ":", "\n", "                   ", "param", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "", "", "", "", "if", "args", ".", "use_loss_fake_D_KL", ":", "\n", "# TODO: The following codeblock is essentially the same as the KL_minimizer part on G side. Unify", "\n", "\n", "        ", "mix_ratio", "=", "args", ".", "stylemix_E", "#0.25", "\n", "mix_N", "=", "int", "(", "mix_ratio", "*", "batch_N", ")", "\n", "z", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "batch_N", ",", "args", ".", "nz", ",", "1", ",", "1", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "#async=(args.gpu_count>1))", "\n", "utils", ".", "populate_z", "(", "z", ",", "args", ".", "nz", "+", "args", ".", "n_label", ",", "args", ".", "noise", ",", "batch_N", ")", "\n", "\n", "if", "session", ".", "phase", ">", "0", "and", "mix_N", ">", "0", ":", "\n", "            ", "alt_mix_z", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "mix_N", ",", "args", ".", "nz", ",", "1", ",", "1", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "#async=(args.gpu_count>1))", "\n", "utils", ".", "populate_z", "(", "alt_mix_z", ",", "args", ".", "nz", "+", "args", ".", "n_label", ",", "args", ".", "noise", ",", "mix_N", ")", "\n", "alt_mix_z", "=", "torch", ".", "cat", "(", "(", "alt_mix_z", ",", "z", "[", "mix_N", ":", ",", ":", "]", ")", ",", "dim", "=", "0", ")", "if", "mix_N", "<", "z", ".", "size", "(", ")", "[", "0", "]", "else", "alt_mix_z", "\n", "", "else", ":", "\n", "            ", "alt_mix_z", "=", "None", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "style_layer_begin", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "1", ",", "high", "=", "(", "session", ".", "phase", "+", "1", ")", ")", "if", "not", "alt_mix_z", "is", "None", "else", "-", "1", "\n", "fake", "=", "utils", ".", "gen_seq", "(", "[", "(", "z", ",", "0", ",", "style_layer_begin", ")", ",", "\n", "(", "alt_mix_z", ",", "style_layer_begin", ",", "-", "1", ")", "\n", "]", ",", "generator", ",", "session", ")", ".", "detach", "(", ")", "\n", "\n", "", "if", "session", ".", "alpha", ">=", "1.0", ":", "\n", "            ", "fake", "=", "generatedImagePool", ".", "query", "(", "fake", ".", "data", ")", "\n", "\n", "", "fake", ".", "requires_grad_", "(", ")", "\n", "\n", "# e(g(Z))", "\n", "egz", "=", "encoder", "(", "fake", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", "\n", "\n", "# KL_fake: \\Delta( e(g(Z)) , Z ) -> max_e", "\n", "KL_fake", "=", "KL_maximizer", "(", "egz", ")", "*", "args", ".", "fake_D_KL_scale", "\n", "\n", "if", "margin", ">", "0.0", ":", "\n", "             ", "KL_loss", "=", "torch", ".", "min", "(", "torch", ".", "ones_like", "(", "KL_fake", ")", "*", "margin", "/", "2", ",", "torch", ".", "max", "(", "-", "torch", ".", "ones_like", "(", "KL_fake", ")", "*", "margin", ",", "KL_real", "+", "KL_fake", ")", ")", "# KL_fake is always negative with abs value typically larger than KL_real. Hence, the sum is negative, and must be gapped so that the minimum is the negative of the margin.", "\n", "", "else", ":", "\n", "             ", "KL_loss", "=", "KL_real", "+", "KL_fake", "\n", "", "e_losses", ".", "append", "(", "KL_loss", ")", "\n", "\n", "stats", "[", "'fake_mean'", "]", "=", "KL_maximizer", ".", "samples_mean", ".", "data", ".", "mean", "(", ")", "\n", "stats", "[", "'fake_var'", "]", "=", "KL_maximizer", ".", "samples_var", ".", "data", ".", "mean", "(", ")", "\n", "stats", "[", "'KL_fake'", "]", "=", "-", "KL_fake", ".", "data", ".", "item", "(", ")", "\n", "stats", "[", "'KL_loss'", "]", "=", "KL_loss", ".", "data", ".", "item", "(", ")", "\n", "\n", "kls", "=", "\"{0}/{1:.3f}\"", ".", "format", "(", "kls", ",", "stats", "[", "'KL_fake'", "]", ")", "\n", "\n", "# Update e", "\n", "", "if", "len", "(", "e_losses", ")", ">", "0", ":", "\n", "        ", "e_loss", "=", "sum", "(", "e_losses", ")", "\n", "e_loss", ".", "backward", "(", ")", "\n", "stats", "[", "'E_loss'", "]", "=", "np", ".", "float32", "(", "e_loss", ".", "data", ".", "cpu", "(", ")", ")", "\n", "\n", "", "session", ".", "optimizerD", ".", "step", "(", ")", "\n", "\n", "if", "flipX", ":", "\n", "        ", "session", ".", "optimizerA", ".", "step", "(", ")", "#The AdaNorm params need to be updated separately since they are on \"generator side\"", "\n", "\n", "", "return", "kls", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.KL_of_encoded_G_output": [[252, 276], ["train.KLN01Loss", "torchvision.utils.gen_seq", "encoder", "numpy.random.randint", "session.getResoPhase", "torchvision.utils.gen_seq", "z_intermediates[].size", "z.size", "KLN01Loss.", "alt_mix_z.size", "z.size", "utils.gen_seq.size", "z_intermediate.size"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq"], ["", "def", "KL_of_encoded_G_output", "(", "generator", ",", "encoder", ",", "z", ",", "batch_N", ",", "session", ",", "alt_mix_z", ",", "mix_N", ")", ":", "\n", "    ", "KL_minimizer", "=", "KLN01Loss", "(", "direction", "=", "args", ".", "KL", ",", "minimize", "=", "True", ")", "\n", "#utils.populate_z(z, args.nz+args.n_label, args.noise, batch_N)", "\n", "\n", "assert", "(", "alt_mix_z", "is", "None", "or", "alt_mix_z", ".", "size", "(", ")", "[", "0", "]", "==", "z", ".", "size", "(", ")", "[", "0", "]", ")", "# Batch sizes must match", "\n", "mix_style_layer_begin", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "1", ",", "high", "=", "(", "session", ".", "phase", "+", "1", ")", ")", "if", "not", "alt_mix_z", "is", "None", "else", "-", "1", "\n", "z_intermediates", "=", "utils", ".", "gen_seq", "(", "[", "(", "z", ",", "0", ",", "mix_style_layer_begin", ")", ",", "\n", "(", "alt_mix_z", ",", "mix_style_layer_begin", ",", "-", "1", ")", "\n", "]", ",", "generator", ",", "session", ",", "retain_intermediate_results", "=", "True", ")", "\n", "\n", "assert", "(", "z_intermediates", "[", "0", "]", ".", "size", "(", ")", "[", "0", "]", "==", "z", ".", "size", "(", ")", "[", "0", "]", ")", "# Batch sizes must remain invariant", "\n", "fake", "=", "z_intermediates", "[", "1", "if", "not", "alt_mix_z", "is", "None", "else", "0", "]", "\n", "z_intermediate", "=", "z_intermediates", "[", "0", "]", "[", ":", "mix_N", ",", ":", "]", "\n", "\n", "egz", "=", "encoder", "(", "fake", ",", "session", ".", "getResoPhase", "(", ")", ",", "session", ".", "alpha", ",", "args", ".", "use_ALQ", ")", "\n", "\n", "if", "mix_style_layer_begin", ">", "-", "1", ":", "\n", "        ", "egz_intermediate", "=", "utils", ".", "gen_seq", "(", "[", "(", "egz", "[", ":", "mix_N", ",", ":", "]", ",", "0", ",", "mix_style_layer_begin", ")", "]", ",", "generator", ",", "session", ")", "# Or we could just call generator directly, ofc.", "\n", "assert", "(", "egz_intermediate", ".", "size", "(", ")", "[", "0", "]", "==", "z_intermediate", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "egz_intermediate", "=", "z_intermediate", "=", "None", "\n", "\n", "# KL_fake: \\Delta( e(g(Z)) , Z ) -> min_g", "\n", "", "return", "egz", ",", "KL_minimizer", "(", "egz", ")", "*", "args", ".", "fake_G_KL_scale", ",", "egz_intermediate", ",", "z_intermediate", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.decoder_train": [[277, 332], ["session.generator.zero_grad", "torch.autograd.Variable().to", "torchvision.utils.populate_z", "train.KL_of_encoded_G_output", "session.optimizerG.step", "session.generator.module.to_rgb[].parameters", "int", "torch.autograd.Variable().to", "torchvision.utils.populate_z", "g_losses.append", "kl.data.item", "g_losses.append", "z_diff.data.item", "len", "sum", "numpy.float32", "sum.backward", "p.requires_grad_", "torch.autograd.Variable", "torch.cat", "torch.cat", "torchvision.utils.mismatch", "torchvision.utils.mismatch", "torch.zeros().cuda", "torch.zeros().cuda", "g_losses.append", "z_mix_diff.data.item", "sum.data.cpu", "list", "numpy.linalg.norm", "print", "torch.FloatTensor", "torch.FloatTensor", "torch.autograd.Variable", "egz_intermediate.view", "z_intermediate.view", "session.generator.adanorm_blocks[].mod.parameters", "adaparams0[].detach().cpu().numpy().ravel", "torch.FloatTensor", "torch.FloatTensor", "Variable().to.size", "torch.zeros", "torch.zeros", "numpy.linalg.norm", "adaparams0[].detach().cpu().numpy", "adaparams0[].grad.detach().cpu().numpy().ravel", "adaparams0[].detach().cpu", "adaparams0[].grad.detach().cpu().numpy", "adaparams0[].detach", "adaparams0[].grad.detach().cpu", "adaparams0[].grad.detach"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.populate_z", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.KL_of_encoded_G_output", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.populate_z", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.backward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatch", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatch"], ["", "def", "decoder_train", "(", "session", ",", "batch_N", ",", "stats", ",", "kls", ",", "x", ")", ":", "\n", "    ", "session", ".", "generator", ".", "zero_grad", "(", ")", "\n", "\n", "if", "session", ".", "phase", ">", "0", ":", "\n", "        ", "for", "p", "in", "session", ".", "generator", ".", "module", ".", "to_rgb", "[", "session", ".", "phase", "-", "1", "]", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "", "", "g_losses", "=", "[", "]", "\n", "\n", "mix_ratio", "=", "args", ".", "stylemix_D", "\n", "mix_N", "=", "int", "(", "mix_ratio", "*", "batch_N", ")", "if", "session", ".", "phase", ">", "0", "else", "0", "\n", "z", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "batch_N", ",", "args", ".", "nz", ",", "1", ",", "1", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "utils", ".", "populate_z", "(", "z", ",", "args", ".", "nz", "+", "args", ".", "n_label", ",", "args", ".", "noise", ",", "batch_N", ")", "\n", "\n", "if", "mix_N", ">", "0", ":", "\n", "        ", "alt_mix_z", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "mix_N", ",", "args", ".", "nz", ",", "1", ",", "1", ")", ")", ".", "to", "(", "device", "=", "args", ".", "device", ")", "\n", "utils", ".", "populate_z", "(", "alt_mix_z", ",", "args", ".", "nz", "+", "args", ".", "n_label", ",", "args", ".", "noise", ",", "mix_N", ")", "\n", "alt_mix_z", "=", "torch", ".", "cat", "(", "(", "alt_mix_z", ",", "z", "[", "mix_N", ":", ",", ":", "]", ")", ",", "dim", "=", "0", ")", "if", "mix_N", "<", "z", ".", "size", "(", ")", "[", "0", "]", "else", "alt_mix_z", "\n", "", "else", ":", "\n", "        ", "alt_mix_z", "=", "None", "\n", "\n", "# KL is calculated from the distro of z's that was re-encoded from z and mixed-z", "\n", "", "egz", ",", "kl", ",", "egz_intermediate", ",", "z_intermediate", "=", "KL_of_encoded_G_output", "(", "session", ".", "generator", ",", "session", ".", "encoder", ",", "z", ",", "batch_N", ",", "session", ",", "alt_mix_z", ",", "mix_N", ")", "\n", "\n", "if", "args", ".", "use_loss_KL_z", ":", "\n", "        ", "g_losses", ".", "append", "(", "kl", ")", "# G minimizes this KL", "\n", "stats", "[", "'KL(Phi(G))'", "]", "=", "kl", ".", "data", ".", "item", "(", ")", "\n", "kls", "=", "\"{0}/{1:.3f}\"", ".", "format", "(", "kls", ",", "stats", "[", "'KL(Phi(G))'", "]", ")", "\n", "\n", "# z_diff is calculated only from the regular z (not mixed z)", "\n", "", "if", "args", ".", "use_loss_z_reco", ":", "#and (mix_N == 0 or session.phase == 0):", "\n", "        ", "z_diff", "=", "utils", ".", "mismatch", "(", "egz", "[", "mix_N", ":", ",", ":", "]", ",", "z", "[", "mix_N", ":", ",", ":", "]", ",", "args", ".", "match_z_metric", ")", "*", "args", ".", "match_z", "# G tries to make the original z and encoded z match #Alternative: [mix_N:,:]", "\n", "z_mix_diff", "=", "utils", ".", "mismatch", "(", "egz_intermediate", ".", "view", "(", "[", "mix_N", ",", "-", "1", "]", ")", ",", "z_intermediate", ".", "view", "(", "[", "mix_N", ",", "-", "1", "]", ")", ",", "'L2'", ")", "if", "mix_N", ">", "0", "else", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", "\n", "if", "args", ".", "intermediate_zreco", ">", "0", ":", "\n", "            ", "g_losses", ".", "append", "(", "z_mix_diff", ")", "\n", "", "g_losses", ".", "append", "(", "z_diff", ")", "\n", "stats", "[", "'z_reconstruction_error'", "]", "=", "z_diff", ".", "data", ".", "item", "(", ")", "\n", "if", "args", ".", "intermediate_zreco", ">", "0", ":", "\n", "            ", "stats", "[", "'z_mix_reconstruction_error'", "]", "=", "z_mix_diff", ".", "data", ".", "item", "(", ")", "\n", "\n", "", "", "if", "len", "(", "g_losses", ")", ">", "0", ":", "\n", "        ", "loss", "=", "sum", "(", "g_losses", ")", "\n", "stats", "[", "'G_loss'", "]", "=", "np", ".", "float32", "(", "loss", ".", "data", ".", "cpu", "(", ")", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "False", ":", "#For debugging the adanorm blocks", "\n", "            ", "from", "model", "import", "AdaNorm", "\n", "adaparams0", "=", "list", "(", "session", ".", "generator", ".", "adanorm_blocks", "[", "0", "]", ".", "mod", ".", "parameters", "(", ")", ")", "\n", "param_scale", "=", "np", ".", "linalg", ".", "norm", "(", "adaparams0", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", "\n", "print", "(", "\"Ada norm: {} / {}\"", ".", "format", "(", "np", ".", "linalg", ".", "norm", "(", "adaparams0", "[", "0", "]", ".", "grad", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", ",", "param_scale", ")", ")", "\n", "\n", "", "", "session", ".", "optimizerG", ".", "step", "(", ")", "\n", "\n", "return", "kls", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.train": [[334, 487], ["tqdm.tqdm", "tqdm.tqdm.close", "len", "print", "sched.update", "sched.get_iteration_of_current_phase", "session.getReso", "torchvision.utils.switch_grad_updates_to_first_of", "train.encoder_train", "session.getBatchSize", "tqdm.tqdm.set_description", "tqdm.tqdm.update", "min", "session.prepareAdaptiveLossForNewPhase", "pioneer.data.Utils.sample_data2", "print", "torchvision.utils.ImagePool", "print", "next", "session.getBatchSize", "torchvision.utils.switch_grad_updates_to_first_of", "range", "pioneer.session.accumulate", "stats.items", "writer.add_scalar", "float", "print", "pioneer.evaluate.tests_run", "train_data_loader", "torchvision.utils.requires_grad", "torchvision.utils.requires_grad", "generator.zero_grad", "encoder.zero_grad", "session.reset_opt", "print", "session.getBatchSize", "pioneer.data.Utils.sample_data2", "next", "train.decoder_train", "writer.add_scalar", "print", "float", "str().zfill", "session.save_all", "print", "session.getBatchSize", "session.getBatchSize", "session.getResoPhase", "str"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.None.h5tool.HDF5Exporter.close", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.get_iteration_of_current_phase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.switch_grad_updates_to_first_of", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.encoder_train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getBatchSize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.prepareAdaptiveLossForNewPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getBatchSize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.switch_grad_updates_to_first_of", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.accumulate", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.tests_run", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.reset_opt", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getBatchSize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.decoder_train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.save_all", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getBatchSize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getBatchSize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["", "def", "train", "(", "generator", ",", "encoder", ",", "g_running", ",", "train_data_loader", ",", "test_data_loader", ",", "session", ",", "total_steps", ",", "train_mode", ",", "sched", ")", ":", "\n", "    ", "pbar", "=", "tqdm", "(", "initial", "=", "session", ".", "sample_i", ",", "total", "=", "total_steps", ")", "\n", "\n", "benchmarking", "=", "False", "\n", "\n", "match_x", "=", "args", ".", "match_x", "\n", "generatedImagePool", "=", "None", "\n", "\n", "refresh_dataset", "=", "True", "\n", "refresh_imagePool", "=", "True", "\n", "refresh_adaptiveLoss", "=", "False", "\n", "\n", "# After the Loading stage, we cycle through successive Fade-in and Stabilization stages", "\n", "\n", "batch_count", "=", "0", "\n", "\n", "reset_optimizers_on_phase_start", "=", "False", "\n", "\n", "# TODO Unhack this (only affects the episode count statistics anyway):", "\n", "if", "args", ".", "data", "!=", "'celebaHQ'", ":", "\n", "        ", "epoch_len", "=", "len", "(", "train_data_loader", "(", "1", ",", "4", ")", ".", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "epoch_len", "=", "train_data_loader", ".", "_len", "[", "'data4x4'", "]", "\n", "\n", "", "if", "args", ".", "step_offset", "!=", "0", ":", "\n", "        ", "if", "args", ".", "step_offset", "==", "-", "1", ":", "\n", "            ", "args", ".", "step_offset", "=", "session", ".", "sample_i", "\n", "", "print", "(", "\"Step offset is {}\"", ".", "format", "(", "args", ".", "step_offset", ")", ")", "\n", "session", ".", "phase", "+=", "args", ".", "phase_offset", "\n", "session", ".", "alpha", "=", "0.0", "\n", "\n", "", "last_fade_done_at_reso", "=", "-", "1", "\n", "\n", "while", "session", ".", "sample_i", "<", "total_steps", ":", "\n", "#######################  Phase Maintenance ####################### ", "\n", "        ", "sched", ".", "update", "(", "session", ".", "sample_i", ")", "\n", "sample_i_current_stage", "=", "sched", ".", "get_iteration_of_current_phase", "(", "session", ".", "sample_i", ")", "\n", "\n", "if", "sched", ".", "phaseChangedOnLastUpdate", ":", "\n", "            ", "match_x", "=", "args", ".", "match_x", "# Reset to non-matching phase", "\n", "refresh_dataset", "=", "True", "\n", "refresh_imagePool", "=", "True", "# Reset the pool to avoid images of 2 different resolutions in the pool", "\n", "refresh_adaptiveLoss", "=", "True", "\n", "if", "reset_optimizers_on_phase_start", ":", "\n", "                ", "utils", ".", "requires_grad", "(", "generator", ")", "\n", "utils", ".", "requires_grad", "(", "encoder", ")", "\n", "generator", ".", "zero_grad", "(", ")", "\n", "encoder", ".", "zero_grad", "(", ")", "\n", "session", ".", "reset_opt", "(", ")", "\n", "print", "(", "\"Optimizers have been reset.\"", ")", "\n", "\n", "", "", "reso", "=", "session", ".", "getReso", "(", ")", "\n", "\n", "# If we can switch from fade-training to stable-training", "\n", "if", "sample_i_current_stage", ">=", "args", ".", "images_per_stage", "/", "2", ":", "\n", "            ", "if", "session", ".", "alpha", "<", "1.0", ":", "\n", "                ", "refresh_dataset", "=", "True", "# refresh dataset generator since no longer have to fade", "\n", "last_fade_done_at_reso", "=", "reso", "\n", "session", ".", "alpha", "=", "1", "\n", "", "match_x", "=", "args", ".", "match_x", "*", "args", ".", "matching_phase_x", "\n", "", "else", ":", "\n", "            ", "match_x", "=", "args", ".", "match_x", "\n", "\n", "# We track whether this resolution was already present in the previous stage, which means that it was already faded once.", "\n", "", "if", "last_fade_done_at_reso", "!=", "reso", ":", "\n", "            ", "session", ".", "alpha", "=", "min", "(", "1", ",", "sample_i_current_stage", "*", "2.0", "/", "args", ".", "images_per_stage", ")", "# For 100k, it was 0.00002 = 2.0 / args.images_per_stage", "\n", "\n", "", "if", "refresh_adaptiveLoss", ":", "\n", "            ", "session", ".", "prepareAdaptiveLossForNewPhase", "(", ")", "\n", "refresh_adaptiveLoss", "=", "False", "\n", "", "if", "refresh_dataset", ":", "\n", "            ", "train_dataset", "=", "data", ".", "Utils", ".", "sample_data2", "(", "train_data_loader", ",", "session", ".", "getBatchSize", "(", ")", ",", "reso", ",", "session", ")", "\n", "refresh_dataset", "=", "False", "\n", "print", "(", "\"Refreshed dataset. Alpha={} and iteration={}\"", ".", "format", "(", "session", ".", "alpha", ",", "sample_i_current_stage", ")", ")", "\n", "", "if", "refresh_imagePool", ":", "\n", "            ", "imagePoolSize", "=", "200", "if", "reso", "<", "256", "else", "100", "\n", "generatedImagePool", "=", "utils", ".", "ImagePool", "(", "imagePoolSize", ")", "#Reset the pool to avoid images of 2 different resolutions in the pool", "\n", "refresh_imagePool", "=", "False", "\n", "print", "(", "'Image pool created with size {} because reso is {}'", ".", "format", "(", "imagePoolSize", ",", "reso", ")", ")", "\n", "\n", "####################### Training init ####################### ", "\n", "\n", "", "stats", "=", "{", "}", "\n", "stats", "[", "'z_mix_reconstruction_error'", "]", "=", "0", "\n", "\n", "try", ":", "\n", "            ", "real_image", ",", "_", "=", "next", "(", "train_dataset", ")", "\n", "", "except", "(", "OSError", ",", "StopIteration", ")", ":", "\n", "            ", "train_dataset", "=", "data", ".", "Utils", ".", "sample_data2", "(", "train_data_loader", ",", "session", ".", "getBatchSize", "(", ")", ",", "reso", ",", "session", ")", "\n", "real_image", ",", "_", "=", "next", "(", "train_dataset", ")", "\n", "\n", "####################### DISCRIMINATOR / ENCODER ###########################", "\n", "\n", "", "utils", ".", "switch_grad_updates_to_first_of", "(", "encoder", ",", "generator", ")", "\n", "kls", "=", "encoder_train", "(", "session", ",", "real_image", ",", "generatedImagePool", ",", "session", ".", "getBatchSize", "(", ")", ",", "match_x", ",", "stats", ",", "\"\"", ",", "margin", "=", "sched", ".", "m", ")", "\n", "\n", "######################## GENERATOR / DECODER #############################", "\n", "\n", "if", "(", "batch_count", "+", "1", ")", "%", "args", ".", "n_critic", "==", "0", ":", "\n", "            ", "utils", ".", "switch_grad_updates_to_first_of", "(", "generator", ",", "encoder", ")", "\n", "\n", "for", "_", "in", "range", "(", "args", ".", "n_generator", ")", ":", "\n", "                ", "kls", "=", "decoder_train", "(", "session", ",", "session", ".", "getBatchSize", "(", ")", ",", "stats", ",", "kls", ",", "real_image", ".", "data", ")", "\n", "\n", "", "accumulate", "(", "g_running", ",", "generator", ")", "\n", "\n", "", "del", "real_image", "\n", "\n", "########################  Statistics ######################## ", "\n", "\n", "if", "args", ".", "use_TB", ":", "\n", "            ", "for", "key", ",", "val", "in", "stats", ".", "items", "(", ")", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "key", ",", "val", ",", "session", ".", "sample_i", ")", "\n", "", "", "elif", "batch_count", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "stats", ")", "\n", "\n", "", "if", "args", ".", "use_TB", ":", "\n", "            ", "writer", ".", "add_scalar", "(", "'LOD'", ",", "session", ".", "getResoPhase", "(", ")", "+", "session", ".", "alpha", ",", "session", ".", "sample_i", ")", "\n", "\n", "", "b", "=", "session", ".", "getBatchSize", "(", ")", "\n", "zr", ",", "xr", "=", "(", "stats", "[", "'z_reconstruction_error'", "]", ",", "stats", "[", "'x_reconstruction_error'", "]", ")", "if", "(", "'z_reconstruction_error'", "in", "stats", "and", "'x_reconstruction_error'", "in", "stats", ")", "else", "(", "0.0", ",", "0.0", ")", "\n", "e", "=", "(", "session", ".", "sample_i", "/", "float", "(", "epoch_len", ")", ")", "\n", "\n", "pbar", ".", "set_description", "(", "\n", "(", "'{0}; it: {1}; phase: {2}; b: {3:.1f}; Alpha: {4:.3f}; Reso: {5}; E: {6:.2f}; KL(Phi(x)/Phi(G0)/Phi(G1)/Phi(G2)): {7}; z-reco: {8:.2f}; x-reco {9:.3f}; real_var {10:.6f}; fake_var {11:.6f}; z-mix: {12:.4f};'", ")", ".", "format", "(", "batch_count", "+", "1", ",", "session", ".", "sample_i", "+", "1", ",", "session", ".", "phase", ",", "b", ",", "session", ".", "alpha", ",", "reso", ",", "e", ",", "kls", ",", "zr", ",", "xr", ",", "stats", "[", "'real_var'", "]", ",", "stats", "[", "'fake_var'", "]", ",", "float", "(", "stats", "[", "'z_mix_reconstruction_error'", "]", ")", ")", "\n", ")", "\n", "\n", "pbar", ".", "update", "(", "b", ")", "\n", "session", ".", "sample_i", "+=", "b", "# if not benchmarking else 100", "\n", "batch_count", "+=", "1", "\n", "\n", "########################  Saving ######################## ", "\n", "\n", "if", "batch_count", "%", "args", ".", "checkpoint_cycle", "==", "0", "or", "session", ".", "sample_i", ">=", "total_steps", ":", "\n", "            ", "for", "postfix", "in", "{", "str", "(", "session", ".", "sample_i", ")", ".", "zfill", "(", "6", ")", "}", ":", "# 'latest'", "\n", "                ", "session", ".", "save_all", "(", "'{}/{}_state'", ".", "format", "(", "args", ".", "checkpoint_dir", ",", "postfix", ")", ")", "\n", "\n", "", "print", "(", "\"Checkpointed to {}\"", ".", "format", "(", "session", ".", "sample_i", ")", ")", "\n", "\n", "########################  Tests ######################## ", "\n", "\n", "", "try", ":", "\n", "            ", "evaluate", ".", "tests_run", "(", "g_running", ",", "encoder", ",", "test_data_loader", ",", "session", ",", "writer", ",", "\n", "reconstruction", "=", "(", "batch_count", "%", "2400", "==", "0", ")", ",", "\n", "interpolation", "=", "(", "batch_count", "%", "2400", "==", "0", ")", ",", "\n", "collated_sampling", "=", "(", "batch_count", "%", "800", "==", "0", ")", ",", "\n", "individual_sampling", "=", "False", ",", "#(batch_count % (args.images_per_stage/batch_size(reso)/4) == 0),", "\n", "metric_eval", "=", "(", "batch_count", "%", "2500", "==", "0", ")", "\n", ")", "\n", "", "except", "(", "OSError", ",", "StopIteration", ")", ":", "\n", "            ", "print", "(", "\"Skipped periodic tests due to an exception.\"", ")", "\n", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.makeTS": [[488, 531], ["print", "pioneer.training_scheduler.TrainingScheduler", "range", "range", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "pioneer.training_scheduler.TrainingScheduler.add", "range", "pioneer.training_scheduler.TrainingScheduler.add"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add"], ["", "def", "makeTS", "(", "opts", ",", "session", ")", ":", "\n", "    ", "print", "(", "\"Using preset training scheduler of celebaHQ and LSUN Bedrooms to set phase length, LR and KL margin. To override this behavior, modify the makeTS() function.\"", ")", "\n", "\n", "ts", "=", "TrainingScheduler", "(", "opts", ",", "session", ")", "\n", "\n", "for", "p", "in", "range", "(", "0", ",", "2", ")", ":", "\n", "        ", "ts", ".", "add", "(", "p", "*", "2400", ",", "_phase", "=", "p", ",", "_lr", "=", "[", "0.0005", ",", "0.0005", "]", ",", "_margin", "=", "0", ",", "_aux_operations", "=", "None", ")", "\n", "#        ts.add(p*2400, _phase=p, _lr=[0.0005, 0.0005], _margin=0.20, _aux_operations=None) # Use this instead if the early stages tend to diverge catastrophically", "\n", "\n", "", "for", "p", "in", "range", "(", "2", ",", "4", ")", ":", "\n", "        ", "ts", ".", "add", "(", "p", "*", "2400", ",", "_phase", "=", "p", ",", "_lr", "=", "[", "0.0005", ",", "0.0005", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "\n", "", "if", "args", ".", "data", "==", "'celebaHQ'", ":", "\n", "        ", "ts", ".", "add", "(", "9600", ",", "_phase", "=", "4", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "if", "args", ".", "flip_invariance_layer", "<=", "0", ":", "\n", "            ", "ts", ".", "add", "(", "20040", ",", "_phase", "=", "5", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.02", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "27500", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.04", ",", "_aux_operations", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "ts", ".", "add", "(", "12000", ",", "_phase", "=", "5", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "#Phase 5 <=> reso 64x64 extension", "\n", "ts", ".", "add", "(", "20040", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "#Phase 6 <=> reso 128x128", "\n", "", "", "elif", "args", ".", "data", "==", "'ffhq'", ":", "\n", "        ", "ts", ".", "add", "(", "9600", ",", "_phase", "=", "4", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "if", "args", ".", "flip_invariance_layer", "<=", "0", ":", "\n", "            ", "ts", ".", "add", "(", "20040", ",", "_phase", "=", "5", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "30680", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "35700", ",", "_phase", "=", "7", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "ts", ".", "add", "(", "12000", ",", "_phase", "=", "5", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "#Phase 5 <=> reso 64x64 extension", "\n", "ts", ".", "add", "(", "20040", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "#Phase 6 <=> reso 128x128", "\n", "", "", "elif", "args", ".", "data", "==", "'lsun'", ":", "\n", "        ", "ts", ".", "add", "(", "9600", ",", "_phase", "=", "4", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "if", "args", ".", "lsunm02e", ":", "\n", "            ", "ts", ".", "add", "(", "20040", ",", "_phase", "=", "5", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.02", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "24840", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "ts", ".", "add", "(", "20040", ",", "_phase", "=", "5", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "30000", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "38000", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0.08", ",", "_aux_operations", "=", "None", ")", "\n", "", "", "elif", "args", ".", "data", "!=", "'cifar10'", ":", "\n", "        ", "for", "p", "in", "range", "(", "4", ",", "8", ")", ":", "\n", "            ", "ts", ".", "add", "(", "p", "*", "2400", ",", "_phase", "=", "p", ",", "_lr", "=", "[", "0.001", ",", "0.001", "]", ",", "_margin", "=", "0", ",", "_aux_operations", "=", "None", ")", "\n", "\n", "", "", "return", "ts", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.main": [[532, 592], ["train.setup", "print", "torch.hub.load", "torch.hub.load", "pioneer.session.Session", "pioneer.session.Session.create", "pioneer.session.Session.eval", "pioneer.session.Session.train", "pioneer.data.get_loader", "pioneer.data.get_loader", "train.makeTS", "train.train", "pioneer.data.get_loader", "pioneer.evaluate.tests_run", "pioneer.data.dump_training_set"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.setup", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.create", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.get_loader", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.get_loader", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.train.makeTS", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.get_loader", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.evaluate.tests_run", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.dump_training_set"], ["", "def", "main", "(", ")", ":", "\n", "    ", "setup", "(", ")", "\n", "\n", "if", "args", ".", "save_dir", "is", "None", ":", "\n", "        ", "session", "=", "torch", ".", "hub", ".", "load", "(", "args", ".", "hub", ",", "args", ".", "hub_model", ",", "pretrained", "=", "True", ",", "source", "=", "'github'", ")", "\n", "# Even when the model is Hub-loaded, we need to save any results and updated checkpoints here:", "\n", "args", ".", "save_dir", "=", "args", ".", "hub_model", "\n", "", "else", ":", "\n", "#Here, we load pretrained model after construction.", "\n", "        ", "session", "=", "Session", "(", "False", ",", "\n", "args", ".", "start_iteration", ",", "\n", "args", ".", "nz", "+", "1", ",", "\n", "args", ".", "n_label", ",", "\n", "args", ".", "start_phase", ",", "\n", "args", ".", "max_phase", ",", "\n", "args", ".", "match_x_metric", ",", "\n", "args", ".", "lr", ",", "\n", "args", ".", "reset_optimizers", ",", "\n", "args", ".", "no_progression", ",", "\n", "args", ".", "images_per_stage", ",", "\n", "args", ".", "device", ",", "\n", "arch", "=", "'small'", "if", "args", ".", "small_darch", "else", "None", ")", "\n", "session", ".", "create", "(", "args", ".", "save_dir", ",", "args", ".", "force_alpha", ")", "\n", "\n", "", "if", "args", ".", "testonly", ":", "\n", "        ", "session", ".", "eval", "(", "useLN", "=", "not", "args", ".", "no_LN", ")", "\n", "", "else", ":", "\n", "        ", "session", ".", "train", "(", ")", "\n", "\n", "", "print", "(", "'PyTorch {}'", ".", "format", "(", "torch", ".", "__version__", ")", ")", "\n", "\n", "if", "args", ".", "train_path", ":", "\n", "        ", "train_data_loader", "=", "data", ".", "get_loader", "(", "args", ".", "data", ",", "args", ".", "train_path", ")", "\n", "", "else", ":", "\n", "        ", "train_data_loader", "=", "None", "\n", "\n", "", "if", "args", ".", "test_path", "or", "args", ".", "z_inpath", ":", "\n", "        ", "test_data_loader", "=", "data", ".", "get_loader", "(", "args", ".", "data", ",", "args", ".", "test_path", ")", "\n", "", "elif", "args", ".", "aux_inpath", ":", "\n", "        ", "test_data_loader", "=", "data", ".", "get_loader", "(", "args", ".", "data", ",", "args", ".", "aux_inpath", ")", "\n", "", "else", ":", "\n", "        ", "test_data_loader", "=", "None", "\n", "\n", "# 4 modes: Train (with data/train), test (with data/test), aux-test (with custom aux_inpath), dump-training-set", "\n", "\n", "", "if", "args", ".", "run_mode", "==", "config", ".", "RUN_TRAIN", ":", "\n", "        ", "scheduler", "=", "makeTS", "(", "[", "session", ".", "optimizerD", ",", "session", ".", "optimizerG", "]", ",", "session", ")", "\n", "\n", "train", "(", "session", ".", "generator", ",", "session", ".", "encoder", ",", "session", ".", "g_running", ",", "train_data_loader", ",", "test_data_loader", ",", "\n", "session", "=", "session", ",", "\n", "total_steps", "=", "args", ".", "total_kimg", "*", "1000", ",", "\n", "train_mode", "=", "args", ".", "train_mode", ",", "\n", "sched", "=", "scheduler", ")", "\n", "", "elif", "args", ".", "run_mode", "==", "config", ".", "RUN_TEST", ":", "\n", "#evaluate.Utils.reconstruction_dryrun(session.g_running, session.encoder, test_data_loader, session=session)", "\n", "###evaluate.tests_run(session.generator, session.encoder, test_data_loader, session=session, writer=writer)", "\n", "        ", "evaluate", ".", "tests_run", "(", "session", ".", "g_running", ",", "session", ".", "encoder", ",", "test_data_loader", ",", "session", "=", "session", ",", "writer", "=", "writer", ")", "\n", "", "elif", "args", ".", "run_mode", "==", "config", ".", "RUN_DUMP", ":", "\n", "        ", "session", ".", "phase", "=", "args", ".", "start_phase", "\n", "data", ".", "dump_training_set", "(", "train_data_loader", ",", "args", ".", "dump_trainingset_N", ",", "args", ".", "dump_trainingset_dir", ",", "session", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.CelebAHQ.__init__": [[26, 36], ["print", "h5py.File", "all", "len", "data.CelebAHQ.dataset.keys"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "resolution", "=", "[", "'data2x2'", ",", "'data4x4'", ",", "'data8x8'", ",", "'data16x16'", ",", "'data32x32'", ",", "'data64x64'", ",", "'data128x128'", ",", "'data256x256'", ",", "'data512x512'", ",", "'data1024x1024'", "]", "\n", "self", ".", "_base_key", "=", "'data'", "\n", "print", "(", "\"Try H5 data path {}\"", ".", "format", "(", "path", ")", ")", "\n", "self", ".", "dataset", "=", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "\n", "\n", "self", ".", "_len", "=", "{", "k", ":", "len", "(", "self", ".", "dataset", "[", "k", "]", ")", "for", "k", "in", "resolution", "}", "\n", "\n", "assert", "all", "(", "[", "resol", "in", "self", ".", "dataset", ".", "keys", "(", ")", "for", "resol", "in", "resolution", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.CelebAHQ.__call__": [[37, 66], ["numpy.random.randint", "numpy.array", "max", "numpy.concatenate", "int", "torch.from_numpy", "upsample_op().cpu().numpy", "numpy.array().repeat().repeat", "range", "numpy.array", "numpy.array", "len", "upsample_op().cpu", "numpy.array().repeat", "random.randint", "numpy.flip", "numpy.flip", "upsample_op", "numpy.array"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch_size", ",", "reso", ",", "alpha", ")", ":", "\n", "        ", "bMethod", "=", "True", "\n", "flip_mode", "=", "False", "\n", "if", "flip_mode", ":", "\n", "            ", "batch_size", "=", "max", "(", "1", ",", "int", "(", "batch_size", "/", "2", ")", ")", "\n", "\n", "", "key", "=", "self", ".", "_base_key", "+", "'{}x{}'", ".", "format", "(", "reso", ",", "reso", ")", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "_len", "[", "key", "]", ",", "size", "=", "batch_size", ")", "\n", "hi_res_batch_x", "=", "np", ".", "array", "(", "[", "self", ".", "dataset", "[", "key", "]", "[", "i", "]", "/", "127.5", "-", "1.0", "for", "i", "in", "idx", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "ret_batch", "=", "[", "]", "\n", "if", "alpha", "<", "1.0", "and", "reso", ">", "4", ":", "\n", "            ", "lr_key", "=", "self", ".", "_base_key", "+", "'{}x{}'", ".", "format", "(", "reso", "//", "2", ",", "reso", "//", "2", ")", "\n", "if", "bMethod", ":", "\n", "                ", "low_res_batch_x", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "self", ".", "dataset", "[", "lr_key", "]", "[", "i", "]", "/", "127.5", "-", "1.0", "for", "i", "in", "idx", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "low_res_batch_x", "=", "upsample_op", "(", "(", "low_res_batch_x", ")", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "low_res_batch_x", "=", "np", ".", "array", "(", "[", "self", ".", "dataset", "[", "lr_key", "]", "[", "i", "]", "/", "127.5", "-", "1.0", "for", "i", "in", "idx", "]", ",", "dtype", "=", "np", ".", "float32", ")", ".", "repeat", "(", "2", ",", "axis", "=", "2", ")", ".", "repeat", "(", "2", ",", "axis", "=", "3", ")", "\n", "", "ret_batch", "=", "hi_res_batch_x", "*", "alpha", "+", "low_res_batch_x", "*", "(", "1.0", "-", "alpha", ")", "\n", "", "else", ":", "\n", "            ", "ret_batch", "=", "hi_res_batch_x", "\n", "\n", "", "if", "flip_mode", ":", "\n", "            ", "ret_batch", "=", "np", ".", "concatenate", "(", "(", "ret_batch", ",", "np", ".", "array", "(", "[", "np", ".", "flip", "(", "b", ",", "axis", "=", "2", ")", "for", "b", "in", "ret_batch", "]", ")", ")", ")", "\n", "", "elif", "args", ".", "sample_mirroring", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "ret_batch", ")", ")", ":", "\n", "                ", "if", "random", ".", "randint", "(", "0", ",", "1", ")", "==", "0", ":", "\n", "                    ", "ret_batch", "[", "i", "]", "=", "np", ".", "flip", "(", "ret_batch", "[", "i", "]", ",", "axis", "=", "2", ")", "\n", "\n", "", "", "", "return", "ret_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.lsun_loader": [[80, 92], ["torchvision.datasets.LSUNClass", "torch.utils.data.DataLoader"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "lsun_loader", "(", "path", ")", ":", "\n", "        ", "def", "loader", "(", "transform", ",", "batch_size", ")", ":", "\n", "            ", "data", "=", "datasets", ".", "LSUNClass", "(", "\n", "path", ",", "transform", "=", "transform", ",", "\n", "target_transform", "=", "lambda", "x", ":", "0", ")", "\n", "data_loader", "=", "DataLoader", "(", "data", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "(", "args", ".", "gpu_count", ">", "1", ")", ")", "\n", "\n", "return", "data_loader", "\n", "\n", "", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.celeba_loader": [[93, 104], ["torchvision.datasets.ImageFolder", "torch.utils.data.DataLoader", "Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "celeba_loader", "(", "path", ")", ":", "\n", "        ", "def", "loader", "(", "transform", ",", "batch_size", ")", ":", "\n", "            ", "from", "pathlib", "import", "Path", "\n", "data", "=", "datasets", ".", "ImageFolder", "(", "Path", "(", "path", ")", ",", "transform", "=", "transform", ")", "\n", "data_loader", "=", "DataLoader", "(", "data", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "4", ",", "drop_last", "=", "True", ",", "pin_memory", "=", "(", "args", ".", "gpu_count", ">", "1", ")", ")", "\n", "\n", "return", "data_loader", "\n", "\n", "", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.cifar10_loader": [[105, 115], ["torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "cifar10_loader", "(", "path", ")", ":", "\n", "        ", "def", "loader", "(", "transform", ",", "batch_size", ")", ":", "\n", "            ", "data", "=", "datasets", ".", "CIFAR10", "(", "root", "=", "path", ",", "download", "=", "True", ",", "\n", "transform", "=", "transform", ")", "\n", "data_loader", "=", "DataLoader", "(", "data", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "2", ",", "pin_memory", "=", "(", "args", ".", "gpu_count", ">", "1", ")", ")", "\n", "return", "data_loader", "\n", "\n", "", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data": [[116, 163], ["torchvision.transforms.Compose", "dataloader", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.Lambda", "torchvision.transforms.Compose", "print", "dataloader", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torch.from_numpy", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "sample_data", "(", "dataloader", ",", "batch_size", ",", "image_size", "=", "4", ")", ":", "\n", "        ", "maybeRandomHorizontalFlip", "=", "transforms", ".", "RandomHorizontalFlip", "(", ")", "if", "args", ".", "sample_mirroring", "else", "transforms", ".", "Lambda", "(", "nop", ")", "\n", "if", "(", "args", ".", "data", "==", "'celebaHQ'", ")", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "batch", "=", "dataloader", "(", "batch_size", ",", "image_size", ",", "0.0", ")", "\n", "yield", "torch", ".", "from_numpy", "(", "batch", ")", ",", "None", "#no label", "\n", "", "return", "# will never be reached", "\n", "\n", "", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "if", "args", ".", "data", "==", "'celeba'", "or", "args", ".", "data", "==", "'ffhq'", ":", "#center crop first to 128 (i.e. leave out the edge parts), then resize to this LOD size", "\n", "            ", "transform_with_resize", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "128", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "128", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "maybeRandomHorizontalFlip", ",", "\n", "#transforms.CenterCrop(image_size),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "", "elif", "args", ".", "data", "==", "'lsun'", ":", "# resize to the desired size, then center crop to this LOD size", "\n", "            ", "transform_with_resize", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "maybeRandomHorizontalFlip", ",", "\n", "transforms", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "", "elif", "args", ".", "data", "==", "'cifar10'", ":", "# No center crop, no horizontal flipping", "\n", "            ", "transform_with_resize", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "assert", "(", "False", ")", "\n", "\n", "", "if", "not", "args", ".", "resize_training_data", ":", "\n", "            ", "print", "(", "\"WARNING! MAKE SURE YOU RUN ON PRE-RESIZED DATA! DATA WILL NOT BE RESIZED.\"", ")", "\n", "\n", "", "loader", "=", "dataloader", "(", "transform_with_resize", "if", "args", ".", "resize_training_data", "else", "transform", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "for", "img", ",", "label", "in", "loader", ":", "\n", "            ", "yield", "img", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2": [[165, 265], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.Lambda", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "print", "dataloader", "dataloader", "dataloader", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.ToPILImage", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "numpy.array().repeat().repeat", "numpy.array", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "int", "torch.from_numpy", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "numpy.array().repeat", "torch.from_numpy", "torchvision.transforms.Compose.numpy", "torch.from_numpy", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "range", "numpy.array", "torchvision.transforms.Compose.", "img.size", "torchvision.transforms.Compose.numpy", "range", "torchvision.transforms.Compose.", "img.size"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "sample_data2", "(", "dataloader", ",", "batch_size", ",", "image_size", ",", "session", ")", ":", "\n", "        ", "maybeRandomHorizontalFlip", "=", "transforms", ".", "RandomHorizontalFlip", "(", ")", "if", "args", ".", "sample_mirroring", "else", "transforms", ".", "Lambda", "(", "nop", ")", "\n", "if", "(", "args", ".", "data", "==", "'celebaHQ'", ")", "and", "args", ".", "h5", ":", "\n", "            ", "while", "True", ":", "#This is an infinite iterator           ", "\n", "                ", "batch", "=", "dataloader", "(", "batch_size", ",", "image_size", ",", "session", ".", "alpha", ")", "\n", "yield", "torch", ".", "from_numpy", "(", "batch", ")", ",", "None", "#no label", "\n", "", "return", "# will never be reached", "\n", "\n", "", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "\n", "celebaMaxReso", "=", "128", "if", "args", ".", "data", "==", "'celeba'", "else", "512", "# 256->512 fixed after v1.0", "\n", "\n", "if", "args", ".", "data", "==", "'celeba'", "or", "args", ".", "data", "==", "'celebaHQ'", "or", "args", ".", "data", "==", "'ffhq'", ":", "\n", "            ", "transform_with_resize_norm", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "celebaMaxReso", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "celebaMaxReso", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "maybeRandomHorizontalFlip", ",", "\n", "#transforms.CenterCrop(image_size),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "transform_with_resize", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "celebaMaxReso", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "celebaMaxReso", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "maybeRandomHorizontalFlip", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "", "elif", "args", ".", "data", "==", "'lsun'", ":", "\n", "            ", "transform_with_resize_norm", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "maybeRandomHorizontalFlip", ",", "\n", "transforms", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "transform_with_resize", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "maybeRandomHorizontalFlip", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "", "elif", "args", ".", "data", "==", "'cifar10'", ":", "# No center crop, no horizontal flipping", "\n", "            ", "transform_with_resize_norm", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "transform_with_resize", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "assert", "(", "False", ")", "\n", "\n", "# Note that random flip is not re-applied when downscaling", "\n", "", "transform_with_resize_previous", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToPILImage", "(", ")", ",", "\n", "transforms", ".", "Resize", "(", "int", "(", "image_size", "/", "2", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "\n", "transform_with_normalize", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToPILImage", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n", "\n", "fade", "=", "image_size", ">", "4", "and", "session", ".", "alpha", "<", "1.0", "\n", "\n", "if", "not", "args", ".", "resize_training_data", ":", "\n", "            ", "print", "(", "\"WARNING! MAKE SURE YOU RUN ON PRE-RESIZED DATA! DATA WILL NOT BE RESIZED.\"", ")", "\n", "\n", "", "if", "fade", ":", "\n", "            ", "loader", "=", "dataloader", "(", "transform_with_resize", "if", "args", ".", "resize_training_data", "else", "transform", ",", "batch_size", "=", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "loader", "=", "dataloader", "(", "transform_with_resize_norm", "if", "args", ".", "resize_training_data", "else", "transform", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "", "for", "img", ",", "label", "in", "loader", ":", "\n", "            ", "if", "not", "fade", ":", "\n", "                ", "yield", "img", ",", "label", "\n", "", "else", ":", "\n", "                ", "low_resol_batch_x", "=", "np", ".", "array", "(", "[", "transform_with_resize_previous", "(", "img", "[", "i", "]", ")", ".", "numpy", "(", ")", "for", "i", "in", "range", "(", "img", ".", "size", "(", "0", ")", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", ".", "repeat", "(", "2", ",", "axis", "=", "2", ")", ".", "repeat", "(", "2", ",", "axis", "=", "3", ")", "\n", "\n", "# For testing:", "\n", "#alpha_delta = torch.from_numpy(np.linspace(0, 1, img.size(0),dtype=np.float32))", "\n", "#alpha_delta = alpha_delta.view((32,1,1,1))", "\n", "\n", "mixed_img", "=", "img", "*", "session", ".", "alpha", "+", "(", "(", "1.0", "-", "session", ".", "alpha", ")", "*", "torch", ".", "from_numpy", "(", "low_resol_batch_x", ")", ")", "\n", "mixed_img", "=", "np", ".", "array", "(", "[", "transform_with_normalize", "(", "mixed_img", "[", "i", "]", ")", ".", "numpy", "(", ")", "for", "i", "in", "range", "(", "img", ".", "size", "(", "0", ")", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# For testing:", "\n", "# yield img, torch.from_numpy(low_resol_batch_x), torch.from_numpy(mixed_img), label", "\n", "\n", "yield", "torch", ".", "from_numpy", "(", "mixed_img", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.nop": [[22, 24], ["None"], "function", ["None"], ["def", "nop", "(", "x", ")", ":", "\n", "    ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.get_loader": [[67, 78], ["data.Utils.celeba_loader", "data.Utils.lsun_loader", "data.Utils.cifar10_loader", "data.CelebAHQ", "data.Utils.celeba_loader"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.celeba_loader", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.lsun_loader", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.cifar10_loader", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.celeba_loader"], ["", "", "def", "get_loader", "(", "datasetName", ",", "path", ")", ":", "\n", "    ", "if", "datasetName", "==", "'celeba'", "or", "datasetName", "==", "'ffhq'", ":", "\n", "        ", "loader", "=", "Utils", ".", "celeba_loader", "(", "path", ")", "\n", "", "elif", "datasetName", "==", "'lsun'", ":", "\n", "        ", "loader", "=", "Utils", ".", "lsun_loader", "(", "path", ")", "\n", "", "elif", "datasetName", "==", "'cifar10'", ":", "\n", "        ", "loader", "=", "Utils", ".", "cifar10_loader", "(", "path", ")", "\n", "", "elif", "datasetName", "==", "'celebaHQ'", ":", "\n", "        ", "loader", "=", "CelebAHQ", "(", "path", ")", "if", "args", ".", "h5", "else", "Utils", ".", "celeba_loader", "(", "path", ")", "# CelebaHQ class expects the path that has the .h5 file. Regular celeba_loader does not.", "\n", "\n", "", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.dump_training_set": [[266, 289], ["min", "print", "Utils.sample_data2", "range", "os.path.exists", "os.makedirs", "min", "next", "range", "int", "torchvision.utils.save_image", "print"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.data.Utils.sample_data2"], ["", "", "", "", "def", "dump_training_set", "(", "loader", ",", "dump_trainingset_N", ",", "dump_trainingset_dir", ",", "session", ")", ":", "\n", "    ", "batch_size", "=", "8", "\n", "total", "=", "0", "\n", "\n", "phase", "=", "min", "(", "args", ".", "max_phase", ",", "session", ".", "phase", ")", "\n", "\n", "reso", "=", "4", "*", "(", "2", "**", "phase", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dump_trainingset_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dump_trainingset_dir", ")", "\n", "\n", "", "print", "(", "\"Dumping training data with {}x{} and alpha {}\"", ".", "format", "(", "reso", ",", "reso", ",", "session", ".", "alpha", ")", ")", "\n", "dataset", "=", "Utils", ".", "sample_data2", "(", "loader", ",", "batch_size", ",", "reso", ",", "session", ")", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "dump_trainingset_N", "/", "batch_size", ")", "+", "1", ")", ":", "\n", "        ", "curr_batch_size", "=", "min", "(", "batch_size", ",", "dump_trainingset_N", "-", "total", ")", "\n", "batch", ",", "_", "=", "next", "(", "dataset", ")", "\n", "for", "j", "in", "range", "(", "curr_batch_size", ")", ":", "\n", "            ", "save_path", "=", "'{}/orig_{}.png'", ".", "format", "(", "dump_trainingset_dir", ",", "total", ")", "\n", "total", "+=", "1", "\n", "grid", "=", "utils", ".", "save_image", "(", "batch", "[", "j", "]", "/", "2", "+", "0.5", ",", "save_path", ",", "padding", "=", "0", ")", "\n", "", "if", "total", "%", "500", "<", "batch_size", ":", "\n", "            ", "print", "(", "total", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.__init__": [[4, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opts", ",", "session", ")", ":", "\n", "        ", "self", ".", "configs", "=", "[", "]", "\n", "self", ".", "myphase", "=", "0", "\n", "self", ".", "opts", "=", "opts", "\n", "self", ".", "m", "=", "0", "\n", "self", ".", "session", "=", "session", "\n", "self", ".", "phaseChangedOnLastUpdate", "=", "False", "\n", "", "def", "update", "(", "self", ",", "iteration", ")", ":", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.update": [[11, 26], ["zip", "print", "print", "print", "len"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "iteration", ")", ":", "\n", "        ", "self", ".", "phaseChangedOnLastUpdate", "=", "False", "\n", "while", "(", "self", ".", "myphase", "<", "len", "(", "self", ".", "configs", ")", "-", "1", "and", "self", ".", "configs", "[", "self", ".", "myphase", "+", "1", "]", "[", "0", "]", "*", "1000", "<=", "iteration", ")", ":", "\n", "            ", "self", ".", "myphase", "+=", "1", "\n", "self", ".", "session", ".", "phase", "=", "self", ".", "configs", "[", "self", ".", "myphase", "]", "[", "1", "]", "\n", "for", "opt", ",", "lr", "in", "zip", "(", "self", ".", "opts", ",", "self", ".", "configs", "[", "self", ".", "myphase", "]", "[", "2", "]", ")", ":", "\n", "                ", "for", "param_group", "in", "opt", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "print", "(", "\"LR updated: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "print", "(", "'Margin updated: {} -> {}'", ".", "format", "(", "self", ".", "m", ",", "self", ".", "configs", "[", "self", ".", "myphase", "]", "[", "3", "]", ")", ")", "\n", "self", ".", "m", "=", "self", ".", "configs", "[", "self", ".", "myphase", "]", "[", "3", "]", "\n", "if", "not", "self", ".", "configs", "[", "self", ".", "myphase", "]", "[", "4", "]", "is", "None", ":", "\n", "                ", "self", ".", "configs", "[", "self", ".", "myphase", "]", "[", "4", "]", "(", ")", "\n", "", "self", ".", "phaseChangedOnLastUpdate", "=", "True", "\n", "print", "(", "\"Session updated phase to {} as iteration is {}\"", ".", "format", "(", "self", ".", "session", ".", "phase", ",", "iteration", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add": [[28, 31], ["None"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "_iteration", ",", "_phase", ",", "_lr", ",", "_margin", ",", "_aux_operations", ")", ":", "\n", "        ", "self", ".", "configs", "+=", "[", "(", "_iteration", ",", "_phase", ",", "_lr", ",", "_margin", ",", "_aux_operations", ")", "]", "\n", "return", "self", "\n", "", "def", "get_iteration_of_current_phase", "(", "self", ",", "iteration", ")", ":", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.get_iteration_of_current_phase": [[31, 33], ["None"], "methods", ["None"], ["", "def", "get_iteration_of_current_phase", "(", "self", ",", "iteration", ")", ":", "\n", "        ", "return", "iteration", "-", "self", ".", "configs", "[", "self", ".", "myphase", "]", "[", "0", "]", "*", "1000", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TestSession.__init__": [[36, 38], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "phase", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.testTrainingScheduler": [[39, 93], ["training_scheduler.TestSession", "torch.nn.Conv2d", "torch.optim.Adam", "torch.optim.Adam", "training_scheduler.TrainingScheduler", "training_scheduler.TrainingScheduler.add", "training_scheduler.TrainingScheduler.add", "training_scheduler.TrainingScheduler.add", "training_scheduler.TrainingScheduler.add", "training_scheduler.TrainingScheduler.update", "training_scheduler.TrainingScheduler.update", "training_scheduler.TrainingScheduler.update", "training_scheduler.TrainingScheduler.update", "training_scheduler.TrainingScheduler.update", "training_scheduler.TrainingScheduler.update", "training_scheduler.TrainingScheduler.update", "training_scheduler.TrainingScheduler.update", "nn.Conv2d.parameters", "nn.Conv2d.parameters"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.training_scheduler.TrainingScheduler.add", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update"], ["", "", "def", "testTrainingScheduler", "(", ")", ":", "\n", "    ", "s", "=", "TestSession", "(", ")", "\n", "\n", "nw", "=", "nn", ".", "Conv2d", "(", "3", ",", "512", ",", "1", ")", "\n", "\n", "opt1", "=", "optim", ".", "Adam", "(", "nw", ".", "parameters", "(", ")", ",", "0.0005", ",", "betas", "=", "(", "0.0", ",", "0.99", ")", ")", "\n", "opt2", "=", "optim", ".", "Adam", "(", "nw", ".", "parameters", "(", ")", ",", "0.0001", ",", "betas", "=", "(", "0.0", ",", "0.99", ")", ")", "\n", "ts", "=", "TrainingScheduler", "(", "[", "opt1", ",", "opt2", "]", ",", "s", ")", "\n", "\n", "ts", ".", "add", "(", "0", ",", "0", ",", "0", ",", "0", ",", "None", ")", "\n", "ts", ".", "add", "(", "9600", ",", "_phase", "=", "4", ",", "_lr", "=", "[", "0.002", ",", "0.0010", "]", ",", "_margin", "=", "0.05", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "14000", ",", "_phase", "=", "5", ",", "_lr", "=", "[", "0.003", ",", "0.0015", "]", ",", "_margin", "=", "0.06", ",", "_aux_operations", "=", "None", ")", "\n", "ts", ".", "add", "(", "20000", ",", "_phase", "=", "6", ",", "_lr", "=", "[", "0.004", ",", "0.0017", "]", ",", "_margin", "=", "0.07", ",", "_aux_operations", "=", "None", ")", "\n", "\n", "ts", ".", "update", "(", "9500000", ")", "\n", "assert", "(", "ts", ".", "m", "==", "0", ")", "\n", "assert", "(", "s", ".", "phase", "<", "4", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0005", ")", "\n", "\n", "ts", ".", "update", "(", "9600000", ")", "\n", "assert", "(", "ts", ".", "m", "==", "0.05", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.002", ")", "\n", "assert", "(", "opt2", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0010", ")", "\n", "assert", "(", "s", ".", "phase", "==", "4", ")", "\n", "ts", ".", "update", "(", "9600001", ")", "\n", "assert", "(", "ts", ".", "m", "==", "0.05", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.002", ")", "\n", "assert", "(", "opt2", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0010", ")", "\n", "assert", "(", "s", ".", "phase", "==", "4", ")", "\n", "ts", ".", "update", "(", "13999999", ")", "\n", "assert", "(", "ts", ".", "m", "==", "0.05", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.002", ")", "\n", "assert", "(", "opt2", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0010", ")", "\n", "assert", "(", "s", ".", "phase", "==", "4", ")", "\n", "ts", ".", "update", "(", "14000000", ")", "\n", "assert", "(", "ts", ".", "m", "==", "0.06", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.003", ")", "\n", "assert", "(", "opt2", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0015", ")", "\n", "assert", "(", "s", ".", "phase", "==", "5", ")", "\n", "ts", ".", "update", "(", "14000000", ")", "#Same, no change", "\n", "assert", "(", "ts", ".", "m", "==", "0.06", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.003", ")", "\n", "assert", "(", "opt2", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0015", ")", "\n", "assert", "(", "s", ".", "phase", "==", "5", ")", "\n", "ts", ".", "update", "(", "14000001", ")", "#+1 step, no change", "\n", "assert", "(", "ts", ".", "m", "==", "0.06", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.003", ")", "\n", "assert", "(", "opt2", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0015", ")", "\n", "assert", "(", "s", ".", "phase", "==", "5", ")", "\n", "ts", ".", "update", "(", "20000001", ")", "#next phase", "\n", "assert", "(", "ts", ".", "m", "==", "0.07", ")", "\n", "assert", "(", "opt1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.004", ")", "\n", "assert", "(", "opt2", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "==", "0.0017", ")", "\n", "assert", "(", "s", ".", "phase", "==", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.__init__": [[37, 92], ["max", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "print", "session.Session.reset_opt", "print", "torch.cuda.is_available", "pioneer.model.Generator().to", "pioneer.model.Generator().to", "pioneer.model.Discriminator().to", "torch.cuda.device_count", "int", "print", "session.Session.create", "torch.device", "torch.device", "pioneer.model.Generator", "pioneer.model.Generator", "pioneer.model.Discriminator"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.reset_opt", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.create"], ["    ", "def", "__init__", "(", "self", ",", "pretrained", "=", "False", ",", "start_iteration", "=", "-", "1", ",", "nz", "=", "512", ",", "n_label", "=", "1", ",", "phase", "=", "-", "1", ",", "max_phase", "=", "7", ",", "\n", "match_x_metric", "=", "'robust'", ",", "lr", "=", "0.0001", ",", "reset_optimizers", "=", "-", "1", ",", "no_progression", "=", "False", ",", "\n", "images_per_stage", "=", "2400e3", ",", "device", "=", "None", ",", "force_alpha", "=", "-", "1", ",", "save_dir", "=", "None", ",", "transform_key", "=", "None", ",", "\n", "arch", "=", "None", ")", ":", "\n", "# Note: 3 requirements for sampling from pre-existing models:", "\n", "# 1) Ensure you save and load both Generator and Encoder multi-gpu versions (DataParallel) or both not.", "\n", "# 2) Ensure you set the same phase value as the pre-existing model and that your local and global alpha=1.0 are set", "\n", "# 3) Sample from the g_running, not from the latest generator", "\n", "\n", "        ", "self", ".", "alpha", "=", "-", "1", "\n", "self", ".", "requested_start_iteration", "=", "start_iteration", "\n", "self", ".", "sample_i", "=", "max", "(", "1", ",", "start_iteration", ")", "\n", "self", ".", "nz", "=", "nz", "\n", "self", ".", "n_label", "=", "n_label", "\n", "self", ".", "phase", "=", "phase", "\n", "self", ".", "max_phase", "=", "max_phase", "\n", "self", ".", "images_per_stage", "=", "images_per_stage", "\n", "\n", "self", ".", "match_x_metric", "=", "match_x_metric", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "reset_optimizers", "=", "reset_optimizers", "\n", "self", ".", "no_progression", "=", "no_progression", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "transform_key", "=", "transform_key", "\n", "\n", "if", "self", ".", "device", "is", "None", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "", "self", ".", "generator", "=", "nn", ".", "DataParallel", "(", "pioneer", ".", "model", ".", "Generator", "(", "self", ".", "nz", ",", "self", ".", "n_label", ",", "arch", "=", "arch", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "self", ".", "g_running", "=", "nn", ".", "DataParallel", "(", "pioneer", ".", "model", ".", "Generator", "(", "self", ".", "nz", ",", "self", ".", "n_label", ",", "arch", "=", "arch", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "DataParallel", "(", "pioneer", ".", "model", ".", "Discriminator", "(", "nz", "=", "self", ".", "nz", ",", "\n", "n_label", "=", "self", ".", "n_label", ",", "\n", "binary_predictor", "=", "False", ")", "\n", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "\n", "print", "(", "\"Using \"", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", "\" GPUs!\"", ")", "\n", "\n", "self", ".", "adaptive_loss_N", "=", "9", "\n", "\n", "self", ".", "reset_opt", "(", ")", "\n", "\n", "if", "self", ".", "requested_start_iteration", "<=", "0", "and", "self", ".", "no_progression", ":", "\n", "            ", "self", ".", "sample_i", "=", "int", "(", "(", "self", ".", "max_phase", "+", "0.5", ")", "*", "self", ".", "images_per_stage", ")", "# Start after the fade-in stage of the last iteration", "\n", "self", ".", "alpha", "=", "1.0", "\n", "print", "(", "\"Progressive growth disabled. Setting start step = {} and alpha = {}\"", ".", "format", "(", "self", ".", "sample_i", ",", "force_alpha", ")", ")", "\n", "\n", "# You can construct this model first and the load the model in later, or if pretrained=True, we load it here already:", "\n", "", "if", "pretrained", ":", "\n", "            ", "self", ".", "create", "(", "save_dir", "=", "save_dir", ",", "force_alpha", "=", "force_alpha", ")", "\n", "\n", "", "print", "(", "'Session created.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.tf": [[93, 101], ["torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "session.Session.getReso"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso"], ["", "def", "tf", "(", "self", ")", ":", "\n", "        ", "maxReso", "=", "512", "if", "self", ".", "transform_key", "==", "'ffhq512'", "else", "256", "\n", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "maxReso", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "maxReso", ")", ",", "\n", "transforms", ".", "Resize", "(", "self", ".", "getReso", "(", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.reset_opt": [[103, 123], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "range", "session.Session.generator.parameters", "b.mod.parameters", "pioneer.robust_loss_pytorch.adaptive.AdaptiveLossFunction", "session.Session.adaptive_loss.append", "list", "list", "_adaparams.append", "pioneer.robust_loss_pytorch.adaptive.AdaptiveLossFunction.parameters", "session.Session.encoder.parameters"], "methods", ["None"], ["", "def", "reset_opt", "(", "self", ")", ":", "\n", "        ", "self", ".", "adaptive_loss", "=", "[", "]", "\n", "adaptive_loss_params", "=", "[", "]", "\n", "if", "self", ".", "match_x_metric", "==", "'robust'", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "adaptive_loss_N", ")", ":", "#Assume 9 phases: 4,8,16,32,64,128,256, 512, 1024 ... \u00b2", "\n", "                ", "loss_j", "=", "(", "AdaptiveLossFunction", "(", "num_dims", "=", "3", "*", "2", "**", "(", "4", "+", "2", "*", "j", ")", ",", "float_dtype", "=", "np", ".", "float32", ",", "\n", "#device='cuda:0'))", "\n", "device", "=", "self", ".", "device", ")", ")", "\n", "self", ".", "adaptive_loss", ".", "append", "(", "loss_j", ")", "\n", "adaptive_loss_params", "+=", "list", "(", "loss_j", ".", "parameters", "(", ")", ")", "\n", "\n", "", "", "self", ".", "optimizerG", "=", "optim", ".", "Adam", "(", "self", ".", "generator", ".", "parameters", "(", ")", ",", "self", ".", "lr", ",", "betas", "=", "(", "0.0", ",", "0.99", ")", ")", "\n", "self", ".", "optimizerD", "=", "optim", ".", "Adam", "(", "list", "(", "self", ".", "encoder", ".", "parameters", "(", ")", ")", "+", "adaptive_loss_params", ",", "self", ".", "lr", ",", "betas", "=", "(", "0.0", ",", "0.99", ")", ")", "# includes all the encoder parameters...", "\n", "\n", "_adaparams", "=", "[", "]", "\n", "for", "b", "in", "self", ".", "generator", ".", "module", ".", "adanorm_blocks", ":", "\n", "            ", "for", "p", "in", "b", ".", "mod", ".", "parameters", "(", ")", ":", "\n", "                ", "_adaparams", ".", "append", "(", "p", ")", "\n", "\n", "", "", "self", ".", "optimizerA", "=", "optim", ".", "Adam", "(", "_adaparams", ",", "self", ".", "lr", ",", "betas", "=", "(", "0.0", ",", "0.99", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.save_all": [[124, 144], ["enumerate", "torch.save", "print", "session.Session.generator.state_dict", "session.Session.encoder.state_dict", "session.Session.g_running.state_dict", "session.Session.optimizerD.state_dict", "session.Session.optimizerG.state_dict", "session.Session.optimizerA.state_dict", "getattr", "loss_param.state_dict"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save"], ["", "def", "save_all", "(", "self", ",", "path", ")", ":", "\n", "# Spectral Norm layers used to be stored separately for historical reasons.", "\n", "        ", "us", "=", "[", "]", "\n", "for", "layer", "in", "pioneer", ".", "model", ".", "SpectralNormConv2d", ".", "spectral_norm_layers", ":", "\n", "            ", "us", "+=", "[", "getattr", "(", "layer", ",", "'weight_u'", ")", "]", "\n", "\n", "", "save_dict", "=", "{", "'G_state_dict'", ":", "self", ".", "generator", ".", "state_dict", "(", ")", ",", "\n", "'D_state_dict'", ":", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "\n", "'G_running_state_dict'", ":", "self", ".", "g_running", ".", "state_dict", "(", ")", ",", "\n", "'optimizerD'", ":", "self", ".", "optimizerD", ".", "state_dict", "(", ")", ",", "\n", "'optimizerG'", ":", "self", ".", "optimizerG", ".", "state_dict", "(", ")", ",", "\n", "'optimizerA'", ":", "self", ".", "optimizerA", ".", "state_dict", "(", ")", ",", "\n", "'iteration'", ":", "self", ".", "sample_i", ",", "\n", "'phase'", ":", "self", ".", "phase", ",", "\n", "'alpha'", ":", "self", ".", "alpha", ",", "\n", "'SNU'", ":", "us", "}", "\n", "for", "i", ",", "loss_param", "in", "enumerate", "(", "self", ".", "adaptive_loss", ")", ":", "\n", "            ", "save_dict", "[", "'adaptive_loss_{}'", ".", "format", "(", "i", ")", "]", "=", "loss_param", ".", "state_dict", "(", ")", ",", "\n", "", "torch", ".", "save", "(", "save_dict", ",", "path", ")", "\n", "print", "(", "\"Adaptive Losses saved.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session._load": [[145, 213], ["int", "session.Session.generator.load_state_dict", "session.Session.g_running.load_state_dict", "session.Session.encoder.load_state_dict", "int", "range", "print", "print", "enumerate", "session.Session.generator.module.create", "session.Session.g_running.module.create", "session.Session.generator.module.create", "session.Session.g_running.module.create", "session.Session.optimizerD.load_state_dict", "session.Session.optimizerG.load_state_dict", "print", "print", "min", "print", "print", "print", "print", "setattr", "session.Session.optimizerA.load_state_dict", "session.Session.adaptive_loss[].load_state_dict", "print", "len", "print"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.create", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.create", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.create", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.create"], ["", "def", "_load", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "self", ".", "sample_i", "=", "int", "(", "checkpoint", "[", "'iteration'", "]", ")", "\n", "\n", "loadGeneratorWithNoise", "=", "True", "\n", "if", "loadGeneratorWithNoise", ":", "\n", "            ", "self", ".", "generator", ".", "module", ".", "create", "(", ")", "\n", "self", ".", "g_running", ".", "module", ".", "create", "(", ")", "\n", "#print(\"Generator dynamic components loaded via create().\")", "\n", "\n", "", "self", ".", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'G_state_dict'", "]", ")", "\n", "self", ".", "g_running", ".", "load_state_dict", "(", "checkpoint", "[", "'G_running_state_dict'", "]", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "checkpoint", "[", "'D_state_dict'", "]", ")", "\n", "\n", "if", "not", "loadGeneratorWithNoise", ":", "\n", "            ", "self", ".", "generator", ".", "module", ".", "create", "(", ")", "\n", "self", ".", "g_running", ".", "module", ".", "create", "(", ")", "\n", "#print(\"Generator dynamic components loaded via create().\")", "\n", "\n", "", "if", "self", ".", "reset_optimizers", "<=", "0", ":", "\n", "            ", "self", ".", "optimizerD", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizerD'", "]", ")", "\n", "self", ".", "optimizerG", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizerG'", "]", ")", "\n", "opts", "=", "[", "self", ".", "optimizerD", ",", "self", ".", "optimizerG", "]", "\n", "try", ":", "\n", "                ", "self", ".", "optimizerA", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizerA'", "]", ")", "\n", "opts", "+=", "[", "self", ".", "optimizerA", "]", "\n", "", "except", ":", "\n", "                ", "print", "(", "'Optimizer for AdaNorm not loaded from state.'", ")", "\n", "", "for", "opt", "in", "opts", ":", "\n", "                ", "for", "param_group", "in", "opt", ".", "param_groups", ":", "\n", "                    ", "if", "param_group", "[", "'lr'", "]", "!=", "self", ".", "lr", ":", "\n", "                        ", "print", "(", "\"LR in optimizer update: {} => {}\"", ".", "format", "(", "param_group", "[", "'lr'", "]", ",", "self", ".", "lr", ")", ")", "\n", "param_group", "[", "'lr'", "]", "=", "self", ".", "lr", "\n", "\n", "", "", "", "print", "(", "\"Reloaded old optimizers\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Despite loading the state, we reset the optimizers.\"", ")", "\n", "\n", "", "self", ".", "alpha", "=", "checkpoint", "[", "'alpha'", "]", "\n", "\n", "loaded_phase", "=", "int", "(", "checkpoint", "[", "'phase'", "]", ")", "\n", "if", "self", ".", "phase", ">", "0", ":", "#If the start phase has been manually set, try to actually use it (e.g. when have trained 64x64 for extra rounds and then turning the model over to 128x128)", "\n", "            ", "self", ".", "phase", "=", "min", "(", "loaded_phase", ",", "self", ".", "phase", ")", "\n", "print", "(", "\"Use start phase: {}\"", ".", "format", "(", "self", ".", "phase", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "phase", "=", "loaded_phase", "\n", "", "if", "loaded_phase", ">", "self", ".", "max_phase", ":", "\n", "            ", "print", "(", "'Warning! Loaded model claimed phase {} but max_phase={}'", ".", "format", "(", "self", ".", "phase", ",", "self", ".", "max_phase", ")", ")", "\n", "self", ".", "phase", "=", "self", ".", "max_phase", "\n", "", "akeys_ok", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "adaptive_loss_N", ")", ":", "\n", "            ", "akey", "=", "'adaptive_loss_{}'", ".", "format", "(", "i", ")", "\n", "if", "akey", "in", "checkpoint", ":", "\n", "                ", "self", ".", "adaptive_loss", "[", "i", "]", ".", "load_state_dict", "(", "checkpoint", "[", "akey", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "akeys_ok", "=", "False", "\n", "\n", "", "", "if", "akeys_ok", ":", "\n", "            ", "print", "(", "\"Adaptive Losses loaded.\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'WARNING! Adaptive Loss parameters were not found in checkpoint. Loss calculations will resume without historical information.'", ")", "\n", "\n", "", "print", "(", "\"Load SNU from the model file\"", ")", "\n", "us_list", "=", "checkpoint", "[", "'SNU'", "]", "\n", "print", "(", "f'Found {len(us_list)} SNU entries'", ")", "\n", "\n", "for", "layer_i", ",", "layer", "in", "enumerate", "(", "pioneer", ".", "model", ".", "SpectralNormConv2d", ".", "spectral_norm_layers", ")", ":", "\n", "            ", "setattr", "(", "layer", ",", "'weight_u'", ",", "us_list", "[", "layer_i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.eval": [[218, 222], ["copy.deepcopy", "pioneer.model.SpectralNorm.eval"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval"], ["", "", "def", "eval", "(", "self", ",", "useLN", "=", "True", ")", ":", "\n", "        ", "self", ".", "g_running", ".", "module", ".", "use_layer_noise", "=", "useLN", "\n", "self", ".", "generator", "=", "copy", ".", "deepcopy", "(", "self", ".", "g_running", ")", "\n", "pioneer", ".", "model", ".", "SpectralNorm", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.train": [[223, 226], ["session.accumulate", "pioneer.model.SpectralNorm.train"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.accumulate", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "accumulate", "(", "self", ".", "g_running", ",", "self", ".", "generator", ",", "0", ")", "\n", "pioneer", ".", "model", ".", "SpectralNorm", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.create": [[228, 249], ["session.Session.g_running.train", "save_dir.find", "print", "session.Session._load", "print", "os.path.exists", "torch.hub.load_state_dict_from_url", "str().zfill", "session.Session._load", "print", "print", "print", "torch.load", "str"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session._load", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session._load"], ["", "def", "create", "(", "self", ",", "save_dir", ",", "force_alpha", "=", "-", "1", ")", ":", "\n", "        ", "is_remote_load", "=", "save_dir", ".", "find", "(", "'http'", ")", "!=", "-", "1", "\n", "\n", "if", "not", "is_remote_load", ":", "\n", "            ", "if", "self", ".", "requested_start_iteration", ">", "1", ":", "\n", "                ", "reload_from", "=", "'{}/checkpoint/{}_state.pth'", ".", "format", "(", "save_dir", ",", "str", "(", "self", ".", "requested_start_iteration", ")", ".", "zfill", "(", "6", ")", ")", "#e.g. '604000' #'600000' #latest'   ", "\n", "print", "(", "reload_from", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "reload_from", ")", ":", "\n", "                    ", "self", ".", "_load", "(", "torch", ".", "load", "(", "reload_from", ")", ")", "\n", "print", "(", "\"Loaded {}\"", ".", "format", "(", "reload_from", ")", ")", "\n", "print", "(", "\"Iteration asked {} and got {}\"", ".", "format", "(", "self", ".", "requested_start_iteration", ",", "self", ".", "sample_i", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Start from iteration {} without pre-loading!'", ".", "format", "(", "self", ".", "sample_i", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "print", "(", "f'Remote load from {save_dir}'", ")", "\n", "self", ".", "_load", "(", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "save_dir", ",", "progress", "=", "True", ")", ")", "\n", "\n", "", "self", ".", "g_running", ".", "train", "(", "False", ")", "\n", "\n", "if", "force_alpha", ">=", "0.0", ":", "\n", "            ", "self", ".", "alpha", "=", "force_alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.prepareAdaptiveLossForNewPhase": [[250, 260], ["torch.no_grad", "range", "print", "session.Session.getResoPhase", "session.Session.getResoPhase", "session.Session.getResoPhase", "session.Session.getResoPhase"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["", "", "def", "prepareAdaptiveLossForNewPhase", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "match_x_metric", "!=", "'robust'", ":", "\n", "            ", "return", "\n", "", "assert", "(", "self", ".", "phase", ">", "0", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "alpha", "<=", "0.02", ":", "#Only run the preparatino if this phase has not already been training. In some resum-from-checkpoint scenarios, there might otherwise be misplaced initialization.", "\n", "                ", "for", "offset", "in", "range", "(", "4", ")", ":", "#Since the resolution doubles for the next phase, there are 4 new params to stand for each old param. The arrays are flattened, so every 4 slots on the new array correspond to 1 in the old. We copy them over.", "\n", "                    ", "self", ".", "adaptive_loss", "[", "self", ".", "getResoPhase", "(", ")", "]", ".", "latent_scale", "[", "0", "]", "[", "offset", ":", ":", "4", "]", "=", "self", ".", "adaptive_loss", "[", "self", ".", "getResoPhase", "(", ")", "-", "1", "]", ".", "latent_scale", "[", "0", "]", "\n", "self", ".", "adaptive_loss", "[", "self", ".", "getResoPhase", "(", ")", "]", ".", "latent_alpha", "[", "0", "]", "[", "offset", ":", ":", "4", "]", "=", "self", ".", "adaptive_loss", "[", "self", ".", "getResoPhase", "(", ")", "-", "1", "]", ".", "latent_alpha", "[", "0", "]", "\n", "", "print", "(", "'Adaptive loss values have been copied over from phase {} to phase {}'", ".", "format", "(", "self", ".", "phase", "-", "1", ",", "self", ".", "phase", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase": [[261, 264], ["sum"], "methods", ["None"], ["", "", "", "def", "getResoPhase", "(", "self", ")", ":", "\n", "        ", "gen_offset", "=", "sum", "(", "1", "for", "j", "in", "pioneer", ".", "model", ".", "Generator", ".", "supportBlockPoints", "if", "j", "<=", "self", ".", "phase", ")", "#TODO: Replace Generator with self.generator once the g_running is handled properly as well.", "\n", "return", "self", ".", "phase", "-", "gen_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso": [[265, 267], ["session.Session.getResoPhase"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["", "def", "getReso", "(", "self", ")", ":", "\n", "        ", "return", "4", "*", "2", "**", "self", ".", "getResoPhase", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getBatchSize": [[268, 270], ["session.batch_size", "session.Session.getReso"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.batch_size", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getReso"], ["", "def", "getBatchSize", "(", "self", ")", ":", "\n", "        ", "return", "batch_size", "(", "self", ".", "getReso", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.reconstruct": [[273, 276], ["torch.no_grad", "session.Session.decode", "session.Session.encode"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.decode", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.encode"], ["", "def", "reconstruct", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "decode", "(", "self", ".", "encode", "(", "imgs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.generate": [[277, 286], ["torch.autograd.Variable().cuda", "pioneer.utils.normalize", "session.Session.g_running().detach", "torch.autograd.Variable", "session.Session.g_running", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize"], ["", "", "def", "generate", "(", "self", ",", "num_imgs", ")", ":", "\n", "        ", "myz", "=", "Variable", "(", "torch", ".", "randn", "(", "num_imgs", ",", "512", ")", ")", ".", "cuda", "(", ")", "\n", "myz", "=", "pioneer", ".", "utils", ".", "normalize", "(", "myz", ")", "\n", "\n", "return", "self", ".", "g_running", "(", "\n", "myz", ",", "\n", "None", ",", "\n", "self", ".", "phase", ",", "\n", "1.0", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.encode": [[287, 291], ["session.Session.encoder", "imgs.unsqueeze.unsqueeze.shape.__len__", "imgs.unsqueeze.unsqueeze.unsqueeze", "session.Session.getResoPhase"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["", "def", "encode", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "if", "imgs", ".", "shape", ".", "__len__", "(", ")", "==", "3", ":", "\n", "            ", "imgs", "=", "imgs", ".", "unsqueeze", "(", "0", ")", "\n", "", "return", "self", ".", "encoder", "(", "imgs", ",", "self", ".", "getResoPhase", "(", ")", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.decode": [[292, 299], ["isinstance", "pioneer.utils.gen_seq().detach", "session.Session.g_running().detach", "z.unsqueeze.unsqueeze.shape.__len__", "z.unsqueeze.unsqueeze.unsqueeze", "pioneer.utils.gen_seq", "session.Session.g_running", "session.Session.getResoPhase"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.getResoPhase"], ["", "def", "decode", "(", "self", ",", "z", ")", ":", "\n", "        ", "if", "isinstance", "(", "z", ",", "ScaledBuilder", ")", ":", "\n", "            ", "return", "pioneer", ".", "utils", ".", "gen_seq", "(", "z", ".", "z_seq", ",", "self", ".", "g_running", ",", "self", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "if", "z", ".", "shape", ".", "__len__", "(", ")", "==", "1", ":", "\n", "                ", "z", "=", "z", ".", "unsqueeze", "(", "0", ")", "\n", "", "return", "self", ".", "g_running", "(", "z", ",", "None", ",", "self", ".", "getResoPhase", "(", ")", ",", "1.0", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.Session.zbuilder": [[300, 305], ["session.ScaledBuilder"], "methods", ["None"], ["", "", "def", "zbuilder", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" We allow accessing the ScaledBuilder here so that it can be accessed via the loaded Session via PyTorch Hub\n        \"\"\"", "\n", "\n", "return", "ScaledBuilder", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.ScaledBuilder.__init__": [[317, 322], ["torch.autograd.Variable().cuda", "range", "pioneer.utils.normalize", "torch.autograd.Variable", "torch.randn().repeat", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize"], ["def", "__init__", "(", "self", ",", "batch_size", "=", "1", ",", "nz", "=", "512", ")", ":", "\n", "        ", "self", ".", "_z_stack", "=", "Variable", "(", "torch", ".", "randn", "(", "batch_size", ",", "1", ",", "nz", ")", ".", "repeat", "(", "1", ",", "ScaledBuilder", ".", "_supported_max_stack_size", ",", "1", ")", ")", ".", "cuda", "(", ")", "\n", "#torch.randn(batch_size, ScaledBuilder._supported_max_stack_size, nz)).cuda()", "\n", "for", "i", "in", "range", "(", "ScaledBuilder", ".", "_supported_max_stack_size", ")", ":", "\n", "            ", "self", ".", "_z_stack", "[", ":", ",", "i", ",", ":", "]", "=", "normalize", "(", "self", ".", "_z_stack", "[", ":", ",", "i", ",", ":", "]", ")", "#Normalize each modulator separately", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.ScaledBuilder.use": [[323, 332], ["torch.no_grad", "len", "range"], "methods", ["None"], ["", "", "def", "use", "(", "self", ",", "z", ",", "mod_range", ")", ":", "\n", "        ", "assert", "(", "len", "(", "mod_range", ")", "==", "2", "and", "mod_range", "[", "0", "]", ">=", "-", "1", "and", "mod_range", "[", "1", "]", "<=", "ScaledBuilder", ".", "_supported_max_stack_size", ")", "\n", "if", "mod_range", "[", "1", "]", "==", "-", "1", ":", "\n", "            ", "mod_range", "[", "1", "]", "=", "ScaledBuilder", ".", "_supported_max_stack_size", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_z_stack", "[", ":", ",", "range", "(", "*", "mod_range", ")", ",", ":", "]", "=", "z", "\n", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.ScaledBuilder.hi": [[333, 337], ["torch.no_grad"], "methods", ["None"], ["", "def", "hi", "(", "self", ",", "z", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_z_stack", "[", ":", ",", ":", "2", ",", ":", "]", "=", "z", "\n", "", "return", "self", "\n", "", "def", "mid", "(", "self", ",", "z", ")", ":", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.ScaledBuilder.mid": [[337, 341], ["torch.no_grad"], "methods", ["None"], ["", "def", "mid", "(", "self", ",", "z", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_z_stack", "[", ":", ",", "2", ":", "5", ",", ":", "]", "=", "z", "\n", "", "return", "self", "\n", "", "def", "lo", "(", "self", ",", "z", ")", ":", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.ScaledBuilder.lo": [[341, 345], ["torch.no_grad"], "methods", ["None"], ["", "def", "lo", "(", "self", ",", "z", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_z_stack", "[", ":", ",", "5", ":", ",", ":", "]", "=", "z", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.ScaledBuilder.z": [[346, 349], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "z", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_z_stack", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.ScaledBuilder.z_seq": [[350, 353], ["range"], "methods", ["None"], ["", "@", "property", "\n", "def", "z_seq", "(", "self", ")", ":", "\n", "        ", "return", "[", "(", "self", ".", "_z_stack", "[", ":", ",", "i", ",", ":", "]", ",", "i", ",", "i", "+", "1", ")", "for", "i", "in", "range", "(", "ScaledBuilder", ".", "_supported_max_stack_size", ")", "]", "#into the format expected by utils.gen_seq", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.batch_size": [[17, 35], ["torch.cuda.device_count"], "function", ["None"], ["def", "batch_size", "(", "reso", ")", ":", "\n", "    ", "gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "gpus", "==", "1", ":", "\n", "        ", "save_memory", "=", "False", "\n", "if", "not", "save_memory", ":", "\n", "            ", "batch_table", "=", "{", "4", ":", "128", ",", "8", ":", "128", ",", "16", ":", "128", ",", "32", ":", "64", ",", "64", ":", "32", ",", "128", ":", "32", ",", "256", ":", "16", ",", "512", ":", "4", ",", "1024", ":", "1", "}", "\n", "", "else", ":", "\n", "            ", "batch_table", "=", "{", "4", ":", "64", ",", "8", ":", "32", ",", "16", ":", "32", ",", "32", ":", "32", ",", "64", ":", "16", ",", "128", ":", "14", ",", "256", ":", "2", ",", "512", ":", "2", ",", "1024", ":", "1", "}", "\n", "", "", "elif", "gpus", "==", "2", ":", "\n", "        ", "batch_table", "=", "{", "4", ":", "256", ",", "8", ":", "256", ",", "16", ":", "256", ",", "32", ":", "128", ",", "64", ":", "64", ",", "128", ":", "28", ",", "256", ":", "32", ",", "512", ":", "14", ",", "1024", ":", "2", "}", "\n", "", "elif", "gpus", "==", "4", ":", "\n", "        ", "batch_table", "=", "{", "4", ":", "512", ",", "8", ":", "256", ",", "16", ":", "128", ",", "32", ":", "64", ",", "64", ":", "32", ",", "128", ":", "64", ",", "256", ":", "64", ",", "512", ":", "32", ",", "1024", ":", "4", "}", "\n", "", "elif", "gpus", "==", "8", ":", "\n", "        ", "batch_table", "=", "{", "4", ":", "512", ",", "8", ":", "512", ",", "16", ":", "512", ",", "32", ":", "256", ",", "64", ":", "256", ",", "128", ":", "128", ",", "256", ":", "64", ",", "512", ":", "32", ",", "1024", ":", "8", "}", "\n", "", "else", ":", "\n", "        ", "assert", "(", "False", ")", "\n", "\n", "", "return", "batch_table", "[", "reso", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.session.accumulate": [[308, 314], ["dict", "dict", "dict.keys", "model1.named_parameters", "model2.named_parameters", "par1[].data.mul_().add_", "par1[].data.mul_"], "function", ["None"], ["", "", "def", "accumulate", "(", "model1", ",", "model2", ",", "decay", "=", "0.999", ")", ":", "\n", "    ", "par1", "=", "dict", "(", "model1", ".", "named_parameters", "(", ")", ")", "\n", "par2", "=", "dict", "(", "model2", ".", "named_parameters", "(", ")", ")", "\n", "\n", "for", "k", "in", "par1", ".", "keys", "(", ")", ":", "\n", "        ", "par1", "[", "k", "]", ".", "data", ".", "mul_", "(", "decay", ")", ".", "add_", "(", "1", "-", "decay", ",", "par2", "[", "k", "]", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.__init__": [[33, 35], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval": [[36, 39], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "eval", "(", ")", ":", "\n", "        ", "SpectralNorm", ".", "_is_eval", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.train": [[40, 43], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "train", "(", ")", ":", "\n", "        ", "SpectralNorm", ".", "_is_eval", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.compute_weight": [[44, 61], ["getattr", "getattr", "getattr.size", "getattr.contiguous().view", "weight_sn.view.view.view", "u.to.to.to", "getattr.contiguous().view.t", "v.norm", "u.to.to.norm", "torch.autograd.Variable", "getattr.contiguous", "torch.device", "u.to.to.t"], "methods", ["None"], ["", "def", "compute_weight", "(", "self", ",", "module", ")", ":", "\n", "        ", "weight", "=", "getattr", "(", "module", ",", "self", ".", "name", "+", "'_orig'", ")", "\n", "\n", "u", "=", "getattr", "(", "module", ",", "self", ".", "name", "+", "'_u'", ")", "\n", "\n", "size", "=", "weight", ".", "size", "(", ")", "\n", "weight_mat", "=", "weight", ".", "contiguous", "(", ")", ".", "view", "(", "size", "[", "0", "]", ",", "-", "1", ")", "\n", "if", "weight_mat", ".", "is_cuda", ":", "\n", "            ", "u", "=", "u", ".", "to", "(", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "", "v", "=", "weight_mat", ".", "t", "(", ")", "@", "u", "\n", "v", "=", "v", "/", "v", ".", "norm", "(", ")", "\n", "u", "=", "weight_mat", "@", "v", "\n", "u", "=", "u", "/", "u", ".", "norm", "(", ")", "\n", "weight_sn", "=", "weight_mat", "/", "(", "u", ".", "t", "(", ")", "@", "weight_mat", "@", "v", ")", "\n", "weight_sn", "=", "weight_sn", ".", "view", "(", "*", "size", ")", "\n", "\n", "return", "weight_sn", ",", "Variable", "(", "u", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.apply": [[62, 77], ["model.SpectralNorm", "getattr", "module.register_parameter", "getattr.size", "torch.autograd.Variable", "setattr", "setattr", "module.register_forward_pre_hook", "torch.nn.Parameter", "torch.randn", "model.SpectralNorm.compute_weight"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.compute_weight"], ["", "@", "staticmethod", "\n", "def", "apply", "(", "module", ",", "name", ")", ":", "\n", "        ", "fn", "=", "SpectralNorm", "(", "name", ")", "\n", "\n", "weight", "=", "getattr", "(", "module", ",", "name", ")", "\n", "del", "module", ".", "_parameters", "[", "name", "]", "\n", "module", ".", "register_parameter", "(", "name", "+", "'_orig'", ",", "nn", ".", "Parameter", "(", "weight", ".", "data", ")", ")", "\n", "input_size", "=", "weight", ".", "size", "(", "0", ")", "\n", "u", "=", "Variable", "(", "torch", ".", "randn", "(", "input_size", ",", "1", ")", "*", "0.1", ",", "requires_grad", "=", "False", ")", "\n", "setattr", "(", "module", ",", "name", "+", "'_u'", ",", "u", ")", "\n", "setattr", "(", "module", ",", "name", ",", "fn", ".", "compute_weight", "(", "module", ")", "[", "0", "]", ")", "\n", "\n", "module", ".", "register_forward_pre_hook", "(", "fn", ")", "\n", "\n", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.__call__": [[78, 84], ["model.SpectralNorm.compute_weight", "setattr", "setattr"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.compute_weight"], ["", "def", "__call__", "(", "self", ",", "module", ",", "input", ")", ":", "\n", "        ", "weight_sn", ",", "u", "=", "self", ".", "compute_weight", "(", "module", ")", "\n", "setattr", "(", "module", ",", "self", ".", "name", ",", "weight_sn", ")", "\n", "# When a state SNU is reloaded (always the case in test mode), we do not want to change weight_u matrix anymore. This caused a bug in style decoder, though the same did not occur for the classical architecture. The symptom: Only the very first decoding run works properly, any batch after that will have its weights collapse to some static value (essentially always the same static image gets generated).", "\n", "if", "not", "SpectralNorm", ".", "_is_eval", ":", "\n", "            ", "setattr", "(", "module", ",", "self", ".", "name", "+", "'_u'", ",", "u", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.__init__": [[92, 94], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.compute_weight": [[95, 102], ["getattr", "getattr", "getattr.data.size", "[].numel", "math.sqrt"], "methods", ["None"], ["", "def", "compute_weight", "(", "self", ",", "module", ")", ":", "\n", "        ", "weight", "=", "getattr", "(", "module", ",", "self", ".", "name", "+", "'_orig'", ")", "\n", "gain", "=", "getattr", "(", "module", ",", "self", ".", "name", "+", "'_gain'", ")", "\n", "\n", "fan_in", "=", "weight", ".", "data", ".", "size", "(", "1", ")", "*", "weight", ".", "data", "[", "0", "]", "[", "0", "]", ".", "numel", "(", ")", "\n", "\n", "return", "weight", "*", "sqrt", "(", "2", "/", "fan_in", ")", "*", "gain", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.apply": [[103, 114], ["model.EqualLR", "getattr", "module.register_parameter", "module.register_parameter", "module.register_forward_pre_hook", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "apply", "(", "module", ",", "name", ",", "gain", ")", ":", "\n", "        ", "fn", "=", "EqualLR", "(", "name", ")", "\n", "\n", "weight", "=", "getattr", "(", "module", ",", "name", ")", "\n", "del", "module", ".", "_parameters", "[", "name", "]", "\n", "module", ".", "register_parameter", "(", "name", "+", "'_orig'", ",", "nn", ".", "Parameter", "(", "weight", ".", "data", ")", ")", "\n", "module", ".", "register_parameter", "(", "name", "+", "'_gain'", ",", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", "*", "gain", ")", ")", "\n", "module", ".", "register_forward_pre_hook", "(", "fn", ")", "\n", "\n", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.__call__": [[115, 118], ["model.EqualLR.compute_weight", "setattr"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.compute_weight"], ["", "def", "__call__", "(", "self", ",", "module", ",", "input", ")", ":", "\n", "        ", "weight", "=", "self", ".", "compute_weight", "(", "module", ")", "\n", "setattr", "(", "module", ",", "self", ".", "name", ",", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.PixelNorm.__init__": [[126, 128], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.PixelNorm.forward": [[129, 132], ["torch.sqrt", "torch.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "/", "torch", ".", "sqrt", "(", "torch", ".", "mean", "(", "input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "+", "1e-8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.__init__": [[136, 148], ["torch.nn.Module.__init__", "torch.nn.Linear", "model.init_linear", "holder.adanorm_blocks.append"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.init_linear"], ["def", "__init__", "(", "self", ",", "nz", ",", "outz", ",", "holder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "outz", "==", "-", "1", ":", "\n", "            ", "self", ".", "outz", "=", "nz", "\n", "", "else", ":", "\n", "            ", "self", ".", "outz", "=", "outz", "\n", "\n", "", "self", ".", "mod", "=", "nn", ".", "Linear", "(", "nz", ",", "outz", "*", "2", ")", "\n", "init_linear", "(", "self", ".", "mod", ",", "lr_gain", "=", "1.0", ")", "\n", "\n", "holder", ".", "adanorm_blocks", ".", "append", "(", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update": [[149, 151], ["model.AdaNorm.mod.to", "input_mod.get_device"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "input_mod", ")", ":", "\n", "        ", "self", ".", "A", "=", "self", ".", "mod", ".", "to", "(", "input_mod", ".", "get_device", "(", ")", ")", "(", "input_mod", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "# The affine transform depends on the actual latent vector", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.forward": [[153, 167], ["ipdb.set_trace", "out.flatten().mean().unsqueeze().unsqueeze", "out.flatten().std().unsqueeze().unsqueeze", "out.flatten().mean().unsqueeze", "out.flatten().std().unsqueeze", "out.flatten().mean", "out.flatten().std", "out.flatten", "out.flatten"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten"], ["", "def", "forward", "(", "self", ",", "out", ")", ":", "\n", "        ", "global", "debug_ada", "\n", "if", "debug_ada", ":", "\n", "            ", "import", "ipdb", "\n", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "o1", "=", "out", "-", "out", ".", "flatten", "(", "start_dim", "=", "2", ")", ".", "mean", "(", "dim", "=", "2", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "o2", "=", "o1", "/", "out", ".", "flatten", "(", "start_dim", "=", "2", ")", ".", "std", "(", "dim", "=", "2", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "out", "=", "self", ".", "A", "[", ":", ",", ":", "(", "self", ".", "outz", ")", ",", ":", ",", ":", "]", "*", "o2", "+", "self", ".", "A", "[", ":", ",", "(", "self", ".", "outz", ")", ":", ",", ":", ",", ":", "]", "\n", "\n", "if", "AdaNorm", ".", "disable", ":", "#For debugging, see the constant output with this.", "\n", "            ", "out", "=", "o2", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNormConv2d.__init__": [[171, 180], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal", "torch.nn.Conv2d.bias.data.zero_", "model.spectral_norm", "SpectralNormConv2d.spectral_norm_layers.append"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.spectral_norm"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "conv", "=", "nn", ".", "Conv2d", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "init", ".", "kaiming_normal", "(", "conv", ".", "weight", ")", "\n", "conv", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "conv", "=", "spectral_norm", "(", "conv", ")", "\n", "\n", "SpectralNormConv2d", ".", "spectral_norm_layers", ".", "append", "(", "self", ".", "conv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNormConv2d.forward": [[181, 183], ["model.SpectralNormConv2d.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "conv", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualConv2d.__init__": [[186, 193], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d.weight.data.normal_", "torch.nn.Conv2d.bias.data.zero_", "model.equal_lr"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.equal_lr"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "conv", "=", "nn", ".", "Conv2d", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "conv", ".", "weight", ".", "data", ".", "normal_", "(", ")", "\n", "conv", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "conv", "=", "equal_lr", "(", "conv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualConv2d.forward": [[194, 196], ["model.EqualConv2d.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "conv", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.__init__": [[223, 225], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BlurLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.forward": [[226, 228], ["model.blur2d"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.blur2d"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "blur2d", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.backward": [[229, 231], ["model.blur2d"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.blur2d"], ["", "def", "backward", "(", "self", ",", "output", ")", ":", "\n", "        ", "return", "blur2d", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.NoiseLayer.__init__": [[233, 236], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mysize", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "noise_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "mysize", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.NoiseLayer.forward": [[237, 239], ["torch.normal", "model.NoiseLayer.noise_scale.view", "torch.zeros_like", "torch.ones_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "+", "torch", ".", "normal", "(", "torch", ".", "zeros_like", "(", "input", ")", ",", "torch", ".", "ones_like", "(", "input", ")", ")", "*", "self", ".", "noise_scale", ".", "view", "(", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.NopLayer.__init__": [[241, 243], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "NopLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.NopLayer.forward": [[243, 245], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.ConvBlock.__init__": [[249, 339], ["torch.nn.LeakyReLU", "torch.nn.Module.__init__", "torch.nn.LeakyReLU", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "model.SpectralNormConv2d", "torch.nn.LeakyReLU", "model.SpectralNormConv2d", "model.SpectralNormConv2d", "model.BlurLayer", "torch.nn.LeakyReLU", "model.SpectralNormConv2d", "model.BlurLayer", "torch.nn.Sequential", "torch.nn.Sequential", "ada_conv2D", "torch.nn.LeakyReLU", "model.AdaNorm", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "model.EqualConv2d", "model.PixelNorm", "torch.nn.LeakyReLU", "model.EqualConv2d", "model.PixelNorm", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.LeakyReLU", "ada_conv2D", "torch.nn.LeakyReLU", "model.AdaNorm", "ada_conv2D", "model.BlurLayer", "torch.nn.LeakyReLU", "model.AdaNorm"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", ",", "out_channel", ",", "kernel_size", ",", "\n", "padding", ",", "\n", "kernel_size2", "=", "None", ",", "padding2", "=", "None", ",", "\n", "pixel_norm", "=", "False", ",", "spectral_norm", "=", "False", ",", "ada_norm", "=", "True", ",", "const_layer", "=", "False", ",", "holder", "=", "None", ",", "last_act", "=", "nn", ".", "LeakyReLU", "(", "0.2", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "last_act", "is", "None", ":", "\n", "            ", "last_act", "=", "nn", ".", "LeakyReLU", "(", "1.0", ")", "#NopLayer()", "\n", "\n", "#BLUR HACK", "\n", "", "blur", "=", "(", "args", ".", "upsampling", "!=", "'bilinear'", ")", "\n", "\n", "pad1", "=", "padding", "\n", "pad2", "=", "padding", "\n", "if", "padding2", "is", "not", "None", ":", "\n", "            ", "pad2", "=", "padding2", "\n", "\n", "", "kernel1", "=", "kernel_size", "\n", "kernel2", "=", "kernel_size", "\n", "if", "kernel_size2", "is", "not", "None", ":", "\n", "            ", "kernel2", "=", "kernel_size2", "\n", "\n", "", "self", ".", "const_layer", "=", "const_layer", "\n", "\n", "if", "spectral_norm", ":", "\n", "            ", "if", "not", "args", ".", "blurSN", ":", "\n", "                ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "SpectralNormConv2d", "(", "in_channel", ",", "\n", "out_channel", ",", "kernel1", ",", "\n", "padding", "=", "pad1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "SpectralNormConv2d", "(", "out_channel", ",", "\n", "out_channel", ",", "kernel2", ",", "\n", "padding", "=", "pad2", ")", ",", "\n", "last_act", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "SpectralNormConv2d", "(", "in_channel", ",", "\n", "out_channel", ",", "kernel1", ",", "\n", "padding", "=", "pad1", ")", ",", "\n", "BlurLayer", "(", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "SpectralNormConv2d", "(", "out_channel", ",", "\n", "out_channel", ",", "kernel2", ",", "\n", "padding", "=", "pad2", ")", ",", "\n", "last_act", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "ada_norm", ":", "# In PGGAN, activation came after PixelNorm. In StyleGAN, PixelNorm/AdaNorm comes after activation.", "\n", "                ", "ada_conv2D", "=", "EqualConv2d", "# nn.Conv2d", "\n", "\n", "#print(\"AdaNorm layer count: {}\".format(len(holder.adanorm_blocks)))", "\n", "\n", "maybeBlur", "=", "BlurLayer", "(", ")", "if", "blur", "else", "nn", ".", "Sequential", "(", ")", "\n", "\n", "if", "not", "const_layer", ":", "\n", "                    ", "if", "not", "blur", ":", "\n", "                        ", "firstBlock", "=", "nn", ".", "Sequential", "(", "ada_conv2D", "(", "in_channel", ",", "out_channel", ",", "\n", "kernel1", ",", "padding", "=", "pad1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "AdaNorm", "(", "args", ".", "nz", "+", "args", ".", "n_label", ",", "out_channel", ",", "holder", "=", "holder", ")", ")", "\n", "", "else", ":", "\n", "                        ", "firstBlock", "=", "nn", ".", "Sequential", "(", "ada_conv2D", "(", "in_channel", ",", "out_channel", ",", "\n", "kernel1", ",", "padding", "=", "pad1", ")", ",", "\n", "BlurLayer", "(", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "AdaNorm", "(", "args", ".", "nz", "+", "args", ".", "n_label", ",", "out_channel", ",", "holder", "=", "holder", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "firstBlock", "=", "nn", ".", "Sequential", "(", ")", "#Dummy", "\n", "\n", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "firstBlock", ",", "\n", "ada_conv2D", "(", "out_channel", ",", "out_channel", ",", "\n", "kernel2", ",", "padding", "=", "pad2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "AdaNorm", "(", "args", ".", "nz", "+", "args", ".", "n_label", ",", "out_channel", ",", "holder", "=", "holder", ")", ")", "\n", "\n", "", "elif", "pixel_norm", ":", "\n", "                ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "EqualConv2d", "(", "in_channel", ",", "out_channel", ",", "\n", "kernel1", ",", "padding", "=", "pad1", ")", ",", "\n", "PixelNorm", "(", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "EqualConv2d", "(", "out_channel", ",", "out_channel", ",", "\n", "kernel2", ",", "padding", "=", "pad2", ")", ",", "\n", "PixelNorm", "(", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channel", ",", "out_channel", ",", "\n", "kernel1", ",", "padding", "=", "pad1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_channel", ",", "out_channel", ",", "\n", "kernel2", ",", "padding", "=", "pad2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.ConvBlock.forward": [[340, 344], ["model.ConvBlock.conv"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv", "(", "input", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.__init__": [[348, 425], ["torch.nn.Module.__init__", "model.PixelNorm", "torch.nn.ModuleList", "torch.nn.Sequential", "model.init_linear", "model.init_linear", "torch.nn.Embedding", "model.Generator.label_embed.weight.data.normal_", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Conv2d", "model.ConvBlock", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "model.equal_lr", "torch.nn.LeakyReLU", "model.equal_lr", "torch.nn.LeakyReLU", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "model.NoiseLayer", "torch.nn.Linear", "torch.nn.Linear", "model.NoiseLayer", "model.NoiseLayer", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.init_linear", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.init_linear", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.equal_lr", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.equal_lr"], ["    ", "def", "__init__", "(", "self", ",", "nz", ",", "n_label", "=", "0", ",", "arch", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nz", "=", "nz", "\n", "#self.tensor_properties = torch.ones(1).to(device=args.device) #hack", "\n", "if", "n_label", ">", "0", ":", "\n", "            ", "self", ".", "label_embed", "=", "nn", ".", "Embedding", "(", "n_label", ",", "n_label", ")", "\n", "self", ".", "label_embed", ".", "weight", ".", "data", ".", "normal_", "(", ")", "\n", "", "self", ".", "code_norm", "=", "PixelNorm", "(", ")", "\n", "\n", "self", ".", "adanorm_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "#self.z_const = torch.ones(512, 4, 4).to(device=args.device)", "\n", "\n", "HLM", "=", "1", "if", "arch", "==", "'small'", "else", "2", "# High-resolution Layer multiplier: Use to make the 64x64+ resolution layers larger by this factor (1 = default Balanced Pioneer)", "\n", "progression_raw", "=", "[", "ConvBlock", "(", "nz", ",", "nz", ",", "4", ",", "3", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "const_layer", "=", "True", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "nz", ",", "nz", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "nz", ",", "nz", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "nz", ",", "nz", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "nz", ",", "int", "(", "nz", "/", "2", ")", "*", "HLM", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "2", ")", "*", "HLM", ",", "int", "(", "nz", "/", "4", ")", "*", "HLM", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "4", ")", "*", "HLM", ",", "int", "(", "nz", "/", "8", ")", "*", "HLM", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "8", ")", "*", "HLM", ",", "int", "(", "nz", "/", "16", ")", "*", "HLM", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "16", ")", "*", "HLM", ",", "int", "(", "nz", "/", "32", ")", "*", "HLM", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", "]", "\n", "\n", "to_rgb_raw", "=", "[", "nn", ".", "Conv2d", "(", "nz", ",", "3", ",", "1", ")", ",", "#Each has 3 out channels and kernel size 1x1!", "\n", "nn", ".", "Conv2d", "(", "nz", ",", "3", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nz", ",", "3", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nz", ",", "3", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "int", "(", "nz", "/", "2", ")", "*", "HLM", ",", "3", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "int", "(", "nz", "/", "4", ")", "*", "HLM", ",", "3", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "int", "(", "nz", "/", "8", ")", "*", "HLM", ",", "3", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "int", "(", "nz", "/", "16", ")", "*", "HLM", ",", "3", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "int", "(", "nz", "/", "32", ")", "*", "HLM", ",", "3", ",", "1", ")", "]", "\n", "\n", "noise_raw", "=", "[", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "nz", ")", ",", "NoiseLayer", "(", "nz", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "nz", ")", ",", "NoiseLayer", "(", "nz", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "nz", ")", ",", "NoiseLayer", "(", "nz", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "nz", ")", ",", "NoiseLayer", "(", "nz", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "int", "(", "nz", "/", "2", ")", "*", "HLM", ")", ",", "NoiseLayer", "(", "int", "(", "nz", "/", "2", ")", "*", "HLM", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "int", "(", "nz", "/", "4", ")", "*", "HLM", ")", ",", "NoiseLayer", "(", "int", "(", "nz", "/", "4", ")", "*", "HLM", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "int", "(", "nz", "/", "8", ")", "*", "HLM", ")", ",", "NoiseLayer", "(", "int", "(", "nz", "/", "8", ")", "*", "HLM", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "int", "(", "nz", "/", "16", ")", "*", "HLM", ")", ",", "NoiseLayer", "(", "int", "(", "nz", "/", "16", ")", "*", "HLM", ")", "]", ")", ",", "\n", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "int", "(", "nz", "/", "32", ")", "*", "HLM", ")", ",", "NoiseLayer", "(", "int", "(", "nz", "/", "32", ")", "*", "HLM", ")", "]", ")", "]", "\n", "\n", "# The args.flip_invariance_layer (when >=0) relates to driving scale-specific invariances in the weakly supervised case.", "\n", "# We disable noise by default if there are support layers. This is only to replicate the approach in Deep Automodulators paper.", "\n", "# Feel free to enable it otherwise.", "\n", "self", ".", "has_noise_layers", "=", "args", ".", "flip_invariance_layer", "<=", "-", "1", "\n", "\n", "if", "args", ".", "flip_invariance_layer", "<=", "-", "1", ":", "\n", "            ", "self", ".", "progression", "=", "nn", ".", "ModuleList", "(", "progression_raw", ")", "\n", "self", ".", "to_rgb", "=", "nn", ".", "ModuleList", "(", "to_rgb_raw", ")", "\n", "if", "self", ".", "has_noise_layers", ":", "\n", "                ", "self", ".", "noise", "=", "nn", ".", "ModuleList", "(", "noise_raw", ")", "\n", "", "Generator", ".", "supportBlockPoints", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "supportTorgbBlock8", "=", "nn", ".", "Conv2d", "(", "nz", ",", "3", ",", "1", ")", "\n", "self", ".", "supportProgression", "=", "ConvBlock", "(", "nz", ",", "nz", ",", "3", ",", "1", ",", "spectral_norm", "=", "gen_spectral_norm", ",", "holder", "=", "self", ")", "\n", "if", "self", ".", "has_noise_layers", ":", "\n", "                ", "self", ".", "supportNoise", "=", "nn", ".", "ModuleList", "(", "[", "NoiseLayer", "(", "nz", ")", ",", "NoiseLayer", "(", "nz", ")", "]", ")", "\n", "# Add support blocks like this and also to the Generator.supportBlockPoints", "\n", "#TODO: Support adding multiple layers in the following ModuleList concatenators:", "\n", "", "self", ".", "progression", "=", "nn", ".", "ModuleList", "(", "progression_raw", "[", ":", "args", ".", "flip_invariance_layer", "]", "+", "[", "self", ".", "supportProgression", "]", "+", "progression_raw", "[", "args", ".", "flip_invariance_layer", ":", "]", ")", "\n", "self", ".", "to_rgb", "=", "nn", ".", "ModuleList", "(", "to_rgb_raw", "[", ":", "args", ".", "flip_invariance_layer", "]", "+", "[", "self", ".", "supportTorgbBlock8", "]", "+", "to_rgb_raw", "[", "args", ".", "flip_invariance_layer", ":", "]", ")", "\n", "if", "self", ".", "has_noise_layers", ":", "\n", "                ", "self", ".", "noise", "=", "nn", ".", "ModuleList", "(", "noise_raw", "[", ":", "args", ".", "flip_invariance_layer", "]", "+", "[", "self", ".", "supportNoise", "]", "+", "noise_raw", "[", "args", ".", "flip_invariance_layer", ":", "]", ")", "\n", "", "Generator", ".", "supportBlockPoints", "=", "[", "args", ".", "flip_invariance_layer", "]", "# You can add several layers here as a list, but you need to add the argparser support for that.", "\n", "\n", "", "mapping_lrmul", "=", "0.01", "\n", "\n", "self", ".", "use_layer_noise", "=", "(", "not", "args", ".", "no_LN", "and", "args", ".", "flip_invariance_layer", "<=", "-", "1", ")", "\n", "\n", "self", ".", "z_preprocess", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Sequential", "(", "equal_lr", "(", "nn", ".", "Linear", "(", "nz", ",", "nz", ")", ",", "gain", "=", "mapping_lrmul", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ")", ")", ",", "\n", "nn", ".", "Sequential", "(", "equal_lr", "(", "nn", ".", "Linear", "(", "nz", ",", "nz", ")", ",", "gain", "=", "mapping_lrmul", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ")", ")", ")", "\n", "\n", "init_linear", "(", "self", ".", "z_preprocess", "[", "0", "]", "[", "0", "]", ",", "lr_gain", "=", "mapping_lrmul", ")", "\n", "init_linear", "(", "self", ".", "z_preprocess", "[", "1", "]", "[", "0", "]", ",", "lr_gain", "=", "mapping_lrmul", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.use_layer_noise": [[430, 433], ["None"], "methods", ["None"], ["", "@", "use_layer_noise", ".", "setter", "\n", "def", "use_layer_noise", "(", "self", ",", "use_layer_noise", ")", ":", "\n", "        ", "self", ".", "__use_layer_noise", "=", "use_layer_noise", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.create": [[434, 436], ["None"], "methods", ["None"], ["", "def", "create", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "#print(\"::create() n/i\")", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Generator.forward": [[442, 523], ["min", "range", "torch.cat", "torch.cat.size", "anb.update", "int", "torch.ones().to().repeat", "out_act", "out_act", "len", "torch.ones().to", "torch.nn.functional.upsample", "torch.nn.functional.interpolate", "out_act.std", "out_act.mean", "out_act.std", "out_act.mean", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.AdaNorm.update", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.upsample"], ["", "def", "forward", "(", "self", ",", "input", ",", "label", ",", "step", "=", "0", ",", "alpha", "=", "-", "1", ",", "content_input", "=", "None", ",", "style_layer_begin", "=", "0", ",", "style_layer_end", "=", "-", "1", ")", ":", "\n", "        ", "out_act", "=", "lambda", "x", ":", "x", "\n", "\n", "if", "style_layer_end", "==", "-", "1", ":", "#content_input layer IDs go from 0 to (step). The local numbering is reversed so that, at 128x128 when step=5, id=0 <==> (step-5), id=1 <==> (step-4) etc.", "\n", "            ", "style_layer_end", "=", "step", "+", "1", "\n", "\n", "", "style_layer_end", "=", "min", "(", "step", "+", "1", ",", "style_layer_end", ")", "\n", "\n", "if", "style_layer_begin", "==", "-", "1", "or", "style_layer_begin", ">=", "style_layer_end", ":", "\n", "            ", "return", "content_input", "\n", "\n", "", "assert", "(", "not", "input", "is", "None", ")", "\n", "\n", "# Label is reserved for future use. Make None if not in use. #label = self.label_embed(label)", "\n", "if", "not", "label", "is", "None", ":", "\n", "            ", "input", "=", "torch", ".", "cat", "(", "[", "input", ",", "label", "]", ",", "1", ")", "\n", "\n", "", "batchN", "=", "input", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "if", "args", ".", "stylefc", ">", "0", ":", "\n", "            ", "input", "=", "self", ".", "z_preprocess", "[", "0", "]", "(", "input", ")", "\n", "\n", "", "for", "anb", "in", "self", ".", "adanorm_blocks", ":", "\n", "            ", "anb", ".", "update", "(", "input", ")", "\n", "\n", "# For 3 levels of coarseness, for the 2 resnet-block layers, in both the generator and generator_running. Since the layers are just added to the global list without specific indices, the resulting index numbers are ad hoc but atm they are deterministically like here:", "\n", "", "def", "layers_for_block_depth", "(", "d", ",", "holder", ")", ":", "\n", "# Generator layers start from 0 and running-Generatro from 17, or vice versa. For both, do the same styling.", "\n", "            ", "network_offset", "=", "int", "(", "len", "(", "holder", ".", "adanorm_blocks", ")", "/", "2", ")", "#17", "\n", "return", "[", "d", "*", "2", ",", "d", "*", "2", "+", "1", "]", "#, d*2+network_offset, d*2+network_offset+1]", "\n", "\n", "# The first conv call will start from a constant content_input defined as a class-level var in AdaNorm", "\n", "", "if", "content_input", "is", "None", ":", "\n", "            ", "out", "=", "torch", ".", "ones", "(", "512", ",", "4", ",", "4", ")", ".", "to", "(", "device", "=", "input", ".", "device", ")", ".", "repeat", "(", "batchN", ",", "1", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "content_input", "\n", "\n", "", "block_offset", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "style_layer_begin", ",", "style_layer_end", ")", ":", "\n", "            ", "if", "i", ">", "0", "and", "not", "i", "in", "Generator", ".", "supportBlockPoints", ":", "\n", "                ", "if", "args", ".", "upsampling", "!=", "'bilinear'", ":", "\n", "                    ", "upsample", "=", "F", ".", "upsample", "(", "out", ",", "scale_factor", "=", "2", ")", "\n", "", "else", ":", "\n", "                    ", "upsample", "=", "F", ".", "interpolate", "(", "out", ",", "align_corners", "=", "False", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ")", "\n", "", "", "else", ":", "\n", "                ", "upsample", "=", "out", "\n", "\n", "", "out", "=", "upsample", "\n", "\n", "if", "i", "==", "0", "or", "not", "self", ".", "use_layer_noise", ":", "\n", "                ", "out", "=", "self", ".", "progression", "[", "i", "]", "(", "out", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "self", ".", "progression", "[", "i", "]", ".", "conv", "[", "0", "]", "[", "0", "]", "(", "out", ")", "\n", "out", "=", "self", ".", "progression", "[", "i", "]", ".", "conv", "[", "0", "]", "[", "1", "]", "(", "out", ")", "\n", "out", "=", "self", ".", "noise", "[", "i", "]", "[", "0", "]", "(", "out", ")", "\n", "out", "=", "self", ".", "progression", "[", "i", "]", ".", "conv", "[", "0", "]", "[", "2", "]", "(", "out", ")", "#act", "\n", "if", "args", ".", "upsampling", "!=", "'bilinear'", ":", "\n", "                    ", "out", "=", "self", ".", "progression", "[", "i", "]", ".", "conv", "[", "0", "]", "[", "3", "]", "(", "out", ")", "#Blur", "\n", "", "out", "=", "self", ".", "progression", "[", "i", "]", ".", "conv", "[", "1", "]", "(", "out", ")", "\n", "out", "=", "self", ".", "noise", "[", "i", "]", "[", "1", "]", "(", "out", ")", "\n", "out", "=", "self", ".", "progression", "[", "i", "]", ".", "conv", "[", "2", "]", "(", "out", ")", "#act", "\n", "out", "=", "self", ".", "progression", "[", "i", "]", ".", "conv", "[", "3", "]", "(", "out", ")", "\n", "\n", "", "", "if", "style_layer_end", "==", "step", "+", "1", ":", "# The final layer is ALWAYS either to_rgb layer, or a mixture of 2 to-rgb_layers!", "\n", "            ", "out", "=", "out_act", "(", "self", ".", "to_rgb", "[", "step", "]", "(", "out", ")", ")", "\n", "\n", "if", "style_layer_end", ">", "1", "and", "0", "<=", "alpha", "<", "1", ":", "\n", "                ", "skip_rgb", "=", "out_act", "(", "self", ".", "to_rgb", "[", "step", "-", "1", "]", "(", "upsample", ")", ")", "\n", "if", "args", ".", "gnn", ":", "\n", "                    ", "channelwise_std", "=", "skip_rgb", ".", "std", "(", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "channelwise_mean", "=", "skip_rgb", ".", "mean", "(", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "\n", "out_std", "=", "out", ".", "std", "(", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "out_mean", "=", "out", ".", "mean", "(", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "\n", "skip_rgb", "=", "(", "skip_rgb", "-", "channelwise_mean", ")", "*", "(", "out_std", "/", "channelwise_std", ")", "+", "out_mean", "\n", "\n", "", "out", "=", "(", "1", "-", "alpha", ")", "*", "skip_rgb", "+", "alpha", "*", "out", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Discriminator.__init__": [[529, 584], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "len", "torch.nn.Linear", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "model.ConvBlock", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nz", ",", "n_label", "=", "10", ",", "binary_predictor", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "binary_predictor", "=", "binary_predictor", "\n", "self", ".", "progression", "=", "nn", ".", "ModuleList", "(", "[", "ConvBlock", "(", "int", "(", "nz", "/", "32", ")", ",", "int", "(", "nz", "/", "16", ")", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "16", ")", ",", "int", "(", "nz", "/", "8", ")", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "8", ")", ",", "int", "(", "nz", "/", "4", ")", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "4", ")", ",", "int", "(", "nz", "/", "2", ")", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "int", "(", "nz", "/", "2", ")", ",", "nz", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "nz", ",", "nz", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "nz", ",", "nz", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "nz", ",", "nz", ",", "3", ",", "1", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ")", ",", "\n", "ConvBlock", "(", "(", "nz", "+", "1", "if", "use_mean_std_layer", "else", "nz", ")", ",", "nz", ",", "3", ",", "1", ",", "4", ",", "0", ",", "\n", "pixel_norm", "=", "pixelNormInDiscriminator", ",", "\n", "spectral_norm", "=", "spectralNormInDiscriminator", ",", "\n", "ada_norm", "=", "False", ",", "\n", "last_act", "=", "None", ")", "]", ")", "\n", "\n", "self", ".", "from_rgb", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "3", ",", "int", "(", "nz", "/", "32", ")", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "int", "(", "nz", "/", "16", ")", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "int", "(", "nz", "/", "8", ")", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "int", "(", "nz", "/", "4", ")", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "int", "(", "nz", "/", "2", ")", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "nz", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "nz", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "nz", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "3", ",", "nz", ",", "1", ")", "]", ")", "\n", "\n", "self", ".", "n_layer", "=", "len", "(", "self", ".", "progression", ")", "\n", "\n", "if", "self", ".", "binary_predictor", ":", "\n", "            ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "nz", ",", "1", "+", "n_label", ")", "\n", "", "", "c", "=", "0", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.Discriminator.forward": [[585, 617], ["range", "torch.nn.functional.avg_pool2d.squeeze().squeeze", "model.Discriminator.linear", "F.avg_pool2d.squeeze().squeeze.view", "pioneer.utils.normalize", "input.std().mean", "mean_std.expand.expand.expand", "torch.cat", "torch.nn.functional.avg_pool2d", "torch.nn.functional.avg_pool2d.squeeze", "F.avg_pool2d.squeeze().squeeze.size", "input.size", "torch.nn.functional.avg_pool2d", "input.std"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize"], ["def", "forward", "(", "self", ",", "input", ",", "step", ",", "alpha", ",", "unused_arg", "=", "False", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "step", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "index", "=", "self", ".", "n_layer", "-", "i", "-", "1", "\n", "\n", "if", "i", "==", "step", ":", "\n", "                ", "out", "=", "self", ".", "from_rgb", "[", "index", "]", "(", "input", ")", "\n", "\n", "", "if", "i", "==", "0", "and", "use_mean_std_layer", ":", "\n", "                ", "mean_std", "=", "input", ".", "std", "(", "0", ")", ".", "mean", "(", ")", "\n", "mean_std", "=", "mean_std", ".", "expand", "(", "input", ".", "size", "(", "0", ")", ",", "1", ",", "4", ",", "4", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "out", ",", "mean_std", "]", ",", "1", ")", "\n", "\n", "", "out", "=", "self", ".", "progression", "[", "index", "]", "(", "out", ")", "\n", "\n", "if", "i", ">", "0", ":", "\n", "                ", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "2", ")", "\n", "\n", "if", "i", "==", "step", "and", "0", "<=", "alpha", "<", "1", ":", "\n", "                    ", "skip_rgb", "=", "F", ".", "avg_pool2d", "(", "input", ",", "2", ")", "\n", "skip_rgb", "=", "self", ".", "from_rgb", "[", "index", "+", "1", "]", "(", "skip_rgb", ")", "\n", "out", "=", "(", "1", "-", "alpha", ")", "*", "skip_rgb", "+", "alpha", "*", "out", "\n", "\n", "", "", "", "z_out", "=", "out", ".", "squeeze", "(", "2", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "if", "self", ".", "binary_predictor", ":", "\n", "            ", "out", "=", "self", ".", "linear", "(", "z_out", ")", "\n", "return", "out", "[", ":", ",", "0", "]", ",", "out", "[", ":", ",", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "out", "=", "z_out", ".", "view", "(", "z_out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "ret", "=", "utils", ".", "normalize", "(", "out", ")", "\n", "\n", "return", "ret", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.init_linear": [[17, 24], ["torch.nn.init.xavier_normal", "linear.bias.data.fill_", "torch.nn.init.xavier_normal", "linear.bias.data.zero_"], "function", ["None"], ["def", "init_linear", "(", "linear", ",", "lr_gain", ")", ":", "\n", "    ", "if", "lr_gain", "==", "1.0", ":", "# Affine mappers", "\n", "        ", "init", ".", "xavier_normal", "(", "linear", ".", "weight", ",", "1.0", ")", "\n", "linear", ".", "bias", ".", "data", ".", "fill_", "(", "1", ")", "\n", "", "else", ":", "# FC-Mapping layers", "\n", "        ", "init", ".", "xavier_normal", "(", "linear", ".", "weight_orig", ",", "1.0", "/", "lr_gain", ")", "\n", "linear", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.init_conv": [[26, 30], ["torch.nn.init.kaiming_normal", "conv.bias.data.zero_"], "function", ["None"], ["", "", "def", "init_conv", "(", "conv", ",", "glu", "=", "True", ")", ":", "\n", "    ", "init", ".", "kaiming_normal", "(", "conv", ".", "weight", ")", "\n", "if", "conv", ".", "bias", "is", "not", "None", ":", "\n", "        ", "conv", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.spectral_norm": [[85, 89], ["model.SpectralNorm.apply"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.apply"], ["", "", "", "def", "spectral_norm", "(", "module", ",", "name", "=", "'weight'", ")", ":", "\n", "    ", "SpectralNorm", ".", "apply", "(", "module", ",", "name", ")", "\n", "\n", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.equal_lr": [[120, 124], ["model.EqualLR.apply"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.EqualLR.apply"], ["", "", "def", "equal_lr", "(", "module", ",", "name", "=", "'weight'", ",", "gain", "=", "1.0", ")", ":", "\n", "    ", "EqualLR", ".", "apply", "(", "module", ",", "name", ",", "gain", ")", "\n", "\n", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.blur2d": [[197, 221], ["numpy.array", "numpy.tile", "torch.nn.functional.conv2d", "numpy.sum", "numpy.shape", "torch.from_numpy().cuda", "int", "torch.from_numpy"], "function", ["None"], ["", "", "def", "blur2d", "(", "x", ")", ":", "#Adapted from StyleGAN TF version", "\n", "    ", "f", "=", "[", "1", ",", "2", ",", "1", "]", "\n", "f", "=", "np", ".", "array", "(", "f", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "normalize", "=", "True", "\n", "flip", "=", "True", "\n", "stride", "=", "1", "\n", "strides", "=", "[", "1", ",", "1", ",", "stride", ",", "stride", "]", "\n", "\n", "if", "f", ".", "ndim", "==", "1", ":", "\n", "        ", "f", "=", "f", "[", ":", ",", "np", ".", "newaxis", "]", "*", "f", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "", "assert", "f", ".", "ndim", "==", "2", "\n", "if", "normalize", ":", "\n", "        ", "f", "/=", "np", ".", "sum", "(", "f", ")", "\n", "", "if", "flip", ":", "\n", "        ", "f", "=", "f", "[", ":", ":", "-", "1", ",", ":", ":", "-", "1", "]", "\n", "", "f", "=", "f", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", ",", ":", ",", ":", "]", "\n", "f", "=", "np", ".", "tile", "(", "f", ",", "[", "int", "(", "x", ".", "shape", "[", "1", "]", ")", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "\n", "orig_dtype", "=", "x", ".", "dtype", "\n", "\n", "nin", "=", "np", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "\n", "return", "F", ".", "conv2d", "(", "x", ",", "torch", ".", "from_numpy", "(", "f", ")", ".", "cuda", "(", ")", ",", "groups", "=", "nin", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.ImagePool.__init__": [[86, 91], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pool_size", ")", ":", "\n", "        ", "self", ".", "pool_size", "=", "pool_size", "\n", "if", "self", ".", "pool_size", ">", "0", ":", "\n", "            ", "self", ".", "num_imgs", "=", "0", "\n", "self", ".", "images", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.ImagePool.query": [[92, 113], ["torch.cat", "torch.unsqueeze", "utils.ImagePool.images.append", "torch.cat.append", "random.uniform", "random.randint", "utils.ImagePool.images[].clone", "torch.cat.append", "torch.cat.append"], "methods", ["None"], ["", "", "def", "query", "(", "self", ",", "images", ")", ":", "\n", "        ", "if", "self", ".", "pool_size", "==", "0", ":", "\n", "            ", "return", "images", "\n", "", "return_images", "=", "[", "]", "\n", "for", "image", "in", "images", ":", "\n", "            ", "image", "=", "torch", ".", "unsqueeze", "(", "image", ",", "0", ")", "\n", "if", "self", ".", "num_imgs", "<", "self", ".", "pool_size", ":", "\n", "                ", "self", ".", "num_imgs", "=", "self", ".", "num_imgs", "+", "1", "\n", "self", ".", "images", ".", "append", "(", "image", ")", "\n", "return_images", ".", "append", "(", "image", ")", "\n", "", "else", ":", "\n", "                ", "p", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "p", ">", "0.5", ":", "\n", "                    ", "random_id", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "pool_size", "-", "1", ")", "\n", "tmp", "=", "self", ".", "images", "[", "random_id", "]", ".", "clone", "(", ")", "\n", "self", ".", "images", "[", "random_id", "]", "=", "image", "\n", "return_images", ".", "append", "(", "tmp", ")", "\n", "", "else", ":", "\n", "                    ", "return_images", ".", "append", "(", "image", ")", "\n", "", "", "", "return_images", "=", "torch", ".", "cat", "(", "return_images", ",", "0", ")", "\n", "return", "return_images", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.switch_grad_updates_to_first_of": [[10, 13], ["utils.requires_grad", "utils.requires_grad"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad"], ["def", "switch_grad_updates_to_first_of", "(", "a", ",", "b", ")", ":", "\n", "    ", "requires_grad", "(", "a", ",", "True", ")", "\n", "requires_grad", "(", "b", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.requires_grad": [[14, 17], ["model.parameters", "p.requires_grad_"], "function", ["None"], ["", "def", "requires_grad", "(", "model", ",", "flag", "=", "True", ")", ":", "\n", "    ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "requires_grad_", "(", "flag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.split_labels_out_of_latent": [[18, 21], ["torch.unsqueeze"], "function", ["None"], ["", "", "def", "split_labels_out_of_latent", "(", "z", ")", ":", "\n", "    ", "label", "=", "torch", ".", "unsqueeze", "(", "z", "[", ":", ",", "-", "args", ".", "n_label", "]", ",", "dim", "=", "1", ")", "\n", "return", "z", "[", ":", ",", ":", "args", ".", "nz", "]", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.make_dirs": [[22, 32], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "make_dirs", "(", ")", ":", "\n", "    ", "if", "not", "args", ".", "save_dir", "is", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "save_dir", ")", "\n", "", "args", ".", "checkpoint_dir", "=", "args", ".", "save_dir", "+", "'/checkpoint'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "checkpoint_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "checkpoint_dir", ")", "\n", "", "", "if", "args", ".", "use_TB", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "summary_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "summary_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.populate_z": [[33, 42], ["z.data.normal_", "torch.no_grad", "z.resize_", "utils.normalize_"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize_"], ["", "", "", "def", "populate_z", "(", "z", ",", "nz", ",", "noise", ",", "batch_size", ")", ":", "\n", "    ", "'''\n    Fills noise variable `z` with noise U(S^M) [from https://github.com/DmitryUlyanov/AGE ]\n    '''", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "z", ".", "resize_", "(", "batch_size", ",", "nz", ")", "#, 1, 1)", "\n", "", "z", ".", "data", ".", "normal_", "(", "0", ",", "1", ")", "\n", "if", "noise", "==", "'sphere'", ":", "\n", "        ", "normalize_", "(", "z", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize_": [[43, 51], ["x.div_.norm", "zn.unsqueeze.unsqueeze", "x.div_.div_", "x.div_.expand_as"], "function", ["None"], ["", "", "def", "normalize_", "(", "x", ",", "dim", "=", "1", ")", ":", "\n", "    ", "'''\n    Projects points to a sphere inplace.\n    '''", "\n", "zn", "=", "x", ".", "norm", "(", "2", ",", "dim", "=", "dim", ")", "\n", "zn", "=", "zn", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "x", ".", "div_", "(", "zn", ")", "\n", "x", ".", "expand_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize": [[52, 59], ["x.norm", "zn.unsqueeze.unsqueeze", "x.div().expand_as", "x.div"], "function", ["None"], ["", "def", "normalize", "(", "x", ",", "dim", "=", "1", ")", ":", "\n", "    ", "'''\n    Projects points to a sphere.\n    '''", "\n", "zn", "=", "x", ".", "norm", "(", "2", ",", "dim", "=", "dim", ")", "\n", "zn", "=", "zn", ".", "unsqueeze", "(", "1", ")", "\n", "return", "x", ".", "div", "(", "zn", ")", ".", "expand_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatch": [[60, 77], ["utils.normalize", "utils.normalize", "ret.mean().mean", "normalize.mul", "ret.mean"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize"], ["", "def", "mismatch", "(", "x", ",", "y", ",", "dist", ")", ":", "\n", "    ", "'''\n    Computes distance between corresponding points points in `x` and `y`\n    using distance `dist`.\n    '''", "\n", "if", "dist", "==", "'L2'", ":", "\n", "        ", "return", "(", "x", "-", "y", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", "elif", "dist", "==", "'L1'", ":", "\n", "        ", "return", "(", "x", "-", "y", ")", ".", "abs", "(", ")", ".", "mean", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", "elif", "dist", "==", "'cos'", ":", "\n", "        ", "x_n", "=", "normalize", "(", "x", ")", "\n", "y_n", "=", "normalize", "(", "y", ")", "\n", "\n", "ret", "=", "2", "-", "(", "x_n", ")", ".", "mul", "(", "y_n", ")", "\n", "return", "ret", ".", "mean", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "        ", "assert", "dist", "==", "'none'", ",", "'?'", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.var": [[78, 84], ["x_zero_meaned.pow().mean", "x.mean().expand_as", "x_zero_meaned.pow", "x.mean"], "function", ["None"], ["", "", "def", "var", "(", "x", ",", "dim", "=", "0", ")", ":", "\n", "    ", "'''\n    Calculates variance. [from https://github.com/DmitryUlyanov/AGE ]\n    '''", "\n", "x_zero_meaned", "=", "x", "-", "x", ".", "mean", "(", "dim", ")", ".", "expand_as", "(", "x", ")", "\n", "return", "x_zero_meaned", ".", "pow", "(", "2", ")", ".", "mean", "(", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.gen_seq": [[116, 124], ["enumerate", "generator"], "function", ["None"], ["", "", "def", "gen_seq", "(", "bindees", ",", "generator", ",", "session", ",", "retain_intermediate_results", "=", "False", ")", ":", "\n", "    ", "z_w", "=", "None", "\n", "z_w_buf", "=", "{", "}", "\n", "for", "i", ",", "(", "z", ",", "s_begin", ",", "s_end", ")", "in", "enumerate", "(", "bindees", ")", ":", "\n", "        ", "z_w", "=", "generator", "(", "input", "=", "z", ",", "label", "=", "None", ",", "step", "=", "session", ".", "phase", ",", "alpha", "=", "session", ".", "alpha", ",", "content_input", "=", "z_w", ",", "style_layer_begin", "=", "s_begin", ",", "style_layer_end", "=", "s_end", ")", "\n", "if", "retain_intermediate_results", ":", "\n", "            ", "z_w_buf", "[", "i", "]", "=", "z_w", "\n", "", "", "return", "z_w", "if", "not", "retain_intermediate_results", "else", "z_w_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.mismatchV": [[125, 141], ["utils.normalize", "utils.normalize", "ret.mean", "normalize.mul"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.utils.normalize"], ["", "def", "mismatchV", "(", "x", ",", "y", ",", "dist", ")", ":", "\n", "    ", "'''\n    Computes distance between corresponding points points in `x` and `y`\n    using distance `dist`.\n    '''", "\n", "if", "dist", "==", "'L2'", ":", "\n", "        ", "return", "(", "x", "-", "y", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", "elif", "dist", "==", "'L1'", ":", "\n", "        ", "return", "(", "x", "-", "y", ")", ".", "abs", "(", ")", ".", "mean", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", "elif", "dist", "==", "'cos'", ":", "\n", "        ", "x_n", "=", "normalize", "(", "x", ")", "\n", "y_n", "=", "normalize", "(", "y", ")", "\n", "ret", "=", "2", "-", "(", "x_n", ")", ".", "mul", "(", "y_n", ")", "\n", "return", "ret", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "assert", "dist", "==", "'none'", ",", "'?'", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveLossFunction.__init__": [[55, 180], ["torch.Module.__init__", "pioneer.robust_loss_pytorch.distribution.Distribution", "numpy.isscalar", "ValueError", "numpy.isscalar", "ValueError", "ValueError", "ValueError", "ValueError", "numpy.isscalar", "ValueError", "numpy.isscalar", "ValueError", "ValueError", "ValueError", "[].repeat", "pioneer.robust_loss_pytorch.util.inv_affine_sigmoid", "adaptive.AdaptiveLossFunction.register_parameter", "[].repeat", "adaptive.AdaptiveLossFunction.register_parameter", "numpy.isscalar", "ValueError", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "pioneer.robust_loss_pytorch.util.affine_sigmoid", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "pioneer.robust_loss_pytorch.util.affine_softplus", "type", "type", "type", "type", "type", "[].repeat", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "pioneer.robust_loss_pytorch.util.inv_affine_sigmoid.clone().detach().to", "pioneer.robust_loss_pytorch.util.inv_affine_sigmoid.clone().detach", "pioneer.robust_loss_pytorch.util.inv_affine_sigmoid.clone"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.inv_affine_sigmoid", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.affine_sigmoid", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.affine_softplus"], ["def", "__init__", "(", "self", ",", "\n", "num_dims", ",", "\n", "float_dtype", ",", "\n", "device", ",", "\n", "alpha_lo", "=", "0.001", ",", "\n", "alpha_hi", "=", "1.999", ",", "\n", "alpha_init", "=", "None", ",", "\n", "scale_lo", "=", "1e-5", ",", "\n", "scale_init", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Sets up the loss function.\n\n    Args:\n      num_dims: The number of dimensions of the input to come.\n      float_dtype: The floating point precision of the inputs to come.\n      device: The device to run on (cpu, cuda, etc).\n      alpha_lo: The lowest possible value for loss's alpha parameters, must be\n        >= 0 and a scalar. Should probably be in (0, 2).\n      alpha_hi: The highest possible value for loss's alpha parameters, must be\n        >= alpha_lo and a scalar. Should probably be in (0, 2).\n      alpha_init: The value that the loss's alpha parameters will be initialized\n        to, must be in (`alpha_lo`, `alpha_hi`), unless `alpha_lo` == `alpha_hi`\n        in which case this will be ignored. Defaults to (`alpha_lo` +\n        `alpha_hi`) / 2\n      scale_lo: The lowest possible value for the loss's scale parameters. Must\n        be > 0 and a scalar. This value may have more of an effect than you\n        think, as the loss is unbounded as scale approaches zero (say, at a\n        delta function).\n      scale_init: The initial value used for the loss's scale parameters. This\n        also defines the zero-point of the latent representation of scales, so\n        SGD may cause optimization to gravitate towards producing scales near\n        this value.\n    \"\"\"", "\n", "super", "(", "AdaptiveLossFunction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "not", "np", ".", "isscalar", "(", "alpha_lo", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'`alpha_lo` must be a scalar, but is of type {}'", ".", "format", "(", "\n", "type", "(", "alpha_lo", ")", ")", ")", "\n", "", "if", "not", "np", ".", "isscalar", "(", "alpha_hi", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'`alpha_hi` must be a scalar, but is of type {}'", ".", "format", "(", "\n", "type", "(", "alpha_hi", ")", ")", ")", "\n", "", "if", "alpha_init", "is", "not", "None", "and", "not", "np", ".", "isscalar", "(", "alpha_init", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'`alpha_init` must be None or a scalar, but is of type {}'", ".", "format", "(", "\n", "type", "(", "alpha_init", ")", ")", ")", "\n", "", "if", "not", "alpha_lo", ">=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'`alpha_lo` must be >= 0, but is {}'", ".", "format", "(", "alpha_lo", ")", ")", "\n", "", "if", "not", "alpha_hi", ">=", "alpha_lo", ":", "\n", "      ", "raise", "ValueError", "(", "'`alpha_hi` = {} must be >= `alpha_lo` = {}'", ".", "format", "(", "\n", "alpha_hi", ",", "alpha_lo", ")", ")", "\n", "", "if", "alpha_init", "is", "not", "None", "and", "alpha_lo", "!=", "alpha_hi", ":", "\n", "      ", "if", "not", "(", "alpha_init", ">", "alpha_lo", "and", "alpha_init", "<", "alpha_hi", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'`alpha_init` = {} must be in (`alpha_lo`, `alpha_hi`) = ({} {})'", "\n", ".", "format", "(", "alpha_init", ",", "alpha_lo", ",", "alpha_hi", ")", ")", "\n", "", "", "if", "not", "np", ".", "isscalar", "(", "scale_lo", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'`scale_lo` must be a scalar, but is of type {}'", ".", "format", "(", "\n", "type", "(", "scale_lo", ")", ")", ")", "\n", "", "if", "not", "np", ".", "isscalar", "(", "scale_init", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'`scale_init` must be a scalar, but is of type {}'", ".", "format", "(", "\n", "type", "(", "scale_init", ")", ")", ")", "\n", "", "if", "not", "scale_lo", ">", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'`scale_lo` must be > 0, but is {}'", ".", "format", "(", "scale_lo", ")", ")", "\n", "", "if", "not", "scale_init", ">=", "scale_lo", ":", "\n", "      ", "raise", "ValueError", "(", "'`scale_init` = {} must be >= `scale_lo` = {}'", ".", "format", "(", "\n", "scale_init", ",", "scale_lo", ")", ")", "\n", "\n", "", "self", ".", "num_dims", "=", "num_dims", "\n", "if", "float_dtype", "==", "np", ".", "float32", ":", "\n", "      ", "float_dtype", "=", "torch", ".", "float32", "\n", "", "if", "float_dtype", "==", "np", ".", "float64", ":", "\n", "      ", "float_dtype", "=", "torch", ".", "float64", "\n", "", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "device", "=", "device", "\n", "#if isinstance(device, int) or\\", "\n", "#   (isinstance(device, str) and 'cuda' in device) or\\", "\n", "#   (isinstance(device, torch.device) and device.type == 'cuda'):", "\n", "#    torch.cuda.set_device(self.device)", "\n", "\n", "self", ".", "distribution", "=", "distribution", ".", "Distribution", "(", ")", "\n", "\n", "if", "alpha_lo", "==", "alpha_hi", ":", "\n", "# If the range of alphas is a single item, then we just fix `alpha` to be", "\n", "# a constant.", "\n", "      ", "self", ".", "fixed_alpha", "=", "torch", ".", "tensor", "(", "\n", "alpha_lo", ",", "dtype", "=", "self", ".", "float_dtype", ",", "\n", "device", "=", "self", ".", "device", ")", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", ".", "repeat", "(", "1", ",", "self", ".", "num_dims", ")", "\n", "self", ".", "alpha", "=", "lambda", ":", "self", ".", "fixed_alpha", "\n", "", "else", ":", "\n", "# Otherwise we construct a \"latent\" alpha variable and define `alpha`", "\n", "# As an affine function of a sigmoid on that latent variable, initialized", "\n", "# such that `alpha` starts off as `alpha_init`.", "\n", "      ", "if", "alpha_init", "is", "None", ":", "\n", "        ", "alpha_init", "=", "(", "alpha_lo", "+", "alpha_hi", ")", "/", "2.", "\n", "", "latent_alpha_init", "=", "util", ".", "inv_affine_sigmoid", "(", "\n", "alpha_init", ",", "lo", "=", "alpha_lo", ",", "hi", "=", "alpha_hi", ")", "\n", "self", ".", "register_parameter", "(", "\n", "'latent_alpha'", ",", "\n", "torch", ".", "nn", ".", "Parameter", "(", "\n", "latent_alpha_init", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "to", "(", "\n", "dtype", "=", "self", ".", "float_dtype", ",", "\n", "device", "=", "self", ".", "device", ")", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", ".", "repeat", "(", "\n", "1", ",", "self", ".", "num_dims", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "alpha", "=", "lambda", ":", "util", ".", "affine_sigmoid", "(", "\n", "self", ".", "latent_alpha", ",", "lo", "=", "alpha_lo", ",", "hi", "=", "alpha_hi", ")", "\n", "\n", "", "if", "scale_lo", "==", "scale_init", ":", "\n", "# If the difference between the minimum and initial scale is zero, then", "\n", "# we just fix `scale` to be a constant.", "\n", "      ", "self", ".", "fixed_scale", "=", "torch", ".", "tensor", "(", "\n", "scale_init", ",", "dtype", "=", "self", ".", "float_dtype", ",", "\n", "device", "=", "self", ".", "device", ")", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", ".", "repeat", "(", "1", ",", "self", ".", "num_dims", ")", "\n", "self", ".", "scale", "=", "lambda", ":", "self", ".", "fixed_scale", "\n", "", "else", ":", "\n", "# Otherwise we construct a \"latent\" scale variable and define `scale`", "\n", "# As an affine function of a softplus on that latent variable.", "\n", "      ", "self", ".", "register_parameter", "(", "\n", "'latent_scale'", ",", "\n", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "(", "1", ",", "self", ".", "num_dims", ")", ")", ".", "to", "(", "\n", "dtype", "=", "self", ".", "float_dtype", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "scale", "=", "lambda", ":", "util", ".", "affine_softplus", "(", "\n", "self", ".", "latent_scale", ",", "lo", "=", "scale_lo", ",", "ref", "=", "scale_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveLossFunction.lossfun": [[181, 203], ["torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "adaptive.AdaptiveLossFunction.distribution.nllfun", "len", "adaptive.AdaptiveLossFunction.alpha", "adaptive.AdaptiveLossFunction.scale"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.nllfun", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.alpha", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.scale"], ["", "", "def", "lossfun", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Computes the loss on a matrix.\n\n    Args:\n      x: The residual for which the loss is being computed. Must be a rank-2\n        tensor, where the innermost dimension is the batch index, and the\n        outermost dimension must be equal to self.num_dims. Must be a tensor or\n        numpy array of type self.float_dtype.\n      **kwargs: Arguments to be passed to the underlying distribution.nllfun().\n\n    Returns:\n      A tensor of the same type and shape as input `x`, containing the loss at\n      each element of `x`. These \"losses\" are actually negative log-likelihoods\n      (as produced by distribution.nllfun()) and so they are not actually\n      bounded from below by zero. You'll probably want to minimize their sum or\n      mean.\n    \"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "2", "\n", "assert", "x", ".", "shape", "[", "1", "]", "==", "self", ".", "num_dims", "\n", "assert", "x", ".", "dtype", "==", "self", ".", "float_dtype", "\n", "return", "self", ".", "distribution", ".", "nllfun", "(", "x", ",", "self", ".", "alpha", "(", ")", ",", "self", ".", "scale", "(", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.StudentsTLossFunction.__init__": [[208, 281], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "adaptive.StudentsTLossFunction.register_parameter", "adaptive.StudentsTLossFunction.register_parameter", "numpy.isscalar", "ValueError", "numpy.isscalar", "ValueError", "ValueError", "ValueError", "isinstance", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "[].repeat", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "pioneer.robust_loss_pytorch.util.affine_softplus", "isinstance", "isinstance", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "type", "type", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.affine_softplus"], ["def", "__init__", "(", "self", ",", "\n", "num_dims", ",", "\n", "float_dtype", ",", "\n", "device", ",", "\n", "scale_lo", "=", "1e-5", ",", "\n", "scale_init", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Sets up the adaptive loss for a matrix of inputs.\n\n    Args:\n      num_dims: The number of dimensions of the input to come.\n      float_dtype: The floating point precision of the inputs to come.\n      device: The device to run on (cpu, cuda, etc).\n      scale_lo: The lowest possible value for the loss's scale parameters. Must\n        be > 0 and a scalar. This value may have more of an effect than you\n        think, as the loss is unbounded as scale approaches zero (say, at a\n        delta function).\n      scale_init: The initial value used for the loss's scale parameters. This\n        also defines the zero-point of the latent representation of scales, so\n        SGD may cause optimization to gravitate towards producing scales near\n        this value.\n    \"\"\"", "\n", "super", "(", "StudentsTLossFunction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "not", "np", ".", "isscalar", "(", "scale_lo", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'`scale_lo` must be a scalar, but is of type {}'", ".", "format", "(", "\n", "type", "(", "scale_lo", ")", ")", ")", "\n", "", "if", "not", "np", ".", "isscalar", "(", "scale_init", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'`scale_init` must be a scalar, but is of type {}'", ".", "format", "(", "\n", "type", "(", "scale_init", ")", ")", ")", "\n", "", "if", "not", "scale_lo", ">", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'`scale_lo` must be > 0, but is {}'", ".", "format", "(", "scale_lo", ")", ")", "\n", "", "if", "not", "scale_init", ">=", "scale_lo", ":", "\n", "      ", "raise", "ValueError", "(", "'`scale_init` = {} must be >= `scale_lo` = {}'", ".", "format", "(", "\n", "scale_init", ",", "scale_lo", ")", ")", "\n", "\n", "", "self", ".", "num_dims", "=", "num_dims", "\n", "if", "float_dtype", "==", "np", ".", "float32", ":", "\n", "      ", "float_dtype", "=", "torch", ".", "float32", "\n", "", "if", "float_dtype", "==", "np", ".", "float64", ":", "\n", "      ", "float_dtype", "=", "torch", ".", "float64", "\n", "", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "device", "=", "device", "\n", "if", "isinstance", "(", "device", ",", "int", ")", "or", "(", "isinstance", "(", "device", ",", "str", ")", "and", "'cuda'", "in", "device", ")", "or", "(", "isinstance", "(", "device", ",", "torch", ".", "device", ")", "and", "device", ".", "type", "==", "'cuda'", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "device", ")", "\n", "\n", "", "self", ".", "log_df", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "self", ".", "num_dims", ")", ")", ".", "to", "(", "dtype", "=", "self", ".", "float_dtype", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "register_parameter", "(", "'log_df'", ",", "self", ".", "log_df", ")", "\n", "\n", "if", "scale_lo", "==", "scale_init", ":", "\n", "# If the difference between the minimum and initial scale is zero, then", "\n", "# we just fix `scale` to be a constant.", "\n", "      ", "self", ".", "latent_scale", "=", "None", "\n", "self", ".", "scale", "=", "torch", ".", "tensor", "(", "\n", "scale_init", ",", "dtype", "=", "self", ".", "float_dtype", ",", "\n", "device", "=", "self", ".", "device", ")", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", ".", "repeat", "(", "1", ",", "self", ".", "num_dims", ")", "\n", "", "else", ":", "\n", "# Otherwise we construct a \"latent\" scale variable and define `scale`", "\n", "# As an affine function of a softplus on that latent variable.", "\n", "      ", "self", ".", "latent_scale", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "\n", "self", ".", "num_dims", ")", ")", ".", "to", "(", "dtype", "=", "self", ".", "float_dtype", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "register_parameter", "(", "'latent_scale'", ",", "self", ".", "latent_scale", ")", "\n", "self", ".", "df", "=", "lambda", ":", "torch", ".", "exp", "(", "self", ".", "log_df", ")", "\n", "self", ".", "scale", "=", "lambda", ":", "util", ".", "affine_softplus", "(", "\n", "self", ".", "latent_scale", ",", "lo", "=", "scale_lo", ",", "ref", "=", "scale_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.StudentsTLossFunction.lossfun": [[282, 303], ["torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "pioneer.robust_loss_pytorch.util.students_t_nll", "len", "adaptive.StudentsTLossFunction.df", "adaptive.StudentsTLossFunction.scale"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.students_t_nll", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.df", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.scale"], ["", "def", "lossfun", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"A variant of lossfun() that uses the NLL of a Student's t-distribution.\n\n    Args:\n      x: The residual for which the loss is being computed. Must be a rank-2\n        tensor, where the innermost dimension is the batch index, and the\n        outermost dimension must be equal to self.num_dims. Must be a tensor or\n        numpy array of type self.float_dtype.\n\n    Returns:\n      A tensor of the same type and shape as input `x`, containing the loss at\n      each element of `x`. These \"losses\" are actually negative log-likelihoods\n      (as produced by distribution.nllfun()) and so they are not actually\n      bounded from below by zero. You'll probably want to minimize their sum or\n      mean.\n    \"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "2", "\n", "assert", "x", ".", "shape", "[", "1", "]", "==", "self", ".", "num_dims", "\n", "assert", "x", ".", "dtype", "==", "self", ".", "float_dtype", "\n", "return", "util", ".", "students_t_nll", "(", "x", ",", "self", ".", "df", "(", ")", ",", "self", ".", "scale", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.transform_to_mat": [[308, 343], ["torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "len", "pioneer.robust_loss_pytorch.util.rgb_to_syuv", "pioneer.robust_loss_pytorch.util.rgb_to_syuv.permute", "pioneer.robust_loss_pytorch.wavelet.generate_filters", "pioneer.robust_loss_pytorch.wavelet.flatten", "torch.reshape().permute", "torch.reshape().permute", "torch.reshape().permute", "torch.reshape().permute", "pioneer.robust_loss_pytorch.wavelet.rescale", "pioneer.robust_loss_pytorch.wavelet.construct", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.rgb_to_syuv", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.generate_filters", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.rescale", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.construct"], ["def", "transform_to_mat", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Transforms a batch of images to a matrix.\"\"\"", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "if", "self", ".", "color_space", "==", "'YUV'", ":", "\n", "      ", "x", "=", "util", ".", "rgb_to_syuv", "(", "x", ")", "\n", "# If `color_space` == 'RGB', do nothing.", "\n", "\n", "# Reshape `x` from", "\n", "#   (num_batches, width, height, num_channels) to", "\n", "#   (num_batches * num_channels, width, height)", "\n", "", "_", ",", "width", ",", "height", ",", "num_channels", "=", "x", ".", "shape", "\n", "x_stack", "=", "torch", ".", "reshape", "(", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "(", "-", "1", ",", "width", ",", "height", ")", ")", "\n", "\n", "# Turn each channel in `x_stack` into the spatial representation specified", "\n", "# by `representation`.", "\n", "if", "self", ".", "representation", "in", "wavelet", ".", "generate_filters", "(", ")", ":", "\n", "      ", "x_stack", "=", "wavelet", ".", "flatten", "(", "\n", "wavelet", ".", "rescale", "(", "\n", "wavelet", ".", "construct", "(", "x_stack", ",", "self", ".", "wavelet_num_levels", ",", "\n", "self", ".", "representation", ")", ",", "self", ".", "wavelet_scale_base", ")", ")", "\n", "## Disabled to remove the dct library dependency:", "\n", "## elif self.representation == 'DCT':", "\n", "##  x_stack = util.image_dct(x_stack)", "\n", "\n", "# If `representation` == 'PIXEL', do nothing.", "\n", "\n", "# Reshape `x_stack` from", "\n", "#   (num_batches * num_channels, width, height) to", "\n", "#   (num_batches, num_channels * width * height)", "\n", "", "x_mat", "=", "torch", ".", "reshape", "(", "\n", "torch", ".", "reshape", "(", "x_stack", ",", "\n", "(", "-", "1", ",", "num_channels", ",", "width", ",", "height", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ",", "\n", "[", "-", "1", ",", "width", "*", "height", "*", "num_channels", "]", ")", "\n", "return", "x_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.__init__": [[344, 442], ["torch.Module.__init__", "torch.zeros().type", "torch.zeros().type", "torch.zeros().type", "torch.zeros().type", "adaptive.AdaptiveImageLossFunction.transform_to_mat", "ValueError", "pioneer.robust_loss_pytorch.wavelet.generate_filters", "ValueError", "len", "adaptive.StudentsTLossFunction", "adaptive.AdaptiveLossFunction", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "list"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.transform_to_mat", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.generate_filters"], ["", "def", "__init__", "(", "self", ",", "\n", "image_size", ",", "\n", "float_dtype", ",", "\n", "device", ",", "\n", "color_space", "=", "'YUV'", ",", "\n", "representation", "=", "'CDF9/7'", ",", "\n", "wavelet_num_levels", "=", "5", ",", "\n", "wavelet_scale_base", "=", "1", ",", "\n", "use_students_t", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Sets up the adaptive form of the robust loss on a set of images.\n\n    This function is a wrapper around AdaptiveLossFunction. It requires inputs\n    of a specific shape and size, and constructs internal parameters describing\n    each non-batch dimension. By default, this function uses a CDF9/7 wavelet\n    decomposition in a YUV color space, which often works well.\n\n    Args:\n      image_size: The size (width, height, num_channels) of the input images.\n      float_dtype: The dtype of the floats used as input.\n      device: The device to use.\n      color_space: The color space that `x` will be transformed into before\n        computing the loss. Must be 'RGB' (in which case no transformation is\n        applied) or 'YUV' (in which case we actually use a volume-preserving\n        scaled YUV colorspace so that log-likelihoods still have meaning, see\n        util.rgb_to_syuv()). Note that changing this argument does not change\n        the assumption that `x` is the set of differences between RGB images, it\n        just changes what color space `x` is converted to from RGB when\n        computing the loss.\n      representation: The spatial image representation that `x` will be\n        transformed into after converting the color space and before computing\n        the loss. If this is a valid type of wavelet according to\n        wavelet.generate_filters() then that is what will be used, but we also\n        support setting this to 'DCT' which applies a 2D DCT to the images, and\n        to 'PIXEL' which applies no transformation to the image, thereby causing\n        the loss to be imposed directly on pixels.\n      wavelet_num_levels: If `representation` is a kind of wavelet, this is the\n        number of levels used when constructing wavelet representations.\n        Otherwise this is ignored. Should probably be set to as large as\n        possible a value that is supported by the input resolution, such as that\n        produced by wavelet.get_max_num_levels().\n      wavelet_scale_base: If `representation` is a kind of wavelet, this is the\n        base of the scaling used when constructing wavelet representations.\n        Otherwise this is ignored. For image_lossfun() to be volume preserving\n        (a useful property when evaluating generative models) this value must be\n        == 1. If the goal of this loss isn't proper statistical modeling, then\n        modifying this value (say, setting it to 0.5 or 2) may significantly\n        improve performance.\n      use_students_t: If true, use the NLL of Student's T-distribution instead\n        of the adaptive loss. This causes all `alpha_*` inputs to be ignored.\n      **kwargs: Arguments to be passed to the underlying lossfun().\n\n    Raises:\n      ValueError: if `color_space` of `representation` are unsupported color\n        spaces or image representations, respectively.\n    \"\"\"", "\n", "super", "(", "AdaptiveImageLossFunction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "color_spaces", "=", "[", "'RGB'", ",", "'YUV'", "]", "\n", "if", "color_space", "not", "in", "color_spaces", ":", "\n", "      ", "raise", "ValueError", "(", "'`color_space` must be in {}, but is {!r}'", ".", "format", "(", "\n", "color_spaces", ",", "color_space", ")", ")", "\n", "", "representations", "=", "wavelet", ".", "generate_filters", "(", ")", "+", "[", "'DCT'", ",", "'PIXEL'", "]", "\n", "if", "representation", "not", "in", "representations", ":", "\n", "      ", "raise", "ValueError", "(", "'`representation` must be in {}, but is {!r}'", ".", "format", "(", "\n", "representations", ",", "representation", ")", ")", "\n", "", "assert", "len", "(", "image_size", ")", "==", "3", "\n", "\n", "self", ".", "color_space", "=", "color_space", "\n", "self", ".", "representation", "=", "representation", "\n", "self", ".", "wavelet_num_levels", "=", "wavelet_num_levels", "\n", "self", ".", "wavelet_scale_base", "=", "wavelet_scale_base", "\n", "self", ".", "use_students_t", "=", "use_students_t", "\n", "self", ".", "image_size", "=", "image_size", "\n", "\n", "if", "float_dtype", "==", "np", ".", "float32", ":", "\n", "      ", "float_dtype", "=", "torch", ".", "float32", "\n", "", "if", "float_dtype", "==", "np", ".", "float64", ":", "\n", "      ", "float_dtype", "=", "torch", ".", "float64", "\n", "", "self", ".", "float_dtype", "=", "float_dtype", "\n", "self", ".", "device", "=", "device", "\n", "#if isinstance(device, int) or\\", "\n", "#   (isinstance(device, str) and 'cuda' in device) or\\", "\n", "#   (isinstance(device, torch.device) and device.type == 'cuda'):", "\n", "#    torch.cuda.set_device(self.device)", "\n", "\n", "x_example", "=", "torch", ".", "zeros", "(", "[", "1", "]", "+", "list", "(", "self", ".", "image_size", ")", ")", ".", "type", "(", "self", ".", "float_dtype", ")", "\n", "x_example_mat", "=", "self", ".", "transform_to_mat", "(", "x_example", ")", "\n", "self", ".", "num_dims", "=", "x_example_mat", ".", "shape", "[", "1", "]", "\n", "\n", "if", "self", ".", "use_students_t", ":", "\n", "      ", "self", ".", "adaptive_lossfun", "=", "StudentsTLossFunction", "(", "self", ".", "num_dims", ",", "\n", "self", ".", "float_dtype", ",", "\n", "self", ".", "device", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "adaptive_lossfun", "=", "AdaptiveLossFunction", "(", "self", ".", "num_dims", ",", "\n", "self", ".", "float_dtype", ",", "\n", "self", ".", "device", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.lossfun": [[443, 465], ["adaptive.AdaptiveImageLossFunction.transform_to_mat", "adaptive.AdaptiveImageLossFunction.adaptive_lossfun.lossfun", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "list"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.transform_to_mat", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.general.lossfun"], ["", "", "def", "lossfun", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Computes the adaptive form of the robust loss on a set of images.\n\n    Args:\n      x: A set of image residuals for which the loss is being computed. Must be\n        a rank-4 tensor of size (num_batches, width, height, color_channels).\n        This is assumed to be a set of differences between RGB images.\n\n    Returns:\n      A tensor of losses of the same type and shape as input `x`. These \"losses\"\n      are actually negative log-likelihoods (as produced by\n      distribution.nllfun())\n      and so they are not actually bounded from below by zero.\n      You'll probably want to minimize their sum or mean.\n    \"\"\"", "\n", "x_mat", "=", "self", ".", "transform_to_mat", "(", "x", ")", "\n", "\n", "loss_mat", "=", "self", ".", "adaptive_lossfun", ".", "lossfun", "(", "x_mat", ")", "\n", "\n", "# Reshape the loss function's outputs to have the shapes as the input.", "\n", "loss", "=", "torch", ".", "reshape", "(", "loss_mat", ",", "[", "-", "1", "]", "+", "list", "(", "self", ".", "image_size", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.alpha": [[466, 470], ["torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "adaptive.AdaptiveImageLossFunction.adaptive_lossfun.alpha"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.alpha"], ["", "def", "alpha", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns an image of alphas.\"\"\"", "\n", "assert", "not", "self", ".", "use_students_t", "\n", "return", "torch", ".", "reshape", "(", "self", ".", "adaptive_lossfun", ".", "alpha", "(", ")", ",", "self", ".", "image_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.df": [[471, 475], ["torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "adaptive.AdaptiveImageLossFunction.adaptive_lossfun.df"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.df"], ["", "def", "df", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns an image of degrees of freedom, for the Student's T model.\"\"\"", "\n", "assert", "self", ".", "use_students_t", "\n", "return", "torch", ".", "reshape", "(", "self", ".", "adaptive_lossfun", ".", "df", "(", ")", ",", "self", ".", "image_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.scale": [[476, 479], ["torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "adaptive.AdaptiveImageLossFunction.adaptive_lossfun.scale"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.adaptive.AdaptiveImageLossFunction.scale"], ["", "def", "scale", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns an image of scales.\"\"\"", "\n", "return", "torch", ".", "reshape", "(", "self", ".", "adaptive_lossfun", ".", "scale", "(", ")", ",", "self", ".", "image_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.generate_filters": [[35, 96], ["mirror", "mirror", "Filters", "HalfFilters", "HalfFilters", "list", "numpy.concatenate", "mirror", "mirror", "supported_half_filters.keys", "numpy.arange", "alternating_sign", "alternating_sign", "numpy.array", "numpy.array", "len", "len", "numpy.array", "numpy.sqrt", "numpy.array", "numpy.sqrt"], "function", ["None"], ["def", "generate_filters", "(", "wavelet_type", "=", "None", ")", ":", "\n", "  ", "\"\"\"Generates the analysis and synthesis filters for a kind of wavelet.\n\n  Currently only supports wavelet types where all filters have an odd length.\n  TODO(barron): Generalize this to even filters as well, and support Haar and\n  Debauchies wavelets.\n\n  Args:\n    wavelet_type: A string encoding the type of wavelet filters to return. This\n      string is used as a key to the `supported_half_filters` dict in the code\n      below, and so the string must be a valid key.\n\n  Returns:\n    If `wavelet_type` is not provided as input, this function returns a list of\n    valid values for `wavelet_type`. If `wavelet_type` is a supported string,\n    this function returns the wavelet type's `Filters` object.\n  \"\"\"", "\n", "supported_half_filters", "=", "{", "\n", "# CDF 9/7 filters from \"Biorthogonal bases of compactly supported", "\n", "# wavelets\", Cohen et al., Commun. Pure Appl. Math 1992.", "\n", "'CDF9/7'", ":", "\n", "HalfFilters", "(", "\n", "lo", "=", "np", ".", "array", "(", "[", "\n", "+", "0.852698679009", ",", "\n", "+", "0.377402855613", ",", "\n", "-", "0.110624404418", ",", "\n", "-", "0.023849465020", ",", "\n", "+", "0.037828455507", "\n", "]", ")", ",", "\n", "hi", "=", "np", ".", "array", "(", "[", "\n", "+", "0.788485616406", ",", "\n", "-", "0.418092273222", ",", "\n", "-", "0.040689417609", ",", "\n", "+", "0.064538882629", "\n", "]", ")", ")", ",", "\n", "# Le Gall 5/3 filters (sometimes called CDF 5/3 filters).", "\n", "'LeGall5/3'", ":", "\n", "HalfFilters", "(", "\n", "lo", "=", "np", ".", "array", "(", "[", "0.75", ",", "0.25", ",", "-", "0.125", "]", ")", "*", "np", ".", "sqrt", "(", "2.", ")", ",", "\n", "hi", "=", "np", ".", "array", "(", "[", "1.", ",", "-", "0.5", "]", ")", "/", "np", ".", "sqrt", "(", "2.", ")", ")", ",", "\n", "}", "# pyformat: disable", "\n", "\n", "if", "wavelet_type", "is", "None", ":", "\n", "    ", "return", "list", "(", "supported_half_filters", ".", "keys", "(", ")", ")", "\n", "\n", "", "half_filters", "=", "supported_half_filters", "[", "wavelet_type", "]", "\n", "\n", "# Returns [f(n-1), ..., f(2), f(1), f(0), f(1), f(2), ... f(n-1)].", "\n", "mirror", "=", "lambda", "f", ":", "np", ".", "concatenate", "(", "[", "f", "[", "-", "1", ":", "0", ":", "-", "1", "]", ",", "f", "]", ")", "\n", "# Makes an n-length vector containing [1, -1, 1, -1, 1, ... ].", "\n", "alternating_sign", "=", "lambda", "n", ":", "(", "-", "1", ")", "**", "np", ".", "arange", "(", "n", ")", "\n", "analysis_lo", "=", "mirror", "(", "half_filters", ".", "lo", ")", "\n", "analysis_hi", "=", "mirror", "(", "half_filters", ".", "hi", ")", "\n", "synthesis_lo", "=", "analysis_hi", "*", "mirror", "(", "alternating_sign", "(", "len", "(", "half_filters", ".", "hi", ")", ")", ")", "\n", "synthesis_hi", "=", "analysis_lo", "*", "mirror", "(", "alternating_sign", "(", "len", "(", "half_filters", ".", "lo", ")", ")", ")", "\n", "\n", "return", "Filters", "(", "\n", "analysis_lo", "=", "analysis_lo", ",", "\n", "analysis_hi", "=", "analysis_hi", ",", "\n", "synthesis_lo", "=", "synthesis_lo", ",", "\n", "synthesis_hi", "=", "synthesis_hi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.pad_reflecting": [[98, 151], ["torch.as_tensor", "numpy.arange", "numpy.mod", "numpy.minimum", "torch.index_select", "isinstance", "ValueError", "isinstance", "ValueError", "isinstance", "ValueError", "ValueError", "numpy.maximum", "torch.as_tensor().type().to", "type", "type", "type", "len", "torch.as_tensor().type", "len", "torch.as_tensor"], "function", ["None"], ["", "def", "pad_reflecting", "(", "x", ",", "padding_below", ",", "padding_above", ",", "axis", ")", ":", "\n", "  ", "\"\"\"Pads `x` with reflecting conditions above and/or below it along some axis.\n\n  Pads `x` with reflecting conditions for `padding_below` entries below the\n  tensor and `padding_above` entries above the tensor in the direction along\n  `axis`. This is like using tf.pad(x, --, 'REFLECT'), except that this code\n  allows for an unbounded number of reflections while tf.pad() only supports\n  one reflection. Multiple reflections are necessary for for wavelet\n  decompositions to guard against cases where the wavelet filters are larger\n  than the input tensor along `axis`, which happens often at coarse scales.\n  Note that \"reflecting\" boundary conditions are different from \"symmetric\"\n  boundary conditions, in that it doesn't repeat the last element:\n  reflect([A, B, C, D], 2) = [C, B, A, B, C, D, C, B]\n  symmet.([A, B, C, D], 2) = [B, A, A, B, C, D, D, C]\n\n  Args:\n    x: The tensor to be padded with reflecting boundary conditions.\n    padding_below: The number of elements being padded below the tensor.\n    padding_above: The number of elements being padded above the tensor.\n    axis: The axis in x in which padding will be performed.\n\n  Returns:\n    `x` padded according to `padding_below` and `padding_above` along `axis`\n    with reflecting boundary conditions.\n  \"\"\"", "\n", "if", "not", "isinstance", "(", "padding_below", ",", "int", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'Expected `padding_below` of type int, but is of type {}'", ".", "format", "(", "\n", "type", "(", "padding_below", ")", ")", ")", "\n", "", "if", "not", "isinstance", "(", "padding_above", ",", "int", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'Expected `padding_above` of type int, but is of type {}'", ".", "format", "(", "\n", "type", "(", "padding_above", ")", ")", ")", "\n", "", "if", "not", "isinstance", "(", "axis", ",", "int", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'Expected `axis` of type int, but is of type {}'", ".", "format", "(", "\n", "type", "(", "axis", ")", ")", ")", "\n", "", "if", "not", "(", "axis", ">=", "0", "and", "axis", "<", "len", "(", "x", ".", "shape", ")", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'Expected `axis` in [0, {}], but is = {}'", ".", "format", "(", "\n", "len", "(", "x", ".", "shape", ")", "-", "1", ",", "axis", ")", ")", "\n", "", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "if", "padding_below", "==", "0", "and", "padding_above", "==", "0", ":", "\n", "    ", "return", "x", "\n", "", "n", "=", "x", ".", "shape", "[", "axis", "]", "\n", "# `i' contains the indices of the output padded tensor in the frame of", "\n", "# reference of the input tensor.", "\n", "i", "=", "np", ".", "arange", "(", "-", "padding_below", ",", "n", "+", "padding_above", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# `j` contains the indices of the input tensor corresponding to the output", "\n", "# padded tensor.", "\n", "i_mod", "=", "np", ".", "mod", "(", "i", ",", "np", ".", "maximum", "(", "1", ",", "2", "*", "(", "n", "-", "1", ")", ")", ")", "\n", "j", "=", "np", ".", "minimum", "(", "2", "*", "(", "n", "-", "1", ")", "-", "i_mod", ",", "i_mod", ")", "\n", "y", "=", "torch", ".", "index_select", "(", "x", ",", "axis", ",", "\n", "torch", ".", "as_tensor", "(", "j", ")", ".", "type", "(", "torch", ".", "int64", ")", ".", "to", "(", "x", ".", "device", ")", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._check_resample_inputs": [[153, 166], ["len", "ValueError", "len", "ValueError", "ValueError", "ValueError"], "function", ["None"], ["", "def", "_check_resample_inputs", "(", "x", ",", "f", ",", "direction", ",", "shift", ")", ":", "\n", "  ", "\"\"\"Checks the inputs to _downsample() and _upsample().\"\"\"", "\n", "if", "len", "(", "x", ".", "shape", ")", "!=", "3", ":", "\n", "    ", "raise", "ValueError", "(", "'Expected `x` to have rank 3, but is of size {}'", ".", "format", "(", "\n", "x", ".", "shape", ")", ")", "\n", "", "if", "len", "(", "f", ".", "shape", ")", "!=", "1", ":", "\n", "    ", "raise", "ValueError", "(", "'Expected `f` to have rank 1, but is of size {}'", ".", "format", "(", "\n", "f", ".", "shape", ")", ")", "\n", "", "if", "not", "(", "direction", "==", "0", "or", "direction", "==", "1", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'Expected `direction` to be 0 or 1, but is {}'", ".", "format", "(", "direction", ")", ")", "\n", "", "if", "not", "(", "shift", "==", "0", "or", "shift", "==", "1", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'Expected `shift` to be 0 or 1, but is {}'", ".", "format", "(", "shift", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._downsample": [[168, 211], ["wavelet._check_resample_inputs", "torch.as_tensor", "torch.tensor().to", "wavelet.pad_reflecting", "torch.conv2d", "torch.tensor", "len", "torch.as_tensor", "f_ex[].type", "len", "torch.as_tensor"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._check_resample_inputs", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.pad_reflecting"], ["", "", "def", "_downsample", "(", "x", ",", "f", ",", "direction", ",", "shift", ")", ":", "\n", "  ", "\"\"\"Downsample by a factor of 2 using reflecting boundary conditions.\n\n  This function convolves `x` with filter `f` with reflecting boundary\n  conditions, and then decimates by a factor of 2. This is usually done to\n  downsample `x`, assuming `f` is some smoothing filter, but will also be used\n  for wavelet transformations in which `f` is not a smoothing filter.\n\n  Args:\n    x: The input tensor (numpy or TF), of size (num_channels, width, height).\n    f: The input filter, which must be an odd-length 1D numpy array.\n    direction: The spatial direction in [0, 1] along which `x` will be convolved\n      with `f` and then decimated. Because `x` has a batch/channels dimension,\n      `direction` == 0 corresponds to downsampling along axis 1 in `x`, and\n      `direction` == 1 corresponds to downsampling along axis 2 in `x`.\n    shift: A shift amount in [0, 1] by which `x` will be shifted along the axis\n      specified by `direction` before filtering.\n\n  Returns:\n    `x` convolved with `f` along the spatial dimension `direction` with\n    reflection boundary conditions with an offset of `shift`.\n  \"\"\"", "\n", "_check_resample_inputs", "(", "x", ",", "f", ",", "direction", ",", "shift", ")", "\n", "# The above and below padding amounts are different so as to support odd", "\n", "# and even length filters. An odd-length filter of length n causes a padding", "\n", "# of (n-1)/2 on both sides, while an even-length filter will pad by one less", "\n", "# below than above.", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "f", "=", "torch", ".", "tensor", "(", "f", ")", ".", "to", "(", "x", ")", "\n", "x_padded", "=", "pad_reflecting", "(", "x", ",", "(", "len", "(", "f", ")", "-", "1", ")", "//", "2", ",", "len", "(", "f", ")", "//", "2", ",", "direction", "+", "1", ")", "\n", "if", "direction", "==", "0", ":", "\n", "    ", "x_padded", "=", "x_padded", "[", ":", ",", "shift", ":", ",", ":", "]", "\n", "f_ex", "=", "torch", ".", "as_tensor", "(", "f", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "stride", "=", "[", "2", ",", "1", "]", "\n", "", "elif", "direction", "==", "1", ":", "\n", "    ", "x_padded", "=", "x_padded", "[", ":", ",", ":", ",", "shift", ":", "]", "\n", "f_ex", "=", "torch", ".", "as_tensor", "(", "f", ")", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "stride", "=", "[", "1", ",", "2", "]", "\n", "", "y", "=", "torch", ".", "conv2d", "(", "\n", "x_padded", "[", ":", ",", "np", ".", "newaxis", ",", ":", ",", ":", "]", ",", "\n", "f_ex", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", ".", "type", "(", "x", ".", "dtype", ")", ",", "\n", "stride", "=", "stride", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._upsample": [[213, 276], ["wavelet._check_resample_inputs", "torch.as_tensor", "f_ex.to.to", "torch.reshape", "torch.nn.functional.pad", "wavelet.pad_reflecting", "torch.stack", "list", "torch.conv2d", "numpy.array", "torch.tensor", "torch.zeros_like", "len", "f_ex[].type", "f[].copy", "numpy.array", "torch.tensor", "torch.zeros_like", "len", "f[].copy"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._check_resample_inputs", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.pad_reflecting"], ["", "def", "_upsample", "(", "x", ",", "up_sz", ",", "f", ",", "direction", ",", "shift", ")", ":", "\n", "  ", "\"\"\"Upsample by a factor of 2 using transposed reflecting boundary conditions.\n\n  This function undecimates `x` along the axis specified by `direction` and then\n  convolves it with filter `f`, thereby upsampling it to have a size of `up_sz`.\n  This function is a bit awkward, as it's written to be the transpose of\n  _downsample(), which uses reflecting boundary conditions. As such, this\n  function approximates *the transpose of reflecting boundary conditions*, which\n  is not the same as reflecting boundary conditions.\n  TODO(barron): Write out the true transpose of reflecting boundary conditions.\n\n  Args:\n    x: The input tensor (numpy or TF), of size (num_channels, width, height).\n    up_sz: A tuple of ints of size (upsampled_width, upsampled_height). Care\n      should be taken by the caller to match the upsampled_width/height with the\n      input width/height along the axis that isn't being upsampled.\n    f: The input filter, which must be an odd-length 1D numpy array.\n    direction: The spatial direction in [0, 1] along which `x` will be convolved\n      with `f` after being undecimated. Because `x` has a batch/channels\n      dimension, `direction` == 0 corresponds to downsampling along axis 1 in\n      `x`, and `direction` == 1 corresponds to downsampling along axis 2 in `x`.\n    shift: A shift amount in [0, 1] by which `x` will be shifted along the axis\n      specified by `direction` after undecimating.\n\n  Returns:\n    `x` undecimated and convolved with `f` along the spatial dimension\n    `direction` with transposed reflection boundary conditions with an offset of\n    `shift`, to match size `up_sz`.\n  \"\"\"", "\n", "_check_resample_inputs", "(", "x", ",", "f", ",", "direction", ",", "shift", ")", "\n", "# Undecimate `x` by a factor of 2 along `direction`, by stacking it with", "\n", "# and tensor of all zeros along the right axis and then reshaping it such", "\n", "# that the zeros are interleaved.", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "if", "direction", "==", "0", ":", "\n", "    ", "sz_ex", "=", "x", ".", "shape", "*", "np", ".", "array", "(", "[", "1", ",", "2", ",", "1", "]", ")", "\n", "f_ex", "=", "torch", ".", "tensor", "(", "f", "[", ":", ":", "-", "1", "]", ".", "copy", "(", ")", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "", "elif", "direction", "==", "1", ":", "\n", "    ", "sz_ex", "=", "x", ".", "shape", "*", "np", ".", "array", "(", "[", "1", ",", "1", ",", "2", "]", ")", "\n", "f_ex", "=", "torch", ".", "tensor", "(", "f", "[", ":", ":", "-", "1", "]", ".", "copy", "(", ")", ")", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "", "f_ex", "=", "f_ex", ".", "to", "(", "x", ")", "\n", "if", "shift", "==", "0", ":", "\n", "    ", "x_and_zeros", "=", "[", "x", ",", "torch", ".", "zeros_like", "(", "x", ")", "]", "\n", "", "elif", "shift", "==", "1", ":", "\n", "    ", "x_and_zeros", "=", "[", "torch", ".", "zeros_like", "(", "x", ")", ",", "x", "]", "\n", "", "x_undecimated", "=", "torch", ".", "reshape", "(", "\n", "torch", ".", "stack", "(", "x_and_zeros", ",", "direction", "+", "2", ")", ",", "list", "(", "sz_ex", ")", ")", "\n", "# Ensure that `x_undecimated` has a size of `up_sz`, by slicing and padding", "\n", "# as needed.", "\n", "x_undecimated", "=", "x_undecimated", "[", ":", ",", "0", ":", "up_sz", "[", "0", "]", ",", "0", ":", "up_sz", "[", "1", "]", "]", "\n", "x_undecimated", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "x_undecimated", ",", "[", "\n", "0", ",", "up_sz", "[", "1", "]", "-", "x_undecimated", ".", "shape", "[", "2", "]", ",", "0", ",", "\n", "up_sz", "[", "0", "]", "-", "x_undecimated", ".", "shape", "[", "1", "]", ",", "0", ",", "0", "\n", "]", ")", "\n", "\n", "# Pad `x_undecimated` with reflection boundary conditions.", "\n", "x_padded", "=", "pad_reflecting", "(", "x_undecimated", ",", "\n", "len", "(", "f", ")", "//", "2", ",", "(", "len", "(", "f", ")", "-", "1", ")", "//", "2", ",", "direction", "+", "1", ")", "\n", "y", "=", "torch", ".", "conv2d", "(", "\n", "x_padded", "[", ":", ",", "np", ".", "newaxis", ",", ":", ",", ":", "]", ",", "\n", "f_ex", "[", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", ".", "type", "(", "x", ".", "dtype", ")", ",", "\n", "stride", "=", "[", "1", ",", "1", "]", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.get_max_num_levels": [[278, 292], ["numpy.minimum", "int", "numpy.ceil", "numpy.log", "numpy.log", "log2", "numpy.float32", "numpy.float32", "numpy.maximum"], "function", ["None"], ["", "def", "get_max_num_levels", "(", "sz", ")", ":", "\n", "  ", "\"\"\"Returns the maximum number of levels that construct() can support.\n\n  Args:\n    sz: A tuple of ints representing some input size (batch, width, height).\n\n  Returns:\n    The maximum value for num_levels, when calling construct(im, num_levels),\n    assuming `sz` is the shape of `im`.\n  \"\"\"", "\n", "min_sz", "=", "np", ".", "minimum", "(", "sz", "[", "1", "]", ",", "sz", "[", "2", "]", ")", "\n", "log2", "=", "lambda", "x", ":", "np", ".", "log", "(", "np", ".", "float32", "(", "x", ")", ")", "/", "np", ".", "log", "(", "np", ".", "float32", "(", "2.", ")", ")", "\n", "max_num_levels", "=", "int", "(", "np", ".", "ceil", "(", "log2", "(", "np", ".", "maximum", "(", "1", ",", "min_sz", ")", ")", ")", ")", "\n", "return", "max_num_levels", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.construct": [[294, 340], ["torch.as_tensor", "wavelet.get_max_num_levels", "wavelet.generate_filters", "range", "tuple.append", "tuple", "len", "ValueError", "wavelet._downsample", "wavelet._downsample", "tuple.append", "wavelet._downsample", "wavelet._downsample", "wavelet._downsample", "wavelet._downsample"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.get_max_num_levels", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.generate_filters", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._downsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._downsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._downsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._downsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._downsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._downsample"], ["", "def", "construct", "(", "im", ",", "num_levels", ",", "wavelet_type", ")", ":", "\n", "  ", "\"\"\"num_levels a wavelet decomposition of an image.\n\n  Args:\n    im: A numpy or TF tensor of single or double precision floats of size\n      (batch_size, width, height)\n    num_levels: The number of levels (or scales) of the wavelet decomposition to\n      apply. A value of 0 returns a \"wavelet decomposition\" that is just the\n      image.\n    wavelet_type: The kind of wavelet to use, see generate_filters().\n\n  Returns:\n    A wavelet decomposition of `im` that has `num_levels` levels (not including\n    the coarsest residual level) and is of type `wavelet_type`. This\n    decomposition is represented as a tuple of 3-tuples, with the final element\n    being a tensor:\n      ((band00, band01, band02), (band10, band11, band12), ..., resid)\n    Where band** and resid are TF tensors. Each element of these nested tuples\n    is of shape [batch_size, width * 2^-(level+1), height * 2^-(level+1)],\n    though the spatial dimensions may be off by 1 if width and height are not\n    factors of 2. The residual image is of the same (rough) size as the last set\n    of bands. The floating point precision of these tensors matches that of\n    `im`.\n  \"\"\"", "\n", "if", "len", "(", "im", ".", "shape", ")", "!=", "3", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'Expected `im` to have a rank of 3, but is of size {}'", ".", "format", "(", "im", ".", "shape", ")", ")", "\n", "", "im", "=", "torch", ".", "as_tensor", "(", "im", ")", "\n", "if", "num_levels", "==", "0", ":", "\n", "    ", "return", "(", "im", ",", ")", "\n", "", "max_num_levels", "=", "get_max_num_levels", "(", "im", ".", "shape", ")", "\n", "assert", "max_num_levels", ">=", "num_levels", "\n", "filters", "=", "generate_filters", "(", "wavelet_type", ")", "\n", "pyr", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_levels", ")", ":", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "    ", "hi", "=", "_downsample", "(", "im", ",", "filters", ".", "analysis_hi", ",", "0", ",", "1", ")", "\n", "lo", "=", "_downsample", "(", "im", ",", "filters", ".", "analysis_lo", ",", "0", ",", "0", ")", "\n", "pyr", ".", "append", "(", "(", "_downsample", "(", "hi", ",", "filters", ".", "analysis_hi", ",", "1", ",", "\n", "1", ")", ",", "_downsample", "(", "lo", ",", "filters", ".", "analysis_hi", ",", "1", ",", "1", ")", ",", "\n", "_downsample", "(", "hi", ",", "filters", ".", "analysis_lo", ",", "1", ",", "0", ")", ")", ")", "\n", "im", "=", "_downsample", "(", "lo", ",", "filters", ".", "analysis_lo", ",", "1", ",", "0", ")", "\n", "", "pyr", ".", "append", "(", "im", ")", "\n", "pyr", "=", "tuple", "(", "pyr", ")", "\n", "return", "pyr", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.collapse": [[342, 386], ["wavelet.generate_filters", "range", "isinstance", "ValueError", "len", "isinstance", "ValueError", "len", "ValueError", "wavelet._upsample", "wavelet._upsample", "type", "type", "len", "wavelet._upsample", "wavelet._upsample", "wavelet._upsample", "wavelet._upsample"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.generate_filters", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._upsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._upsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._upsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._upsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._upsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet._upsample"], ["", "def", "collapse", "(", "pyr", ",", "wavelet_type", ")", ":", "\n", "  ", "\"\"\"Collapses a wavelet decomposition made by construct() back into an image.\n\n  Args:\n    pyr: A numpy or TF tensor of single or double precision floats containing a\n      wavelet decomposition produced by construct().\n    wavelet_type: The kind of wavelet to use, see generate_filters().\n\n  Returns:\n    A TF tensor of a reconstructed image, with the same floating point precision\n    as the element of `pyr`, and the same size as the image that was used to\n    create `pyr`.\n  \"\"\"", "\n", "if", "not", "isinstance", "(", "pyr", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'Expected `pyr` to be a list or tuple, but is a {}'", ".", "format", "(", "\n", "type", "(", "pyr", ")", ")", ")", "\n", "\n", "", "filters", "=", "generate_filters", "(", "wavelet_type", ")", "\n", "im", "=", "pyr", "[", "-", "1", "]", "\n", "num_levels", "=", "len", "(", "pyr", ")", "-", "1", "\n", "for", "d", "in", "range", "(", "num_levels", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "pyr", "[", "d", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'Expected `pyr[{}]` to be a list or tuple, but is a {}'", ".", "format", "(", "\n", "d", ",", "type", "(", "pyr", "[", "d", "]", ")", ")", ")", "\n", "", "if", "len", "(", "pyr", "[", "d", "]", ")", "!=", "3", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'Expected `pyr[{}]` to have length 3, but has length {}'", ".", "format", "(", "\n", "d", ",", "len", "(", "pyr", "[", "d", "]", ")", ")", ")", "\n", "\n", "", "hi_hi", ",", "hi_lo", ",", "lo_hi", "=", "pyr", "[", "d", "]", "\n", "up_sz", "=", "(", "hi_lo", ".", "shape", "[", "1", "]", "+", "lo_hi", ".", "shape", "[", "1", "]", ",", "lo_hi", ".", "shape", "[", "2", "]", "+", "hi_lo", ".", "shape", "[", "2", "]", ")", "\n", "lo_sz", "=", "(", "im", ".", "shape", "[", "1", "]", ",", "up_sz", "[", "1", "]", ")", "\n", "hi_sz", "=", "(", "hi_hi", ".", "shape", "[", "1", "]", ",", "up_sz", "[", "1", "]", ")", "\n", "im", "=", "(", "\n", "_upsample", "(", "\n", "_upsample", "(", "im", ",", "lo_sz", ",", "filters", ".", "synthesis_lo", ",", "1", ",", "0", ")", "+", "\n", "_upsample", "(", "hi_lo", ",", "lo_sz", ",", "filters", ".", "synthesis_hi", ",", "1", ",", "1", ")", ",", "\n", "up_sz", ",", "filters", ".", "synthesis_lo", ",", "0", ",", "0", ")", "+", "\n", "_upsample", "(", "\n", "_upsample", "(", "lo_hi", ",", "hi_sz", ",", "filters", ".", "synthesis_lo", ",", "1", ",", "0", ")", "+", "\n", "_upsample", "(", "hi_hi", ",", "hi_sz", ",", "filters", ".", "synthesis_hi", ",", "1", ",", "1", ")", ",", "\n", "up_sz", ",", "filters", ".", "synthesis_hi", ",", "0", ",", "1", ")", ")", "# pyformat: disable", "\n", "", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.rescale": [[388, 410], ["range", "pyr_norm.append", "range", "pyr_norm.append", "len", "len", "level_norm.append"], "function", ["None"], ["", "def", "rescale", "(", "pyr", ",", "scale_base", ")", ":", "\n", "  ", "\"\"\"Rescale a wavelet decomposition `pyr` by `scale_base`^level.\n\n  Args:\n    pyr: A wavelet decomposition produced by construct().\n    scale_base: The base of the exponentiation used for the per-level scaling.\n\n  Returns:\n    pyr where each level has been scaled by `scale_base`^level. The first\n    level is 0 and is therefore not scaled.\n  \"\"\"", "\n", "pyr_norm", "=", "[", "]", "\n", "for", "d", "in", "range", "(", "len", "(", "pyr", ")", "-", "1", ")", ":", "\n", "    ", "level_norm", "=", "[", "]", "\n", "scale", "=", "scale_base", "**", "d", "\n", "for", "b", "in", "range", "(", "3", ")", ":", "\n", "      ", "level_norm", ".", "append", "(", "pyr", "[", "d", "]", "[", "b", "]", "*", "scale", ")", "\n", "", "pyr_norm", ".", "append", "(", "level_norm", ")", "\n", "", "d", "=", "len", "(", "pyr", ")", "-", "1", "\n", "scale", "=", "scale_base", "**", "d", "\n", "pyr_norm", ".", "append", "(", "pyr", "[", "d", "]", "*", "scale", ")", "\n", "return", "pyr_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten": [[412, 446], ["range", "torch.cat", "len", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "flatten", "(", "pyr", ")", ":", "\n", "  ", "\"\"\"Flattens a wavelet decomposition into an image-like single Tensor.\n\n  construct() produces wavelet decompositions in the form of nested tuples,\n  which is convenient for TensorFlow. But Wavelets are often formatted like:\n  _____________________________________\n  |        |        |                 |\n  | Resid  | Band11 |                 |\n  |________|________|      Band01     |\n  |        |        |                 |\n  | Band12 | Band10 |                 |\n  |________|________|_________________|\n  |                 |                 |\n  |                 |                 |\n  |     Band02      |      Band00     |\n  |                 |                 |\n  |                 |                 |\n  |_________________|_________________|\n  This function turns our internal representation into this more-standard\n  representation. This is useful for visualization and for integration into\n  loss functions.\n\n  Args:\n    pyr: A pyramid-formatted wavelet decomposition produced by construct()\n\n  Returns:\n    A (num_channels, width, height) representation of pyr, as described above.\n  \"\"\"", "\n", "flat", "=", "pyr", "[", "-", "1", "]", "\n", "for", "d", "in", "range", "(", "len", "(", "pyr", ")", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "    ", "flat", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "cat", "(", "[", "flat", ",", "pyr", "[", "d", "]", "[", "1", "]", "]", ",", "dim", "=", "2", ")", ",", "\n", "torch", ".", "cat", "(", "[", "pyr", "[", "d", "]", "[", "2", "]", ",", "pyr", "[", "d", "]", "[", "0", "]", "]", ",", "dim", "=", "2", ")", "]", ",", "dim", "=", "1", ")", "# pyformat: disable", "\n", "", "return", "flat", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.visualize": [[448, 485], ["range", "torch.as_tensor", "vis_pyr.append", "torch.round().type", "range", "vis_pyr.append", "len", "len", "torch.as_tensor", "vis_band.append", "torch.min", "torch.max", "torch.min", "torch.round", "torch.sort", "torch.reshape", "numpy.int64", "flatten().permute", "torch.abs", "numpy.floor", "torch.clamp", "wavelet.flatten", "numpy.clip"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten"], ["", "def", "visualize", "(", "pyr", ",", "percentile", "=", "99.", ")", ":", "\n", "  ", "\"\"\"Visualizes a wavelet decomposition produced by construct().\n\n  Args:\n    pyr: A wavelet decomposition produced by construct(),\n    percentile: The percentile of the deviation for each (non-residual) wavelet\n      band to be clamped by before normalization. Seeting this to 100 causes\n      visualization to clamp to the maximum deviation, which preserves the\n      entire dynamic range but may make subtle details hard to see. A value of\n      99 (the default) will clip away the 1% largest-magnitude values in each\n      band.\n\n  Returns:\n    An image (a TF tensor of uint8's) of shape (width, height, num_channels).\n    Note that the input wavelet decomposition was produced from an image of\n    shape (num_channels, width, height) --- this function permutes the ordering\n    to what is expected in a planar image.\n  \"\"\"", "\n", "vis_pyr", "=", "[", "]", "\n", "for", "d", "in", "range", "(", "len", "(", "pyr", ")", "-", "1", ")", ":", "\n", "    ", "vis_band", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "3", ")", ":", "\n", "      ", "band", "=", "pyr", "[", "d", "]", "[", "b", "]", "\n", "band", "=", "torch", ".", "as_tensor", "(", "band", ")", "\n", "vec", "=", "torch", ".", "sort", "(", "torch", ".", "reshape", "(", "torch", ".", "abs", "(", "band", ")", ",", "[", "-", "1", "]", ")", ")", "[", "0", "]", "\n", "max_mag", "=", "vec", "[", "np", ".", "int64", "(", "\n", "np", ".", "floor", "(", "vec", ".", "shape", "[", "0", "]", "*", "np", ".", "clip", "(", "percentile", "/", "100.", ",", "0.", ",", "1.", ")", ")", ")", "]", "\n", "vis_band", ".", "append", "(", "0.5", "*", "(", "1.", "+", "torch", ".", "clamp", "(", "band", "/", "max_mag", ",", "-", "1.", ",", "1.", ")", ")", ")", "\n", "", "vis_pyr", ".", "append", "(", "vis_band", ")", "\n", "", "d", "=", "len", "(", "pyr", ")", "-", "1", "\n", "resid", "=", "torch", ".", "as_tensor", "(", "pyr", "[", "d", "]", ")", "\n", "resid_norm", "=", "(", "resid", "-", "torch", ".", "min", "(", "resid", ")", ")", "/", "(", "\n", "torch", ".", "max", "(", "resid", ")", "-", "torch", ".", "min", "(", "resid", ")", ")", "\n", "vis_pyr", ".", "append", "(", "resid_norm", ")", "\n", "vis", "=", "torch", ".", "round", "(", "255.", "*", "flatten", "(", "vis_pyr", ")", ".", "permute", "(", "[", "1", ",", "2", ",", "0", "]", ")", ")", ".", "type", "(", "\n", "torch", ".", "uint8", ")", "\n", "return", "vis", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.cubic_spline.interpolate1d": [[24, 98], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.floor().type", "torch.where", "len", "len", "torch.floor().type.type", "torch.where", "torch.floor", "torch.clamp", "torch.as_tensor"], "function", ["None"], ["def", "interpolate1d", "(", "x", ",", "values", ",", "tangents", ")", ":", "\n", "  ", "r\"\"\"Perform cubic hermite spline interpolation on a 1D spline.\n\n  The x coordinates of the spline knots are at [0 : 1 : len(values)-1].\n  Queries outside of the range of the spline are computed using linear\n  extrapolation. See https://en.wikipedia.org/wiki/Cubic_Hermite_spline\n  for details, where \"x\" corresponds to `x`, \"p\" corresponds to `values`, and\n  \"m\" corresponds to `tangents`.\n\n  Args:\n    x: A tensor of any size of single or double precision floats containing the\n      set of values to be used for interpolation into the spline.\n    values: A vector of single or double precision floats containing the value\n      of each knot of the spline being interpolated into. Must be the same\n      length as `tangents` and the same type as `x`.\n    tangents: A vector of single or double precision floats containing the\n      tangent (derivative) of each knot of the spline being interpolated into.\n      Must be the same length as `values` and the same type as `x`.\n\n  Returns:\n    The result of interpolating along the spline defined by `values`, and\n    `tangents`, using `x` as the query values. Will be the same length and type\n    as `x`.\n  \"\"\"", "\n", "# if x.dtype == 'float64' or torch.as_tensor(x).dtype == torch.float64:", "\n", "#   float_dtype = torch.float64", "\n", "# else:", "\n", "#   float_dtype = torch.float32", "\n", "# x = torch.as_tensor(x, dtype=float_dtype)", "\n", "# values = torch.as_tensor(values, dtype=float_dtype)", "\n", "# tangents = torch.as_tensor(tangents, dtype=float_dtype)", "\n", "assert", "torch", ".", "is_tensor", "(", "x", ")", "\n", "assert", "torch", ".", "is_tensor", "(", "values", ")", "\n", "assert", "torch", ".", "is_tensor", "(", "tangents", ")", "\n", "float_dtype", "=", "x", ".", "dtype", "\n", "assert", "values", ".", "dtype", "==", "float_dtype", "\n", "assert", "tangents", ".", "dtype", "==", "float_dtype", "\n", "assert", "len", "(", "values", ".", "shape", ")", "==", "1", "\n", "assert", "len", "(", "tangents", ".", "shape", ")", "==", "1", "\n", "assert", "values", ".", "shape", "[", "0", "]", "==", "tangents", ".", "shape", "[", "0", "]", "\n", "\n", "x_lo", "=", "torch", ".", "floor", "(", "torch", ".", "clamp", "(", "x", ",", "torch", ".", "as_tensor", "(", "0", ")", ",", "\n", "values", ".", "shape", "[", "0", "]", "-", "2", ")", ")", ".", "type", "(", "torch", ".", "int64", ")", "\n", "x_hi", "=", "x_lo", "+", "1", "\n", "\n", "# Compute the relative distance between each `x` and the knot below it.", "\n", "t", "=", "x", "-", "x_lo", ".", "type", "(", "float_dtype", ")", "\n", "\n", "# Compute the cubic hermite expansion of `t`.", "\n", "t_sq", "=", "t", "**", "2", "\n", "t_cu", "=", "t", "*", "t_sq", "\n", "h01", "=", "-", "2.", "*", "t_cu", "+", "3.", "*", "t_sq", "\n", "h00", "=", "1.", "-", "h01", "\n", "h11", "=", "t_cu", "-", "t_sq", "\n", "h10", "=", "h11", "-", "t_sq", "+", "t", "\n", "\n", "# Linearly extrapolate above and below the extents of the spline for all", "\n", "# values.", "\n", "value_before", "=", "tangents", "[", "0", "]", "*", "t", "+", "values", "[", "0", "]", "\n", "value_after", "=", "tangents", "[", "-", "1", "]", "*", "(", "t", "-", "1.", ")", "+", "values", "[", "-", "1", "]", "\n", "\n", "# Cubically interpolate between the knots below and above each query point.", "\n", "neighbor_values_lo", "=", "values", "[", "x_lo", "]", "\n", "neighbor_values_hi", "=", "values", "[", "x_hi", "]", "\n", "neighbor_tangents_lo", "=", "tangents", "[", "x_lo", "]", "\n", "neighbor_tangents_hi", "=", "tangents", "[", "x_hi", "]", "\n", "value_mid", "=", "(", "\n", "neighbor_values_lo", "*", "h00", "+", "neighbor_values_hi", "*", "h01", "+", "\n", "neighbor_tangents_lo", "*", "h10", "+", "neighbor_tangents_hi", "*", "h11", ")", "\n", "\n", "# Return the interpolated or extrapolated values for each query point,", "\n", "# depending on whether or not the query lies within the span of the spline.", "\n", "return", "torch", ".", "where", "(", "t", "<", "0.", ",", "value_before", ",", "\n", "torch", ".", "where", "(", "t", ">", "1.", ",", "value_after", ",", "value_mid", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.__init__": [[82, 92], ["pkg_resources.resource_stream", "numpy.load", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# Load the values, tangents, and x-coordinate scaling of a spline that", "\n", "# approximates the partition function. This was produced by running", "\n", "# the script in fit_partition_spline.py", "\n", "    ", "with", "resource_stream", "(", "__name__", ",", "'resources/partition_spline.npz'", ")", "as", "spline_file", ":", "\n", "      ", "with", "np", ".", "load", "(", "spline_file", ",", "allow_pickle", "=", "False", ")", "as", "f", ":", "\n", "        ", "self", ".", "_spline_x_scale", "=", "torch", ".", "tensor", "(", "f", "[", "'x_scale'", "]", ")", "\n", "self", ".", "_spline_values", "=", "torch", ".", "tensor", "(", "f", "[", "'values'", "]", ")", "\n", "self", ".", "_spline_tangents", "=", "torch", ".", "tensor", "(", "f", "[", "'tangents'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.log_base_partition_function": [[93, 120], ["torch.as_tensor", "distribution.partition_spline_curve", "pioneer.robust_loss_pytorch.cubic_spline.interpolate1d", "distribution.Distribution._spline_values.to", "distribution.Distribution._spline_tangents.to", "distribution.Distribution._spline_x_scale.to"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.partition_spline_curve", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.cubic_spline.interpolate1d"], ["", "", "", "def", "log_base_partition_function", "(", "self", ",", "alpha", ")", ":", "\n", "    ", "r\"\"\"Approximate the distribution's log-partition function with a 1D spline.\n\n    Because the partition function (Z(\\alpha) in the paper) of the distribution\n    is difficult to model analytically, we approximate it with a (transformed)\n    cubic hermite spline: Each alpha is pushed through a nonlinearity before\n    being used to interpolate into a spline, which allows us to use a relatively\n    small spline to accurately model the log partition function over the range\n    of all non-negative input values.\n\n    Args:\n      alpha: A tensor or scalar of single or double precision floats containing\n        the set of alphas for which we would like an approximate log partition\n        function. Must be non-negative, as the partition function is undefined\n        when alpha < 0.\n\n    Returns:\n      An approximation of log(Z(alpha)) accurate to within 1e-6\n    \"\"\"", "\n", "alpha", "=", "torch", ".", "as_tensor", "(", "alpha", ")", "\n", "assert", "(", "alpha", ">=", "0", ")", ".", "all", "(", ")", "\n", "# Transform `alpha` to the form expected by the spline.", "\n", "x", "=", "partition_spline_curve", "(", "alpha", ")", "\n", "# Interpolate into the spline.", "\n", "return", "cubic_spline", ".", "interpolate1d", "(", "x", "*", "self", ".", "_spline_x_scale", ".", "to", "(", "x", ")", ",", "\n", "self", ".", "_spline_values", ".", "to", "(", "x", ")", ",", "\n", "self", ".", "_spline_tangents", ".", "to", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.nllfun": [[121, 161], ["torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "pioneer.robust_loss_pytorch.general.lossfun", "torch.log", "distribution.Distribution.log_base_partition_function"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.general.lossfun", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.log_base_partition_function"], ["", "def", "nllfun", "(", "self", ",", "x", ",", "alpha", ",", "scale", ")", ":", "\n", "    ", "r\"\"\"Implements the negative log-likelihood (NLL).\n\n    Specifically, we implement -log(p(x | 0, \\alpha, c) of Equation 16 in the\n    paper as nllfun(x, alpha, shape).\n\n    Args:\n      x: The residual for which the NLL is being computed. x can have any shape,\n        and alpha and scale will be broadcasted to match x's shape if necessary.\n        Must be a tensor or numpy array of floats.\n      alpha: The shape parameter of the NLL (\\alpha in the paper), where more\n        negative values cause outliers to \"cost\" more and inliers to \"cost\"\n        less. Alpha can be any non-negative value, but the gradient of the NLL\n        with respect to alpha has singularities at 0 and 2 so you may want to\n        limit usage to (0, 2) during gradient descent. Must be a tensor or numpy\n        array of floats. Varying alpha in that range allows for smooth\n        interpolation between a Cauchy distribution (alpha = 0) and a Normal\n        distribution (alpha = 2) similar to a Student's T distribution.\n      scale: The scale parameter of the loss. When |x| < scale, the NLL is like\n        that of a (possibly unnormalized) normal distribution, and when |x| >\n        scale the NLL takes on a different shape according to alpha. Must be a\n        tensor or numpy array of floats.\n\n    Returns:\n      The NLLs for each element of x, in the same shape and precision as x.\n    \"\"\"", "\n", "# `scale` and `alpha` must have the same type as `x`.", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "alpha", "=", "torch", ".", "as_tensor", "(", "alpha", ")", "\n", "scale", "=", "torch", ".", "as_tensor", "(", "scale", ")", "\n", "assert", "(", "alpha", ">=", "0", ")", ".", "all", "(", ")", "\n", "assert", "(", "scale", ">=", "0", ")", ".", "all", "(", ")", "\n", "float_dtype", "=", "x", ".", "dtype", "\n", "assert", "alpha", ".", "dtype", "==", "float_dtype", "\n", "assert", "scale", ".", "dtype", "==", "float_dtype", "\n", "\n", "loss", "=", "general", ".", "lossfun", "(", "x", ",", "alpha", ",", "scale", ",", "approximate", "=", "False", ")", "\n", "log_partition", "=", "torch", ".", "log", "(", "scale", ")", "+", "self", ".", "log_base_partition_function", "(", "alpha", ")", "\n", "nll", "=", "loss", "+", "log_partition", "\n", "return", "nll", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.draw_samples": [[162, 234], ["torch.as_tensor", "torch.as_tensor", "torch.distributions.cauchy.Cauchy", "torch.distributions.uniform.Uniform", "torch.zeros_like", "torch.zeros().type", "numpy.sqrt", "torch.zeros().type.type().all", "torch.reshape", "cauchy_sample.type.type.type", "distribution.Distribution.nllfun", "torch.reshape", "uniform_sample.type.type.type", "torch.where", "torch.zeros", "torch.distributions.cauchy.Cauchy.sample", "torch.as_tensor().to", "torch.tensor().to", "pioneer.robust_loss_pytorch.general.lossfun", "distribution.Distribution.log_base_partition_function", "torch.distributions.uniform.Uniform.sample", "torch.exp", "torch.zeros().type.type", "torch.tensor", "torch.tensor", "numpy.prod", "torch.as_tensor", "torch.tensor", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.nllfun", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.general.lossfun", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.Distribution.log_base_partition_function"], ["", "def", "draw_samples", "(", "self", ",", "alpha", ",", "scale", ")", ":", "\n", "    ", "r\"\"\"Draw samples from the robust distribution.\n\n    This function implements Algorithm 1 the paper. This code is written to\n    allow\n    for sampling from a set of different distributions, each parametrized by its\n    own alpha and scale values, as opposed to the more standard approach of\n    drawing N samples from the same distribution. This is done by repeatedly\n    performing N instances of rejection sampling for each of the N distributions\n    until at least one proposal for each of the N distributions has been\n    accepted.\n    All samples are drawn with a zero mean, to use a non-zero mean just add each\n    mean to each sample.\n\n    Args:\n      alpha: A tensor/scalar or numpy array/scalar of floats where each element\n        is the shape parameter of that element's distribution.\n      scale: A tensor/scalar or numpy array/scalar of floats where each element\n        is the scale parameter of that element's distribution. Must be the same\n        shape as `alpha`.\n\n    Returns:\n      A tensor with the same shape and precision as `alpha` and `scale` where\n      each element is a sample drawn from the distribution specified for that\n      element by `alpha` and `scale`.\n    \"\"\"", "\n", "alpha", "=", "torch", ".", "as_tensor", "(", "alpha", ")", "\n", "scale", "=", "torch", ".", "as_tensor", "(", "scale", ")", "\n", "assert", "(", "alpha", ">=", "0", ")", ".", "all", "(", ")", "\n", "assert", "(", "scale", ">=", "0", ")", ".", "all", "(", ")", "\n", "float_dtype", "=", "alpha", ".", "dtype", "\n", "assert", "scale", ".", "dtype", "==", "float_dtype", "\n", "\n", "cauchy", "=", "torch", ".", "distributions", ".", "cauchy", ".", "Cauchy", "(", "0.", ",", "np", ".", "sqrt", "(", "2.", ")", ")", "\n", "uniform", "=", "torch", ".", "distributions", ".", "uniform", ".", "Uniform", "(", "0", ",", "1", ")", "\n", "samples", "=", "torch", ".", "zeros_like", "(", "alpha", ")", "\n", "accepted", "=", "torch", ".", "zeros", "(", "alpha", ".", "shape", ")", ".", "type", "(", "torch", ".", "uint8", ")", "\n", "while", "not", "accepted", ".", "type", "(", "torch", ".", "uint8", ")", ".", "all", "(", ")", ":", "\n", "# Draw N samples from a Cauchy, our proposal distribution.", "\n", "      ", "cauchy_sample", "=", "torch", ".", "reshape", "(", "\n", "cauchy", ".", "sample", "(", "(", "np", ".", "prod", "(", "alpha", ".", "shape", ")", ",", ")", ")", ",", "alpha", ".", "shape", ")", "\n", "cauchy_sample", "=", "cauchy_sample", ".", "type", "(", "alpha", ".", "dtype", ")", "\n", "\n", "# Compute the likelihood of each sample under its target distribution.", "\n", "nll", "=", "self", ".", "nllfun", "(", "cauchy_sample", ",", "\n", "torch", ".", "as_tensor", "(", "alpha", ")", ".", "to", "(", "cauchy_sample", ")", ",", "\n", "torch", ".", "tensor", "(", "1", ")", ".", "to", "(", "cauchy_sample", ")", ")", "\n", "\n", "# Bound the NLL. We don't use the approximate loss as it may cause", "\n", "# unpredictable behavior in the context of sampling.", "\n", "nll_bound", "=", "general", ".", "lossfun", "(", "\n", "cauchy_sample", ",", "\n", "torch", ".", "tensor", "(", "0.", ",", "dtype", "=", "cauchy_sample", ".", "dtype", ")", ",", "\n", "torch", ".", "tensor", "(", "1.", ",", "dtype", "=", "cauchy_sample", ".", "dtype", ")", ",", "\n", "approximate", "=", "False", ")", "+", "self", ".", "log_base_partition_function", "(", "alpha", ")", "\n", "\n", "# Draw N samples from a uniform distribution, and use each uniform sample", "\n", "# to decide whether or not to accept each proposal sample.", "\n", "uniform_sample", "=", "torch", ".", "reshape", "(", "\n", "uniform", ".", "sample", "(", "(", "np", ".", "prod", "(", "alpha", ".", "shape", ")", ",", ")", ")", ",", "alpha", ".", "shape", ")", "\n", "uniform_sample", "=", "uniform_sample", ".", "type", "(", "alpha", ".", "dtype", ")", "\n", "accept", "=", "uniform_sample", "<=", "torch", ".", "exp", "(", "nll_bound", "-", "nll", ")", "\n", "\n", "# If a sample is accepted, replace its element in `samples` with the", "\n", "# proposal sample, and set its bit in `accepted` to True.", "\n", "samples", "=", "torch", ".", "where", "(", "accept", ",", "cauchy_sample", ",", "samples", ")", "\n", "accepted", "=", "accepted", "|", "accept", "\n", "\n", "# Because our distribution is a location-scale family, we sample from", "\n", "# p(x | 0, \\alpha, 1) and then scale each sample by `scale`.", "\n", "", "samples", "*=", "scale", "\n", "return", "samples", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.partition_spline_curve": [[40, 65], ["torch.as_tensor", "torch.where", "pioneer.robust_loss_pytorch.util.log_safe", "torch.abs"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.log_safe"], ["def", "partition_spline_curve", "(", "alpha", ")", ":", "\n", "  ", "\"\"\"Applies a curve to alpha >= 0 to compress its range before interpolation.\n\n  This is a weird hand-crafted function designed to take in alpha values and\n  curve them to occupy a short finite range that works well when using spline\n  interpolation to model the partition function Z(alpha). Because Z(alpha)\n  is only varied in [0, 4] and is especially interesting around alpha=2, this\n  curve is roughly linear in [0, 4] with a slope of ~1 at alpha=0 and alpha=4\n  but a slope of ~10 at alpha=2. When alpha > 4 the curve becomes logarithmic.\n  Some (input, output) pairs for this function are:\n    [(0, 0), (1, ~1.2), (2, 4), (3, ~6.8), (4, 8), (8, ~8.8), (400000, ~12)]\n  This function is continuously differentiable.\n\n  Args:\n    alpha: A numpy array or tensor (float32 or float64) with values >= 0.\n\n  Returns:\n    An array/tensor of curved values >= 0 with the same type as `alpha`, to be\n    used as input x-coordinates for spline interpolation.\n  \"\"\"", "\n", "alpha", "=", "torch", ".", "as_tensor", "(", "alpha", ")", "\n", "x", "=", "torch", ".", "where", "(", "alpha", "<", "4", ",", "(", "2.25", "*", "alpha", "-", "4.5", ")", "/", "\n", "(", "torch", ".", "abs", "(", "alpha", "-", "2", ")", "+", "0.25", ")", "+", "alpha", "+", "2", ",", "\n", "5.", "/", "18.", "*", "util", ".", "log_safe", "(", "4", "*", "alpha", "-", "15", ")", "+", "8", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.distribution.inv_partition_spline_curve": [[67, 77], ["torch.as_tensor", "torch.where", "torch.where", "pioneer.robust_loss_pytorch.util.exp_safe", "torch.sqrt", "torch.sqrt"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.exp_safe"], ["", "def", "inv_partition_spline_curve", "(", "x", ")", ":", "\n", "  ", "\"\"\"The inverse of partition_spline_curve().\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "assert", "(", "x", ">=", "0", ")", ".", "all", "(", ")", "\n", "alpha", "=", "torch", ".", "where", "(", "\n", "x", "<", "8", ",", "\n", "0.5", "*", "x", "+", "torch", ".", "where", "(", "x", "<=", "4", ",", "1.25", "-", "torch", ".", "sqrt", "(", "1.5625", "-", "x", "+", ".25", "*", "x", "**", "2", ")", ",", "\n", "-", "1.25", "+", "torch", ".", "sqrt", "(", "9.5625", "-", "3", "*", "x", "+", ".25", "*", "x", "**", "2", ")", ")", ",", "\n", "3.75", "+", "0.25", "*", "util", ".", "exp_safe", "(", "x", "*", "3.6", "-", "28.8", ")", ")", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.log_safe": [[28, 32], ["torch.as_tensor().to", "torch.log", "torch.device", "torch.min", "torch.as_tensor", "torch.tensor().to", "torch.tensor"], "function", ["None"], ["def", "log_safe", "(", "x", ")", ":", "\n", "  ", "\"\"\"The same as torch.log(x), but clamps the input to prevent NaNs.\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "log", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "33e37", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.log1p_safe": [[34, 38], ["torch.as_tensor().to", "torch.log1p", "torch.device", "torch.min", "torch.as_tensor", "torch.tensor().to", "torch.tensor"], "function", ["None"], ["", "def", "log1p_safe", "(", "x", ")", ":", "\n", "  ", "\"\"\"The same as torch.log1p(x), but clamps the input to prevent NaNs.\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "log1p", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "33e37", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.exp_safe": [[40, 44], ["torch.as_tensor().to", "torch.exp", "torch.device", "torch.min", "torch.as_tensor", "torch.tensor().to", "torch.tensor"], "function", ["None"], ["", "def", "exp_safe", "(", "x", ")", ":", "\n", "  ", "\"\"\"The same as torch.exp(x), but clamps the input to prevent NaNs.\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "exp", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "87.5", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.expm1_safe": [[46, 50], ["torch.as_tensor().to", "torch.expm1", "torch.device", "torch.min", "torch.as_tensor", "torch.tensor().to", "torch.tensor"], "function", ["None"], ["", "def", "expm1_safe", "(", "x", ")", ":", "\n", "  ", "\"\"\"The same as tf.math.expm1(x), but clamps the input to prevent NaNs.\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "expm1", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "87.5", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.inv_softplus": [[52, 56], ["torch.as_tensor().to", "torch.where", "torch.device", "torch.log", "torch.as_tensor", "torch.expm1"], "function", ["None"], ["", "def", "inv_softplus", "(", "y", ")", ":", "\n", "  ", "\"\"\"The inverse of tf.nn.softplus().\"\"\"", "\n", "y", "=", "torch", ".", "as_tensor", "(", "y", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "where", "(", "y", ">", "87.5", ",", "y", ",", "torch", ".", "log", "(", "torch", ".", "expm1", "(", "y", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.logit": [[58, 62], ["torch.as_tensor().to", "torch.device", "torch.log", "torch.as_tensor"], "function", ["None"], ["", "def", "logit", "(", "y", ")", ":", "\n", "  ", "\"\"\"The inverse of tf.nn.sigmoid().\"\"\"", "\n", "y", "=", "torch", ".", "as_tensor", "(", "y", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "-", "torch", ".", "log", "(", "1.", "/", "y", "-", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.affine_sigmoid": [[64, 74], ["torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "ValueError", "torch.device", "torch.device", "torch.device", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.sigmoid"], "function", ["None"], ["", "def", "affine_sigmoid", "(", "logits", ",", "lo", "=", "0", ",", "hi", "=", "1", ")", ":", "\n", "  ", "\"\"\"Maps reals to (lo, hi), where 0 maps to (lo+hi)/2.\"\"\"", "\n", "#import ipdb; ipdb.set_trace()", "\n", "if", "not", "lo", "<", "hi", ":", "\n", "    ", "raise", "ValueError", "(", "'`lo` (%g) must be < `hi` (%g)'", "%", "(", "lo", ",", "hi", ")", ")", "\n", "", "logits", "=", "torch", ".", "as_tensor", "(", "logits", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "lo", "=", "torch", ".", "as_tensor", "(", "lo", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "hi", "=", "torch", ".", "as_tensor", "(", "hi", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "alpha", "=", "torch", ".", "sigmoid", "(", "logits", ")", "*", "(", "hi", "-", "lo", ")", "+", "lo", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.inv_affine_sigmoid": [[76, 85], ["torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "util.logit", "ValueError", "torch.device", "torch.device", "torch.device", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.logit"], ["", "def", "inv_affine_sigmoid", "(", "probs", ",", "lo", "=", "0", ",", "hi", "=", "1", ")", ":", "\n", "  ", "\"\"\"The inverse of affine_sigmoid(., lo, hi).\"\"\"", "\n", "if", "not", "lo", "<", "hi", ":", "\n", "    ", "raise", "ValueError", "(", "'`lo` (%g) must be < `hi` (%g)'", "%", "(", "lo", ",", "hi", ")", ")", "\n", "", "probs", "=", "torch", ".", "as_tensor", "(", "probs", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "lo", "=", "torch", ".", "as_tensor", "(", "lo", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "hi", "=", "torch", ".", "as_tensor", "(", "hi", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "logits", "=", "logit", "(", "(", "probs", "-", "lo", ")", "/", "(", "hi", "-", "lo", ")", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.affine_softplus": [[87, 97], ["torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "util.inv_softplus", "ValueError", "torch.device", "torch.device", "torch.device", "torch.tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.nn.Softplus"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.inv_softplus"], ["", "def", "affine_softplus", "(", "x", ",", "lo", "=", "0", ",", "ref", "=", "1", ")", ":", "\n", "  ", "\"\"\"Maps real numbers to (lo, infinity), where 0 maps to ref.\"\"\"", "\n", "if", "not", "lo", "<", "ref", ":", "\n", "    ", "raise", "ValueError", "(", "'`lo` (%g) must be < `ref` (%g)'", "%", "(", "lo", ",", "ref", ")", ")", "\n", "", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "lo", "=", "torch", ".", "as_tensor", "(", "lo", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "ref", "=", "torch", ".", "as_tensor", "(", "ref", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "shift", "=", "inv_softplus", "(", "torch", ".", "tensor", "(", "1.", ")", ")", "\n", "y", "=", "(", "ref", "-", "lo", ")", "*", "torch", ".", "nn", ".", "Softplus", "(", ")", "(", "x", "+", "shift", ")", "+", "lo", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.inv_affine_softplus": [[99, 109], ["torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "util.inv_softplus", "ValueError", "torch.device", "torch.device", "torch.device", "torch.tensor", "util.inv_softplus", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.inv_softplus", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.inv_softplus"], ["", "def", "inv_affine_softplus", "(", "y", ",", "lo", "=", "0", ",", "ref", "=", "1", ")", ":", "\n", "  ", "\"\"\"The inverse of affine_softplus(., lo, ref).\"\"\"", "\n", "if", "not", "lo", "<", "ref", ":", "\n", "    ", "raise", "ValueError", "(", "'`lo` (%g) must be < `ref` (%g)'", "%", "(", "lo", ",", "ref", ")", ")", "\n", "", "y", "=", "torch", ".", "as_tensor", "(", "y", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "lo", "=", "torch", ".", "as_tensor", "(", "lo", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "ref", "=", "torch", ".", "as_tensor", "(", "ref", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "shift", "=", "inv_softplus", "(", "torch", ".", "tensor", "(", "1.", ")", ")", "\n", "x", "=", "inv_softplus", "(", "(", "y", "-", "lo", ")", "/", "(", "ref", "-", "lo", ")", ")", "-", "shift", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.students_t_nll": [[111, 121], ["torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.tensor", "torch.lgamma", "torch.log", "torch.lgamma", "numpy.log", "torch.log", "torch.abs", "torch.tensor", "torch.log1p"], "function", ["None"], ["", "def", "students_t_nll", "(", "x", ",", "df", ",", "scale", ")", ":", "\n", "  ", "\"\"\"The NLL of a Generalized Student's T distribution (w/o including TFP).\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "df", "=", "torch", ".", "as_tensor", "(", "df", ")", "\n", "scale", "=", "torch", ".", "as_tensor", "(", "scale", ")", "\n", "log_partition", "=", "torch", ".", "log", "(", "torch", ".", "abs", "(", "scale", ")", ")", "+", "torch", ".", "lgamma", "(", "\n", "0.5", "*", "df", ")", "-", "torch", ".", "lgamma", "(", "0.5", "*", "df", "+", "torch", ".", "tensor", "(", "0.5", ")", ")", "+", "torch", ".", "tensor", "(", "\n", "0.5", "*", "np", ".", "log", "(", "np", ".", "pi", ")", ")", "\n", "return", "0.5", "*", "(", "(", "df", "+", "1.", ")", "*", "torch", ".", "log1p", "(", "\n", "(", "x", "/", "scale", ")", "**", "2.", "/", "df", ")", "+", "torch", ".", "log", "(", "df", ")", ")", "+", "log_partition", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.rgb_to_syuv": [[127, 149], ["torch.as_tensor().to", "torch.tensor().to().to", "torch.reshape", "torch.device", "torch.device", "torch.matmul", "torch.as_tensor", "torch.tensor().to", "torch.reshape", "torch.tensor"], "function", ["None"], ["def", "rgb_to_syuv", "(", "rgb", ")", ":", "\n", "  ", "\"\"\"A volume preserving version of tf.image.rgb_to_yuv().\n\n  By \"volume preserving\" we mean that rgb_to_syuv() is in the \"special linear\n  group\", or equivalently, that the Jacobian determinant of the transformation\n  is 1.\n\n  Args:\n    rgb: A tensor whose last dimension corresponds to RGB channels and is of\n      size 3.\n\n  Returns:\n    A scaled YUV version of the input tensor, such that this transformation is\n    volume-preserving.\n  \"\"\"", "\n", "rgb", "=", "torch", ".", "as_tensor", "(", "rgb", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "kernel", "=", "torch", ".", "tensor", "(", "[", "[", "0.299", ",", "-", "0.14714119", ",", "0.61497538", "]", ",", "\n", "[", "0.587", ",", "-", "0.28886916", ",", "-", "0.51496512", "]", ",", "\n", "[", "0.114", ",", "0.43601035", ",", "-", "0.10001026", "]", "]", ")", ".", "to", "(", "rgb", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "yuv", "=", "torch", ".", "reshape", "(", "\n", "torch", ".", "matmul", "(", "torch", ".", "reshape", "(", "rgb", ",", "[", "-", "1", ",", "3", "]", ")", ",", "kernel", ")", ",", "rgb", ".", "shape", ")", "\n", "return", "_VOLUME_PRESERVING_YUV_SCALE", "*", "yuv", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.syuv_to_rgb": [[151, 172], ["torch.as_tensor().to", "torch.tensor().to().to", "torch.reshape", "torch.device", "torch.device", "torch.matmul", "torch.as_tensor", "torch.tensor().to", "torch.reshape", "torch.tensor"], "function", ["None"], ["", "def", "syuv_to_rgb", "(", "yuv", ")", ":", "\n", "  ", "\"\"\"A volume preserving version of tf.image.yuv_to_rgb().\n\n  By \"volume preserving\" we mean that rgb_to_syuv() is in the \"special linear\n  group\", or equivalently, that the Jacobian determinant of the transformation\n  is 1.\n\n  Args:\n    yuv: A tensor whose last dimension corresponds to scaled YUV channels and is\n      of size 3 (ie, the output of rgb_to_syuv()).\n\n  Returns:\n    An RGB version of the input tensor, such that this transformation is\n    volume-preserving.\n  \"\"\"", "\n", "yuv", "=", "torch", ".", "as_tensor", "(", "yuv", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "kernel", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "0", ",", "-", "0.394642334", ",", "2.03206185", "]", ",", "\n", "[", "1.13988303", ",", "-", "0.58062185", ",", "0", "]", "]", ")", ".", "to", "(", "yuv", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "rgb", "=", "torch", ".", "reshape", "(", "\n", "torch", ".", "matmul", "(", "torch", ".", "reshape", "(", "yuv", ",", "[", "-", "1", ",", "3", "]", ")", ",", "kernel", ")", ",", "yuv", ".", "shape", ")", "\n", "return", "rgb", "/", "_VOLUME_PRESERVING_YUV_SCALE", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.compute_jacobian": [[190, 201], ["range", "numpy.stack", "torch.reshape", "numpy.prod", "torch.autograd.Variable", "y.backward", "np.stack.append", "torch.tensor", "vec", "numpy.array", "f", "vec"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.backward"], ["", "def", "compute_jacobian", "(", "f", ",", "x", ")", ":", "\n", "  ", "\"\"\"Computes the Jacobian of function `f` with respect to input `x`.\"\"\"", "\n", "vec", "=", "lambda", "z", ":", "torch", ".", "reshape", "(", "z", ",", "[", "-", "1", "]", ")", "\n", "jacobian", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "np", ".", "prod", "(", "x", ".", "shape", ")", ")", ":", "\n", "    ", "var_x", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "tensor", "(", "x", ")", ",", "requires_grad", "=", "True", ")", "\n", "y", "=", "vec", "(", "f", "(", "var_x", ")", ")", "[", "i", "]", "\n", "y", ".", "backward", "(", ")", "\n", "jacobian", ".", "append", "(", "np", ".", "array", "(", "vec", "(", "var_x", ".", "grad", ")", ")", ")", "\n", "", "jacobian", "=", "np", ".", "stack", "(", "jacobian", ",", "1", ")", "\n", "return", "jacobian", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.general.lossfun": [[32, 121], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.where", "pioneer.robust_loss_pytorch.util.log1p_safe", "pioneer.robust_loss_pytorch.util.expm1_safe", "torch.tensor().to", "torch.max", "torch.where", "torch.abs", "torch.expm1", "torch.abs", "torch.where", "torch.max", "torch.where", "numpy.finfo", "torch.pow", "torch.tensor", "torch.ones_like", "torch.abs", "torch.pow", "torch.where", "torch.ones_like", "float", "torch.where", "numpy.finfo", "float"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.log1p_safe", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.util.expm1_safe"], ["def", "lossfun", "(", "x", ",", "alpha", ",", "scale", ",", "approximate", "=", "False", ",", "epsilon", "=", "1e-6", ")", ":", "\n", "  ", "r\"\"\"Implements the general form of the loss.\n\n  This implements the rho(x, \\alpha, c) function described in \"A General and\n  Adaptive Robust Loss Function\", Jonathan T. Barron,\n  https://arxiv.org/abs/1701.03077.\n\n  Args:\n    x: The residual for which the loss is being computed. x can have any shape,\n      and alpha and scale will be broadcasted to match x's shape if necessary.\n      Must be a tensor of floats.\n    alpha: The shape parameter of the loss (\\alpha in the paper), where more\n      negative values produce a loss with more robust behavior (outliers \"cost\"\n      less), and more positive values produce a loss with less robust behavior\n      (outliers are penalized more heavily). Alpha can be any value in\n      [-infinity, infinity], but the gradient of the loss with respect to alpha\n      is 0 at -infinity, infinity, 0, and 2. Must be a tensor of floats with the\n      same precision as `x`. Varying alpha allows\n      for smooth interpolation between a number of discrete robust losses:\n      alpha=-Infinity: Welsch/Leclerc Loss.\n      alpha=-2: Geman-McClure loss.\n      alpha=0: Cauchy/Lortentzian loss.\n      alpha=1: Charbonnier/pseudo-Huber loss.\n      alpha=2: L2 loss.\n    scale: The scale parameter of the loss. When |x| < scale, the loss is an\n      L2-like quadratic bowl, and when |x| > scale the loss function takes on a\n      different shape according to alpha. Must be a tensor of single-precision\n      floats.\n    approximate: a bool, where if True, this function returns an approximate and\n      faster form of the loss, as described in the appendix of the paper. This\n      approximation holds well everywhere except as x and alpha approach zero.\n    epsilon: A float that determines how inaccurate the \"approximate\" version of\n      the loss will be. Larger values are less accurate but more numerically\n      stable. Must be great than single-precision machine epsilon.\n\n  Returns:\n    The losses for each element of x, in the same shape and precision as x.\n  \"\"\"", "\n", "assert", "torch", ".", "is_tensor", "(", "x", ")", "\n", "assert", "torch", ".", "is_tensor", "(", "scale", ")", "\n", "assert", "torch", ".", "is_tensor", "(", "alpha", ")", "\n", "assert", "alpha", ".", "dtype", "==", "x", ".", "dtype", "\n", "assert", "scale", ".", "dtype", "==", "x", ".", "dtype", "\n", "assert", "(", "scale", ">", "0", ")", ".", "all", "(", ")", "\n", "if", "approximate", ":", "\n", "# `epsilon` must be greater than single-precision machine epsilon.", "\n", "    ", "assert", "epsilon", ">", "np", ".", "finfo", "(", "np", ".", "float32", ")", ".", "eps", "\n", "# Compute an approximate form of the loss which is faster, but innacurate", "\n", "# when x and alpha are near zero.", "\n", "b", "=", "torch", ".", "abs", "(", "alpha", "-", "2", ")", "+", "epsilon", "\n", "d", "=", "torch", ".", "where", "(", "alpha", ">=", "0", ",", "alpha", "+", "epsilon", ",", "alpha", "-", "epsilon", ")", "\n", "loss", "=", "(", "b", "/", "d", ")", "*", "(", "torch", ".", "pow", "(", "(", "x", "/", "scale", ")", "**", "2", "/", "b", "+", "1.", ",", "0.5", "*", "d", ")", "-", "1.", ")", "\n", "", "else", ":", "\n", "# Compute the exact loss.", "\n", "\n", "# This will be used repeatedly.", "\n", "    ", "squared_scaled_x", "=", "(", "x", "/", "scale", ")", "**", "2", "\n", "\n", "# The loss when alpha == 2.", "\n", "loss_two", "=", "0.5", "*", "squared_scaled_x", "\n", "# The loss when alpha == 0.", "\n", "loss_zero", "=", "util", ".", "log1p_safe", "(", "0.5", "*", "squared_scaled_x", ")", "\n", "# The loss when alpha == -infinity.", "\n", "loss_neginf", "=", "-", "torch", ".", "expm1", "(", "-", "0.5", "*", "squared_scaled_x", ")", "\n", "# The loss when alpha == +infinity.", "\n", "loss_posinf", "=", "util", ".", "expm1_safe", "(", "0.5", "*", "squared_scaled_x", ")", "\n", "\n", "# The loss when not in one of the above special cases.", "\n", "machine_epsilon", "=", "torch", ".", "tensor", "(", "np", ".", "finfo", "(", "np", ".", "float32", ")", ".", "eps", ")", ".", "to", "(", "x", ")", "\n", "# Clamp |2-alpha| to be >= machine epsilon so that it's safe to divide by.", "\n", "beta_safe", "=", "torch", ".", "max", "(", "machine_epsilon", ",", "torch", ".", "abs", "(", "alpha", "-", "2.", ")", ")", "\n", "# Clamp |alpha| to be >= machine epsilon so that it's safe to divide by.", "\n", "alpha_safe", "=", "torch", ".", "where", "(", "alpha", ">=", "0", ",", "torch", ".", "ones_like", "(", "alpha", ")", ",", "\n", "-", "torch", ".", "ones_like", "(", "alpha", ")", ")", "*", "torch", ".", "max", "(", "\n", "machine_epsilon", ",", "torch", ".", "abs", "(", "alpha", ")", ")", "\n", "loss_otherwise", "=", "(", "beta_safe", "/", "alpha_safe", ")", "*", "(", "\n", "torch", ".", "pow", "(", "squared_scaled_x", "/", "beta_safe", "+", "1.", ",", "0.5", "*", "alpha", ")", "-", "1.", ")", "\n", "\n", "# Select which of the cases of the loss to return.", "\n", "loss", "=", "torch", ".", "where", "(", "\n", "alpha", "==", "-", "float", "(", "'inf'", ")", ",", "loss_neginf", ",", "\n", "torch", ".", "where", "(", "\n", "alpha", "==", "0", ",", "loss_zero", ",", "\n", "torch", ".", "where", "(", "\n", "alpha", "==", "2", ",", "loss_two", ",", "\n", "torch", ".", "where", "(", "alpha", "==", "float", "(", "'inf'", ")", ",", "loss_posinf", ",", "\n", "loss_otherwise", ")", ")", ")", ")", "\n", "\n", "", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.PNetLin.__init__": [[28, 63], ["torch.Module.__init__", "networks_basic.ScalingLayer", "len", "net_type", "networks_basic.NetLinLayer", "networks_basic.NetLinLayer", "networks_basic.NetLinLayer", "networks_basic.NetLinLayer", "networks_basic.NetLinLayer", "networks_basic.NetLinLayer", "networks_basic.NetLinLayer"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "pnet_type", "=", "'vgg'", ",", "pnet_rand", "=", "False", ",", "pnet_tune", "=", "False", ",", "use_dropout", "=", "True", ",", "spatial", "=", "False", ",", "version", "=", "'0.1'", ",", "lpips", "=", "True", ")", ":", "\n", "        ", "super", "(", "PNetLin", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pnet_type", "=", "pnet_type", "\n", "self", ".", "pnet_tune", "=", "pnet_tune", "\n", "self", ".", "pnet_rand", "=", "pnet_rand", "\n", "self", ".", "spatial", "=", "spatial", "\n", "self", ".", "lpips", "=", "lpips", "\n", "self", ".", "version", "=", "version", "\n", "self", ".", "scaling_layer", "=", "ScalingLayer", "(", ")", "\n", "\n", "if", "(", "self", ".", "pnet_type", "in", "[", "'vgg'", ",", "'vgg16'", "]", ")", ":", "\n", "            ", "net_type", "=", "pn", ".", "vgg16", "\n", "self", ".", "chns", "=", "[", "64", ",", "128", ",", "256", ",", "512", ",", "512", "]", "\n", "", "elif", "(", "self", ".", "pnet_type", "==", "'alex'", ")", ":", "\n", "            ", "net_type", "=", "pn", ".", "alexnet", "\n", "self", ".", "chns", "=", "[", "64", ",", "192", ",", "384", ",", "256", ",", "256", "]", "\n", "", "elif", "(", "self", ".", "pnet_type", "==", "'squeeze'", ")", ":", "\n", "            ", "net_type", "=", "pn", ".", "squeezenet", "\n", "self", ".", "chns", "=", "[", "64", ",", "128", ",", "256", ",", "384", ",", "384", ",", "512", ",", "512", "]", "\n", "", "self", ".", "L", "=", "len", "(", "self", ".", "chns", ")", "\n", "\n", "self", ".", "net", "=", "net_type", "(", "pretrained", "=", "not", "self", ".", "pnet_rand", ",", "requires_grad", "=", "self", ".", "pnet_tune", ")", "\n", "\n", "if", "(", "lpips", ")", ":", "\n", "            ", "self", ".", "lin0", "=", "NetLinLayer", "(", "self", ".", "chns", "[", "0", "]", ",", "use_dropout", "=", "use_dropout", ")", "\n", "self", ".", "lin1", "=", "NetLinLayer", "(", "self", ".", "chns", "[", "1", "]", ",", "use_dropout", "=", "use_dropout", ")", "\n", "self", ".", "lin2", "=", "NetLinLayer", "(", "self", ".", "chns", "[", "2", "]", ",", "use_dropout", "=", "use_dropout", ")", "\n", "self", ".", "lin3", "=", "NetLinLayer", "(", "self", ".", "chns", "[", "3", "]", ",", "use_dropout", "=", "use_dropout", ")", "\n", "self", ".", "lin4", "=", "NetLinLayer", "(", "self", ".", "chns", "[", "4", "]", ",", "use_dropout", "=", "use_dropout", ")", "\n", "self", ".", "lins", "=", "[", "self", ".", "lin0", ",", "self", ".", "lin1", ",", "self", ".", "lin2", ",", "self", ".", "lin3", ",", "self", ".", "lin4", "]", "\n", "if", "(", "self", ".", "pnet_type", "==", "'squeeze'", ")", ":", "# 7 layers for squeezenet", "\n", "                ", "self", ".", "lin5", "=", "NetLinLayer", "(", "self", ".", "chns", "[", "5", "]", ",", "use_dropout", "=", "use_dropout", ")", "\n", "self", ".", "lin6", "=", "NetLinLayer", "(", "self", ".", "chns", "[", "6", "]", ",", "use_dropout", "=", "use_dropout", ")", "\n", "self", ".", "lins", "+=", "[", "self", ".", "lin5", ",", "self", ".", "lin6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.PNetLin.forward": [[64, 93], ["range", "range", "networks_basic.PNetLin.net.forward", "networks_basic.PNetLin.net.forward", "networks_basic.PNetLin.scaling_layer", "networks_basic.PNetLin.scaling_layer", "util.normalize_tensor", "util.normalize_tensor", "networks_basic.upsample", "networks_basic.spatial_average", "networks_basic.upsample", "networks_basic.spatial_average", "networks_basic.PNetLin.lins[].model", "range", "networks_basic.PNetLin.lins[].model", "range", "diffs[].sum", "range", "diffs[].sum", "range"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.normalize_tensor", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.normalize_tensor", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.upsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.spatial_average", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.upsample", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.spatial_average"], ["", "", "", "def", "forward", "(", "self", ",", "in0", ",", "in1", ",", "retPerLayer", "=", "False", ")", ":", "\n", "# v0.0 - original release had a bug, where input was not scaled", "\n", "        ", "in0_input", ",", "in1_input", "=", "(", "self", ".", "scaling_layer", "(", "in0", ")", ",", "self", ".", "scaling_layer", "(", "in1", ")", ")", "if", "self", ".", "version", "==", "'0.1'", "else", "(", "in0", ",", "in1", ")", "\n", "outs0", ",", "outs1", "=", "self", ".", "net", ".", "forward", "(", "in0_input", ")", ",", "self", ".", "net", ".", "forward", "(", "in1_input", ")", "\n", "feats0", ",", "feats1", ",", "diffs", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "\n", "for", "kk", "in", "range", "(", "self", ".", "L", ")", ":", "\n", "            ", "feats0", "[", "kk", "]", ",", "feats1", "[", "kk", "]", "=", "util", ".", "normalize_tensor", "(", "outs0", "[", "kk", "]", ")", ",", "util", ".", "normalize_tensor", "(", "outs1", "[", "kk", "]", ")", "\n", "diffs", "[", "kk", "]", "=", "(", "feats0", "[", "kk", "]", "-", "feats1", "[", "kk", "]", ")", "**", "2", "\n", "\n", "", "if", "(", "self", ".", "lpips", ")", ":", "\n", "            ", "if", "(", "self", ".", "spatial", ")", ":", "\n", "                ", "res", "=", "[", "upsample", "(", "self", ".", "lins", "[", "kk", "]", ".", "model", "(", "diffs", "[", "kk", "]", ")", ",", "out_H", "=", "in0", ".", "shape", "[", "2", "]", ")", "for", "kk", "in", "range", "(", "self", ".", "L", ")", "]", "\n", "", "else", ":", "\n", "                ", "res", "=", "[", "spatial_average", "(", "self", ".", "lins", "[", "kk", "]", ".", "model", "(", "diffs", "[", "kk", "]", ")", ",", "keepdim", "=", "True", ")", "for", "kk", "in", "range", "(", "self", ".", "L", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "self", ".", "spatial", ")", ":", "\n", "                ", "res", "=", "[", "upsample", "(", "diffs", "[", "kk", "]", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ",", "out_H", "=", "in0", ".", "shape", "[", "2", "]", ")", "for", "kk", "in", "range", "(", "self", ".", "L", ")", "]", "\n", "", "else", ":", "\n", "                ", "res", "=", "[", "spatial_average", "(", "diffs", "[", "kk", "]", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ",", "keepdim", "=", "True", ")", "for", "kk", "in", "range", "(", "self", ".", "L", ")", "]", "\n", "\n", "", "", "val", "=", "res", "[", "0", "]", "\n", "for", "l", "in", "range", "(", "1", ",", "self", ".", "L", ")", ":", "\n", "            ", "val", "+=", "res", "[", "l", "]", "\n", "\n", "", "if", "(", "retPerLayer", ")", ":", "\n", "            ", "return", "(", "val", ",", "res", ")", "\n", "", "else", ":", "\n", "            ", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.ScalingLayer.__init__": [[95, 99], ["torch.Module.__init__", "networks_basic.ScalingLayer.register_buffer", "networks_basic.ScalingLayer.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ScalingLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'shift'", ",", "torch", ".", "Tensor", "(", "[", "-", ".030", ",", "-", ".088", ",", "-", ".188", "]", ")", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "\n", "self", ".", "register_buffer", "(", "'scale'", ",", "torch", ".", "Tensor", "(", "[", ".458", ",", ".448", ",", ".450", "]", ")", "[", "None", ",", ":", ",", "None", ",", "None", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.ScalingLayer.forward": [[100, 102], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "(", "inp", "-", "self", ".", "shift", ")", "/", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.NetLinLayer.__init__": [[106, 112], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["def", "__init__", "(", "self", ",", "chn_in", ",", "chn_out", "=", "1", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "super", "(", "NetLinLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "[", "nn", ".", "Dropout", "(", ")", ",", "]", "if", "(", "use_dropout", ")", "else", "[", "]", "\n", "layers", "+=", "[", "nn", ".", "Conv2d", "(", "chn_in", ",", "chn_out", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.Dist2LogitLayer.__init__": [[116, 127], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["def", "__init__", "(", "self", ",", "chn_mid", "=", "32", ",", "use_sigmoid", "=", "True", ")", ":", "\n", "        ", "super", "(", "Dist2LogitLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "[", "nn", ".", "Conv2d", "(", "5", ",", "chn_mid", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "]", "\n", "layers", "+=", "[", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "]", "\n", "layers", "+=", "[", "nn", ".", "Conv2d", "(", "chn_mid", ",", "chn_mid", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "]", "\n", "layers", "+=", "[", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "]", "\n", "layers", "+=", "[", "nn", ".", "Conv2d", "(", "chn_mid", ",", "1", ",", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "]", "\n", "if", "(", "use_sigmoid", ")", ":", "\n", "            ", "layers", "+=", "[", "nn", ".", "Sigmoid", "(", ")", ",", "]", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.Dist2LogitLayer.forward": [[128, 130], ["networks_basic.Dist2LogitLayer.model.forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward"], ["", "def", "forward", "(", "self", ",", "d0", ",", "d1", ",", "eps", "=", "0.1", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "forward", "(", "torch", ".", "cat", "(", "(", "d0", ",", "d1", ",", "d0", "-", "d1", ",", "d0", "/", "(", "d1", "+", "eps", ")", ",", "d1", "/", "(", "d0", "+", "eps", ")", ")", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.BCERankingLoss.__init__": [[132, 137], ["torch.Module.__init__", "networks_basic.Dist2LogitLayer", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "chn_mid", "=", "32", ")", ":", "\n", "        ", "super", "(", "BCERankingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "Dist2LogitLayer", "(", "chn_mid", "=", "chn_mid", ")", "\n", "# self.parameters = list(self.net.parameters())", "\n", "self", ".", "loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.BCERankingLoss.forward": [[138, 142], ["networks_basic.BCERankingLoss.net.forward", "networks_basic.BCERankingLoss.loss"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward"], ["", "def", "forward", "(", "self", ",", "d0", ",", "d1", ",", "judge", ")", ":", "\n", "        ", "per", "=", "(", "judge", "+", "1.", ")", "/", "2.", "\n", "self", ".", "logit", "=", "self", ".", "net", ".", "forward", "(", "d0", ",", "d1", ")", "\n", "return", "self", ".", "loss", "(", "self", ".", "logit", ",", "per", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.FakeNet.__init__": [[145, 149], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "use_gpu", "=", "True", ",", "colorspace", "=", "'Lab'", ")", ":", "\n", "        ", "super", "(", "FakeNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "colorspace", "=", "colorspace", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.L2.forward": [[152, 166], ["in0.size", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "in0.size", "util.l2().astype", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ret_var.cuda.cuda.cuda", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "util.l2", "util.tensor2np", "util.tensor2np", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "util.tensor2tensorlab", "util.tensor2tensorlab", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.l2", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2np", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2np", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2tensorlab", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2tensorlab"], ["    ", "def", "forward", "(", "self", ",", "in0", ",", "in1", ",", "retPerLayer", "=", "None", ")", ":", "\n", "        ", "assert", "(", "in0", ".", "size", "(", ")", "[", "0", "]", "==", "1", ")", "# currently only supports batchSize 1", "\n", "\n", "if", "(", "self", ".", "colorspace", "==", "'RGB'", ")", ":", "\n", "            ", "(", "N", ",", "C", ",", "X", ",", "Y", ")", "=", "in0", ".", "size", "(", ")", "\n", "value", "=", "torch", ".", "mean", "(", "torch", ".", "mean", "(", "torch", ".", "mean", "(", "(", "in0", "-", "in1", ")", "**", "2", ",", "dim", "=", "1", ")", ".", "view", "(", "N", ",", "1", ",", "X", ",", "Y", ")", ",", "dim", "=", "2", ")", ".", "view", "(", "N", ",", "1", ",", "1", ",", "Y", ")", ",", "dim", "=", "3", ")", ".", "view", "(", "N", ")", "\n", "return", "value", "\n", "", "elif", "(", "self", ".", "colorspace", "==", "'Lab'", ")", ":", "\n", "            ", "value", "=", "util", ".", "l2", "(", "util", ".", "tensor2np", "(", "util", ".", "tensor2tensorlab", "(", "in0", ".", "data", ",", "to_norm", "=", "False", ")", ")", ",", "\n", "util", ".", "tensor2np", "(", "util", ".", "tensor2tensorlab", "(", "in1", ".", "data", ",", "to_norm", "=", "False", ")", ")", ",", "range", "=", "100.", ")", ".", "astype", "(", "'float'", ")", "\n", "ret_var", "=", "Variable", "(", "torch", ".", "Tensor", "(", "(", "value", ",", ")", ")", ")", "\n", "if", "(", "self", ".", "use_gpu", ")", ":", "\n", "                ", "ret_var", "=", "ret_var", ".", "cuda", "(", ")", "\n", "", "return", "ret_var", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.DSSIM.forward": [[169, 181], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "util.dssim().astype", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ret_var.cuda.cuda.cuda", "in0.size", "util.dssim().astype", "util.dssim", "util.dssim", "util.tensor2im", "util.tensor2im", "util.tensor2np", "util.tensor2np", "util.tensor2tensorlab", "util.tensor2tensorlab"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.dssim", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.dssim", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2im", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2im", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2np", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2np", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2tensorlab", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2tensorlab"], ["    ", "def", "forward", "(", "self", ",", "in0", ",", "in1", ",", "retPerLayer", "=", "None", ")", ":", "\n", "        ", "assert", "(", "in0", ".", "size", "(", ")", "[", "0", "]", "==", "1", ")", "# currently only supports batchSize 1", "\n", "\n", "if", "(", "self", ".", "colorspace", "==", "'RGB'", ")", ":", "\n", "            ", "value", "=", "util", ".", "dssim", "(", "1.", "*", "util", ".", "tensor2im", "(", "in0", ".", "data", ")", ",", "1.", "*", "util", ".", "tensor2im", "(", "in1", ".", "data", ")", ",", "range", "=", "255.", ")", ".", "astype", "(", "'float'", ")", "\n", "", "elif", "(", "self", ".", "colorspace", "==", "'Lab'", ")", ":", "\n", "            ", "value", "=", "util", ".", "dssim", "(", "util", ".", "tensor2np", "(", "util", ".", "tensor2tensorlab", "(", "in0", ".", "data", ",", "to_norm", "=", "False", ")", ")", ",", "\n", "util", ".", "tensor2np", "(", "util", ".", "tensor2tensorlab", "(", "in1", ".", "data", ",", "to_norm", "=", "False", ")", ")", ",", "range", "=", "100.", ")", ".", "astype", "(", "'float'", ")", "\n", "", "ret_var", "=", "Variable", "(", "torch", ".", "Tensor", "(", "(", "value", ",", ")", ")", ")", "\n", "if", "(", "self", ".", "use_gpu", ")", ":", "\n", "            ", "ret_var", "=", "ret_var", ".", "cuda", "(", ")", "\n", "", "return", "ret_var", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.spatial_average": [[16, 18], ["in_tens.mean"], "function", ["None"], ["def", "spatial_average", "(", "in_tens", ",", "keepdim", "=", "True", ")", ":", "\n", "    ", "return", "in_tens", ".", "mean", "(", "[", "2", ",", "3", "]", ",", "keepdim", "=", "keepdim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.upsample": [[20, 25], ["torch.Upsample"], "function", ["None"], ["", "def", "upsample", "(", "in_tens", ",", "out_H", "=", "64", ")", ":", "# assumes scale factor is same for H and W", "\n", "    ", "in_H", "=", "in_tens", ".", "shape", "[", "2", "]", "\n", "scale_factor", "=", "1.", "*", "out_H", "/", "in_H", "\n", "\n", "return", "nn", ".", "Upsample", "(", "scale_factor", "=", "scale_factor", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "(", "in_tens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.print_network": [[182, 188], ["net.parameters", "print", "print", "param.numel"], "function", ["None"], ["", "", "def", "print_network", "(", "net", ")", ":", "\n", "    ", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "print", "(", "'Network'", ",", "net", ")", "\n", "print", "(", "'Total number of parameters: %d'", "%", "num_params", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.name": [[25, 27], ["None"], "methods", ["None"], ["    ", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.initialize": [[28, 108], ["base_model.BaseModel.initialize", "list", "networks_basic.PNetLin", "dist_model.DistModel.net.parameters", "networks_basic.BCERankingLoss", "list", "torch.optim.Adam", "dist_model.DistModel.net.eval", "dist_model.DistModel.net.to", "torch.nn.DataParallel", "print", "networks_basic.print_network", "print", "os.path.abspath", "print", "dist_model.DistModel.net.load_state_dict", "networks_basic.PNetLin", "dist_model.DistModel.rankLoss.net.parameters", "dist_model.DistModel.rankLoss.to", "os.path.join", "torch.load", "networks_basic.L2", "inspect.getfile", "networks_basic.DSSIM", "ValueError"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.initialize", "home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.networks_basic.print_network"], ["", "def", "initialize", "(", "self", ",", "model", "=", "'net-lin'", ",", "net", "=", "'alex'", ",", "colorspace", "=", "'Lab'", ",", "pnet_rand", "=", "False", ",", "pnet_tune", "=", "False", ",", "model_path", "=", "None", ",", "\n", "use_gpu", "=", "True", ",", "printNet", "=", "False", ",", "spatial", "=", "False", ",", "\n", "is_train", "=", "False", ",", "lr", "=", ".0001", ",", "beta1", "=", "0.5", ",", "version", "=", "'0.1'", ",", "gpu_ids", "=", "[", "0", "]", ")", ":", "\n", "        ", "'''\n        INPUTS\n            model - ['net-lin'] for linearly calibrated network\n                    ['net'] for off-the-shelf network\n                    ['L2'] for L2 distance in Lab colorspace\n                    ['SSIM'] for ssim in RGB colorspace\n            net - ['squeeze','alex','vgg']\n            model_path - if None, will look in weights/[NET_NAME].pth\n            colorspace - ['Lab','RGB'] colorspace to use for L2 and SSIM\n            use_gpu - bool - whether or not to use a GPU\n            printNet - bool - whether or not to print network architecture out\n            spatial - bool - whether to output an array containing varying distances across spatial dimensions\n            spatial_shape - if given, output spatial shape. if None then spatial shape is determined automatically via spatial_factor (see below).\n            spatial_factor - if given, specifies upsampling factor relative to the largest spatial extent of a convolutional layer. if None then resized to size of input images.\n            spatial_order - spline order of filter for upsampling in spatial mode, by default 1 (bilinear).\n            is_train - bool - [True] for training mode\n            lr - float - initial learning rate\n            beta1 - float - initial momentum term for adam\n            version - 0.1 for latest, 0.0 was original (with a bug)\n            gpu_ids - int array - [0] by default, gpus to use\n        '''", "\n", "BaseModel", ".", "initialize", "(", "self", ",", "use_gpu", "=", "use_gpu", ",", "gpu_ids", "=", "gpu_ids", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "spatial", "=", "spatial", "\n", "self", ".", "gpu_ids", "=", "gpu_ids", "\n", "self", ".", "model_name", "=", "'%s [%s]'", "%", "(", "model", ",", "net", ")", "\n", "\n", "if", "(", "self", ".", "model", "==", "'net-lin'", ")", ":", "# pretrained net + linear layer", "\n", "            ", "self", ".", "net", "=", "networks", ".", "PNetLin", "(", "pnet_rand", "=", "pnet_rand", ",", "pnet_tune", "=", "pnet_tune", ",", "pnet_type", "=", "net", ",", "\n", "use_dropout", "=", "True", ",", "spatial", "=", "spatial", ",", "version", "=", "version", ",", "lpips", "=", "True", ")", "\n", "kw", "=", "{", "}", "\n", "if", "not", "use_gpu", ":", "\n", "                ", "kw", "[", "'map_location'", "]", "=", "'cpu'", "\n", "", "if", "(", "model_path", "is", "None", ")", ":", "\n", "                ", "import", "inspect", "\n", "model_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "inspect", ".", "getfile", "(", "self", ".", "initialize", ")", ",", "'..'", ",", "'weights/v%s/%s.pth'", "%", "(", "version", ",", "net", ")", ")", ")", "\n", "\n", "", "if", "(", "not", "is_train", ")", ":", "\n", "                ", "print", "(", "'Loading model from: %s'", "%", "model_path", ")", "\n", "self", ".", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ",", "**", "kw", ")", ",", "strict", "=", "False", ")", "\n", "\n", "", "", "elif", "(", "self", ".", "model", "==", "'net'", ")", ":", "# pretrained network", "\n", "            ", "self", ".", "net", "=", "networks", ".", "PNetLin", "(", "pnet_rand", "=", "pnet_rand", ",", "pnet_type", "=", "net", ",", "lpips", "=", "False", ")", "\n", "", "elif", "(", "self", ".", "model", "in", "[", "'L2'", ",", "'l2'", "]", ")", ":", "\n", "            ", "self", ".", "net", "=", "networks", ".", "L2", "(", "use_gpu", "=", "use_gpu", ",", "colorspace", "=", "colorspace", ")", "# not really a network, only for testing", "\n", "self", ".", "model_name", "=", "'L2'", "\n", "", "elif", "(", "self", ".", "model", "in", "[", "'DSSIM'", ",", "'dssim'", ",", "'SSIM'", ",", "'ssim'", "]", ")", ":", "\n", "            ", "self", ".", "net", "=", "networks", ".", "DSSIM", "(", "use_gpu", "=", "use_gpu", ",", "colorspace", "=", "colorspace", ")", "\n", "self", ".", "model_name", "=", "'SSIM'", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Model [%s] not recognized.\"", "%", "self", ".", "model", ")", "\n", "\n", "", "self", ".", "parameters", "=", "list", "(", "self", ".", "net", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "self", ".", "is_train", ":", "# training mode", "\n", "# extra network on top to go from distances (d0,d1) => predicted human judgment (h*)", "\n", "            ", "self", ".", "rankLoss", "=", "networks", ".", "BCERankingLoss", "(", ")", "\n", "self", ".", "parameters", "+=", "list", "(", "self", ".", "rankLoss", ".", "net", ".", "parameters", "(", ")", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "old_lr", "=", "lr", "\n", "self", ".", "optimizer_net", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", ",", "lr", "=", "lr", ",", "betas", "=", "(", "beta1", ",", "0.999", ")", ")", "\n", "", "else", ":", "# test mode", "\n", "            ", "self", ".", "net", ".", "eval", "(", ")", "\n", "\n", "", "if", "(", "use_gpu", ")", ":", "\n", "            ", "self", ".", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "self", ".", "net", "=", "torch", ".", "nn", ".", "DataParallel", "(", "self", ".", "net", ",", "device_ids", "=", "gpu_ids", ")", "\n", "if", "(", "self", ".", "is_train", ")", ":", "\n", "                ", "self", ".", "rankLoss", "=", "self", ".", "rankLoss", ".", "to", "(", "device", "=", "gpu_ids", "[", "0", "]", ")", "# just put this on GPU0", "\n", "\n", "", "", "if", "(", "printNet", ")", ":", "\n", "            ", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "networks", ".", "print_network", "(", "self", ".", "net", ")", "\n", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.forward": [[109, 118], ["dist_model.DistModel.net.forward"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward"], ["", "", "def", "forward", "(", "self", ",", "in0", ",", "in1", ",", "retPerLayer", "=", "False", ")", ":", "\n", "        ", "''' Function computes the distance between image patches in0 and in1\n        INPUTS\n            in0, in1 - torch.Tensor object of shape Nx3xXxY - image patch scaled to [-1,1]\n        OUTPUT\n            computed distances between in0 and in1\n        '''", "\n", "\n", "return", "self", ".", "net", ".", "forward", "(", "in0", ",", "in1", ",", "retPerLayer", "=", "retPerLayer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.optimize_parameters": [[120, 126], ["dist_model.DistModel.forward_train", "dist_model.DistModel.optimizer_net.zero_grad", "dist_model.DistModel.backward_train", "dist_model.DistModel.optimizer_net.step", "dist_model.DistModel.clamp_weights"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.forward_train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.backward_train", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.clamp_weights"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "forward_train", "(", ")", "\n", "self", ".", "optimizer_net", ".", "zero_grad", "(", ")", "\n", "self", ".", "backward_train", "(", ")", "\n", "self", ".", "optimizer_net", ".", "step", "(", ")", "\n", "self", ".", "clamp_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.clamp_weights": [[127, 131], ["dist_model.DistModel.net.modules", "hasattr", "torch.clamp"], "methods", ["None"], ["", "def", "clamp_weights", "(", "self", ")", ":", "\n", "        ", "for", "module", "in", "self", ".", "net", ".", "modules", "(", ")", ":", "\n", "            ", "if", "(", "hasattr", "(", "module", ",", "'weight'", ")", "and", "module", ".", "kernel_size", "==", "(", "1", ",", "1", ")", ")", ":", "\n", "                ", "module", ".", "weight", ".", "data", "=", "torch", ".", "clamp", "(", "module", ".", "weight", ".", "data", ",", "min", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.set_input": [[132, 147], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "dist_model.DistModel.input_ref.to", "dist_model.DistModel.input_p0.to", "dist_model.DistModel.input_p1.to", "dist_model.DistModel.input_judge.to"], "methods", ["None"], ["", "", "", "def", "set_input", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "input_ref", "=", "data", "[", "'ref'", "]", "\n", "self", ".", "input_p0", "=", "data", "[", "'p0'", "]", "\n", "self", ".", "input_p1", "=", "data", "[", "'p1'", "]", "\n", "self", ".", "input_judge", "=", "data", "[", "'judge'", "]", "\n", "\n", "if", "(", "self", ".", "use_gpu", ")", ":", "\n", "            ", "self", ".", "input_ref", "=", "self", ".", "input_ref", ".", "to", "(", "device", "=", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "self", ".", "input_p0", "=", "self", ".", "input_p0", ".", "to", "(", "device", "=", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "self", ".", "input_p1", "=", "self", ".", "input_p1", ".", "to", "(", "device", "=", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "self", ".", "input_judge", "=", "self", ".", "input_judge", ".", "to", "(", "device", "=", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "var_ref", "=", "Variable", "(", "self", ".", "input_ref", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "var_p0", "=", "Variable", "(", "self", ".", "input_p0", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "var_p1", "=", "Variable", "(", "self", ".", "input_p1", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.forward_train": [[148, 161], ["dist_model.DistModel.forward", "dist_model.DistModel.forward", "dist_model.DistModel.compute_accuracy", "torch.autograd.Variable().view", "dist_model.DistModel.rankLoss.forward", "dist_model.DistModel.d0.size", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.compute_accuracy", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward"], ["", "def", "forward_train", "(", "self", ")", ":", "# run forward pass", "\n", "# print(self.net.module.scaling_layer.shift)", "\n", "# print(torch.norm(self.net.module.net.slice1[0].weight).item(), torch.norm(self.net.module.lin0.model[1].weight).item())", "\n", "\n", "        ", "self", ".", "d0", "=", "self", ".", "forward", "(", "self", ".", "var_ref", ",", "self", ".", "var_p0", ")", "\n", "self", ".", "d1", "=", "self", ".", "forward", "(", "self", ".", "var_ref", ",", "self", ".", "var_p1", ")", "\n", "self", ".", "acc_r", "=", "self", ".", "compute_accuracy", "(", "self", ".", "d0", ",", "self", ".", "d1", ",", "self", ".", "input_judge", ")", "\n", "\n", "self", ".", "var_judge", "=", "Variable", "(", "1.", "*", "self", ".", "input_judge", ")", ".", "view", "(", "self", ".", "d0", ".", "size", "(", ")", ")", "\n", "\n", "self", ".", "loss_total", "=", "self", ".", "rankLoss", ".", "forward", "(", "self", ".", "d0", ",", "self", ".", "d1", ",", "self", ".", "var_judge", "*", "2.", "-", "1.", ")", "\n", "\n", "return", "self", ".", "loss_total", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.backward_train": [[162, 164], ["torch.mean().backward", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.BlurLayer.backward"], ["", "def", "backward_train", "(", "self", ")", ":", "\n", "        ", "torch", ".", "mean", "(", "self", ".", "loss_total", ")", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.compute_accuracy": [[165, 170], ["judge.cpu().numpy().flatten", "judge.cpu().numpy", "judge.cpu"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten"], ["", "def", "compute_accuracy", "(", "self", ",", "d0", ",", "d1", ",", "judge", ")", ":", "\n", "        ", "''' d0, d1 are Variables, judge is a Tensor '''", "\n", "d1_lt_d0", "=", "(", "d1", "<", "d0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "judge_per", "=", "judge", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "return", "d1_lt_d0", "*", "judge_per", "+", "(", "1", "-", "d1_lt_d0", ")", "*", "(", "1", "-", "judge_per", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.get_current_errors": [[171, 179], ["collections.OrderedDict", "collections.OrderedDict.keys", "numpy.mean", "dist_model.DistModel.loss_total.data.cpu().numpy", "dist_model.DistModel.loss_total.data.cpu"], "methods", ["None"], ["", "def", "get_current_errors", "(", "self", ")", ":", "\n", "        ", "retDict", "=", "OrderedDict", "(", "[", "(", "'loss_total'", ",", "self", ".", "loss_total", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "(", "'acc_r'", ",", "self", ".", "acc_r", ")", "]", ")", "\n", "\n", "for", "key", "in", "retDict", ".", "keys", "(", ")", ":", "\n", "            ", "retDict", "[", "key", "]", "=", "np", ".", "mean", "(", "retDict", "[", "key", "]", ")", "\n", "\n", "", "return", "retDict", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.get_current_visuals": [[180, 194], ["util.tensor2im", "util.tensor2im", "util.tensor2im", "scipy.ndimage.zoom", "scipy.ndimage.zoom", "scipy.ndimage.zoom", "collections.OrderedDict", "dist_model.DistModel.var_ref.data.size"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2im", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2im", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2im"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "zoom_factor", "=", "256", "/", "self", ".", "var_ref", ".", "data", ".", "size", "(", ")", "[", "2", "]", "\n", "\n", "ref_img", "=", "util", ".", "tensor2im", "(", "self", ".", "var_ref", ".", "data", ")", "\n", "p0_img", "=", "util", ".", "tensor2im", "(", "self", ".", "var_p0", ".", "data", ")", "\n", "p1_img", "=", "util", ".", "tensor2im", "(", "self", ".", "var_p1", ".", "data", ")", "\n", "\n", "ref_img_vis", "=", "zoom", "(", "ref_img", ",", "[", "zoom_factor", ",", "zoom_factor", ",", "1", "]", ",", "order", "=", "0", ")", "\n", "p0_img_vis", "=", "zoom", "(", "p0_img", ",", "[", "zoom_factor", ",", "zoom_factor", ",", "1", "]", ",", "order", "=", "0", ")", "\n", "p1_img_vis", "=", "zoom", "(", "p1_img", ",", "[", "zoom_factor", ",", "zoom_factor", ",", "1", "]", ",", "order", "=", "0", ")", "\n", "\n", "return", "OrderedDict", "(", "[", "(", "'ref'", ",", "ref_img_vis", ")", ",", "\n", "(", "'p0'", ",", "p0_img_vis", ")", ",", "\n", "(", "'p1'", ",", "p1_img_vis", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.save": [[195, 201], ["dist_model.DistModel.save_network", "dist_model.DistModel.save_network", "dist_model.DistModel.save_network"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save_network", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save_network", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save_network"], ["", "def", "save", "(", "self", ",", "path", ",", "label", ")", ":", "\n", "        ", "if", "(", "self", ".", "use_gpu", ")", ":", "\n", "            ", "self", ".", "save_network", "(", "self", ".", "net", ".", "module", ",", "path", ",", "''", ",", "label", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "save_network", "(", "self", ".", "net", ",", "path", ",", "''", ",", "label", ")", "\n", "", "self", ".", "save_network", "(", "self", ".", "rankLoss", ".", "net", ",", "path", ",", "'rank'", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.DistModel.update_learning_rate": [[202, 211], ["print"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ",", "nepoch_decay", ")", ":", "\n", "        ", "lrd", "=", "self", ".", "lr", "/", "nepoch_decay", "\n", "lr", "=", "self", ".", "old_lr", "-", "lrd", "\n", "\n", "for", "param_group", "in", "self", ".", "optimizer_net", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "", "print", "(", "'update lr [%s] decay: %f -> %f'", "%", "(", "type", ",", "self", ".", "old_lr", ",", "lr", ")", ")", "\n", "self", ".", "old_lr", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.score_2afc_dataset": [[212, 246], ["tqdm.tqdm", "numpy.array", "numpy.array", "numpy.array", "data_loader.load_data", "func().data.cpu().numpy().flatten().tolist", "func().data.cpu().numpy().flatten().tolist", "data[].cpu().numpy().flatten().tolist", "numpy.mean", "dict", "func().data.cpu().numpy().flatten", "func().data.cpu().numpy().flatten", "data[].cpu().numpy().flatten", "func().data.cpu().numpy", "func().data.cpu().numpy", "data[].cpu().numpy", "func().data.cpu", "func().data.cpu", "data[].cpu", "func", "func"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten"], ["", "", "def", "score_2afc_dataset", "(", "data_loader", ",", "func", ",", "name", "=", "''", ")", ":", "\n", "    ", "''' Function computes Two Alternative Forced Choice (2AFC) score using\n        distance function 'func' in dataset 'data_loader'\n    INPUTS\n        data_loader - CustomDatasetDataLoader object - contains a TwoAFCDataset inside\n        func - callable distance function - calling d=func(in0,in1) should take 2\n            pytorch tensors with shape Nx3xXxY, and return numpy array of length N\n    OUTPUTS\n        [0] - 2AFC score in [0,1], fraction of time func agrees with human evaluators\n        [1] - dictionary with following elements\n            d0s,d1s - N arrays containing distances between reference patch to perturbed patches \n            gts - N array in [0,1], preferred patch selected by human evaluators\n                (closer to \"0\" for left patch p0, \"1\" for right patch p1,\n                \"0.6\" means 60pct people preferred right patch, 40pct preferred left)\n            scores - N array in [0,1], corresponding to what percentage function agreed with humans\n    CONSTS\n        N - number of test triplets in data_loader\n    '''", "\n", "\n", "d0s", "=", "[", "]", "\n", "d1s", "=", "[", "]", "\n", "gts", "=", "[", "]", "\n", "\n", "for", "data", "in", "tqdm", "(", "data_loader", ".", "load_data", "(", ")", ",", "desc", "=", "name", ")", ":", "\n", "        ", "d0s", "+=", "func", "(", "data", "[", "'ref'", "]", ",", "data", "[", "'p0'", "]", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "d1s", "+=", "func", "(", "data", "[", "'ref'", "]", ",", "data", "[", "'p1'", "]", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "gts", "+=", "data", "[", "'judge'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "", "d0s", "=", "np", ".", "array", "(", "d0s", ")", "\n", "d1s", "=", "np", ".", "array", "(", "d1s", ")", "\n", "gts", "=", "np", ".", "array", "(", "gts", ")", "\n", "scores", "=", "(", "d0s", "<", "d1s", ")", "*", "(", "1.", "-", "gts", ")", "+", "(", "d1s", "<", "d0s", ")", "*", "gts", "+", "(", "d1s", "==", "d0s", ")", "*", ".5", "\n", "\n", "return", "(", "np", ".", "mean", "(", "scores", ")", ",", "dict", "(", "d0s", "=", "d0s", ",", "d1s", "=", "d1s", ",", "gts", "=", "gts", ",", "scores", "=", "scores", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.dist_model.score_jnd_dataset": [[247, 285], ["tqdm.tqdm", "numpy.array", "numpy.array", "numpy.argsort", "numpy.cumsum", "numpy.cumsum", "util.voc_ap", "data_loader.load_data", "func().data.cpu().numpy().tolist", "data[].cpu().numpy().flatten().tolist", "numpy.sum", "dict", "func().data.cpu().numpy", "data[].cpu().numpy().flatten", "func().data.cpu", "data[].cpu().numpy", "data[].cpu", "func"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.voc_ap", "home.repos.pwc.inspect_result.AaltoVision_automodulator.robust_loss_pytorch.wavelet.flatten"], ["", "def", "score_jnd_dataset", "(", "data_loader", ",", "func", ",", "name", "=", "''", ")", ":", "\n", "    ", "''' Function computes JND score using distance function 'func' in dataset 'data_loader'\n    INPUTS\n        data_loader - CustomDatasetDataLoader object - contains a JNDDataset inside\n        func - callable distance function - calling d=func(in0,in1) should take 2\n            pytorch tensors with shape Nx3xXxY, and return pytorch array of length N\n    OUTPUTS\n        [0] - JND score in [0,1], mAP score (area under precision-recall curve)\n        [1] - dictionary with following elements\n            ds - N array containing distances between two patches shown to human evaluator\n            sames - N array containing fraction of people who thought the two patches were identical\n    CONSTS\n        N - number of test triplets in data_loader\n    '''", "\n", "\n", "ds", "=", "[", "]", "\n", "gts", "=", "[", "]", "\n", "\n", "for", "data", "in", "tqdm", "(", "data_loader", ".", "load_data", "(", ")", ",", "desc", "=", "name", ")", ":", "\n", "        ", "ds", "+=", "func", "(", "data", "[", "'p0'", "]", ",", "data", "[", "'p1'", "]", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "gts", "+=", "data", "[", "'same'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "", "sames", "=", "np", ".", "array", "(", "gts", ")", "\n", "ds", "=", "np", ".", "array", "(", "ds", ")", "\n", "\n", "sorted_inds", "=", "np", ".", "argsort", "(", "ds", ")", "\n", "ds_sorted", "=", "ds", "[", "sorted_inds", "]", "\n", "sames_sorted", "=", "sames", "[", "sorted_inds", "]", "\n", "\n", "TPs", "=", "np", ".", "cumsum", "(", "sames_sorted", ")", "\n", "FPs", "=", "np", ".", "cumsum", "(", "1", "-", "sames_sorted", ")", "\n", "FNs", "=", "np", ".", "sum", "(", "sames_sorted", ")", "-", "TPs", "\n", "\n", "precs", "=", "TPs", "/", "(", "TPs", "+", "FPs", ")", "\n", "recs", "=", "TPs", "/", "(", "TPs", "+", "FNs", ")", "\n", "score", "=", "util", ".", "voc_ap", "(", "recs", ",", "precs", ")", "\n", "\n", "return", "(", "score", ",", "dict", "(", "ds", "=", "ds", ",", "sames", "=", "sames", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.squeezenet.__init__": [[7, 35], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "range", "range", "range", "range", "torchvision.models.squeezenet1_1", "pretrained_networks.squeezenet.slice1.add_module", "pretrained_networks.squeezenet.slice2.add_module", "pretrained_networks.squeezenet.slice3.add_module", "pretrained_networks.squeezenet.slice4.add_module", "pretrained_networks.squeezenet.slice5.add_module", "pretrained_networks.squeezenet.slice6.add_module", "pretrained_networks.squeezenet.slice7.add_module", "pretrained_networks.squeezenet.parameters", "str", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ",", "pretrained", "=", "True", ")", ":", "\n", "        ", "super", "(", "squeezenet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "pretrained_features", "=", "tv", ".", "squeezenet1_1", "(", "pretrained", "=", "pretrained", ")", ".", "features", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice4", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice5", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice6", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice7", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "N_slices", "=", "7", "\n", "for", "x", "in", "range", "(", "2", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "2", ",", "5", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "5", ",", "8", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "8", ",", "10", ")", ":", "\n", "            ", "self", ".", "slice4", ".", "add_module", "(", "str", "(", "x", ")", ",", "pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "10", ",", "11", ")", ":", "\n", "            ", "self", ".", "slice5", ".", "add_module", "(", "str", "(", "x", ")", ",", "pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "11", ",", "12", ")", ":", "\n", "            ", "self", ".", "slice6", ".", "add_module", "(", "str", "(", "x", ")", ",", "pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "12", ",", "13", ")", ":", "\n", "            ", "self", ".", "slice7", ".", "add_module", "(", "str", "(", "x", ")", ",", "pretrained_features", "[", "x", "]", ")", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.squeezenet.forward": [[36, 55], ["pretrained_networks.squeezenet.slice1", "pretrained_networks.squeezenet.slice2", "pretrained_networks.squeezenet.slice3", "pretrained_networks.squeezenet.slice4", "pretrained_networks.squeezenet.slice5", "pretrained_networks.squeezenet.slice6", "pretrained_networks.squeezenet.slice7", "collections.namedtuple", "collections.namedtuple."], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu1", "=", "h", "\n", "h", "=", "self", ".", "slice2", "(", "h", ")", "\n", "h_relu2", "=", "h", "\n", "h", "=", "self", ".", "slice3", "(", "h", ")", "\n", "h_relu3", "=", "h", "\n", "h", "=", "self", ".", "slice4", "(", "h", ")", "\n", "h_relu4", "=", "h", "\n", "h", "=", "self", ".", "slice5", "(", "h", ")", "\n", "h_relu5", "=", "h", "\n", "h", "=", "self", ".", "slice6", "(", "h", ")", "\n", "h_relu6", "=", "h", "\n", "h", "=", "self", ".", "slice7", "(", "h", ")", "\n", "h_relu7", "=", "h", "\n", "vgg_outputs", "=", "namedtuple", "(", "\"SqueezeOutputs\"", ",", "[", "'relu1'", ",", "'relu2'", ",", "'relu3'", ",", "'relu4'", ",", "'relu5'", ",", "'relu6'", ",", "'relu7'", "]", ")", "\n", "out", "=", "vgg_outputs", "(", "h_relu1", ",", "h_relu2", ",", "h_relu3", ",", "h_relu4", ",", "h_relu5", ",", "h_relu6", ",", "h_relu7", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.alexnet.__init__": [[58, 80], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "range", "range", "torchvision.models.alexnet", "pretrained_networks.alexnet.slice1.add_module", "pretrained_networks.alexnet.slice2.add_module", "pretrained_networks.alexnet.slice3.add_module", "pretrained_networks.alexnet.slice4.add_module", "pretrained_networks.alexnet.slice5.add_module", "pretrained_networks.alexnet.parameters", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ",", "pretrained", "=", "True", ")", ":", "\n", "        ", "super", "(", "alexnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "alexnet_pretrained_features", "=", "tv", ".", "alexnet", "(", "pretrained", "=", "pretrained", ")", ".", "features", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice4", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice5", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "N_slices", "=", "5", "\n", "for", "x", "in", "range", "(", "2", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "alexnet_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "2", ",", "5", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "alexnet_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "5", ",", "8", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "alexnet_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "8", ",", "10", ")", ":", "\n", "            ", "self", ".", "slice4", ".", "add_module", "(", "str", "(", "x", ")", ",", "alexnet_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "10", ",", "12", ")", ":", "\n", "            ", "self", ".", "slice5", ".", "add_module", "(", "str", "(", "x", ")", ",", "alexnet_pretrained_features", "[", "x", "]", ")", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.alexnet.forward": [[81, 96], ["pretrained_networks.alexnet.slice1", "pretrained_networks.alexnet.slice2", "pretrained_networks.alexnet.slice3", "pretrained_networks.alexnet.slice4", "pretrained_networks.alexnet.slice5", "collections.namedtuple", "collections.namedtuple."], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu1", "=", "h", "\n", "h", "=", "self", ".", "slice2", "(", "h", ")", "\n", "h_relu2", "=", "h", "\n", "h", "=", "self", ".", "slice3", "(", "h", ")", "\n", "h_relu3", "=", "h", "\n", "h", "=", "self", ".", "slice4", "(", "h", ")", "\n", "h_relu4", "=", "h", "\n", "h", "=", "self", ".", "slice5", "(", "h", ")", "\n", "h_relu5", "=", "h", "\n", "alexnet_outputs", "=", "namedtuple", "(", "\"AlexnetOutputs\"", ",", "[", "'relu1'", ",", "'relu2'", ",", "'relu3'", ",", "'relu4'", ",", "'relu5'", "]", ")", "\n", "out", "=", "alexnet_outputs", "(", "h_relu1", ",", "h_relu2", ",", "h_relu3", ",", "h_relu4", ",", "h_relu5", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.vgg16.__init__": [[98, 120], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "range", "range", "torchvision.models.vgg16", "pretrained_networks.vgg16.slice1.add_module", "pretrained_networks.vgg16.slice2.add_module", "pretrained_networks.vgg16.slice3.add_module", "pretrained_networks.vgg16.slice4.add_module", "pretrained_networks.vgg16.slice5.add_module", "pretrained_networks.vgg16.parameters", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ",", "pretrained", "=", "True", ")", ":", "\n", "        ", "super", "(", "vgg16", ",", "self", ")", ".", "__init__", "(", ")", "\n", "vgg_pretrained_features", "=", "tv", ".", "vgg16", "(", "pretrained", "=", "pretrained", ")", ".", "features", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice4", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice5", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "N_slices", "=", "5", "\n", "for", "x", "in", "range", "(", "4", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "4", ",", "9", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "9", ",", "16", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "16", ",", "23", ")", ":", "\n", "            ", "self", ".", "slice4", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "23", ",", "30", ")", ":", "\n", "            ", "self", ".", "slice5", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.vgg16.forward": [[121, 136], ["pretrained_networks.vgg16.slice1", "pretrained_networks.vgg16.slice2", "pretrained_networks.vgg16.slice3", "pretrained_networks.vgg16.slice4", "pretrained_networks.vgg16.slice5", "collections.namedtuple", "collections.namedtuple."], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu1_2", "=", "h", "\n", "h", "=", "self", ".", "slice2", "(", "h", ")", "\n", "h_relu2_2", "=", "h", "\n", "h", "=", "self", ".", "slice3", "(", "h", ")", "\n", "h_relu3_3", "=", "h", "\n", "h", "=", "self", ".", "slice4", "(", "h", ")", "\n", "h_relu4_3", "=", "h", "\n", "h", "=", "self", ".", "slice5", "(", "h", ")", "\n", "h_relu5_3", "=", "h", "\n", "vgg_outputs", "=", "namedtuple", "(", "\"VggOutputs\"", ",", "[", "'relu1_2'", ",", "'relu2_2'", ",", "'relu3_3'", ",", "'relu4_3'", ",", "'relu5_3'", "]", ")", "\n", "out", "=", "vgg_outputs", "(", "h_relu1_2", ",", "h_relu2_2", ",", "h_relu3_3", ",", "h_relu4_3", ",", "h_relu5_3", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.resnet.__init__": [[140, 162], ["super().__init__", "torchvision.models.resnet18", "torchvision.models.resnet34", "torchvision.models.resnet50", "torchvision.models.resnet101", "torchvision.models.resnet152"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ",", "pretrained", "=", "True", ",", "num", "=", "18", ")", ":", "\n", "        ", "super", "(", "resnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "(", "num", "==", "18", ")", ":", "\n", "            ", "self", ".", "net", "=", "tv", ".", "resnet18", "(", "pretrained", "=", "pretrained", ")", "\n", "", "elif", "(", "num", "==", "34", ")", ":", "\n", "            ", "self", ".", "net", "=", "tv", ".", "resnet34", "(", "pretrained", "=", "pretrained", ")", "\n", "", "elif", "(", "num", "==", "50", ")", ":", "\n", "            ", "self", ".", "net", "=", "tv", ".", "resnet50", "(", "pretrained", "=", "pretrained", ")", "\n", "", "elif", "(", "num", "==", "101", ")", ":", "\n", "            ", "self", ".", "net", "=", "tv", ".", "resnet101", "(", "pretrained", "=", "pretrained", ")", "\n", "", "elif", "(", "num", "==", "152", ")", ":", "\n", "            ", "self", ".", "net", "=", "tv", ".", "resnet152", "(", "pretrained", "=", "pretrained", ")", "\n", "", "self", ".", "N_slices", "=", "5", "\n", "\n", "self", ".", "conv1", "=", "self", ".", "net", ".", "conv1", "\n", "self", ".", "bn1", "=", "self", ".", "net", ".", "bn1", "\n", "self", ".", "relu", "=", "self", ".", "net", ".", "relu", "\n", "self", ".", "maxpool", "=", "self", ".", "net", ".", "maxpool", "\n", "self", ".", "layer1", "=", "self", ".", "net", ".", "layer1", "\n", "self", ".", "layer2", "=", "self", ".", "net", ".", "layer2", "\n", "self", ".", "layer3", "=", "self", ".", "net", ".", "layer3", "\n", "self", ".", "layer4", "=", "self", ".", "net", ".", "layer4", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.pretrained_networks.resnet.forward": [[163, 182], ["pretrained_networks.resnet.conv1", "pretrained_networks.resnet.bn1", "pretrained_networks.resnet.relu", "pretrained_networks.resnet.maxpool", "pretrained_networks.resnet.layer1", "pretrained_networks.resnet.layer2", "pretrained_networks.resnet.layer3", "pretrained_networks.resnet.layer4", "collections.namedtuple", "collections.namedtuple."], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h", "=", "self", ".", "conv1", "(", "X", ")", "\n", "h", "=", "self", ".", "bn1", "(", "h", ")", "\n", "h", "=", "self", ".", "relu", "(", "h", ")", "\n", "h_relu1", "=", "h", "\n", "h", "=", "self", ".", "maxpool", "(", "h", ")", "\n", "h", "=", "self", ".", "layer1", "(", "h", ")", "\n", "h_conv2", "=", "h", "\n", "h", "=", "self", ".", "layer2", "(", "h", ")", "\n", "h_conv3", "=", "h", "\n", "h", "=", "self", ".", "layer3", "(", "h", ")", "\n", "h_conv4", "=", "h", "\n", "h", "=", "self", ".", "layer4", "(", "h", ")", "\n", "h_conv5", "=", "h", "\n", "\n", "outputs", "=", "namedtuple", "(", "\"Outputs\"", ",", "[", "'relu1'", ",", "'conv2'", ",", "'conv3'", ",", "'conv4'", ",", "'conv5'", "]", ")", "\n", "out", "=", "outputs", "(", "h_relu1", ",", "h_conv2", ",", "h_conv3", ",", "h_conv4", ",", "h_conv5", ")", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.__init__.PerceptualLoss.__init__": [[14, 23], ["super().__init__", "dist_model.DistModel", "__init__.PerceptualLoss.model.initialize"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.initialize"], []], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.__init__.PerceptualLoss.forward": [[26, 41], ["__init__.PerceptualLoss.model.forward"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward"], []], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.normalize_tensor": [[11, 14], ["torch.sqrt", "torch.sum"], "function", ["None"], ["# distributed under the License is distributed on an \"AS IS\" BASIS,", "\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.", "\n", "# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.l2": [[15, 17], ["numpy.mean"], "function", ["None"], ["\"\"\"Helper functions.\"\"\"", "\n", "\n", "from", "__future__", "import", "absolute_import", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.psnr": [[18, 20], ["numpy.log10", "numpy.mean"], "function", ["None"], ["from", "__future__", "import", "division", "\n", "from", "__future__", "import", "print_function", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.dssim": [[21, 23], ["skimage.measure.compare_ssim"], "function", ["None"], ["import", "os", "\n", "\n", "import", "numpy", "as", "np", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.rgb2lab": [[71, 74], ["color.rgb2lab"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.rgb2lab"], ["hi", "=", "torch", ".", "as_tensor", "(", "hi", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "alpha", "=", "torch", ".", "sigmoid", "(", "logits", ")", "*", "(", "hi", "-", "lo", ")", "+", "lo", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2np": [[31, 34], ["tensor_obj[].cpu().float().numpy().transpose", "tensor_obj[].cpu().float().numpy", "tensor_obj[].cpu().float", "tensor_obj[].cpu"], "function", ["None"], ["return", "torch", ".", "log", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "33e37", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n", "\n", "", "def", "log1p_safe", "(", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.np2tensor": [[35, 38], ["torch.Tensor", "np_obj[].transpose"], "function", ["None"], ["  ", "\"\"\"The same as torch.log1p(x), but clamps the input to prevent NaNs.\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "log1p", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "33e37", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2tensorlab": [[39, 52], ["util.tensor2im", "color.rgb2lab", "util.np2tensor"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2im", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.rgb2lab", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.np2tensor"], ["\n", "", "def", "exp_safe", "(", "x", ")", ":", "\n", "  ", "\"\"\"The same as torch.exp(x), but clamps the input to prevent NaNs.\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "exp", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "87.5", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n", "\n", "", "def", "expm1_safe", "(", "x", ")", ":", "\n", "  ", "\"\"\"The same as tf.math.expm1(x), but clamps the input to prevent NaNs.\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "expm1", "(", "torch", ".", "min", "(", "x", ",", "torch", ".", "tensor", "(", "87.5", ")", ".", "to", "(", "x", ")", ")", ")", "\n", "\n", "\n", "", "def", "inv_softplus", "(", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensorlab2tensor": [[53, 70], ["warnings.filterwarnings", "util.tensor2np", "numpy.clip", "color.rgb2lab", "util.np2tensor", "util.im2tensor", "color.lab2rgb", "rgb_back.astype", "numpy.isclose", "util.im2tensor", "lab.astype", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2np", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.rgb2lab", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.np2tensor", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.im2tensor", "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.im2tensor"], ["  ", "\"\"\"The inverse of tf.nn.softplus().\"\"\"", "\n", "y", "=", "torch", ".", "as_tensor", "(", "y", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "torch", ".", "where", "(", "y", ">", "87.5", ",", "y", ",", "torch", ".", "log", "(", "torch", ".", "expm1", "(", "y", ")", ")", ")", "\n", "\n", "\n", "", "def", "logit", "(", "y", ")", ":", "\n", "  ", "\"\"\"The inverse of tf.nn.sigmoid().\"\"\"", "\n", "y", "=", "torch", ".", "as_tensor", "(", "y", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "return", "-", "torch", ".", "log", "(", "1.", "/", "y", "-", "1.", ")", "\n", "\n", "\n", "", "def", "affine_sigmoid", "(", "logits", ",", "lo", "=", "0", ",", "hi", "=", "1", ")", ":", "\n", "  ", "\"\"\"Maps reals to (lo, hi), where 0 maps to (lo+hi)/2.\"\"\"", "\n", "#import ipdb; ipdb.set_trace()", "\n", "if", "not", "lo", "<", "hi", ":", "\n", "    ", "raise", "ValueError", "(", "'`lo` (%g) must be < `hi` (%g)'", "%", "(", "lo", ",", "hi", ")", ")", "\n", "", "logits", "=", "torch", ".", "as_tensor", "(", "logits", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "lo", "=", "torch", ".", "as_tensor", "(", "lo", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2im": [[120, 125], ["image_tensor[].cpu().float().numpy", "image_tensor[].cpu().float().numpy.astype", "image_tensor[].cpu().float", "numpy.transpose", "image_tensor[].cpu"], "function", ["None"], ["(", "x", "/", "scale", ")", "**", "2.", "/", "df", ")", "+", "torch", ".", "log", "(", "df", ")", ")", "+", "log_partition", "\n", "\n", "\n", "# A constant scale that makes tf.image.rgb_to_yuv() volume preserving.", "\n", "", "_VOLUME_PRESERVING_YUV_SCALE", "=", "1.580227820074", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.im2tensor": [[126, 130], ["torch.Tensor", "[].transpose"], "function", ["None"], ["\n", "def", "rgb_to_syuv", "(", "rgb", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.tensor2vec": [[84, 86], ["vector_tensor.data.cpu().numpy", "vector_tensor.data.cpu"], "function", ["None"], ["return", "logits", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.util.voc_ap": [[87, 119], ["numpy.arange", "numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "numpy.maximum", "numpy.where", "numpy.sum", "numpy.max"], "function", ["None"], ["", "def", "affine_softplus", "(", "x", ",", "lo", "=", "0", ",", "ref", "=", "1", ")", ":", "\n", "  ", "\"\"\"Maps real numbers to (lo, infinity), where 0 maps to ref.\"\"\"", "\n", "if", "not", "lo", "<", "ref", ":", "\n", "    ", "raise", "ValueError", "(", "'`lo` (%g) must be < `ref` (%g)'", "%", "(", "lo", ",", "ref", ")", ")", "\n", "", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "lo", "=", "torch", ".", "as_tensor", "(", "lo", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "ref", "=", "torch", ".", "as_tensor", "(", "ref", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "shift", "=", "inv_softplus", "(", "torch", ".", "tensor", "(", "1.", ")", ")", "\n", "y", "=", "(", "ref", "-", "lo", ")", "*", "torch", ".", "nn", ".", "Softplus", "(", ")", "(", "x", "+", "shift", ")", "+", "lo", "\n", "return", "y", "\n", "\n", "\n", "", "def", "inv_affine_softplus", "(", "y", ",", "lo", "=", "0", ",", "ref", "=", "1", ")", ":", "\n", "  ", "\"\"\"The inverse of affine_softplus(., lo, ref).\"\"\"", "\n", "if", "not", "lo", "<", "ref", ":", "\n", "    ", "raise", "ValueError", "(", "'`lo` (%g) must be < `ref` (%g)'", "%", "(", "lo", ",", "ref", ")", ")", "\n", "", "y", "=", "torch", ".", "as_tensor", "(", "y", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "lo", "=", "torch", ".", "as_tensor", "(", "lo", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "ref", "=", "torch", ".", "as_tensor", "(", "ref", ")", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "shift", "=", "inv_softplus", "(", "torch", ".", "tensor", "(", "1.", ")", ")", "\n", "x", "=", "inv_softplus", "(", "(", "y", "-", "lo", ")", "/", "(", "ref", "-", "lo", ")", ")", "-", "shift", "\n", "return", "x", "\n", "\n", "\n", "", "def", "students_t_nll", "(", "x", ",", "df", ",", "scale", ")", ":", "\n", "  ", "\"\"\"The NLL of a Generalized Student's T distribution (w/o including TFP).\"\"\"", "\n", "x", "=", "torch", ".", "as_tensor", "(", "x", ")", "\n", "df", "=", "torch", ".", "as_tensor", "(", "df", ")", "\n", "scale", "=", "torch", ".", "as_tensor", "(", "scale", ")", "\n", "log_partition", "=", "torch", ".", "log", "(", "torch", ".", "abs", "(", "scale", ")", ")", "+", "torch", ".", "lgamma", "(", "\n", "0.5", "*", "df", ")", "-", "torch", ".", "lgamma", "(", "0.5", "*", "df", "+", "torch", ".", "tensor", "(", "0.5", ")", ")", "+", "torch", ".", "tensor", "(", "\n", "0.5", "*", "np", ".", "log", "(", "np", ".", "pi", ")", ")", "\n", "return", "0.5", "*", "(", "(", "df", "+", "1.", ")", "*", "torch", ".", "log1p", "(", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.__init__": [[8, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", ";", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.name": [[11, 13], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'BaseModel'", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.initialize": [[14, 17], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "use_gpu", "=", "True", ",", "gpu_ids", "=", "[", "0", "]", ")", ":", "\n", "        ", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "gpu_ids", "=", "gpu_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.forward": [[18, 20], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.get_image_paths": [[52, 54], ["None"], "methods", ["None"], ["", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.optimize_parameters": [[24, 26], ["None"], "methods", ["None"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.get_current_visuals": [[27, 29], ["None"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.get_current_errors": [[30, 32], ["None"], "methods", ["None"], ["", "def", "get_current_errors", "(", "self", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save": [[33, 35], ["None"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "label", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save_network": [[37, 41], ["os.path.join", "torch.save", "network.state_dict"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save"], ["", "def", "save_network", "(", "self", ",", "network", ",", "path", ",", "network_label", ",", "epoch_label", ")", ":", "\n", "        ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch_label", ",", "network_label", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "save_filename", ")", "\n", "torch", ".", "save", "(", "network", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.load_network": [[43, 48], ["os.path.join", "print", "network.load_state_dict", "torch.load"], "methods", ["None"], ["", "def", "load_network", "(", "self", ",", "network", ",", "network_label", ",", "epoch_label", ")", ":", "\n", "        ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch_label", ",", "network_label", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "print", "(", "'Loading network from %s'", "%", "save_path", ")", "\n", "network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "save_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.update_learning_rate": [[49, 51], ["None"], "methods", ["None"], ["", "def", "update_learning_rate", "(", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save_done": [[55, 58], ["np.save", "np.savetxt", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.LPIPS.base_model.BaseModel.save"], ["", "def", "save_done", "(", "self", ",", "flag", "=", "False", ")", ":", "\n", "        ", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'done_flag'", ")", ",", "flag", ")", "\n", "np", ".", "savetxt", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'done_flag'", ")", ",", "[", "flag", ",", "]", ",", "fmt", "=", "'%i'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.InceptionV3.__init__": [[31, 128], ["torch.Module.__init__", "sorted", "max", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.parameters", "inception.fid_inception_v3", "torchvision.models.inception_v3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.fid_inception_v3"], ["def", "__init__", "(", "self", ",", "\n", "output_blocks", "=", "[", "DEFAULT_BLOCK_INDEX", "]", ",", "\n", "resize_input", "=", "True", ",", "\n", "normalize_input", "=", "True", ",", "\n", "requires_grad", "=", "False", ",", "\n", "use_fid_inception", "=", "True", ")", ":", "\n", "        ", "\"\"\"Build pretrained InceptionV3\n\n        Parameters\n        ----------\n        output_blocks : list of int\n            Indices of blocks to return features of. Possible values are:\n                - 0: corresponds to output of first max pooling\n                - 1: corresponds to output of second max pooling\n                - 2: corresponds to output which is fed to aux classifier\n                - 3: corresponds to output of final average pooling\n        resize_input : bool\n            If true, bilinearly resizes input to width and height 299 before\n            feeding input to model. As the network without fully connected\n            layers is fully convolutional, it should be able to handle inputs\n            of arbitrary size, so resizing might not be strictly needed\n        normalize_input : bool\n            If true, scales the input from range (0, 1) to the range the\n            pretrained Inception network expects, namely (-1, 1)\n        requires_grad : bool\n            If true, parameters of the model require gradients. Possibly useful\n            for finetuning the network\n        use_fid_inception : bool\n            If true, uses the pretrained Inception model used in Tensorflow's\n            FID implementation. If false, uses the pretrained Inception model\n            available in torchvision. The FID Inception model has different\n            weights and a slightly different structure from torchvision's\n            Inception model. If you want to compute FID scores, you are\n            strongly advised to set this parameter to true to get comparable\n            results.\n        \"\"\"", "\n", "super", "(", "InceptionV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "resize_input", "=", "resize_input", "\n", "self", ".", "normalize_input", "=", "normalize_input", "\n", "self", ".", "output_blocks", "=", "sorted", "(", "output_blocks", ")", "\n", "self", ".", "last_needed_block", "=", "max", "(", "output_blocks", ")", "\n", "\n", "assert", "self", ".", "last_needed_block", "<=", "3", ",", "'Last possible output block index is 3'", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "if", "use_fid_inception", ":", "\n", "            ", "inception", "=", "fid_inception_v3", "(", ")", "\n", "", "else", ":", "\n", "            ", "inception", "=", "models", ".", "inception_v3", "(", "pretrained", "=", "True", ")", "\n", "\n", "# Block 0: input to maxpool1", "\n", "", "block0", "=", "[", "\n", "inception", ".", "Conv2d_1a_3x3", ",", "\n", "inception", ".", "Conv2d_2a_3x3", ",", "\n", "inception", ".", "Conv2d_2b_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block0", ")", ")", "\n", "\n", "# Block 1: maxpool1 to maxpool2", "\n", "if", "self", ".", "last_needed_block", ">=", "1", ":", "\n", "            ", "block1", "=", "[", "\n", "inception", ".", "Conv2d_3b_1x1", ",", "\n", "inception", ".", "Conv2d_4a_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block1", ")", ")", "\n", "\n", "# Block 2: maxpool2 to aux classifier", "\n", "", "if", "self", ".", "last_needed_block", ">=", "2", ":", "\n", "            ", "block2", "=", "[", "\n", "inception", ".", "Mixed_5b", ",", "\n", "inception", ".", "Mixed_5c", ",", "\n", "inception", ".", "Mixed_5d", ",", "\n", "inception", ".", "Mixed_6a", ",", "\n", "inception", ".", "Mixed_6b", ",", "\n", "inception", ".", "Mixed_6c", ",", "\n", "inception", ".", "Mixed_6d", ",", "\n", "inception", ".", "Mixed_6e", ",", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block2", ")", ")", "\n", "\n", "# Block 3: aux classifier to final avgpool", "\n", "", "if", "self", ".", "last_needed_block", ">=", "3", ":", "\n", "            ", "block3", "=", "[", "\n", "inception", ".", "Mixed_7a", ",", "\n", "inception", ".", "Mixed_7b", ",", "\n", "inception", ".", "Mixed_7c", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block3", ")", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.InceptionV3.forward": [[129, 164], ["enumerate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "block", "outp.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"Get Inception feature maps\n\n        Parameters\n        ----------\n        inp : torch.autograd.Variable\n            Input tensor of shape Bx3xHxW. Values are expected to be in\n            range (0, 1)\n\n        Returns\n        -------\n        List of torch.autograd.Variable, corresponding to the selected output\n        block, sorted ascending by index\n        \"\"\"", "\n", "outp", "=", "[", "]", "\n", "x", "=", "inp", "\n", "\n", "if", "self", ".", "resize_input", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "\n", "size", "=", "(", "299", ",", "299", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "2", "*", "x", "-", "1", "# Scale from range (0, 1) to range (-1, 1)", "\n", "\n", "", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "if", "idx", "in", "self", ".", "output_blocks", ":", "\n", "                ", "outp", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "idx", "==", "self", ".", "last_needed_block", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "outp", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionA.__init__": [[195, 197], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "pool_features", ")", ":", "\n", "        ", "super", "(", "FIDInceptionA", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "pool_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionA.forward": [[198, 216], ["inception.FIDInceptionA.branch1x1", "inception.FIDInceptionA.branch5x5_1", "inception.FIDInceptionA.branch5x5_2", "inception.FIDInceptionA.branch3x3dbl_1", "inception.FIDInceptionA.branch3x3dbl_2", "inception.FIDInceptionA.branch3x3dbl_3", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionA.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch5x5", "=", "self", ".", "branch5x5_1", "(", "x", ")", "\n", "branch5x5", "=", "self", ".", "branch5x5_2", "(", "branch5x5", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_3", "(", "branch3x3dbl", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch5x5", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionC.__init__": [[220, 222], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "channels_7x7", ")", ":", "\n", "        ", "super", "(", "FIDInceptionC", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "channels_7x7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionC.forward": [[223, 244], ["inception.FIDInceptionC.branch1x1", "inception.FIDInceptionC.branch7x7_1", "inception.FIDInceptionC.branch7x7_2", "inception.FIDInceptionC.branch7x7_3", "inception.FIDInceptionC.branch7x7dbl_1", "inception.FIDInceptionC.branch7x7dbl_2", "inception.FIDInceptionC.branch7x7dbl_3", "inception.FIDInceptionC.branch7x7dbl_4", "inception.FIDInceptionC.branch7x7dbl_5", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionC.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch7x7", "=", "self", ".", "branch7x7_1", "(", "x", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_2", "(", "branch7x7", ")", "\n", "branch7x7", "=", "self", ".", "branch7x7_3", "(", "branch7x7", ")", "\n", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_1", "(", "x", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_2", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_3", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_4", "(", "branch7x7dbl", ")", "\n", "branch7x7dbl", "=", "self", ".", "branch7x7dbl_5", "(", "branch7x7dbl", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch7x7", ",", "branch7x7dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_1.__init__": [[248, 250], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FIDInceptionE_1", ",", "self", ")", ".", "__init__", "(", "in_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_1.forward": [[251, 277], ["inception.FIDInceptionE_1.branch1x1", "inception.FIDInceptionE_1.branch3x3_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_1.branch3x3dbl_1", "inception.FIDInceptionE_1.branch3x3dbl_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "inception.FIDInceptionE_1.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_1.branch3x3_2a", "inception.FIDInceptionE_1.branch3x3_2b", "inception.FIDInceptionE_1.branch3x3dbl_3a", "inception.FIDInceptionE_1.branch3x3dbl_3b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "[", "\n", "self", ".", "branch3x3_2a", "(", "branch3x3", ")", ",", "\n", "self", ".", "branch3x3_2b", "(", "branch3x3", ")", ",", "\n", "]", "\n", "branch3x3", "=", "torch", ".", "cat", "(", "branch3x3", ",", "1", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "[", "\n", "self", ".", "branch3x3dbl_3a", "(", "branch3x3dbl", ")", ",", "\n", "self", ".", "branch3x3dbl_3b", "(", "branch3x3dbl", ")", ",", "\n", "]", "\n", "branch3x3dbl", "=", "torch", ".", "cat", "(", "branch3x3dbl", ",", "1", ")", "\n", "\n", "# Patch: Tensorflow's average pool does not use the padded zero's in", "\n", "# its average calculation", "\n", "branch_pool", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__": [[281, 283], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ")", ":", "\n", "        ", "super", "(", "FIDInceptionE_2", ",", "self", ")", ".", "__init__", "(", "in_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.FIDInceptionE_2.forward": [[284, 311], ["inception.FIDInceptionE_2.branch1x1", "inception.FIDInceptionE_2.branch3x3_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_2.branch3x3dbl_1", "inception.FIDInceptionE_2.branch3x3dbl_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "inception.FIDInceptionE_2.branch_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inception.FIDInceptionE_2.branch3x3_2a", "inception.FIDInceptionE_2.branch3x3_2b", "inception.FIDInceptionE_2.branch3x3dbl_3a", "inception.FIDInceptionE_2.branch3x3dbl_3b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "branch1x1", "=", "self", ".", "branch1x1", "(", "x", ")", "\n", "\n", "branch3x3", "=", "self", ".", "branch3x3_1", "(", "x", ")", "\n", "branch3x3", "=", "[", "\n", "self", ".", "branch3x3_2a", "(", "branch3x3", ")", ",", "\n", "self", ".", "branch3x3_2b", "(", "branch3x3", ")", ",", "\n", "]", "\n", "branch3x3", "=", "torch", ".", "cat", "(", "branch3x3", ",", "1", ")", "\n", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_1", "(", "x", ")", "\n", "branch3x3dbl", "=", "self", ".", "branch3x3dbl_2", "(", "branch3x3dbl", ")", "\n", "branch3x3dbl", "=", "[", "\n", "self", ".", "branch3x3dbl_3a", "(", "branch3x3dbl", ")", ",", "\n", "self", ".", "branch3x3dbl_3b", "(", "branch3x3dbl", ")", ",", "\n", "]", "\n", "branch3x3dbl", "=", "torch", ".", "cat", "(", "branch3x3dbl", ",", "1", ")", "\n", "\n", "# Patch: The FID Inception model uses max pooling instead of average", "\n", "# pooling. This is likely an error in this specific Inception", "\n", "# implementation, as other Inception models use average pooling here", "\n", "# (which matches the description in the paper).", "\n", "branch_pool", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "branch_pool", "=", "self", ".", "branch_pool", "(", "branch_pool", ")", "\n", "\n", "outputs", "=", "[", "branch1x1", ",", "branch3x3", ",", "branch3x3dbl", ",", "branch_pool", "]", "\n", "return", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.inception.fid_inception_v3": [[166, 191], ["torchvision.models.inception_v3", "inception.FIDInceptionA", "inception.FIDInceptionA", "inception.FIDInceptionA", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionC", "inception.FIDInceptionE_1", "inception.FIDInceptionE_2", "load_state_dict_from_url", "models.inception_v3.load_state_dict"], "function", ["None"], ["", "", "def", "fid_inception_v3", "(", ")", ":", "\n", "    ", "\"\"\"Build pretrained Inception model for FID computation\n\n    The Inception model for FID computation uses a different set of weights\n    and has a slightly different structure than torchvision's Inception.\n\n    This method first constructs torchvision's Inception and then patches the\n    necessary parts that are different in the FID Inception model.\n    \"\"\"", "\n", "inception", "=", "models", ".", "inception_v3", "(", "num_classes", "=", "1008", ",", "\n", "aux_logits", "=", "False", ",", "\n", "pretrained", "=", "False", ")", "\n", "inception", ".", "Mixed_5b", "=", "FIDInceptionA", "(", "192", ",", "pool_features", "=", "32", ")", "\n", "inception", ".", "Mixed_5c", "=", "FIDInceptionA", "(", "256", ",", "pool_features", "=", "64", ")", "\n", "inception", ".", "Mixed_5d", "=", "FIDInceptionA", "(", "288", ",", "pool_features", "=", "64", ")", "\n", "inception", ".", "Mixed_6b", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "128", ")", "\n", "inception", ".", "Mixed_6c", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "inception", ".", "Mixed_6d", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "160", ")", "\n", "inception", ".", "Mixed_6e", "=", "FIDInceptionC", "(", "768", ",", "channels_7x7", "=", "192", ")", "\n", "inception", ".", "Mixed_7b", "=", "FIDInceptionE_1", "(", "1280", ")", "\n", "inception", ".", "Mixed_7c", "=", "FIDInceptionE_2", "(", "2048", ")", "\n", "\n", "state_dict", "=", "load_state_dict_from_url", "(", "FID_WEIGHTS_URL", ",", "progress", "=", "True", ")", "\n", "inception", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "inception", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score.calculate_frechet_distance": [[86, 141], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "print", "scipy.linalg.sqrtm", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["def", "calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n\n    Stable version by Dougal J. Sutherland.\n\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an\n               representative data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an\n               representative data set.\n\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# Product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "        ", "msg", "=", "(", "'fid calculation produces singular product; '", "\n", "'adding %s to diagonal of cov estimates'", ")", "%", "eps", "\n", "print", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# Numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "        ", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "            ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "'Imaginary component {}'", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "return", "(", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "\n", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", ")", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score.get_activations_of_images": [[206, 261], ["model.eval", "numpy.empty", "images.float", "range", "print", "print", "batch.cuda.cuda", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy().reshape", "batch.cuda.cuda", "model", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy", "torch.nn.functional.adaptive_avg_pool2d.cpu"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.pioneer.model.SpectralNorm.eval"], ["", "def", "get_activations_of_images", "(", "images", ",", "model", ",", "batch_size", "=", "50", ",", "dims", "=", "2048", ",", "\n", "cuda", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- files       : Tensor [n_imgs, 3, H, Warning]\n    -- model       : Instance of inception model\n    -- batch_size  : Batch size of images for the model to process at once.\n\n    Returns:\n    -- A numpy array of dimension (num images, dims) that contains the\n       activations of the given tensor when feeding inception with the\n       query tensor.\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "n_used_imgs", ",", "_", ",", "h", ",", "w", "=", "images", ".", "shape", "\n", "\n", "if", "n_used_imgs", "%", "batch_size", "!=", "0", ":", "\n", "        ", "print", "(", "(", "'Warning: number of images is not a multiple of the '", "\n", "'batch size. Some samples are going to be ignored.'", ")", ")", "\n", "", "if", "batch_size", ">", "n_used_imgs", ":", "\n", "        ", "print", "(", "(", "'Warning: batch size is bigger than the data size. '", "\n", "'Setting batch size to data size'", ")", ")", "\n", "batch_size", "=", "n_used_imgs", "\n", "\n", "", "n_batches", "=", "n_used_imgs", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "dims", ")", ")", "\n", "\n", "batch", "=", "images", ".", "float", "(", ")", "\n", "if", "cuda", ":", "\n", "        ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "\n", "        ", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "batch", "=", "images", "[", "start", ":", "end", "]", "\n", "\n", "if", "cuda", ":", "\n", "            ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "\n", "", "pred", "=", "model", "(", "batch", ")", "[", "0", "]", "\n", "\n", "# If model output is not scalar, apply global spatial average pooling.", "\n", "# This happens if you choose a dimensionality not equal 2048.", "\n", "if", "pred", ".", "shape", "[", "2", "]", "!=", "1", "or", "pred", ".", "shape", "[", "3", "]", "!=", "1", ":", "\n", "            ", "pred", "=", "adaptive_avg_pool2d", "(", "pred", ",", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "return", "pred_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score._calculate_activation_statistics_of_images": [[263, 279], ["fid_score.get_activations_of_images", "numpy.mean", "numpy.cov"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score.get_activations_of_images"], ["", "def", "_calculate_activation_statistics_of_images", "(", "files", ",", "model", ",", "batch_size", "=", "50", ",", "\n", "dims", "=", "2048", ",", "cuda", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculation of the statistics used by the FID.\n    Params:\n    -- files       : Tensor [n_imgs, 3, H, W]\n\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the inception model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the inception model.\n    \"\"\"", "\n", "act", "=", "get_activations_of_images", "(", "files", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score.calculate_fid_given_images": [[280, 299], ["pioneer.FID.inception.InceptionV3", "fid_score._calculate_activation_statistics_of_images", "fid_score._calculate_activation_statistics_of_images", "fid_score.calculate_frechet_distance", "pioneer.FID.inception.InceptionV3.cuda"], "function", ["home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score._calculate_activation_statistics_of_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score._calculate_activation_statistics_of_images", "home.repos.pwc.inspect_result.AaltoVision_automodulator.FID.fid_score.calculate_frechet_distance"], ["", "def", "calculate_fid_given_images", "(", "real", ",", "reco", ",", "batch_size", ",", "cuda", ",", "dims", ")", ":", "\n", "    ", "\"\"\"Calculates the FID of real and reco\"\"\"", "\n", "\"\"\"real/reco : Tensor [number of image, 3, H, W]\"\"\"", "\n", "\n", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "\n", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", "\n", "\n", "if", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "\n", "", "m1", ",", "s1", "=", "_calculate_activation_statistics_of_images", "(", "real", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "m2", ",", "s2", "=", "_calculate_activation_statistics_of_images", "(", "reco", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "\n", "return", "fid_value", "\n", "\n"]]}