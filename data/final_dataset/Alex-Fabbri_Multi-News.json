{"home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.prep_data.clean": [[11, 52], ["line.replace.strip().replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.strip"], "function", ["None"], ["def", "clean", "(", "line", ")", ":", "\n", "    ", "line", "=", "line", ".", "strip", "(", ")", ".", "replace", "(", "\"newline_char\"", ",", "\" \"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"( opens in new window )\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"click to email this to a friend\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"lick to share on whatsapp\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"click to share on facebook\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"share on facebook\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"click to share on twitter\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"click to share on pinterest\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"click to share on tumblr\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"click to share on google+\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"feel free to share these resources in your social \"", "\n", "\"media networks , websites and other platforms\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"share share tweet link\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"e-mail article print share\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"read or share this story :\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"share the map view in e-mail by clicking the share \"", "\n", "\"button and copying the link url .     embed the map \"", "\n", "\"on your website or blog by getting a snippet of html \"", "\n", "\"code from the share button .     if you wish to \"", "\n", "\"provide feedback or comments on the map , or if \"", "\n", "\"you are aware of map layers or other \"", "\n", "\"datasets that you would like to see included on our maps , \"", "\n", "\"please submit them for our evaluation using this this form .\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"share this article share tweet post email\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"skip in skip x embed x share close\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"share tweet pin email\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"share on twitter\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"feel free to weigh-in yourself , via\"", "\n", "\"the comments section . and while you \u2019 \"", "\n", "\"re here , why don \u2019 t you sign up to \"", "\n", "\"follow us on twitter us on twitter .\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"follow us on facebook , twitter , instagram and youtube\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"follow us on twitter\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"follow us on facebook\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"play facebook twitter google plus embed\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"play facebook twitter embed\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"enlarge icon pinterest icon close icon\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"follow on twitter\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"autoplay autoplay copy this code to your website or blog\"", ",", "\"\"", ")", "\n", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.prep_data.clean_archive_data": [[54, 69], ["nltk.tokenize.ToktokTokenizer", "enumerate", "os.path.exists", "os.makedirs", "os.listdir", "open().read", "print", "nltk.tokenize.ToktokTokenizer.tokenize", "prep_data.clean", "open", "newspaper.fulltext", "open", "output.write", "print"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.tokenize", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.prep_data.clean"], ["", "def", "clean_archive_data", "(", "folder", ")", ":", "\n", "    ", "toktok", "=", "ToktokTokenizer", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "f\"{folder}-cleaned\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "f\"{folder}-cleaned\"", ")", "\n", "", "for", "count", ",", "file", "in", "enumerate", "(", "os", ".", "listdir", "(", "f\"{folder}\"", ")", ")", ":", "\n", "        ", "if", "count", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "count", ")", "\n", "", "file_data", "=", "open", "(", "f\"{folder}/{file}\"", ",", "\"r\"", ")", ".", "read", "(", ")", "\n", "try", ":", "\n", "            ", "text_newspaper", "=", "toktok", ".", "tokenize", "(", "fulltext", "(", "file_data", ")", ")", "\n", "text_newspaper_cleaned", "=", "clean", "(", "\" \"", ".", "join", "(", "text_newspaper", ")", ")", "\n", "with", "open", "(", "f\"{folder}-cleaned/{file}\"", ",", "\"w\"", ")", "as", "output", ":", "\n", "                ", "output", ".", "write", "(", "text_newspaper_cleaned", ")", "\n", "", "", "except", ":", "# pylint: disable=W0702", "\n", "            ", "print", "(", "f\"error with {file}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.prep_data.get_split": [[70, 91], ["open", "open", "open", "enumerate", "int", "output_src.write", "output_tgt.write", "print", "line.strip", "glob.glob", "open().read().replace", "open().read().replace", "cur_data.append", "print", "open().read", "open().read", "open", "open"], "function", ["None"], ["", "", "", "def", "get_split", "(", "split", ")", ":", "\n", "    ", "with", "open", "(", "f\"../final_data/{split}.src.txt\"", ",", "\"w\"", ")", "as", "output_src", ",", "open", "(", "f\"../final_data/{split}.tgt.txt\"", ",", "\"w\"", ")", "as", "output_tgt", ",", "open", "(", "f\"../ids/{split}.id\"", ",", "\"r\"", ")", "as", "input_file", ":", "\n", "        ", "for", "count", ",", "line", "in", "enumerate", "(", "input_file", ")", ":", "\n", "            ", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "count", ")", "\n", "", "cur_id", "=", "int", "(", "line", ".", "strip", "(", ")", ")", "\n", "try", ":", "\n", "                ", "cur_data", "=", "[", "]", "\n", "for", "filename", "in", "glob", ".", "glob", "(", "f\"../articles-cleaned/{cur_id}*\"", ")", ":", "\n", "                    ", "file_data", "=", "open", "(", "filename", ",", "\"r\"", ")", ".", "read", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "cur_data", ".", "append", "(", "file_data", ")", "\n", "", "input_str", "=", "\" story_separator_special_tag \"", ".", "join", "(", "cur_data", ")", "\n", "summary_str", "=", "open", "(", "f\"../summaries-cleaned/{cur_id}\"", ",", "\n", "\"r\"", ")", ".", "read", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "                ", "print", "(", "cur_id", ")", "\n", "continue", "\n", "", "output_src", ".", "write", "(", "f\"{input_str}\\n\"", ")", "\n", "output_tgt", ".", "write", "(", "f\"{summary_str}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.prep_data.check_available": [[93, 105], ["open", "enumerate", "os.listdir", "print", "json.load", "output.write", "open"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["", "", "", "def", "check_available", "(", "folder", ")", ":", "\n", "    ", "with", "open", "(", "\"available.txt\"", ",", "\"w\"", ")", "as", "output", ":", "\n", "# TODO directory corresponding to downloaded \"availability\" WayBack links", "\n", "        ", "for", "count", ",", "file", "in", "enumerate", "(", "os", ".", "listdir", "(", "f\"{folder}\"", ")", ")", ":", "\n", "            ", "if", "count", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "count", ")", "\n", "", "try", ":", "\n", "                ", "json_dict", "=", "json", ".", "load", "(", "open", "(", "f\"{folder}/{file}\"", ",", "\"r\"", ")", ")", "\n", "url", "=", "json_dict", "[", "\"archived_snapshots\"", "]", "[", "\"closest\"", "]", "[", "\"url\"", "]", "\n", "output", ".", "write", "(", "f\"{url}\\tarticles/{file}\\n\"", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "continue", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.prep_data.truncate": [[106, 156], ["enumerate", "print", "line.split", "len", "result.append", "print", "print", "line.split", "len", "print", "math.floor", "enumerate", "result.append", "print", "print", "source.split", "len", "min", "enumerate", "sum", "math.floor", "final_words_ar.append", "len", "len", "enumerate", "min", "len", "len", "str", "enumerate", "len", "len"], "function", ["None"], ["", "", "", "", "def", "truncate", "(", "corpus", ",", "separator_tag", ")", ":", "\n", "    ", "result", "=", "[", "]", "\n", "for", "count", ",", "line", "in", "enumerate", "(", "corpus", ")", ":", "\n", "        ", "print", "(", "f\"example number: {count}\"", ")", "\n", "line_word_split", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "line_word_split", ")", "<", "500", ":", "\n", "            ", "result", ".", "append", "(", "line", ")", "\n", "print", "(", "\"total length smaller than 500\"", ")", "\n", "print", "(", "\"=============================================\"", ")", "\n", "", "else", ":", "\n", "            ", "sources_split", "=", "line", ".", "split", "(", "separator_tag", ")", "\n", "# previous dataset had separator at the end of each example", "\n", "if", "sources_split", "[", "-", "1", "]", "==", "\"\"", ":", "\n", "                ", "del", "sources_split", "[", "-", "1", "]", "\n", "", "num_sources", "=", "len", "(", "sources_split", ")", "\n", "words_ar", "=", "[", "source", ".", "split", "(", ")", "for", "source", "in", "sources_split", "]", "\n", "num_words_ar", "=", "[", "len", "(", "words", ")", "for", "words", "in", "words_ar", "]", "\n", "print", "(", "f\"initial number of words: {str(num_words_ar)}\"", ")", "\n", "per_source_count", "=", "math", ".", "floor", "(", "TOTAL_WORDS", "/", "num_sources", ")", "\n", "total_ar", "=", "[", "0", "]", "*", "num_sources", "\n", "total", "=", "0", "\n", "done", "=", "{", "}", "\n", "while", "total", "<", "TOTAL_WORDS", "and", "len", "(", "done", ")", "<", "len", "(", "num_words_ar", ")", ":", "\n", "# e.g. total=499 and still trying to add -- just add from the first doc which isn't done", "\n", "                ", "if", "per_source_count", "==", "0", ":", "\n", "                    ", "for", "index", ",", "x", "in", "enumerate", "(", "total_ar", ")", ":", "\n", "                        ", "if", "index", "not", "in", "done", ":", "\n", "                            ", "total_ar", "[", "index", "]", "+=", "TOTAL_WORDS", "-", "total", "\n", "break", "\n", "", "", "break", "\n", "", "min_amount", "=", "min", "(", "min", "(", "[", "x", "for", "x", "in", "num_words_ar", "if", "x", ">", "0", "]", ")", ",", "per_source_count", ")", "\n", "total_ar", "=", "[", "x", "+", "min_amount", "if", "index", "not", "in", "done", "else", "x", "for", "index", ",", "x", "in", "enumerate", "(", "total_ar", ")", "]", "\n", "for", "index", ",", "val", "in", "enumerate", "(", "num_words_ar", ")", ":", "\n", "                    ", "if", "val", "==", "min_amount", ":", "\n", "                        ", "done", "[", "index", "]", "=", "True", "\n", "", "", "num_words_ar", "=", "[", "x", "-", "min_amount", "for", "x", "in", "num_words_ar", "]", "\n", "total", "=", "sum", "(", "total_ar", ")", "\n", "if", "len", "(", "done", ")", "==", "len", "(", "num_words_ar", ")", ":", "\n", "                    ", "break", "\n", "", "per_source_count", "=", "math", ".", "floor", "(", "(", "TOTAL_WORDS", "-", "total", ")", "/", "(", "len", "(", "num_words_ar", ")", "-", "len", "(", "done", ")", ")", ")", "\n", "", "final_words_ar", "=", "[", "]", "\n", "for", "count_words", ",", "words", "in", "enumerate", "(", "words_ar", ")", ":", "\n", "                ", "cur_string", "=", "\" \"", ".", "join", "(", "words", "[", ":", "total_ar", "[", "count_words", "]", "]", ")", "\n", "final_words_ar", ".", "append", "(", "cur_string", ")", "\n", "", "final_str", "=", "(", "\" \"", "+", "separator_tag", "+", "\" \"", ")", ".", "join", "(", "final_words_ar", ")", ".", "strip", "(", ")", "# e.g. \" story_separator_special_tag \"", "\n", "result", ".", "append", "(", "final_str", ")", "\n", "print", "(", "\"final word count for each source:\"", ",", "total_ar", ")", "\n", "print", "(", "\"=============================================\"", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.prep_data.clean_summary_str": [[157, 175], ["s.replace.lower", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace", "s.replace.replace"], "function", ["None"], ["", "def", "clean_summary_str", "(", "s", ")", ":", "\n", "    ", "s", "=", "s", ".", "lower", "(", ")", "\n", "s", "=", "s", ".", "replace", "(", "'<unk>'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'`'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'.'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "','", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "';'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'\\''", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'\\\"'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'('", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "')'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "s", "=", "s", ".", "replace", "(", "'<p>'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'</p>'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'<t>'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'</t>'", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'[!@#$]'", ",", "''", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._load_model": [[20, 33], ["hasattr", "spacy.load", "os.system", "spacy.load"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["@", "classmethod", "\n", "def", "_load_model", "(", "cls", ")", ":", "\n", "\n", "        ", "if", "not", "hasattr", "(", "cls", ",", "\"_en\"", ")", ":", "\n", "\n", "            ", "try", ":", "\n", "\n", "                ", "cls", ".", "_en", "=", "_spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "\n", "", "except", ":", "\n", "\n", "                ", "_system", "(", "\"python -m spacy download en_core_web_sm\"", ")", "\n", "cls", ".", "_en", "=", "_spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.__init__": [[34, 47], ["fragments.Fragments._load_model", "fragments.Fragments._normalize", "fragments.Fragments._normalize", "fragments.Fragments._match", "fragments.Fragments._tokenize", "summary.split", "fragments.Fragments._tokenize", "text.split"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._load_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._normalize", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._normalize", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._match", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._tokenize", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._tokenize"], ["", "", "", "def", "__init__", "(", "self", ",", "summary", ",", "text", ",", "tokenize", "=", "True", ",", "case", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "_load_model", "(", ")", "\n", "\n", "self", ".", "_tokens", "=", "tokenize", "\n", "\n", "self", ".", "summary", "=", "self", ".", "_tokenize", "(", "summary", ")", "if", "tokenize", "else", "summary", ".", "split", "(", ")", "\n", "self", ".", "text", "=", "self", ".", "_tokenize", "(", "text", ")", "if", "tokenize", "else", "text", ".", "split", "(", ")", "\n", "\n", "self", ".", "_norm_summary", "=", "self", ".", "_normalize", "(", "self", ".", "summary", ",", "case", ")", "\n", "self", ".", "_norm_text", "=", "self", ".", "_normalize", "(", "self", ".", "text", ",", "case", ")", "\n", "\n", "self", ".", "_match", "(", "self", ".", "_norm_summary", ",", "self", ".", "_norm_text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._tokenize": [[49, 59], ["fragments.Fragments._en"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Tokenizes input using the fastest possible SpaCy configuration.\n        This is optional, can be disabled in constructor.\n\n        \"\"\"", "\n", "\n", "return", "self", ".", "_en", "(", "text", ",", "disable", "=", "[", "\"tagger\"", ",", "\"parser\"", ",", "\"ner\"", ",", "\"textcat\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._normalize": [[61, 74], ["str().lower", "str", "str"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "tokens", ",", "case", "=", "False", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Lowercases and turns tokens into distinct words.\n\n        \"\"\"", "\n", "\n", "return", "[", "\n", "str", "(", "t", ")", ".", "lower", "(", ")", "\n", "if", "not", "case", "\n", "else", "str", "(", "t", ")", "\n", "for", "t", "in", "tokens", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.overlaps": [[77, 91], ["None"], "methods", ["None"], ["", "def", "overlaps", "(", "self", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Return a list of Fragments.Match objects between summary and text.\n        This is a list of named tuples of the form (summary, text, length):\n\n            - summary (int): the start index of the match in the summary\n            - text (int): the start index of the match in the reference\n            - length (int): the length of the extractive fragment\n\n        \"\"\"", "\n", "\n", "return", "self", ".", "_matches", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.strings": [[93, 141], ["enumerate", "fragments.Fragments.overlaps", "str"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.overlaps"], ["", "def", "strings", "(", "self", ",", "min_length", "=", "0", ",", "raw", "=", "None", ",", "summary_base", "=", "True", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Return a list of explicit match strings between the summary and reference.\n        Note that this will be in the same format as the strings are input. This is\n        important to remember if tokenization is done manually. If tokenization is\n        specified automatically on the raw strings, raw strings will automatically\n        be returned rather than SpaCy tokenized sequences.\n\n        Arguments:\n\n            - min_length (int): filter out overlaps shorter than this (default = 0)\n            - raw (bool): return raw input rather than stringified\n                - (default = False if automatic tokenization, True otherwise)\n            - summary_base (true): strings are based of summary text (default = True)\n\n        Returns:\n\n            - list of overlaps, where overlaps are strings or token sequences\n\n        \"\"\"", "\n", "\n", "# Compute the strings against the summary or the text?", "\n", "\n", "base", "=", "self", ".", "summary", "if", "summary_base", "else", "self", ".", "text", "\n", "\n", "# Generate strings, filtering out strings below the minimum length.", "\n", "\n", "strings", "=", "[", "\n", "base", "[", "i", ":", "i", "+", "length", "]", "\n", "for", "i", ",", "j", ",", "length", "\n", "in", "self", ".", "overlaps", "(", ")", "\n", "if", "length", ">", "min_length", "\n", "]", "\n", "\n", "# By default, we just return the tokenization being used.", "\n", "# But if they user wants a raw string, then we convert.", "\n", "# Mostly, this will be used along with spacy.", "\n", "\n", "if", "self", ".", "_tokens", "and", "raw", ":", "\n", "\n", "            ", "for", "i", ",", "s", "in", "enumerate", "(", "strings", ")", ":", "\n", "                ", "strings", "[", "i", "]", "=", "str", "(", "s", ")", "\n", "\n", "# Return the list of strings.", "\n", "\n", "", "", "return", "strings", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.coverage": [[143, 166], ["sum", "len", "len", "fragments.Fragments.overlaps"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.overlaps"], ["", "def", "coverage", "(", "self", ",", "summary_base", "=", "True", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Return the COVERAGE score of the summary and text.\n\n        Arguments:\n\n            - summary_base (bool): use summary as numerator (default = True)\n\n        Returns:\n\n            - decimal COVERAGE score within [0, 1]\n\n        \"\"\"", "\n", "\n", "numerator", "=", "sum", "(", "o", ".", "length", "for", "o", "in", "self", ".", "overlaps", "(", ")", ")", "\n", "\n", "if", "summary_base", ":", "denominator", "=", "len", "(", "self", ".", "summary", ")", "\n", "else", ":", "denominator", "=", "len", "(", "self", ".", "reference", ")", "\n", "\n", "if", "denominator", "==", "0", ":", "return", "0", "\n", "else", ":", "return", "numerator", "/", "denominator", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.density": [[168, 191], ["sum", "len", "len", "fragments.Fragments.overlaps"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.overlaps"], ["", "def", "density", "(", "self", ",", "summary_base", "=", "True", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Return the DENSITY score of summary and text.\n\n        Arguments:\n\n            - summary_base (bool): use summary as numerator (default = True)\n\n        Returns:\n\n            - decimal DENSITY score within [0, ...]\n\n        \"\"\"", "\n", "\n", "numerator", "=", "sum", "(", "o", ".", "length", "**", "2", "for", "o", "in", "self", ".", "overlaps", "(", ")", ")", "\n", "\n", "if", "summary_base", ":", "denominator", "=", "len", "(", "self", ".", "summary", ")", "\n", "else", ":", "denominator", "=", "len", "(", "self", ".", "reference", ")", "\n", "\n", "if", "denominator", "==", "0", ":", "return", "0", "\n", "else", ":", "return", "numerator", "/", "denominator", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.compression": [[193, 219], ["len", "len"], "methods", ["None"], ["", "def", "compression", "(", "self", ",", "text_to_summary", "=", "True", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Return compression ratio between summary and text.\n\n        Arguments:\n\n            - text_to_summary (bool): compute text/summary ratio (default = True)\n\n        Returns:\n\n            - decimal compression score within [0, ...]\n\n        \"\"\"", "\n", "\n", "ratio", "=", "[", "len", "(", "self", ".", "text", ")", ",", "len", "(", "self", ".", "summary", ")", "]", "\n", "\n", "try", ":", "\n", "\n", "            ", "if", "text_to_summary", ":", "return", "ratio", "[", "0", "]", "/", "ratio", "[", "1", "]", "\n", "else", ":", "return", "ratio", "[", "1", "]", "/", "ratio", "[", "0", "]", "\n", "\n", "", "except", "ZeroDivisionError", ":", "\n", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._match": [[221, 276], ["len", "len", "fragments.Fragments._matches.append", "Fragments.Match", "len", "len"], "methods", ["None"], ["", "", "def", "_match", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Raw procedure for matching summary in text, described in paper.\n\n        \"\"\"", "\n", "\n", "self", ".", "_matches", "=", "[", "]", "\n", "\n", "a_start", "=", "b_start", "=", "0", "\n", "\n", "while", "a_start", "<", "len", "(", "a", ")", ":", "\n", "\n", "            ", "best_match", "=", "None", "\n", "best_match_length", "=", "0", "\n", "\n", "while", "b_start", "<", "len", "(", "b", ")", ":", "\n", "\n", "                ", "if", "a", "[", "a_start", "]", "==", "b", "[", "b_start", "]", ":", "\n", "\n", "                    ", "a_end", "=", "a_start", "\n", "b_end", "=", "b_start", "\n", "\n", "while", "a_end", "<", "len", "(", "a", ")", "and", "b_end", "<", "len", "(", "b", ")", "and", "b", "[", "b_end", "]", "==", "a", "[", "a_end", "]", ":", "\n", "\n", "                        ", "b_end", "+=", "1", "\n", "a_end", "+=", "1", "\n", "\n", "", "length", "=", "a_end", "-", "a_start", "\n", "\n", "if", "length", ">", "best_match_length", ":", "\n", "\n", "                        ", "best_match", "=", "Fragments", ".", "Match", "(", "a_start", ",", "b_start", ",", "length", ")", "\n", "best_match_length", "=", "length", "\n", "\n", "", "b_start", "=", "b_end", "\n", "\n", "", "else", ":", "\n", "\n", "                    ", "b_start", "+=", "1", "\n", "\n", "", "", "b_start", "=", "0", "\n", "\n", "if", "best_match", ":", "\n", "\n", "                ", "if", "best_match_length", ">", "0", ":", "\n", "                    ", "self", ".", "_matches", ".", "append", "(", "best_match", ")", "\n", "\n", "", "a_start", "+=", "best_match_length", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "a_start", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._htmltokens": [[278, 293], ["html.escape().replace", "html.escape().replace", "html.escape", "html.escape"], "methods", ["None"], ["", "", "", "def", "_htmltokens", "(", "self", ",", "tokens", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Carefully process tokens to handle whitespace and HTML characters.\n\n        \"\"\"", "\n", "\n", "return", "[", "\n", "[", "\n", "_html", ".", "escape", "(", "t", ".", "text", ")", ".", "replace", "(", "\"\\n\"", ",", "\"<br/>\"", ")", ",", "\n", "_html", ".", "escape", "(", "t", ".", "whitespace_", ")", ".", "replace", "(", "\"\\n\"", ",", "\"<br/>\"", ")", "\n", "]", "\n", "\n", "for", "t", "in", "tokens", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.annotate": [[296, 397], ["fragments.Fragments._htmltokens", "fragments.Fragments._htmltokens", "fragments.Fragments._itercolors", "fragments.Fragments.overlaps", "random.randint", "next", "set", "set", "start.format", "start.format", "word_whitespace[].lower"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._htmltokens", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._htmltokens", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._itercolors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments.overlaps"], ["", "def", "annotate", "(", "self", ",", "min_length", "=", "0", ",", "text_truncation", "=", "None", ",", "novel_italics", "=", "False", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        Used to annotate fragments for website visualization.\n\n        Arguments:\n\n            - min_length (int): minimum length overlap to count (default = 0)\n            - text_truncation (int): tuncated text length (default = None)\n            - novel_italics (bool): italicize novel words (default = True)\n\n        Returns:\n\n            - a tuple of strings: (summary HTML, text HTML)\n\n        \"\"\"", "\n", "\n", "start", "=", "\"\"\"\n            <u\n            style=\"color: {color}; border-color: {color};\"\n            data-ref=\"{ref}\" title=\"Length: {length}\"\n            >\n        \"\"\"", ".", "strip", "(", ")", "\n", "\n", "end", "=", "\"\"\"\n            </u>\n        \"\"\"", ".", "strip", "(", ")", "\n", "\n", "# Here we tokenize carefully to preserve sane-looking whitespace.", "\n", "# (This part does require text to use a SpaCy tokenization.)", "\n", "\n", "summary", "=", "self", ".", "_htmltokens", "(", "self", ".", "summary", ")", "\n", "text", "=", "self", ".", "_htmltokens", "(", "self", ".", "text", ")", "\n", "\n", "# Compute novel word set, if requested.", "\n", "\n", "if", "novel_italics", ":", "\n", "\n", "            ", "novel", "=", "set", "(", "self", ".", "_norm_summary", ")", "-", "set", "(", "self", ".", "_norm_text", ")", "\n", "\n", "for", "word_whitespace", "in", "summary", ":", "\n", "\n", "                ", "if", "word_whitespace", "[", "0", "]", ".", "lower", "(", ")", "in", "novel", ":", "\n", "                    ", "word_whitespace", "[", "0", "]", "=", "\"<em>\"", "+", "word_whitespace", "[", "0", "]", "+", "\"</em>\"", "\n", "\n", "# Truncate text, if requested.", "\n", "# Must be careful later on with this.", "\n", "\n", "", "", "", "if", "text_truncation", "is", "not", "None", ":", "\n", "            ", "text", "=", "text", "[", ":", "text_truncation", "]", "\n", "\n", "# March through overlaps, replacing tokens with HTML-tagged strings.", "\n", "\n", "", "colors", "=", "self", ".", "_itercolors", "(", ")", "\n", "\n", "for", "overlap", "in", "self", ".", "overlaps", "(", ")", ":", "\n", "\n", "# Skip overlaps that are too short.", "\n", "\n", "            ", "if", "overlap", ".", "length", "<", "min_length", ":", "\n", "                ", "continue", "\n", "\n", "# Reference ID for JavaScript highlighting.", "\n", "# This is random, but shared between corresponding fragments.", "\n", "\n", "", "ref", "=", "_random", ".", "randint", "(", "0", ",", "1e10", ")", "\n", "color", "=", "next", "(", "colors", ")", "\n", "\n", "# Summary starting tag.", "\n", "\n", "summary", "[", "overlap", ".", "summary", "]", "[", "0", "]", "=", "start", ".", "format", "(", "\n", "color", "=", "color", ",", "\n", "ref", "=", "ref", ",", "\n", "length", "=", "overlap", ".", "length", ",", "\n", ")", "+", "summary", "[", "overlap", ".", "summary", "]", "[", "0", "]", "\n", "\n", "# Text starting tag.", "\n", "\n", "text", "[", "overlap", ".", "text", "]", "[", "0", "]", "=", "start", ".", "format", "(", "\n", "color", "=", "color", ",", "\n", "ref", "=", "ref", ",", "\n", "length", "=", "overlap", ".", "length", ",", "\n", ")", "+", "text", "[", "overlap", ".", "text", "]", "[", "0", "]", "\n", "\n", "# Summary ending tag.", "\n", "\n", "summary", "[", "overlap", ".", "summary", "+", "overlap", ".", "length", "-", "1", "]", "[", "0", "]", "+=", "end", "\n", "\n", "# Text ending tag.", "\n", "\n", "text", "[", "overlap", ".", "text", "+", "overlap", ".", "length", "-", "1", "]", "[", "0", "]", "+=", "end", "\n", "\n", "# Carefully join tokens and whitespace to reconstruct the string.", "\n", "\n", "", "summary", "=", "\" \"", ".", "join", "(", "\"\"", ".", "join", "(", "\"\"", ".", "join", "(", "tw", ")", "for", "tw", "in", "summary", ")", ".", "split", "(", ")", ")", "\n", "text", "=", "\" \"", ".", "join", "(", "\"\"", ".", "join", "(", "\"\"", ".", "join", "(", "tw", ")", "for", "tw", "in", "text", ")", ".", "split", "(", ")", ")", "\n", "\n", "# Return the tuple.", "\n", "\n", "return", "summary", ",", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scripts.fragments.Fragments._itercolors": [[399, 425], ["itertools.cycle"], "methods", ["None"], ["", "def", "_itercolors", "(", "self", ")", ":", "\n", "\n", "# Endlessly cycle through these colors.", "\n", "\n", "        ", "return", "_itertools", ".", "cycle", "(", "(", "\n", "\n", "\"#393b79\"", ",", "\n", "\"#5254a3\"", ",", "\n", "\"#6b6ecf\"", ",", "\n", "\"#9c9ede\"", ",", "\n", "\"#637939\"", ",", "\n", "\"#8ca252\"", ",", "\n", "\"#b5cf6b\"", ",", "\n", "\"#cedb9c\"", ",", "\n", "\"#8c6d31\"", ",", "\n", "\"#bd9e39\"", ",", "\n", "\"#e7ba52\"", ",", "\n", "\"#e7cb94\"", ",", "\n", "\"#843c39\"", ",", "\n", "\"#ad494a\"", ",", "\n", "\"#d6616b\"", ",", "\n", "\"#e7969c\"", ",", "\n", "\"#7b4173\"", ",", "\n", "\"#a55194\"", ",", "\n", "\"#ce6dbd\"", ",", "\n", "\"#de9ed6\"", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.pipelines.TutorialPipeline.process_item": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "process_item", "(", "self", ",", "item", ",", "spider", ")", ":", "\n", "        ", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialSpiderMiddleware.from_crawler": [[16, 22], ["cls", "crawler.signals.connect"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "from_crawler", "(", "cls", ",", "crawler", ")", ":", "\n", "# This method is used by Scrapy to create your spiders.", "\n", "        ", "s", "=", "cls", "(", ")", "\n", "crawler", ".", "signals", ".", "connect", "(", "s", ".", "spider_opened", ",", "signal", "=", "signals", ".", "spider_opened", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialSpiderMiddleware.process_spider_input": [[23, 29], ["None"], "methods", ["None"], ["", "def", "process_spider_input", "(", "self", ",", "response", ",", "spider", ")", ":", "\n", "# Called for each response that goes through the spider", "\n", "# middleware and into the spider.", "\n", "\n", "# Should return None or raise an exception.", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialSpiderMiddleware.process_spider_output": [[30, 37], ["None"], "methods", ["None"], ["", "def", "process_spider_output", "(", "self", ",", "response", ",", "result", ",", "spider", ")", ":", "\n", "# Called with the results returned from the Spider, after", "\n", "# it has processed the response.", "\n", "\n", "# Must return an iterable of Request, dict or Item objects.", "\n", "        ", "for", "i", "in", "result", ":", "\n", "            ", "yield", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialSpiderMiddleware.process_spider_exception": [[38, 45], ["None"], "methods", ["None"], ["", "", "def", "process_spider_exception", "(", "self", ",", "response", ",", "exception", ",", "spider", ")", ":", "\n", "# Called when a spider or process_spider_input() method", "\n", "# (from other spider middleware) raises an exception.", "\n", "\n", "# Should return either None or an iterable of Response, dict", "\n", "# or Item objects.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialSpiderMiddleware.process_start_requests": [[46, 54], ["None"], "methods", ["None"], ["", "def", "process_start_requests", "(", "self", ",", "start_requests", ",", "spider", ")", ":", "\n", "# Called with the start requests of the spider, and works", "\n", "# similarly to the process_spider_output() method, except", "\n", "# that it doesn\u2019t have a response associated.", "\n", "\n", "# Must return only requests (not items).", "\n", "        ", "for", "r", "in", "start_requests", ":", "\n", "            ", "yield", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialSpiderMiddleware.spider_opened": [[55, 57], ["spider.logger.info"], "methods", ["None"], ["", "", "def", "spider_opened", "(", "self", ",", "spider", ")", ":", "\n", "        ", "spider", ".", "logger", ".", "info", "(", "'Spider opened: %s'", "%", "spider", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialDownloaderMiddleware.from_crawler": [[64, 70], ["cls", "crawler.signals.connect"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "from_crawler", "(", "cls", ",", "crawler", ")", ":", "\n", "# This method is used by Scrapy to create your spiders.", "\n", "        ", "s", "=", "cls", "(", ")", "\n", "crawler", ".", "signals", ".", "connect", "(", "s", ".", "spider_opened", ",", "signal", "=", "signals", ".", "spider_opened", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialDownloaderMiddleware.process_request": [[71, 82], ["None"], "methods", ["None"], ["", "def", "process_request", "(", "self", ",", "request", ",", "spider", ")", ":", "\n", "# Called for each request that goes through the downloader", "\n", "# middleware.", "\n", "\n", "# Must either:", "\n", "# - return None: continue processing this request", "\n", "# - or return a Response object", "\n", "# - or return a Request object", "\n", "# - or raise IgnoreRequest: process_exception() methods of", "\n", "#   installed downloader middleware will be called", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialDownloaderMiddleware.process_response": [[83, 91], ["None"], "methods", ["None"], ["", "def", "process_response", "(", "self", ",", "request", ",", "response", ",", "spider", ")", ":", "\n", "# Called with the response returned from the downloader.", "\n", "\n", "# Must either;", "\n", "# - return a Response object", "\n", "# - return a Request object", "\n", "# - or raise IgnoreRequest", "\n", "        ", "return", "response", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialDownloaderMiddleware.process_exception": [[92, 101], ["None"], "methods", ["None"], ["", "def", "process_exception", "(", "self", ",", "request", ",", "exception", ",", "spider", ")", ":", "\n", "# Called when a download handler or a process_request()", "\n", "# (from other downloader middleware) raises an exception.", "\n", "\n", "# Must either:", "\n", "# - return None: continue processing this exception", "\n", "# - return a Response object: stops process_exception() chain", "\n", "# - return a Request object: stops process_exception() chain", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.scrapy_code.middlewares.TutorialDownloaderMiddleware.spider_opened": [[102, 104], ["spider.logger.info"], "methods", ["None"], ["", "def", "spider_opened", "(", "self", ",", "spider", ")", ":", "\n", "        ", "spider", ".", "logger", ".", "info", "(", "'Spider opened: %s'", "%", "spider", ".", "name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.spiders.quotes_spiders.MySpider1.start_requests": [[11, 19], ["open", "line.split.split.split", "scrapy.Request", "line[].strip", "line[].strip"], "methods", ["None"], ["def", "start_requests", "(", "self", ")", ":", "\n", "# TODO change to the path to the inputs.txt or summaries.txt fils", "\n", "        ", "with", "open", "(", "\"inputs.txt\"", ",", "\"r\"", ")", "as", "input", ":", "\n", "            ", "for", "line", "in", "input", ":", "\n", "                ", "line", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "req", "=", "scrapy", ".", "Request", "(", "url", "=", "line", "[", "0", "]", ".", "strip", "(", ")", ",", "callback", "=", "self", ".", "parse", ")", "\n", "req", ".", "meta", "[", "'filename'", "]", "=", "line", "[", "1", "]", ".", "strip", "(", ")", "\n", "yield", "req", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.spiders.quotes_spiders.MySpider1.parse": [[20, 26], ["quotes_spiders.MySpider1.log", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log"], ["", "", "", "def", "parse", "(", "self", ",", "response", ")", ":", "\n", "        ", "filename", "=", "response", ".", "meta", "[", "'filename'", "]", "\n", "# TODO change to the path where you want to store output html files", "\n", "with", "open", "(", "f\"{filename}\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "response", ".", "text", ")", "\n", "", "self", ".", "log", "(", "'Saved file %s'", "%", "filename", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.translate.main": [[18, 25], ["onmt.translate.translator.build_translator", "onmt.translate.translator.build_translator.translate"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.build_translator", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator.translate"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "translator", "=", "build_translator", "(", "opt", ",", "report_score", "=", "True", ")", "\n", "translator", ".", "translate", "(", "src_path", "=", "opt", ".", "src", ",", "\n", "tgt_path", "=", "opt", ".", "tgt", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "attn_debug", "=", "opt", ".", "attn_debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.train.ErrorHandler.__init__": [[82, 92], ["threading.Thread", "train.ErrorHandler.error_thread.start", "signal.signal"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start"], ["def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "        ", "\"\"\" init error handler \"\"\"", "\n", "import", "signal", "\n", "import", "threading", "\n", "self", ".", "error_queue", "=", "error_queue", "\n", "self", ".", "children_pids", "=", "[", "]", "\n", "self", ".", "error_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "error_listener", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_thread", ".", "start", "(", ")", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.train.ErrorHandler.add_child": [[93, 96], ["train.ErrorHandler.children_pids.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\" error handler \"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.train.ErrorHandler.error_listener": [[97, 102], ["train.ErrorHandler.error_queue.get", "train.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["", "def", "error_listener", "(", "self", ")", ":", "\n", "        ", "\"\"\" error listener \"\"\"", "\n", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "self", ".", "error_queue", ".", "put", "(", "(", "rank", ",", "original_trace", ")", ")", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.train.ErrorHandler.signal_handler": [[103, 112], ["train.ErrorHandler.error_queue.get", "Exception", "os.kill"], "methods", ["None"], ["", "def", "signal_handler", "(", "self", ",", "signalnum", ",", "stackframe", ")", ":", "\n", "        ", "\"\"\" signal handler \"\"\"", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "# kill children processes", "\n", "", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "msg", "=", "\"\"\"\\n\\n-- Tracebacks above this line can probably\n                 be ignored --\\n\\n\"\"\"", "\n", "msg", "+=", "original_trace", "\n", "raise", "Exception", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.train.main": [[24, 60], ["len", "AssertionError", "AssertionError", "AssertionError", "len", "AssertionError", "torch.multiprocessing.get_context", "torch.multiprocessing.get_context.SimpleQueue", "train.ErrorHandler", "range", "procs.append", "procs[].start", "onmt.utils.logging.logger.info", "train.ErrorHandler.add_child", "p.join", "onmt.train_single.main", "onmt.train_single.main", "torch.multiprocessing.get_context.Process"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.ErrorHandler.add_child", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.main", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.main"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "rnn_type", "==", "\"SRU\"", "and", "not", "opt", ".", "gpu_ranks", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Using SRU requires -gpu_ranks set.\"", ")", "\n", "\n", "", "if", "opt", ".", "epochs", ":", "\n", "        ", "raise", "AssertionError", "(", "\"-epochs is deprecated please use -train_steps.\"", ")", "\n", "\n", "", "if", "opt", ".", "truncated_decoder", ">", "0", "and", "opt", ".", "accum_count", ">", "1", ":", "\n", "        ", "raise", "AssertionError", "(", "\"BPTT is not compatible with -accum > 1\"", ")", "\n", "\n", "", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "raise", "AssertionError", "(", "\"gpuid is deprecated \\\n              see world_size and gpu_ranks\"", ")", "\n", "\n", "", "nb_gpu", "=", "len", "(", "opt", ".", "gpu_ranks", ")", "\n", "\n", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "        ", "mp", "=", "torch", ".", "multiprocessing", ".", "get_context", "(", "'spawn'", ")", "\n", "# Create a thread to listen for errors in the child processes.", "\n", "error_queue", "=", "mp", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "# Train with multiprocessing.", "\n", "procs", "=", "[", "]", "\n", "for", "device_id", "in", "range", "(", "nb_gpu", ")", ":", "\n", "            ", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "run", ",", "args", "=", "(", "\n", "opt", ",", "device_id", ",", "error_queue", ",", ")", ",", "daemon", "=", "True", ")", ")", "\n", "procs", "[", "device_id", "]", ".", "start", "(", ")", "\n", "logger", ".", "info", "(", "\" Starting process pid: %d  \"", "%", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "error_handler", ".", "add_child", "(", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "\n", "", "", "elif", "nb_gpu", "==", "1", ":", "# case 1 GPU only", "\n", "        ", "single_main", "(", "opt", ",", "0", ")", "\n", "", "else", ":", "# case only CPU", "\n", "        ", "single_main", "(", "opt", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.train.run": [[62, 76], ["onmt.utils.distributed.multi_init", "onmt.utils.distributed.multi_init", "onmt.train_single.main", "AssertionError", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.multi_init", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.multi_init", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.main"], ["", "", "def", "run", "(", "opt", ",", "device_id", ",", "error_queue", ")", ":", "\n", "    ", "\"\"\" run process \"\"\"", "\n", "try", ":", "\n", "        ", "gpu_rank", "=", "onmt", ".", "utils", ".", "distributed", ".", "multi_init", "(", "opt", ",", "device_id", ")", "\n", "if", "gpu_rank", "!=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ":", "\n", "            ", "raise", "AssertionError", "(", "\"An error occurred in \\\n                  Distributed initialization\"", ")", "\n", "", "single_main", "(", "opt", ",", "device_id", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# killed by parent, do nothing", "\n", "", "except", "Exception", ":", "\n", "# propagate exception to parent process, keeping original traceback", "\n", "        ", "import", "traceback", "\n", "error_queue", ".", "put", "(", "(", "opt", ".", "gpu_ranks", "[", "device_id", "]", ",", "traceback", ".", "format_exc", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.preprocess.check_existing_pt_files": [[20, 31], ["glob.glob", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Checking if there are existing .pt files to avoid tampering \"\"\"", "\n", "# We will use glob.glob() to find sharded {train|valid}.[0-9]*.pt", "\n", "# when training, so check to avoid tampering with existing pt files", "\n", "# or mixing them up.", "\n", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "pattern", "=", "opt", ".", "save_data", "+", "'.'", "+", "t", "+", "'*.pt'", "\n", "if", "glob", ".", "glob", "(", "pattern", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup existing pt file: %s, \"", "\n", "\"to avoid tampering!\\n\"", "%", "pattern", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.preprocess.parse_args": [[33, 48], ["argparse.ArgumentParser", "onmt.add_md_help_argument", "onmt.preprocess_opts", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "preprocess.check_existing_pt_files"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.add_md_help_argument", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.preprocess_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.check_existing_pt_files"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\" Parsing arguments \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'preprocess.py'", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n", "opts", ".", "add_md_help_argument", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.preprocess.build_save_in_shards": [[50, 122], ["os.path.getsize", "onmt.ShardedTextCorpusIterator", "onmt.ShardedTextCorpusIterator", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "inputters.ShardedTextCorpusIterator.hit_end", "onmt.TextDataset", "onmt.utils.logging.logger.info", "torch.save", "ret_list.append"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator.hit_end"], ["", "def", "build_save_in_shards", "(", "src_corpus", ",", "tgt_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Divide the big corpus into shards, and build dataset separately.\n    This is currently only for data_type=='text'.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n\n    To tackle this, we only read in part of the corpus file of size\n    `max_shard_size`(actually it is multiples of 64 bytes that equals\n    or is slightly larger than this size), and process it into dataset,\n    then write it to disk along the way. By doing this, we only focus on\n    part of the corpus at any moment, thus effectively reducing memory use.\n    According to test, this method can reduce memory footprint by ~50%.\n\n    Note! As we process along the shards, previous shards might still\n    stay in memory, but since we are done with them, and no more\n    reference to them, if there is memory tight situation, the OS could\n    easily reclaim these memory.\n\n    If `max_shard_size` is 0 or is larger than the corpus size, it is\n    effectively preprocessed into one dataset, i.e. no sharding.\n\n    NOTE! `max_shard_size` is measuring the input corpus size, not the\n    output pt file size. So a shard pt file consists of examples of size\n    2 * `max_shard_size`(source + target).\n    \"\"\"", "\n", "\n", "corpus_size", "=", "os", ".", "path", ".", "getsize", "(", "src_corpus", ")", "\n", "if", "corpus_size", ">", "10", "*", "(", "1024", "**", "2", ")", "and", "opt", ".", "max_shard_size", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"Warning. The corpus %s is larger than 10M bytes, \"", "\n", "\"you can set '-max_shard_size' to process it by \"", "\n", "\"small shards to use less memory.\"", "%", "src_corpus", ")", "\n", "\n", "", "if", "opt", ".", "max_shard_size", "!=", "0", ":", "\n", "        ", "logger", ".", "info", "(", "' * divide corpus into shards and build dataset '", "\n", "'separately (shard_size = %d bytes).'", "\n", "%", "opt", ".", "max_shard_size", ")", "\n", "\n", "", "ret_list", "=", "[", "]", "\n", "src_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "src_corpus", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"src\"", ",", "opt", ".", "max_shard_size", ")", "\n", "tgt_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "tgt_corpus", ",", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "\"tgt\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "\n", "index", "=", "0", "\n", "while", "not", "src_iter", ".", "hit_end", "(", ")", ":", "\n", "        ", "index", "+=", "1", "\n", "dataset", "=", "inputters", ".", "TextDataset", "(", "\n", "fields", ",", "src_iter", ",", "tgt_iter", ",", "\n", "src_iter", ".", "num_feats", ",", "tgt_iter", ".", "num_feats", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ")", "\n", "\n", "# We save fields in vocab.pt separately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "logger", ".", "info", "(", "\" * saving %s data shard to %s.\"", "\n", "%", "(", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "", "return", "ret_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.preprocess.build_save_in_shards_using_shards_size": [[124, 190], ["open().readlines", "open().readlines", "range", "sorted", "sorted", "enumerate", "int", "open().writelines", "open().writelines", "glob.glob", "glob.glob", "onmt.build_dataset", "onmt.utils.logging.logger.info", "torch.save", "ret_list.append", "gc.collect", "gc.collect", "open", "open", "src_corpus.split", "tgt_corpus.split", "len", "open", "open"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset"], ["", "def", "build_save_in_shards_using_shards_size", "(", "src_corpus", ",", "tgt_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Divide src_corpus and tgt_corpus into smaller multiples\n    src_copus and tgt corpus files, then build shards, each\n    shard will have opt.shard_size samples except last shard.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n    \"\"\"", "\n", "\n", "src_data", "=", "open", "(", "src_corpus", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "\n", "tgt_data", "=", "open", "(", "tgt_corpus", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "\n", "\n", "src_corpus", "=", "\"\"", ".", "join", "(", "src_corpus", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", "\n", "tgt_corpus", "=", "\"\"", ".", "join", "(", "tgt_corpus", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", "\n", "\n", "for", "x", "in", "range", "(", "int", "(", "len", "(", "src_data", ")", "/", "opt", ".", "shard_size", ")", ")", ":", "\n", "        ", "open", "(", "src_corpus", "+", "\".{0}.txt\"", ".", "format", "(", "x", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", ".", "writelines", "(", "\n", "src_data", "[", "x", "*", "opt", ".", "shard_size", ":", "(", "x", "+", "1", ")", "*", "opt", ".", "shard_size", "]", ")", "\n", "open", "(", "tgt_corpus", "+", "\".{0}.txt\"", ".", "format", "(", "x", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", ".", "writelines", "(", "\n", "tgt_data", "[", "x", "*", "opt", ".", "shard_size", ":", "(", "x", "+", "1", ")", "*", "opt", ".", "shard_size", "]", ")", "\n", "\n", "", "src_list", "=", "sorted", "(", "glob", ".", "glob", "(", "src_corpus", "+", "'.*.txt'", ")", ")", "\n", "tgt_list", "=", "sorted", "(", "glob", ".", "glob", "(", "tgt_corpus", "+", "'.*.txt'", ")", ")", "\n", "\n", "ret_list", "=", "[", "]", "\n", "\n", "for", "index", ",", "src", "in", "enumerate", "(", "src_list", ")", ":", "\n", "        ", "dataset", "=", "inputters", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "\n", "src_path", "=", "src", ",", "\n", "tgt_path", "=", "tgt_list", "[", "index", "]", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ",", "\n", "image_channel_size", "=", "opt", ".", "image_channel_size", "\n", ")", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "logger", ".", "info", "(", "\" * saving %sth %s data image shard to %s.\"", "\n", "%", "(", "index", ",", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "del", "dataset", ".", "examples", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "return", "ret_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.preprocess.build_save_dataset": [[192, 244], ["onmt.build_dataset", "onmt.utils.logging.logger.info", "torch.save", "preprocess.build_save_in_shards", "preprocess.build_save_in_shards_using_shards_size"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_in_shards", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_in_shards_using_shards_size"], ["", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the dataset \"\"\"", "\n", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "train_src", "\n", "tgt_corpus", "=", "opt", ".", "train_tgt", "\n", "", "else", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "valid_src", "\n", "tgt_corpus", "=", "opt", ".", "valid_tgt", "\n", "\n", "# Currently we only do preprocess sharding for corpus: data_type=='text'.", "\n", "", "if", "opt", ".", "data_type", "==", "'text'", ":", "\n", "        ", "return", "build_save_in_shards", "(", "\n", "src_corpus", ",", "tgt_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", "\n", "\n", "", "if", "(", "opt", ".", "shard_size", ">", "0", ")", ":", "\n", "        ", "return", "build_save_in_shards_using_shards_size", "(", "src_corpus", ",", "\n", "tgt_corpus", ",", "\n", "fields", ",", "\n", "corpus_type", ",", "\n", "opt", ")", "\n", "\n", "# For data_type == 'img' or 'audio', currently we don't do", "\n", "# preprocess sharding. We only build a monolithic dataset.", "\n", "# But since the interfaces are uniform, it would be not hard", "\n", "# to do this should users need this feature.", "\n", "", "dataset", "=", "inputters", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "\n", "src_path", "=", "src_corpus", ",", "\n", "tgt_path", "=", "tgt_corpus", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ",", "\n", "image_channel_size", "=", "opt", ".", "image_channel_size", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ")", "\n", "logger", ".", "info", "(", "\" * saving %s dataset to %s.\"", "%", "(", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "return", "[", "pt_file", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.preprocess.build_save_vocab": [[246, 260], ["onmt.build_vocab", "torch.save", "onmt.save_fields_to_vocab"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.save_fields_to_vocab"], ["", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the vocab \"\"\"", "\n", "fields", "=", "inputters", ".", "build_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "\n", "opt", ".", "share_vocab", ",", "\n", "opt", ".", "src_vocab", ",", "\n", "opt", ".", "src_vocab_size", ",", "\n", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab", ",", "\n", "opt", ".", "tgt_vocab_size", ",", "\n", "opt", ".", "tgt_words_min_frequency", ")", "\n", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "vocab_file", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "inputters", ".", "save_fields_to_vocab", "(", "fields", ")", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.preprocess.main": [[262, 287], ["preprocess.parse_args", "onmt.utils.logging.init_logger", "onmt.utils.logging.logger.info", "onmt.get_num_features", "onmt.get_num_features", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.get_fields", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_vocab"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.logging.init_logger", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_vocab"], ["", "def", "main", "(", ")", ":", "\n", "#pdb.set_trace()", "\n", "    ", "opt", "=", "parse_args", "(", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "logger", ".", "info", "(", "\"Extracting features...\"", ")", "\n", "\n", "# If there are special features added -- not in our case", "\n", "src_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_src", ",", "'src'", ")", "\n", "tgt_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_tgt", ",", "'tgt'", ")", "\n", "logger", ".", "info", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "logger", ".", "info", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building `Fields` object...\"", ")", "\n", "fields", "=", "inputters", ".", "get_fields", "(", "opt", ".", "data_type", ",", "src_nfeats", ",", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving training data...\"", ")", "\n", "train_dataset_files", "=", "build_save_dataset", "(", "'train'", ",", "fields", ",", "opt", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving validation data...\"", ")", "\n", "valid_dataset_files", "=", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "opt", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving vocabulary...\"", ")", "\n", "build_save_vocab", "(", "train_dataset_files", "+", "valid_dataset_files", ",", "fields", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.Hi_MAP.server.start": [[11, 104], ["flask.Flask", "server.start.prefix_route"], "function", ["None"], ["def", "start", "(", "config_file", ",", "\n", "url_root", "=", "\"./translator\"", ",", "\n", "host", "=", "\"0.0.0.0\"", ",", "\n", "port", "=", "5000", ",", "\n", "debug", "=", "True", ")", ":", "\n", "    ", "def", "prefix_route", "(", "route_function", ",", "prefix", "=", "''", ",", "mask", "=", "'{0}{1}'", ")", ":", "\n", "        ", "def", "newroute", "(", "route", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "route_function", "(", "mask", ".", "format", "(", "prefix", ",", "route", ")", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "newroute", "\n", "\n", "", "app", "=", "Flask", "(", "__name__", ")", "\n", "app", ".", "route", "=", "prefix_route", "(", "app", ".", "route", ",", "url_root", ")", "\n", "translation_server", "=", "TranslationServer", "(", ")", "\n", "translation_server", ".", "start", "(", "config_file", ")", "\n", "\n", "@", "app", ".", "route", "(", "'/models'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "get_models", "(", ")", ":", "\n", "        ", "out", "=", "translation_server", ".", "list_models", "(", ")", "\n", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/clone_model/<int:model_id>'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "clone_model", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "}", "\n", "data", "=", "request", ".", "get_json", "(", "force", "=", "True", ")", "\n", "timeout", "=", "-", "1", "\n", "if", "'timeout'", "in", "data", ":", "\n", "            ", "timeout", "=", "data", "[", "'timeout'", "]", "\n", "del", "data", "[", "'timeout'", "]", "\n", "\n", "", "opt", "=", "data", ".", "get", "(", "'opt'", ",", "None", ")", "\n", "try", ":", "\n", "            ", "model_id", ",", "load_time", "=", "translation_server", ".", "clone_model", "(", "\n", "model_id", ",", "opt", ",", "timeout", ")", "\n", "", "except", "ServerModelError", "as", "e", ":", "\n", "            ", "out", "[", "'status'", "]", "=", "STATUS_ERROR", "\n", "out", "[", "'error'", "]", "=", "str", "(", "e", ")", "\n", "", "else", ":", "\n", "            ", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "out", "[", "'model_id'", "]", "=", "model_id", "\n", "out", "[", "'load_time'", "]", "=", "load_time", "\n", "\n", "", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/unload_model/<int:model_id>'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "unload_model", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "\"model_id\"", ":", "model_id", "}", "\n", "\n", "try", ":", "\n", "            ", "translation_server", ".", "unload_model", "(", "model_id", ")", "\n", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "out", "[", "'status'", "]", "=", "STATUS_ERROR", "\n", "out", "[", "'error'", "]", "=", "str", "(", "e", ")", "\n", "\n", "", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/translate'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "translate", "(", ")", ":", "\n", "        ", "inputs", "=", "request", ".", "get_json", "(", "force", "=", "True", ")", "\n", "out", "=", "{", "}", "\n", "try", ":", "\n", "            ", "translation", ",", "scores", ",", "n_best", ",", "times", "=", "translation_server", ".", "run", "(", "inputs", ")", "\n", "assert", "len", "(", "translation", ")", "==", "len", "(", "inputs", ")", "\n", "assert", "len", "(", "scores", ")", "==", "len", "(", "inputs", ")", "\n", "\n", "out", "=", "[", "[", "{", "\"src\"", ":", "inputs", "[", "i", "]", "[", "'src'", "]", ",", "\"tgt\"", ":", "translation", "[", "i", "]", ",", "\n", "\"n_best\"", ":", "n_best", ",", "\n", "\"pred_score\"", ":", "scores", "[", "i", "]", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "translation", ")", ")", "]", "]", "\n", "", "except", "ServerModelError", "as", "e", ":", "\n", "            ", "out", "[", "'error'", "]", "=", "str", "(", "e", ")", "\n", "out", "[", "'status'", "]", "=", "STATUS_ERROR", "\n", "\n", "", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/to_cpu/<int:model_id>'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "to_cpu", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "'model_id'", ":", "model_id", "}", "\n", "translation_server", ".", "models", "[", "model_id", "]", ".", "to_cpu", "(", ")", "\n", "\n", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/to_gpu/<int:model_id>'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "to_gpu", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "'model_id'", ":", "model_id", "}", "\n", "translation_server", ".", "models", "[", "model_id", "]", ".", "to_gpu", "(", ")", "\n", "\n", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "app", ".", "run", "(", "debug", "=", "debug", ",", "host", "=", "host", ",", "port", "=", "port", ",", "use_reloader", "=", "False", ",", "\n", "threaded", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpFormatter._format_usage": [[578, 580], ["None"], "methods", ["None"], ["def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpFormatter.format_help": [[581, 585], ["print", "super().format_help"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpFormatter.format_help"], ["", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "_prog", ")", "\n", "self", ".", "_root_section", ".", "heading", "=", "'# Options: %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpFormatter.start_section": [[586, 589], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpFormatter.start_section"], ["", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'### **%s**'", "%", "heading", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpFormatter._format_action": [[590, 602], ["lines.append", "lines.extend", "opts.MarkdownHelpFormatter._expand_help", "lines.extend", "opts.MarkdownHelpFormatter._split_lines"], "methods", ["None"], ["", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", ".", "dest", "==", "\"help\"", "or", "action", ".", "dest", "==", "\"md\"", ":", "\n", "            ", "return", "\"\"", "\n", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'* **-%s %s** '", "%", "(", "action", ".", "dest", ",", "\n", "\"[%s]\"", "%", "action", ".", "default", "\n", "if", "action", ".", "default", "else", "\"[]\"", ")", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpAction.__init__": [[607, 616], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "argparse", ".", "SUPPRESS", ",", "default", "=", "argparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n", "dest", "=", "dest", ",", "\n", "default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.MarkdownHelpAction.__call__": [[617, 621], ["parser.print_help", "parser.exit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "parser", ".", "formatter_class", "=", "MarkdownHelpFormatter", "\n", "parser", ".", "print_help", "(", ")", "\n", "parser", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.DeprecateAction.__init__": [[626, 629], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.DeprecateAction.__call__": [[630, 634], ["argparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "mdhelp", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "argparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.model_opts": [[8, 135], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add_argument", "(", "'-src_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-share_decoder_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a shared weight matrix for the input and\n                       output word  embeddings in the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                       and decoder. Need to use shared dictionary for this\n                       option.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a sin to mark relative words positions.\n                       Necessary for non-RNN style models.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add_argument", "(", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"Merge action for incorporating features embeddings.\n                       Options [concat|sum|mlp].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"If specified, feature embedding sizes\n                       will be set to this. Otherwise, feat_vec_exponent\n                       will be used.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_exponent'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"\"\"If -feat_merge_size is not set, feature\n                       embedding sizes will be set to N^feat_vec_exponent\n                       where N is the number of values the feature takes.\"\"\"", ")", "\n", "\n", "# Encoder-Decoder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "help", "=", "\"\"\"Type of source model to use. Allows\n                       the system to incorporate non-text inputs.\n                       Options are [text|img|audio].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|brnn|mean|transformer|cnn].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of decoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|transformer|cnn].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Size of rnn hidden states'", ")", "\n", "group", ".", "add_argument", "(", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"\"\"Size of windows in the cnn, the kernel_size is\n                       (cnn_kernel_width, 1) in conv layer\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Feed the context vector at each time step as\n                       additional input (via concatenation with the word\n                       embeddings) to the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-bridge'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Have an additional layer between the last encoder\n                       state and the first decoder state\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "# group.add_argument('-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add_argument", "(", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"\"\"Type of context gate to use.\n                       Do not select for no context gate.\"\"\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                       dotprod or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-global_attention_function'", ",", "type", "=", "str", ",", "\n", "default", "=", "\"softmax\"", ",", "choices", "=", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ")", "\n", "group", ".", "add_argument", "(", "'-self_attn_type'", ",", "type", "=", "str", ",", "default", "=", "\"scaled-dot\"", ",", "\n", "help", "=", "\"\"\"Self attention type in Transformer decoder\n                       layer -- currently \"scaled-dot\" or \"average\" \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of heads for transformer self-attention'", ")", "\n", "group", ".", "add_argument", "(", "'-transformer_ff'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'Size of hidden transformer feed-forward'", ")", "\n", "\n", "# Generator and loss options.", "\n", "group", ".", "add_argument", "(", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-generator_function'", ",", "default", "=", "\"log_softmax\"", ",", "\n", "choices", "=", "[", "\"log_softmax\"", ",", "\"sparsemax\"", "]", ",", "\n", "help", "=", "\"\"\"Which function to use for generating\n                       probabilities over the target vocabulary (choices:\n                       log_softmax, sparsemax)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add_argument", "(", "'-reuse_copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Reuse standard attention for copy\"", ")", "\n", "group", ".", "add_argument", "(", "'-copy_loss_by_seqlength'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Divide copy loss by length of sequence\"", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.preprocess_opts": [[137, 243], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Pre-procesing options \"\"\"", "\n", "# Data options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"\"\"Type of the source input.\n                       Options are [text|img].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"For text corpus of large volume, it will\n                       be divided into shards of this size to preprocess.\n                       If 0, the data will be handled as a whole. The unit\n                       is in bytes. Optimal value should be multiples of\n                       64 bytes. A commonly used sharding value is 131072000.\n                       It is recommended to ensure the corpus is shuffled\n                       before sharding.\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Divide src_corpus and tgt_corpus into\n                       smaller multiple src_copus and tgt corpus files, then\n                       build shards, each shard will have\n                       opt.shard_size samples except last shard.\n                       shard_size=0 means no segmentation\n                       shard_size>0 means segment dataset into multiple shards,\n                       each shard has shard_size samples\"\"\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"\"\"Path to an existing source vocabulary. Format:\n                       one word per line.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"\"\"Path to an existing target vocabulary. Format:\n                       one word per line.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-features_vocabs_prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "group", ".", "add_argument", "(", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add_argument", "(", "'-image_channel_size'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"\"\"Using grayscale image can training\n                       model faster and smaller\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.train_opts": [[245, 437], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Training and saving options \"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add_argument", "(", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".train.pt\" and\n                       \".valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"\"\"Model filename (the model will be saved as\n                       <save_model>_N.pt where N is the number\n                       of steps\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_checkpoint_steps'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"\"\"Save a checkpoint every X steps\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-keep_checkpoint'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Keep X checkpoints (negative: keep all)\"\"\"", ")", "\n", "\n", "# GPU", "\n", "group", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Deprecated see world_size and gpu_ranks.\"", ")", "\n", "group", ".", "add_argument", "(", "'-gpu_ranks'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"list of ranks of each process.\"", ")", "\n", "group", ".", "add_argument", "(", "'-world_size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"total number of distributed processes.\"", ")", "\n", "group", ".", "add_argument", "(", "'-gpu_backend'", ",", "default", "=", "'nccl'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Type of torch distributed backend\"", ")", "\n", "group", ".", "add_argument", "(", "'-gpu_verbose_level'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Gives more info on each process per GPU.\"", ")", "\n", "group", ".", "add_argument", "(", "'-master_ip'", ",", "default", "=", "\"localhost\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"IP of master for torch.distributed training.\"", ")", "\n", "group", ".", "add_argument", "(", "'-master_port'", ",", "default", "=", "10000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Port of master for torch.distributed training.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                       reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                       with support (-param_init, param_init).\n                       Use 0 to not use initialization\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-param_init_glorot'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Init parameters with xavier_uniform.\n                       Required for transfomer.\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                       path to the pretrained model's state_dict.\"\"\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the encoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the decoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the decoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"\"\"Batch grouping for batch_size. Standard\n                               is sents. Tokens will do dynamic batching\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add_argument", "(", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Accumulate gradient this many times.\n                       Approximately equivalent to updating\n                       batch_size * accum_count batches at once.\n                       Recommended for Transformer.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "'Perfom validation every X steps'", ")", "\n", "group", ".", "add_argument", "(", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_steps'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "'Number of training steps'", ")", "\n", "group", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Deprecated epochs see train_steps'", ")", "\n", "group", ".", "add_argument", "(", "'-optim'", ",", "default", "=", "'sgd'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", ",", "\n", "'sparseadam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adagrad_accumulator_init'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Initializes the accumulator values in adagrad.\n                       Mirrors the initial_accumulator_value option\n                       in the tensorflow adagrad (use 0.1 for their default).\n                       \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                       renormalize it to have the norm equal to\n                       max_grad_norm\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add_argument", "(", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"\"\"The beta1 parameter used by Adam.\n                       Almost without exception a value of 0.9 is used in\n                       the literature, seemingly giving good results,\n                       so we would discourage changing this value from\n                       the default without due consideration.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "\"\"\"The beta2 parameter used by Adam.\n                       Typically a value of 0.999 is recommended, as this is\n                       the value suggested by the original paper describing\n                       Adam, and is also the value adopted in other frameworks\n                       such as Tensorflow and Kerras, i.e. see:\n                       https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n                       https://keras.io/optimizers/ .\n                       Whereas recently the paper \"Attention is All You Need\"\n                       suggested a value of 0.98 for beta2, this parameter may\n                       not work well for normal models / default\n                       baselines.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"\"\"Label smoothing value epsilon.\n                       Probabilities of all non-true labels\n                       will be smoothed by epsilon / (vocab_size - 1).\n                       Set to zero to turn off label smoothing.\n                       For more detailed information, see:\n                       https://arxiv.org/abs/1512.00567\"\"\"", ")", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                       Recommended settings: sgd = 1, adagrad = 0.1,\n                       adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by\n                       this much if (i) perplexity does not decrease on the\n                       validation set or (ii) steps have gone past\n                       start_decay_steps\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_decay_steps'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"\"\"Start decaying every decay_steps after\n                       start_decay_steps\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decay_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"\"\"Decay every decay_steps\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add_argument", "(", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "# Use TensorboardX for visualization during training", "\n", "group", ".", "add_argument", "(", "'-tensorboard'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Use tensorboardX for visualization during training.\n                       Must have the library tensorboardX.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "\"-tensorboard_log_dir\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"runs/onmt\"", ",", "\n", "help", "=", "\"\"\"Log directory for Tensorboard.\n                       This is also the name of the run.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add_argument", "(", "'-image_channel_size'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"\"\"Using grayscale image can training\n                       model faster and smaller\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.translate_opts": [[439, 554], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Translation / inference options \"\"\"", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add_argument", "(", "'-model'", ",", "dest", "=", "'models'", ",", "metavar", "=", "'MODEL'", ",", "\n", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file(s). '", "\n", "'Multiple models can be specified, '", "\n", "'for ensemble decoding.'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Source sequence to decode (one line per\n                       sequence)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt'", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will\n                       be the decoded sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report bleu score after translation,\n                       call tools/multi-bleu.perl on command line\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report rouge 1/2/3/L/SU4 score after translation\n                       call tools/test_rouge.py on command line\"\"\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add_argument", "(", "'-fast'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Use fast beam search (some features may not be\n                       supported!)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add_argument", "(", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add_argument", "(", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add_argument", "(", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add_argument", "(", "'-stepwise_penalty'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Apply penalty at every decoding step.\n                       Helpful for summary penalty.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-length_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'avg'", "]", ",", "\n", "help", "=", "\"\"\"Length Penalty to use.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'summary'", "]", ",", "\n", "help", "=", "\"\"\"Coverage Penalty to use.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"\"\"Google NMT length penalty parameter\n                        (higher = longer generation)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"\"\"Coverage penalty parameter\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-block_ngram_repeat'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Block repetition of ngrams during decoding.'", ")", "\n", "group", ".", "add_argument", "(", "'-ignore_when_blocking'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "\n", "default", "=", "[", "]", ",", "\n", "help", "=", "\"\"\"Ignore these strings when blocking repeats.\n                       You want to block sentence delimiters.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Replace the generated UNK tokens with the\n                       source token that had highest attention weight. If\n                       phrase_table is provided, it will lookup the\n                       identified source token and give the corresponding\n                       target token. If it is not provided(or the identified\n                       source token does not exist in the table) then it\n                       will copy the source token\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add_argument", "(", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add_argument", "(", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add_argument", "(", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add_argument", "(", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"If verbose is set, will output the n_best\n                       decoded sentences\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n", "# Option most relevant to image input", "\n", "group", ".", "add_argument", "(", "'-image_channel_size'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "choices", "=", "[", "3", ",", "1", "]", ",", "\n", "help", "=", "\"\"\"Using grayscale image can training\n                       model faster and smaller\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.add_md_help_argument": [[556, 560], ["parser.add_argument"], "function", ["None"], ["", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "\"\"\" md help parser \"\"\"", "\n", "parser", ".", "add_argument", "(", "'-md'", ",", "action", "=", "MarkdownHelpAction", ",", "\n", "help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer.__init__": [[89, 117], ["trainer.Trainer.model.train"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer.train"], ["\n", "\n", "def", "__init__", "(", "self", ",", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "\n", "trunc_size", "=", "0", ",", "shard_size", "=", "32", ",", "data_type", "=", "'text'", ",", "\n", "norm_method", "=", "\"sents\"", ",", "grad_accum_count", "=", "1", ",", "n_gpu", "=", "1", ",", "gpu_rank", "=", "1", ",", "\n", "gpu_verbose_level", "=", "0", ",", "report_manager", "=", "None", ",", "model_saver", "=", "None", ")", ":", "\n", "# Basic attributes.", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "train_loss", "=", "train_loss", "\n", "self", ".", "valid_loss", "=", "valid_loss", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "trunc_size", "=", "trunc_size", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "norm_method", "=", "norm_method", "\n", "self", ".", "grad_accum_count", "=", "grad_accum_count", "\n", "self", ".", "n_gpu", "=", "n_gpu", "\n", "self", ".", "gpu_rank", "=", "gpu_rank", "\n", "self", ".", "gpu_verbose_level", "=", "gpu_verbose_level", "\n", "self", ".", "report_manager", "=", "report_manager", "\n", "self", ".", "model_saver", "=", "model_saver", "\n", "\n", "assert", "grad_accum_count", ">", "0", "\n", "if", "grad_accum_count", ">", "1", ":", "\n", "            ", "assert", "(", "self", ".", "trunc_size", "==", "0", ")", ",", "\"\"\"To enable accumulated gradients,\n                   you must disable target sequence truncating.\"\"\"", "\n", "\n", "# Set model in training mode.", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer.train": [[118, 218], ["onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "train_iter_fct", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "trainer.Trainer._start_report_manager", "enumerate", "train_iter_fct", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "true_batchs.append", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "batch.tgt[].ne().sum", "batch.tgt[].ne().sum.item", "trainer.Trainer._gradient_accumulation", "trainer.Trainer._maybe_report_training", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "sum", "valid_iter_fct", "trainer.Trainer._maybe_gather_stats", "trainer.Trainer._report_step", "trainer.Trainer._maybe_save", "batch.tgt[].ne", "onmt.utils.distributed.all_gather_list", "onmt.utils.distributed.all_gather_list", "onmt.utils.distributed.all_gather_list", "onmt.utils.distributed.all_gather_list", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "torch.no_grad", "trainer.Trainer.validate", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._start_report_manager", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._gradient_accumulation", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._maybe_report_training", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._maybe_gather_stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr._report_step", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._maybe_save", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer.validate"], ["", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "", "def", "train", "(", "self", ",", "train_iter_fct", ",", "valid_iter_fct", ",", "train_steps", ",", "valid_steps", ")", ":", "\n", "        ", "\"\"\"\n        The main training loops.\n        by iterating over training data (i.e. `train_iter_fct`)\n        and running validation (i.e. iterating over `valid_iter_fct`\n\n        Args:\n            train_iter_fct(function): a function that returns the train\n                iterator. e.g. something like\n                train_iter_fct = lambda: generator(*args, **kwargs)\n            valid_iter_fct(function): same as train_iter_fct, for valid data\n            train_steps(int):\n            valid_steps(int):\n            save_checkpoint_steps(int):\n\n        Return:\n            None\n        \"\"\"", "\n", "logger", ".", "info", "(", "'Start training...'", ")", "\n", "\n", "step", "=", "self", ".", "optim", ".", "_step", "+", "1", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "total_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "self", ".", "_start_report_manager", "(", "start_time", "=", "total_stats", ".", "start_time", ")", "\n", "\n", "\n", "while", "step", "<=", "train_steps", ":", "\n", "            ", "reduce_counter", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "\n", "# import pdb; pdb.set_trace()", "\n", "\n", "                ", "if", "self", ".", "n_gpu", "==", "0", "or", "(", "i", "%", "self", ".", "n_gpu", "==", "self", ".", "gpu_rank", ")", ":", "\n", "                    ", "if", "self", ".", "gpu_verbose_level", ">", "1", ":", "\n", "                        ", "logger", ".", "info", "(", "\"GpuRank %d: index: %d accum: %d\"", "\n", "%", "(", "self", ".", "gpu_rank", ",", "i", ",", "accum", ")", ")", "\n", "\n", "", "true_batchs", ".", "append", "(", "batch", ")", "\n", "\n", "if", "self", ".", "norm_method", "==", "\"tokens\"", ":", "\n", "                        ", "num_tokens", "=", "batch", ".", "tgt", "[", "1", ":", "]", ".", "ne", "(", "\n", "self", ".", "train_loss", ".", "padding_idx", ")", ".", "sum", "(", ")", "\n", "normalization", "+=", "num_tokens", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                        ", "normalization", "+=", "batch", ".", "batch_size", "\n", "", "accum", "+=", "1", "\n", "if", "accum", "==", "self", ".", "grad_accum_count", ":", "\n", "                        ", "reduce_counter", "+=", "1", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                            ", "logger", ".", "info", "(", "\"GpuRank %d: reduce_counter: %d \\\n                                        n_minibatch %d\"", "\n", "%", "(", "self", ".", "gpu_rank", ",", "reduce_counter", ",", "\n", "len", "(", "true_batchs", ")", ")", ")", "\n", "", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                            ", "normalization", "=", "sum", "(", "onmt", ".", "utils", ".", "distributed", "\n", ".", "all_gather_list", "\n", "(", "normalization", ")", ")", "\n", "\n", "", "self", ".", "_gradient_accumulation", "(", "\n", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", "\n", "\n", "report_stats", "=", "self", ".", "_maybe_report_training", "(", "\n", "step", ",", "train_steps", ",", "\n", "self", ".", "optim", ".", "learning_rate", ",", "\n", "report_stats", ")", "\n", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "if", "(", "step", "%", "valid_steps", "==", "0", ")", ":", "\n", "                            ", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                                ", "logger", ".", "info", "(", "'GpuRank %d: validate step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "valid_iter", "=", "valid_iter_fct", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                                ", "valid_stats", "=", "self", ".", "validate", "(", "valid_iter", ")", "\n", "", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                                ", "logger", ".", "info", "(", "'GpuRank %d: gather valid stat \\\n                                            step %d'", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "valid_stats", "=", "self", ".", "_maybe_gather_stats", "(", "valid_stats", ")", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                                ", "logger", ".", "info", "(", "'GpuRank %d: report stat step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "self", ".", "_report_step", "(", "self", ".", "optim", ".", "learning_rate", ",", "\n", "step", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n", "", "if", "self", ".", "gpu_rank", "==", "0", ":", "\n", "                            ", "self", ".", "_maybe_save", "(", "step", ")", "\n", "", "step", "+=", "1", "\n", "if", "step", ">", "train_steps", ":", "\n", "                            ", "break", "\n", "", "", "", "", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                ", "logger", ".", "info", "("]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer.validate": [[219, 253], ["trainer.Trainer.model.eval", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "trainer.Trainer.model.train", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "trainer.Trainer.model", "trainer.Trainer.valid_loss.monolithic_compute_loss", "onmt.utils.Statistics.update", "onmt.utils.Statistics.update"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase.monolithic_compute_loss", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "", "return", "total_stats", "\n", "\n", "", "def", "validate", "(", "self", ",", "valid_iter", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "# Set model in validating mode.", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "\n", "\n", "for", "batch", "in", "valid_iter", ":", "\n", "            ", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "", "else", ":", "\n", "                ", "src_lengths", "=", "None", "\n", "\n", "", "tgt", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "\n", "# F-prop through the model.", "\n", "src_sents", "=", "batch", ".", "src_sents", "\n", "outputs", ",", "attns", ",", "_", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_sents", ",", "src_lengths", ")", "\n", "\n", "# Compute loss.", "\n", "batch_stats", "=", "self", ".", "valid_loss", ".", "monolithic_compute_loss", "(", "\n", "batch", ",", "outputs", ",", "attns", ")", "\n", "\n", "# Update statistics.", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._gradient_accumulation": [[254, 319], ["trainer.Trainer.model.zero_grad", "batch.tgt.size", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "range", "trainer.Trainer.optim.step", "src_lengths.sum().item", "trainer.Trainer.model", "trainer.Trainer.train_loss.sharded_compute_loss", "total_stats.update", "report_stats.update", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "trainer.Trainer.model.zero_grad", "trainer.Trainer.optim.step", "dec_state.detach", "float", "src_lengths.sum", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "trainer.Trainer.model.parameters", "float", "trainer.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase.sharded_compute_loss", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors"], ["stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# Set model back to training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "stats", "\n", "\n", "", "def", "_gradient_accumulation", "(", "self", ",", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "batch", "in", "true_batchs", ":", "\n", "#", "\n", "# the actual length is given:", "\n", "# >> batch.src_sents (tgt_sents)", "\n", "# >> tensor([10, 9, 5, 11, 10, 9, 10, 9, 9, 6], device='cuda:0')", "\n", "\n", "            ", "src_sents", "=", "batch", ".", "src_sents", "\n", "# print(src_sents)", "\n", "\n", "target_size", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "\n", "# Truncated BPTT: reminder not compatible with accum > 1", "\n", "if", "self", ".", "trunc_size", ":", "\n", "                ", "trunc_size", "=", "self", ".", "trunc_size", "\n", "", "else", ":", "\n", "                ", "trunc_size", "=", "target_size", "\n", "\n", "", "dec_state", "=", "None", "\n", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "# src size torch.Size([200, 10, 1])", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "report_stats", ".", "n_src_words", "+=", "src_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                ", "src_lengths", "=", "None", "\n", "\n", "", "tgt_outer", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "\n", "for", "j", "in", "range", "(", "0", ",", "target_size", "-", "1", ",", "trunc_size", ")", ":", "\n", "# 1. Create truncated target.", "\n", "                ", "tgt", "=", "tgt_outer", "[", "j", ":", "j", "+", "trunc_size", "]", "\n", "\n", "# 2. F-prop all but generator.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                    ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "\n", "#TODO: this is the input to the datasets", "\n", "", "outputs", ",", "attns", ",", "dec_state", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_sents", ",", "src_lengths", ",", "dec_state", ")", "\n", "\n", "# 3. Compute loss in shards for memory efficiency.", "\n", "batch_stats", "=", "self", ".", "train_loss", ".", "sharded_compute_loss", "(", "\n", "batch", ",", "outputs", ",", "attns", ",", "j", ",", "\n", "trunc_size", ",", "self", ".", "shard_size", ",", "normalization", ")", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# 4. Update the parameters and statistics.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "# Multi GPU gradient gather", "\n", "                    ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                        ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._start_report_manager": [[320, 329], ["trainer.Trainer.report_manager.start"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start"], ["grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# If truncated, don't backprop fully.", "\n", "", "if", "dec_state", "is", "not", "None", ":", "\n", "                    ", "dec_state", ".", "detach", "(", ")", "\n", "\n", "# in case of multi step gradient accumulation,", "\n", "# update only after accum batches", "\n", "", "", "", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._maybe_gather_stats": [[330, 344], ["onmt.utils.Statistics.all_gather_stats", "onmt.utils.Statistics.all_gather_stats", "onmt.utils.Statistics.all_gather_stats", "onmt.utils.Statistics.all_gather_stats"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats"], ["            ", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "", "", "def", "_start_report_manager", "(", "self", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to start report manager (if any)\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "if", "start_time", "is", "None", ":", "\n", "                ", "self", ".", "report_manager", ".", "start", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._maybe_report_training": [[345, 355], ["trainer.Trainer.report_manager.report_training"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase.report_training"], ["", "else", ":", "\n", "                ", "self", ".", "report_manager", ".", "start_time", "=", "start_time", "\n", "\n", "", "", "", "def", "_maybe_gather_stats", "(", "self", ",", "stat", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._report_step": [[356, 366], ["trainer.Trainer.report_manager.report_step"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase.report_step"], ["\n", "if", "stat", "is", "not", "None", "and", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "return", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "stat", ")", "\n", "", "return", "stat", "\n", "\n", "", "def", "_maybe_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer._maybe_save": [[367, 373], ["trainer.Trainer.model_saver.maybe_save"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaverBase.maybe_save"], ["\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ",", "\n", "multigpu", "=", "self", ".", "n_gpu", ">", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.build_trainer": [[23, 62], ["onmt.utils.loss.build_loss_compute", "onmt.utils.loss.build_loss_compute", "onmt.utils.loss.build_loss_compute", "onmt.utils.loss.build_loss_compute", "onmt.utils.build_report_manager", "onmt.utils.build_report_manager", "onmt.Trainer", "onmt.Trainer"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.build_loss_compute", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.build_report_manager", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.build_report_manager"], ["def", "build_trainer", "(", "opt", ",", "device_id", ",", "model", ",", "fields", ",", "\n", "optim", ",", "data_type", ",", "model_saver", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Simplify `Trainer` creation based on user `opt`s*\n\n    Args:\n        opt (:obj:`Namespace`): user options (usually from argument parsing)\n        model (:obj:`onmt.models.NMTModel`): the model to train\n        fields (dict): dict of fields\n        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n        data_type (str): string describing the type of data\n            e.g. \"text\", \"img\", \"audio\"\n        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n            used to save the model\n    \"\"\"", "\n", "# fine", "\n", "\n", "train_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "build_loss_compute", "(", "\n", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "valid_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "build_loss_compute", "(", "\n", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ",", "train", "=", "False", ")", "\n", "\n", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "shard_size", "=", "opt", ".", "max_generator_batches", "\n", "norm_method", "=", "opt", ".", "normalization", "\n", "grad_accum_count", "=", "opt", ".", "accum_count", "\n", "n_gpu", "=", "opt", ".", "world_size", "\n", "if", "device_id", ">=", "0", ":", "\n", "        ", "gpu_rank", "=", "opt", ".", "gpu_ranks", "[", "device_id", "]", "\n", "", "else", ":", "\n", "        ", "gpu_rank", "=", "0", "\n", "n_gpu", "=", "0", "\n", "", "gpu_verbose_level", "=", "opt", ".", "gpu_verbose_level", "\n", "\n", "report_manager", "=", "onmt", ".", "utils", ".", "build_report_manager", "(", "opt", ")", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "trunc_size", ",", "\n", "shard_size", ",", "data_type", ",", "norm_method", ",", "\n", "grad_accum_count", ",", "n_gpu", ",", "gpu_rank", ",", "\n", "gpu_verbose_level", ",", "report_manager", ",", "\n", "model_saver", "=", "model_saver", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings": [[29, 62], ["len", "onmt.modules.Embeddings", "len"], "function", ["None"], ["def", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ",", "for_encoder", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Build an Embeddings instance.\n    Args:\n        opt: the option in current environment.\n        word_dict(Vocab): words dictionary.\n        feature_dicts([Vocab], optional): a list of feature dictionary.\n        for_encoder(bool): build Embeddings for encoder or decoder?\n    \"\"\"", "\n", "if", "for_encoder", ":", "\n", "        ", "embedding_dim", "=", "opt", ".", "src_word_vec_size", "\n", "", "else", ":", "\n", "        ", "embedding_dim", "=", "opt", ".", "tgt_word_vec_size", "\n", "\n", "", "word_padding_idx", "=", "word_dict", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "num_word_embeddings", "=", "len", "(", "word_dict", ")", "\n", "\n", "feats_padding_idx", "=", "[", "feat_dict", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "for", "feat_dict", "in", "feature_dicts", "]", "\n", "num_feat_embeddings", "=", "[", "len", "(", "feat_dict", ")", "for", "feat_dict", "in", "\n", "feature_dicts", "]", "\n", "\n", "\n", "return", "Embeddings", "(", "word_vec_size", "=", "embedding_dim", ",", "\n", "position_encoding", "=", "opt", ".", "position_encoding", ",", "\n", "feat_merge", "=", "opt", ".", "feat_merge", ",", "\n", "feat_vec_exponent", "=", "opt", ".", "feat_vec_exponent", ",", "\n", "feat_vec_size", "=", "opt", ".", "feat_vec_size", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "word_padding_idx", "=", "word_padding_idx", ",", "\n", "feat_padding_idx", "=", "feats_padding_idx", ",", "\n", "word_vocab_size", "=", "num_word_embeddings", ",", "\n", "feat_vocab_sizes", "=", "num_feat_embeddings", ",", "\n", "sparse", "=", "opt", ".", "optim", "==", "\"sparseadam\"", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder": [[64, 86], ["onmt.encoders.transformer.TransformerEncoder", "onmt.encoders.cnn_encoder.CNNEncoder", "onmt.encoders.mean_encoder.MeanEncoder", "onmt.encoders.rnn_encoder.RNNEncoder"], "function", ["None"], ["\n", "", "def", "build_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various encoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this encoder.\n    \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "\"transformer\"", ":", "\n", "# return TransformerEncoder(opt.enc_layers, opt.rnn_size,", "\n", "#                           opt.heads, opt.transformer_ff,", "\n", "#                           opt.dropout, embeddings)", "\n", "        ", "return", "None", "\n", "", "elif", "opt", ".", "encoder_type", "==", "\"cnn\"", ":", "\n", "        ", "return", "CNNEncoder", "(", "opt", ".", "enc_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "\n", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "", "elif", "opt", ".", "encoder_type", "==", "\"mean\"", ":", "\n", "        ", "return", "MeanEncoder", "(", "opt", ".", "enc_layers", ",", "embeddings", ")", "\n", "", "else", ":", "\n", "# \"rnn\" or \"brnn\"", "\n", "        ", "return", "RNNEncoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "embeddings", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder": [[88, 128], ["onmt.decoders.transformer.TransformerDecoder", "onmt.decoders.cnn_decoder.CNNDecoder", "onmt.decoders.decoder.InputFeedRNNDecoder", "onmt.decoders.decoder.StdRNNDecoder"], "function", ["None"], ["\n", "\n", "", "", "def", "build_decoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various decoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this decoder.\n    \"\"\"", "\n", "if", "opt", ".", "decoder_type", "==", "\"transformer\"", ":", "\n", "        ", "return", "TransformerDecoder", "(", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "heads", ",", "opt", ".", "transformer_ff", ",", "\n", "opt", ".", "global_attention", ",", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "self_attn_type", ",", "\n", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "", "elif", "opt", ".", "decoder_type", "==", "\"cnn\"", ":", "\n", "        ", "return", "CNNDecoder", "(", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "", "elif", "opt", ".", "input_feed", ":", "\n", "# others", "\n", "        ", "return", "InputFeedRNNDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "global_attention_function", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "reuse_copy_attn", ")", "\n", "", "else", ":", "\n", "        ", "return", "StdRNNDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "global_attention_function", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.load_test_model": [[130, 146], ["torch.load", "torch.load", "onmt.load_fields_from_vocab", "model_builder.build_base_model", "build_base_model.eval", "build_base_model.generator.eval", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.use_gpu"], ["opt", ".", "reuse_copy_attn", ")", "\n", "\n", "\n", "", "", "def", "load_test_model", "(", "opt", ",", "dummy_opt", ",", "model_path", "=", "None", ")", ":", "\n", "\n", "\n", "    ", "if", "model_path", "is", "None", ":", "\n", "        ", "model_path", "=", "opt", ".", "models", "[", "0", "]", "# 'cnndm_sent_step_50.pt'", "\n", "\n", "# model_path add", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "fields", "=", "inputters", ".", "load_fields_from_vocab", "(", "\n", "checkpoint", "[", "'vocab'", "]", ",", "data_type", "=", "opt", ".", "data_type", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "for", "arg", "in", "dummy_opt", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_base_model": [[148, 256], ["filter", "sum", "onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_decoder", "torch.device", "torch.device", "onmt.models.NMTModel", "onmt.models.NMTModel", "onmt.models.NMTModel.to", "onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_encoder", "onmt.encoders.audio_encoder.AudioEncoder.parameters", "torch.Sequential", "onmt.modules.CopyGenerator", "onmt.models.NMTModel.load_state_dict", "onmt.modules.CopyGenerator.load_state_dict", "hasattr", "hasattr", "onmt.encoders.image_encoder.ImageEncoder", "numpy.prod", "AssertionError", "onmt.modules.sparse_activations.LogSparsemax", "onmt.modules.sparse_activations.LogSparsemax", "torch.LogSoftmax", "torch.Linear", "onmt.models.NMTModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.NMTModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.NMTModel.encoder.embeddings.load_pretrained_vectors", "onmt.models.NMTModel.decoder.embeddings.load_pretrained_vectors", "onmt.encoders.audio_encoder.AudioEncoder", "p.size", "len", "p.data.uniform_", "p.data.uniform_", "p.dim", "torch.nn.init.xavier_uniform_", "p.dim", "torch.nn.init.xavier_uniform_"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.image_encoder.ImageEncoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.image_encoder.ImageEncoder.load_pretrained_vectors"], ["            ", "model_opt", ".", "__dict__", "[", "arg", "]", "=", "dummy_opt", "[", "arg", "]", "\n", "", "", "model", "=", "build_base_model", "(", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "generator", ".", "eval", "(", ")", "\n", "return", "fields", ",", "model", ",", "model_opt", "\n", "\n", "\n", "", "def", "build_base_model", "(", "model_opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        model_opt: the option loaded from checkpoint.\n        fields: `Field` objects for the model.\n        gpu(bool): whether to use gpu.\n        checkpoint: the model gnerated by train phase, or a resumed snapshot\n                    model from a stopped training.\n    Returns:\n        the NMTModel.\n    \"\"\"", "\n", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", ",", "\"img\"", ",", "\"audio\"", "]", ",", "(", "\"Unsupported model type %s\"", "%", "(", "model_opt", ".", "model_type", ")", ")", "\n", "\n", "# Build encoder.", "\n", "if", "model_opt", ".", "model_type", "==", "\"text\"", ":", "\n", "        ", "src_dict", "=", "fields", "[", "\"src\"", "]", ".", "vocab", "\n", "\n", "feature_dicts", "=", "inputters", ".", "collect_feature_vocabs", "(", "fields", ",", "'src'", ")", "\n", "src_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "src_dict", ",", "feature_dicts", ")", "\n", "encoder", "=", "build_encoder", "(", "model_opt", ",", "src_embeddings", ")", "\n", "\n", "\n", "", "elif", "model_opt", ".", "model_type", "==", "\"img\"", ":", "\n", "        ", "if", "(", "\"image_channel_size\"", "not", "in", "model_opt", ".", "__dict__", ")", ":", "\n", "            ", "image_channel_size", "=", "3", "\n", "", "else", ":", "\n", "            ", "image_channel_size", "=", "model_opt", ".", "image_channel_size", "\n", "\n", "", "encoder", "=", "ImageEncoder", "(", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "rnn_size", ",", "\n", "model_opt", ".", "dropout", ",", "\n", "image_channel_size", ")", "\n", "", "elif", "model_opt", ".", "model_type", "==", "\"audio\"", ":", "\n", "        ", "encoder", "=", "AudioEncoder", "(", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "rnn_size", ",", "\n", "model_opt", ".", "dropout", ",", "\n", "model_opt", ".", "sample_rate", ",", "\n", "model_opt", ".", "window_size", ")", "\n", "\n", "", "model_parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "encoder", ".", "parameters", "(", ")", ")", "\n", "params", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "model_parameters", "]", ")", "\n", "# Build decoder.", "\n", "tgt_dict", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "inputters", ".", "collect_feature_vocabs", "(", "fields", ",", "'tgt'", ")", "\n", "tgt_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "tgt_dict", ",", "\n", "feature_dicts", ",", "for_encoder", "=", "False", ")", "\n", "\n", "# Share the embedding matrix - preprocess with share_vocab required.", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "# src/tgt vocab should be the same if `-share_vocab` is specified.", "\n", "        ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "            ", "raise", "AssertionError", "(", "'The `-share_vocab` should be set during '", "\n", "'preprocess if you use share_embeddings!'", ")", "\n", "\n", "", "tgt_embeddings", ".", "word_lut", ".", "weight", "=", "src_embeddings", ".", "word_lut", ".", "weight", "\n", "\n", "", "decoder", "=", "build_decoder", "(", "model_opt", ",", "tgt_embeddings", ")", "\n", "\n", "# Build NMTModel(= encoder + decoder).", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "gpu", "else", "\"cpu\"", ")", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "NMTModel", "(", "encoder", ",", "decoder", ")", "\n", "model", ".", "model_type", "=", "model_opt", ".", "model_type", "\n", "\n", "# Build Generator.", "\n", "if", "not", "model_opt", ".", "copy_attn", ":", "\n", "        ", "if", "model_opt", ".", "generator_function", "==", "\"sparsemax\"", ":", "\n", "            ", "gen_func", "=", "onmt", ".", "modules", ".", "sparse_activations", ".", "LogSparsemax", "(", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "gen_func", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", ",", "gen_func", "\n", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "            ", "generator", "[", "0", "]", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "", "else", ":", "\n", "        ", "generator", "=", "CopyGenerator", "(", "model_opt", ".", "rnn_size", ",", "\n", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "model_opt", ".", "param_init_glorot", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "if", "hasattr", "(", "model", ".", "encoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "encoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_model": [[258, 265], ["onmt.utils.logging.logger.info", "model_builder.build_base_model", "onmt.utils.logging.logger.info", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.use_gpu"], ["", "if", "hasattr", "(", "model", ".", "decoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_dec", ",", "model_opt", ".", "fix_word_vecs_dec", ")", "\n", "\n", "# Add generator to model (this registers it as parameter of model).", "\n", "", "", "model", ".", "generator", "=", "generator", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.train_single._check_save_model_path": [[24, 29], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "_check_save_model_path", "(", "opt", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.train_single._tally_parameters": [[31, 41], ["sum", "model.named_parameters", "p.nelement", "param.nelement", "model.parameters", "param.nelement"], "function", ["None"], ["", "", "def", "_tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'decoder'", "or", "'generator'", "in", "name", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "return", "n_params", ",", "enc", ",", "dec", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.train_single.training_opt_postprocessing": [[43, 77], ["AssertionError", "torch.cuda.is_available", "onmt.utils.logging.logger.info", "torch.manual_seed", "random.seed", "torch.cuda.set_device", "torch.cuda.manual_seed"], "function", ["None"], ["", "def", "training_opt_postprocessing", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "if", "opt", ".", "word_vec_size", "!=", "-", "1", ":", "\n", "        ", "opt", ".", "src_word_vec_size", "=", "opt", ".", "word_vec_size", "\n", "opt", ".", "tgt_word_vec_size", "=", "opt", ".", "word_vec_size", "\n", "\n", "", "if", "opt", ".", "layers", "!=", "-", "1", ":", "\n", "        ", "opt", ".", "enc_layers", "=", "opt", ".", "layers", "\n", "opt", ".", "dec_layers", "=", "opt", ".", "layers", "\n", "\n", "", "opt", ".", "brnn", "=", "(", "opt", ".", "encoder_type", "==", "\"brnn\"", ")", "\n", "\n", "if", "opt", ".", "rnn_type", "==", "\"SRU\"", "and", "not", "opt", ".", "gpu_ranks", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Using SRU requires -gpu_ranks set.\"", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "opt", ".", "gpu_ranks", ":", "\n", "        ", "logger", ".", "info", "(", "\"WARNING: You have a CUDA device, \\\n                    should run with -gpu_ranks\"", ")", "\n", "\n", "", "if", "opt", ".", "seed", ">", "0", ":", "\n", "        ", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "# this one is needed for torchtext random call (shuffled iterator)", "\n", "# in multi gpu it ensures datasets are read in the same order", "\n", "random", ".", "seed", "(", "opt", ".", "seed", ")", "\n", "# some cudnn methods can be random even after fixing the seed", "\n", "# unless you tell it to be deterministic", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "", "if", "device_id", ">=", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "if", "opt", ".", "seed", ">", "0", ":", "\n", "# These ensure same initialization in multi gpu mode", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "", "", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.train_single.main": [[79, 140], ["train_single.training_opt_postprocessing", "onmt.utils.logging.init_logger", "next", "onmt.inputters.inputter._load_fields", "onmt.inputters.inputter._collect_report_features", "enumerate", "enumerate", "onmt.model_builder.build_model", "train_single._tally_parameters", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "train_single._check_save_model_path", "onmt.utils.optimizers.build_optim", "onmt.models.build_model_saver", "onmt.trainer.build_trainer", "onmt.trainer.build_trainer.train", "onmt.utils.logging.logger.info", "torch.load", "onmt.inputters.inputter.lazily_load_dataset", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.inputters.inputter.build_dataset_iter", "onmt.inputters.inputter.build_dataset_iter", "onmt.trainer.build_trainer.report_manager.tensorboard_writer.close", "onmt.inputters.inputter.lazily_load_dataset", "onmt.inputters.inputter.lazily_load_dataset", "len", "len"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.train_single.training_opt_postprocessing", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.logging.init_logger", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._load_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._collect_report_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.train_single._tally_parameters", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.train_single._check_save_model_path", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.build_optim", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.build_model_saver", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.build_trainer", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.lazily_load_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.lazily_load_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.lazily_load_dataset"], ["", "def", "main", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "opt", "=", "training_opt_postprocessing", "(", "opt", ",", "device_id", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Peek the first dataset to determine the data_type.", "\n", "# (All datasets have the same data_type).", "\n", "", "first_dataset", "=", "next", "(", "lazily_load_dataset", "(", "\"train\"", ",", "opt", ")", ")", "\n", "data_type", "=", "first_dataset", ".", "data_type", "\n", "\n", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "fields", "=", "_load_fields", "(", "first_dataset", ",", "data_type", ",", "opt", ",", "checkpoint", ")", "\n", "\n", "\n", "\n", "# Report src/tgt features.", "\n", "\n", "src_features", ",", "tgt_features", "=", "_collect_report_features", "(", "fields", ")", "\n", "\n", "\n", "\n", "for", "j", ",", "feat", "in", "enumerate", "(", "src_features", ")", ":", "\n", "        ", "logger", ".", "info", "(", "' * src feature %d size = %d'", "\n", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "", "for", "j", ",", "feat", "in", "enumerate", "(", "tgt_features", ")", ":", "\n", "        ", "logger", ".", "info", "(", "' * tgt feature %d size = %d'", "\n", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "# Build model.", "\n", "#pdb.set_trace()", "\n", "", "model", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ")", "\n", "n_params", ",", "enc", ",", "dec", "=", "_tally_parameters", "(", "model", ")", "\n", "logger", ".", "info", "(", "'encoder: %d'", "%", "enc", ")", "\n", "logger", ".", "info", "(", "'decoder: %d'", "%", "dec", ")", "\n", "logger", ".", "info", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "_check_save_model_path", "(", "opt", ")", "\n", "\n", "# Build optimizer.", "\n", "optim", "=", "build_optim", "(", "model", ",", "opt", ",", "checkpoint", ")", "\n", "\n", "# Build model saver", "\n", "model_saver", "=", "build_model_saver", "(", "model_opt", ",", "opt", ",", "model", ",", "fields", ",", "optim", ")", "\n", "\n", "trainer", "=", "build_trainer", "(", "opt", ",", "device_id", ",", "model", ",", "fields", ",", "\n", "optim", ",", "data_type", ",", "model_saver", "=", "model_saver", ")", "\n", "\n", "def", "train_iter_fct", "(", ")", ":", "\n", "\n", "        ", "return", "build_dataset_iter", "(", "\n", "lazily_load_dataset", "(", "\"train\"", ",", "opt", ")", ",", "fields", ",", "opt", ")", "\n", "\n", "", "def", "valid_iter_fct", "(", ")", ":", "return", "build_dataset_iter", "(", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.__init__": [[22, 28], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loss", "=", "0", ",", "n_words", "=", "0", ",", "n_correct", "=", "0", ")", ":", "\n", "        ", "self", ".", "loss", "=", "loss", "\n", "self", ".", "n_words", "=", "n_words", "\n", "self", ".", "n_correct", "=", "n_correct", "\n", "self", ".", "n_src_words", "=", "0", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats": [[29, 44], ["statistics.Statistics.all_gather_stats_list"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats_list"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats", "(", "stat", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` object accross multiple process/nodes\n\n        Args:\n            stat(:obj:Statistics): the statistics object to gather\n                accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            `Statistics`, the update stats object\n        \"\"\"", "\n", "stats", "=", "Statistics", ".", "all_gather_stats_list", "(", "[", "stat", "]", ",", "max_size", "=", "max_size", ")", "\n", "return", "stats", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats_list": [[45, 69], ["onmt.utils.distributed.all_gather_list", "torch.distributed.get_rank", "enumerate", "enumerate", "our_stats[].update"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["", "@", "staticmethod", "\n", "def", "all_gather_stats_list", "(", "stat_list", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "\"\"\"\n        Gather a `Statistics` list accross all processes/nodes\n\n        Args:\n            stat_list(list([`Statistics`])): list of statistics objects to\n                gather accross all processes/nodes\n            max_size(int): max buffer size to use\n\n        Returns:\n            our_stats(list([`Statistics`])): list of updated stats\n        \"\"\"", "\n", "# Get a list of world_size lists with len(stat_list) Statistics objects", "\n", "all_stats", "=", "all_gather_list", "(", "stat_list", ",", "max_size", "=", "max_size", ")", "\n", "\n", "our_rank", "=", "get_rank", "(", ")", "\n", "our_stats", "=", "all_stats", "[", "our_rank", "]", "\n", "for", "other_rank", ",", "stats", "in", "enumerate", "(", "all_stats", ")", ":", "\n", "            ", "if", "other_rank", "==", "our_rank", ":", "\n", "                ", "continue", "\n", "", "for", "i", ",", "stat", "in", "enumerate", "(", "stats", ")", ":", "\n", "                ", "our_stats", "[", "i", "]", ".", "update", "(", "stat", ",", "update_n_src_words", "=", "True", ")", "\n", "", "", "return", "our_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update": [[70, 86], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "stat", ",", "update_n_src_words", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Update statistics by suming values with another `Statistics` object\n\n        Args:\n            stat: another statistic object\n            update_n_src_words(bool): whether to update (sum) `n_src_words`\n                or not\n\n        \"\"\"", "\n", "self", ".", "loss", "+=", "stat", ".", "loss", "\n", "self", ".", "n_words", "+=", "stat", ".", "n_words", "\n", "self", ".", "n_correct", "+=", "stat", ".", "n_correct", "\n", "\n", "if", "update_n_src_words", ":", "\n", "            ", "self", ".", "n_src_words", "+=", "stat", ".", "n_src_words", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.accuracy": [[87, 90], ["None"], "methods", ["None"], ["", "", "def", "accuracy", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute accuracy \"\"\"", "\n", "return", "100", "*", "(", "self", ".", "n_correct", "/", "self", ".", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.xent": [[91, 94], ["None"], "methods", ["None"], ["", "def", "xent", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute cross entropy \"\"\"", "\n", "return", "self", ".", "loss", "/", "self", ".", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.ppl": [[95, 98], ["math.exp", "min"], "methods", ["None"], ["", "def", "ppl", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute perplexity \"\"\"", "\n", "return", "math", ".", "exp", "(", "min", "(", "self", ".", "loss", "/", "self", ".", "n_words", ",", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.elapsed_time": [[99, 102], ["time.time"], "methods", ["None"], ["", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute elapsed time \"\"\"", "\n", "return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.output": [[103, 124], ["statistics.Statistics.elapsed_time", "onmt.utils.logging.logger.info", "sys.stdout.flush", "statistics.Statistics.accuracy", "statistics.Statistics.ppl", "statistics.Statistics.xent", "time.time"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.elapsed_time", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.accuracy", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.xent"], ["", "def", "output", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "start", ")", ":", "\n", "        ", "\"\"\"Write out statistics to stdout.\n\n        Args:\n           step (int): current step\n           n_batch (int): total batches\n           start (int): start time of step.\n        \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "logger", ".", "info", "(", "\n", "(", "\"Step %2d/%5d; acc: %6.2f; ppl: %5.2f; xent: %4.2f; \"", "+", "\n", "\"lr: %7.5f; %3.0f/%3.0f tok/s; %6.0f sec\"", ")", "\n", "%", "(", "step", ",", "num_steps", ",", "\n", "self", ".", "accuracy", "(", ")", ",", "\n", "self", ".", "ppl", "(", ")", ",", "\n", "self", ".", "xent", "(", ")", ",", "\n", "learning_rate", ",", "\n", "self", ".", "n_src_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "self", ".", "n_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.log_tensorboard": [[125, 133], ["statistics.Statistics.elapsed_time", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "statistics.Statistics.xent", "statistics.Statistics.ppl", "statistics.Statistics.accuracy"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.elapsed_time", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.xent", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.accuracy"], ["", "def", "log_tensorboard", "(", "self", ",", "prefix", ",", "writer", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "\"\"\" display statistics to tensorboard \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/xent\"", ",", "self", ".", "xent", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/ppl\"", ",", "self", ".", "ppl", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/accuracy\"", ",", "self", ".", "accuracy", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/tgtper\"", ",", "self", ".", "n_words", "/", "t", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/lr\"", ",", "learning_rate", ",", "step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.logging.init_logger": [[9, 24], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["def", "init_logger", "(", "log_file", "=", "None", ")", ":", "\n", "    ", "log_format", "=", "logging", ".", "Formatter", "(", "\"[%(asctime)s %(levelname)s] %(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "handlers", "=", "[", "console_handler", "]", "\n", "\n", "if", "log_file", "and", "log_file", "!=", "''", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.is_master": [[16, 18], ["None"], "function", ["None"], ["def", "is_master", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "return", "opt", ".", "gpu_ranks", "[", "device_id", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.multi_init": [[20, 33], ["torch.distributed.init_process_group", "torch.distributed.get_rank", "distributed.is_master"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.is_master"], ["", "def", "multi_init", "(", "opt", ",", "device_id", ")", ":", "\n", "    ", "dist_init_method", "=", "'tcp://{master_ip}:{master_port}'", ".", "format", "(", "\n", "master_ip", "=", "opt", ".", "master_ip", ",", "\n", "master_port", "=", "opt", ".", "master_port", ")", "\n", "dist_world_size", "=", "opt", ".", "world_size", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "opt", ".", "gpu_backend", ",", "init_method", "=", "dist_init_method", ",", "\n", "world_size", "=", "dist_world_size", ",", "rank", "=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ")", "\n", "gpu_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "if", "not", "is_master", "(", "opt", ",", "device_id", ")", ":", "\n", "        ", "logger", ".", "disabled", "=", "True", "\n", "\n", "", "return", "gpu_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_reduce_and_rescale_tensors": [[35, 87], ["tensors[].new().zero_", "torch.distributed.all_reduce", "tensors[].new().zero_.div_", "len", "distributed.all_reduce_and_rescale_tensors.all_reduce_buffer"], "function", ["None"], ["", "def", "all_reduce_and_rescale_tensors", "(", "tensors", ",", "rescale_denom", ",", "\n", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n        buffer_size: all-reduce chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "all_reduce_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "torch", ".", "distributed", ".", "all_reduce", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, all-reduce and rescale directly", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "t", ")", "\n", "t", ".", "div_", "(", "rescale_denom", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, all-reduce and replace buffer with grad", "\n", "            ", "all_reduce_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "all_reduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.all_gather_list": [[89, 123], ["torch.distributed.get_world_size", "pickle.dumps", "len", "torch.ByteTensor", "torch.distributed.all_gather", "range", "torch.cuda.ByteTensor", "ValueError", "list", "in_buffer.cuda", "bytes", "pickle.loads", "results.append", "hasattr", "all_gather_list._in_buffer.size", "torch.cuda.ByteTensor", "out_buffer[].item", "out_buffer[].tolist", "range", "out_buffer[].item"], "function", ["None"], ["", "", "def", "all_gather_list", "(", "data", ",", "max_size", "=", "4096", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\"\"\"", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_in_buffer'", ")", "or", "max_size", "!=", "all_gather_list", ".", "_in_buffer", ".", "size", "(", ")", ":", "\n", "        ", "all_gather_list", ".", "_in_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "all_gather_list", ".", "_out_buffers", "=", "[", "\n", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "", "in_buffer", "=", "all_gather_list", ".", "_in_buffer", "\n", "out_buffers", "=", "all_gather_list", ".", "_out_buffers", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "if", "enc_size", "+", "2", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'encoded data exceeds max_size: {}'", ".", "format", "(", "enc_size", "+", "2", ")", ")", "\n", "", "assert", "max_size", "<", "255", "*", "256", "\n", "in_buffer", "[", "0", "]", "=", "enc_size", "//", "255", "# this encoding works for max_size < 65k", "\n", "in_buffer", "[", "1", "]", "=", "enc_size", "%", "255", "\n", "in_buffer", "[", "2", ":", "enc_size", "+", "2", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "out_buffers", ",", "in_buffer", ".", "cuda", "(", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "out_buffer", "=", "out_buffers", "[", "i", "]", "\n", "size", "=", "(", "255", "*", "out_buffer", "[", "0", "]", ".", "item", "(", ")", ")", "+", "out_buffer", "[", "1", "]", ".", "item", "(", ")", "\n", "\n", "bytes_list", "=", "bytes", "(", "out_buffer", "[", "2", ":", "size", "+", "2", "]", ".", "tolist", "(", ")", ")", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase.__init__": [[33, 43], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            report_every(int): Report status every this many sentences\n            start_time(float): manually set report start time. Negative values\n                means that you will need to set it later or use `start()`\n        \"\"\"", "\n", "self", ".", "report_every", "=", "report_every", "\n", "self", ".", "progress_step", "=", "0", "\n", "self", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase.start": [[44, 46], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase.log": [[47, 49], ["onmt.utils.logging.logger.info"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase.report_training": [[50, 76], ["onmt.utils.Statistics", "ValueError", "onmt.utils.Statistics.all_gather_stats", "report_manager.ReportMgrBase._report_training"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.all_gather_stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr._report_training"], ["", "def", "report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This is the user-defined batch-level traing progress\n        report function.\n\n        Args:\n            step(int): current step count.\n            num_steps(int): total number of batches.\n            learning_rate(float): current learning rate.\n            report_stats(Statistics): old Statistics instance.\n        Returns:\n            report_stats(Statistics): updated Statistics instance.\n        \"\"\"", "\n", "if", "self", ".", "start_time", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"ReportMgr needs to be started\n                                (set 'start_time' or use 'start()'\"\"\"", ")", "\n", "\n", "", "if", "multigpu", ":", "\n", "            ", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "report_stats", ")", "\n", "\n", "", "if", "step", "%", "self", ".", "report_every", "==", "0", ":", "\n", "            ", "self", ".", "_report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ")", "\n", "self", ".", "progress_step", "+=", "1", "\n", "", "return", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase._report_training": [[77, 80], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" To be overridden \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase.report_step": [[81, 92], ["report_manager.ReportMgrBase._report_step"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr._report_step"], ["", "def", "report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report stats of a step\n\n        Args:\n            train_stats(Statistics): training stats\n            valid_stats(Statistics): validation stats\n            lr(float): current learning rate\n        \"\"\"", "\n", "self", ".", "_report_step", "(", "\n", "lr", ",", "step", ",", "train_stats", "=", "train_stats", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgrBase._report_step": [[93, 95], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_step", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr.__init__": [[98, 110], ["report_manager.ReportMgrBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["    ", "def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ",", "tensorboard_writer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        A report manager that writes statistics on standard output as well as\n        (optionally) TensorBoard\n\n        Args:\n            report_every(int): Report status every this many sentences\n            tensorboard_writer(:obj:`tensorboard.SummaryWriter`):\n                The TensorBoard Summary writer to use or None\n        \"\"\"", "\n", "super", "(", "ReportMgr", ",", "self", ")", ".", "__init__", "(", "report_every", ",", "start_time", ")", "\n", "self", ".", "tensorboard_writer", "=", "tensorboard_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr.maybe_log_tensorboard": [[111, 115], ["stats.log_tensorboard"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.log_tensorboard"], ["", "def", "maybe_log_tensorboard", "(", "self", ",", "stats", ",", "prefix", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "tensorboard_writer", "is", "not", "None", ":", "\n", "            ", "stats", ".", "log_tensorboard", "(", "\n", "prefix", ",", "self", ".", "tensorboard_writer", ",", "learning_rate", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr._report_training": [[116, 132], ["onmt.utils.Statistics.output", "report_manager.ReportMgr.maybe_log_tensorboard", "onmt.utils.Statistics"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.output", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr.maybe_log_tensorboard"], ["", "", "def", "_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_training`.\n        \"\"\"", "\n", "report_stats", ".", "output", "(", "step", ",", "num_steps", ",", "\n", "learning_rate", ",", "self", ".", "start_time", ")", "\n", "\n", "# Log the progress using the number of batches on the x-axis.", "\n", "self", ".", "maybe_log_tensorboard", "(", "report_stats", ",", "\n", "\"progress\"", ",", "\n", "learning_rate", ",", "\n", "self", ".", "progress_step", ")", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "\n", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr._report_step": [[133, 154], ["report_manager.ReportMgr.log", "report_manager.ReportMgr.log", "report_manager.ReportMgr.maybe_log_tensorboard", "report_manager.ReportMgr.log", "report_manager.ReportMgr.log", "report_manager.ReportMgr.maybe_log_tensorboard", "train_stats.ppl", "train_stats.accuracy", "valid_stats.ppl", "valid_stats.accuracy"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.ReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.accuracy", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.ppl", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.accuracy"], ["", "def", "_report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_step`.\n        \"\"\"", "\n", "if", "train_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "train_stats", ",", "\n", "\"train\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "\n", "", "if", "valid_stats", "is", "not", "None", ":", "\n", "            ", "self", ".", "log", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "self", ".", "log", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "self", ".", "maybe_log_tensorboard", "(", "valid_stats", ",", "\n", "\"valid\"", ",", "\n", "lr", ",", "\n", "step", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.report_manager.build_report_manager": [[11, 23], ["report_manager.ReportMgr", "SummaryWriter", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "build_report_manager", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "writer", "=", "SummaryWriter", "(", "opt", ".", "tensorboard_log_dir", "\n", "+", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"/%b-%d_%H-%M-%S\"", ")", ",", "\n", "comment", "=", "\"Unmt\"", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "\n", "", "report_mgr", "=", "ReportMgr", "(", "opt", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "\n", "tensorboard_writer", "=", "writer", ")", "\n", "return", "report_mgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase.__init__": [[58, 63], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ")", ":", "\n", "        ", "super", "(", "LossComputeBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "padding_idx", "=", "tgt_vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._make_shard_state": [[64, 77], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Make shard state dictionary for shards() to return iterable\n        shards for efficient loss computation. Subclass must define\n        this method to match its own _compute_loss() interface.\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            range_: the range of examples for computing, the whole\n                    batch or a trunc of it?\n            attns: the attns dictionary returned from the model.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._compute_loss": [[78, 90], ["None"], "methods", ["None"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. Subclass must define this method.\n\n        Args:\n\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            **kwargs(optional): additional info for computing loss.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase.monolithic_compute_loss": [[91, 110], ["loss.LossComputeBase._make_shard_state", "loss.LossComputeBase._compute_loss", "batch.tgt.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorLossCompute._compute_loss"], ["", "def", "monolithic_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "attns", ")", ":", "\n", "        ", "\"\"\"\n        Compute the forward loss for the batch.\n\n        Args:\n          batch (batch): batch of labeled examples\n          output (:obj:`FloatTensor`):\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict of :obj:`FloatTensor`) :\n              dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n        Returns:\n            :obj:`onmt.utils.Statistics`: loss statistics\n        \"\"\"", "\n", "range_", "=", "(", "0", ",", "batch", ".", "tgt", ".", "size", "(", "0", ")", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ",", "range_", ",", "attns", ")", "\n", "_", ",", "batch_stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "\n", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase.sharded_compute_loss": [[111, 150], ["onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "loss.LossComputeBase._make_shard_state", "loss.shards", "loss.LossComputeBase._compute_loss", "loss.div().backward", "onmt.utils.Statistics.update", "onmt.utils.Statistics.update", "loss.div", "float"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.shards", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["", "def", "sharded_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "attns", ",", "\n", "cur_trunc", ",", "trunc_size", ",", "shard_size", ",", "\n", "normalization", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss and backpropagate.  Computation is done\n        with shards and optionally truncation for memory efficiency.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(cur_trunc, cur_trunc + trunc_size)`.\n\n        Note sharding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch) : batch of labeled examples\n          output (:obj:`FloatTensor`) :\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict) : dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n          cur_trunc (int) : starting position of truncation window\n          trunc_size (int) : length of truncation window\n          shard_size (int) : maximum number of examples in a shard\n          normalization (int) : Loss is divided by this number\n\n        Returns:\n            :obj:`onmt.utils.Statistics`: validation loss statistics\n\n        \"\"\"", "\n", "batch_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "range_", "=", "(", "cur_trunc", ",", "cur_trunc", "+", "trunc_size", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ",", "range_", ",", "attns", ")", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ")", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "loss", ".", "div", "(", "float", "(", "normalization", ")", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "\n", "", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._stats": [[151, 169], ["target.ne", "pred.eq().masked_select().sum().item", "target.ne.sum().item", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "scores.max", "loss.item", "pred.eq().masked_select().sum", "target.ne.sum", "pred.eq().masked_select", "pred.eq"], "methods", ["None"], ["", "def", "_stats", "(", "self", ",", "loss", ",", "scores", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss (:obj:`FloatTensor`): the loss computed by the loss criterion.\n            scores (:obj:`FloatTensor`): a score for each possible output\n            target (:obj:`FloatTensor`): true targets\n\n        Returns:\n            :obj:`onmt.utils.Statistics` : statistics for this batch.\n        \"\"\"", "\n", "pred", "=", "scores", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "non_padding", "=", "target", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "num_correct", "=", "pred", ".", "eq", "(", "target", ")", ".", "masked_select", "(", "non_padding", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_non_padding", "=", "non_padding", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "onmt", ".", "utils", ".", "Statistics", "(", "loss", ".", "item", "(", ")", ",", "num_non_padding", ",", "num_correct", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._bottle": [[170, 172], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_bottle", "(", "self", ",", "_v", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "_v", ".", "size", "(", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._unbottle": [[173, 175], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_unbottle", "(", "self", ",", "_v", ",", "batch_size", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "batch_size", ",", "_v", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LabelSmoothingLoss.__init__": [[183, 194], ["torch.Module.__init__", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "loss.LabelSmoothingLoss.register_buffer", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "label_smoothing", ",", "tgt_vocab_size", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "        ", "assert", "0.0", "<", "label_smoothing", "<=", "1.0", "\n", "self", ".", "padding_idx", "=", "ignore_index", "\n", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "smoothing_value", "=", "label_smoothing", "/", "(", "tgt_vocab_size", "-", "2", ")", "\n", "one_hot", "=", "torch", ".", "full", "(", "(", "tgt_vocab_size", ",", ")", ",", "smoothing_value", ")", "\n", "one_hot", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "self", ".", "register_buffer", "(", "'one_hot'", ",", "one_hot", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "self", ".", "confidence", "=", "1.0", "-", "label_smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LabelSmoothingLoss.forward": [[195, 205], ["loss.LabelSmoothingLoss.one_hot.repeat", "loss.LabelSmoothingLoss.scatter_", "loss.LabelSmoothingLoss.masked_fill_", "torch.kl_div", "torch.kl_div", "torch.kl_div", "target.size", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        output (FloatTensor): batch_size x n_classes\n        target (LongTensor): batch_size\n        \"\"\"", "\n", "model_prob", "=", "self", ".", "one_hot", ".", "repeat", "(", "target", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "model_prob", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "model_prob", ".", "masked_fill_", "(", "(", "target", "==", "self", ".", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ",", "0", ")", "\n", "\n", "return", "F", ".", "kl_div", "(", "output", ",", "model_prob", ",", "reduction", "=", "'sum'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.NMTLossCompute.__init__": [[212, 227], ["loss.LossComputeBase.__init__", "isinstance", "loss.LabelSmoothingLoss", "len", "onmt.modules.sparse_losses.SparsemaxLoss", "onmt.modules.sparse_losses.SparsemaxLoss", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ",", "normalization", "=", "\"sents\"", ",", "\n", "label_smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "NMTLossCompute", ",", "self", ")", ".", "__init__", "(", "generator", ",", "tgt_vocab", ")", "\n", "self", ".", "sparse", "=", "not", "isinstance", "(", "generator", "[", "1", "]", ",", "nn", ".", "LogSoftmax", ")", "\n", "if", "label_smoothing", ">", "0", ":", "\n", "            ", "self", ".", "criterion", "=", "LabelSmoothingLoss", "(", "\n", "label_smoothing", ",", "len", "(", "tgt_vocab", ")", ",", "ignore_index", "=", "self", ".", "padding_idx", "\n", ")", "\n", "", "elif", "self", ".", "sparse", ":", "\n", "            ", "self", ".", "criterion", "=", "SparsemaxLoss", "(", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "size_average", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "criterion", "=", "nn", ".", "NLLLoss", "(", "\n", "ignore_index", "=", "self", ".", "padding_idx", ",", "reduction", "=", "'sum'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.NMTLossCompute._make_shard_state": [[229, 233], ["None"], "methods", ["None"], ["", "", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        ", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.NMTLossCompute._compute_loss": [[235, 250], ["loss.NMTLossCompute.NMTLossCompute._bottle", "target.view", "loss.NMTLossCompute.NMTLossCompute.criterion", "loss.NMTLossCompute.NMTLossCompute._stats", "loss.NMTLossCompute.NMTLossCompute.generator", "loss.NMTLossCompute.NMTLossCompute.clone"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._stats"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ")", ":", "\n", "        ", "bottled_output", "=", "self", ".", "_bottle", "(", "output", ")", "\n", "if", "self", ".", "sparse", ":", "\n", "# for sparsemax loss, the loss function operates on the raw output", "\n", "# vector, not a probability vector. Hence it's only necessary to", "\n", "# apply the first part of the generator here.", "\n", "            ", "scores", "=", "self", ".", "generator", "[", "0", "]", "(", "bottled_output", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "self", ".", "generator", "(", "bottled_output", ")", "\n", "", "gtruth", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "gtruth", ")", "\n", "stats", "=", "self", ".", "_stats", "(", "loss", ".", "clone", "(", ")", ",", "scores", ",", "gtruth", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.build_loss_compute": [[17, 36], ["torch.device", "torch.device", "torch.device", "NMTLossCompute.to", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "loss.NMTLossCompute", "onmt.utils.misc.use_gpu", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.use_gpu", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.use_gpu"], ["def", "build_loss_compute", "(", "model", ",", "tgt_vocab", ",", "opt", ",", "train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined LossCompute object, which is used to\n    compute loss in train/validate process. You can implement your\n    own *LossCompute class, by subclassing LossComputeBase.\n    \"\"\"", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "onmt", ".", "utils", ".", "misc", ".", "use_gpu", "(", "opt", ")", "else", "\"cpu\"", ")", "\n", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "opt", ".", "copy_attn_force", ",", "\n", "opt", ".", "copy_loss_by_seqlength", ")", "\n", "", "else", ":", "\n", "        ", "compute", "=", "NMTLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "\n", "label_smoothing", "=", "opt", ".", "label_smoothing", "if", "train", "else", "0.0", ")", "\n", "", "compute", ".", "to", "(", "device", ")", "\n", "\n", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.filter_shard_state": [[252, 266], ["state.items", "isinstance", "torch.split", "torch.split", "torch.split", "v_chunk.data.clone.data.clone", "v_split.append"], "function", ["None"], ["", "", "def", "filter_shard_state", "(", "state", ",", "shard_size", "=", "None", ")", ":", "\n", "    ", "\"\"\" ? \"\"\"", "\n", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "        ", "if", "shard_size", "is", "None", ":", "\n", "            ", "yield", "k", ",", "v", "\n", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v_split", "=", "[", "]", "\n", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "for", "v_chunk", "in", "torch", ".", "split", "(", "v", ",", "shard_size", ")", ":", "\n", "                    ", "v_chunk", "=", "v_chunk", ".", "data", ".", "clone", "(", ")", "\n", "v_chunk", ".", "requires_grad", "=", "v", ".", "requires_grad", "\n", "v_split", ".", "append", "(", "v_chunk", ")", "\n", "", "", "yield", "k", ",", "(", "v", ",", "v_split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.shards": [[268, 316], ["dict", "zip", "zip", "dict.items", "zip", "torch.autograd.backward", "torch.autograd.backward", "torch.autograd.backward", "loss.filter_shard_state", "loss.filter_shard_state", "dict", "isinstance", "variables.extend", "zip", "zip", "dict.items", "torch.split", "torch.split", "torch.split"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.filter_shard_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.filter_shard_state"], ["", "", "", "def", "shards", "(", "state", ",", "shard_size", ",", "eval_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        state: A dictionary which corresponds to the output of\n               *LossCompute._make_shard_state(). The values for\n               those keys are Tensor-like or None.\n        shard_size: The maximum size of the shards yielded by the model.\n        eval_only: If True, only yield the state, nothing else.\n              Otherwise, yield shards.\n\n    Yields:\n        Each yielded shard is a dict.\n\n    Side effect:\n        After the last shard, this function does back-propagation.\n    \"\"\"", "\n", "if", "eval_only", ":", "\n", "        ", "yield", "filter_shard_state", "(", "state", ")", "\n", "", "else", ":", "\n", "# non_none: the subdict of the state dictionary where the values", "\n", "# are not None.", "\n", "        ", "non_none", "=", "dict", "(", "filter_shard_state", "(", "state", ",", "shard_size", ")", ")", "\n", "\n", "# Now, the iteration:", "\n", "# state is a dictionary of sequences of tensor-like but we", "\n", "# want a sequence of dictionaries of tensors.", "\n", "# First, unzip the dictionary into a sequence of keys and a", "\n", "# sequence of tensor-like sequences.", "\n", "keys", ",", "values", "=", "zip", "(", "*", "(", "(", "k", ",", "[", "v_chunk", "for", "v_chunk", "in", "v_split", "]", ")", "\n", "for", "k", ",", "(", "_", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ")", ")", "\n", "\n", "# Now, yield a dictionary for each shard. The keys are always", "\n", "# the same. values is a sequence of length #keys where each", "\n", "# element is a sequence of length #shards. We want to iterate", "\n", "# over the shards, not over the keys: therefore, the values need", "\n", "# to be re-zipped by shard and then each shard can be paired", "\n", "# with the keys.", "\n", "for", "shard_tensors", "in", "zip", "(", "*", "values", ")", ":", "\n", "            ", "yield", "dict", "(", "zip", "(", "keys", ",", "shard_tensors", ")", ")", "\n", "\n", "# Assumed backprop'd", "\n", "", "variables", "=", "[", "]", "\n", "for", "k", ",", "(", "v", ",", "v_split", ")", "in", "non_none", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "and", "state", "[", "k", "]", ".", "requires_grad", ":", "\n", "                ", "variables", ".", "extend", "(", "zip", "(", "torch", ".", "split", "(", "state", "[", "k", "]", ",", "shard_size", ")", ",", "\n", "[", "v_chunk", ".", "grad", "for", "v_chunk", "in", "v_split", "]", ")", ")", "\n", "", "", "inputs", ",", "grads", "=", "zip", "(", "*", "variables", ")", "\n", "torch", ".", "autograd", ".", "backward", "(", "inputs", ",", "grads", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.GatedConv.__init__": [[22, 29], ["torch.Module.__init__", "onmt.modules.WeightNormConv2d", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "width", "=", "3", ",", "dropout", "=", "0.2", ",", "nopad", "=", "False", ")", ":", "\n", "        ", "super", "(", "GatedConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "onmt", ".", "modules", ".", "WeightNormConv2d", "(", "\n", "input_size", ",", "2", "*", "input_size", ",", "kernel_size", "=", "(", "width", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "width", "//", "2", "*", "(", "1", "-", "nopad", ")", ",", "0", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "conv", ".", "weight", ",", "gain", "=", "(", "4", "*", "(", "1", "-", "dropout", ")", ")", "**", "0.5", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.GatedConv.forward": [[30, 36], ["cnn_factory.GatedConv.dropout", "cnn_factory.GatedConv.conv", "cnn_factory.GatedConv.split", "int", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "cnn_factory.GatedConv.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_var", ")", ":", "\n", "        ", "x_var", "=", "self", ".", "dropout", "(", "x_var", ")", "\n", "x_var", "=", "self", ".", "conv", "(", "x_var", ")", "\n", "out", ",", "gate", "=", "x_var", ".", "split", "(", "int", "(", "x_var", ".", "size", "(", "1", ")", "/", "2", ")", ",", "1", ")", "\n", "out", "=", "out", "*", "F", ".", "sigmoid", "(", "gate", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.StackedCNN.__init__": [[41, 50], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "cnn_factory.StackedCNN.layers.append", "cnn_factory.GatedConv"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "cnn_kernel_width", "=", "3", ",", "\n", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "StackedCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "GatedConv", "(", "input_size", ",", "cnn_kernel_width", ",", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.StackedCNN.forward": [[51, 56], ["conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "x", "+", "conv", "(", "x", ")", "\n", "x", "*=", "SCALE_WEIGHT", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.shape_transform": [[14, 17], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "shape_transform", "(", "x", ")", ":", "\n", "    ", "\"\"\" Tranform the size of the tensors to fit for conv input. \"\"\"", "\n", "return", "torch", ".", "unsqueeze", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.rnn_factory.rnn_factory": [[10, 20], ["onmt.models.sru.SRU", "getattr"], "function", ["None"], ["def", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" rnn factory, Use pytorch version when available. \"\"\"", "\n", "no_pack_padded_seq", "=", "False", "\n", "if", "rnn_type", "==", "\"SRU\"", ":", "\n", "# SRU doesn't support PackedSequence.", "\n", "        ", "no_pack_padded_seq", "=", "True", "\n", "rnn", "=", "onmt", ".", "models", ".", "sru", ".", "SRU", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "**", "kwargs", ")", "\n", "", "return", "rnn", ",", "no_pack_padded_seq", "\n", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq": [[6, 14], ["next", "all", "str"], "function", ["None"], ["def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.sequence_mask": [[16, 26], ["lengths.numel", "torch.arange().type_as().repeat().lt", "lengths.max", "lengths.unsqueeze", "torch.arange().type_as().repeat", "torch.arange().type_as", "torch.arange"], "function", ["None"], ["", "def", "sequence_mask", "(", "lengths", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean mask from sequence lengths.\n    \"\"\"", "\n", "batch_size", "=", "lengths", ".", "numel", "(", ")", "\n", "max_len", "=", "max_len", "or", "lengths", ".", "max", "(", ")", "\n", "return", "(", "torch", ".", "arange", "(", "0", ",", "max_len", ")", "\n", ".", "type_as", "(", "lengths", ")", "\n", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", ".", "lt", "(", "lengths", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile": [[28, 48], ["list", "list", "x.permute().contiguous.size", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous().view", "range", "x.permute().contiguous.permute().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute().contiguous", "len", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute", "x.permute().contiguous.permute", "x.permute().contiguous.view().transpose().repeat().transpose", "x.permute().contiguous.view().transpose().repeat", "x.permute().contiguous.view().transpose", "x.permute().contiguous.view"], "function", ["None"], ["", "def", "tile", "(", "x", ",", "count", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Tiles x on dimension dim count times.\n    \"\"\"", "\n", "perm", "=", "list", "(", "range", "(", "len", "(", "x", ".", "size", "(", ")", ")", ")", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "perm", "[", "0", "]", ",", "perm", "[", "dim", "]", "=", "perm", "[", "dim", "]", ",", "perm", "[", "0", "]", "\n", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "out_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "out_size", "[", "0", "]", "*=", "count", "\n", "batch", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "view", "(", "batch", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "repeat", "(", "count", ",", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "out_size", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.use_gpu": [[50, 56], ["hasattr", "hasattr", "len"], "function", ["None"], ["", "def", "use_gpu", "(", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean if gpu used\n    \"\"\"", "\n", "return", "(", "hasattr", "(", "opt", ",", "'gpu_ranks'", ")", "and", "len", "(", "opt", ".", "gpu_ranks", ")", ">", "0", ")", "or", "(", "hasattr", "(", "opt", ",", "'gpu'", ")", "and", "opt", ".", "gpu", ">", "-", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.__init__": [[74, 77], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "optimizers", "=", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.zero_grad": [[78, 82], ["op.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.step": [[83, 87], ["op.step"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.state": [[88, 92], ["op.state.items"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "{", "k", ":", "v", "for", "op", "in", "self", ".", "optimizers", "for", "k", ",", "v", "in", "op", ".", "state", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.state_dict": [[93, 96], ["op.state_dict"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "[", "op", ".", "state_dict", "(", ")", "for", "op", "in", "self", ".", "optimizers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.load_state_dict": [[97, 102], ["range", "len", "len", "len", "optimizers.MultipleOptimizer.optimizers[].load_state_dict"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dicts", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "assert", "len", "(", "state_dicts", ")", "==", "len", "(", "self", ".", "optimizers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "state_dicts", ")", ")", ":", "\n", "            ", "self", ".", "optimizers", "[", "i", "]", ".", "load_state_dict", "(", "state_dicts", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.__init__": [[135, 157], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "method", ",", "learning_rate", ",", "max_grad_norm", ",", "\n", "lr_decay", "=", "1", ",", "start_decay_steps", "=", "None", ",", "decay_steps", "=", "None", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "adagrad_accum", "=", "0.0", ",", "\n", "decay_method", "=", "None", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "model_size", "=", "None", ")", ":", "\n", "        ", "self", ".", "last_ppl", "=", "None", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "original_lr", "=", "learning_rate", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_steps", "=", "start_decay_steps", "\n", "self", ".", "decay_steps", "=", "decay_steps", "\n", "self", ".", "start_decay", "=", "False", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "betas", "=", "[", "beta1", ",", "beta2", "]", "\n", "self", ".", "adagrad_accum", "=", "adagrad_accum", "\n", "self", ".", "decay_method", "=", "decay_method", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "model_size", "=", "model_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.set_parameters": [[158, 189], ["torch.SGD", "torch.SGD", "torch.Adagrad", "torch.Adagrad", "optimizers.Optimizer.params.append", "optimizers.Optimizer.sparse_params.append", "torch.Adadelta", "torch.Adadelta", "[].fill_", "torch.Adam", "torch.Adam", "optimizers.MultipleOptimizer", "RuntimeError", "torch.Adam", "torch.Adam", "torch.SparseAdam", "torch.SparseAdam"], "methods", ["None"], ["", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "params", "=", "[", "]", "\n", "self", ".", "sparse_params", "=", "[", "]", "\n", "for", "k", ",", "p", "in", "params", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "if", "self", ".", "method", "!=", "'sparseadam'", "or", "\"embed\"", "not", "in", "k", ":", "\n", "                    ", "self", ".", "params", ".", "append", "(", "p", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "sparse_params", ".", "append", "(", "p", ")", "\n", "", "", "", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                    ", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", "=", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", ".", "fill_", "(", "self", ".", "adagrad_accum", ")", "\n", "", "", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-9", ")", "\n", "", "elif", "self", ".", "method", "==", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "MultipleOptimizer", "(", "\n", "[", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-8", ")", ",", "\n", "optim", ".", "SparseAdam", "(", "self", ".", "sparse_params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-8", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer._set_rate": [[190, 197], ["None"], "methods", ["None"], ["", "", "def", "_set_rate", "(", "self", ",", "learning_rate", ")", ":", "\n", "        ", "self", ".", "learning_rate", "=", "learning_rate", "\n", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "", "else", ":", "\n", "            ", "for", "op", "in", "self", ".", "optimizer", ".", "optimizers", ":", "\n", "                ", "op", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.step": [[198, 229], ["optimizers.Optimizer.optimizer.step", "optimizers.Optimizer._set_rate", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "min"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer._set_rate"], ["", "", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the model parameters based on current gradients.\n\n        Optionally, will employ gradient modification or update learning\n        rate.\n        \"\"\"", "\n", "self", ".", "_step", "+=", "1", "\n", "\n", "# Decay method used in tensor2tensor.", "\n", "if", "self", ".", "decay_method", "==", "\"noam\"", ":", "\n", "            ", "self", ".", "_set_rate", "(", "\n", "self", ".", "original_lr", "*", "\n", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "self", ".", "_step", "**", "(", "-", "0.5", ")", ",", "\n", "self", ".", "_step", "*", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", ")", "\n", "# Decay based on start_decay_steps every decay_steps", "\n", "", "else", ":", "\n", "            ", "if", "(", "(", "self", ".", "start_decay_steps", "is", "not", "None", ")", "and", "(", "\n", "self", ".", "_step", ">=", "self", ".", "start_decay_steps", ")", ")", ":", "\n", "                ", "self", ".", "start_decay", "=", "True", "\n", "", "if", "self", ".", "start_decay", ":", "\n", "                ", "if", "(", "(", "self", ".", "_step", "-", "self", ".", "start_decay_steps", ")", "\n", "%", "self", ".", "decay_steps", "==", "0", ")", ":", "\n", "                    ", "self", ".", "learning_rate", "=", "self", ".", "learning_rate", "*", "self", ".", "lr_decay", "\n", "\n", "", "", "", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n", "", "if", "self", ".", "max_grad_norm", ":", "\n", "            ", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.build_optim": [[9, 69], ["optimizers.Optimizer.set_parameters", "Optimizer.optimizer.state_dict", "optimizers.Optimizer", "model.named_parameters", "Optimizer.optimizer.load_state_dict", "onmt.utils.use_gpu", "Optimizer.optimizer.state.values", "RuntimeError", "state.items", "len", "torch.is_tensor", "torch.is_tensor", "v.cuda"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.Optimizer.set_parameters", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.use_gpu"], ["def", "build_optim", "(", "model", ",", "opt", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\" Build optimizer \"\"\"", "\n", "saved_optimizer_state_dict", "=", "None", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "# We need to save a copy of optim.optimizer.state_dict() for setting", "\n", "# the, optimizer state later on in Stage 2 in this method, since", "\n", "# the method optim.set_parameters(model.parameters()) will overwrite", "\n", "# optim.optimizer, and with ith the values stored in", "\n", "# optim.optimizer.state_dict()", "\n", "saved_optimizer_state_dict", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "        ", "optim", "=", "Optimizer", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_steps", "=", "opt", ".", "start_decay_steps", ",", "\n", "decay_steps", "=", "opt", ".", "decay_steps", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "\n", "# Stage 1:", "\n", "# Essentially optim.set_parameters (re-)creates and optimizer using", "\n", "# model.paramters() as parameters that will be stored in the", "\n", "# optim.optimizer.param_groups field of the torch optimizer class.", "\n", "# Importantly, this method does not yet load the optimizer state, as", "\n", "# essentially it builds a new optimizer with empty optimizer state and", "\n", "# parameters from the model.", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "# Stage 2: In this stage, which is only performed when loading an", "\n", "# optimizer from a checkpoint, we load the saved_optimizer_state_dict", "\n", "# into the re-created optimizer, to set the optim.optimizer.state", "\n", "# field, which was previously empty. For this, we use the optimizer", "\n", "# state saved in the \"saved_optimizer_state_dict\" variable for", "\n", "# this purpose.", "\n", "# See also: https://github.com/pytorch/pytorch/issues/2830", "\n", "        ", "optim", ".", "optimizer", ".", "load_state_dict", "(", "saved_optimizer_state_dict", ")", "\n", "# Convert back the state values to cuda type if applicable", "\n", "if", "use_gpu", "(", "opt", ")", ":", "\n", "            ", "for", "state", "in", "optim", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                    ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                        ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "# We want to make sure that indeed we have a non-empty optimizer state", "\n", "# when we loaded an existing model. This should be at least the case", "\n", "# for Adam, which saves \"exp_avg\" and \"exp_avg_sq\" state", "\n", "# (Exponential moving average of gradient and squared gradient values)", "\n", "", "", "", "", "if", "(", "optim", ".", "method", "==", "'adam'", ")", "and", "(", "len", "(", "optim", ".", "optimizer", ".", "state", ")", "<", "1", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error: loaded Adam optimizer from existing model\"", "+", "\n", "\" but optimizer state is empty\"", ")", "\n", "\n", "", "", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.__init__": [[36, 78], ["image_dataset.ImageDataset._peek", "ex.keys", "list", "onmt.inputters.dataset_base.DatasetBase.__init__", "image_dataset.ImageDataset._construct_example_fromlist", "image_dataset.ImageDataset._join_dicts", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._peek", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "tgt_seq_length", "=", "0", ",", "use_filter_pred", "=", "True", ",", "\n", "image_channel_size", "=", "3", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'img'", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "self", ".", "image_channel_size", "=", "image_channel_size", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "out_examples", "=", "(", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "for", "ex_values", "in", "example_values", ")", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "out_examples", "=", "list", "(", "out_examples", ")", "\n", "\n", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "                ", "return", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "ImageDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.sort_key": [[80, 83], ["ex.src.size", "ex.src.size"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using the size of the image: (width, height).\"\"\"", "\n", "return", "(", "ex", ".", "src", ".", "size", "(", "2", ")", ",", "ex", ".", "src", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.make_image_examples_nfeats_tpl": [[84, 112], ["image_dataset.ImageDataset.make_examples", "image_dataset.ImageDataset.make_img_iterator_from_file", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.make_examples", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.make_img_iterator_from_file"], ["", "@", "staticmethod", "\n", "def", "make_image_examples_nfeats_tpl", "(", "img_iter", ",", "img_path", ",", "img_dir", ",", "\n", "image_channel_size", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Note: one of img_iter and img_path must be not None\n        Args:\n            img_iter(iterator): an iterator that yields pairs (img, filename)\n                (or None)\n            img_path(str): location of a src file containing image paths\n                (or None)\n            src_dir (str): location of source images\n\n        Returns:\n            (example_dict iterator, num_feats) tuple\n        \"\"\"", "\n", "if", "img_iter", "is", "None", ":", "\n", "            ", "if", "img_path", "is", "not", "None", ":", "\n", "                ", "img_iter", "=", "ImageDataset", ".", "make_img_iterator_from_file", "(", "img_path", ",", "\n", "img_dir", ",", "\n", "image_channel_size", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"One of 'img_iter' and 'img_path'\n                                    must be not None\"\"\"", ")", "\n", "", "", "examples_iter", "=", "ImageDataset", ".", "make_examples", "(", "img_iter", ",", "img_dir", ",", "'src'", ")", "\n", "num_feats", "=", "0", "# Source side(img) has no features.", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.make_examples": [[113, 138], ["enumerate", "os.path.exists", "img.size", "img.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_examples", "(", "img_iter", ",", "src_dir", ",", "side", ",", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing image paths\n            src_dir (str): location of source images\n            side (str): 'src' or 'tgt'\n            truncate: maximum img size ((0,0) or None for unlimited)\n\n        Yields:\n            a dictionary containing image data, path and index for each line.\n        \"\"\"", "\n", "assert", "(", "src_dir", "is", "not", "None", ")", "and", "os", ".", "path", ".", "exists", "(", "src_dir", ")", ",", "'src_dir must be a valid directory if data_type is img'", "\n", "\n", "for", "index", ",", "(", "img", ",", "filename", ")", "in", "enumerate", "(", "img_iter", ")", ":", "\n", "            ", "if", "truncate", "and", "truncate", "!=", "(", "0", ",", "0", ")", ":", "\n", "                ", "if", "not", "(", "img", ".", "size", "(", "1", ")", "<=", "truncate", "[", "0", "]", "\n", "and", "img", ".", "size", "(", "2", ")", "<=", "truncate", "[", "1", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "example_dict", "=", "{", "side", ":", "img", ",", "\n", "side", "+", "'_path'", ":", "filename", ",", "\n", "'indices'", ":", "index", "}", "\n", "yield", "example_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.make_img_iterator_from_file": [[139, 170], ["codecs.open", "line.strip", "os.path.join", "os.path.exists", "os.path.exists", "line.strip", "transforms.ToTensor", "Image.fromarray", "transforms.ToTensor", "Image.open", "cv2.imread"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "make_img_iterator_from_file", "(", "path", ",", "src_dir", ",", "image_channel_size", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path(str):\n            src_dir(str):\n\n        Yields:\n            img: and image tensor\n            filename(str): the image filename\n        \"\"\"", "\n", "from", "PIL", "import", "Image", "\n", "from", "torchvision", "import", "transforms", "\n", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "for", "line", "in", "corpus_file", ":", "\n", "                ", "filename", "=", "line", ".", "strip", "(", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "src_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                    ", "img_path", "=", "line", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "img_path", ")", ",", "'img path %s not found'", "%", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "if", "(", "image_channel_size", "==", "1", ")", ":", "\n", "                    ", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "\n", "Image", ".", "fromarray", "(", "cv2", ".", "imread", "(", "img_path", ",", "0", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "Image", ".", "open", "(", "img_path", ")", ")", "\n", "\n", "", "yield", "img", ",", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.get_fields": [[171, 244], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "data[].size", "max", "max", "torch.zeros().fill_", "enumerate", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "max", "len", "enumerate", "t.size", "t.size", "torch.zeros", "t.size", "t.size", "torch.zeros", "len", "str", "str", "t.max", "len", "img.size", "img.size", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features: the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features: the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "def", "make_img", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "c", "=", "data", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "h", "=", "max", "(", "[", "t", ".", "size", "(", "1", ")", "for", "t", "in", "data", "]", ")", "\n", "w", "=", "max", "(", "[", "t", ".", "size", "(", "2", ")", "for", "t", "in", "data", "]", ")", "\n", "imgs", "=", "torch", ".", "zeros", "(", "len", "(", "data", ")", ",", "c", ",", "h", ",", "w", ")", ".", "fill_", "(", "1", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "imgs", "[", "i", ",", ":", ",", "0", ":", "img", ".", "size", "(", "1", ")", ",", "0", ":", "img", ".", "size", "(", "2", ")", "]", "=", "img", "\n", "", "return", "imgs", "\n", "\n", "", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_img", ",", "sequential", "=", "False", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.image_dataset.ImageDataset.get_num_features": [[245, 267], ["codecs.open", "cf.readline().strip().split", "ImageDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.extract_text_features"], ["", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        For image corpus, source side is in form of image, thus\n        no feature; while target side is in form of text, thus\n        we can extract its text features.\n\n        Args:\n            corpus_file (str): file path to get the features.\n            side (str): 'src' or 'tgt'.\n\n        Returns:\n            number of features on `side`.\n        \"\"\"", "\n", "if", "side", "==", "'src'", ":", "\n", "            ", "num_feats", "=", "0", "\n", "", "else", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "                ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "ImageDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "", "return", "num_feats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.__init__": [[41, 95], ["text_dataset.TextDataset._peek", "ex.keys", "onmt.inputters.dataset_base.DatasetBase.__init__", "text_dataset.TextDataset._dynamic_dict", "text_dataset.TextDataset._construct_example_fromlist", "len", "out_examples.append", "text_dataset.TextDataset._join_dicts", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._peek", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset._dynamic_dict", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._join_dicts"], ["\n", "def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "src_seq_length", "=", "0", ",", "tgt_seq_length", "=", "0", ",", "\n", "dynamic_dict", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'text'", "\n", "\n", "# self.src_vocabs: mutated in dynamic_dict, used in", "\n", "# collapse_copy_scores and in Translator.py", "\n", "self", ".", "src_vocabs", "=", "[", "]", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "\n", "# Each element of an example is a dictionary whose keys represents", "\n", "# at minimum the src tokens and their indices and potentially also", "\n", "# the src and tgt features and alignment information.", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "", "if", "dynamic_dict", ":", "\n", "            ", "examples_iter", "=", "self", ".", "_dynamic_dict", "(", "examples_iter", ")", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "for", "k", "in", "keys", "]", "\n", "\n", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "\n", "# import pdb;", "\n", "# pdb.set_trace()", "\n", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "src_size", "=", "0", "\n", "\n", "out_examples", "=", "[", "]", "\n", "for", "ex_values", "in", "example_values", ":", "\n", "            ", "example", "=", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "src_size", "+=", "len", "(", "example", ".", "src", ")", "\n", "# print (example.src)", "\n", "out_examples", ".", "append", "(", "example", ")", "\n", "\n", "", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.sort_key": [[97, 104], ["hasattr", "len", "len", "len"], "methods", ["None"], ["and", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "\n", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "TextDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.collapse_copy_scores": [[105, 131], ["len", "range", "range", "len", "torch.Tensor().type_as", "torch.Tensor().type_as", "scores[].index_add_", "scores[].index_fill_", "torch.Tensor().type_as.append", "torch.Tensor().type_as.append", "scores[].index_select", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using length of source sentences. \"\"\"", "\n", "# Default to a balanced sort, prioritizing tgt len match.", "\n", "# TODO: make this configurable.", "\n", "if", "hasattr", "(", "ex", ",", "\"tgt\"", ")", ":", "\n", "            ", "return", "len", "(", "ex", ".", "src", ")", ",", "len", "(", "ex", ".", "tgt", ")", "\n", "", "return", "len", "(", "ex", ".", "src", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "collapse_copy_scores", "(", "scores", ",", "batch", ",", "tgt_vocab", ",", "src_vocabs", ")", ":", "\n", "        ", "\"\"\"\n        Given scores from an expanded dictionary\n        corresponeding to a batch, sums together copies,\n        with a dictionary word when it is ambigious.\n        \"\"\"", "\n", "offset", "=", "len", "(", "tgt_vocab", ")", "\n", "for", "b", "in", "range", "(", "batch", ".", "batch_size", ")", ":", "\n", "            ", "blank", "=", "[", "]", "\n", "fill", "=", "[", "]", "\n", "index", "=", "batch", ".", "indices", ".", "data", "[", "b", "]", "\n", "src_vocab", "=", "src_vocabs", "[", "index", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "src_vocab", ")", ")", ":", "\n", "                ", "sw", "=", "src_vocab", ".", "itos", "[", "i", "]", "\n", "ti", "=", "tgt_vocab", ".", "stoi", "[", "sw", "]", "\n", "if", "ti", "!=", "0", ":", "\n", "                    ", "blank", ".", "append", "(", "offset", "+", "i", ")", "\n", "fill", ".", "append", "(", "ti", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.make_text_examples_nfeats_tpl": [[132, 168], ["text_dataset.TextDataset.make_examples", "next", "itertools.chain", "text_dataset.TextDataset.make_text_iterator_from_file"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.make_examples", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.make_text_iterator_from_file"], ["", "", "if", "blank", ":", "\n", "                ", "blank", "=", "torch", ".", "Tensor", "(", "blank", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "fill", "=", "torch", ".", "Tensor", "(", "fill", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "scores", "[", ":", ",", "b", "]", ".", "index_add_", "(", "1", ",", "fill", ",", "\n", "scores", "[", ":", ",", "b", "]", ".", "index_select", "(", "1", ",", "blank", ")", ")", "\n", "scores", "[", ":", ",", "b", "]", ".", "index_fill_", "(", "1", ",", "blank", ",", "1e-10", ")", "\n", "", "", "return", "scores", "\n", "\n", "", "@", "staticmethod", "\n", "def", "make_text_examples_nfeats_tpl", "(", "text_iter", ",", "text_path", ",", "truncate", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            text_iter(iterator): an iterator (or None) that we can loop over\n                to read examples.\n                It may be an openned file, a string list etc...\n            text_path(str): path to file or None\n            path (str): location of a src or tgt file.\n            truncate (int): maximum sequence length (0 for unlimited).\n            side (str): \"src\" or \"tgt\".\n\n        Returns:\n            (example_dict iterator, num_feats) tuple.\n        \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", "]", "\n", "\n", "if", "text_iter", "is", "None", ":", "\n", "            ", "if", "text_path", "is", "not", "None", ":", "\n", "                ", "text_iter", "=", "TextDataset", ".", "make_text_iterator_from_file", "(", "text_path", ")", "\n", "", "else", ":", "\n", "                ", "return", "(", "None", ",", "0", ")", "\n", "\n", "# All examples have same number of features, so we peek first one", "\n", "# to get the num_feats.", "\n", "", "", "examples_nfeats_iter", "=", "TextDataset", ".", "make_examples", "(", "text_iter", ",", "truncate", ",", "side", ")", "\n", "\n", "first_ex", "=", "next", "(", "examples_nfeats_iter", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.make_examples": [[169, 194], ["enumerate", "line.strip().split.strip().split.strip().split", "TextDataset.extract_text_features", "example_dict.update", "line.strip().split.strip().split.strip", "enumerate", "str"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.extract_text_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["num_feats", "=", "first_ex", "[", "1", "]", "\n", "\n", "# Chain back the first element - we only want to peek it.", "\n", "examples_nfeats_iter", "=", "chain", "(", "[", "first_ex", "]", ",", "examples_nfeats_iter", ")", "\n", "examples_iter", "=", "(", "ex", "for", "ex", ",", "nfeats", "in", "examples_nfeats_iter", ")", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "make_examples", "(", "text_iter", ",", "truncate", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            text_iter (iterator): iterator of text sequences\n            truncate (int): maximum sequence length (0 for unlimited).\n            side (str): \"src\" or \"tgt\".\n\n        Yields:\n            (word, features, nfeat) triples for each line.\n        \"\"\"", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "text_iter", ")", ":", "\n", "# print('*' * 10)", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n", "if", "truncate", ":", "\n", "                ", "line", "=", "line", "[", ":", "truncate", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.make_text_iterator_from_file": [[195, 200], ["codecs.open"], "methods", ["None"], ["", "words", ",", "feats", ",", "n_feats", "=", "TextDataset", ".", "extract_text_features", "(", "line", ")", "\n", "\n", "# print (line)", "\n", "# print (words)", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.get_fields": [[201, 275], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "max", "enumerate", "max", "torch.zeros().long", "enumerate", "int", "torch.zeros", "enumerate", "t.size", "max", "len", "print", "print", "print", "t.size", "torch.zeros", "str", "str", "len", "len", "t.max", "sent.size"], "methods", ["None"], ["example_dict", "=", "{", "side", ":", "words", ",", "\"indices\"", ":", "i", "}", "\n", "if", "feats", ":", "\n", "                ", "prefix", "=", "side", "+", "\"_feat_\"", "\n", "example_dict", ".", "update", "(", "(", "prefix", "+", "str", "(", "j", ")", ",", "f", ")", "\n", "for", "j", ",", "f", "in", "enumerate", "(", "feats", ")", ")", "\n", "", "yield", "example_dict", ",", "n_feats", "\n", "\n", "", "", "@", "staticmethod", "\n", "def", "make_text_iterator_from_file", "(", "path", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "for", "line", "in", "corpus_file", ":", "\n", "                ", "yield", "line", "\n", "\n", "", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features (int): the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features (int): the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "\n", "\n", "\n", "fields", "=", "{", "}", "\n", "\n", "\n", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "#pdb.set_trace()", "\n", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "\n", "src_vocab_size", "=", "int", "(", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", ")", "+", "1", "\n", "\n", "try", ":", "\n", "                ", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "", "except", ":", "\n", "\n", "                ", "print", "(", "src_size", ")", "\n", "print", "(", "len", "(", "data", ")", ")", "\n", "print", "(", "src_vocab_size", ")", "\n", "\n", "", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.get_num_features": [[276, 296], ["codecs.open", "cf.readline().strip().split", "TextDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.extract_text_features"], ["            ", "\"\"\" ? \"\"\"", "\n", "\n", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "def", "make_sents", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset._dynamic_dict": [[298, 314], ["torchtext.vocab.Vocab", "text_dataset.TextDataset.src_vocabs.append", "torch.LongTensor", "collections.Counter", "torch.LongTensor"], "methods", ["None"], ["\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", "i", ",", ":", "sent", ".", "size", "(", "0", ")", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_sents\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "postprocessing", "=", "make_sents", ",", "sequential", "=", "False", ")", "\n", "fields", "[", "\"tgt_sents\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "postprocessing", "=", "make_sents", ",", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n", "", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator.__init__": [[326, 353], ["io.open", "sys.stderr.write", "sys.exit"], "methods", ["None"], ["            ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "TextDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "return", "num_feats", "\n", "\n", "# @staticmethod", "\n", "# def get_num_sents(corpus_file, side):", "\n", "#     \"\"\"", "\n", "#     Peek one line and get number of features of it.", "\n", "#     (All lines must have same number of features).", "\n", "#     For text corpus, both sides are in text form, thus", "\n", "#     it works the same.", "\n", "#", "\n", "#     Args:", "\n", "#         corpus_file (str): file path to get the features.", "\n", "#         side (str): 'src' or 'tgt'.", "\n", "#", "\n", "#     Returns:", "\n", "#         number of features on `side`.", "\n", "#     \"\"\"", "\n", "#     with codecs.open(corpus_file, \"r\", \"utf-8\") as cf:", "\n", "#         f_line = cf.readline().strip().split()", "\n", "#         _, _, _, num_sents = TextDataset.extract_text_features(f_line)", "\n", "#", "\n", "#     return num_sents", "\n", "\n", "# Below are helper functions for intra-class use only.", "\n", "", "def", "_dynamic_dict", "(", "self", ",", "examples_iter", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator.__iter__": [[354, 401], ["text_dataset.ShardedTextCorpusIterator.corpus.seek", "text_dataset.ShardedTextCorpusIterator.corpus.readline", "text_dataset.ShardedTextCorpusIterator.corpus.close", "text_dataset.ShardedTextCorpusIterator.corpus.readline", "AssertionError", "text_dataset.ShardedTextCorpusIterator._example_dict_iter", "text_dataset.ShardedTextCorpusIterator.corpus.tell", "text_dataset.ShardedTextCorpusIterator.corpus.close", "text_dataset.ShardedTextCorpusIterator._example_dict_iter"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator._example_dict_iter", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator._example_dict_iter"], ["\n", "        ", "for", "example", "in", "examples_iter", ":", "\n", "            ", "src", "=", "example", "[", "\"src\"", "]", "# src is a list of words", "\n", "# print ('....',src)", "\n", "\n", "\n", "#TODO We add here", "\n", "# get sentence length", "\n", "sent", "=", "' '", ".", "join", "(", "src", ")", "\n", "sents", "=", "sent_tokenize", "(", "sent", ")", "\n", "\n", "n_sents", "=", "[", "len", "(", "x", ".", "split", "(", "' '", ")", ")", "for", "x", "in", "sents", "]", "\n", "if", "len", "(", "n_sents", ")", "<", "1", ":", "# empty line", "\n", "                ", "n_sents", "=", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "n_sents", "[", "0", "]", "=", "n_sents", "[", "0", "]", "-", "1", "# change on the first one", "\n", "", "example", "[", "\"src_sents\"", "]", "=", "torch", ".", "LongTensor", "(", "n_sents", ")", "\n", "\n", "src_vocab", "=", "torchtext", ".", "vocab", ".", "Vocab", "(", "Counter", "(", "src", ")", ",", "\n", "specials", "=", "[", "UNK_WORD", ",", "PAD_WORD", "]", ")", "\n", "self", ".", "src_vocabs", ".", "append", "(", "src_vocab", ")", "\n", "# Mapping source tokens to indices in the dynamic dict.", "\n", "src_map", "=", "torch", ".", "LongTensor", "(", "[", "src_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "src", "]", ")", "\n", "example", "[", "\"src_map\"", "]", "=", "src_map", "\n", "\n", "if", "\"tgt\"", "in", "example", ":", "\n", "                ", "tgt", "=", "example", "[", "\"tgt\"", "]", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "\n", "[", "0", "]", "+", "[", "src_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "tgt", "]", "+", "[", "0", "]", ")", "\n", "example", "[", "\"alignment\"", "]", "=", "mask", "\n", "\n", "#TODO We add here", "\n", "# get sentence length", "\n", "sent", "=", "' '", ".", "join", "(", "tgt", ")", "\n", "sents", "=", "sent_tokenize", "(", "sent", ")", "\n", "n_sents", "=", "[", "len", "(", "x", ".", "split", "(", "' '", ")", ")", "for", "x", "in", "sents", "]", "\n", "n_sents", "[", "0", "]", "=", "n_sents", "[", "0", "]", "-", "1", "# change on the first one", "\n", "example", "[", "\"tgt_sents\"", "]", "=", "torch", ".", "LongTensor", "(", "n_sents", ")", "\n", "\n", "", "yield", "example", "\n", "\n", "\n", "", "", "", "class", "ShardedTextCorpusIterator", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator.hit_end": [[402, 405], ["None"], "methods", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator.num_feats": [[406, 422], ["text_dataset.ShardedTextCorpusIterator.corpus.tell", "text_dataset.ShardedTextCorpusIterator.corpus.readline().split", "TextDataset.extract_text_features", "text_dataset.ShardedTextCorpusIterator.corpus.seek", "text_dataset.ShardedTextCorpusIterator.corpus.readline"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.extract_text_features"], ["def", "__init__", "(", "self", ",", "corpus_path", ",", "line_truncate", ",", "side", ",", "shard_size", ",", "\n", "assoc_iter", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            corpus_path: the corpus file path.\n            line_truncate: the maximum length of a line to read.\n                            0 for unlimited.\n            side: \"src\" or \"tgt\".\n            shard_size: the shard size, 0 means not sharding the file.\n            assoc_iter: if not None, it is the associate iterator that\n                        this iterator should align its step with.\n        \"\"\"", "\n", "try", ":", "\n", "# The codecs module seems to have bugs with seek()/tell(),", "\n", "# so we use io.open().", "\n", "            ", "self", ".", "corpus", "=", "io", ".", "open", "(", "corpus_path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "", "except", "IOError", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator._example_dict_iter": [[423, 438], ["line.split.split.split", "TextDataset.extract_text_features", "onmt.utils.misc.aeq", "example_dict.update", "enumerate", "str"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.extract_text_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["            ", "sys", ".", "stderr", ".", "write", "(", "\"Failed to open corpus file: %s\"", "%", "corpus_path", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "self", ".", "line_truncate", "=", "line_truncate", "\n", "self", ".", "side", "=", "side", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "assoc_iter", "=", "assoc_iter", "\n", "self", ".", "last_pos", "=", "0", "\n", "self", ".", "line_index", "=", "-", "1", "\n", "self", ".", "eof", "=", "False", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.OrderedIterator.create_batches": [[406, 423], ["inputter.OrderedIterator.create_batches._pool"], "methods", ["None"], ["", "word", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "vocabulary", ".", "add", "(", "word", ")", "\n", "", "", "", "", "return", "vocabulary", "\n", "\n", "\n", "", "class", "OrderedIterator", "(", "torchtext", ".", "data", ".", "Iterator", ")", ":", "\n", "    ", "\"\"\" Ordered Iterator Class \"\"\"", "\n", "\n", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "\"\"\" Create batches \"\"\"", "\n", "if", "self", ".", "train", ":", "\n", "            ", "def", "_pool", "(", "data", ",", "random_shuffler", ")", ":", "\n", "                ", "for", "p", "in", "torchtext", ".", "data", ".", "batch", "(", "data", ",", "self", ".", "batch_size", "*", "100", ")", ":", "\n", "                    ", "p_batch", "=", "torchtext", ".", "data", ".", "batch", "(", "\n", "sorted", "(", "p", ",", "key", "=", "self", ".", "sort_key", ")", ",", "\n", "self", ".", "batch_size", ",", "self", ".", "batch_size_fn", ")", "\n", "for", "b", "in", "random_shuffler", "(", "list", "(", "p_batch", ")", ")", ":", "\n", "                        ", "yield", "b", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.DatasetLazyIter.__init__": [[438, 450], ["inputter.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.DatasetLazyIter._next_dataset_iterator"], ["\n", "\n", "def", "__init__", "(", "self", ",", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", ":", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.DatasetLazyIter.__iter__": [[451, 457], ["inputter.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.DatasetLazyIter._next_dataset_iterator"], ["        ", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.DatasetLazyIter.__len__": [[458, 464], ["len"], "methods", ["None"], ["self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "datasets", ")", "\n", "\n", "# We have at least one dataset.", "\n", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dataset_iter", "=", "(", "d", "for", "d", "in", "self", ".", "datasets", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.DatasetLazyIter._next_dataset_iterator": [[465, 489], ["inputter.OrderedIterator", "hasattr", "next", "gc.collect", "gc.collect"], "methods", ["None"], ["while", "self", ".", "cur_iter", "is", "not", "None", ":", "\n", "            ", "for", "batch", "in", "self", ".", "cur_iter", ":", "\n", "                ", "yield", "batch", "\n", "", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "dataset_iter", ")", "\n", "\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "# We return the len of cur_dataset, otherwise we need to load", "\n", "# all datasets to determine the real len, which loses the benefit", "\n", "# of lazy loading.", "\n", "        ", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "return", "len", "(", "self", ".", "cur_iter", ")", "\n", "\n", "", "def", "_next_dataset_iterator", "(", "self", ",", "dataset_iter", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "# Drop the current dataset for decreasing memory", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"cur_dataset\"", ")", ":", "\n", "                ", "self", ".", "cur_dataset", ".", "examples", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "self", ".", "cur_dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "self", ".", "cur_dataset", "=", "next", "(", "dataset_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._getstate": [[23, 25], ["dict", "dict"], "function", ["None"], ["def", "_getstate", "(", "self", ")", ":", "\n", "    ", "return", "dict", "(", "self", ".", "__dict__", ",", "stoi", "=", "dict", "(", "self", ".", "stoi", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._setstate": [[27, 30], ["inputter..__dict__.update", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["", "def", "_setstate", "(", "self", ",", "state", ")", ":", "\n", "    ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "self", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "self", ".", "stoi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.get_fields": [[36, 57], ["onmt.inputters.text_dataset.TextDataset.get_fields", "onmt.inputters.image_dataset.ImageDataset.get_fields", "onmt.inputters.audio_dataset.AudioDataset.get_fields", "ValueError"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields"], ["def", "get_fields", "(", "data_type", ",", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        data_type: type of the source input. Options are [text|img|audio].\n        n_src_features: the number of source features to\n            create `torchtext.data.Field` for.\n        n_tgt_features: the number of target features to\n            create `torchtext.data.Field` for.\n\n    Returns:\n        A dictionary whose keys are strings and whose values are the\n        corresponding Field objects.\n    \"\"\"", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "TextDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "return", "ImageDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "return", "AudioDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Data type not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab": [[59, 72], ["dict", "len", "len", "inputter.get_fields", "dict.items", "inputter.collect_features", "inputter.collect_features", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_features"], ["", "", "def", "load_fields_from_vocab", "(", "vocab", ",", "data_type", "=", "\"text\"", ")", ":", "\n", "    ", "\"\"\"\n    Load Field objects from `vocab.pt` file.\n    \"\"\"", "\n", "vocab", "=", "dict", "(", "vocab", ")", "\n", "n_src_features", "=", "len", "(", "collect_features", "(", "vocab", ",", "'src'", ")", ")", "\n", "n_tgt_features", "=", "len", "(", "collect_features", "(", "vocab", ",", "'tgt'", ")", ")", "\n", "\n", "\n", "fields", "=", "get_fields", "(", "data_type", ",", "n_src_features", ",", "n_tgt_features", ")", "\n", "\n", "\n", "\n", "for", "k", ",", "v", "in", "vocab", ".", "items", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.save_fields_to_vocab": [[74, 84], ["fields.items", "vocab.append"], "function", ["None"], ["        ", "v", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "v", ".", "stoi", ")", "\n", "fields", "[", "k", "]", ".", "vocab", "=", "v", "\n", "# TODO: until here, fields has 'tgt_sents'", "\n", "\n", "\n", "", "return", "fields", "\n", "\n", "\n", "", "def", "save_fields_to_vocab", "(", "fields", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs": [[86, 102], ["sum", "torchtext.vocab.Vocab", "torchtext.vocab.Vocab", "collections.Counter"], "function", ["None"], ["vocab", "=", "[", "]", "\n", "for", "k", ",", "f", "in", "fields", ".", "items", "(", ")", ":", "\n", "        ", "if", "f", "is", "not", "None", "and", "'vocab'", "in", "f", ".", "__dict__", ":", "\n", "            ", "f", ".", "vocab", ".", "stoi", "=", "f", ".", "vocab", ".", "stoi", "\n", "vocab", ".", "append", "(", "(", "k", ",", "f", ".", "vocab", ")", ")", "\n", "", "", "return", "vocab", "\n", "\n", "\n", "", "def", "merge_vocabs", "(", "vocabs", ",", "vocab_size", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.get_num_features": [[104, 125], ["onmt.inputters.text_dataset.TextDataset.get_num_features", "onmt.inputters.image_dataset.ImageDataset.get_num_features", "onmt.inputters.audio_dataset.AudioDataset.get_num_features", "ValueError"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features"], ["\n", "merged", "=", "sum", "(", "[", "vocab", ".", "freqs", "for", "vocab", "in", "vocabs", "]", ",", "Counter", "(", ")", ")", "\n", "return", "torchtext", ".", "vocab", ".", "Vocab", "(", "merged", ",", "\n", "specials", "=", "[", "UNK_WORD", ",", "PAD_WORD", ",", "\n", "BOS_WORD", ",", "EOS_WORD", "]", ",", "\n", "max_size", "=", "vocab_size", ")", "\n", "\n", "\n", "", "def", "get_num_features", "(", "data_type", ",", "corpus_file", ",", "side", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        data_type (str): type of the source input.\n            Options are [text|img|audio].\n        corpus_file (str): file path to get the features.\n        side (str): for source or for target.\n\n    Returns:\n        number of features on `side`.\n    \"\"\"", "\n", "assert", "side", "in", "[", "\"src\"", ",", "\"tgt\"", "]", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features": [[127, 153], ["isinstance", "sorted", "torch.cat", "level.unsqueeze"], "function", ["None"], ["", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "return", "ImageDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "return", "AudioDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Data type not implemented\"", ")", "\n", "\n", "\n", "", "", "def", "make_features", "(", "batch", ",", "side", ",", "data_type", "=", "'text'", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        batch (Tensor): a batch of source or target data.\n        side (str): for source or for target.\n        data_type (str): type of the source input.\n            Options are [text|img|audio].\n    Returns:\n        A sequence of src/tgt tensors with optional feature tensors\n        of size (len x batch).\n    \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", "]", "\n", "if", "isinstance", "(", "batch", ".", "__dict__", "[", "side", "]", ",", "tuple", ")", ":", "\n", "        ", "data", "=", "batch", ".", "__dict__", "[", "side", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "data", "=", "batch", ".", "__dict__", "[", "side", "]", "\n", "\n", "", "feat_start", "=", "side", "+", "\"_feat_\"", "\n", "keys", "=", "sorted", "(", "[", "k", "for", "k", "in", "batch", ".", "__dict__", "if", "feat_start", "in", "k", "]", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_features": [[155, 167], ["itertools.count", "feats.append", "str"], "function", ["None"], ["levels", "=", "[", "data", "]", "+", "features", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "level", ".", "unsqueeze", "(", "2", ")", "for", "level", "in", "levels", "]", ",", "2", ")", "\n", "", "else", ":", "\n", "        ", "return", "levels", "[", "0", "]", "\n", "\n", "\n", "", "", "def", "collect_features", "(", "fields", ",", "side", "=", "\"src\"", ")", ":", "\n", "    ", "\"\"\"\n    Collect features from Field object.\n    \"\"\"", "\n", "assert", "side", "in", "[", "\"src\"", ",", "\"tgt\"", "]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_feature_vocabs": [[169, 181], ["itertools.count", "feature_vocabs.append", "str"], "function", ["None"], ["for", "j", "in", "count", "(", ")", ":", "\n", "        ", "key", "=", "side", "+", "\"_feat_\"", "+", "str", "(", "j", ")", "\n", "if", "key", "not", "in", "fields", ":", "\n", "            ", "break", "\n", "", "feats", ".", "append", "(", "key", ")", "\n", "", "return", "feats", "\n", "\n", "\n", "", "def", "collect_feature_vocabs", "(", "fields", ",", "side", ")", ":", "\n", "    ", "\"\"\"\n    Collect feature Vocab objects from Field object.\n    \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", "]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset": [[183, 270], ["inputter.build_dataset._make_examples_nfeats_tpl"], "function", ["None"], ["for", "j", "in", "count", "(", ")", ":", "\n", "        ", "key", "=", "side", "+", "\"_feat_\"", "+", "str", "(", "j", ")", "\n", "if", "key", "not", "in", "fields", ":", "\n", "            ", "break", "\n", "", "feature_vocabs", ".", "append", "(", "fields", "[", "key", "]", ".", "vocab", ")", "\n", "", "return", "feature_vocabs", "\n", "\n", "\n", "", "def", "build_dataset", "(", "fields", ",", "data_type", ",", "src_data_iter", "=", "None", ",", "src_path", "=", "None", ",", "\n", "src_dir", "=", "None", ",", "tgt_data_iter", "=", "None", ",", "tgt_path", "=", "None", ",", "\n", "src_seq_length", "=", "0", ",", "tgt_seq_length", "=", "0", ",", "\n", "src_seq_length_trunc", "=", "0", ",", "tgt_seq_length_trunc", "=", "0", ",", "\n", "dynamic_dict", "=", "True", ",", "sample_rate", "=", "0", ",", "\n", "window_size", "=", "0", ",", "window_stride", "=", "0", ",", "window", "=", "None", ",", "\n", "normalize_audio", "=", "True", ",", "use_filter_pred", "=", "True", ",", "\n", "image_channel_size", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    Build src/tgt examples iterator from corpus files, also extract\n    number of features.\n    \"\"\"", "\n", "\n", "def", "_make_examples_nfeats_tpl", "(", "data_type", ",", "src_data_iter", ",", "src_path", ",", "src_dir", ",", "\n", "src_seq_length_trunc", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "\n", "window", ",", "normalize_audio", ",", "\n", "image_channel_size", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Process the corpus into (example_dict iterator, num_feats) tuple\n        on source side for different 'data_type'.\n        \"\"\"", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "src_examples_iter", ",", "num_src_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "src_data_iter", ",", "src_path", ",", "src_seq_length_trunc", ",", "\"src\"", ")", "\n", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "            ", "src_examples_iter", ",", "num_src_feats", "=", "ImageDataset", ".", "make_image_examples_nfeats_tpl", "(", "\n", "src_data_iter", ",", "src_path", ",", "src_dir", ",", "image_channel_size", ")", "\n", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "            ", "if", "src_data_iter", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"Data iterator for AudioDataset isn't\n                                    implemented\"\"\"", ")", "\n", "\n", "", "if", "src_path", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"AudioDataset requires a non None path\"", ")", "\n", "", "src_examples_iter", ",", "num_src_feats", "=", "AudioDataset", ".", "make_audio_examples_nfeats_tpl", "(", "\n", "src_path", ",", "src_dir", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "window", ",", "\n", "normalize_audio", ")", "\n", "\n", "", "return", "src_examples_iter", ",", "num_src_feats", "\n", "\n", "", "src_examples_iter", ",", "num_src_feats", "=", "_make_examples_nfeats_tpl", "(", "data_type", ",", "src_data_iter", ",", "src_path", ",", "src_dir", ",", "\n", "src_seq_length_trunc", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "\n", "window", ",", "normalize_audio", ",", "\n", "image_channel_size", "=", "image_channel_size", ")", "\n", "\n", "# For all data types, the tgt side corpus is in form of text.", "\n", "tgt_examples_iter", ",", "num_tgt_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "tgt_data_iter", ",", "tgt_path", ",", "tgt_seq_length_trunc", ",", "\"tgt\"", ")", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "dataset", "=", "TextDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "src_seq_length", "=", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "dynamic_dict", "=", "dynamic_dict", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "dataset", "=", "ImageDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ",", "\n", "image_channel_size", "=", "image_channel_size", ")", "\n", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "dataset", "=", "AudioDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._build_field_vocab": [[272, 278], ["list", "field.vocab_cls", "collections.OrderedDict.fromkeys"], "function", ["None"], ["window_stride", "=", "window_stride", ",", "\n", "window", "=", "window", ",", "\n", "normalize_audio", "=", "normalize_audio", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_vocab": [[280, 375], ["inputter.load_vocabulary", "inputter.load_vocabulary", "enumerate", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "range", "fields.pop", "collections.Counter", "torch.load", "onmt.utils.logging.logger.info", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "range", "gc.collect", "gc.collect", "gc.collect", "len", "str", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "inputter.merge_vocabs", "getattr", "counter[].update", "len", "len", "str", "len", "len"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_vocabulary", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_vocabulary", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["", "def", "_build_field_vocab", "(", "field", ",", "counter", ",", "**", "kwargs", ")", ":", "\n", "    ", "specials", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "\n", "tok", "for", "tok", "in", "[", "field", ".", "unk_token", ",", "field", ".", "pad_token", ",", "field", ".", "init_token", ",", "\n", "field", ".", "eos_token", "]", "\n", "if", "tok", "is", "not", "None", ")", ")", "\n", "field", ".", "vocab", "=", "field", ".", "vocab_cls", "(", "counter", ",", "specials", "=", "specials", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "def", "build_vocab", "(", "train_dataset_files", ",", "fields", ",", "data_type", ",", "share_vocab", ",", "\n", "src_vocab_path", ",", "src_vocab_size", ",", "src_words_min_frequency", ",", "\n", "tgt_vocab_path", ",", "tgt_vocab_size", ",", "tgt_words_min_frequency", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        train_dataset_files: a list of train dataset pt file.\n        fields (dict): fields to build vocab for.\n        data_type: \"text\", \"img\" or \"audio\"?\n        share_vocab(bool): share source and target vocabulary?\n        src_vocab_path(string): Path to src vocabulary file.\n        src_vocab_size(int): size of the source vocabulary.\n        src_words_min_frequency(int): the minimum frequency needed to\n                include a source word in the vocabulary.\n        tgt_vocab_path(string): Path to tgt vocabulary file.\n        tgt_vocab_size(int): size of the target vocabulary.\n        tgt_words_min_frequency(int): the minimum frequency needed to\n                include a target word in the vocabulary.\n\n    Returns:\n        Dict of Fields\n    \"\"\"", "\n", "counter", "=", "{", "}", "\n", "\n", "# Prop src from field to get lower memory using when training with image", "\n", "if", "data_type", "==", "'img'", ":", "\n", "        ", "fields", ".", "pop", "(", "\"src\"", ")", "\n", "\n", "", "for", "k", "in", "fields", ":", "\n", "        ", "counter", "[", "k", "]", "=", "Counter", "(", ")", "\n", "\n", "# Load vocabulary", "\n", "", "src_vocab", "=", "load_vocabulary", "(", "src_vocab_path", ",", "tag", "=", "\"source\"", ")", "\n", "tgt_vocab", "=", "load_vocabulary", "(", "tgt_vocab_path", ",", "tag", "=", "\"target\"", ")", "\n", "\n", "for", "index", ",", "path", "in", "enumerate", "(", "train_dataset_files", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "logger", ".", "info", "(", "\" * reloading %s.\"", "%", "path", ")", "\n", "for", "ex", "in", "dataset", ".", "examples", ":", "\n", "            ", "for", "k", "in", "fields", ":", "\n", "                ", "val", "=", "getattr", "(", "ex", ",", "k", ",", "None", ")", "\n", "if", "val", "is", "not", "None", "and", "not", "fields", "[", "k", "]", ".", "sequential", ":", "\n", "                    ", "val", "=", "[", "val", "]", "\n", "", "elif", "k", "==", "'src'", "and", "src_vocab", ":", "\n", "                    ", "val", "=", "[", "item", "for", "item", "in", "val", "if", "item", "in", "src_vocab", "]", "\n", "", "elif", "k", "==", "'tgt'", "and", "tgt_vocab", ":", "\n", "                    ", "val", "=", "[", "item", "for", "item", "in", "val", "if", "item", "in", "tgt_vocab", "]", "\n", "", "counter", "[", "k", "]", ".", "update", "(", "val", ")", "\n", "\n", "# Drop the none-using from memory but keep the last", "\n", "", "", "if", "(", "index", "<", "len", "(", "train_dataset_files", ")", "-", "1", ")", ":", "\n", "            ", "dataset", ".", "examples", "=", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", ".", "examples", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "", "_build_field_vocab", "(", "fields", "[", "\"tgt\"", "]", ",", "counter", "[", "\"tgt\"", "]", ",", "\n", "max_size", "=", "tgt_vocab_size", ",", "\n", "min_freq", "=", "tgt_words_min_frequency", ")", "\n", "logger", ".", "info", "(", "\" * tgt vocab size: %d.\"", "%", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", "\n", "\n", "# All datasets have same num of n_tgt_features,", "\n", "# getting the last one is OK.", "\n", "for", "j", "in", "range", "(", "dataset", ".", "n_tgt_feats", ")", ":", "\n", "        ", "key", "=", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "\n", "_build_field_vocab", "(", "fields", "[", "key", "]", ",", "counter", "[", "key", "]", ")", "\n", "logger", ".", "info", "(", "\" * %s vocab size: %d.\"", "%", "(", "key", ",", "\n", "len", "(", "fields", "[", "key", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "", "if", "data_type", "==", "'text'", ":", "\n", "        ", "_build_field_vocab", "(", "fields", "[", "\"src\"", "]", ",", "counter", "[", "\"src\"", "]", ",", "\n", "max_size", "=", "src_vocab_size", ",", "\n", "min_freq", "=", "src_words_min_frequency", ")", "\n", "logger", ".", "info", "(", "\" * src vocab size: %d.\"", "%", "len", "(", "fields", "[", "\"src\"", "]", ".", "vocab", ")", ")", "\n", "\n", "# All datasets have same num of n_src_features,", "\n", "# getting the last one is OK.", "\n", "for", "j", "in", "range", "(", "dataset", ".", "n_src_feats", ")", ":", "\n", "            ", "key", "=", "\"src_feat_\"", "+", "str", "(", "j", ")", "\n", "_build_field_vocab", "(", "fields", "[", "key", "]", ",", "counter", "[", "key", "]", ")", "\n", "logger", ".", "info", "(", "\" * %s vocab size: %d.\"", "%", "\n", "(", "key", ",", "len", "(", "fields", "[", "key", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "# Merge the input and output vocabularies.", "\n", "", "if", "share_vocab", ":", "\n", "# `tgt_vocab_size` is ignored when sharing vocabularies", "\n", "            ", "logger", ".", "info", "(", "\" * merging src and tgt vocab...\"", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_vocabulary": [[377, 401], ["set", "onmt.utils.logging.logger.info", "os.path.exists", "RuntimeError", "open", "set.add", "len", "line.strip().split", "line.strip", "line.strip"], "function", ["None"], ["[", "fields", "[", "\"src\"", "]", ".", "vocab", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", "]", ",", "\n", "vocab_size", "=", "src_vocab_size", ")", "\n", "fields", "[", "\"src\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "fields", "[", "\"tgt\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "\n", "", "", "return", "fields", "\n", "\n", "\n", "", "def", "load_vocabulary", "(", "vocabulary_path", ",", "tag", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"\n    Loads a vocabulary from the given path.\n    :param vocabulary_path: path to load vocabulary from\n    :param tag: tag for vocabulary (only used for logging)\n    :return: vocabulary or None if path is null\n    \"\"\"", "\n", "vocabulary", "=", "None", "\n", "if", "vocabulary_path", ":", "\n", "        ", "vocabulary", "=", "set", "(", "[", "]", ")", "\n", "logger", ".", "info", "(", "\"Loading {} vocabulary from {}\"", ".", "format", "(", "tag", ",", "\n", "vocabulary_path", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "vocabulary_path", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"{} vocabulary not found at {}!\"", ".", "format", "(", "tag", ",", "vocabulary_path", ")", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset_iter": [[491, 528], ["inputter.DatasetLazyIter", "max", "max", "max", "len", "len"], "function", ["None"], ["# We clear `fields` when saving, restore when loading.", "\n", "", "self", ".", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "\n", "\n", "\n", "# Sort batch by decreasing lengths of sentence required by pytorch.", "\n", "# sort=False means \"Use dataset's sortkey instead of iterator's\".", "\n", "return", "OrderedIterator", "(", "\n", "dataset", "=", "self", ".", "cur_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", ")", "\n", "\n", "\n", "", "", "def", "build_dataset_iter", "(", "datasets", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over. We implement simple ordered iterator strategy here,\n    but more sophisticated strategy like curriculum learning is ok too.\n    \"\"\"", "\n", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "\"\"\"\n            In token batching scheme, the number of sequences is limited\n            such that the total number of src/tgt tokens (including padding)\n            in a batch <= batch_size\n            \"\"\"", "\n", "# Maintains the longest src and tgt length in the current batch", "\n", "global", "max_src_in_batch", ",", "max_tgt_in_batch", "\n", "# Reset current longest length at a new batch (count=1)", "\n", "if", "count", "==", "1", ":", "\n", "                ", "max_src_in_batch", "=", "0", "\n", "max_tgt_in_batch", "=", "0", "\n", "# Src: <bos> w1 ... wN <eos>", "\n", "", "max_src_in_batch", "=", "max", "(", "max_src_in_batch", ",", "len", "(", "new", ".", "src", ")", "+", "2", ")", "\n", "# Tgt: w1 ... wN <eos>", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.lazily_load_dataset": [[530, 557], ["sorted", "torch.load", "onmt.utils.logging.logger.info", "glob.glob", "inputter.lazily_load_dataset._lazy_dataset_loader"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["src_elements", "=", "count", "*", "max_src_in_batch", "\n", "tgt_elements", "=", "count", "*", "max_tgt_in_batch", "\n", "return", "max", "(", "src_elements", ",", "tgt_elements", ")", "\n", "", "", "else", ":", "\n", "        ", "batch_size_fn", "=", "None", "\n", "\n", "", "if", "opt", ".", "gpu_ranks", ":", "\n", "        ", "device", "=", "\"cuda\"", "\n", "", "else", ":", "\n", "        ", "device", "=", "\"cpu\"", "\n", "\n", "", "return", "DatasetLazyIter", "(", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", "\n", "\n", "\n", "", "def", "lazily_load_dataset", "(", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Dataset generator. Don't do extra stuff here, like printing,\n    because they will be postponed to the first loading time.\n\n    Args:\n        corpus_type: 'train' or 'valid'\n    Returns:\n        A list of dataset, the dataset(s) are lazily loaded.\n    \"\"\"", "\n", "assert", "corpus_type", "in", "[", "\"train\"", ",", "\"valid\"", "]", "\n", "\n", "def", "_lazy_dataset_loader", "(", "pt_file", ",", "corpus_type", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._load_fields": [[559, 578], ["dict", "onmt.utils.logging.logger.info", "inputter.load_fields_from_vocab", "inputter.load_fields_from_vocab", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "torch.load", "load_fields_from_vocab.items", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["# logger.info('Loading %s dataset from %s, number of examples: %d' %", "\n", "#             (corpus_type, pt_file, len(dataset)))", "\n", "# import pdb;", "\n", "# pdb.set_trace()", "\n", "\n", "return", "dataset", "\n", "\n", "\n", "# Sort the glob output by file name (by increasing indexes).", "\n", "", "pts", "=", "sorted", "(", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.[0-9]*.pt'", ")", ")", "\n", "if", "pts", ":", "\n", "        ", "for", "pt", "in", "pts", ":", "\n", "            ", "yield", "_lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "", "", "else", ":", "\n", "# Only one inputters.*Dataset, simple!", "\n", "        ", "pt", "=", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.pt'", "\n", "yield", "_lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "\n", "\n", "", "", "def", "_load_fields", "(", "dataset", ",", "data_type", ",", "opt", ",", "checkpoint", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter._collect_report_features": [[580, 585], ["inputter.collect_features", "inputter.collect_features"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.collect_features"], ["\n", "    ", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading vocab from checkpoint at %s.'", "%", "opt", ".", "train_from", ")", "\n", "fields", "=", "load_fields_from_vocab", "(", "\n", "checkpoint", "[", "'vocab'", "]", ",", "data_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.__getstate__": [[31, 33], ["None"], "methods", ["None"], ["\n", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.__setstate__": [[34, 36], ["dataset_base.DatasetBase.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.statistics.Statistics.update"], ["\n", "", "def", "__setstate__", "(", "self", ",", "_d", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "_d", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.__reduce_ex__": [[37, 40], ["super().__reduce_ex__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.__reduce_ex__"], ["\n", "", "def", "__reduce_ex__", "(", "self", ",", "proto", ")", ":", "\n", "        ", "\"This is a hack. Something is broken with torch pickle.\"", "\n", "return", "super", "(", "DatasetBase", ",", "self", ")", ".", "__reduce_ex__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.load_fields": [[41, 51], ["onmt.inputters.inputter.load_fields_from_vocab", "dict", "vocab_dict.items", "onmt.inputters.inputter.load_fields_from_vocab.items"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab"], ["\n", "", "def", "load_fields", "(", "self", ",", "vocab_dict", ")", ":", "\n", "        ", "\"\"\" Load fields from vocab.pt, and set the `fields` attribute.\n\n        Args:\n            vocab_dict (dict): a dict of loaded vocab from vocab.pt file.\n        \"\"\"", "\n", "fields", "=", "onmt", ".", "inputters", ".", "inputter", ".", "load_fields_from_vocab", "(", "\n", "vocab_dict", ".", "items", "(", ")", ",", "self", ".", "data_type", ")", "\n", "self", ".", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "self", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.extract_text_features": [[52, 84], ["list", "token.split", "all", "zip", "tuple", "len", "len"], "methods", ["None"], ["\n", "", "@", "staticmethod", "\n", "def", "extract_text_features", "(", "tokens", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokens: A list of tokens, where each token consists of a word,\n                optionally followed by u\"\uffe8\"-delimited features.\n        Returns:\n            A sequence of words, a sequence of features, and num of features.\n        \"\"\"", "\n", "if", "not", "tokens", ":", "\n", "            ", "return", "[", "]", ",", "[", "]", ",", "-", "1", "\n", "\n", "", "specials", "=", "[", "PAD_WORD", ",", "UNK_WORD", ",", "BOS_WORD", ",", "EOS_WORD", "]", "\n", "words", "=", "[", "]", "\n", "features", "=", "[", "]", "\n", "n_feats", "=", "None", "\n", "\n", "#TODO We stop here", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "split_token", "=", "token", ".", "split", "(", "u\"\uffe8\"", ")", "\n", "assert", "all", "(", "[", "special", "!=", "split_token", "[", "0", "]", "for", "special", "in", "specials", "]", ")", ",", "\"Dataset cannot contain Special Tokens\"", "\n", "\n", "if", "split_token", "[", "0", "]", ":", "\n", "                ", "words", "+=", "[", "split_token", "[", "0", "]", "]", "\n", "features", "+=", "[", "split_token", "[", "1", ":", "]", "]", "\n", "\n", "if", "n_feats", "is", "None", ":", "\n", "                    ", "n_feats", "=", "len", "(", "split_token", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "len", "(", "split_token", ")", "==", "n_feats", ",", "\"all words must have the same number of features\"", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._join_dicts": [[87, 96], ["dict", "itertools.chain", "d.items"], "methods", ["None"], ["return", "tuple", "(", "words", ")", ",", "features", ",", "n_feats", "-", "1", "\n", "\n", "# Below are helper functions for intra-class use only.", "\n", "\n", "", "def", "_join_dicts", "(", "self", ",", "*", "args", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._peek": [[97, 109], ["next", "itertools.chain"], "methods", ["None"], ["\n", "return", "dict", "(", "chain", "(", "*", "[", "d", ".", "items", "(", ")", "for", "d", "in", "args", "]", ")", ")", "\n", "\n", "", "def", "_peek", "(", "self", ",", "seq", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._construct_example_fromlist": [[110, 129], ["torchtext.data.Example", "zip", "setattr", "setattr", "field.preprocess"], "methods", ["None"], ["\n", "first", "=", "next", "(", "seq", ")", "\n", "return", "first", ",", "chain", "(", "[", "first", "]", ",", "seq", ")", "\n", "\n", "", "def", "_construct_example_fromlist", "(", "self", ",", "data", ",", "fields", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data: the data to be set as the value of the attributes of\n                the to-be-created `Example`, associating with respective\n                `Field` objects with same key.\n            fields: a dict of `torchtext.data.Field` objects. The keys\n                are attributes of the to-be-created `Example`.\n\n        Returns:\n            the created `Example` object.\n        \"\"\"", "\n", "ex", "=", "torchtext", ".", "data", ".", "Example", "(", ")", "\n", "# import pdb;pdb.set_trace()", "\n", "for", "(", "name", ",", "field", ")", ",", "val", "in", "zip", "(", "fields", ",", "data", ")", ":", "\n", "            ", "if", "field", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.__init__": [[40, 88], ["audio_dataset.AudioDataset._peek", "ex.keys", "list", "onmt.inputters.dataset_base.DatasetBase.__init__", "audio_dataset.AudioDataset._construct_example_fromlist", "audio_dataset.AudioDataset._join_dicts", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._peek", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "tgt_seq_length", "=", "0", ",", "sample_rate", "=", "0", ",", "\n", "window_size", "=", "0.0", ",", "window_stride", "=", "0.0", ",", "window", "=", "None", ",", "\n", "normalize_audio", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'audio'", "\n", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "window_stride", "=", "window_stride", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "normalize_audio", "=", "normalize_audio", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "out_examples", "=", "(", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "for", "ex_values", "in", "example_values", ")", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "out_examples", "=", "list", "(", "out_examples", ")", "\n", "\n", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "\"\"\"    ?    \"\"\"", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "                ", "return", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "AudioDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.sort_key": [[90, 93], ["ex.src.size"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using duration time of the sound spectrogram. \"\"\"", "\n", "return", "ex", ".", "src", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.make_audio_examples_nfeats_tpl": [[94, 121], ["audio_dataset.AudioDataset.read_audio_file"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.read_audio_file"], ["", "@", "staticmethod", "\n", "def", "make_audio_examples_nfeats_tpl", "(", "path", ",", "audio_dir", ",", "\n", "sample_rate", ",", "window_size", ",", "\n", "window_stride", ",", "window", ",", "\n", "normalize_audio", ",", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing audio paths.\n            audio_dir (str): location of source audio files.\n            sample_rate (int): sample_rate.\n            window_size (float) : window size for spectrogram in seconds.\n            window_stride (float): window stride for spectrogram in seconds.\n            window (str): window type for spectrogram generation.\n            normalize_audio (bool): subtract spectrogram by mean and divide\n                by std or not.\n            truncate (int): maximum audio length (0 or None for unlimited).\n\n        Returns:\n            (example_dict iterator, num_feats) tuple\n        \"\"\"", "\n", "examples_iter", "=", "AudioDataset", ".", "read_audio_file", "(", "\n", "path", ",", "audio_dir", ",", "\"src\"", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "window", ",", "\n", "normalize_audio", ",", "truncate", ")", "\n", "num_feats", "=", "0", "# Source side(audio) has no features.", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.read_audio_file": [[122, 196], ["os.path.exists", "codecs.open", "os.path.join", "os.path.exists", "torchaudio.load", "sound.mean.mean.numpy", "int", "int", "librosa.stft", "librosa.magphase", "np.log1p", "torch.FloatTensor", "line.strip", "os.path.exists", "line.strip", "len", "torch.FloatTensor.mean", "torch.FloatTensor.std", "torch.FloatTensor.add_", "torch.FloatTensor.div_", "line.strip", "sound.mean.mean.size", "sound.mean.mean.squeeze", "sound.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "@", "staticmethod", "\n", "def", "read_audio_file", "(", "path", ",", "src_dir", ",", "side", ",", "sample_rate", ",", "window_size", ",", "\n", "window_stride", ",", "window", ",", "normalize_audio", ",", "\n", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing audio paths.\n            src_dir (str): location of source audio files.\n            side (str): 'src' or 'tgt'.\n            sample_rate (int): sample_rate.\n            window_size (float) : window size for spectrogram in seconds.\n            window_stride (float): window stride for spectrogram in seconds.\n            window (str): window type for spectrogram generation.\n            normalize_audio (bool): subtract spectrogram by mean and divide\n                by std or not.\n            truncate (int): maximum audio length (0 or None for unlimited).\n\n        Yields:\n            a dictionary containing audio data for each line.\n        \"\"\"", "\n", "assert", "(", "src_dir", "is", "not", "None", ")", "and", "os", ".", "path", ".", "exists", "(", "src_dir", ")", ",", "\"src_dir must be a valid directory if data_type is audio\"", "\n", "\n", "import", "torchaudio", "\n", "import", "librosa", "\n", "import", "numpy", "as", "np", "\n", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "index", "=", "0", "\n", "for", "line", "in", "corpus_file", ":", "\n", "                ", "audio_path", "=", "os", ".", "path", ".", "join", "(", "src_dir", ",", "line", ".", "strip", "(", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ":", "\n", "                    ", "audio_path", "=", "line", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ",", "'audio path %s not found'", "%", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "sound", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "audio_path", ")", "\n", "if", "truncate", "and", "truncate", ">", "0", ":", "\n", "                    ", "if", "sound", ".", "size", "(", "0", ")", ">", "truncate", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "assert", "sample_rate", "==", "sample_rate", ",", "'Sample rate of %s != -sample_rate (%d vs %d)'", "%", "(", "audio_path", ",", "sample_rate", ",", "sample_rate", ")", "\n", "\n", "sound", "=", "sound", ".", "numpy", "(", ")", "\n", "if", "len", "(", "sound", ".", "shape", ")", ">", "1", ":", "\n", "                    ", "if", "sound", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "                        ", "sound", "=", "sound", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                        ", "sound", "=", "sound", ".", "mean", "(", "axis", "=", "1", ")", "# average multiple channels", "\n", "\n", "", "", "n_fft", "=", "int", "(", "sample_rate", "*", "window_size", ")", "\n", "win_length", "=", "n_fft", "\n", "hop_length", "=", "int", "(", "sample_rate", "*", "window_stride", ")", "\n", "# STFT", "\n", "d", "=", "librosa", ".", "stft", "(", "sound", ",", "n_fft", "=", "n_fft", ",", "hop_length", "=", "hop_length", ",", "\n", "win_length", "=", "win_length", ",", "window", "=", "window", ")", "\n", "spect", ",", "_", "=", "librosa", ".", "magphase", "(", "d", ")", "\n", "spect", "=", "np", ".", "log1p", "(", "spect", ")", "\n", "spect", "=", "torch", ".", "FloatTensor", "(", "spect", ")", "\n", "if", "normalize_audio", ":", "\n", "                    ", "mean", "=", "spect", ".", "mean", "(", ")", "\n", "std", "=", "spect", ".", "std", "(", ")", "\n", "spect", ".", "add_", "(", "-", "mean", ")", "\n", "spect", ".", "div_", "(", "std", ")", "\n", "\n", "", "example_dict", "=", "{", "side", ":", "spect", ",", "\n", "side", "+", "'_path'", ":", "line", ".", "strip", "(", ")", ",", "\n", "'indices'", ":", "index", "}", "\n", "index", "+=", "1", "\n", "\n", "yield", "example_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields": [[197, 269], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "data[].size", "max", "torch.zeros", "enumerate", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "len", "max", "len", "enumerate", "max.size", "max.size", "max.size", "torch.zeros", "str", "str", "max.max", "len", "spect.size", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features: the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features: the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "def", "make_audio", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "nfft", "=", "data", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "t", "=", "max", "(", "[", "t", ".", "size", "(", "1", ")", "for", "t", "in", "data", "]", ")", "\n", "sounds", "=", "torch", ".", "zeros", "(", "len", "(", "data", ")", ",", "1", ",", "nfft", ",", "t", ")", "\n", "for", "i", ",", "spect", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "sounds", "[", "i", ",", ":", ",", ":", ",", "0", ":", "spect", ".", "size", "(", "1", ")", "]", "=", "spect", "\n", "", "return", "sounds", "\n", "\n", "", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_audio", ",", "sequential", "=", "False", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features": [[270, 292], ["codecs.open", "cf.readline().strip().split", "AudioDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.dataset_base.DatasetBase.extract_text_features"], ["", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        For audio corpus, source side is in form of audio, thus\n        no feature; while target side is in form of text, thus\n        we can extract its text features.\n\n        Args:\n            corpus_file (str): file path to get the features.\n            side (str): 'src' or 'tgt'.\n\n        Returns:\n            number of features on `side`.\n        \"\"\"", "\n", "if", "side", "==", "'src'", ":", "\n", "            ", "num_feats", "=", "0", "\n", "", "else", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "                ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "AudioDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "", "return", "num_feats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.util_class.LayerNorm.__init__": [[11, 16], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.util_class.LayerNorm.forward": [[17, 21], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.util_class.Elementwise.__init__": [[35, 39], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "merge", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "assert", "merge", "in", "[", "None", ",", "'first'", ",", "'concat'", ",", "'sum'", ",", "'mlp'", "]", "\n", "self", ".", "merge", "=", "merge", "\n", "super", "(", "Elementwise", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.util_class.Elementwise.forward": [[40, 52], ["feat.squeeze", "len", "len", "f", "inputs.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "inputs_", "=", "[", "feat", ".", "squeeze", "(", "2", ")", "for", "feat", "in", "inputs", ".", "split", "(", "1", ",", "dim", "=", "2", ")", "]", "\n", "assert", "len", "(", "self", ")", "==", "len", "(", "inputs_", ")", "\n", "outputs", "=", "[", "f", "(", "x", ")", "for", "f", ",", "x", "in", "zip", "(", "self", ",", "inputs_", ")", "]", "\n", "if", "self", ".", "merge", "==", "'first'", ":", "\n", "            ", "return", "outputs", "[", "0", "]", "\n", "", "elif", "self", ".", "merge", "==", "'concat'", "or", "self", ".", "merge", "==", "'mlp'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "2", ")", "\n", "", "elif", "self", ".", "merge", "==", "'sum'", ":", "\n", "            ", "return", "sum", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "return", "outputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.conv_multi_step_attention.ConvMultiStepAttention.__init__": [[29, 33], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ")", ":", "\n", "        ", "super", "(", "ConvMultiStepAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.conv_multi_step_attention.ConvMultiStepAttention.apply_mask": [[34, 37], ["None"], "methods", ["None"], ["", "def", "apply_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "\"\"\" Apply mask \"\"\"", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.conv_multi_step_attention.ConvMultiStepAttention.forward": [[38, 84], ["base_target_emb.size", "input_from_dec.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "encoder_out_top.size", "encoder_out_combine.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "conv_multi_step_attention.seq_linear", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "pre_attn.transpose.transpose.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "attn.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "pre_attn.transpose.transpose.data.masked_fill_", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "attn.transpose().contiguous.transpose().contiguous.transpose", "float"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.conv_multi_step_attention.seq_linear", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "base_target_emb", ",", "input_from_dec", ",", "encoder_out_top", ",", "\n", "encoder_out_combine", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            base_target_emb: target emb tensor\n            input: output of decode conv\n            encoder_out_t: the key matrix for calculation of attetion weight,\n                which is the top output of encode conv\n            encoder_out_combine:\n                the value matrix for the attention-weighted sum,\n                which is the combination of base emb and top output of encode\n\n        \"\"\"", "\n", "# checks", "\n", "# batch, channel, height, width = base_target_emb.size()", "\n", "batch", ",", "_", ",", "height", ",", "_", "=", "base_target_emb", ".", "size", "(", ")", "\n", "# batch_, channel_, height_, width_ = input_from_dec.size()", "\n", "batch_", ",", "_", ",", "height_", ",", "_", "=", "input_from_dec", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "height", ",", "height_", ")", "\n", "\n", "# enc_batch, enc_channel, enc_height = encoder_out_top.size()", "\n", "enc_batch", ",", "_", ",", "enc_height", "=", "encoder_out_top", ".", "size", "(", ")", "\n", "# enc_batch_, enc_channel_, enc_height_ = encoder_out_combine.size()", "\n", "enc_batch_", ",", "_", ",", "enc_height_", "=", "encoder_out_combine", ".", "size", "(", ")", "\n", "\n", "aeq", "(", "enc_batch", ",", "enc_batch_", ")", "\n", "aeq", "(", "enc_height", ",", "enc_height_", ")", "\n", "\n", "preatt", "=", "seq_linear", "(", "self", ".", "linear_in", ",", "input_from_dec", ")", "\n", "target", "=", "(", "base_target_emb", "+", "preatt", ")", "*", "SCALE_WEIGHT", "\n", "target", "=", "torch", ".", "squeeze", "(", "target", ",", "3", ")", "\n", "target", "=", "torch", ".", "transpose", "(", "target", ",", "1", ",", "2", ")", "\n", "pre_attn", "=", "torch", ".", "bmm", "(", "target", ",", "encoder_out_top", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "pre_attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "pre_attn", "=", "pre_attn", ".", "transpose", "(", "0", ",", "2", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "pre_attn", ",", "dim", "=", "-", "1", ")", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "context_output", "=", "torch", ".", "bmm", "(", "\n", "attn", ",", "torch", ".", "transpose", "(", "encoder_out_combine", ",", "1", ",", "2", ")", ")", "\n", "context_output", "=", "torch", ".", "transpose", "(", "\n", "torch", ".", "unsqueeze", "(", "context_output", ",", "3", ")", ",", "1", ",", "2", ")", "\n", "return", "context_output", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.conv_multi_step_attention.seq_linear": [[11, 17], ["x.size", "linear", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "linear.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "seq_linear", "(", "linear", ",", "x", ")", ":", "\n", "    ", "\"\"\" linear transform for 3-d tensor \"\"\"", "\n", "batch", ",", "hidden_size", ",", "length", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "h", "=", "linear", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch", "*", "length", ",", "hidden_size", ")", ")", "\n", "return", "torch", ".", "transpose", "(", "h", ".", "view", "(", "batch", ",", "length", ",", "hidden_size", ",", "1", ")", ",", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.multi_headed_attn.MultiHeadedAttention.__init__": [[51, 68], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "assert", "model_dim", "%", "head_count", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head_count", "=", "head_count", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.multi_headed_attn.MultiHeadedAttention.forward": [[69, 202], ["shape.size", "shape.size", "multi_headed_attn.MultiHeadedAttention.size", "multi_headed_attn.MultiHeadedAttention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "query", ",", "mask", "=", "None", ",", "\n", "layer_cache", "=", "None", ",", "type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n\n        Args:\n           key (`FloatTensor`): set of `key_len`\n                key vectors `[batch, key_len, dim]`\n           value (`FloatTensor`): set of `key_len`\n                value vectors `[batch, key_len, dim]`\n           query (`FloatTensor`): set of `query_len`\n                 query vectors  `[batch, query_len, dim]`\n           mask: binary mask indicating which keys have\n                 non-zero attention `[batch, query_len, key_len]`\n        Returns:\n           (`FloatTensor`, `FloatTensor`) :\n\n           * output context vectors `[batch, query_len, dim]`\n           * one of the attention vectors `[batch, query_len, key_len]`\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "# batch, k_len, d = key.size()", "\n", "# batch_, k_len_, d_ = value.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(k_len, k_len_)", "\n", "# aeq(d, d_)", "\n", "# batch_, q_len, d_ = query.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "# aeq(self.model_dim % 8, 0)", "\n", "# if mask is not None:", "\n", "#    batch_, q_len_, k_len_ = mask.size()", "\n", "#    aeq(batch_, batch)", "\n", "#    aeq(k_len_, k_len)", "\n", "#    aeq(q_len_ == q_len)", "\n", "# END CHECKS", "\n", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "head_count", "=", "self", ".", "head_count", "\n", "key_len", "=", "key", ".", "size", "(", "1", ")", "\n", "query_len", "=", "query", ".", "size", "(", "1", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", "*", "dim_per_head", ")", "\n", "\n", "# 1) Project key, value, and query.", "\n", "", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "if", "type", "==", "\"self\"", ":", "\n", "                ", "query", ",", "key", ",", "value", "=", "self", ".", "linear_query", "(", "query", ")", ",", "self", ".", "linear_keys", "(", "query", ")", ",", "self", ".", "linear_values", "(", "query", ")", "\n", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "device", "=", "key", ".", "device", "\n", "if", "layer_cache", "[", "\"self_keys\"", "]", "is", "not", "None", ":", "\n", "                        ", "key", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_keys\"", "]", ".", "to", "(", "device", ")", ",", "key", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "if", "layer_cache", "[", "\"self_values\"", "]", "is", "not", "None", ":", "\n", "                        ", "value", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_values\"", "]", ".", "to", "(", "device", ")", ",", "value", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "layer_cache", "[", "\"self_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "value", "\n", "", "", "elif", "type", "==", "\"context\"", ":", "\n", "                ", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "if", "layer_cache", "[", "\"memory_keys\"", "]", "is", "None", ":", "\n", "                        ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "else", ":", "\n", "                        ", "key", ",", "value", "=", "layer_cache", "[", "\"memory_keys\"", "]", ",", "layer_cache", "[", "\"memory_values\"", "]", "\n", "", "layer_cache", "[", "\"memory_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"memory_values\"", "]", "=", "value", "\n", "", "else", ":", "\n", "                    ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "", "", "else", ":", "\n", "            ", "key", "=", "self", ".", "linear_keys", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_values", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "", "query", "=", "shape", "(", "query", ")", "\n", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "query_len", "=", "query", ".", "size", "(", "2", ")", "\n", "\n", "# 2) Calculate and scale scores.", "\n", "query", "=", "query", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "scores", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e18", ")", "\n", "\n", "# 3) Apply attention dropout and compute context vectors.", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", "\n", "drop_attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "context", "=", "unshape", "(", "torch", ".", "matmul", "(", "drop_attn", ",", "value", ")", ")", "\n", "\n", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "# CHECK", "\n", "# batch_, q_len_, d_ = output.size()", "\n", "# aeq(q_len, q_len_)", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "\n", "# Return one attn", "\n", "top_attn", "=", "attn", ".", "view", "(", "batch_size", ",", "head_count", ",", "\n", "query_len", ",", "key_len", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", ",", "top_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.structured_attention.MatrixTree.__init__": [[16, 19], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "self", ".", "eps", "=", "eps", "\n", "super", "(", "MatrixTree", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.structured_attention.MatrixTree.forward": [[20, 42], ["input.clone", "range", "input.exp", "input.size", "laplacian[].masked_fill", "input[].diag().exp", "laplacian[].masked_fill.inverse", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as().transpose", "input[].exp().mul().clone", "input[].exp().mul().clone", "input[].diag().exp().mul", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "laplacian[].masked_fill.sum", "input[].diag", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as", "input[].exp().mul", "input[].exp().mul", "input[].diag().exp", "laplacian[].masked_fill.inverse.transpose", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "laplacian[].masked_fill.inverse.transpose", "laplacian[].masked_fill.inverse.diag().unsqueeze", "input[].exp", "input[].exp", "input[].diag", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "input.size", "laplacian[].masked_fill.inverse.diag"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "laplacian", "=", "input", ".", "exp", "(", ")", "+", "self", ".", "eps", "\n", "output", "=", "input", ".", "clone", "(", ")", "\n", "for", "b", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "lap", "=", "laplacian", "[", "b", "]", ".", "masked_fill", "(", "\n", "torch", ".", "eye", "(", "input", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", ".", "ne", "(", "0", ")", ",", "0", ")", "\n", "lap", "=", "-", "lap", "+", "torch", ".", "diag", "(", "lap", ".", "sum", "(", "0", ")", ")", "\n", "# store roots on diagonal", "\n", "lap", "[", "0", "]", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", "\n", "inv_laplacian", "=", "lap", ".", "inverse", "(", ")", "\n", "\n", "factor", "=", "inv_laplacian", ".", "diag", "(", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "input", "[", "b", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "term1", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "factor", ")", ".", "clone", "(", ")", "\n", "term2", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "clone", "(", ")", "\n", "term1", "[", ":", ",", "0", "]", "=", "0", "\n", "term2", "[", "0", "]", "=", "0", "\n", "output", "[", "b", "]", "=", "term1", "-", "term2", "\n", "roots_output", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", ".", "mul", "(", "\n", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", "[", "0", "]", ")", "\n", "output", "[", "b", "]", "=", "output", "[", "b", "]", "+", "torch", ".", "diag", "(", "roots_output", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.average_attn.AverageAttention.__init__": [[22, 30], ["torch.Module.__init__", "onmt.modules.position_ffn.PositionwiseFeedForward", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "model_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "AverageAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "average_layer", "=", "PositionwiseFeedForward", "(", "model_dim", ",", "model_dim", ",", "\n", "dropout", ")", "\n", "self", ".", "gating_layer", "=", "nn", ".", "Linear", "(", "model_dim", "*", "2", ",", "model_dim", "*", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.average_attn.AverageAttention.cumulative_average_mask": [[31, 52], ["torch.tril", "torch.tril", "torch.tril", "torch.tril", "mask.unsqueeze().expand", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "weights.transpose", "mask.unsqueeze"], "methods", ["None"], ["", "def", "cumulative_average_mask", "(", "self", ",", "batch_size", ",", "inputs_len", ")", ":", "\n", "        ", "\"\"\"\n        Builds the mask to compute the cumulative average as described in\n        https://arxiv.org/abs/1805.00631 -- Figure 3\n\n        Args:\n            batch_size (int): batch size\n            inputs_len (int): length of the inputs\n\n        Returns:\n            (`FloatTensor`):\n\n            * A Tensor of shape `[batch_size x input_len x input_len]`\n        \"\"\"", "\n", "\n", "triangle", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "inputs_len", ",", "inputs_len", ")", ")", "\n", "weights", "=", "torch", ".", "ones", "(", "1", ",", "inputs_len", ")", "/", "torch", ".", "arange", "(", "\n", "1", ",", "inputs_len", "+", "1", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "mask", "=", "triangle", "*", "weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "inputs_len", ",", "inputs_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.average_attn.AverageAttention.cumulative_average": [[53, 79], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "layer_cache[].to"], "methods", ["None"], ["", "def", "cumulative_average", "(", "self", ",", "inputs", ",", "mask_or_step", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the cumulative average as described in\n        https://arxiv.org/abs/1805.00631 -- Equations (1) (5) (6)\n\n        Args:\n            inputs (`FloatTensor`): sequence to average\n                `[batch_size x input_len x dimension]`\n            mask_or_step: if cache is set, this is assumed\n                to be the current step of the\n                dynamic decoding. Otherwise, it is the mask matrix\n                used to compute the cumulative average.\n            cache: a dictionary containing the cumulative average\n                of the previous step.\n        \"\"\"", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "step", "=", "mask_or_step", "\n", "device", "=", "inputs", ".", "device", "\n", "average_attention", "=", "(", "inputs", "+", "step", "*", "\n", "layer_cache", "[", "\"prev_g\"", "]", ".", "to", "(", "device", ")", ")", "/", "(", "step", "+", "1", ")", "\n", "layer_cache", "[", "\"prev_g\"", "]", "=", "average_attention", "\n", "return", "average_attention", "\n", "", "else", ":", "\n", "            ", "mask", "=", "mask_or_step", "\n", "return", "torch", ".", "matmul", "(", "mask", ",", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.average_attn.AverageAttention.forward": [[80, 107], ["inputs.size", "inputs.size", "average_attn.AverageAttention.cumulative_average", "average_attn.AverageAttention.average_layer", "average_attn.AverageAttention.gating_layer", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "average_attn.AverageAttention.cumulative_average_mask().to().float", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "average_attn.AverageAttention.cumulative_average_mask().to", "average_attn.AverageAttention.cumulative_average_mask"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.average_attn.AverageAttention.cumulative_average", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.average_attn.AverageAttention.cumulative_average_mask"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "mask", "=", "None", ",", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (`FloatTensor`): `[batch_size x input_len x model_dim]`\n\n        Returns:\n            (`FloatTensor`, `FloatTensor`):\n\n            * gating_outputs `[batch_size x 1 x model_dim]`\n            * average_outputs average attention `[batch_size x 1 x model_dim]`\n        \"\"\"", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "inputs_len", "=", "inputs", ".", "size", "(", "1", ")", "\n", "\n", "device", "=", "inputs", ".", "device", "\n", "average_outputs", "=", "self", ".", "cumulative_average", "(", "\n", "inputs", ",", "self", ".", "cumulative_average_mask", "(", "batch_size", ",", "\n", "inputs_len", ")", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "if", "layer_cache", "is", "None", "else", "step", ",", "layer_cache", "=", "layer_cache", ")", "\n", "average_outputs", "=", "self", ".", "average_layer", "(", "average_outputs", ")", "\n", "gating_outputs", "=", "self", ".", "gating_layer", "(", "torch", ".", "cat", "(", "(", "inputs", ",", "\n", "average_outputs", ")", ",", "-", "1", ")", ")", "\n", "input_gate", ",", "forget_gate", "=", "torch", ".", "chunk", "(", "gating_outputs", ",", "2", ",", "dim", "=", "2", ")", "\n", "gating_outputs", "=", "torch", ".", "sigmoid", "(", "input_gate", ")", "*", "inputs", "+", "torch", ".", "sigmoid", "(", "forget_gate", ")", "*", "average_outputs", "\n", "\n", "return", "gating_outputs", ",", "average_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_losses.SparsemaxLossFunction.forward": [[10, 32], ["input.size", "target.size", "onmt.utils.misc.aeq", "input.gather().squeeze", "onmt.modules.sparse_activations.threshold_and_support", "torch.where().sum", "torch.where().sum", "torch.where().sum", "torch.where().sum", "ctx.save_for_backward", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "input.gather", "torch.where", "torch.where", "torch.where", "torch.where", "target.unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.threshold_and_support"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        input (FloatTensor): n x num_classes\n        target (LongTensor): n, the indices of the target classes\n        \"\"\"", "\n", "input_batch", ",", "classes", "=", "input", ".", "size", "(", ")", "\n", "target_batch", "=", "target", ".", "size", "(", "0", ")", "\n", "aeq", "(", "input_batch", ",", "target_batch", ")", "\n", "\n", "z_k", "=", "input", ".", "gather", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "tau_z", ",", "support_size", "=", "threshold_and_support", "(", "input", ",", "dim", "=", "1", ")", "\n", "support", "=", "input", ">", "tau_z", "\n", "x", "=", "torch", ".", "where", "(", "\n", "support", ",", "input", "**", "2", "-", "tau_z", "**", "2", ",", "\n", "torch", ".", "tensor", "(", "0.0", ",", "device", "=", "input", ".", "device", ")", "\n", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "target", ",", "tau_z", ")", "\n", "# clamping necessary because of numerical errors: loss should be lower", "\n", "# bounded by zero, but negative values near zero are possible without", "\n", "# the clamp", "\n", "return", "torch", ".", "clamp", "(", "x", "/", "2", "-", "z_k", "+", "0.5", ",", "min", "=", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_losses.SparsemaxLossFunction.backward": [[33, 40], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "target.unsqueeze"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "target", ",", "tau_z", "=", "ctx", ".", "saved_tensors", "\n", "sparsemax_out", "=", "torch", ".", "clamp", "(", "input", "-", "tau_z", ",", "min", "=", "0", ")", "\n", "delta", "=", "torch", ".", "zeros_like", "(", "sparsemax_out", ")", "\n", "delta", ".", "scatter_", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ",", "1", ")", "\n", "return", "sparsemax_out", "-", "delta", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_losses.SparsemaxLoss.__init__": [[57, 64], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "weight", "=", "None", ",", "ignore_index", "=", "-", "100", ",", "\n", "reduce", "=", "True", ",", "size_average", "=", "True", ")", ":", "\n", "        ", "self", ".", "weight", "=", "weight", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "self", ".", "reduce", "=", "reduce", "\n", "self", ".", "size_average", "=", "size_average", "\n", "super", "(", "SparsemaxLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_losses.SparsemaxLoss.forward": [[65, 78], ["sparsemax_loss", "float", "loss.sum.sum.masked_fill_", "float", "loss.sum.sum.sum", "target.size", "target.size", "ignored_positions.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "loss", "=", "sparsemax_loss", "(", "input", ",", "target", ")", "\n", "if", "self", ".", "ignore_index", ">=", "0", ":", "\n", "            ", "ignored_positions", "=", "target", "==", "self", ".", "ignore_index", "\n", "size", "=", "float", "(", "(", "target", ".", "size", "(", "0", ")", "-", "ignored_positions", ".", "sum", "(", ")", ")", ".", "item", "(", ")", ")", "\n", "loss", ".", "masked_fill_", "(", "ignored_positions", ",", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "float", "(", "target", ".", "size", "(", "0", ")", ")", "\n", "", "if", "self", ".", "reduce", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "if", "self", ".", "size_average", ":", "\n", "                ", "loss", "=", "loss", "/", "size", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.position_ffn.PositionwiseFeedForward.__init__": [[20, 28], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "onmt.modules.LayerNorm", "torch.Dropout", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout_1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout_2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.position_ffn.PositionwiseFeedForward.forward": [[29, 43], ["position_ffn.PositionwiseFeedForward.dropout_1", "position_ffn.PositionwiseFeedForward.dropout_2", "position_ffn.PositionwiseFeedForward.relu", "position_ffn.PositionwiseFeedForward.w_2", "position_ffn.PositionwiseFeedForward.w_1", "position_ffn.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Layer definition.\n\n        Args:\n            input: [ batch_size, input_len, model_dim ]\n\n\n        Returns:\n            output: [ batch_size, input_len, model_dim ]\n        \"\"\"", "\n", "inter", "=", "self", ".", "dropout_1", "(", "self", ".", "relu", "(", "self", ".", "w_1", "(", "self", ".", "layer_norm", "(", "x", ")", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout_2", "(", "self", ".", "w_2", "(", "inter", ")", ")", "\n", "return", "output", "+", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGenerator.__init__": [[63, 70], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", "CopyGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "len", "(", "tgt_dict", ")", ")", "\n", "self", ".", "linear_copy", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ")", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGenerator.forward": [[71, 107], ["hidden.size", "attn.size", "src_map.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "copy_generator.CopyGenerator.linear", "copy_generator.CopyGenerator.softmax", "copy_generator.CopyGenerator.sigmoid", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "copy_prob.contiguous().view.contiguous().view.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "float", "copy_generator.CopyGenerator.linear_copy", "copy_generator.CopyGenerator.expand_as", "copy_generator.CopyGenerator.expand_as", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "copy_prob.contiguous().view.contiguous().view.contiguous", "torch.mul.view().transpose", "torch.mul.view().transpose", "torch.mul.view().transpose", "src_map.transpose", "torch.mul.view", "torch.mul.view", "torch.mul.view"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "attn", ",", "src_map", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        extended by the dynamic dictionary implied by compying\n        source words.\n\n        Args:\n           hidden (`FloatTensor`): hidden outputs `[batch*tlen, input_size]`\n           attn (`FloatTensor`): attn for each `[batch*tlen, input_size]`\n           src_map (`FloatTensor`):\n             A sparse indicator matrix mapping each source word to\n             its index in the \"extended\" vocab containing.\n             `[src_len, batch, extra_words]`\n        \"\"\"", "\n", "# CHECKS", "\n", "batch_by_tlen", ",", "_", "=", "hidden", ".", "size", "(", ")", "\n", "batch_by_tlen_", ",", "slen", "=", "attn", ".", "size", "(", ")", "\n", "slen_", ",", "batch", ",", "cvocab", "=", "src_map", ".", "size", "(", ")", "\n", "aeq", "(", "batch_by_tlen", ",", "batch_by_tlen_", ")", "\n", "aeq", "(", "slen", ",", "slen_", ")", "\n", "\n", "# Original probabilities.", "\n", "logits", "=", "self", ".", "linear", "(", "hidden", ")", "\n", "logits", "[", ":", ",", "self", ".", "tgt_dict", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "prob", "=", "self", ".", "softmax", "(", "logits", ")", "\n", "\n", "# Probability of copying p(z=1) batch.", "\n", "p_copy", "=", "self", ".", "sigmoid", "(", "self", ".", "linear_copy", "(", "hidden", ")", ")", "\n", "# Probibility of not copying: p_{word}(w) * (1 - p(z))", "\n", "out_prob", "=", "torch", ".", "mul", "(", "prob", ",", "1", "-", "p_copy", ".", "expand_as", "(", "prob", ")", ")", "\n", "mul_attn", "=", "torch", ".", "mul", "(", "attn", ",", "p_copy", ".", "expand_as", "(", "attn", ")", ")", "\n", "copy_prob", "=", "torch", ".", "bmm", "(", "mul_attn", ".", "view", "(", "-", "1", ",", "batch", ",", "slen", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "src_map", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "copy_prob", "=", "copy_prob", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "cvocab", ")", "\n", "return", "torch", ".", "cat", "(", "[", "out_prob", ",", "copy_prob", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorCriterion.__init__": [[112, 117], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "force_copy", ",", "pad", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "offset", "=", "vocab_size", "\n", "self", ".", "pad", "=", "pad", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorCriterion.__call__": [[118, 146], ["align.eq().float", "align.ne().float", "target.eq().float", "target.ne().float", "scores.gather().view", "scores.gather().view", "scores.gather().view.mul", "scores.gather().view.log().mul", "align.eq", "align.ne", "target.eq", "target.ne", "scores.gather", "scores.gather", "scores.gather().view.mul", "scores.gather().view.mul().mul", "scores.gather().view.mul", "target.ne().float", "target.view", "scores.gather().view.log", "align.view", "scores.gather().view.mul", "target.ne"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log"], ["", "def", "__call__", "(", "self", ",", "scores", ",", "align", ",", "target", ")", ":", "\n", "#pdb.set_trace()", "\n", "# Compute unks in align and target for readability", "\n", "        ", "align_unk", "=", "align", ".", "eq", "(", "0", ")", ".", "float", "(", ")", "\n", "align_not_unk", "=", "align", ".", "ne", "(", "0", ")", ".", "float", "(", ")", "\n", "target_unk", "=", "target", ".", "eq", "(", "0", ")", ".", "float", "(", ")", "\n", "target_not_unk", "=", "target", ".", "ne", "(", "0", ")", ".", "float", "(", ")", "\n", "\n", "# Copy probability of tokens in source", "\n", "out", "=", "scores", ".", "gather", "(", "1", ",", "align", ".", "view", "(", "-", "1", ",", "1", ")", "+", "self", ".", "offset", ")", ".", "view", "(", "-", "1", ")", "\n", "# Set scores for unk to 0 and add eps", "\n", "out", "=", "out", ".", "mul", "(", "align_not_unk", ")", "+", "self", ".", "eps", "\n", "# Get scores for tokens in target", "\n", "tmp", "=", "scores", ".", "gather", "(", "1", ",", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Regular prob (no unks and unks that can't be copied)", "\n", "if", "not", "self", ".", "force_copy", ":", "\n", "# Add score for non-unks in target", "\n", "            ", "out", "=", "out", "+", "tmp", ".", "mul", "(", "target_not_unk", ")", "\n", "# Add score for when word is unk in both align and tgt", "\n", "out", "=", "out", "+", "tmp", ".", "mul", "(", "align_unk", ")", ".", "mul", "(", "target_unk", ")", "\n", "", "else", ":", "\n", "# Forced copy. Add only probability for not-copied tokens", "\n", "            ", "out", "=", "out", "+", "tmp", ".", "mul", "(", "align_unk", ")", "\n", "\n", "# Drop padding.", "\n", "", "loss", "=", "-", "out", ".", "log", "(", ")", ".", "mul", "(", "target", ".", "ne", "(", "self", ".", "pad", ")", ".", "float", "(", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorLossCompute.__init__": [[153, 162], ["onmt.utils.loss.LossComputeBase.__init__", "copy_generator.CopyGeneratorCriterion", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ",", "\n", "force_copy", ",", "normalize_by_length", ",", "\n", "eps", "=", "1e-20", ")", ":", "\n", "        ", "super", "(", "CopyGeneratorLossCompute", ",", "self", ")", ".", "__init__", "(", "\n", "generator", ",", "tgt_vocab", ")", "\n", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "normalize_by_length", "=", "normalize_by_length", "\n", "self", ".", "criterion", "=", "CopyGeneratorCriterion", "(", "len", "(", "tgt_vocab", ")", ",", "force_copy", ",", "\n", "self", ".", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state": [[163, 174], ["getattr", "AssertionError", "attns.get"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", ")", ":", "\n", "        ", "\"\"\" See base class for args description. \"\"\"", "\n", "if", "getattr", "(", "batch", ",", "\"alignment\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"using -copy_attn you need to pass in \"", "\n", "\"-dynamic_dict during preprocess stage.\"", ")", "\n", "\n", "", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", ",", "\n", "\"copy_attn\"", ":", "attns", ".", "get", "(", "\"copy\"", ")", ",", "\n", "\"align\"", ":", "batch", ".", "alignment", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.copy_generator.CopyGeneratorLossCompute._compute_loss": [[176, 223], ["target.view.view.view", "align.view.view.view", "copy_generator.CopyGeneratorLossCompute.generator", "copy_generator.CopyGeneratorLossCompute.criterion", "copy_generator.CopyGeneratorLossCompute.data.clone", "onmt.TextDataset.collapse_copy_scores", "copy_generator.CopyGeneratorLossCompute._bottle", "target.view.view.data.clone", "loss.sum.sum.sum().data.clone", "copy_generator.CopyGeneratorLossCompute._stats", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute._unbottle", "target.view.data.clone.eq", "align.view.view.data.ne", "correct_mask.long", "batch.tgt.ne().float().sum", "loss.sum.sum.view().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "loss.sum.sum.sum", "len", "loss.sum.sum.sum", "batch.tgt.ne().float", "loss.sum.sum.view", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "batch.tgt.ne"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.loss.LossComputeBase._unbottle"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "copy_attn", ",", "align", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. The args must match self._make_shard_state().\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            copy_attn: the copy attention value.\n            align: the align info.\n        \"\"\"", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "align", "=", "align", ".", "view", "(", "-", "1", ")", "\n", "scores", "=", "self", ".", "generator", "(", "self", ".", "_bottle", "(", "output", ")", ",", "\n", "self", ".", "_bottle", "(", "copy_attn", ")", ",", "\n", "batch", ".", "src_map", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "align", ",", "target", ")", "\n", "scores_data", "=", "scores", ".", "data", ".", "clone", "(", ")", "\n", "scores_data", "=", "inputters", ".", "TextDataset", ".", "collapse_copy_scores", "(", "\n", "self", ".", "_unbottle", "(", "scores_data", ",", "batch", ".", "batch_size", ")", ",", "\n", "batch", ",", "self", ".", "tgt_vocab", ",", "batch", ".", "dataset", ".", "src_vocabs", ")", "\n", "scores_data", "=", "self", ".", "_bottle", "(", "scores_data", ")", "\n", "\n", "# Correct target copy token instead of <unk>", "\n", "# tgt[i] = align[i] + len(tgt_vocab)", "\n", "# for i such that tgt[i] == 0 and align[i] != 0", "\n", "target_data", "=", "target", ".", "data", ".", "clone", "(", ")", "\n", "correct_mask", "=", "target_data", ".", "eq", "(", "0", ")", "*", "align", ".", "data", ".", "ne", "(", "0", ")", "\n", "correct_copy", "=", "(", "align", ".", "data", "+", "len", "(", "self", ".", "tgt_vocab", ")", ")", "*", "correct_mask", ".", "long", "(", ")", "\n", "target_data", "=", "target_data", "+", "correct_copy", "\n", "\n", "# Compute sum of perplexities for stats", "\n", "loss_data", "=", "loss", ".", "sum", "(", ")", ".", "data", ".", "clone", "(", ")", "\n", "stats", "=", "self", ".", "_stats", "(", "loss_data", ",", "scores_data", ",", "target_data", ")", "\n", "\n", "if", "self", ".", "normalize_by_length", ":", "\n", "# Compute Loss as NLL divided by seq length", "\n", "# Compute Sequence Lengths", "\n", "            ", "pad_ix", "=", "batch", ".", "dataset", ".", "fields", "[", "'tgt'", "]", ".", "vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "tgt_lens", "=", "batch", ".", "tgt", ".", "ne", "(", "pad_ix", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "loss", "=", "loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "loss", "=", "torch", ".", "div", "(", "loss", ",", "tgt_lens", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.embeddings.PositionalEncoding.__init__": [[23, 35], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "torch.Module.__init__", "embeddings.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "math.log"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log"], ["def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "dim", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "0", ",", "dim", ",", "2", ",", "dtype", "=", "torch", ".", "float", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "dim", ")", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "1", ")", "\n", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.embeddings.PositionalEncoding.forward": [[36, 44], ["embeddings.PositionalEncoding.dropout", "math.sqrt", "embeddings.PositionalEncoding.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ")", ":", "\n", "        ", "emb", "=", "emb", "*", "math", ".", "sqrt", "(", "self", ".", "dim", ")", "\n", "if", "step", "is", "None", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", ":", "emb", ".", "size", "(", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", "step", "]", "\n", "", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.embeddings.Embeddings.__init__": [[89, 158], ["vocab_sizes.extend", "emb_dims.extend", "pad_indices.extend", "zip", "onmt.modules.util_class.Elementwise", "torch.Module.__init__", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "torch.Embedding", "torch.Embedding", "sum", "sum", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "embeddings.PositionalEncoding", "embeddings.Embeddings.make_embedding.add_module", "len", "len", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "len", "int"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "word_vec_size", ",", "\n", "word_vocab_size", ",", "\n", "word_padding_idx", ",", "\n", "position_encoding", "=", "False", ",", "\n", "feat_merge", "=", "\"concat\"", ",", "\n", "feat_vec_exponent", "=", "0.7", ",", "feat_vec_size", "=", "-", "1", ",", "\n", "feat_padding_idx", "=", "[", "]", ",", "\n", "feat_vocab_sizes", "=", "[", "]", ",", "\n", "dropout", "=", "0", ",", "\n", "sparse", "=", "False", ")", ":", "\n", "\n", "        ", "if", "feat_padding_idx", "is", "None", ":", "\n", "            ", "feat_padding_idx", "=", "[", "]", "\n", "", "self", ".", "word_padding_idx", "=", "word_padding_idx", "\n", "\n", "self", ".", "word_vec_size", "=", "word_vec_size", "\n", "\n", "# Dimensions and padding for constructing the word embedding matrix", "\n", "vocab_sizes", "=", "[", "word_vocab_size", "]", "\n", "emb_dims", "=", "[", "word_vec_size", "]", "\n", "pad_indices", "=", "[", "word_padding_idx", "]", "\n", "\n", "# Dimensions and padding for feature embedding matrices", "\n", "# (these have no effect if feat_vocab_sizes is empty)", "\n", "if", "feat_merge", "==", "'sum'", ":", "\n", "            ", "feat_dims", "=", "[", "word_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "elif", "feat_vec_size", ">", "0", ":", "\n", "            ", "feat_dims", "=", "[", "feat_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "else", ":", "\n", "            ", "feat_dims", "=", "[", "int", "(", "vocab", "**", "feat_vec_exponent", ")", "\n", "for", "vocab", "in", "feat_vocab_sizes", "]", "\n", "", "vocab_sizes", ".", "extend", "(", "feat_vocab_sizes", ")", "\n", "emb_dims", ".", "extend", "(", "feat_dims", ")", "\n", "pad_indices", ".", "extend", "(", "feat_padding_idx", ")", "\n", "\n", "# The embedding matrix look-up tables. The first look-up table", "\n", "# is for words. Subsequent ones are for features, if any exist.", "\n", "emb_params", "=", "zip", "(", "vocab_sizes", ",", "emb_dims", ",", "pad_indices", ")", "\n", "embeddings", "=", "[", "nn", ".", "Embedding", "(", "vocab", ",", "dim", ",", "padding_idx", "=", "pad", ",", "sparse", "=", "sparse", ")", "\n", "for", "vocab", ",", "dim", ",", "pad", "in", "emb_params", "]", "\n", "emb_luts", "=", "Elementwise", "(", "feat_merge", ",", "embeddings", ")", "\n", "\n", "# The final output size of word + feature vectors. This can vary", "\n", "# from the word vector size if and only if features are defined.", "\n", "# This is the attribute you should access if you need to know", "\n", "# how big your embeddings are going to be.", "\n", "self", ".", "embedding_size", "=", "(", "sum", "(", "emb_dims", ")", "if", "feat_merge", "==", "'concat'", "\n", "else", "word_vec_size", ")", "\n", "\n", "# The sequence of operations that converts the input sequence", "\n", "# into a sequence of embeddings. At minimum this consists of", "\n", "# looking up the embeddings for each word and feature in the", "\n", "# input. Model parameters may require the sequence to contain", "\n", "# additional operations as well.", "\n", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "make_embedding", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'emb_luts'", ",", "emb_luts", ")", "\n", "\n", "if", "feat_merge", "==", "'mlp'", "and", "len", "(", "feat_vocab_sizes", ")", ">", "0", ":", "\n", "            ", "in_dim", "=", "sum", "(", "emb_dims", ")", "\n", "out_dim", "=", "word_vec_size", "\n", "mlp", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_dim", ",", "out_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'mlp'", ",", "mlp", ")", "\n", "\n", "", "self", ".", "position_encoding", "=", "position_encoding", "\n", "\n", "if", "self", ".", "position_encoding", ":", "\n", "            ", "pe", "=", "PositionalEncoding", "(", "dropout", ",", "self", ".", "embedding_size", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.embeddings.Embeddings.word_lut": [[159, 163], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "word_lut", "(", "self", ")", ":", "\n", "        ", "\"\"\" word look-up table \"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.embeddings.Embeddings.emb_luts": [[164, 168], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "emb_luts", "(", "self", ")", ":", "\n", "        ", "\"\"\" embedding look-up table \"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.embeddings.Embeddings.load_pretrained_vectors": [[169, 188], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load.size", "torch.load.size", "embeddings.Embeddings.word_lut.weight.data.copy_", "embeddings.Embeddings.word_lut.weight.data.copy_"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "emb_file", ",", "fixed", ")", ":", "\n", "        ", "\"\"\"Load in pretrained embeddings.\n\n        Args:\n          emb_file (str) : path to torch serialized embeddings\n          fixed (bool) : if true, embeddings are not updated\n        \"\"\"", "\n", "if", "emb_file", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "emb_file", ")", "\n", "pretrained_vec_size", "=", "pretrained", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "word_vec_size", ">", "pretrained_vec_size", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", "[", ":", ",", ":", "pretrained_vec_size", "]", "=", "pretrained", "\n", "", "elif", "self", ".", "word_vec_size", "<", "pretrained_vec_size", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", "[", ":", ",", ":", "self", ".", "word_vec_size", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "", "if", "fixed", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.embeddings.Embeddings.forward": [[189, 208], ["enumerate", "embeddings.Embeddings.make_embedding", "embeddings.Embeddings.make_embedding._modules.values", "module", "module", "len", "embeddings.Embeddings.make_embedding._modules.values"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "source", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the embeddings for words and features.\n\n        Args:\n            source (`LongTensor`): index tensor `[len x batch x nfeat]`\n        Return:\n            `FloatTensor`: word embeddings `[len x batch x embedding_size]`\n        \"\"\"", "\n", "if", "self", ".", "position_encoding", ":", "\n", "            ", "for", "i", ",", "module", "in", "enumerate", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", ":", "\n", "                ", "if", "i", "==", "len", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", "-", "1", ":", "\n", "                    ", "source", "=", "module", "(", "source", ",", "step", "=", "step", ")", "\n", "", "else", ":", "\n", "                    ", "source", "=", "module", "(", "source", ")", "\n", "", "", "", "else", ":", "\n", "            ", "source", "=", "self", ".", "make_embedding", "(", "source", ")", "\n", "\n", "", "return", "source", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormLinear.__init__": [[44, 61], ["torch.Linear.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "\n", "init_scale", "=", "1.", ",", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormLinear", ",", "self", ")", ".", "__init__", "(", "\n", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "\n", "'V_avg'", ",", "torch", ".", "zeros", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormLinear.reset_parameters": [[62, 64], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormLinear.forward": [[65, 99], ["weight_norm.WeightNormLinear.V.data.copy_", "weight_norm.WeightNormLinear.g.data.copy_", "weight_norm.WeightNormLinear.b.data.copy_", "weight_norm.WeightNormLinear.V_avg.copy_", "weight_norm.WeightNormLinear.g_avg.copy_", "weight_norm.WeightNormLinear.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.linear", "torch.linear", "torch.linear", "weight_norm.WeightNormLinear.V.data.norm().expand_as", "torch.linear", "torch.linear", "torch.linear", "x_init.mean().squeeze", "x_init.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view().expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "b.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "m_init.view().expand_as", "scalar.view().expand_as", "weight_norm.WeightNormLinear.V.data.norm", "x_init.mean", "x_init.var", "scale_init.view", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "b.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "m_init.view", "scalar.view", "weight_norm.WeightNormLinear.V.data.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_features * in_features", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "# norm is out_features * 1", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "norm", "(", "2", ",", "1", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "# batch_size * out_features", "\n", "x_init", "=", "F", ".", "linear", "(", "x", ",", "v_norm", ")", ".", "data", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "x_init", ".", "mean", "(", "0", ")", ".", "squeeze", "(", "\n", "0", ")", ",", "x_init", ".", "var", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "x_init", "=", "scale_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "\n", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "# batch_size * out_features", "\n", "x", "=", "F", ".", "linear", "(", "x", ",", "v", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "scalar", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "*", "x", "+", "b", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConv2d.__init__": [[102, 120], ["torch.Conv2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConv2d.V.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConv2d", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "dilation", ",", "groups", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConv2d.reset_parameters": [[121, 123], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConv2d.forward": [[124, 170], ["weight_norm.WeightNormConv2d.V.data.copy_", "x_init.transpose().contiguous().view", "weight_norm.WeightNormConv2d.g.data.copy_", "weight_norm.WeightNormConv2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConv2d.V_avg.copy_", "weight_norm.WeightNormConv2d.g_avg.copy_", "weight_norm.WeightNormConv2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "weight_norm.WeightNormConv2d.V.data.view().norm().view().expand_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "x_init.transpose().contiguous().view.mean().squeeze", "x_init.transpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "v.view", "len", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.transpose().contiguous", "m_init.view.expand_as", "torch.norm.size", "torch.norm.size", "torch.norm.size", "torch.norm.squeeze", "torch.norm.squeeze", "torch.norm.squeeze", "weight_norm.WeightNormConv2d.V.data.view().norm().view", "x_init.transpose().contiguous().view.mean", "x_init.transpose().contiguous().view.var", "torch.norm.view", "torch.norm.view", "torch.norm.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.transpose", "len", "len", "weight_norm.WeightNormConv2d.V.data.size", "weight_norm.WeightNormConv2d.V.data.view().norm", "x_init.size", "x_init.size", "weight_norm.WeightNormConv2d.V.data.view", "len", "len", "v.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_channels, in_channels // groups, * kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "self", ".", "out_channels", ",", "*", "(", "\n", "[", "1", "]", "*", "(", "len", "(", "self", ".", "kernel_size", ")", "+", "1", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv2d", "(", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", ".", "data", "\n", "t_x_init", "=", "x_init", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "\n", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "\n", "scalar", "=", "torch", ".", "norm", "(", "v", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", "\n", "if", "len", "(", "scalar", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", "\n", "\n", "", "w", "=", "scalar", ".", "view", "(", "self", ".", "out_channels", ",", "*", "\n", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "1", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConvTranspose2d.__init__": [[175, 195], ["torch.ConvTranspose2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConvTranspose2d.V.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "output_padding", "=", "0", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConvTranspose2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "output_padding", ",", "\n", "groups", ")", "\n", "# in_channels, out_channels, *kernel_size", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters": [[196, 198], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.WeightNormConvTranspose2d.forward": [[199, 247], ["weight_norm.WeightNormConvTranspose2d.V.data.copy_", "x_init.tranpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.g.data.copy_", "weight_norm.WeightNormConvTranspose2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConvTranspose2d.V_avg.copy_", "weight_norm.WeightNormConvTranspose2d.g_avg.copy_", "weight_norm.WeightNormConvTranspose2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view().expand_as", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "x_init.tranpose().contiguous().view.mean().squeeze", "x_init.tranpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "scalar.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.tranpose().contiguous", "m_init.view.expand_as", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view", "x_init.tranpose().contiguous().view.mean", "x_init.tranpose().contiguous().view.var", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "scalar.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.tranpose", "len", "len", "v.transpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.V.data.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm", "x_init.size", "x_init.size", "len", "v.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view", "len", "v.transpose", "v.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.get_vars_maybe_avg", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# in_channels, out_channels, *kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "len", "(", "self", ".", "kernel_size", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv_transpose2d", "(", "\n", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "self", ".", "groups", ")", ".", "data", "\n", "# self.out_channels, 1", "\n", "t_x_init", "=", "x_init", ".", "tranpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "w", "=", "scalar", ".", "view", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "\n", "self", ".", "groups", ")", "\n", "return", "x", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.get_var_maybe_avg": [[8, 20], ["getattr", "getattr"], "function", ["None"], ["def", "get_var_maybe_avg", "(", "namespace", ",", "var_name", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params\n        Update average\n    \"\"\"", "\n", "v", "=", "getattr", "(", "namespace", ",", "var_name", ")", "\n", "v_avg", "=", "getattr", "(", "namespace", ",", "var_name", "+", "'_avg'", ")", "\n", "v_avg", "-=", "(", "1", "-", "polyak_decay", ")", "*", "(", "v_avg", "-", "v", ".", "data", ")", "\n", "\n", "if", "training", ":", "\n", "        ", "return", "v", "\n", "", "else", ":", "\n", "        ", "return", "v_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.get_vars_maybe_avg": [[22, 29], ["vars.append", "weight_norm.get_var_maybe_avg"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.weight_norm.get_var_maybe_avg"], ["", "", "def", "get_vars_maybe_avg", "(", "namespace", ",", "var_names", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params \"\"\"", "\n", "vars", "=", "[", "]", "\n", "for", "vn", "in", "var_names", ":", "\n", "        ", "vars", ".", "append", "(", "get_var_maybe_avg", "(", "\n", "namespace", ",", "vn", ",", "training", ",", "polyak_decay", ")", ")", "\n", "", "return", "vars", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.SparsemaxFunction.forward": [[31, 42], ["sparse_activations.threshold_and_support", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.threshold_and_support"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "dim", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        input (FloatTensor): any shape\n        returns (FloatTensor): same shape with sparsemax computed on given dim\n        \"\"\"", "\n", "ctx", ".", "dim", "=", "dim", "\n", "tau_z", ",", "k_z", "=", "threshold_and_support", "(", "input", ",", "dim", "=", "dim", ")", "\n", "output", "=", "torch", ".", "clamp", "(", "input", "-", "tau_z", ",", "min", "=", "0", ")", "\n", "ctx", ".", "save_for_backward", "(", "k_z", ",", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.SparsemaxFunction.backward": [[43, 53], ["grad_output.clone", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where.sum", "torch.where.sum", "k_z.squeeze"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "k_z", ",", "output", "=", "ctx", ".", "saved_tensors", "\n", "dim", "=", "ctx", ".", "dim", "\n", "grad_input", "=", "grad_output", ".", "clone", "(", ")", "\n", "grad_input", "[", "output", "==", "0", "]", "=", "0", "\n", "\n", "v_hat", "=", "(", "grad_input", ".", "sum", "(", "dim", "=", "dim", ")", "/", "k_z", ".", "squeeze", "(", ")", ")", ".", "unsqueeze", "(", "dim", ")", "\n", "grad_input", "=", "torch", ".", "where", "(", "output", "!=", "0", ",", "grad_input", "-", "v_hat", ",", "grad_input", ")", "\n", "return", "grad_input", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.Sparsemax.__init__": [[60, 63], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "0", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "super", "(", "Sparsemax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.Sparsemax.forward": [[64, 66], ["sparsemax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "sparsemax", "(", "input", ",", "self", ".", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.LogSparsemax.__init__": [[70, 73], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "0", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "super", "(", "LogSparsemax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.LogSparsemax.forward": [[74, 76], ["torch.log", "torch.log", "torch.log", "torch.log", "sparsemax"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "torch", ".", "log", "(", "sparsemax", "(", "input", ",", "self", ".", "dim", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.sparse_activations.threshold_and_support": [[11, 27], ["torch.sort", "torch.sort", "torch.arange().float().view().transpose", "torch.arange().float().view().transpose", "support.sum().unsqueeze", "support.sum().unsqueeze.float", "sorted_z.cumsum", "z_sum.gather", "torch.arange().float().view", "torch.arange().float().view", "support.sum", "torch.Size", "torch.Size", "torch.arange().float", "torch.arange().float", "torch.arange", "torch.arange", "z.dim", "sorted_z.size"], "function", ["None"], ["def", "threshold_and_support", "(", "z", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    z: any dimension\n    dim: dimension along which to apply the sparsemax\n    \"\"\"", "\n", "sorted_z", ",", "_", "=", "torch", ".", "sort", "(", "z", ",", "descending", "=", "True", ",", "dim", "=", "dim", ")", "\n", "z_sum", "=", "sorted_z", ".", "cumsum", "(", "dim", ")", "-", "1", "# sort of a misnomer", "\n", "k", "=", "torch", ".", "arange", "(", "1", ",", "sorted_z", ".", "size", "(", "dim", ")", "+", "1", ",", "device", "=", "z", ".", "device", ")", ".", "float", "(", ")", ".", "view", "(", "\n", "torch", ".", "Size", "(", "[", "-", "1", "]", "+", "[", "1", "]", "*", "(", "z", ".", "dim", "(", ")", "-", "1", ")", ")", "\n", ")", ".", "transpose", "(", "0", ",", "dim", ")", "\n", "support", "=", "k", "*", "sorted_z", ">", "z_sum", "\n", "\n", "k_z_indices", "=", "support", ".", "sum", "(", "dim", "=", "dim", ")", ".", "unsqueeze", "(", "dim", ")", "\n", "k_z", "=", "k_z_indices", ".", "float", "(", ")", "\n", "tau_z", "=", "z_sum", ".", "gather", "(", "dim", ",", "k_z_indices", "-", "1", ")", "/", "k_z", "\n", "return", "tau_z", ",", "k_z", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.global_attention.GlobalAttention.__init__": [[70, 94], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["\n", "\n", "def", "__init__", "(", "self", ",", "dim", ",", "coverage", "=", "False", ",", "attn_type", "=", "\"dot\"", ",", "\n", "attn_func", "=", "\"softmax\"", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "# 512", "\n", "\n", "assert", "attn_type", "in", "[", "\"dot\"", ",", "\"general\"", ",", "\"mlp\"", "]", ",", "(", "\n", "\"Please select a valid attention type.\"", ")", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "assert", "attn_func", "in", "[", "\"softmax\"", ",", "\"sparsemax\"", "]", ",", "(", "\n", "\"Please select a valid attention function.\"", ")", "\n", "self", ".", "attn_func", "=", "attn_func", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.global_attention.GlobalAttention.mmr_score": [[99, 106], ["None"], "methods", ["None"], ["", "", "def", "mmr_score", "(", "self", ",", "inputs", ",", "output", ")", ":", "\n", "        ", "'''\n\n        :param inputs: inputs sentence matrix\n        :param output: output sentence (vector)\n        :return: scores of mmr\n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.global_attention.GlobalAttention.score": [[95, 137], ["h_s.size", "global_attention.GlobalAttention.view.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "h_s.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "global_attention.GlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "global_attention.GlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "global_attention.GlobalAttention.v().view", "global_attention.GlobalAttention.view.view", "global_attention.GlobalAttention.linear_in", "global_attention.GlobalAttention.view", "global_attention.GlobalAttention.view.view", "h_s.contiguous().view", "global_attention.GlobalAttention.v", "h_s.contiguous", "torch.tanh.view", "torch.tanh.view", "torch.tanh.view"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq"], ["\n", "if", "coverage", ":", "\n", "            ", "self", ".", "linear_cover", "=", "nn", ".", "Linear", "(", "1", ",", "dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "", "def", "mmr_score", "(", "self", ",", "inputs", ",", "output", ")", ":", "\n", "        ", "'''\n\n        :param inputs: inputs sentence matrix\n        :param output: output sentence (vector)\n        :return: scores of mmr\n        '''", "\n", "\n", "\n", "\n", "", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          h_t (`FloatTensor`): sequence of queries `[batch x tgt_len x dim]`\n          h_s (`FloatTensor`): sequence of sources `[batch x src_len x dim]`\n\n        Returns:\n          :obj:`FloatTensor`:\n           raw attention scores (unnormalized) for each src index\n          `[batch x tgt_len x src_len]`\n\n        \"\"\"", "\n", "# target length is 1 (tgt_len)", "\n", "\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "aeq", "(", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "src_dim", ",", "tgt_dim", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "src_dim", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t_", "=", "h_t", ".", "view", "(", "tgt_batch", "*", "tgt_len", ",", "tgt_dim", ")", "\n", "h_t_", "=", "self", ".", "linear_in", "(", "h_t_", ")", "\n", "h_t", "=", "h_t_", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "# print('tgt_len, src_len...', tgt_len, src_len) tgt_len=1, src_len is various", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.global_attention.GlobalAttention.forward": [[138, 228], ["torch.tanh.size", "torch.tanh.size", "torch.tanh.size", "source.unsqueeze.unsqueeze.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.score", "align_vectors.transpose().contiguous.transpose().contiguous.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "global_attention.GlobalAttention.linear_out().view", "source.unsqueeze.unsqueeze.dim", "source.unsqueeze.unsqueeze.unsqueeze", "coverage.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "coverage.view().unsqueeze", "global_attention.GlobalAttention.linear_cover().view_as", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "onmt.utils.misc.sequence_mask", "mask.unsqueeze.unsqueeze.unsqueeze", "global_attention.GlobalAttention.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "onmt.modules.sparse_activations.sparsemax", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attn_h.transpose().contiguous.transpose().contiguous.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "attn_h.transpose().contiguous.transpose().contiguous.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.view", "global_attention.GlobalAttention.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "global_attention.GlobalAttention.linear_out", "coverage.view", "global_attention.GlobalAttention.linear_cover", "global_attention.GlobalAttention.size", "float", "attn_h.transpose().contiguous.transpose().contiguous.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.sequence_mask", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq"], ["return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "# Performs a batch matrix-matrix product of matrices", "\n", "", "else", ":", "# normal attention", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "torch", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "source", ",", "memory_bank", ",", "memory_lengths", "=", "None", ",", "coverage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          source (`FloatTensor`): query vectors `[batch x tgt_len x dim]`\n          memory_bank (`FloatTensor`): source vectors `[batch x src_len x dim]`\n          memory_lengths (`LongTensor`): the source context lengths `[batch]`\n          coverage (`FloatTensor`): None (not supported yet)\n\n        Returns:\n          (`FloatTensor`, `FloatTensor`):\n\n          * Computed vector `[tgt_len x batch x dim]`\n          * Attention distribtutions for each query\n             `[tgt_len x batch x src_len]`\n        \"\"\"", "\n", "# print ('Source..',source.size())", "\n", "# print ('memory_bank..',memory_bank.size())", "\n", "# Source..torch.Size([16, 512])", "\n", "# memory_bank..torch.Size([16, 400, 512])", "\n", "\n", "\n", "# one step input", "\n", "if", "source", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "source", "=", "source", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "source_l", ",", "dim", "=", "memory_bank", ".", "size", "(", ")", "\n", "batch_", ",", "target_l", ",", "dim_", "=", "source", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "dim", ")", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "batch_", ",", "source_l_", "=", "coverage", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "cover", "=", "coverage", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "memory_bank", "+=", "self", ".", "linear_cover", "(", "cover", ")", ".", "view_as", "(", "memory_bank", ")", "\n", "memory_bank", "=", "torch", ".", "tanh", "(", "memory_bank", ")", "\n", "\n", "# compute attention scores, as in Luong et al.", "\n", "", "align", "=", "self", ".", "score", "(", "source", ",", "memory_bank", ")", "\n", "\n", "if", "memory_lengths", "is", "not", "None", ":", "\n", "#????", "\n", "            ", "mask", "=", "sequence_mask", "(", "memory_lengths", ",", "max_len", "=", "align", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "align", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# Softmax or sparsemax to normalize attention weights", "\n", "", "if", "self", ".", "attn_func", "==", "\"softmax\"", ":", "\n", "            ", "align_vectors", "=", "F", ".", "softmax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "align_vectors", "=", "sparsemax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ",", "-", "1", ")", "\n", "", "align_vectors", "=", "align_vectors", ".", "view", "(", "batch", ",", "target_l", ",", "source_l", ")", "\n", "\n", "# each context vector c_t is the weighted average", "\n", "# over all the source hidden states", "\n", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "memory_bank", ")", "\n", "\n", "# concatenate", "\n", "concat_c", "=", "torch", ".", "cat", "(", "[", "c", ",", "source", "]", ",", "2", ")", ".", "view", "(", "batch", "*", "target_l", ",", "dim", "*", "2", ")", "\n", "attn_h", "=", "self", ".", "linear_out", "(", "concat_c", ")", ".", "view", "(", "batch", ",", "target_l", ",", "dim", ")", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "attn_h", "=", "torch", ".", "tanh", "(", "attn_h", ")", "\n", "\n", "", "if", "one_step", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "squeeze", "(", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "squeeze", "(", "1", ")", "\n", "\n", "# Check output sizes", "\n", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.ContextGate.__init__": [[29, 38], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "ContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_size", "=", "embeddings_size", "+", "decoder_size", "+", "attention_size", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "source_proj", "=", "nn", ".", "Linear", "(", "attention_size", ",", "output_size", ")", "\n", "self", ".", "target_proj", "=", "nn", ".", "Linear", "(", "embeddings_size", "+", "decoder_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.ContextGate.forward": [[39, 46], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "gate.ContextGate.sig", "gate.ContextGate.source_proj", "gate.ContextGate.target_proj", "gate.ContextGate.gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ",", "dim", "=", "1", ")", "\n", "z", "=", "self", ".", "sig", "(", "self", ".", "gate", "(", "input_tensor", ")", ")", "\n", "proj_source", "=", "self", ".", "source_proj", "(", "attn_state", ")", "\n", "proj_target", "=", "self", ".", "target_proj", "(", "\n", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "z", ",", "proj_source", ",", "proj_target", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.SourceContextGate.__init__": [[51, 57], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SourceContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.SourceContextGate.forward": [[58, 62], ["gate.SourceContextGate.context_gate", "gate.SourceContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "\n", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "target", "+", "z", "*", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.TargetContextGate.__init__": [[67, 73], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "TargetContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.TargetContextGate.forward": [[74, 77], ["gate.TargetContextGate.context_gate", "gate.TargetContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "z", "*", "target", "+", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.BothContextGate.__init__": [[82, 88], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "BothContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.BothContextGate.forward": [[89, 92], ["gate.BothContextGate.context_gate", "gate.BothContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "(", "1.", "-", "z", ")", "*", "target", "+", "z", "*", "source", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.context_gate_factory": [[6, 18], ["None"], "function", ["None"], ["def", "context_gate_factory", "(", "gate_type", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Returns the correct ContextGate class\"\"\"", "\n", "\n", "gate_types", "=", "{", "'source'", ":", "SourceContextGate", ",", "\n", "'target'", ":", "TargetContextGate", ",", "\n", "'both'", ":", "BothContextGate", "}", "\n", "\n", "assert", "gate_type", "in", "gate_types", ",", "\"Not valid ContextGate type: {0}\"", ".", "format", "(", "\n", "gate_type", ")", "\n", "return", "gate_types", "[", "gate_type", "]", "(", "embeddings_size", ",", "decoder_size", ",", "attention_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoder.__init__": [[24, 57], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "range", "cnn_decoder.CNNDecoder.conv_layers.append", "cnn_decoder.CNNDecoder.attn_layers.append", "onmt.modules.GlobalAttention", "onmt.utils.cnn_factory.GatedConv", "onmt.modules.ConvMultiStepAttention"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "attn_type", ",", "\n", "copy_attn", ",", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'cnn'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "cnn_kernel_width", "=", "cnn_kernel_width", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "# Build the CNN.", "\n", "input_size", "=", "self", ".", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "conv_layers", ".", "append", "(", "\n", "GatedConv", "(", "self", ".", "hidden_size", ",", "self", ".", "cnn_kernel_width", ",", "\n", "self", ".", "dropout", ",", "True", ")", ")", "\n", "\n", "", "self", ".", "attn_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "attn_layers", ".", "append", "(", "\n", "onmt", ".", "modules", ".", "ConvMultiStepAttention", "(", "self", ".", "hidden_size", ")", ")", "\n", "\n", "# CNNDecoder has its own attention mechanism.", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoder.forward": [[58, 123], ["isinstance", "torch.cat.size", "torch.cat.size", "memory_bank.size", "onmt.utils.misc.aeq", "cnn_decoder.CNNDecoder.embeddings", "cnn_decoder.CNNDecoder.transpose().contiguous", "memory_bank.transpose().contiguous", "state.init_src.transpose().contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous().view", "cnn_decoder.CNNDecoder.linear", "cnn_decoder.CNNDecoder.view", "onmt.utils.cnn_factory.shape_transform", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "pad.type_as.type_as.type_as", "zip", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose().contiguous", "state.update_state", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cnn_decoder.CNNDecoder.dim", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.size", "onmt.utils.cnn_factory.shape_transform.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv", "attention", "attn[].squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "cnn_decoder.CNNDecoder.transpose", "memory_bank.transpose", "state.init_src.transpose", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose", "state.previous_input.size", "state.previous_input.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.shape_transform", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.update_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.RNNDecoderBase.forward()`\"\"\"", "\n", "# NOTE: memory_lengths is only here for compatibility reasons", "\n", "#       with onmt.modules.RNNDecoderBase.forward()", "\n", "# CHECKS", "\n", "assert", "isinstance", "(", "state", ",", "CNNDecoderState", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "_", ",", "contxt_batch", ",", "_", "=", "memory_bank", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "contxt_batch", ")", "\n", "# END CHECKS", "\n", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "tgt", "=", "torch", ".", "cat", "(", "[", "state", ".", "previous_input", ",", "tgt", "]", ",", "0", ")", "\n", "\n", "# Initialize return variables.", "\n", "", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "assert", "not", "self", ".", "_copy", ",", "\"Copy mechanism not yet tested in conv2conv\"", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "tgt_emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The output of CNNEncoder.", "\n", "src_memory_bank_t", "=", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The combination of output of CNNEncoder and source embeddings.", "\n", "src_memory_bank_c", "=", "state", ".", "init_src", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Run the forward pass of the CNNDecoder.", "\n", "emb_reshape", "=", "tgt_emb", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_emb", ".", "size", "(", "0", ")", "*", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "linear_out", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "x", "=", "linear_out", ".", "view", "(", "tgt_emb", ".", "size", "(", "0", ")", ",", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "x", "=", "shape_transform", "(", "x", ")", "\n", "\n", "pad", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "\n", "self", ".", "cnn_kernel_width", "-", "1", ",", "1", ")", "\n", "\n", "pad", "=", "pad", ".", "type_as", "(", "x", ")", "\n", "base_target_emb", "=", "x", "\n", "\n", "for", "conv", ",", "attention", "in", "zip", "(", "self", ".", "conv_layers", ",", "self", ".", "attn_layers", ")", ":", "\n", "            ", "new_target_input", "=", "torch", ".", "cat", "(", "[", "pad", ",", "x", "]", ",", "2", ")", "\n", "out", "=", "conv", "(", "new_target_input", ")", "\n", "c", ",", "attn", "=", "attention", "(", "base_target_emb", ",", "out", ",", "\n", "src_memory_bank_t", ",", "src_memory_bank_c", ")", "\n", "x", "=", "(", "x", "+", "(", "c", "+", "out", ")", "*", "SCALE_WEIGHT", ")", "*", "SCALE_WEIGHT", "\n", "", "output", "=", "x", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "outputs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "outputs", "[", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", ".", "squeeze", "(", ")", "\n", "attn", "=", "torch", ".", "stack", "(", "[", "attn", "]", ")", "\n", "", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "# Update the state.", "\n", "", "state", ".", "update_state", "(", "tgt", ")", "\n", "\n", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoder.init_decoder_state": [[124, 129], ["cnn_decoder.CNNDecoderState"], "methods", ["None"], ["", "def", "init_decoder_state", "(", "self", ",", "_", ",", "memory_bank", ",", "enc_hidden", ",", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Init decoder state.\n        \"\"\"", "\n", "return", "CNNDecoderState", "(", "memory_bank", ",", "enc_hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoderState.__init__": [[136, 139], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "self", ".", "init_src", "=", "(", "memory_bank", "+", "enc_hidden", ")", "*", "SCALE_WEIGHT", "\n", "self", ".", "previous_input", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoderState._all": [[140, 146], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "return", "(", "self", ".", "previous_input", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoderState.detach": [[147, 149], ["cnn_decoder.CNNDecoderState.previous_input.detach"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach"], ["", "def", "detach", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_input", "=", "self", ".", "previous_input", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoderState.update_state": [[150, 153], ["None"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_input", ")", ":", "\n", "        ", "\"\"\" Called for every decoder forward pass. \"\"\"", "\n", "self", ".", "previous_input", "=", "new_input", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.cnn_decoder.CNNDecoderState.repeat_beam_size_times": [[154, 157], ["cnn_decoder.CNNDecoderState.init_src.data.repeat"], "methods", ["None"], ["", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "init_src", "=", "self", ".", "init_src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderBase.__init__": [[60, 106], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "decoder.RNNDecoderBase._build_rnn", "onmt.modules.GlobalAttention", "onmt.modules.context_gate_factory", "onmt.modules.GlobalAttention"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._build_rnn", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.context_gate_factory"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", "=", "\"general\"", ",", "attn_func", "=", "\"softmax\"", ",", "\n", "coverage_attn", "=", "False", ",", "context_gate", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "reuse_copy_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNDecoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'rnn'", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Build the RNN.", "\n", "self", ".", "rnn", "=", "self", ".", "_build_rnn", "(", "rnn_type", ",", "\n", "input_size", "=", "self", ".", "_input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "# Set up the context gate.", "\n", "self", ".", "context_gate", "=", "None", "\n", "if", "context_gate", "is", "not", "None", ":", "\n", "            ", "self", ".", "context_gate", "=", "onmt", ".", "modules", ".", "context_gate_factory", "(", "\n", "context_gate", ",", "self", ".", "_input_size", ",", "\n", "hidden_size", ",", "hidden_size", ",", "hidden_size", "\n", ")", "\n", "\n", "# Set up the standard attention.", "\n", "", "self", ".", "_coverage", "=", "coverage_attn", "\n", "# 2333 TODO: the following is init only, we are using this one", "\n", "self", ".", "attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "coverage", "=", "coverage_attn", ",", "\n", "attn_type", "=", "attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "self", ".", "_copy", "=", "False", "\n", "\n", "if", "copy_attn", "and", "not", "reuse_copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "", "if", "copy_attn", ":", "\n", "            ", "self", ".", "_copy", "=", "True", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderBase.forward": [[107, 159], ["isinstance", "tgt.size", "memory_bank.size", "onmt.utils.misc.aeq", "decoder.RNNDecoderBase._run_forward_pass", "state.update_state", "[].unsqueeze", "final_output.unsqueeze", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._run_forward_pass", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.update_state"], ["", "self", ".", "_reuse_copy_attn", "=", "reuse_copy_attn", "\n", "\n", "# init mmr param", "\n", "self", ".", "_init_mmr", "(", "hidden_size", ")", "\n", "# print('Initialized the parameters,',hidden_size)", "\n", "\n", "\n", "\n", "", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "step", "=", "None", ",", "sent_encoder", "=", "None", ",", "src_sents", "=", "None", ",", "dec", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tgt (`LongTensor`): sequences of padded tokens\n                 `[tgt_len x batch x nfeats]`.\n            memory_bank (`FloatTensor`): vectors from the encoder\n                 `[src_len x batch x hidden]`.\n            state (:obj:`onmt.models.DecoderState`):\n                 decoder state object to initialize the decoder\n            memory_lengths (`LongTensor`): the padded source lengths\n                `[batch]`.\n        Returns:\n            (`FloatTensor`,:obj:`onmt.Models.DecoderState`,`FloatTensor`):\n                * decoder_outputs: output from the decoder (after attn)\n                         `[tgt_len x batch x hidden]`.\n                * decoder_state: final hidden state from the decoder\n                * attns: distribution over src at each tgt\n                        `[tgt_len x batch x src_len]`.\n        \"\"\"", "\n", "# Check", "\n", "assert", "isinstance", "(", "state", ",", "RNNDecoderState", ")", "\n", "# tgt.size() returns tgt length and batch", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "_", ",", "memory_batch", ",", "_", "=", "memory_bank", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "memory_batch", ")", "\n", "# END", "\n", "\n", "\n", "# 23333: TODO I changed this return value 'sent_decoder'", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "decoder_final", ",", "decoder_outputs", ",", "attns", "=", "self", ".", "_run_forward_pass", "(", "\n", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "memory_lengths", ",", "sent_encoder", "=", "sent_encoder", ",", "src_sents", "=", "src_sents", ",", "dec", "=", "dec", ")", "\n", "\n", "# Update the state with the result.", "\n", "final_output", "=", "decoder_outputs", "[", "-", "1", "]", "\n", "coverage", "=", "None", "\n", "if", "\"coverage\"", "in", "attns", ":", "\n", "            ", "coverage", "=", "attns", "[", "\"coverage\"", "]", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "state", ".", "update_state", "(", "decoder_final", ",", "final_output", ".", "unsqueeze", "(", "0", ")", ",", "coverage", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "# NOTE: v0.3 to 0.4: decoder_outputs / attns[*] may not be list", "\n", "#       (in particular in case of SRU) it was not raising error in 0.3", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderBase.init_decoder_state": [[160, 178], ["isinstance", "decoder.RNNDecoderState", "decoder.RNNDecoderState", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tuple", "decoder.RNNDecoderBase.init_decoder_state._fix_enc_hidden"], "methods", ["None"], ["#       since stack(Variable) was allowed.", "\n", "#       In 0.4, SRU returns a tensor that shouldn't be stacke", "\n", "\n", "\n", "if", "type", "(", "decoder_outputs", ")", "==", "list", ":", "\n", "            ", "decoder_outputs", "=", "torch", ".", "stack", "(", "decoder_outputs", ")", "\n", "\n", "for", "k", "in", "attns", ":", "\n", "                ", "if", "type", "(", "attns", "[", "k", "]", ")", "==", "list", ":", "\n", "\n", "                    ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "\n", "", "", "", "return", "decoder_outputs", ",", "state", ",", "attns", "\n", "\n", "", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "encoder_final", ",", "\n", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\" Init decoder state with last state of the encoder \"\"\"", "\n", "def", "_fix_enc_hidden", "(", "hidden", ")", ":", "\n", "# The encoder hidden is  (layers*directions) x batch x dim.", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.StdRNNDecoder._run_forward_pass": [[196, 256], ["decoder.StdRNNDecoder.embeddings", "isinstance", "tgt.size", "rnn_output.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "decoder.StdRNNDecoder.attn", "decoder.StdRNNDecoder.dropout", "decoder.StdRNNDecoder.rnn", "decoder.StdRNNDecoder.rnn", "rnn_output.transpose().contiguous", "memory_bank.transpose", "decoder.StdRNNDecoder.context_gate", "decoder_outputs.view.view.view", "decoder.StdRNNDecoder.view", "rnn_output.view", "decoder_outputs.view.view.view", "rnn_output.transpose", "decoder.StdRNNDecoder.size", "rnn_output.size", "decoder_outputs.view.view.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq"], ["\n", "\n", "def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "dec", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n        Args:\n            tgt (LongTensor): a sequence of input tokens tensors\n                                 [len x batch x nfeats].\n            memory_bank (FloatTensor): output(tensor sequence) from the encoder\n                        RNN of size (src_len x batch x hidden_size).\n            state (FloatTensor): hidden state from the encoder RNN for\n                                 initializing the decoder.\n            memory_lengths (LongTensor): the source memory_bank lengths.\n        Returns:\n            decoder_final (Tensor): final hidden state from the decoder.\n            decoder_outputs ([FloatTensor]): an array of output of every time\n                                     step from the decoder.\n            attns (dict of (str, [FloatTensor]): a dictionary of different\n                            type of attention Tensor array of every time\n                            step from the decoder.\n        \"\"\"", "\n", "assert", "not", "self", ".", "_copy", "# TODO, no support yet.", "\n", "assert", "not", "self", ".", "_coverage", "# TODO, no support yet.", "\n", "\n", "# Initialize local and return variables.", "\n", "attns", "=", "{", "}", "\n", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "if", "isinstance", "(", "self", ".", "rnn", ",", "nn", ".", "GRU", ")", ":", "\n", "            ", "rnn_output", ",", "decoder_final", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "rnn_output", ",", "decoder_final", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", ")", "\n", "\n", "# Check", "\n", "", "tgt_len", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "output_len", ",", "output_batch", ",", "_", "=", "rnn_output", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_len", ",", "output_len", ")", "\n", "aeq", "(", "tgt_batch", ",", "output_batch", ")", "\n", "# END", "\n", "\n", "# Calculate the attention.", "\n", "decoder_outputs", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "p_attn", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.StdRNNDecoder._build_rnn": [[257, 260], ["onmt.utils.rnn_factory.rnn_factory"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.rnn_factory.rnn_factory"], ["\n", "# Calculate the context gate.", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "            ", "decoder_outputs", "=", "self", ".", "context_gate", "(", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.StdRNNDecoder._input_size": [[261, 267], ["None"], "methods", ["None"], ["emb", ".", "view", "(", "-", "1", ",", "emb", ".", "size", "(", "2", ")", ")", ",", "\n", "rnn_output", ".", "view", "(", "-", "1", ",", "rnn_output", ".", "size", "(", "2", ")", ")", ",", "\n", "decoder_outputs", ".", "view", "(", "-", "1", ",", "decoder_outputs", ".", "size", "(", "2", ")", ")", "\n", ")", "\n", "decoder_outputs", "=", "decoder_outputs", ".", "view", "(", "tgt_len", ",", "tgt_batch", ",", "self", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.InputFeedRNNDecoder._init_mmr": [[311, 314], ["torch.Linear().cuda", "torch.Linear().cuda", "torch.Linear", "torch.Linear"], "methods", ["None"], ["def", "_init_mmr", "(", "self", ",", "dim", ")", ":", "\n", "# for sentence and summary distance.. This is defined as sim 1", "\n", "        ", "self", ".", "mmr_W", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", ".", "cuda", "(", ")", "# 512*512", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.InputFeedRNNDecoder._run_mmr": [[315, 380], ["torch.PairwiseDistance", "torch.PairwiseDistance", "sent_decoder.permute.permute.permute", "torch.t", "torch.t", "torch.t", "torch.t", "torch.softmax().permute", "torch.softmax().permute", "torch.softmax().permute", "torch.softmax().permute", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "scores.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat.append", "torch.cat.append", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax().permute.size", "torch.softmax().permute.size", "range", "len", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.zeros().float().cuda.append", "torch.zeros().float().cuda.append", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "decoder.InputFeedRNNDecoder.mmr_W", "sent.unsqueeze", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.PairwiseDistance.", "sent_encoder.permute", "sent.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "_run_mmr", "(", "self", ",", "sent_encoder", ",", "sent_decoder", ",", "src_sents", ",", "input_step", ")", ":", "\n", "        ", "'''\n        # sent_encoder: size (sent_len=9,batch=2,dim=512)\n        # sent_decoder: size (sent_len=1,batch=2,dim=512)\n        # src_sents: size (batch=2,sent_len=9)\n        function to calculate mmr\n        :param sent_encoder:\n        :param sent_decoder:\n        :param src_sents:\n        :return:\n        '''", "\n", "pdist", "=", "nn", ".", "PairwiseDistance", "(", "p", "=", "2", ")", "\n", "sent_decoder", "=", "sent_decoder", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# (2,1,512)", "\n", "\n", "scores", "=", "[", "]", "\n", "# define sent matrix and current vector distance as the Euclidean distance", "\n", "for", "sent", "in", "sent_encoder", ":", "# iterate over each batch sample", "\n", "# distance: https://pytorch.org/docs/stable/_modules/torch/nn/modules/distance.html", "\n", "\n", "# import pdb;", "\n", "# pdb.set_trace()", "\n", "\n", "# sim1=torch.sum(pdist(sent_encoder.permute(1,0,2),sent.unsqueeze(1)),1).unsqueeze(1)  # -> this is sim2 on my equation, note this is distance!", "\n", "\n", "            ", "sim1", "=", "1", "-", "torch", ".", "mean", "(", "pdist", "(", "sent_encoder", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ",", "sent", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", "# this is a similarity function", "\n", "# sim1 shape: (batch_size,1)", "\n", "\n", "sim2", "=", "torch", ".", "bmm", "(", "self", ".", "mmr_W", "(", "sent_decoder", ")", ",", "sent", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "# (2,1) -> this is sim1 on my equation", "\n", "\n", "# scores.append(sim1-sim2)", "\n", "scores", ".", "append", "(", "sim2", "-", "sim1", ")", "\n", "\n", "\n", "", "sent_ranking_att", "=", "torch", ".", "t", "(", "torch", ".", "cat", "(", "scores", ",", "1", ")", ")", "#(sent_len=9,batch_size)", "\n", "sent_ranking_att", "=", "torch", ".", "softmax", "(", "sent_ranking_att", ",", "dim", "=", "0", ")", ".", "permute", "(", "1", ",", "0", ")", "#(sent_len=9,batch_size)", "\n", "# scores is a list of score (sent_len=9, tensor shape (batch_size, 1))", "\n", "mmr_among_words", "=", "[", "]", "# should be (batch=2,input_step=200)", "\n", "for", "batch_id", "in", "range", "(", "sent_ranking_att", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "# iterate each batch, create zero weight on the input steps", "\n", "# mmr= torch.zeros([input_step], dtype=torch.float32).cuda()", "\n", "\n", "            ", "tmp", "=", "[", "]", "\n", "for", "id", ",", "position", "in", "enumerate", "(", "src_sents", "[", "batch_id", "]", ")", ":", "\n", "\n", "                ", "for", "x", "in", "range", "(", "position", ")", ":", "\n", "                    ", "tmp", ".", "append", "(", "sent_ranking_att", "[", "batch_id", "]", "[", "id", "]", ")", "\n", "\n", "\n", "", "", "mmr", "=", "torch", ".", "stack", "(", "tmp", ")", "# make to 1-d", "\n", "\n", "\n", "if", "len", "(", "mmr", ")", "<", "input_step", ":", "# pad with 0", "\n", "                ", "tmp", "=", "torch", ".", "zeros", "(", "input_step", "-", "len", "(", "mmr", ")", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "# for x in range(input_step-len(mmr)):", "\n", "mmr", "=", "torch", ".", "cat", "(", "(", "mmr", ",", "tmp", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "mmr", "=", "mmr", "[", ":", "input_step", "]", "\n", "\n", "", "mmr_among_words", ".", "append", "(", "mmr", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "mmr_among_words", "=", "torch", ".", "cat", "(", "mmr_among_words", ",", "0", ")", "\n", "\n", "# shape: (batch=2, input_step=200)", "\n", "\n", "return", "mmr_among_words", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.InputFeedRNNDecoder._run_forward_pass": [[296, 364], ["state.input_feed.squeeze", "state.input_feed.squeeze.size", "tgt.size", "onmt.utils.misc.aeq", "decoder.InputFeedRNNDecoder.embeddings", "enumerate", "decoder.InputFeedRNNDecoder.dim", "state.coverage.squeeze", "decoder.InputFeedRNNDecoder.split", "emb_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.InputFeedRNNDecoder.rnn", "decoder.InputFeedRNNDecoder.attn", "decoder.InputFeedRNNDecoder.dropout", "memory_bank.transpose", "decoder.InputFeedRNNDecoder.context_gate", "decoder.InputFeedRNNDecoder.copy_attn", "memory_bank.transpose"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["\n", "def", "_init_mmr", "(", "self", ",", "dim", ")", ":", "\n", "# for sentence and summary distance.. This is defined as sim 1", "\n", "        ", "self", ".", "mmr_W", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", ".", "cuda", "(", ")", "# 512*512", "\n", "\n", "", "def", "_run_mmr", "(", "self", ",", "sent_encoder", ",", "sent_decoder", ",", "src_sents", ",", "input_step", ")", ":", "\n", "        ", "'''\n        # sent_encoder: size (sent_len=9,batch=2,dim=512)\n        # sent_decoder: size (sent_len=1,batch=2,dim=512)\n        # src_sents: size (batch=2,sent_len=9)\n        function to calculate mmr\n        :param sent_encoder:\n        :param sent_decoder:\n        :param src_sents:\n        :return:\n        '''", "\n", "pdist", "=", "nn", ".", "PairwiseDistance", "(", "p", "=", "2", ")", "\n", "sent_decoder", "=", "sent_decoder", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# (2,1,512)", "\n", "\n", "scores", "=", "[", "]", "\n", "# define sent matrix and current vector distance as the Euclidean distance", "\n", "for", "sent", "in", "sent_encoder", ":", "# iterate over each batch sample", "\n", "# distance: https://pytorch.org/docs/stable/_modules/torch/nn/modules/distance.html", "\n", "\n", "# import pdb;", "\n", "# pdb.set_trace()", "\n", "\n", "# sim1=torch.sum(pdist(sent_encoder.permute(1,0,2),sent.unsqueeze(1)),1).unsqueeze(1)  # -> this is sim2 on my equation, note this is distance!", "\n", "\n", "            ", "sim1", "=", "1", "-", "torch", ".", "mean", "(", "pdist", "(", "sent_encoder", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ",", "sent", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", "# this is a similarity function", "\n", "# sim1 shape: (batch_size,1)", "\n", "\n", "sim2", "=", "torch", ".", "bmm", "(", "self", ".", "mmr_W", "(", "sent_decoder", ")", ",", "sent", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "# (2,1) -> this is sim1 on my equation", "\n", "\n", "# scores.append(sim1-sim2)", "\n", "scores", ".", "append", "(", "sim2", "-", "sim1", ")", "\n", "\n", "\n", "", "sent_ranking_att", "=", "torch", ".", "t", "(", "torch", ".", "cat", "(", "scores", ",", "1", ")", ")", "#(sent_len=9,batch_size)", "\n", "sent_ranking_att", "=", "torch", ".", "softmax", "(", "sent_ranking_att", ",", "dim", "=", "0", ")", ".", "permute", "(", "1", ",", "0", ")", "#(sent_len=9,batch_size)", "\n", "# scores is a list of score (sent_len=9, tensor shape (batch_size, 1))", "\n", "mmr_among_words", "=", "[", "]", "# should be (batch=2,input_step=200)", "\n", "for", "batch_id", "in", "range", "(", "sent_ranking_att", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "# iterate each batch, create zero weight on the input steps", "\n", "# mmr= torch.zeros([input_step], dtype=torch.float32).cuda()", "\n", "\n", "            ", "tmp", "=", "[", "]", "\n", "for", "id", ",", "position", "in", "enumerate", "(", "src_sents", "[", "batch_id", "]", ")", ":", "\n", "\n", "                ", "for", "x", "in", "range", "(", "position", ")", ":", "\n", "                    ", "tmp", ".", "append", "(", "sent_ranking_att", "[", "batch_id", "]", "[", "id", "]", ")", "\n", "\n", "\n", "", "", "mmr", "=", "torch", ".", "stack", "(", "tmp", ")", "# make to 1-d", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.InputFeedRNNDecoder._build_rnn": [[365, 375], ["stacked_cell"], "methods", ["None"], ["\n", "if", "len", "(", "mmr", ")", "<", "input_step", ":", "# pad with 0", "\n", "                ", "tmp", "=", "torch", ".", "zeros", "(", "input_step", "-", "len", "(", "mmr", ")", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "# for x in range(input_step-len(mmr)):", "\n", "mmr", "=", "torch", ".", "cat", "(", "(", "mmr", ",", "tmp", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "mmr", "=", "mmr", "[", ":", "input_step", "]", "\n", "\n", "", "mmr_among_words", ".", "append", "(", "mmr", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "mmr_among_words", "=", "torch", ".", "cat", "(", "mmr_among_words", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.InputFeedRNNDecoder._input_size": [[376, 382], ["None"], "methods", ["None"], ["\n", "# shape: (batch=2, input_step=200)", "\n", "\n", "return", "mmr_among_words", "\n", "\n", "", "def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "sent_encoder", "=", "None", ",", "src_sents", "=", "None", ",", "dec", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.DecoderState.detach": [[392, 396], ["tuple", "decoder.DecoderState.input_feed.detach", "_.detach"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach"], ["input_feed_batch", ",", "_", "=", "input_feed", ".", "size", "(", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "input_feed_batch", ")", "\n", "# END Additional args check.", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.DecoderState.beam_update": [[397, 413], ["e.size", "sent_states.data.copy_", "len", "sent_states.data.index_select", "e.view", "e.view"], "methods", ["None"], ["# Initialize local and return variables.", "\n", "decoder_outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "_coverage", ":", "\n", "            ", "attns", "[", "\"coverage\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "hidden", "=", "state", ".", "hidden", "\n", "coverage", "=", "state", ".", "coverage", ".", "squeeze", "(", "0", ")", "if", "state", ".", "coverage", "is", "not", "None", "else", "None", "\n", "\n", "# Input feed concatenates hidden state with", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.DecoderState.map_batch_fn": [[414, 416], ["NotImplementedError"], "methods", ["None"], ["# input at every time step.", "\n", "\n", "#print(\"emb size: {}\\n\".format(emb.size()));exit()", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderState.__init__": [[421, 439], ["decoder.RNNDecoderState.hidden[].size", "decoder.RNNDecoderState.hidden[].data.new().zero_().unsqueeze", "isinstance", "decoder.RNNDecoderState.hidden[].data.new().zero_", "decoder.RNNDecoderState.hidden[].data.new"], "methods", ["None"], ["decoder_input", "=", "torch", ".", "cat", "(", "[", "emb_t", ",", "input_feed", "]", ",", "1", ")", "\n", "\n", "# TODO: the following is where we get attention!", "\n", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "decoder_input", ",", "hidden", ")", "\n", "decoder_output", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", ")", "\n", "# p_attn: size (batch=2,input_step=200)", "\n", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "# TODO: context gate should be employed (not me)", "\n", "# instead of second RNN transform.", "\n", "                ", "decoder_output", "=", "self", ".", "context_gate", "(", "\n", "decoder_input", ",", "rnn_output", ",", "decoder_output", "\n", ")", "\n", "", "decoder_output", "=", "self", ".", "dropout", "(", "decoder_output", ")", "\n", "input_feed", "=", "decoder_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderState._all": [[440, 443], ["None"], "methods", ["None"], ["decoder_outputs", "+=", "[", "decoder_output", "]", "\n", "attns", "[", "\"std\"", "]", "+=", "[", "p_attn", "]", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderState.update_state": [[444, 452], ["isinstance"], "methods", ["None"], ["# Update the coverage attention.", "\n", "if", "self", ".", "_coverage", ":", "\n", "                ", "coverage", "=", "coverage", "+", "p_attn", "if", "coverage", "is", "not", "None", "else", "p_attn", "\n", "attns", "[", "\"coverage\"", "]", "+=", "[", "coverage", "]", "\n", "\n", "# Run the forward pass of the copy attention layer.", "\n", "#", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderState.repeat_beam_size_times": [[453, 459], ["tuple", "e.data.repeat"], "methods", ["None"], ["", "if", "self", ".", "_copy", "and", "not", "self", ".", "_reuse_copy_attn", ":", "\n", "\n", "                ", "_", ",", "copy_attn", "=", "self", ".", "copy_attn", "(", "decoder_output", ",", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "attns", "[", "\"copy\"", "]", "+=", "[", "copy_attn", "]", "\n", "", "elif", "self", ".", "_copy", ":", "\n", "                ", "attns", "[", "\"copy\"", "]", "=", "attns", "[", "\"std\"", "]", "# attns[\"copy\"] is a list of tensor for each output step=51, each size: [batch_size=2, input_step=200]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.decoder.RNNDecoderState.map_batch_fn": [[460, 463], ["tuple", "fn", "map", "fn"], "methods", ["None"], ["\n", "", "", "if", "not", "dec", ":", "#if this is not dec?", "\n", "            ", "attns", "[", "\"mmr\"", "]", "=", "[", "]", "\n", "# 2333: TODO : the sentence representation for decoder", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderLayer.__init__": [[28, 52], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.position_ffn.PositionwiseFeedForward", "onmt.modules.LayerNorm", "onmt.modules.LayerNorm", "torch.Dropout", "torch.Dropout", "transformer.TransformerDecoderLayer._get_attn_subsequent_mask", "transformer.TransformerDecoderLayer.register_buffer", "onmt.modules.MultiHeadedAttention", "onmt.modules.AverageAttention"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderLayer._get_attn_subsequent_mask"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ")", ":", "\n", "        ", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn_type", "=", "self_attn_type", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "AverageAttention", "(", "\n", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "\n", "", "self", ".", "context_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "layer_norm_2", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "mask", "=", "self", ".", "_get_attn_subsequent_mask", "(", "MAX_SIZE", ")", "\n", "# Register self.mask as a buffer in TransformerDecoderLayer, so", "\n", "# it gets TransformerDecoderLayer's cuda behavior automatically.", "\n", "self", ".", "register_buffer", "(", "'mask'", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderLayer.forward": [[53, 98], ["torch.gt", "torch.gt", "torch.gt", "torch.gt", "transformer.TransformerDecoderLayer.layer_norm_1", "transformer.TransformerDecoderLayer.layer_norm_2", "transformer.TransformerDecoderLayer.context_attn", "transformer.TransformerDecoderLayer.feed_forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.drop", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.drop", "tgt_pad_mask.size", "tgt_pad_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "previous_input", "=", "None", ",", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (`FloatTensor`): `[batch_size x 1 x model_dim]`\n            memory_bank (`FloatTensor`): `[batch_size x src_len x model_dim]`\n            src_pad_mask (`LongTensor`): `[batch_size x 1 x src_len]`\n            tgt_pad_mask (`LongTensor`): `[batch_size x 1 x 1]`\n\n        Returns:\n            (`FloatTensor`, `FloatTensor`, `FloatTensor`):\n\n            * output `[batch_size x 1 x model_dim]`\n            * attn `[batch_size x 1 x src_len]`\n            * all_input `[batch_size x current_step x model_dim]`\n\n        \"\"\"", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "\n", "self", ".", "mask", "[", ":", ",", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", ",", "\n", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", "]", ",", "0", ")", "\n", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "all_input", "=", "input_norm", "\n", "if", "previous_input", "is", "not", "None", ":", "\n", "            ", "all_input", "=", "torch", ".", "cat", "(", "(", "previous_input", ",", "input_norm", ")", ",", "dim", "=", "1", ")", "\n", "dec_mask", "=", "None", "\n", "\n", "", "if", "self", ".", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "all_input", ",", "all_input", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"self\"", ")", "\n", "", "elif", "self", ".", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "step", "=", "step", ")", "\n", "\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "output", "=", "self", ".", "feed_forward", "(", "self", ".", "drop", "(", "mid", ")", "+", "query", ")", "\n", "\n", "return", "output", ",", "attn", ",", "all_input", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderLayer._get_attn_subsequent_mask": [[99, 115], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.triu", "numpy.ones"], "methods", ["None"], ["", "def", "_get_attn_subsequent_mask", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n        Get an attention mask to avoid using the subsequent info.\n\n        Args:\n            size: int\n\n        Returns:\n            (`LongTensor`):\n\n            * subsequent_mask `[1 x size x size]`\n        \"\"\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "subsequent_mask", "=", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "\n", "return", "subsequent_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoder.__init__": [[147, 171], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "onmt.modules.LayerNorm", "onmt.modules.GlobalAttention", "transformer.TransformerDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "d_model", ",", "heads", ",", "d_ff", ",", "attn_type", ",", "\n", "copy_attn", ",", "self_attn_type", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "TransformerDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'transformer'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "self_attn_type", "=", "self_attn_type", "\n", "\n", "# Build TransformerDecoder.", "\n", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerDecoderLayer", "(", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "\n", "self_attn_type", "=", "self_attn_type", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "# TransformerDecoder has its own attention mechanism.", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "d_model", ",", "attn_type", "=", "attn_type", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoder.forward": [[172, 238], ["src[].transpose", "tgt[].transpose", "src[].transpose.size", "tgt[].transpose.size", "transformer.TransformerDecoder.embeddings", "transformer.TransformerDecoder.transpose().contiguous", "memory_bank.transpose().contiguous", "src[].transpose.data.eq().unsqueeze().expand", "tgt[].transpose.data.eq().unsqueeze().expand", "range", "transformer.TransformerDecoder.layer_norm", "transformer.TransformerDecoder.transpose().contiguous", "attn.transpose().contiguous.transpose().contiguous.transpose().contiguous", "transformer.TransformerDecoder.dim", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "state.update_state.update_state.update_state", "transformer.TransformerDecoder.transpose", "memory_bank.transpose", "src[].transpose.data.eq().unsqueeze", "tgt[].transpose.data.eq().unsqueeze", "torch.stack.append", "torch.stack.append", "transformer.TransformerDecoder.transpose", "attn.transpose().contiguous.transpose().contiguous.transpose", "src[].transpose.data.eq", "tgt[].transpose.data.eq"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.update_state"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "step", "=", "None", ",", "cache", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :obj:`onmt.modules.RNNDecoderBase.forward()`\n        \"\"\"", "\n", "src", "=", "state", ".", "src", "\n", "src_words", "=", "src", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "tgt_words", "=", "tgt", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "src_batch", ",", "src_len", "=", "src_words", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", "=", "tgt_words", ".", "size", "(", ")", "\n", "\n", "# Initialize return variables.", "\n", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "# Run the forward pass of the TransformerDecoder.", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ",", "step", "=", "step", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "output", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "src_memory_bank", "=", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "padding_idx", "=", "self", ".", "embeddings", ".", "word_padding_idx", "\n", "src_pad_mask", "=", "src_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "tgt_pad_mask", "=", "tgt_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_len", ")", "\n", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "saved_inputs", "=", "[", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "prev_layer_input", "=", "None", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "                ", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "                    ", "prev_layer_input", "=", "state", ".", "previous_layer_inputs", "[", "i", "]", "\n", "", "", "output", ",", "attn", ",", "all_input", "=", "self", ".", "transformer_layers", "[", "i", "]", "(", "\n", "output", ",", "src_memory_bank", ",", "\n", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "previous_input", "=", "prev_layer_input", ",", "\n", "layer_cache", "=", "state", ".", "cache", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "\n", "if", "state", ".", "cache", "is", "not", "None", "else", "None", ",", "\n", "step", "=", "step", ")", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "                ", "saved_inputs", ".", "append", "(", "all_input", ")", "\n", "\n", "", "", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "saved_inputs", "=", "torch", ".", "stack", "(", "saved_inputs", ")", "\n", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "output", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "outputs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "state", "=", "state", ".", "update_state", "(", "tgt", ",", "saved_inputs", ")", "\n", "\n", "", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoder.init_decoder_state": [[239, 247], ["transformer.TransformerDecoderState", "transformer.TransformerDecoderState._init_cache"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState._init_cache"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "enc_hidden", ",", "\n", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\" Init decoder state \"\"\"", "\n", "state", "=", "TransformerDecoderState", "(", "src", ")", "\n", "if", "with_cache", ":", "\n", "            ", "state", ".", "_init_cache", "(", "memory_bank", ",", "self", ".", "num_layers", ",", "\n", "self", ".", "self_attn_type", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState.__init__": [[252, 262], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (FloatTensor): a sequence of source words tensors\n                    with optional feature tensors, of size (len x batch).\n        \"\"\"", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "previous_input", "=", "None", "\n", "self", ".", "previous_layer_inputs", "=", "None", "\n", "self", ".", "cache", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState._all": [[263, 275], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "if", "(", "self", ".", "previous_input", "is", "not", "None", "\n", "and", "self", ".", "previous_layer_inputs", "is", "not", "None", ")", ":", "\n", "            ", "return", "(", "self", ".", "previous_input", ",", "\n", "self", ".", "previous_layer_inputs", ",", "\n", "self", ".", "src", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "self", ".", "src", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState.detach": [[276, 282], ["transformer.TransformerDecoderState.src.detach", "transformer.TransformerDecoderState.previous_input.detach", "transformer.TransformerDecoderState.previous_layer_inputs.detach"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach"], ["", "", "def", "detach", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_input", "=", "self", ".", "previous_input", ".", "detach", "(", ")", "\n", "", "if", "self", ".", "previous_layer_inputs", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_layer_inputs", "=", "self", ".", "previous_layer_inputs", ".", "detach", "(", ")", "\n", "", "self", ".", "src", "=", "self", ".", "src", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState.update_state": [[283, 288], ["transformer.TransformerDecoderState"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_input", ",", "previous_layer_inputs", ")", ":", "\n", "        ", "state", "=", "TransformerDecoderState", "(", "self", ".", "src", ")", "\n", "state", ".", "previous_input", "=", "new_input", "\n", "state", ".", "previous_layer_inputs", "=", "previous_layer_inputs", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState._init_cache": [[289, 308], ["memory_bank.size", "memory_bank.size", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "_init_cache", "(", "self", ",", "memory_bank", ",", "num_layers", ",", "self_attn_type", ")", ":", "\n", "        ", "self", ".", "cache", "=", "{", "}", "\n", "batch_size", "=", "memory_bank", ".", "size", "(", "1", ")", "\n", "depth", "=", "memory_bank", ".", "size", "(", "-", "1", ")", "\n", "\n", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "layer_cache", "=", "{", "\n", "\"memory_keys\"", ":", "None", ",", "\n", "\"memory_values\"", ":", "None", "\n", "}", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "                ", "layer_cache", "[", "\"self_keys\"", "]", "=", "None", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "None", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "                ", "layer_cache", "[", "\"prev_g\"", "]", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "depth", ")", ")", "\n", "", "else", ":", "\n", "                ", "layer_cache", "[", "\"self_keys\"", "]", "=", "None", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "None", "\n", "", "self", ".", "cache", "[", "\"layer_{}\"", ".", "format", "(", "l", ")", "]", "=", "layer_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState.repeat_beam_size_times": [[309, 312], ["transformer.TransformerDecoderState.src.data.repeat"], "methods", ["None"], ["", "", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "src", "=", "self", ".", "src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.transformer.TransformerDecoderState.map_batch_fn": [[313, 325], ["fn", "struct.items", "transformer.TransformerDecoderState.map_batch_fn._recursive_map"], "methods", ["None"], ["", "def", "map_batch_fn", "(", "self", ",", "fn", ")", ":", "\n", "        ", "def", "_recursive_map", "(", "struct", ",", "batch_dim", "=", "0", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "struct", ".", "items", "(", ")", ":", "\n", "                ", "if", "v", "is", "not", "None", ":", "\n", "                    ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                        ", "_recursive_map", "(", "v", ")", "\n", "", "else", ":", "\n", "                        ", "struct", "[", "k", "]", "=", "fn", "(", "v", ",", "batch_dim", ")", "\n", "\n", "", "", "", "", "self", ".", "src", "=", "fn", "(", "self", ".", "src", ",", "1", ")", "\n", "if", "self", ".", "cache", "is", "not", "None", ":", "\n", "            ", "_recursive_map", "(", "self", ".", "cache", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoderState.__init__": [[20, 22], ["tuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_decoder_states", ")", ":", "\n", "        ", "self", ".", "model_decoder_states", "=", "tuple", "(", "model_decoder_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoderState.beam_update": [[23, 26], ["model_state.beam_update"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.beam_update"], ["", "def", "beam_update", "(", "self", ",", "idx", ",", "positions", ",", "beam_size", ")", ":", "\n", "        ", "for", "model_state", "in", "self", ".", "model_decoder_states", ":", "\n", "            ", "model_state", ".", "beam_update", "(", "idx", ",", "positions", ",", "beam_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoderState.repeat_beam_size_times": [[27, 31], ["model_state.repeat_beam_size_times"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.repeat_beam_size_times"], ["", "", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "for", "model_state", "in", "self", ".", "model_decoder_states", ":", "\n", "            ", "model_state", ".", "repeat_beam_size_times", "(", "beam_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoderState.__getitem__": [[32, 34], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "model_decoder_states", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoderOutput.__init__": [[38, 40], ["tuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_outputs", ")", ":", "\n", "        ", "self", ".", "model_outputs", "=", "tuple", "(", "model_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoderOutput.squeeze": [[41, 48], ["ensemble.EnsembleDecoderOutput", "x.squeeze"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "squeeze", "(", "self", ",", "dim", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Delegate squeeze to avoid modifying\n        :obj:`Translator.translate_batch()`\n        \"\"\"", "\n", "return", "EnsembleDecoderOutput", "(", "[", "\n", "x", ".", "squeeze", "(", "dim", ")", "for", "x", "in", "self", ".", "model_outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoderOutput.__getitem__": [[49, 51], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "model_outputs", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleEncoder.__init__": [[55, 58], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.ModuleList", "torch.ModuleList", "list"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "model_encoders", ")", ":", "\n", "        ", "super", "(", "EnsembleEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_encoders", "=", "nn", ".", "ModuleList", "(", "list", "(", "model_encoders", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleEncoder.forward": [[59, 64], ["zip", "model_encoder.forward"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "enc_hidden", ",", "memory_bank", "=", "zip", "(", "*", "[", "\n", "model_encoder", ".", "forward", "(", "src", ",", "lengths", ")", "\n", "for", "model_encoder", "in", "self", ".", "model_encoders", "]", ")", "\n", "return", "enc_hidden", ",", "memory_bank", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoder.__init__": [[68, 71], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "list"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "model_decoders", ")", ":", "\n", "        ", "super", "(", "EnsembleDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_decoders", "=", "nn", ".", "ModuleList", "(", "list", "(", "model_decoders", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoder.forward": [[72, 88], ["zip", "ensemble.EnsembleDecoder.combine_attns", "ensemble.EnsembleDecoderOutput", "ensemble.EnsembleDecoderState", "model_decoder.forward", "enumerate"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.combine_attns", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`RNNDecoderBase.forward()` \"\"\"", "\n", "# Memory_lengths is a single tensor shared between all models.", "\n", "# This assumption will not hold if Translator is modified", "\n", "# to calculate memory_lengths as something other than the length", "\n", "# of the input.", "\n", "outputs", ",", "states", ",", "attns", "=", "zip", "(", "*", "[", "\n", "model_decoder", ".", "forward", "(", "\n", "tgt", ",", "memory_bank", "[", "i", "]", ",", "state", "[", "i", "]", ",", "memory_lengths", ",", "step", "=", "step", ")", "\n", "for", "(", "i", ",", "model_decoder", ")", "\n", "in", "enumerate", "(", "self", ".", "model_decoders", ")", "]", ")", "\n", "mean_attns", "=", "self", ".", "combine_attns", "(", "attns", ")", "\n", "return", "(", "EnsembleDecoderOutput", "(", "outputs", ")", ",", "\n", "EnsembleDecoderState", "(", "states", ")", ",", "\n", "mean_attns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoder.combine_attns": [[89, 94], ["attns[].keys", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "combine_attns", "(", "self", ",", "attns", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "for", "key", "in", "attns", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "result", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "attn", "[", "key", "]", "for", "attn", "in", "attns", "]", ")", ".", "mean", "(", "0", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleDecoder.init_decoder_state": [[95, 102], ["ensemble.EnsembleDecoderState", "model_decoder.init_decoder_state", "enumerate"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.init_decoder_state"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "\"\"\" See :obj:`RNNDecoderBase.init_decoder_state()` \"\"\"", "\n", "return", "EnsembleDecoderState", "(", "\n", "[", "model_decoder", ".", "init_decoder_state", "(", "src", ",", "\n", "memory_bank", "[", "i", "]", ",", "\n", "enc_hidden", "[", "i", "]", ")", "\n", "for", "(", "i", ",", "model_decoder", ")", "in", "enumerate", "(", "self", ".", "model_decoders", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleGenerator.__init__": [[109, 112], ["tuple", "torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "model_generators", ")", ":", "\n", "        ", "self", ".", "model_generators", "=", "tuple", "(", "model_generators", ")", "\n", "super", "(", "EnsembleGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleGenerator.forward": [[113, 123], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "model_generator.forward", "enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward"], ["", "def", "forward", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        by averaging distributions from models in the ensemble.\n        All models in the ensemble must share a target vocabulary.\n        \"\"\"", "\n", "distributions", "=", "[", "model_generator", ".", "forward", "(", "hidden", "[", "i", "]", ")", "\n", "for", "(", "i", ",", "model_generator", ")", "\n", "in", "enumerate", "(", "self", ".", "model_generators", ")", "]", "\n", "return", "torch", ".", "stack", "(", "distributions", ")", ".", "mean", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.EnsembleModel.__init__": [[127, 133], ["ensemble.EnsembleEncoder", "ensemble.EnsembleDecoder", "onmt.models.NMTModel.__init__", "ensemble.EnsembleGenerator", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "encoder", "=", "EnsembleEncoder", "(", "model", ".", "encoder", "for", "model", "in", "models", ")", "\n", "decoder", "=", "EnsembleDecoder", "(", "model", ".", "decoder", "for", "model", "in", "models", ")", "\n", "super", "(", "EnsembleModel", ",", "self", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "generator", "=", "EnsembleGenerator", "(", "model", ".", "generator", "for", "model", "in", "models", ")", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.decoders.ensemble.load_test_model": [[135, 157], ["ensemble.EnsembleModel", "onmt.model_builder.load_test_model", "models.append", "fields.items"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model"], ["", "", "def", "load_test_model", "(", "opt", ",", "dummy_opt", ")", ":", "\n", "    ", "\"\"\" Read in multiple models for ensemble \"\"\"", "\n", "shared_fields", "=", "None", "\n", "shared_model_opt", "=", "None", "\n", "models", "=", "[", "]", "\n", "for", "model_path", "in", "opt", ".", "models", ":", "\n", "        ", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "model_builder", ".", "load_test_model", "(", "opt", ",", "\n", "dummy_opt", ",", "\n", "model_path", "=", "model_path", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "if", "shared_fields", "is", "None", ":", "\n", "            ", "shared_fields", "=", "fields", "\n", "", "else", ":", "\n", "            ", "for", "key", ",", "field", "in", "fields", ".", "items", "(", ")", ":", "\n", "                ", "if", "field", "is", "not", "None", "and", "'vocab'", "in", "field", ".", "__dict__", ":", "\n", "                    ", "assert", "field", ".", "vocab", ".", "stoi", "==", "shared_fields", "[", "key", "]", ".", "vocab", ".", "stoi", ",", "'Ensemble models must use the same preprocessed data'", "\n", "", "", "", "models", ".", "append", "(", "model", ")", "\n", "if", "shared_model_opt", "is", "None", ":", "\n", "            ", "shared_model_opt", "=", "model_opt", "\n", "", "", "ensemble_model", "=", "EnsembleModel", "(", "models", ")", "\n", "return", "shared_fields", ",", "ensemble_model", ",", "shared_model_opt", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.HAN.hierarchical_att_model.HierAttNet.__init__": [[11, 22], ["torch.Module.__init__", "src.word_att_model.WordAttNet", "src.sent_att_model.SentAttNet", "hierarchical_att_model.HierAttNet._init_hidden_state"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.HAN.hierarchical_att_model.HierAttNet._init_hidden_state"], ["    ", "def", "__init__", "(", "self", ",", "word_hidden_size", ",", "sent_hidden_size", ",", "batch_size", ",", "num_classes", ",", "pretrained_word2vec_path", ",", "\n", "max_sent_length", ",", "max_word_length", ")", ":", "\n", "        ", "super", "(", "HierAttNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "word_hidden_size", "=", "word_hidden_size", "\n", "self", ".", "sent_hidden_size", "=", "sent_hidden_size", "\n", "self", ".", "max_sent_length", "=", "max_sent_length", "\n", "self", ".", "max_word_length", "=", "max_word_length", "\n", "self", ".", "word_att_net", "=", "WordAttNet", "(", "pretrained_word2vec_path", ",", "word_hidden_size", ")", "\n", "self", ".", "sent_att_net", "=", "SentAttNet", "(", "sent_hidden_size", ",", "word_hidden_size", ",", "num_classes", ")", "\n", "self", ".", "_init_hidden_state", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.HAN.hierarchical_att_model.HierAttNet._init_hidden_state": [[23, 33], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "hierarchical_att_model.HierAttNet.word_hidden_state.cuda", "hierarchical_att_model.HierAttNet.sent_hidden_state.cuda"], "methods", ["None"], ["", "def", "_init_hidden_state", "(", "self", ",", "last_batch_size", "=", "None", ")", ":", "\n", "        ", "if", "last_batch_size", ":", "\n", "            ", "batch_size", "=", "last_batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "self", ".", "batch_size", "\n", "", "self", ".", "word_hidden_state", "=", "torch", ".", "zeros", "(", "2", ",", "batch_size", ",", "self", ".", "word_hidden_size", ")", "\n", "self", ".", "sent_hidden_state", "=", "torch", ".", "zeros", "(", "2", ",", "batch_size", ",", "self", ".", "sent_hidden_size", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "word_hidden_state", "=", "self", ".", "word_hidden_state", ".", "cuda", "(", ")", "\n", "self", ".", "sent_hidden_state", "=", "self", ".", "sent_hidden_state", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.HAN.hierarchical_att_model.HierAttNet.forward": [[34, 45], ["input.permute.permute.permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hierarchical_att_model.HierAttNet.sent_att_net", "hierarchical_att_model.HierAttNet.word_att_net", "output_list.append", "i.permute"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "\n", "        ", "output_list", "=", "[", "]", "\n", "input", "=", "input", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "for", "i", "in", "input", ":", "\n", "            ", "output", ",", "self", ".", "word_hidden_state", "=", "self", ".", "word_att_net", "(", "i", ".", "permute", "(", "1", ",", "0", ")", ",", "self", ".", "word_hidden_state", ")", "\n", "output_list", ".", "append", "(", "output", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "output_list", ",", "0", ")", "\n", "output", ",", "self", ".", "sent_hidden_state", "=", "self", ".", "sent_att_net", "(", "output", ",", "self", ".", "sent_hidden_state", ")", "\n", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder.__init__": [[25, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "fields", ",", "n_best", "=", "1", ",", "replace_unk", "=", "False", ",", "\n", "has_tgt", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "self", ".", "has_tgt", "=", "has_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder._build_target_tokens": [[33, 50], ["range", "len", "tokens.append", "tokens.append", "len", "attn[].max", "max_index.item", "len"], "methods", ["None"], ["", "def", "_build_target_tokens", "(", "self", ",", "src", ",", "src_vocab", ",", "src_raw", ",", "pred", ",", "attn", ")", ":", "\n", "        ", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "tokens", "=", "[", "]", "\n", "for", "tok", "in", "pred", ":", "\n", "            ", "if", "tok", "<", "len", "(", "vocab", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "src_vocab", ".", "itos", "[", "tok", "-", "len", "(", "vocab", ")", "]", ")", "\n", "", "if", "tokens", "[", "-", "1", "]", "==", "inputters", ".", "EOS_WORD", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "if", "self", ".", "replace_unk", "and", "(", "attn", "is", "not", "None", ")", "and", "(", "src", "is", "not", "None", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "vocab", ".", "itos", "[", "inputters", ".", "UNK", "]", ":", "\n", "                    ", "_", ",", "max_index", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src_raw", "[", "max_index", ".", "item", "(", ")", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder.from_batch": [[51, 106], ["list", "torch.sort", "range", "len", "len", "zip", "batch.src[].data.index_select", "batch.tgt.data.index_select", "Translation.Translation", "translations.append", "Translation.TranslationBuilder._build_target_tokens", "Translation.TranslationBuilder._build_target_tokens", "sorted", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder._build_target_tokens", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder._build_target_tokens"], ["", "def", "from_batch", "(", "self", ",", "translation_batch", ")", ":", "\n", "        ", "batch", "=", "translation_batch", "[", "\"batch\"", "]", "\n", "assert", "(", "len", "(", "translation_batch", "[", "\"gold_score\"", "]", ")", "==", "\n", "len", "(", "translation_batch", "[", "\"predictions\"", "]", ")", ")", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "preds", ",", "pred_score", ",", "attn", ",", "gold_score", ",", "indices", "=", "list", "(", "zip", "(", "\n", "*", "sorted", "(", "zip", "(", "translation_batch", "[", "\"predictions\"", "]", ",", "\n", "translation_batch", "[", "\"scores\"", "]", ",", "\n", "translation_batch", "[", "\"attention\"", "]", ",", "\n", "translation_batch", "[", "\"gold_score\"", "]", ",", "\n", "batch", ".", "indices", ".", "data", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "\n", "\n", "# Sorting", "\n", "inds", ",", "perm", "=", "torch", ".", "sort", "(", "batch", ".", "indices", ".", "data", ")", "\n", "data_type", "=", "self", ".", "data", ".", "data_type", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "src", "=", "batch", ".", "src", "[", "0", "]", ".", "data", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "src", "=", "None", "\n", "\n", "", "if", "self", ".", "has_tgt", ":", "\n", "            ", "tgt", "=", "batch", ".", "tgt", ".", "data", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "tgt", "=", "None", "\n", "\n", "", "translations", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "data_type", "==", "'text'", ":", "\n", "                ", "src_vocab", "=", "self", ".", "data", ".", "src_vocabs", "[", "inds", "[", "b", "]", "]", "if", "self", ".", "data", ".", "src_vocabs", "else", "None", "\n", "src_raw", "=", "self", ".", "data", ".", "examples", "[", "inds", "[", "b", "]", "]", ".", "src", "\n", "", "else", ":", "\n", "                ", "src_vocab", "=", "None", "\n", "src_raw", "=", "None", "\n", "", "pred_sents", "=", "[", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "preds", "[", "b", "]", "[", "n", "]", ",", "attn", "[", "b", "]", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_best", ")", "]", "\n", "gold_sent", "=", "None", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                ", "gold_sent", "=", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "tgt", "[", "1", ":", ",", "b", "]", "if", "tgt", "is", "not", "None", "else", "None", ",", "None", ")", "\n", "\n", "", "translation", "=", "Translation", "(", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_raw", ",", "pred_sents", ",", "\n", "attn", "[", "b", "]", ",", "pred_score", "[", "b", "]", ",", "gold_sent", ",", "\n", "gold_score", "[", "b", "]", ")", "\n", "translations", ".", "append", "(", "translation", ")", "\n", "\n", "", "return", "translations", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.__init__": [[124, 133], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ",", "src_raw", ",", "pred_sents", ",", "\n", "attn", ",", "pred_scores", ",", "tgt_sent", ",", "gold_score", ")", ":", "\n", "        ", "self", ".", "src", "=", "src", "\n", "self", ".", "src_raw", "=", "src_raw", "\n", "self", ".", "pred_sents", "=", "pred_sents", "\n", "self", ".", "attns", "=", "attn", "\n", "self", ".", "pred_scores", "=", "pred_scores", "\n", "self", ".", "gold_sent", "=", "tgt_sent", "\n", "self", ".", "gold_score", "=", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log": [[134, 157], ["len", "zip"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "sent_number", ")", ":", "\n", "        ", "\"\"\"\n        Log translation.\n        \"\"\"", "\n", "\n", "output", "=", "'\\nSENT {}: {}\\n'", ".", "format", "(", "sent_number", ",", "self", ".", "src_raw", ")", "\n", "\n", "best_pred", "=", "self", ".", "pred_sents", "[", "0", "]", "\n", "best_score", "=", "self", ".", "pred_scores", "[", "0", "]", "\n", "pred_sent", "=", "' '", ".", "join", "(", "best_pred", ")", "\n", "output", "+=", "'PRED {}: {}\\n'", ".", "format", "(", "sent_number", ",", "pred_sent", ")", "\n", "output", "+=", "\"PRED SCORE: {:.4f}\\n\"", ".", "format", "(", "best_score", ")", "\n", "\n", "if", "self", ".", "gold_sent", "is", "not", "None", ":", "\n", "            ", "tgt_sent", "=", "' '", ".", "join", "(", "self", ".", "gold_sent", ")", "\n", "output", "+=", "'GOLD {}: {}\\n'", ".", "format", "(", "sent_number", ",", "tgt_sent", ")", "\n", "output", "+=", "(", "\"GOLD SCORE: {:.4f}\\n\"", ".", "format", "(", "self", ".", "gold_score", ")", ")", "\n", "", "if", "len", "(", "self", ".", "pred_sents", ")", ">", "1", ":", "\n", "            ", "output", "+=", "'\\nBEST HYP:\\n'", "\n", "for", "score", ",", "sent", "in", "zip", "(", "self", ".", "pred_scores", ",", "self", ".", "pred_sents", ")", ":", "\n", "                ", "output", "+=", "\"[{:.4f}] {}\\n\"", ".", "format", "(", "score", ",", "sent", ")", "\n", "\n", "", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator.__init__": [[80, 149], ["set"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "beam_size", ",", "\n", "n_best", "=", "1", ",", "\n", "max_length", "=", "100", ",", "\n", "global_scorer", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "\n", "logger", "=", "None", ",", "\n", "gpu", "=", "False", ",", "\n", "dump_beam", "=", "\"\"", ",", "\n", "min_length", "=", "0", ",", "\n", "stepwise_penalty", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "ignore_when_blocking", "=", "[", "]", ",", "\n", "sample_rate", "=", "'16000'", ",", "\n", "window_size", "=", ".02", ",", "\n", "window_stride", "=", ".01", ",", "\n", "window", "=", "'hamming'", ",", "\n", "use_filter_pred", "=", "False", ",", "\n", "data_type", "=", "\"text\"", ",", "\n", "replace_unk", "=", "False", ",", "\n", "report_score", "=", "True", ",", "\n", "report_bleu", "=", "False", ",", "\n", "report_rouge", "=", "False", ",", "\n", "verbose", "=", "False", ",", "\n", "out_file", "=", "None", ",", "\n", "fast", "=", "False", ",", "\n", "image_channel_size", "=", "3", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "self", ".", "gpu", "=", "gpu", "\n", "self", ".", "cuda", "=", "gpu", ">", "-", "1", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "copy_attn", "=", "copy_attn", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "dump_beam", "=", "dump_beam", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "ignore_when_blocking", "=", "set", "(", "ignore_when_blocking", ")", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "window_stride", "=", "window_stride", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "use_filter_pred", "=", "use_filter_pred", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "out_file", "=", "out_file", "\n", "self", ".", "report_score", "=", "report_score", "\n", "self", ".", "report_bleu", "=", "report_bleu", "\n", "self", ".", "report_rouge", "=", "report_rouge", "\n", "self", ".", "fast", "=", "fast", "\n", "self", ".", "image_channel_size", "=", "image_channel_size", "\n", "\n", "# for debugging", "\n", "self", ".", "beam_trace", "=", "self", ".", "dump_beam", "!=", "\"\"", "\n", "self", ".", "beam_accum", "=", "None", "\n", "if", "self", ".", "beam_trace", ":", "\n", "            ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator.translate": [[150, 304], ["onmt.build_dataset", "onmt.build_dataset", "onmt.build_dataset", "onmt.build_dataset", "onmt.build_dataset", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "itertools.count", "ValueError", "translator.Translator.translate_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "json.dump", "len", "translator.Translator.out_file.write", "translator.Translator.out_file.flush", "codecs.open", "next", "trans.log", "preds.append", "trans.attns[].tolist", "zip", "os.write", "len", "translator.Translator.logger.info", "os.write", "header_format.format", "row.index", "row_format.replace.replace.replace", "row_format.replace.replace.replace", "trans.log.encode", "trans.log.encode", "len", "len", "max", "row_format.replace.replace.format", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator.translate_batch", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.encode", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.encode"], ["\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n", "", "", "def", "translate", "(", "self", ",", "\n", "src_path", "=", "None", ",", "\n", "src_data_iter", "=", "None", ",", "\n", "tgt_path", "=", "None", ",", "\n", "tgt_data_iter", "=", "None", ",", "\n", "src_dir", "=", "None", ",", "\n", "batch_size", "=", "None", ",", "\n", "attn_debug", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Translate content of `src_data_iter` (if not None) or `src_path`\n        and get gold scores if one of `tgt_data_iter` or `tgt_path` is set.\n\n        Note: batch_size must not be None\n        Note: one of ('src_path', 'src_data_iter') must not be None\n\n        Args:\n            src_path (str): filepath of source data\n            src_data_iter (iterator): an interator generating source data\n                e.g. it may be a list or an openned file\n            tgt_path (str): filepath of target data\n            tgt_data_iter (iterator): an interator generating target data\n            src_dir (str): source directory path\n                (used for Audio and Image datasets)\n            batch_size (int): size of examples per mini-batch\n            attn_debug (bool): enables the attention logging\n\n        Returns:\n            (`list`, `list`)\n\n            * all_scores is a list of `batch_size` lists of `n_best` scores\n            * all_predictions is a list of `batch_size` lists\n                of `n_best` predictions\n        \"\"\"", "\n", "\n", "assert", "src_data_iter", "is", "not", "None", "or", "src_path", "is", "not", "None", "\n", "\n", "if", "batch_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_size must be set\"", ")", "\n", "", "data", "=", "inputters", ".", "build_dataset", "(", "self", ".", "fields", ",", "\n", "self", ".", "data_type", ",", "\n", "src_path", "=", "src_path", ",", "\n", "src_data_iter", "=", "src_data_iter", ",", "\n", "tgt_path", "=", "tgt_path", ",", "\n", "tgt_data_iter", "=", "tgt_data_iter", ",", "\n", "src_dir", "=", "src_dir", ",", "\n", "sample_rate", "=", "self", ".", "sample_rate", ",", "\n", "window_size", "=", "self", ".", "window_size", ",", "\n", "window_stride", "=", "self", ".", "window_stride", ",", "\n", "window", "=", "self", ".", "window", ",", "\n", "use_filter_pred", "=", "self", ".", "use_filter_pred", ",", "\n", "image_channel_size", "=", "self", ".", "image_channel_size", ")", "\n", "\n", "if", "self", ".", "cuda", ":", "\n", "            ", "cur_device", "=", "\"cuda\"", "\n", "", "else", ":", "\n", "            ", "cur_device", "=", "\"cpu\"", "\n", "\n", "", "data_iter", "=", "inputters", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "device", "=", "cur_device", ",", "\n", "batch_size", "=", "batch_size", ",", "train", "=", "False", ",", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "shuffle", "=", "False", ")", "\n", "\n", "builder", "=", "onmt", ".", "translate", ".", "TranslationBuilder", "(", "\n", "data", ",", "self", ".", "fields", ",", "\n", "self", ".", "n_best", ",", "self", ".", "replace_unk", ",", "tgt_path", ")", "\n", "\n", "# Statistics", "\n", "counter", "=", "count", "(", "1", ")", "\n", "pred_score_total", ",", "pred_words_total", "=", "0", ",", "0", "\n", "gold_score_total", ",", "gold_words_total", "=", "0", ",", "0", "\n", "\n", "all_scores", "=", "[", "]", "\n", "all_predictions", "=", "[", "]", "\n", "\n", "for", "batch", "in", "data_iter", ":", "\n", "\n", "\n", "\n", "            ", "batch_data", "=", "self", ".", "translate_batch", "(", "batch", ",", "data", ",", "fast", "=", "self", ".", "fast", ")", "\n", "\n", "\n", "translations", "=", "builder", ".", "from_batch", "(", "batch_data", ")", "\n", "\n", "\n", "\n", "for", "trans", "in", "translations", ":", "\n", "                ", "all_scores", "+=", "[", "trans", ".", "pred_scores", "[", ":", "self", ".", "n_best", "]", "]", "\n", "pred_score_total", "+=", "trans", ".", "pred_scores", "[", "0", "]", "\n", "pred_words_total", "+=", "len", "(", "trans", ".", "pred_sents", "[", "0", "]", ")", "\n", "if", "tgt_path", "is", "not", "None", ":", "\n", "                    ", "gold_score_total", "+=", "trans", ".", "gold_score", "\n", "gold_words_total", "+=", "len", "(", "trans", ".", "gold_sent", ")", "+", "1", "\n", "\n", "", "n_best_preds", "=", "[", "\" \"", ".", "join", "(", "pred", ")", "\n", "for", "pred", "in", "trans", ".", "pred_sents", "[", ":", "self", ".", "n_best", "]", "]", "\n", "all_predictions", "+=", "[", "n_best_preds", "]", "\n", "self", ".", "out_file", ".", "write", "(", "'\\n'", ".", "join", "(", "n_best_preds", ")", "+", "'\\n'", ")", "\n", "self", ".", "out_file", ".", "flush", "(", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                    ", "sent_number", "=", "next", "(", "counter", ")", "\n", "output", "=", "trans", ".", "log", "(", "sent_number", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                        ", "self", ".", "logger", ".", "info", "(", "output", ")", "\n", "", "else", ":", "\n", "                        ", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "# Debug attention.", "\n", "", "", "if", "attn_debug", ":", "\n", "                    ", "srcs", "=", "trans", ".", "src_raw", "\n", "preds", "=", "trans", ".", "pred_sents", "[", "0", "]", "\n", "preds", ".", "append", "(", "'</s>'", ")", "\n", "attns", "=", "trans", ".", "attns", "[", "0", "]", ".", "tolist", "(", ")", "\n", "header_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7} \"", "*", "len", "(", "srcs", ")", "\n", "row_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7f} \"", "*", "len", "(", "srcs", ")", "\n", "output", "=", "header_format", ".", "format", "(", "\"\"", ",", "*", "trans", ".", "src_raw", ")", "+", "'\\n'", "\n", "for", "word", ",", "row", "in", "zip", "(", "preds", ",", "attns", ")", ":", "\n", "                        ", "max_index", "=", "row", ".", "index", "(", "max", "(", "row", ")", ")", "\n", "row_format", "=", "row_format", ".", "replace", "(", "\n", "\"{:>10.7f} \"", ",", "\"{:*>10.7f} \"", ",", "max_index", "+", "1", ")", "\n", "row_format", "=", "row_format", ".", "replace", "(", "\n", "\"{:*>10.7f} \"", ",", "\"{:>10.7f} \"", ",", "max_index", ")", "\n", "output", "+=", "row_format", ".", "format", "(", "word", ",", "*", "row", ")", "+", "'\\n'", "\n", "row_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7f} \"", "*", "len", "(", "srcs", ")", "\n", "", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "#TODO change back", "\n", "#if self.report_score:", "\n", "#    msg = self._report_score('PRED', pred_score_total,", "\n", "#                             pred_words_total)", "\n", "#    if self.logger:", "\n", "#        self.logger.info(msg)", "\n", "#    else:", "\n", "#        print(msg)", "\n", "#    if tgt_path is not None:", "\n", "#        msg = self._report_score('GOLD', gold_score_total,", "\n", "#                                 gold_words_total)", "\n", "#        if self.logger:", "\n", "#            self.logger.info(msg)", "\n", "#        else:", "\n", "#            print(msg)", "\n", "#        if self.report_bleu:", "\n", "#            msg = self._report_bleu(tgt_path)", "\n", "#            if self.logger:", "\n", "#                self.logger.info(msg)", "\n", "#            else:", "\n", "#                print(msg)", "\n", "#        if self.report_rouge:", "\n", "#            msg = self._report_rouge(tgt_path)", "\n", "#            if self.logger:", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator.translate_batch": [[305, 330], ["torch.no_grad", "translator.Translator._fast_translate_batch", "translator.Translator._translate_batch"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._fast_translate_batch", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._translate_batch"], ["#                self.logger.info(msg)", "\n", "#            else:", "\n", "#                print(msg)", "\n", "\n", "", "", "", "if", "self", ".", "dump_beam", ":", "\n", "            ", "import", "json", "\n", "json", ".", "dump", "(", "self", ".", "translator", ".", "beam_accum", ",", "\n", "codecs", ".", "open", "(", "self", ".", "dump_beam", ",", "'w'", ",", "'utf-8'", ")", ")", "\n", "", "return", "all_scores", ",", "all_predictions", "\n", "\n", "", "def", "translate_batch", "(", "self", ",", "batch", ",", "data", ",", "fast", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Translate a batch of sentences.\n\n        Mostly a wrapper around :obj:`Beam`.\n\n        Args:\n           batch (:obj:`Batch`): a batch from a dataset object\n           data (:obj:`Dataset`): the dataset object\n           fast (bool): enables fast beam search (may not support all features)\n\n        Todo:\n           Shouldn't need the original dataset.\n        \"\"\"", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._fast_translate_batch": [[331, 510], ["onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.encoder", "translator.Translator.model.decoder.init_decoder_state", "translator.Translator.map_batch_fn", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "torch.arange", "torch.arange", "torch.full", "torch.tensor().repeat", "range", "alive_seq[].view", "translator.Translator.model.decoder", "translator.Translator.model.generator.forward", "translator.Translator.size", "topk_log_probs.index_select.index_select.view().unsqueeze", "curr_scores.reshape.reshape.reshape", "curr_scores.reshape.reshape.topk", "topk_ids.fmod.fmod.div", "topk_ids.fmod.fmod.fmod", "batch_index.index_select.index_select.view", "torch.cat", "topk_ids.fmod.fmod.eq", "is_finished[].eq", "topk_ids.fmod.eq.any", "batch_index.index_select.index_select.view", "memory_bank.index_select.index_select.index_select", "memory_lengths.index_select.index_select.index_select", "translator.Translator.map_batch_fn", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "torch.tensor", "range", "range", "range", "range", "dec_out.squeeze", "beam_offset[].unsqueeze", "attn[].index_select", "topk_ids.fmod.eq.fill_", "alive_seq.view.index_select().view.view", "range", "is_finished[].eq.eq().nonzero().view", "topk_log_probs.index_select.index_select.index_select", "batch_index.index_select.index_select.index_select", "batch_offset.index_select.index_select.index_select", "predictions.index_select().view.view.index_select().view", "topk_log_probs.index_select.index_select.view", "alive_seq.view.index_select().view.index_select", "topk_ids.fmod.fmod.view", "attention.index_select().view.index_select", "torch.cat", "alive_seq.view.index_select().view.size", "attention.index_select().view.view", "topk_ids.fmod.eq.size", "is_finished[].nonzero().view", "len", "alive_seq.view.index_select().view.size", "attention.index_select().view", "state.index_select", "attention.index_select().view.size", "attention.index_select().view.size", "is_finished[].fill_", "hypotheses[].append", "sorted", "enumerate", "is_finished[].eq.eq().nonzero", "predictions.index_select().view.view.index_select", "attention.index_select().view.size", "attention.index_select().view.size", "is_finished[].nonzero", "[].append", "[].append", "[].append", "attention.index_select", "float", "topk_ids.fmod.div.size", "is_finished[].eq.eq"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.init_decoder_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.map_batch_fn", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.map_batch_fn", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.tile", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "fast", ":", "\n", "                ", "return", "self", ".", "_fast_translate_batch", "(", "\n", "batch", ",", "\n", "data", ",", "\n", "self", ".", "max_length", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "n_best", "=", "self", ".", "n_best", ",", "\n", "return_attention", "=", "self", ".", "replace_unk", ")", "\n", "", "else", ":", "\n", "# 2333: go here", "\n", "                ", "return", "self", ".", "_translate_batch", "(", "batch", ",", "data", ")", "\n", "\n", "", "", "", "def", "_fast_translate_batch", "(", "self", ",", "\n", "batch", ",", "\n", "data", ",", "\n", "max_length", ",", "\n", "min_length", "=", "0", ",", "\n", "n_best", "=", "1", ",", "\n", "return_attention", "=", "False", ")", ":", "\n", "# TODO: faster code path for beam_size == 1.", "\n", "\n", "# TODO: support these blacklisted features.", "\n", "        ", "assert", "data", ".", "data_type", "==", "'text'", "\n", "assert", "not", "self", ".", "copy_attn", "\n", "assert", "not", "self", ".", "dump_beam", "\n", "assert", "not", "self", ".", "use_filter_pred", "\n", "assert", "self", ".", "block_ngram_repeat", "==", "0", "\n", "assert", "self", ".", "global_scorer", ".", "beta", "==", "0", "\n", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "start_token", "=", "vocab", ".", "stoi", "[", "inputters", ".", "BOS_WORD", "]", "\n", "end_token", "=", "vocab", ".", "stoi", "[", "inputters", ".", "EOS_WORD", "]", "\n", "\n", "# Encoder forward.", "\n", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "data", ".", "data_type", ")", "\n", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "\n", "enc_states", ",", "memory_bank", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "\n", "src", ",", "memory_bank", ",", "enc_states", ",", "with_cache", "=", "True", ")", "\n", "\n", "# Tile states and memory beam_size times.", "\n", "dec_states", ".", "map_batch_fn", "(", "\n", "lambda", "state", ",", "dim", ":", "tile", "(", "state", ",", "beam_size", ",", "dim", "=", "dim", ")", ")", "\n", "memory_bank", "=", "tile", "(", "memory_bank", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "memory_lengths", "=", "tile", "(", "src_lengths", ",", "beam_size", ")", "\n", "\n", "batch_offset", "=", "torch", ".", "arange", "(", "\n", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "memory_bank", ".", "device", ")", "\n", "beam_offset", "=", "torch", ".", "arange", "(", "\n", "0", ",", "\n", "batch_size", "*", "beam_size", ",", "\n", "step", "=", "beam_size", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "memory_bank", ".", "device", ")", "\n", "alive_seq", "=", "torch", ".", "full", "(", "\n", "[", "batch_size", "*", "beam_size", ",", "1", "]", ",", "\n", "start_token", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "memory_bank", ".", "device", ")", "\n", "alive_attn", "=", "None", "\n", "\n", "# Give full probability to the first beam on the first step.", "\n", "topk_log_probs", "=", "(", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", "+", "[", "float", "(", "\"-inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", ",", "\n", "device", "=", "memory_bank", ".", "device", ")", ".", "repeat", "(", "batch_size", ")", ")", "\n", "\n", "# Structure that holds finished hypotheses.", "\n", "hypotheses", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "\n", "results", "=", "{", "}", "\n", "results", "[", "\"predictions\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"scores\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"attention\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"gold_score\"", "]", "=", "[", "0", "]", "*", "batch_size", "\n", "results", "[", "\"batch\"", "]", "=", "batch", "\n", "\n", "for", "step", "in", "range", "(", "max_length", ")", ":", "\n", "            ", "decoder_input", "=", "alive_seq", "[", ":", ",", "-", "1", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "# Decoder forward.", "\n", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "decoder_input", ",", "\n", "memory_bank", ",", "\n", "dec_states", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "step", "=", "step", ")", "\n", "\n", "# Generator forward.", "\n", "log_probs", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ".", "squeeze", "(", "0", ")", ")", "\n", "vocab_size", "=", "log_probs", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "step", "<", "min_length", ":", "\n", "                ", "log_probs", "[", ":", ",", "end_token", "]", "=", "-", "1e20", "\n", "\n", "# Multiply probs by the beam probability.", "\n", "", "log_probs", "+=", "topk_log_probs", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "alpha", "=", "self", ".", "global_scorer", ".", "alpha", "\n", "length_penalty", "=", "(", "(", "5.0", "+", "(", "step", "+", "1", ")", ")", "/", "6.0", ")", "**", "alpha", "\n", "\n", "# Flatten probs into a list of possibilities.", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "curr_scores", "=", "curr_scores", ".", "reshape", "(", "-", "1", ",", "beam_size", "*", "vocab_size", ")", "\n", "topk_scores", ",", "topk_ids", "=", "curr_scores", ".", "topk", "(", "beam_size", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Recover log probs.", "\n", "topk_log_probs", "=", "topk_scores", "*", "length_penalty", "\n", "\n", "# Resolve beam origin and true word ids.", "\n", "topk_beam_index", "=", "topk_ids", ".", "div", "(", "vocab_size", ")", "\n", "topk_ids", "=", "topk_ids", ".", "fmod", "(", "vocab_size", ")", "\n", "\n", "# Map beam_index to batch_index in the flat representation.", "\n", "batch_index", "=", "(", "\n", "topk_beam_index", "\n", "+", "beam_offset", "[", ":", "topk_beam_index", ".", "size", "(", "0", ")", "]", ".", "unsqueeze", "(", "1", ")", ")", "\n", "select_indices", "=", "batch_index", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Append last prediction.", "\n", "alive_seq", "=", "torch", ".", "cat", "(", "\n", "[", "alive_seq", ".", "index_select", "(", "0", ",", "select_indices", ")", ",", "\n", "topk_ids", ".", "view", "(", "-", "1", ",", "1", ")", "]", ",", "-", "1", ")", "\n", "if", "return_attention", ":", "\n", "                ", "current_attn", "=", "attn", "[", "\"std\"", "]", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "if", "alive_attn", "is", "None", ":", "\n", "                    ", "alive_attn", "=", "current_attn", "\n", "", "else", ":", "\n", "                    ", "alive_attn", "=", "alive_attn", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "alive_attn", "=", "torch", ".", "cat", "(", "[", "alive_attn", ",", "current_attn", "]", ",", "0", ")", "\n", "\n", "", "", "is_finished", "=", "topk_ids", ".", "eq", "(", "end_token", ")", "\n", "if", "step", "+", "1", "==", "max_length", ":", "\n", "                ", "is_finished", ".", "fill_", "(", "1", ")", "\n", "# End condition is top beam is finished.", "\n", "", "end_condition", "=", "is_finished", "[", ":", ",", "0", "]", ".", "eq", "(", "1", ")", "\n", "\n", "# Save finished hypotheses.", "\n", "if", "is_finished", ".", "any", "(", ")", ":", "\n", "                ", "predictions", "=", "alive_seq", ".", "view", "(", "-", "1", ",", "beam_size", ",", "alive_seq", ".", "size", "(", "-", "1", ")", ")", "\n", "attention", "=", "(", "\n", "alive_attn", ".", "view", "(", "\n", "alive_attn", ".", "size", "(", "0", ")", ",", "-", "1", ",", "beam_size", ",", "alive_attn", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "alive_attn", "is", "not", "None", "else", "None", ")", "\n", "for", "i", "in", "range", "(", "is_finished", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "b", "=", "batch_offset", "[", "i", "]", "\n", "if", "end_condition", "[", "i", "]", ":", "\n", "                        ", "is_finished", "[", "i", "]", ".", "fill_", "(", "1", ")", "\n", "", "finished_hyp", "=", "is_finished", "[", "i", "]", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "# Store finished hypotheses for this batch.", "\n", "for", "j", "in", "finished_hyp", ":", "\n", "                        ", "hypotheses", "[", "b", "]", ".", "append", "(", "(", "\n", "topk_scores", "[", "i", ",", "j", "]", ",", "\n", "predictions", "[", "i", ",", "j", ",", "1", ":", "]", ",", "# Ignore start_token.", "\n", "attention", "[", ":", ",", "i", ",", "j", ",", ":", "memory_lengths", "[", "i", "]", "]", "\n", "if", "attention", "is", "not", "None", "else", "None", ")", ")", "\n", "# If the batch reached the end, save the n_best hypotheses.", "\n", "", "if", "end_condition", "[", "i", "]", ":", "\n", "                        ", "best_hyp", "=", "sorted", "(", "\n", "hypotheses", "[", "b", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "for", "n", ",", "(", "score", ",", "pred", ",", "attn", ")", "in", "enumerate", "(", "best_hyp", ")", ":", "\n", "                            ", "if", "n", ">=", "n_best", ":", "\n", "                                ", "break", "\n", "", "results", "[", "\"scores\"", "]", "[", "b", "]", ".", "append", "(", "score", ")", "\n", "results", "[", "\"predictions\"", "]", "[", "b", "]", ".", "append", "(", "pred", ")", "\n", "results", "[", "\"attention\"", "]", "[", "b", "]", ".", "append", "(", "\n", "attn", "if", "attn", "is", "not", "None", "else", "[", "]", ")", "\n", "", "", "", "non_finished", "=", "end_condition", ".", "eq", "(", "0", ")", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "# If all sentences are translated, no need to go further.", "\n", "if", "len", "(", "non_finished", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "# Remove finished batches for the next step.", "\n", "", "topk_log_probs", "=", "topk_log_probs", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "batch_index", "=", "batch_index", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "batch_offset", "=", "batch_offset", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "alive_seq", "=", "predictions", ".", "index_select", "(", "0", ",", "non_finished", ")", ".", "view", "(", "-", "1", ",", "alive_seq", ".", "size", "(", "-", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._translate_batch": [[511, 638], ["set", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.encoder", "translator.Translator.model.decoder.init_decoder_state", "isinstance", "torch.Tensor().type_as().long().fill_.repeat", "translator.Translator.repeat_beam_size_times", "range", "translator.Translator._from_beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "onmt.translate.Beam", "torch.tensor", "translator.Translator._translate_batch.var"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.init_decoder_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.repeat_beam_size_times", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._from_beam"], ["if", "alive_attn", "is", "not", "None", ":", "\n", "                    ", "alive_attn", "=", "attention", ".", "index_select", "(", "1", ",", "non_finished", ")", ".", "view", "(", "alive_attn", ".", "size", "(", "0", ")", ",", "\n", "-", "1", ",", "alive_attn", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "# Reorder states.", "\n", "", "", "select_indices", "=", "batch_index", ".", "view", "(", "-", "1", ")", "\n", "memory_bank", "=", "memory_bank", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "memory_lengths", "=", "memory_lengths", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "dec_states", ".", "map_batch_fn", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "def", "_translate_batch", "(", "self", ",", "batch", ",", "data", ")", ":", "\n", "# (0) Prep each of the components of the search.", "\n", "# And helper method for reducing verbosity.", "\n", "        ", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "data_type", "=", "data", ".", "data_type", "\n", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "\n", "\n", "\n", "\n", "# Define a list of tokens to exclude from ngram-blocking", "\n", "# exclusion_list = [\"<t>\", \"</t>\", \".\"]", "\n", "exclusion_tokens", "=", "set", "(", "[", "vocab", ".", "stoi", "[", "t", "]", "\n", "for", "t", "in", "self", ".", "ignore_when_blocking", "]", ")", "\n", "\n", "beam", "=", "[", "onmt", ".", "translate", ".", "Beam", "(", "beam_size", ",", "n_best", "=", "self", ".", "n_best", ",", "\n", "cuda", "=", "self", ".", "cuda", ",", "\n", "global_scorer", "=", "self", ".", "global_scorer", ",", "\n", "pad", "=", "vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", ",", "\n", "eos", "=", "vocab", ".", "stoi", "[", "inputters", ".", "EOS_WORD", "]", ",", "\n", "bos", "=", "vocab", ".", "stoi", "[", "inputters", ".", "BOS_WORD", "]", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "stepwise_penalty", "=", "self", ".", "stepwise_penalty", ",", "\n", "block_ngram_repeat", "=", "self", ".", "block_ngram_repeat", ",", "\n", "exclusion_tokens", "=", "exclusion_tokens", ")", "\n", "for", "__", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "# Help functions for working with beams and batches", "\n", "def", "var", "(", "a", ")", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "a", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "def", "rvar", "(", "a", ")", ":", "\n", "            ", "return", "var", "(", "a", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", ")", "\n", "\n", "", "def", "bottle", "(", "m", ")", ":", "\n", "            ", "return", "m", ".", "view", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "\n", "\n", "", "def", "unbottle", "(", "m", ")", ":", "\n", "            ", "return", "m", ".", "view", "(", "beam_size", ",", "batch_size", ",", "-", "1", ")", "\n", "\n", "# (1) Run the encoder on the src.", "\n", "", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "data_type", ")", "\n", "src_lengths", "=", "None", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "\n", "\n", "\n", "", "enc_states", ",", "memory_bank", ",", "sent_encoder", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "batch", ".", "src_sents", ",", "src_lengths", ")", "# pass in the src_sents", "\n", "old_src_sents", "=", "batch", ".", "src_sents", ".", "clone", "(", ")", "\n", "\n", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "\n", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "\n", "if", "src_lengths", "is", "None", ":", "\n", "            ", "assert", "not", "isinstance", "(", "memory_bank", ",", "tuple", ")", ",", "'Ensemble decoding only supported for text data'", "\n", "src_lengths", "=", "torch", ".", "Tensor", "(", "batch_size", ")", ".", "type_as", "(", "memory_bank", ".", "data", ")", ".", "long", "(", ")", ".", "fill_", "(", "memory_bank", ".", "size", "(", "0", ")", ")", "\n", "\n", "# (2) Repeat src objects `beam_size` times.", "\n", "", "src_map", "=", "rvar", "(", "batch", ".", "src_map", ".", "data", ")", "if", "data_type", "==", "'text'", "and", "self", ".", "copy_attn", "else", "None", "\n", "if", "isinstance", "(", "memory_bank", ",", "tuple", ")", ":", "\n", "            ", "memory_bank", "=", "tuple", "(", "rvar", "(", "x", ".", "data", ")", "for", "x", "in", "memory_bank", ")", "\n", "", "else", ":", "\n", "            ", "memory_bank", "=", "rvar", "(", "memory_bank", ".", "data", ")", "\n", "", "memory_lengths", "=", "src_lengths", ".", "repeat", "(", "beam_size", ")", "\n", "dec_states", ".", "repeat_beam_size_times", "(", "beam_size", ")", "\n", "\n", "# (3) run the decoder to generate sentences, using beam search.", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "if", "all", "(", "(", "b", ".", "done", "(", ")", "for", "b", "in", "beam", ")", ")", ":", "\n", "                ", "break", "\n", "\n", "# Construct batch x beam_size nxt words.", "\n", "# Get all the pending current beam words and arrange for forward.", "\n", "", "inp", "=", "var", "(", "torch", ".", "stack", "(", "[", "b", ".", "get_current_state", "(", ")", "for", "b", "in", "beam", "]", ")", "\n", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "\n", "# Turn any copied words to UNKs", "\n", "# 0 is unk", "\n", "if", "self", ".", "copy_attn", ":", "\n", "                ", "inp", "=", "inp", ".", "masked_fill", "(", "\n", "inp", ".", "gt", "(", "len", "(", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "-", "1", ")", ",", "0", ")", "\n", "\n", "# Temporary kludge solution to handle changed dim expectation", "\n", "# in the decoder", "\n", "", "inp", "=", "inp", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Run one step.", "\n", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "inp", ",", "memory_bank", ",", "dec_states", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "sent_encoder", "=", "sent_encoder", ",", "src_sents", "=", "old_src_sents", ",", "dec", "=", "True", ",", "\n", "step", "=", "i", ")", "\n", "\n", "dec_out", "=", "dec_out", ".", "squeeze", "(", "0", ")", "\n", "\n", "# dec_out: beam x rnn_size", "\n", "\n", "# (b) Compute a vector of batch x beam word scores.", "\n", "if", "not", "self", ".", "copy_attn", ":", "\n", "                ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ")", ".", "data", "\n", "out", "=", "unbottle", "(", "out", ")", "\n", "# beam x tgt_vocab", "\n", "beam_attn", "=", "unbottle", "(", "attn", "[", "\"std\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ",", "\n", "attn", "[", "\"copy\"", "]", ".", "squeeze", "(", "0", ")", ",", "\n", "src_map", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._from_beam": [[639, 655], ["b.sort_finished", "enumerate", "ret[].append", "ret[].append", "ret[].append", "b.get_hyp", "hyps.append", "attn.append"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.sort_finished", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.get_hyp"], ["# beam x (tgt_vocab + extra_vocab)", "\n", "out", "=", "data", ".", "collapse_copy_scores", "(", "\n", "unbottle", "(", "out", ".", "data", ")", ",", "\n", "batch", ",", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "data", ".", "src_vocabs", ")", "\n", "# beam x tgt_vocab", "\n", "out", "=", "out", ".", "log", "(", ")", "\n", "beam_attn", "=", "unbottle", "(", "attn", "[", "\"copy\"", "]", ")", "\n", "\n", "# (c) Advance each beam.", "\n", "", "for", "j", ",", "b", "in", "enumerate", "(", "beam", ")", ":", "\n", "                ", "b", ".", "advance", "(", "out", "[", ":", ",", "j", "]", ",", "\n", "beam_attn", ".", "data", "[", ":", ",", "j", ",", ":", "memory_lengths", "[", "j", "]", "]", ")", "\n", "dec_states", ".", "beam_update", "(", "j", ",", "b", ".", "get_current_origin", "(", ")", ",", "beam_size", ")", "\n", "\n", "# (4) Extract sentences from beam.", "\n", "", "", "ret", "=", "self", ".", "_from_beam", "(", "beam", ")", "\n", "ret", "[", "\"gold_score\"", "]", "=", "[", "0", "]", "*", "batch_size", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._run_target": [[656, 686], ["onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.encoder", "translator.Translator.model.decoder.init_decoder_state", "tt.FloatTensor().fill_", "translator.Translator.model.decoder", "zip", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.generator.forward", "tgt.unsqueeze.unsqueeze.unsqueeze", "translator.Translator.data.gather", "translator.Translator.data.gather.masked_fill_", "translator.Translator.data.gather.view", "tt.FloatTensor", "tgt.unsqueeze.unsqueeze.eq"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.init_decoder_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward"], ["if", "\"tgt\"", "in", "batch", ".", "__dict__", ":", "\n", "            ", "ret", "[", "\"gold_score\"", "]", "=", "self", ".", "_run_target", "(", "batch", ",", "data", ")", "\n", "", "ret", "[", "\"batch\"", "]", "=", "batch", "\n", "\n", "return", "ret", "\n", "\n", "", "def", "_from_beam", "(", "self", ",", "beam", ")", ":", "\n", "        ", "ret", "=", "{", "\"predictions\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"attention\"", ":", "[", "]", "}", "\n", "for", "b", "in", "beam", ":", "\n", "            ", "n_best", "=", "self", ".", "n_best", "\n", "scores", ",", "ks", "=", "b", ".", "sort_finished", "(", "minimum", "=", "n_best", ")", "\n", "hyps", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "(", "times", ",", "k", ")", "in", "enumerate", "(", "ks", "[", ":", "n_best", "]", ")", ":", "\n", "                ", "hyp", ",", "att", "=", "b", ".", "get_hyp", "(", "times", ",", "k", ")", "\n", "hyps", ".", "append", "(", "hyp", ")", "\n", "attn", ".", "append", "(", "att", ")", "\n", "", "ret", "[", "\"predictions\"", "]", ".", "append", "(", "hyps", ")", "\n", "ret", "[", "\"scores\"", "]", ".", "append", "(", "scores", ")", "\n", "ret", "[", "\"attention\"", "]", ".", "append", "(", "attn", ")", "\n", "", "return", "ret", "\n", "\n", "", "def", "_run_target", "(", "self", ",", "batch", ",", "data", ")", ":", "\n", "        ", "data_type", "=", "data", ".", "data_type", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "", "else", ":", "\n", "            ", "src_lengths", "=", "None", "\n", "", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "data_type", ")", "\n", "tgt_in", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "[", ":", "-", "1", "]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._report_score": [[687, 695], ["math.exp"], "methods", ["None"], ["\n", "#  (1) run the encoder on the src", "\n", "enc_states", ",", "memory_bank", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "\n", "#  (2) if a target is specified, compute the 'goldScore'", "\n", "#  (i.e. log likelihood) of the target under the model", "\n", "tt", "=", "torch", ".", "cuda", "if", "self", ".", "cuda", "else", "torch", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._report_bleu": [[696, 710], ["os.path.abspath", "translator.Translator.out_file.seek", "print", "subprocess.check_output().decode", "subprocess.check_output().decode.strip", "subprocess.check_output"], "methods", ["None"], ["gold_scores", "=", "tt", ".", "FloatTensor", "(", "batch", ".", "batch_size", ")", ".", "fill_", "(", "0", ")", "\n", "dec_out", ",", "_", ",", "_", "=", "self", ".", "model", ".", "decoder", "(", "\n", "tgt_in", ",", "memory_bank", ",", "dec_states", ",", "memory_lengths", "=", "src_lengths", ")", "\n", "\n", "tgt_pad", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "for", "dec", ",", "tgt", "in", "zip", "(", "dec_out", ",", "batch", ".", "tgt", "[", "1", ":", "]", ".", "data", ")", ":", "\n", "# Log prob of each word.", "\n", "            ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec", ")", "\n", "tgt", "=", "tgt", ".", "unsqueeze", "(", "1", ")", "\n", "scores", "=", "out", ".", "data", ".", "gather", "(", "1", ",", "tgt", ")", "\n", "scores", ".", "masked_fill_", "(", "tgt", ".", "eq", "(", "tgt_pad", ")", ",", "0", ")", "\n", "gold_scores", "+=", "scores", ".", "view", "(", "-", "1", ")", "\n", "", "return", "gold_scores", "\n", "\n", "", "def", "_report_score", "(", "self", ",", "name", ",", "score_total", ",", "words_total", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator._report_rouge": [[711, 721], ["subprocess.check_output().decode", "subprocess.check_output().decode.strip", "os.path.split", "os.path.realpath", "subprocess.check_output"], "methods", ["None"], ["        ", "if", "words_total", "==", "0", ":", "\n", "            ", "msg", "=", "\"%s No words predicted\"", "%", "(", "name", ",", ")", "\n", "", "else", ":", "\n", "            ", "msg", "=", "(", "\"%s AVG SCORE: %.4f, %s PPL: %.4f\"", "%", "(", "\n", "name", ",", "score_total", "/", "words_total", ",", "\n", "name", ",", "math", ".", "exp", "(", "-", "score_total", "/", "words_total", ")", ")", ")", "\n", "", "return", "msg", "\n", "\n", "", "def", "_report_bleu", "(", "self", ",", "tgt_path", ")", ":", "\n", "        ", "import", "subprocess", "\n", "base_dir", "=", "os", ".", "path", ".", "abspath", "(", "__file__", "+", "\"/../../..\"", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.build_translator": [[21, 58], ["argparse.ArgumentParser", "onmt.model_opts", "print", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "translator.Translator", "codecs.open", "torch.cuda.set_device", "argparse.ArgumentParser.parse_known_args", "len", "onmt.decoders.ensemble.load_test_model", "onmt.decoders.ensemble.load_test_model", "onmt.decoders.ensemble.load_test_model", "onmt.decoders.ensemble.load_test_model", "onmt.decoders.ensemble.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "getattr"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model"], ["def", "build_translator", "(", "opt", ",", "report_score", "=", "True", ",", "logger", "=", "None", ",", "out_file", "=", "None", ")", ":", "\n", "    ", "if", "out_file", "is", "None", ":", "\n", "        ", "out_file", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w+'", ",", "'utf-8'", ")", "\n", "\n", "", "if", "opt", ".", "gpu", ">", "-", "1", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "\n", "\n", "if", "len", "(", "opt", ".", "models", ")", ">", "1", ":", "\n", "# use ensemble decoding if more than one model is specified", "\n", "        ", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "decoders", ".", "ensemble", ".", "load_test_model", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "\n", "", "else", ":", "\n", "        ", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "model_builder", ".", "load_test_model", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "", "print", "(", "model_opt", ")", "\n", "\n", "\n", "\n", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", "(", "opt", ".", "alpha", ",", "\n", "opt", ".", "beta", ",", "\n", "opt", ".", "coverage_penalty", ",", "\n", "opt", ".", "length_penalty", ")", "\n", "\n", "kwargs", "=", "{", "k", ":", "getattr", "(", "opt", ",", "k", ")", "\n", "for", "k", "in", "[", "\"beam_size\"", ",", "\"n_best\"", ",", "\"max_length\"", ",", "\"min_length\"", ",", "\n", "\"stepwise_penalty\"", ",", "\"block_ngram_repeat\"", ",", "\n", "\"ignore_when_blocking\"", ",", "\"dump_beam\"", ",", "\"report_bleu\"", ",", "\n", "\"data_type\"", ",", "\"replace_unk\"", ",", "\"gpu\"", ",", "\"verbose\"", ",", "\"fast\"", ",", "\n", "\"image_channel_size\"", "]", "}", "\n", "\n", "translator", "=", "Translator", "(", "model", ",", "fields", ",", "global_scorer", "=", "scorer", ",", "\n", "out_file", "=", "out_file", ",", "report_score", "=", "report_score", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.Timer.__init__": [[20, 26], ["translation_server.Timer.start"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start"], ["    ", "def", "__init__", "(", "self", ",", "start", "=", "False", ")", ":", "\n", "        ", "self", ".", "stime", "=", "-", "1", "\n", "self", ".", "prev", "=", "-", "1", "\n", "self", ".", "times", "=", "{", "}", "\n", "if", "start", ":", "\n", "            ", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.Timer.start": [[27, 31], ["time.time"], "methods", ["None"], ["", "", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "stime", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "prev", "=", "self", ".", "stime", "\n", "self", ".", "times", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.Timer.tick": [[32, 43], ["time.time"], "methods", ["None"], ["", "def", "tick", "(", "self", ",", "name", "=", "None", ",", "tot", "=", "False", ")", ":", "\n", "        ", "t", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "tot", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "prev", "\n", "", "else", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "stime", "\n", "", "self", ".", "prev", "=", "t", "\n", "\n", "if", "name", "is", "not", "None", ":", "\n", "            ", "self", ".", "times", "[", "name", "]", "=", "elapsed", "\n", "", "return", "elapsed", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.__init__": [[50, 53], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "models", "=", "{", "}", "\n", "self", ".", "next_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.start": [[54, 81], ["translation_server.TranslationServer.confs.get", "enumerate", "open", "json.load", "conf.get", "translation_server.TranslationServer.preload_model", "conf.get", "conf.get", "conf.get", "conf.get", "conf.get", "ValueError", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.preload_model"], ["", "def", "start", "(", "self", ",", "config_file", ")", ":", "\n", "        ", "\"\"\"Read the config file and pre-/load the models\n        \"\"\"", "\n", "self", ".", "config_file", "=", "config_file", "\n", "with", "open", "(", "self", ".", "config_file", ")", "as", "f", ":", "\n", "            ", "self", ".", "confs", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "models_root", "=", "self", ".", "confs", ".", "get", "(", "'models_root'", ",", "'./available_models'", ")", "\n", "for", "i", ",", "conf", "in", "enumerate", "(", "self", ".", "confs", "[", "\"models\"", "]", ")", ":", "\n", "            ", "if", "\"models\"", "not", "in", "conf", ":", "\n", "                ", "if", "\"model\"", "in", "conf", ":", "\n", "# backwards compatibility for confs", "\n", "                    ", "conf", "[", "\"models\"", "]", "=", "[", "conf", "[", "\"model\"", "]", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"\"\"Incorrect config file: missing 'models'\n                                        parameter for model #%d\"\"\"", "%", "i", ")", "\n", "", "", "kwargs", "=", "{", "'timeout'", ":", "conf", ".", "get", "(", "'timeout'", ",", "None", ")", ",", "\n", "'load'", ":", "conf", ".", "get", "(", "'load'", ",", "None", ")", ",", "\n", "'tokenizer_opt'", ":", "conf", ".", "get", "(", "'tokenizer'", ",", "None", ")", ",", "\n", "'on_timeout'", ":", "conf", ".", "get", "(", "'on_timeout'", ",", "None", ")", ",", "\n", "'model_root'", ":", "conf", ".", "get", "(", "'model_root'", ",", "self", ".", "models_root", ")", "\n", "}", "\n", "kwargs", "=", "{", "k", ":", "v", "for", "(", "k", ",", "v", ")", "in", "kwargs", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", "model_id", "=", "conf", ".", "get", "(", "\"id\"", ",", "None", ")", "\n", "opt", "=", "conf", "[", "\"opt\"", "]", "\n", "opt", "[", "\"models\"", "]", "=", "conf", "[", "\"models\"", "]", "\n", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.clone_model": [[82, 94], ["translation_server.TranslationServer.load_model", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.load_model"], ["", "", "def", "clone_model", "(", "self", ",", "model_id", ",", "opt", ",", "timeout", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Clone a model `model_id`.\n           Different options may be passed. If `opt` is None, it will use the\n           same set of options\n        \"\"\"", "\n", "if", "model_id", "in", "self", ".", "models", ":", "\n", "            ", "if", "opt", "is", "None", ":", "\n", "                ", "opt", "=", "self", ".", "models", "[", "model_id", "]", ".", "user_opt", "\n", "", "opt", "[", "\"models\"", "]", "=", "self", ".", "models", "[", "model_id", "]", ".", "opt", ".", "models", "\n", "return", "self", ".", "load_model", "(", "opt", ",", "timeout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.load_model": [[95, 102], ["translation_server.TranslationServer.preload_model"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.preload_model"], ["", "", "def", "load_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Loading a model given a set of options\n        \"\"\"", "\n", "model_id", "=", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "model_kwargs", ")", "\n", "load_time", "=", "self", ".", "models", "[", "model_id", "]", ".", "load_time", "\n", "\n", "return", "model_id", ",", "load_time", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.preload_model": [[103, 120], ["print", "translation_server.ServerModel", "translation_server.TranslationServer.models.keys", "ValueError", "translation_server.TranslationServer.models.keys"], "methods", ["None"], ["", "def", "preload_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Preloading the model: updating internal datastructure\n           It will effectively load the model if `load` is set\n        \"\"\"", "\n", "if", "model_id", "is", "not", "None", ":", "\n", "            ", "if", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Model ID %d already exists\"", "%", "model_id", ")", "\n", "", "", "else", ":", "\n", "            ", "model_id", "=", "self", ".", "next_id", "\n", "while", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "model_id", "+=", "1", "\n", "", "self", ".", "next_id", "=", "model_id", "+", "1", "\n", "", "print", "(", "\"Pre-loading model %d\"", "%", "model_id", ")", "\n", "model", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "**", "model_kwargs", ")", "\n", "self", ".", "models", "[", "model_id", "]", "=", "model", "\n", "\n", "return", "model_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.run": [[121, 134], ["inputs[].get", "translation_server.TranslationServer.models[].run", "print", "translation_server.ServerModelError", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.run"], ["", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs`\n           We keep the same format as the Lua version i.e.\n             [{\"id\": model_id, \"src\": \"sequence to translate\"},{ ...}]\n\n           We use inputs[0][\"id\"] as the model id\n        \"\"\"", "\n", "model_id", "=", "inputs", "[", "0", "]", ".", "get", "(", "\"id\"", ",", "0", ")", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "models", "[", "model_id", "]", ".", "run", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Error No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.unload_model": [[135, 143], ["translation_server.TranslationServer.models[].unload", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.unload"], ["", "", "def", "unload_model", "(", "self", ",", "model_id", ")", ":", "\n", "        ", "\"\"\"Manually unload a model.\n           It will free the memory and cancel the timer\n        \"\"\"", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "models", "[", "model_id", "]", ".", "unload", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.TranslationServer.list_models": [[144, 151], ["translation_server.TranslationServer.models.items", "model.to_dict"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.to_dict"], ["", "", "def", "list_models", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the list of available models\n        \"\"\"", "\n", "models", "=", "[", "]", "\n", "for", "_", ",", "model", "in", "self", ".", "models", ".", "items", "(", ")", ":", "\n", "            ", "models", "+=", "[", "model", ".", "to_dict", "(", ")", "]", "\n", "", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.__init__": [[154, 189], ["translation_server.ServerModel.parse_opt", "onmt.utils.logging.init_logger", "threading.Event", "translation_server.ServerModel.loading_lock.set", "ValueError", "translation_server.ServerModel.load"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.parse_opt", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.logging.init_logger", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model_id", ",", "tokenizer_opt", "=", "None", ",", "load", "=", "False", ",", "\n", "timeout", "=", "-", "1", ",", "on_timeout", "=", "\"to_cpu\"", ",", "model_root", "=", "\"./\"", ")", ":", "\n", "        ", "\"\"\"\n            Args:\n                opt: (dict) options for the Translator\n                model_id: (int) model id\n                tokenizer_opt: (dict) options for the tokenizer or None\n                load: (bool) whether to load the model during __init__\n                timeout: (int) seconds before running `do_timeout`\n                         Negative values means no timeout\n                on_timeout: (str) in [\"to_cpu\", \"unload\"] set what to do on\n                            timeout (see function `do_timeout`)\n                model_root: (str) path to the model directory\n                            it must contain de model and tokenizer file\n\n        \"\"\"", "\n", "self", ".", "model_root", "=", "model_root", "\n", "self", ".", "opt", "=", "self", ".", "parse_opt", "(", "opt", ")", "\n", "if", "self", ".", "opt", ".", "n_best", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Values of n_best > 1 are not supported\"", ")", "\n", "\n", "", "self", ".", "model_id", "=", "model_id", "\n", "self", ".", "tokenizer_opt", "=", "tokenizer_opt", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "on_timeout", "=", "on_timeout", "\n", "\n", "self", ".", "unload_timer", "=", "None", "\n", "self", ".", "user_opt", "=", "opt", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "logger", "=", "init_logger", "(", "self", ".", "opt", ".", "log_file", ")", "\n", "self", ".", "loading_lock", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "loading_lock", ".", "set", "(", ")", "\n", "\n", "if", "load", ":", "\n", "            ", "self", ".", "load", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.parse_opt": [[190, 224], ["argparse.ArgumentParser", "onmt.opts.translate_opts", "argparse.ArgumentParser.parse_args.items", "argparse.ArgumentParser.parse_args", "isinstance", "os.path.join", "str", "type", "str"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.translate_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args"], ["", "", "def", "parse_opt", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Parse the option set passed by the user using `onmt.opts`\n           Args:\n               opt: (dict) options passed by the user\n\n           Returns:\n               opt: (Namespace) full set of options for the Translator\n        \"\"\"", "\n", "prec_argv", "=", "sys", ".", "argv", "\n", "sys", ".", "argv", "=", "sys", ".", "argv", "[", ":", "1", "]", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "onmt", ".", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "\n", "models", "=", "opt", "[", "'models'", "]", "\n", "if", "not", "isinstance", "(", "models", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "models", "=", "[", "models", "]", "\n", "", "opt", "[", "'models'", "]", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "model", ")", "\n", "for", "model", "in", "models", "]", "\n", "opt", "[", "'src'", "]", "=", "\"dummy_src\"", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "opt", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "==", "'models'", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-model'", "]", "\n", "sys", ".", "argv", "+=", "[", "str", "(", "model", ")", "for", "model", "in", "v", "]", "\n", "", "elif", "type", "(", "v", ")", "==", "bool", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-%s'", "%", "k", "]", "\n", "", "else", ":", "\n", "                ", "sys", ".", "argv", "+=", "[", "'-%s'", "%", "k", ",", "str", "(", "v", ")", "]", "\n", "\n", "", "", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "\n", "sys", ".", "argv", "=", "prec_argv", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.loaded": [[225, 228], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "loaded", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ",", "'translator'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load": [[229, 285], ["translation_server.ServerModel.loading_lock.clear", "translation_server.Timer", "translation_server.ServerModel.logger.info", "translation_server.Timer.start", "translation_server.Timer.tick", "translation_server.Timer.tick", "translation_server.ServerModel.reset_unload_timer", "translation_server.ServerModel.loading_lock.set", "onmt.translate.translator.build_translator", "translation_server.ServerModel.logger.info", "translation_server.ServerModelError", "ValueError", "spm.SentencePieceProcessor", "os.path.join", "spm.SentencePieceProcessor.Load", "open", "ValueError", "dict", "translation_server.ServerModel.tokenizer_opt[].items", "pyonmttok.Tokenizer", "ValueError", "str", "ValueError", "key.endswith", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.reset_unload_timer", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.build_translator"], ["", "def", "load", "(", "self", ")", ":", "\n", "        ", "self", ".", "loading_lock", ".", "clear", "(", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading model %d\"", "%", "self", ".", "model_id", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "translator", "=", "build_translator", "(", "self", ".", "opt", ",", "\n", "report_score", "=", "False", ",", "\n", "out_file", "=", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"Runtime Error: %s\"", "%", "str", "(", "e", ")", ")", "\n", "\n", "", "timer", ".", "tick", "(", "\"model_loading\"", ")", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading tokenizer\"", ")", "\n", "\n", "if", "\"type\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'type'\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "'type'", "]", "==", "'sentencepiece'", ":", "\n", "                ", "if", "\"model\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'model'\"", ")", "\n", "", "import", "sentencepiece", "as", "spm", "\n", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "\n", "self", ".", "tokenizer_opt", "[", "'model'", "]", ")", "\n", "sp", ".", "Load", "(", "model_path", ")", "\n", "self", ".", "tokenizer", "=", "sp", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "'type'", "]", "==", "'pyonmttok'", ":", "\n", "                ", "if", "\"params\"", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Missing mandatory tokenizer option 'params'\"", ")", "\n", "", "import", "pyonmttok", "\n", "if", "self", ".", "tokenizer_opt", "[", "\"mode\"", "]", "is", "not", "None", ":", "\n", "                    ", "mode", "=", "self", ".", "tokenizer_opt", "[", "\"mode\"", "]", "\n", "", "else", ":", "\n", "                    ", "mode", "=", "None", "\n", "# load can be called multiple times: modify copy", "\n", "", "tokenizer_params", "=", "dict", "(", "self", ".", "tokenizer_opt", "[", "\"params\"", "]", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "tokenizer_opt", "[", "\"params\"", "]", ".", "items", "(", ")", ":", "\n", "                    ", "if", "key", ".", "endswith", "(", "\"path\"", ")", ":", "\n", "                        ", "tokenizer_params", "[", "key", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "model_root", ",", "value", ")", "\n", "", "", "tokenizer", "=", "pyonmttok", ".", "Tokenizer", "(", "mode", ",", "\n", "**", "tokenizer_params", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid value for tokenizer type\"", ")", "\n", "\n", "", "", "self", ".", "load_time", "=", "timer", ".", "tick", "(", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "self", ".", "loading_lock", ".", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.run": [[286, 383], ["translation_server.ServerModel.stop_unload_timer", "translation_server.Timer", "translation_server.Timer.start", "translation_server.ServerModel.logger.info", "enumerate", "translation_server.Timer.tick", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.reset_unload_timer", "translation_server.ServerModel.run.flatten_list"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.stop_unload_timer", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.reset_unload_timer"], ["", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs` using this model\n\n            Args:\n                inputs: [{\"src\": \"...\"},{\"src\": ...}]\n\n            Returns:\n                result: (list) translations\n                times: (dict) containing times\n        \"\"\"", "\n", "self", ".", "stop_unload_timer", "(", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "timer", ".", "start", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Running translation using %d\"", "%", "self", ".", "model_id", ")", "\n", "\n", "if", "not", "self", ".", "loading_lock", ".", "is_set", "(", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\n", "\"Model #%d is being loaded by another thread, waiting\"", "\n", "%", "self", ".", "model_id", ")", "\n", "if", "not", "self", ".", "loading_lock", ".", "wait", "(", "timeout", "=", "30", ")", ":", "\n", "                ", "raise", "ServerModelError", "(", "\"Model %d loading timeout\"", "\n", "%", "self", ".", "model_id", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "loaded", ":", "\n", "                ", "self", ".", "load", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"load\"", ")", "\n", "", "elif", "self", ".", "opt", ".", "cuda", ":", "\n", "                ", "self", ".", "to_gpu", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"to_gpu\"", ")", "\n", "\n", "", "", "texts", "=", "[", "]", "\n", "head_spaces", "=", "[", "]", "\n", "tail_spaces", "=", "[", "]", "\n", "sslength", "=", "[", "]", "\n", "for", "i", ",", "inp", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "src", "=", "inp", "[", "'src'", "]", "\n", "if", "src", ".", "strip", "(", ")", "==", "\"\"", ":", "\n", "                ", "head_spaces", ".", "append", "(", "src", ")", "\n", "texts", ".", "append", "(", "\"\"", ")", "\n", "tail_spaces", ".", "append", "(", "\"\"", ")", "\n", "", "else", ":", "\n", "                ", "whitespaces_before", ",", "whitespaces_after", "=", "\"\"", ",", "\"\"", "\n", "match_before", "=", "re", ".", "search", "(", "r'^\\s+'", ",", "src", ")", "\n", "match_after", "=", "re", ".", "search", "(", "r'\\s+$'", ",", "src", ")", "\n", "if", "match_before", "is", "not", "None", ":", "\n", "                    ", "whitespaces_before", "=", "match_before", ".", "group", "(", "0", ")", "\n", "", "if", "match_after", "is", "not", "None", ":", "\n", "                    ", "whitespaces_after", "=", "match_after", ".", "group", "(", "0", ")", "\n", "", "head_spaces", ".", "append", "(", "whitespaces_before", ")", "\n", "tok", "=", "self", ".", "maybe_tokenize", "(", "src", ".", "strip", "(", ")", ")", "\n", "texts", ".", "append", "(", "tok", ")", "\n", "sslength", ".", "append", "(", "len", "(", "tok", ".", "split", "(", ")", ")", ")", "\n", "tail_spaces", ".", "append", "(", "whitespaces_after", ")", "\n", "\n", "", "", "empty_indices", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "texts", ")", "if", "x", "==", "\"\"", "]", "\n", "texts_to_translate", "=", "[", "x", "for", "x", "in", "texts", "if", "x", "!=", "\"\"", "]", "\n", "\n", "scores", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "if", "len", "(", "texts_to_translate", ")", ">", "0", ":", "\n", "            ", "try", ":", "\n", "                ", "scores", ",", "predictions", "=", "self", ".", "translator", ".", "translate", "(", "\n", "src_data_iter", "=", "texts_to_translate", ",", "\n", "batch_size", "=", "self", ".", "opt", ".", "batch_size", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "raise", "ServerModelError", "(", "\"Runtime Error: %s\"", "%", "str", "(", "e", ")", ")", "\n", "\n", "", "", "timer", ".", "tick", "(", "name", "=", "\"translation\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"\"\"Using model #%d\\t%d inputs\n               \\ttranslation time: %f\"\"\"", "%", "(", "self", ".", "model_id", ",", "len", "(", "texts", ")", ",", "\n", "timer", ".", "times", "[", "'translation'", "]", ")", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "\n", "# NOTE: translator returns lists of `n_best` list", "\n", "#       we can ignore that (i.e. flatten lists) only because", "\n", "#       we restrict `n_best=1`", "\n", "def", "flatten_list", "(", "_list", ")", ":", "return", "sum", "(", "_list", ",", "[", "]", ")", "\n", "results", "=", "flatten_list", "(", "predictions", ")", "\n", "scores", "=", "[", "score_tensor", ".", "item", "(", ")", "\n", "for", "score_tensor", "in", "flatten_list", "(", "scores", ")", "]", "\n", "\n", "results", "=", "[", "self", ".", "maybe_detokenize", "(", "item", ")", "\n", "for", "item", "in", "results", "]", "\n", "\n", "# build back results with empty texts", "\n", "for", "i", "in", "empty_indices", ":", "\n", "            ", "results", ".", "insert", "(", "i", ",", "\"\"", ")", "\n", "scores", ".", "insert", "(", "i", ",", "0", ")", "\n", "\n", "", "results", "=", "[", "\"\"", ".", "join", "(", "items", ")", "\n", "for", "items", "in", "zip", "(", "head_spaces", ",", "results", ",", "tail_spaces", ")", "]", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Translation Results: %d\"", ",", "len", "(", "results", ")", ")", "\n", "\n", "return", "results", ",", "scores", ",", "self", ".", "opt", ".", "n_best", ",", "timer", ".", "times", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.do_timeout": [[384, 395], ["translation_server.ServerModel.logger.info", "translation_server.ServerModel.unload", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.to_cpu"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.unload", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.to_cpu"], ["", "def", "do_timeout", "(", "self", ")", ":", "\n", "        ", "\"\"\"Timeout function that free GPU memory by moving the model to CPU\n           or unloading it; depending on `self.on_timemout` value\n        \"\"\"", "\n", "if", "self", ".", "on_timeout", "==", "\"unload\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "self", ".", "unload", "(", ")", "\n", "", "if", "self", ".", "on_timeout", "==", "\"to_cpu\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: sending model %d to CPU\"", "\n", "%", "self", ".", "model_id", ")", "\n", "self", ".", "to_cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.unload": [[396, 402], ["translation_server.ServerModel.logger.info", "torch.cuda.empty_cache"], "methods", ["None"], ["", "", "def", "unload", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "del", "self", ".", "translator", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "self", ".", "unload_timer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.stop_unload_timer": [[403, 406], ["translation_server.ServerModel.unload_timer.cancel"], "methods", ["None"], ["", "def", "stop_unload_timer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "unload_timer", "is", "not", "None", ":", "\n", "            ", "self", ".", "unload_timer", ".", "cancel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.reset_unload_timer": [[407, 414], ["translation_server.ServerModel.stop_unload_timer", "threading.Timer", "translation_server.ServerModel.unload_timer.start"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.stop_unload_timer", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start"], ["", "", "def", "reset_unload_timer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "timeout", "<", "0", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "stop_unload_timer", "(", ")", "\n", "self", ".", "unload_timer", "=", "threading", ".", "Timer", "(", "self", ".", "timeout", ",", "self", ".", "do_timeout", ")", "\n", "self", ".", "unload_timer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.to_dict": [[415, 427], ["translation_server.ServerModel.user_opt.keys"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "hide_opt", "=", "[", "\"models\"", ",", "\"src\"", "]", "\n", "d", "=", "{", "\"model_id\"", ":", "self", ".", "model_id", ",", "\n", "\"opt\"", ":", "{", "k", ":", "self", ".", "user_opt", "[", "k", "]", "for", "k", "in", "self", ".", "user_opt", ".", "keys", "(", ")", "\n", "if", "k", "not", "in", "hide_opt", "}", ",", "\n", "\"models\"", ":", "self", ".", "user_opt", "[", "\"models\"", "]", ",", "\n", "\"loaded\"", ":", "self", ".", "loaded", ",", "\n", "\"timeout\"", ":", "self", ".", "timeout", ",", "\n", "}", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "d", "[", "\"tokenizer\"", "]", "=", "self", ".", "tokenizer_opt", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.to_cpu": [[428, 434], ["translation_server.ServerModel.translator.model.cpu", "torch.cuda.empty_cache"], "methods", ["None"], ["", "def", "to_cpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to CPU and clear CUDA cache\n        \"\"\"", "\n", "self", ".", "translator", ".", "model", ".", "cpu", "(", ")", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.to_gpu": [[435, 440], ["torch.cuda.set_device", "translation_server.ServerModel.translator.model.cuda"], "methods", ["None"], ["", "", "def", "to_gpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to GPU\n        \"\"\"", "\n", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "opt", ".", "gpu", ")", "\n", "self", ".", "translator", ".", "model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.maybe_tokenize": [[441, 449], ["translation_server.ServerModel.tokenize"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.tokenize"], ["", "def", "maybe_tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize the sequence (or not)\n\n           Same args/returns as `tokenize`\n        \"\"\"", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "tokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.tokenize": [[450, 470], ["ValueError", "translation_server.ServerModel.tokenizer.EncodeAsPieces", "translation_server.ServerModel.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.tokenize"], ["", "def", "tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize a single sequence\n\n            Args:\n                sequence: (str) the sequence to tokenize\n\n            Returns:\n                tok: (str) the tokenized sequence\n\n        \"\"\"", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "tok", "=", "self", ".", "tokenizer", ".", "EncodeAsPieces", "(", "sequence", ")", "\n", "tok", "=", "\" \"", ".", "join", "(", "tok", ")", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"pyonmttok\"", ":", "\n", "            ", "tok", ",", "_", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "\n", "tok", "=", "\" \"", ".", "join", "(", "tok", ")", "\n", "", "return", "tok", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.maybe_detokenize": [[471, 479], ["translation_server.ServerModel.detokenize", "sequence.split"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.detokenize"], ["", "def", "maybe_detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"De-tokenize the sequence (or not)\n\n           Same args/returns as `tokenize`\n        \"\"\"", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", "and", "''", ".", "join", "(", "sequence", ".", "split", "(", ")", ")", "!=", "''", ":", "\n", "            ", "return", "self", ".", "detokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.detokenize": [[480, 494], ["ValueError", "translation_server.ServerModel.tokenizer.DecodePieces", "sequence.split", "translation_server.ServerModel.tokenizer.detokenize", "sequence.split"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.detokenize"], ["", "def", "detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Detokenize a single sequence\n\n           Same args/returns as `tokenize`\n        \"\"\"", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "detok", "=", "self", ".", "tokenizer", ".", "DecodePieces", "(", "sequence", ".", "split", "(", ")", ")", "\n", "", "elif", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"pyonmttok\"", ":", "\n", "            ", "detok", "=", "self", ".", "tokenizer", ".", "detokenize", "(", "sequence", ".", "split", "(", ")", ")", "\n", "\n", "", "return", "detok", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.__init__": [[20, 65], ["set", "beam.Beam.tt.FloatTensor().zero_", "beam.Beam.tt.LongTensor().fill_", "beam.Beam.tt.FloatTensor", "beam.Beam.tt.LongTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "pad", ",", "bos", ",", "eos", ",", "\n", "n_best", "=", "1", ",", "cuda", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "min_length", "=", "0", ",", "\n", "stepwise_penalty", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "self", ".", "prev_ks_cpu", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", "\n", ".", "fill_", "(", "pad", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "bos", "\n", "self", ".", "next_ys_cpu", "=", "[", "elem", ".", "tolist", "(", ")", "for", "elem", "in", "self", ".", "next_ys", "]", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "eos", "\n", "self", ".", "eos_top", "=", "False", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "self", ".", "n_best", "=", "n_best", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "global_state", "=", "{", "}", "\n", "\n", "# Minimum prediction length", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n", "# Apply Penalty at every step", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.get_current_state": [[66, 69], ["None"], "methods", ["None"], ["self", ".", "exclusion_tokens", "=", "exclusion_tokens", "\n", "\n", "", "def", "get_current_state", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.get_current_origin": [[70, 73], ["None"], "methods", ["None"], ["return", "self", ".", "next_ys", "[", "-", "1", "]", "\n", "\n", "", "def", "get_current_origin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.advance": [[74, 151], ["word_probs.size", "len", "beam_scores.view", "beam_scores.view.topk", "beam.Beam.all_scores.append", "beam.Beam.prev_ks.append", "beam.Beam.next_ys.append", "beam.Beam.attn.append", "beam.Beam.global_scorer.update_global_state", "range", "beam.Beam.global_scorer.update_score", "range", "len", "range", "attn_out.index_select", "beam.Beam.next_ys[].size", "beam.Beam.all_scores.append", "len", "beam.Beam.scores.unsqueeze().expand_as", "beam.Beam.next_ys[].size", "len", "range", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "beam.Beam.next_ys[].size", "beam.Beam.get_hyp", "set", "range", "beam.Beam.scores.unsqueeze", "set.add", "set", "tuple", "tuple", "len", "hyp[].item"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.update_global_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.update_score", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.get_hyp"], ["return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n", "", "def", "advance", "(", "self", ",", "word_probs", ",", "attn_out", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attn_out`: Compute and update the beam search.\n\n        Parameters:\n\n        * `word_probs`- probs of advancing from the last step (K x words)\n        * `attn_out`- attention at the last step\n\n        Returns: True if beam search is complete.\n        \"\"\"", "\n", "num_words", "=", "word_probs", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "stepwise_penalty", ":", "\n", "            ", "self", ".", "global_scorer", ".", "update_score", "(", "self", ",", "attn_out", ")", "\n", "# force the output to be longer than self.min_length", "\n", "", "cur_len", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "if", "cur_len", "<", "self", ".", "min_length", ":", "\n", "            ", "word_probs", "[", ":", ",", "self", ".", "_eos", "]", "=", "-", "1e20", "\n", "# Sum the previous scores.", "\n", "", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_scores", "=", "word_probs", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "word_probs", ")", "\n", "# Don't let EOS have children.            ", "\n", "beam_scores", "[", "self", ".", "next_ys", "[", "-", "1", "]", "==", "self", ".", "_eos", "]", "=", "-", "1e20", "\n", "# Block ngram repeats", "\n", "if", "self", ".", "block_ngram_repeat", ">", "0", ":", "\n", "                ", "ngrams", "=", "[", "]", "\n", "le", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "hyp", ",", "_", "=", "self", ".", "get_hyp", "(", "le", "-", "1", ",", "j", ",", "requires_attn", "=", "False", ")", "\n", "ngrams", "=", "set", "(", ")", "\n", "fail", "=", "False", "\n", "gram", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "le", "-", "1", ")", ":", "\n", "# Last n tokens, n = block_ngram_repeat", "\n", "                        ", "gram", "=", "(", "gram", "+", "\n", "[", "hyp", "[", "i", "]", "]", ")", "[", "-", "self", ".", "block_ngram_repeat", ":", "]", "\n", "# Skip the blocking if it is in the exclusion list", "\n", "if", "set", "(", "gram", ")", "&", "self", ".", "exclusion_tokens", ":", "\n", "                            ", "continue", "\n", "", "if", "tuple", "(", "gram", ")", "in", "ngrams", ":", "\n", "                            ", "fail", "=", "True", "\n", "", "ngrams", ".", "add", "(", "tuple", "(", "gram", ")", ")", "\n", "", "if", "fail", ":", "\n", "                        ", "beam_scores", "[", "j", "]", "=", "-", "10e20", "\n", "", "", "", "", "else", ":", "\n", "            ", "beam_scores", "=", "word_probs", "[", "0", "]", "\n", "", "flat_beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_scores", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "\n", "True", ",", "True", ")", "\n", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# best_scores_id is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "prev_ks_cpu", ".", "append", "(", "prev_k", ".", "tolist", "(", ")", ")", "\n", "\n", "self", ".", "next_ys", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ")", "\n", "self", ".", "next_ys_cpu", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "self", ".", "attn", ".", "append", "(", "attn_out", ".", "index_select", "(", "0", ",", "prev_k", ")", ")", "\n", "self", ".", "global_scorer", ".", "update_global_state", "(", "self", ")", "\n", "\n", "eos_indicator", "=", "self", ".", "next_ys", "[", "-", "1", "]", "==", "self", ".", "_eos", "\n", "if", "eos_indicator", ".", "any", "(", ")", ":", "\n", "            ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "global_scores_eos", "=", "global_scores", "[", "eos_indicator", "]", "\n", "i_indexes", "=", "torch", ".", "where", "(", "eos_indicator", ")", "[", "0", "]", "\n", "for", "s", ",", "i", ",", "in", "zip", "(", "global_scores_eos", ".", "tolist", "(", ")", ",", "i_indexes", ".", "tolist", "(", ")", ")", ":", "\n", "                ", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "#             for i in range(self.next_ys[-1].size(0)):", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.done": [[152, 154], ["len"], "methods", ["None"], ["#                 if self.next_ys[-1][i] == self._eos:", "\n", "#                     global_scores = self.global_scorer.score(self, self.scores)", "\n", "#                     s = global_scores[i]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.sort_finished": [[155, 169], ["beam.Beam.finished.sort", "len", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.score"], ["#                     self.finished.append((s, len(self.next_ys) - 1, i))", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "_eos", ":", "\n", "            ", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "eos_top", "=", "True", "\n", "\n", "", "", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eos_top", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "n_best", "\n", "\n", "", "def", "sort_finished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.Beam.get_hyp": [[170, 180], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n", "", "def", "get_hyp", "(", "self", ",", "timestep", ",", "k", ",", "requires_attn", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.__init__": [[192, 201], ["onmt.translate.penalties.PenaltyBuilder", "onmt.translate.penalties.PenaltyBuilder.coverage_penalty", "onmt.translate.penalties.PenaltyBuilder.length_penalty"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.coverage_penalty", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.length_penalty"], ["            ", "attn", "=", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "attn", "\n", "\n", "\n", "", "", "class", "GNMTGlobalScorer", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.score": [[202, 216], ["beam.GNMTGlobalScorer.length_penalty", "beam.GNMTGlobalScorer.cov_penalty"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.length_penalty"], ["\n", "\n", "def", "__init__", "(", "self", ",", "alpha", ",", "beta", ",", "cov_penalty", ",", "length_penalty", ")", ":", "\n", "        ", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "penalty_builder", "=", "penalties", ".", "PenaltyBuilder", "(", "cov_penalty", ",", "\n", "length_penalty", ")", "\n", "# Term will be subtracted from probability", "\n", "self", ".", "cov_penalty", "=", "penalty_builder", ".", "coverage_penalty", "(", ")", "\n", "# Probability will be divided by this", "\n", "self", ".", "length_penalty", "=", "penalty_builder", ".", "length_penalty", "(", ")", "\n", "\n", "", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.update_score": [[217, 227], ["beam.global_state.keys", "beam.scores.add_", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.sub_"], "methods", ["None"], ["        ", "\"\"\"\n        Rescores a prediction based on penalty functions\n        \"\"\"", "\n", "normalized_probs", "=", "self", ".", "length_penalty", "(", "beam", ",", "\n", "logprobs", ",", "\n", "self", ".", "alpha", ")", "\n", "if", "not", "beam", ".", "stepwise_penalty", ":", "\n", "            ", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ",", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", ",", "\n", "self", ".", "beta", ")", "\n", "normalized_probs", "-=", "penalty", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.beam.GNMTGlobalScorer.update_global_state": [[228, 244], ["len", "beam.scores.clone().fill_", "beam.attn[].sum", "torch.min().sum", "beam.global_state[].index_select().add", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.clone", "torch.min", "beam.global_state[].index_select"], "methods", ["None"], ["\n", "", "return", "normalized_probs", "\n", "\n", "", "def", "update_score", "(", "self", ",", "beam", ",", "attn", ")", ":", "\n", "        ", "\"\"\"\n        Function to update scores of a Beam that is not finished\n        \"\"\"", "\n", "if", "\"prev_penalty\"", "in", "beam", ".", "global_state", ".", "keys", "(", ")", ":", "\n", "            ", "beam", ".", "scores", ".", "add_", "(", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", ")", "\n", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ",", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "+", "attn", ",", "\n", "self", ".", "beta", ")", "\n", "beam", ".", "scores", ".", "sub_", "(", "penalty", ")", "\n", "\n", "", "", "def", "update_global_state", "(", "self", ",", "beam", ")", ":", "\n", "        ", "\"Keeps the coverage vector as sum of attentions\"", "\n", "if", "len", "(", "beam", ".", "prev_ks", ")", "==", "1", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.__init__": [[14, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cov_pen", ",", "length_pen", ")", ":", "\n", "        ", "self", ".", "length_pen", "=", "length_pen", "\n", "self", ".", "cov_pen", "=", "cov_pen", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.coverage_penalty": [[18, 25], ["None"], "methods", ["None"], ["", "def", "coverage_penalty", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cov_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "coverage_wu", "\n", "", "elif", "self", ".", "cov_pen", "==", "\"summary\"", ":", "\n", "            ", "return", "self", ".", "coverage_summary", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "coverage_none", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.length_penalty": [[26, 33], ["None"], "methods", ["None"], ["", "", "def", "length_penalty", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "length_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "length_wu", "\n", "", "elif", "self", ".", "length_pen", "==", "\"avg\"", ":", "\n", "            ", "return", "self", ".", "length_average", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "length_none", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.coverage_wu": [[38, 45], ["torch.min().log().sum", "torch.min().log", "torch.min", "cov.clone().fill_", "cov.clone"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation.Translation.log"], ["def", "coverage_wu", "(", "self", ",", "beam", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        NMT coverage re-ranking score from\n        \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "penalty", "=", "-", "torch", ".", "min", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "log", "(", ")", ".", "sum", "(", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.coverage_summary": [[46, 53], ["torch.max().sum", "cov.size", "torch.max", "cov.clone().fill_", "cov.clone"], "methods", ["None"], ["", "def", "coverage_summary", "(", "self", ",", "beam", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Our summary penalty.\n        \"\"\"", "\n", "penalty", "=", "torch", ".", "max", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "sum", "(", "1", ")", "\n", "penalty", "-=", "cov", ".", "size", "(", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.coverage_none": [[54, 59], ["beam.scores.clone().fill_", "beam.scores.clone"], "methods", ["None"], ["", "def", "coverage_none", "(", "self", ",", "beam", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        returns zero as penalty\n        \"\"\"", "\n", "return", "beam", ".", "scores", ".", "clone", "(", ")", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.length_wu": [[60, 69], ["len"], "methods", ["None"], ["", "def", "length_wu", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        NMT length re-ranking score from\n        \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "\n", "modifier", "=", "(", "(", "(", "5", "+", "len", "(", "beam", ".", "next_ys", ")", ")", "**", "alpha", ")", "/", "\n", "(", "(", "5", "+", "1", ")", "**", "alpha", ")", ")", "\n", "return", "(", "logprobs", "/", "modifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.length_average": [[70, 75], ["len"], "methods", ["None"], ["", "def", "length_average", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns the average probability of tokens in a sequence.\n        \"\"\"", "\n", "return", "logprobs", "/", "len", "(", "beam", ".", "next_ys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.penalties.PenaltyBuilder.length_none": [[76, 81], ["None"], "methods", ["None"], ["", "def", "length_none", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns unmodified scores.\n        \"\"\"", "\n", "return", "logprobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.stacked_rnn.StackedLSTM.__init__": [[12, 21], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.stacked_rnn.StackedLSTM.forward": [[22, 37], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input_feed", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input_feed", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.stacked_rnn.StackedGRU.__init__": [[45, 54], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedGRU.layers.append", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "GRUCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.stacked_rnn.StackedGRU.forward": [[55, 66], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedGRU.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", "=", "layer", "(", "input_feed", ",", "hidden", "[", "0", "]", "[", "i", "]", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "return", "input_feed", ",", "(", "h_1", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model.NMTModel.__init__": [[16, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "self", ".", "multigpu", "=", "multigpu", "\n", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model.NMTModel.forward": [[22, 58], ["model.NMTModel.encoder", "model.NMTModel.decoder.init_decoder_state", "model.NMTModel.decoder"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.init_decoder_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "src_sents", ",", "lengths", ",", "dec_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (:obj:`Tensor`):\n                a source sequence passed to encoder.\n                typically for inputs this will be a padded :obj:`LongTensor`\n                of size `[len x batch x features]`. however, may be an\n                image or other generic input depending on encoder.\n            tgt (:obj:`LongTensor`):\n                 a target sequence of size `[tgt_len x batch]`.\n            lengths(:obj:`LongTensor`): the src lengths, pre-padding `[batch]`.\n            dec_state (:obj:`DecoderState`, optional): initial decoder state\n        Returns:\n            (:obj:`FloatTensor`, `dict`, :obj:`onmt.Models.DecoderState`):\n\n                 * decoder output `[tgt_len x batch x hidden]`\n                 * dictionary attention dists of `[tgt_len x batch x src_len]`\n                 * final decoder state\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs ?? why", "\n", "\n", "# import pdb;pdb.set_trace()", "\n", "old_src_sents", "=", "src_sents", ".", "clone", "(", ")", "\n", "\n", "\n", "enc_final", ",", "memory_bank", ",", "sent_encoder", "=", "self", ".", "encoder", "(", "src", ",", "src_sents", ",", "lengths", ")", "\n", "\n", "\n", "enc_state", "=", "self", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "memory_bank", ",", "enc_final", ")", "\n", "\n", "\n", "decoder_outputs", ",", "dec_state", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "memory_bank", ",", "\n", "enc_state", "if", "dec_state", "is", "None", "\n", "else", "dec_state", ",", "sent_encoder", "=", "sent_encoder", ",", "src_sents", "=", "old_src_sents", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.CheckSRU.__init__": [[17, 19], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CheckSRU", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.CheckSRU.__call__": [[20, 25], ["setattr", "sru.check_sru_requirement"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.check_sru_requirement"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "values", "==", "'SRU'", ":", "\n", "            ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "# Check pass, set the args.", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.__init__": [[381, 387], ["SRU_Compute.maybe_load_sru_mod", "torch.autograd.Function.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.maybe_load_sru_mod", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["    ", "def", "__init__", "(", "self", ",", "activation_type", ",", "d_out", ",", "bidirectional", "=", "False", ")", ":", "\n", "        ", "SRU_Compute", ".", "maybe_load_sru_mod", "(", ")", "\n", "super", "(", "SRU_Compute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation_type", "=", "activation_type", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.maybe_load_sru_mod": [[388, 394], ["sru.load_sru_mod"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.load_sru_mod"], ["", "@", "staticmethod", "\n", "def", "maybe_load_sru_mod", "(", ")", ":", "\n", "        ", "global", "SRU_FWD_FUNC", "\n", "\n", "if", "SRU_FWD_FUNC", "is", "None", ":", "\n", "            ", "load_sru_mod", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.forward": [[395, 439], ["x.size", "min", "x.new", "x.new", "FUNC", "sru.SRU_Compute.save_for_backward", "x.size", "u.size", "x.new().zero_", "x.dim", "x.dim", "x.dim", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.new", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.contiguous().data_ptr", "mask_h.data_ptr", "u.contiguous", "init_.contiguous", "x.contiguous"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "u", ",", "x", ",", "bias", ",", "init", "=", "None", ",", "mask_h", "=", "None", ")", ":", "\n", "        ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "size", "=", "(", "length", ",", "batch", ",", "d", "*", "bidir", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "c", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "h", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "\n", "FUNC", "=", "SRU_FWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiFWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "h", ".", "data_ptr", "(", ")", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "\n", "self", ".", "save_for_backward", "(", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", ")", "\n", "self", ".", "intermediate", "=", "c", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "last_hidden", "=", "c", "\n", "", "elif", "self", ".", "bidirectional", ":", "\n", "# -> directions x batch x dim", "\n", "            ", "last_hidden", "=", "torch", ".", "stack", "(", "(", "c", "[", "-", "1", ",", ":", ",", ":", "d", "]", ",", "c", "[", "0", ",", ":", ",", "d", ":", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "last_hidden", "=", "c", "[", "-", "1", "]", "\n", "", "return", "h", ",", "last_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU_Compute.backward": [[440, 491], ["x.size", "min", "u.new", "x.new", "x.new", "FUNC", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.size", "u.size", "x.new().zero_", "x.new", "x.new.sum().view", "x.dim", "u.size", "x.new", "x.size", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "c.data_ptr", "grad_h.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "u.new.data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.new.sum", "x.contiguous().data_ptr", "mask_h.data_ptr", "grad_x.data_ptr", "u.contiguous", "init_.contiguous", "grad_h.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "x.contiguous"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_h", ",", "grad_last", ")", ":", "\n", "        ", "if", "self", ".", "bidirectional", ":", "\n", "            ", "grad_last", "=", "torch", ".", "cat", "(", "(", "grad_last", "[", "0", "]", ",", "grad_last", "[", "1", "]", ")", ",", "1", ")", "\n", "", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", "=", "self", ".", "saved_tensors", "\n", "c", "=", "self", ".", "intermediate", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "grad_u", "=", "u", ".", "new", "(", "*", "u", ".", "size", "(", ")", ")", "\n", "grad_bias", "=", "x", ".", "new", "(", "2", ",", "batch", ",", "d", "*", "bidir", ")", "\n", "grad_init", "=", "x", ".", "new", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "\n", "# For DEBUG", "\n", "# size = (length, batch, x.size(-1)) \\", "\n", "#         if x.dim() == 3 else (batch, x.size(-1))", "\n", "# grad_x = x.new(*x.size()) if k_ == 3 else x.new(*size).zero_()", "\n", "\n", "# Normal use", "\n", "grad_x", "=", "x", ".", "new", "(", "*", "x", ".", "size", "(", ")", ")", "if", "k_", "==", "3", "else", "None", "\n", "\n", "FUNC", "=", "SRU_BWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiBWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "grad_h", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "grad_last", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "grad_u", ".", "data_ptr", "(", ")", ",", "\n", "grad_x", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "grad_bias", ".", "data_ptr", "(", ")", ",", "\n", "grad_init", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "return", "grad_u", ",", "grad_x", ",", "grad_bias", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ")", ",", "grad_init", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.__init__": [[494, 515], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "sru.SRUCell.init_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.init_weight"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "        ", "super", "(", "SRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "n_in", "\n", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "activation_type", "=", "2", "if", "use_relu", "else", "(", "1", "if", "use_tanh", "else", "0", ")", "\n", "\n", "out_size", "=", "n_out", "*", "2", "if", "bidirectional", "else", "n_out", "\n", "k", "=", "4", "if", "n_in", "!=", "out_size", "else", "3", "\n", "self", ".", "size_per_dir", "=", "n_out", "*", "k", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_in", ",", "\n", "self", ".", "size_per_dir", "*", "2", "if", "bidirectional", "else", "self", ".", "size_per_dir", "\n", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_out", "*", "4", "if", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ")", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.init_weight": [[516, 520], ["sru.SRUCell.weight.data.uniform_", "sru.SRUCell.bias.data.zero_"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "val_range", "=", "(", "3.0", "/", "self", ".", "n_in", ")", "**", "0.5", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "val_range", ",", "val_range", ")", "\n", "self", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.set_bias": [[521, 527], ["sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_", "sru.SRUCell.bias.data[].zero_"], "methods", ["None"], ["", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "n_out", "=", "self", ".", "n_out", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", "*", "2", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.forward": [[528, 561], ["input.size", "x_2d.mm", "input.data.new().zero_", "sru.SRUCell.get_dropout_mask_", "x.contiguous().view", "sru.SRUCell.get_dropout_mask_", "input.dim", "input.dim", "sru.SRUCell.expand_as", "x.dim", "sru.SRU_Compute", "sru.SRU_Compute", "input.data.new", "x.contiguous"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.get_dropout_mask_", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.get_dropout_mask_"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "2", "or", "input", ".", "dim", "(", ")", "==", "3", "\n", "n_in", ",", "n_out", "=", "self", ".", "n_in", ",", "self", ".", "n_out", "\n", "batch", "=", "input", ".", "size", "(", "-", "2", ")", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "c0", "=", "input", ".", "data", ".", "new", "(", "\n", "batch", ",", "n_out", "if", "not", "self", ".", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ".", "zero_", "(", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "(", "self", ".", "rnn_dropout", ">", "0", ")", ":", "\n", "            ", "mask", "=", "self", ".", "get_dropout_mask_", "(", "(", "batch", ",", "n_in", ")", ",", "self", ".", "rnn_dropout", ")", "\n", "x", "=", "input", "*", "mask", ".", "expand_as", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "\n", "", "x_2d", "=", "x", "if", "x", ".", "dim", "(", ")", "==", "2", "else", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_in", ")", "\n", "u", "=", "x_2d", ".", "mm", "(", "self", ".", "weight", ")", "\n", "\n", "if", "self", ".", "training", "and", "(", "self", ".", "dropout", ">", "0", ")", ":", "\n", "            ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "mask_h", "=", "self", ".", "get_dropout_mask_", "(", "\n", "(", "batch", ",", "n_out", "*", "bidir", ")", ",", "self", ".", "dropout", ")", "\n", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", ",", "mask_h", "\n", ")", "\n", "", "else", ":", "\n", "            ", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", "\n", ")", "\n", "\n", "", "return", "h", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRUCell.get_dropout_mask_": [[562, 565], ["w.new().bernoulli_().div_", "w.new().bernoulli_", "w.new"], "methods", ["None"], ["", "def", "get_dropout_mask_", "(", "self", ",", "size", ",", "p", ")", ":", "\n", "        ", "w", "=", "self", ".", "weight", ".", "data", "\n", "return", "w", ".", "new", "(", "*", "size", ")", ".", "bernoulli_", "(", "1", "-", "p", ")", ".", "div_", "(", "1", "-", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU.__init__": [[589, 616], ["sru.check_sru_requirement", "torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "range", "sru.SRUCell", "sru.SRU.rnn_lst.append"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "# An entry check here, will catch on train side and translate side", "\n", "# if requirements are not satisfied.", "\n", "        ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "super", "(", "SRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "input_size", "\n", "self", ".", "n_out", "=", "hidden_size", "\n", "self", ".", "depth", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "rnn_lst", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "out_size", "=", "hidden_size", "*", "2", "if", "bidirectional", "else", "hidden_size", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "sru_cell", "=", "SRUCell", "(", "\n", "n_in", "=", "self", ".", "n_in", "if", "i", "==", "0", "else", "self", ".", "out_size", ",", "\n", "n_out", "=", "self", ".", "n_out", ",", "\n", "dropout", "=", "dropout", "if", "i", "+", "1", "!=", "num_layers", "else", "0", ",", "\n", "rnn_dropout", "=", "rnn_dropout", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "use_tanh", "=", "use_tanh", ",", "\n", "use_relu", "=", "use_relu", ",", "\n", ")", "\n", "self", ".", "rnn_lst", ".", "append", "(", "sru_cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU.set_bias": [[617, 620], ["l.set_bias"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU.set_bias"], ["", "", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "rnn_lst", ":", "\n", "            ", "l", ".", "set_bias", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.SRU.forward": [[621, 653], ["enumerate", "input.dim", "input.data.new().zero_", "isinstance", "rnn", "lstc.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "c0.dim", "h.squeeze", "input.data.new", "range", "c0.chunk", "input.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ",", "return_hidden", "=", "True", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "3", "# (len, batch, n_in)", "\n", "dir_", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "zeros", "=", "input", ".", "data", ".", "new", "(", "\n", "input", ".", "size", "(", "1", ")", ",", "self", ".", "n_out", "*", "dir_", "\n", ")", ".", "zero_", "(", ")", "\n", "c0", "=", "[", "zeros", "for", "i", "in", "range", "(", "self", ".", "depth", ")", "]", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "c0", ",", "tuple", ")", ":", "\n", "# RNNDecoderState wraps hidden as a tuple.", "\n", "                ", "c0", "=", "c0", "[", "0", "]", "\n", "", "assert", "c0", ".", "dim", "(", ")", "==", "3", "# (depth, batch, dir_*n_out)", "\n", "c0", "=", "[", "h", ".", "squeeze", "(", "0", ")", "for", "h", "in", "c0", ".", "chunk", "(", "self", ".", "depth", ",", "0", ")", "]", "\n", "\n", "", "prevx", "=", "input", "\n", "lstc", "=", "[", "]", "\n", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnn_lst", ")", ":", "\n", "            ", "h", ",", "c", "=", "rnn", "(", "prevx", ",", "c0", "[", "i", "]", ")", "\n", "prevx", "=", "h", "\n", "lstc", ".", "append", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "# fh -> (layers*directions) x batch x dim", "\n", "            ", "fh", "=", "torch", ".", "cat", "(", "lstc", ")", "\n", "", "else", ":", "\n", "            ", "fh", "=", "torch", ".", "stack", "(", "lstc", ")", "\n", "\n", "", "if", "return_hidden", ":", "\n", "            ", "return", "prevx", ",", "fh", "\n", "", "else", ":", "\n", "            ", "return", "prevx", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.check_sru_requirement": [[32, 70], ["re.compile", "os.getenv", "torch.cuda.is_available", "torch.cuda.is_available", "AssertionError", "re.match", "AssertionError", "platform.system", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "AssertionError"], "function", ["None"], ["", "", "def", "check_sru_requirement", "(", "abort", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return True if check pass; if check fails and abort is True,\n    raise an Exception, othereise return False.\n    \"\"\"", "\n", "\n", "# Check 1.", "\n", "try", ":", "\n", "        ", "if", "platform", ".", "system", "(", ")", "==", "'Windows'", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | findstr cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | findstr pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "else", ":", "# Unix-like systems", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires 'cupy' and 'pynvrtc' \"", "\n", "\"python packages installed.\"", ")", "\n", "\n", "# Check 2.", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "is", "False", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires pytorch built with cuda.\"", ")", "\n", "\n", "# Check 3.", "\n", "", "pattern", "=", "re", ".", "compile", "(", "\".*cuda/lib.*\"", ")", "\n", "ld_path", "=", "os", ".", "getenv", "(", "'LD_LIBRARY_PATH'", ",", "\"\"", ")", "\n", "if", "re", ".", "match", "(", "pattern", ",", "ld_path", ")", "is", "None", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires setting cuda lib path, e.g. \"", "\n", "\"export LD_LIBRARY_PATH=/usr/local/cuda/lib64.\"", ")", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.load_sru_mod": [[353, 377], ["sru.check_sru_requirement", "torch.device", "torch.device", "torch.rand().to", "torch.rand().to", "Program", "Program.compile", "function.Module", "function.Module.load", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "collections.namedtuple", "collections.namedtuple.", "SRU_CODE.encode", "bytes", "torch.rand", "torch.rand", "sru_prog.compile.encode", "torch.cuda.current_stream", "torch.cuda.current_stream"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.encode", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.encode"], ["def", "load_sru_mod", "(", ")", ":", "\n", "    ", "global", "SRU_FWD_FUNC", ",", "SRU_BWD_FUNC", ",", "SRU_BiFWD_FUNC", ",", "SRU_BiBWD_FUNC", "\n", "global", "SRU_STREAM", "\n", "if", "check_sru_requirement", "(", ")", ":", "\n", "        ", "from", "cupy", ".", "cuda", "import", "function", "\n", "from", "pynvrtc", ".", "compiler", "import", "Program", "\n", "\n", "# This sets up device to use.", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "tmp_", "=", "torch", ".", "rand", "(", "1", ",", "1", ")", ".", "to", "(", "device", ")", "\n", "\n", "sru_prog", "=", "Program", "(", "SRU_CODE", ".", "encode", "(", "'utf-8'", ")", ",", "\n", "'sru_prog.cu'", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "sru_ptx", "=", "sru_prog", ".", "compile", "(", ")", "\n", "sru_mod", "=", "function", ".", "Module", "(", ")", "\n", "sru_mod", ".", "load", "(", "bytes", "(", "sru_ptx", ".", "encode", "(", ")", ")", ")", "\n", "\n", "SRU_FWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_fwd'", ")", "\n", "SRU_BWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bwd'", ")", "\n", "SRU_BiFWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_fwd'", ")", "\n", "SRU_BiBWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_bwd'", ")", "\n", "\n", "stream", "=", "namedtuple", "(", "'Stream'", ",", "[", "'ptr'", "]", ")", "\n", "SRU_STREAM", "=", "stream", "(", "ptr", "=", "torch", ".", "cuda", ".", "current_stream", "(", ")", ".", "cuda_stream", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaverBase.__init__": [[30, 42], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "base_path", "=", "base_path", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "keep_checkpoint", "=", "keep_checkpoint", "\n", "self", ".", "save_checkpoint_steps", "=", "save_checkpoint_steps", "\n", "\n", "if", "keep_checkpoint", ">", "0", ":", "\n", "            ", "self", ".", "checkpoint_queue", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "keep_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaverBase.maybe_save": [[43, 62], ["model_saver.ModelSaverBase._save", "model_saver.ModelSaverBase.checkpoint_queue.append", "len", "model_saver.ModelSaverBase.checkpoint_queue.popleft", "model_saver.ModelSaverBase._rm_checkpoint"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaver._save", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaver._rm_checkpoint"], ["", "", "def", "maybe_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"\n        Main entry point for model saver\n        It wraps the `_save` method with checks and apply `keep_checkpoint`\n        related logic\n        \"\"\"", "\n", "if", "self", ".", "keep_checkpoint", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "if", "step", "%", "self", ".", "save_checkpoint_steps", "!=", "0", ":", "\n", "            ", "return", "\n", "\n", "", "chkpt", ",", "chkpt_name", "=", "self", ".", "_save", "(", "step", ")", "\n", "\n", "if", "self", ".", "keep_checkpoint", ">", "0", ":", "\n", "            ", "if", "len", "(", "self", ".", "checkpoint_queue", ")", "==", "self", ".", "checkpoint_queue", ".", "maxlen", ":", "\n", "                ", "todel", "=", "self", ".", "checkpoint_queue", ".", "popleft", "(", ")", "\n", "self", ".", "_rm_checkpoint", "(", "todel", ")", "\n", "", "self", ".", "checkpoint_queue", ".", "append", "(", "chkpt_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaverBase._save": [[63, 74], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\" Save a resumable checkpoint.\n\n        Args:\n            step (int): step number\n\n        Returns:\n            checkpoint: the saved object\n            checkpoint_name: name (or path) of the saved checkpoint\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaverBase._rm_checkpoint": [[75, 84], ["NotImplementedError"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Remove a checkpoint\n\n        Args:\n            name(str): name that indentifies the checkpoint\n                (it may be a filepath)\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaver.__init__": [[91, 96], ["model_saver.ModelSaverBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", "=", "0", ")", ":", "\n", "        ", "super", "(", "ModelSaver", ",", "self", ")", ".", "__init__", "(", "\n", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaver._save": [[97, 121], ["real_model.state_dict", "real_generator.state_dict", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "isinstance", "onmt.inputters.save_fields_to_vocab", "real_model.state_dict.items"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.save_fields_to_vocab"], ["", "def", "_save", "(", "self", ",", "step", ")", ":", "\n", "        ", "real_model", "=", "(", "self", ".", "model", ".", "module", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "self", ".", "model", ")", "\n", "real_generator", "=", "(", "real_model", ".", "generator", ".", "module", "\n", "if", "isinstance", "(", "real_model", ".", "generator", ",", "nn", ".", "DataParallel", ")", "\n", "else", "real_model", ".", "generator", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "real_generator", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n", "'vocab'", ":", "onmt", ".", "inputters", ".", "save_fields_to_vocab", "(", "self", ".", "fields", ")", ",", "\n", "'opt'", ":", "self", ".", "model_opt", ",", "\n", "'optim'", ":", "self", ".", "optim", ",", "\n", "}", "\n", "\n", "logger", ".", "info", "(", "\"Saving checkpoint %s_step_%d.pt\"", "%", "(", "self", ".", "base_path", ",", "step", ")", ")", "\n", "checkpoint_path", "=", "'%s_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "step", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n", "return", "checkpoint", ",", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.ModelSaver._rm_checkpoint": [[122, 124], ["os.remove"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.models.model_saver.build_model_saver": [[11, 20], ["model_saver.ModelSaver"], "function", ["None"], ["def", "build_model_saver", "(", "model_opt", ",", "opt", ",", "model", ",", "fields", ",", "optim", ")", ":", "\n", "    ", "model_saver", "=", "ModelSaver", "(", "opt", ".", "save_model", ",", "\n", "model", ",", "\n", "model_opt", ",", "\n", "fields", ",", "\n", "optim", ",", "\n", "opt", ".", "save_checkpoint_steps", ",", "\n", "opt", ".", "keep_checkpoint", ")", "\n", "return", "model_saver", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.__init__": [[26, 29], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TestModel", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_vocab": [[32, 36], ["src.build_vocab", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "src", "=", "onmt", ".", "inputters", ".", "get_fields", "(", "\"text\"", ",", "0", ",", "0", ")", "[", "\"src\"", "]", "\n", "src", ".", "build_vocab", "(", "[", "]", ")", "\n", "return", "src", ".", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch": [[37, 43], ["torch.ones().long", "torch.ones().long", "torch.ones().fill_().long", "torch.ones", "torch.ones", "torch.ones().fill_", "torch.ones"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "# len x batch x nfeat", "\n", "        ", "test_src", "=", "torch", ".", "ones", "(", "source_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_tgt", "=", "torch", ".", "ones", "(", "source_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_length", "=", "torch", ".", "ones", "(", "bsize", ")", ".", "fill_", "(", "source_l", ")", ".", "long", "(", ")", "\n", "return", "test_src", ",", "test_tgt", ",", "test_length", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch_image": [[44, 50], ["torch.ones().float", "torch.ones().long", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "get_batch_image", "(", "self", ",", "tgt_l", "=", "3", ",", "bsize", "=", "1", ",", "h", "=", "15", ",", "w", "=", "17", ")", ":", "\n", "# batch x c x h x w", "\n", "        ", "test_src", "=", "torch", ".", "ones", "(", "bsize", ",", "3", ",", "h", ",", "w", ")", ".", "float", "(", ")", "\n", "test_tgt", "=", "torch", ".", "ones", "(", "tgt_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_length", "=", "None", "\n", "return", "test_src", ",", "test_tgt", ",", "test_length", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch_audio": [[51, 59], ["int", "torch.ones().float", "torch.ones().long", "math.floor", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "get_batch_audio", "(", "self", ",", "tgt_l", "=", "3", ",", "bsize", "=", "1", ",", "sample_rate", "=", "5500", ",", "\n", "window_size", "=", "0.03", ",", "t", "=", "37", ")", ":", "\n", "# batch x 1 x nfft x t", "\n", "        ", "nfft", "=", "int", "(", "math", ".", "floor", "(", "(", "sample_rate", "*", "window_size", ")", "/", "2", ")", "+", "1", ")", "\n", "test_src", "=", "torch", ".", "ones", "(", "bsize", ",", "1", ",", "nfft", ",", "t", ")", ".", "float", "(", ")", "\n", "test_tgt", "=", "torch", ".", "ones", "(", "tgt_l", ",", "bsize", ",", "1", ")", ".", "long", "(", ")", "\n", "test_length", "=", "None", "\n", "return", "test_src", ",", "test_tgt", ",", "test_length", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.embeddings_forward": [[60, 84], ["test_models.TestModel.get_vocab", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "test_models.TestModel.get_batch", "test_models.TestModel.assertEqual", "torch.cat", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "torch.zeros", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "onmt.model_builder.build_embeddings.", "torch.zeros", "onmt.model_builder.build_embeddings.size", "torch.zeros.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch"], ["", "def", "embeddings_forward", "(", "self", ",", "opt", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "        ", "'''\n        Tests if the embeddings works as expected\n\n        args:\n            opt: set of options\n            source_l: Length of generated input sentence\n            bsize: Batchsize of generated input\n        '''", "\n", "word_dict", "=", "self", ".", "get_vocab", "(", ")", "\n", "feature_dicts", "=", "[", "]", "\n", "emb", "=", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ")", "\n", "test_src", ",", "_", ",", "__", "=", "self", ".", "get_batch", "(", "source_l", "=", "source_l", ",", "\n", "bsize", "=", "bsize", ")", "\n", "if", "opt", ".", "decoder_type", "==", "'transformer'", ":", "\n", "            ", "input", "=", "torch", ".", "cat", "(", "[", "test_src", ",", "test_src", "]", ",", "0", ")", "\n", "res", "=", "emb", "(", "input", ")", "\n", "compare_to", "=", "torch", ".", "zeros", "(", "source_l", "*", "2", ",", "bsize", ",", "\n", "opt", ".", "src_word_vec_size", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "emb", "(", "test_src", ")", "\n", "compare_to", "=", "torch", ".", "zeros", "(", "source_l", ",", "bsize", ",", "opt", ".", "src_word_vec_size", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "res", ".", "size", "(", ")", ",", "compare_to", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.encoder_forward": [[85, 114], ["test_models.TestModel.get_vocab", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "test_models.TestModel.get_batch", "onmt.model_builder.build_encoder.", "onmt.model_builder.build_encoder.", "onmt.model_builder.build_encoder.", "torch.zeros", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "torch.zeros.size", "hidden_t[].size", "hidden_t[].size", "torch.zeros.size", "outputs.size", "type"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch"], ["", "def", "encoder_forward", "(", "self", ",", "opt", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "        ", "'''\n        Tests if the encoder works as expected\n\n        args:\n            opt: set of options\n            source_l: Length of generated input sentence\n            bsize: Batchsize of generated input\n        '''", "\n", "word_dict", "=", "self", ".", "get_vocab", "(", ")", "\n", "feature_dicts", "=", "[", "]", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ")", "\n", "enc", "=", "build_encoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch", "(", "source_l", "=", "source_l", ",", "\n", "bsize", "=", "bsize", ")", "\n", "\n", "hidden_t", ",", "outputs", "=", "enc", "(", "test_src", ",", "test_length", ")", "\n", "\n", "# Initialize vectors to compare size with", "\n", "test_hid", "=", "torch", ".", "zeros", "(", "self", ".", "opt", ".", "enc_layers", ",", "bsize", ",", "opt", ".", "rnn_size", ")", "\n", "test_out", "=", "torch", ".", "zeros", "(", "source_l", ",", "bsize", ",", "opt", ".", "rnn_size", ")", "\n", "\n", "# Ensure correct sizes and types", "\n", "self", ".", "assertEqual", "(", "test_hid", ".", "size", "(", ")", ",", "\n", "hidden_t", "[", "0", "]", ".", "size", "(", ")", ",", "\n", "hidden_t", "[", "1", "]", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "test_out", ".", "size", "(", ")", ",", "outputs", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.nmtmodel_forward": [[115, 146], ["test_models.TestModel.get_vocab", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "onmt.model_builder.build_encoder", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "test_models.TestModel.get_batch", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "outputs.size", "torch.zeros.size", "type"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch"], ["", "def", "nmtmodel_forward", "(", "self", ",", "opt", ",", "source_l", "=", "3", ",", "bsize", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Creates a nmtmodel with a custom opt function.\n        Forwards a testbatch and checks output size.\n\n        Args:\n            opt: Namespace with options\n            source_l: length of input sequence\n            bsize: batchsize\n        \"\"\"", "\n", "word_dict", "=", "self", ".", "get_vocab", "(", ")", "\n", "feature_dicts", "=", "[", "]", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ")", "\n", "enc", "=", "build_encoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ",", "\n", "for_encoder", "=", "False", ")", "\n", "dec", "=", "build_decoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "model", ".", "NMTModel", "(", "enc", ",", "dec", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch", "(", "source_l", "=", "source_l", ",", "\n", "bsize", "=", "bsize", ")", "\n", "outputs", ",", "attn", ",", "_", "=", "model", "(", "test_src", ",", "\n", "test_tgt", ",", "\n", "test_length", ")", "\n", "outputsize", "=", "torch", ".", "zeros", "(", "source_l", "-", "1", ",", "bsize", ",", "opt", ".", "rnn_size", ")", "\n", "# Make sure that output has the correct size and type", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "size", "(", ")", ",", "outputsize", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.imagemodel_forward": [[147, 185], ["test_models.TestModel.get_vocab", "onmt.encoders.image_encoder.ImageEncoder", "onmt.encoders.image_encoder.ImageEncoder", "onmt.encoders.image_encoder.ImageEncoder", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "test_models.TestModel.get_batch_image", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "outputs.size", "torch.zeros.size", "type"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch_image"], ["", "def", "imagemodel_forward", "(", "self", ",", "opt", ",", "tgt_l", "=", "2", ",", "bsize", "=", "1", ",", "h", "=", "15", ",", "w", "=", "17", ")", ":", "\n", "        ", "\"\"\"\n        Creates an image-to-text nmtmodel with a custom opt function.\n        Forwards a testbatch and checks output size.\n\n        Args:\n            opt: Namespace with options\n            source_l: length of input sequence\n            bsize: batchsize\n        \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "'transformer'", "or", "opt", ".", "encoder_type", "==", "'cnn'", ":", "\n", "            ", "return", "\n", "\n", "", "word_dict", "=", "self", ".", "get_vocab", "(", ")", "\n", "feature_dicts", "=", "[", "]", "\n", "\n", "enc", "=", "ImageEncoder", "(", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "dropout", ")", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ",", "\n", "for_encoder", "=", "False", ")", "\n", "dec", "=", "build_decoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "model", ".", "NMTModel", "(", "enc", ",", "dec", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch_image", "(", "\n", "h", "=", "h", ",", "w", "=", "w", ",", "\n", "bsize", "=", "bsize", ",", "\n", "tgt_l", "=", "tgt_l", ")", "\n", "outputs", ",", "attn", ",", "_", "=", "model", "(", "test_src", ",", "\n", "test_tgt", ",", "\n", "test_length", ")", "\n", "outputsize", "=", "torch", ".", "zeros", "(", "tgt_l", "-", "1", ",", "bsize", ",", "opt", ".", "rnn_size", ")", "\n", "# Make sure that output has the correct size and type", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "size", "(", ")", ",", "outputsize", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.audiomodel_forward": [[186, 227], ["test_models.TestModel.get_vocab", "onmt.encoders.audio_encoder.AudioEncoder", "onmt.encoders.audio_encoder.AudioEncoder", "onmt.encoders.audio_encoder.AudioEncoder", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_embeddings", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.model_builder.build_decoder", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "onmt.models.model.NMTModel", "test_models.TestModel.get_batch_audio", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "onmt.models.model.NMTModel.", "torch.zeros", "test_models.TestModel.assertEqual", "test_models.TestModel.assertEqual", "outputs.size", "torch.zeros.size", "type"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models.TestModel.get_batch_audio"], ["", "def", "audiomodel_forward", "(", "self", ",", "opt", ",", "tgt_l", "=", "2", ",", "bsize", "=", "1", ",", "t", "=", "37", ")", ":", "\n", "        ", "\"\"\"\n        Creates a speech-to-text nmtmodel with a custom opt function.\n        Forwards a testbatch and checks output size.\n\n        Args:\n            opt: Namespace with options\n            source_l: length of input sequence\n            bsize: batchsize\n        \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "'transformer'", "or", "opt", ".", "encoder_type", "==", "'cnn'", ":", "\n", "            ", "return", "\n", "\n", "", "word_dict", "=", "self", ".", "get_vocab", "(", ")", "\n", "feature_dicts", "=", "[", "]", "\n", "\n", "enc", "=", "AudioEncoder", "(", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "brnn", ",", "\n", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "dropout", ",", "\n", "opt", ".", "sample_rate", ",", "\n", "opt", ".", "window_size", ")", "\n", "\n", "embeddings", "=", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ",", "\n", "for_encoder", "=", "False", ")", "\n", "dec", "=", "build_decoder", "(", "opt", ",", "embeddings", ")", "\n", "\n", "model", "=", "onmt", ".", "models", ".", "model", ".", "NMTModel", "(", "enc", ",", "dec", ")", "\n", "\n", "test_src", ",", "test_tgt", ",", "test_length", "=", "self", ".", "get_batch_audio", "(", "\n", "bsize", "=", "bsize", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "t", "=", "t", ",", "tgt_l", "=", "tgt_l", ")", "\n", "outputs", ",", "attn", ",", "_", "=", "model", "(", "test_src", ",", "\n", "test_tgt", ",", "\n", "test_length", ")", "\n", "outputsize", "=", "torch", ".", "zeros", "(", "tgt_l", "-", "1", ",", "bsize", ",", "opt", ".", "rnn_size", ")", "\n", "# Make sure that output has the correct size and type", "\n", "self", ".", "assertEqual", "(", "outputs", ".", "size", "(", ")", ",", "outputsize", ".", "size", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "type", "(", "outputs", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_models._add_test": [[229, 253], ["setattr", "copy.deepcopy", "getattr", "setattr", "str().split", "str"], "function", ["None"], ["", "", "def", "_add_test", "(", "param_setting", ",", "methodname", ")", ":", "\n", "    ", "\"\"\"\n    Adds a Test to TestModel according to settings\n\n    Args:\n        param_setting: list of tuples of (param, setting)\n        methodname: name of the method that gets called\n    \"\"\"", "\n", "\n", "def", "test_method", "(", "self", ")", ":", "\n", "        ", "if", "param_setting", ":", "\n", "            ", "opt", "=", "copy", ".", "deepcopy", "(", "self", ".", "opt", ")", "\n", "for", "param", ",", "setting", "in", "param_setting", ":", "\n", "                ", "setattr", "(", "opt", ",", "param", ",", "setting", ")", "\n", "", "", "else", ":", "\n", "            ", "opt", "=", "self", ".", "opt", "\n", "", "getattr", "(", "self", ",", "methodname", ")", "(", "opt", ")", "\n", "", "if", "param_setting", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "\"_\"", "+", "\"_\"", ".", "join", "(", "\n", "str", "(", "param_setting", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "'_standard'", "\n", "", "setattr", "(", "TestModel", ",", "name", ",", "test_method", ")", "\n", "test_method", ".", "__name__", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_preprocess.TestData.__init__": [[39, 42], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TestData", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_preprocess.TestData.dataset_build": [[43, 66], ["onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "onmt.inputters.get_fields", "preprocess.build_save_dataset", "preprocess.build_save_vocab", "preprocess.build_save_dataset", "glob.glob", "hasattr", "hasattr", "os.remove", "hasattr", "os.path.exists", "os.remove", "hasattr", "os.path.exists", "os.remove", "len", "codecs.open", "f.write", "len", "codecs.open", "f.write"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_dataset"], ["", "def", "dataset_build", "(", "self", ",", "opt", ")", ":", "\n", "        ", "fields", "=", "onmt", ".", "inputters", ".", "get_fields", "(", "\"text\"", ",", "0", ",", "0", ")", "\n", "\n", "if", "hasattr", "(", "opt", ",", "'src_vocab'", ")", "and", "len", "(", "opt", ".", "src_vocab", ")", ">", "0", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "opt", ".", "src_vocab", ",", "'w'", ",", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "'a\\nb\\nc\\nd\\ne\\nf\\n'", ")", "\n", "", "", "if", "hasattr", "(", "opt", ",", "'tgt_vocab'", ")", "and", "len", "(", "opt", ".", "tgt_vocab", ")", ">", "0", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "opt", ".", "tgt_vocab", ",", "'w'", ",", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "'a\\nb\\nc\\nd\\ne\\nf\\n'", ")", "\n", "\n", "", "", "train_data_files", "=", "preprocess", ".", "build_save_dataset", "(", "'train'", ",", "fields", ",", "opt", ")", "\n", "\n", "preprocess", ".", "build_save_vocab", "(", "train_data_files", ",", "fields", ",", "opt", ")", "\n", "\n", "preprocess", ".", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "opt", ")", "\n", "\n", "# Remove the generated *pt files.", "\n", "for", "pt", "in", "glob", ".", "glob", "(", "SAVE_DATA_PREFIX", "+", "'*.pt'", ")", ":", "\n", "            ", "os", ".", "remove", "(", "pt", ")", "\n", "", "if", "hasattr", "(", "opt", ",", "'src_vocab'", ")", "and", "os", ".", "path", ".", "exists", "(", "opt", ".", "src_vocab", ")", ":", "\n", "            ", "os", ".", "remove", "(", "opt", ".", "src_vocab", ")", "\n", "", "if", "hasattr", "(", "opt", ",", "'tgt_vocab'", ")", "and", "os", ".", "path", ".", "exists", "(", "opt", ".", "tgt_vocab", ")", ":", "\n", "            ", "os", ".", "remove", "(", "opt", ".", "tgt_vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_preprocess.TestData.test_merge_vocab": [[67, 78], ["torchtext.vocab.Vocab", "torchtext.vocab.Vocab", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "onmt.inputters.merge_vocabs", "test_preprocess.TestData.assertEqual", "test_preprocess.TestData.assertEqual", "test_preprocess.TestData.assertTrue", "collections.Counter", "collections.Counter", "collections.Counter", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.merge_vocabs"], ["", "", "def", "test_merge_vocab", "(", "self", ")", ":", "\n", "        ", "va", "=", "torchtext", ".", "vocab", ".", "Vocab", "(", "Counter", "(", "'abbccc'", ")", ")", "\n", "vb", "=", "torchtext", ".", "vocab", ".", "Vocab", "(", "Counter", "(", "'eeabbcccf'", ")", ")", "\n", "\n", "merged", "=", "onmt", ".", "inputters", ".", "merge_vocabs", "(", "[", "va", ",", "vb", "]", ",", "2", ")", "\n", "\n", "self", ".", "assertEqual", "(", "Counter", "(", "{", "'c'", ":", "6", ",", "'b'", ":", "4", ",", "'a'", ":", "2", ",", "'e'", ":", "2", ",", "'f'", ":", "1", "}", ")", ",", "\n", "merged", ".", "freqs", ")", "\n", "# 4 specicials + 2 words (since we pass 2 to merge_vocabs)", "\n", "self", ".", "assertEqual", "(", "6", ",", "len", "(", "merged", ".", "itos", ")", ")", "\n", "self", ".", "assertTrue", "(", "'b'", "in", "merged", ".", "itos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_preprocess._add_test": [[80, 104], ["setattr", "copy.deepcopy", "getattr", "setattr", "str().split", "str"], "function", ["None"], ["", "", "def", "_add_test", "(", "param_setting", ",", "methodname", ")", ":", "\n", "    ", "\"\"\"\n    Adds a Test to TestData according to settings\n\n    Args:\n        param_setting: list of tuples of (param, setting)\n        methodname: name of the method that gets called\n    \"\"\"", "\n", "\n", "def", "test_method", "(", "self", ")", ":", "\n", "        ", "if", "param_setting", ":", "\n", "            ", "opt", "=", "copy", ".", "deepcopy", "(", "self", ".", "opt", ")", "\n", "for", "param", ",", "setting", "in", "param_setting", ":", "\n", "                ", "setattr", "(", "opt", ",", "param", ",", "setting", ")", "\n", "", "", "else", ":", "\n", "            ", "opt", "=", "self", ".", "opt", "\n", "", "getattr", "(", "self", ",", "methodname", ")", "(", "opt", ")", "\n", "", "if", "param_setting", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "\"_\"", "+", "\"_\"", ".", "join", "(", "\n", "str", "(", "param_setting", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "name", "=", "'test_'", "+", "methodname", "+", "'_standard'", "\n", "", "setattr", "(", "TestData", ",", "name", ",", "test_method", ")", "\n", "test_method", ".", "__name__", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_simple.test_load": [[4, 7], ["None"], "function", ["None"], ["def", "test_load", "(", ")", ":", "\n", "    ", "onmt", "\n", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tests.test_attention.TestAttention.test_masked_global_attention": [[13, 33], ["torch.IntTensor", "torch.IntTensor.size", "torch.autograd.Variable", "torch.autograd.Variable", "onmt.modules.GlobalAttention", "onmt.modules.GlobalAttention.", "torch.randn", "torch.randn", "torch.IntTensor.max"], "methods", ["None"], ["    ", "def", "test_masked_global_attention", "(", "self", ")", ":", "\n", "\n", "        ", "source_lengths", "=", "torch", ".", "IntTensor", "(", "[", "7", ",", "3", ",", "5", ",", "2", "]", ")", "\n", "# illegal_weights_mask = torch.ByteTensor([", "\n", "#     [0, 0, 0, 0, 0, 0, 0],", "\n", "#     [0, 0, 0, 1, 1, 1, 1],", "\n", "#     [0, 0, 0, 0, 0, 1, 1],", "\n", "#     [0, 0, 1, 1, 1, 1, 1]])", "\n", "\n", "batch_size", "=", "source_lengths", ".", "size", "(", "0", ")", "\n", "dim", "=", "20", "\n", "\n", "memory_bank", "=", "Variable", "(", "torch", ".", "randn", "(", "batch_size", ",", "\n", "source_lengths", ".", "max", "(", ")", ",", "dim", ")", ")", "\n", "hidden", "=", "Variable", "(", "torch", ".", "randn", "(", "batch_size", ",", "dim", ")", ")", "\n", "\n", "attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "dim", ")", "\n", "\n", "_", ",", "alignments", "=", "attn", "(", "hidden", ",", "memory_bank", ",", "\n", "memory_lengths", "=", "source_lengths", ")", "\n", "# TODO: fix for pytorch 0.3", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_encoder.CNNEncoder.__init__": [[18, 27], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.Linear", "onmt.utils.cnn_factory.StackedCNN"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "input_size", "=", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "cnn", "=", "StackedCNN", "(", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_encoder.CNNEncoder.forward": [[28, 44], ["cnn_encoder.CNNEncoder._check_args", "cnn_encoder.CNNEncoder.embeddings", "emb.transpose().contiguous.transpose().contiguous.transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.view", "cnn_encoder.CNNEncoder.linear", "onmt.utils.cnn_factory.shape_transform.view", "onmt.utils.cnn_factory.shape_transform", "cnn_encoder.CNNEncoder.cnn", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose().contiguous", "cnn_encoder.CNNEncoder.squeeze().transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.transpose", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose", "cnn_encoder.CNNEncoder.squeeze().transpose", "onmt.utils.cnn_factory.shape_transform.squeeze", "cnn_encoder.CNNEncoder.squeeze"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.shape_transform", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "input", ",", "lengths", ",", "hidden", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "# s_len, batch, emb_dim = emb.size()", "\n", "\n", "emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "emb_reshape", "=", "emb", ".", "view", "(", "emb", ".", "size", "(", "0", ")", "*", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "emb_remap", "=", "emb_remap", ".", "view", "(", "emb", ".", "size", "(", "0", ")", ",", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "shape_transform", "(", "emb_remap", ")", "\n", "out", "=", "self", ".", "cnn", "(", "emb_remap", ")", "\n", "\n", "return", "emb_remap", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "out", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase._check_args": [[35, 40], ["src.size", "lengths.size", "onmt.utils.misc.aeq"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq"], ["def", "_check_args", "(", "self", ",", "src", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "_", ",", "n_batch", ",", "_", "=", "src", ".", "size", "(", ")", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "            ", "n_batch_", ",", "=", "lengths", ".", "size", "(", ")", "\n", "aeq", "(", "n_batch", ",", "n_batch_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase.forward": [[41, 55], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (:obj:`LongTensor`):\n               padded sequences of sparse indices `[src_len x batch x nfeat]`\n            lengths (:obj:`LongTensor`): length of each sequence `[batch]`\n\n\n        Returns:\n            (tuple of :obj:`FloatTensor`, :obj:`FloatTensor`):\n                * final encoder state, used to initialize decoder\n                * memory bank for attention, `[src_len x batch x hidden]`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder.__init__": [[27, 52], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "rnn_encoder.RNNEncoder._initialize_bridge"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder._initialize_bridge"], ["\n", "\n", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "use_bridge", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "self", ".", "rnn", ",", "self", ".", "no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "# this is 1.", "\n", "dropout", "=", "dropout", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder.build_sentence_layer": [[71, 151], ["isinstance", "memory_bank.permute", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_encoder.RNNEncoder.sent_rnn", "len", "output.unsqueeze.unsqueeze.unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "batch_input_list.append", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "sent_input_list.append", "len", "output[].size", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output.unsqueeze.unsqueeze.size", "sent_id.size", "sent_id.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len"], "methods", ["None"], ["", "", "def", "build_sentence_layer", "(", "self", ",", "memory_bank", ",", "src_sents", ")", ":", "\n", "        ", "'''\n        In this method we define sentence level representation. (This is the old version)\n        :param memory_bank:\n        :param encoder_final:\n        :param src_sents:\n        :return: sentence embeddings\n        '''", "\n", "# print('Memory..', memory_bank.size()) # torch.Size([200, 2, 512]) TODO: this is the output", "\n", "# #", "\n", "# print ('encoder_final..',encoder_final) #", "\n", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", ")", ":", "\n", "\n", "            ", "memory_bank", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "memory_bank", ")", "[", "0", "]", "# as after unpack it is a tuple", "\n", "\n", "", "hidden", "=", "memory_bank", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# size: (2,200,512)", "\n", "\n", "# print ('in func...', src_sents)", "\n", "\n", "# in each case for the current batch, send the last hidden output as the input to the sent_lstm layer", "\n", "batch_input_list", "=", "[", "]", "\n", "for", "output", ",", "sent_id", "in", "zip", "(", "hidden", ",", "src_sents", ")", ":", "# so we have batch_size to be 1", "\n", "\n", "            ", "common_len", "=", "len", "(", "sent_id", ")", "\n", "\n", "output", "=", "output", ".", "unsqueeze", "(", "1", ")", "\n", "sent_input_list", "=", "[", "]", "\n", "\n", "# firs id", "\n", "start_ind_sent_id", "=", "0", "\n", "start_ind", "=", "sent_id", "[", "start_ind_sent_id", "]", "\n", "\n", "\n", "while", "(", "start_ind", "<", "output", ".", "size", "(", ")", "[", "0", "]", ")", "and", "(", "start_ind_sent_id", "<", "sent_id", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "\n", "\n", "# add", "\n", "                ", "sent_input_list", ".", "append", "(", "output", "[", "start_ind", "]", ")", "\n", "\n", "# both ids move to the next", "\n", "start_ind_sent_id", "+=", "1", "\n", "if", "start_ind_sent_id", "<", "sent_id", ".", "size", "(", ")", "[", "0", "]", ":", "\n", "                    ", "start_ind", "+=", "sent_id", "[", "start_ind_sent_id", "]", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "\n", "\n", "# FEB 10, len check", "\n", "", "", "if", "len", "(", "sent_input_list", ")", "<", "common_len", ":", "\n", "# pad with zero", "\n", "                ", "pad_size", "=", "output", "[", "0", "]", ".", "size", "(", ")", "\n", "zeros", "=", "torch", ".", "zeros", "(", "pad_size", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "cuda", "(", ")", "\n", "pad_list", "=", "[", "zeros", "]", "*", "(", "common_len", "-", "len", "(", "sent_input_list", ")", ")", "\n", "\n", "sent_input_list", "=", "sent_input_list", "+", "pad_list", "\n", "\n", "\n", "", "sent_input", "=", "torch", ".", "cat", "(", "sent_input_list", ",", "0", ")", ".", "unsqueeze", "(", "1", ")", "# (n_sent, batch_size=1,dim=512)", "\n", "\n", "\n", "batch_input_list", ".", "append", "(", "sent_input", ")", "\n", "\n", "\n", "\n", "# print ([x.size() for x in batch_input_list])", "\n", "# [torch.Size([18, 1, 512]), torch.Size([15, 1, 512]), torch.Size([18, 1, 512]), torch.Size([18, 1, 512]), torch.Size([18, 1, 512])]", "\n", "\n", "\n", "", "batch_input_list_concat", "=", "torch", ".", "cat", "(", "batch_input_list", ",", "1", ")", "\n", "\n", "# get the id of sent length:", "\n", "sent_output", ",", "(", "h_", ",", "c_", ")", "=", "self", ".", "sent_rnn", "(", "batch_input_list_concat", ")", "\n", "# LSTM(512, 256, bidirectional=True), sent_output has the same shape with batch_input_list_concat", "\n", "\n", "\n", "#sent_output: shape(number of sents or step, batch_size, dim) (9, 2, 512), number of sents or step can be different", "\n", "# print ('Encoder Sentence_output...',sent_output.size())", "\n", "return", "sent_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder.sent_level_encoder": [[153, 174], ["isinstance", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "rnn_encoder.RNNEncoder.sent_rnn", "[].permute", "x[].unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence"], "methods", ["None"], ["", "def", "sent_level_encoder", "(", "self", ",", "memory_bank", ")", ":", "\n", "        ", "'''\n        This is the sentence level encoder, it takes a bunch of sentence encoding,\n        then feed into another sentence level rnn\n        :param memory_bank: sentence encoding ( a list of packed)\n        :return: output of the rnn layer\n        '''", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", ")", ":", "\n", "            ", "memory_bank_unpacked", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "memory_bank", ")", "[", "0", "]", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# as after unpack it is a tuple", "\n", "# memory_bank_unpacked size: torch.Size([42, 9, 512]) # [seq_len,batch_size,512]", "\n", "\n", "\n", "# take the last hiddent state of each", "\n", "", "last_hidden", "=", "[", "x", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "for", "x", "in", "memory_bank_unpacked", "]", "\n", "last_hidden", "=", "torch", ".", "cat", "(", "last_hidden", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "# size is [1,9,512]", "\n", "\n", "sent_output", ",", "(", "h_", ",", "c_", ")", "=", "self", ".", "sent_rnn", "(", "last_hidden", ")", "\n", "\n", "\n", "return", "sent_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder.forward_new": [[175, 299], ["rnn_encoder.RNNEncoder._check_args", "rnn_encoder.RNNEncoder.embeddings", "rnn_encoder.RNNEncoder.size", "rnn_encoder.RNNEncoder.permute", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tuple", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_encoder.RNNEncoder.rnn", "rnn_encoder.RNNEncoder.sent_level_encoder", "torch.nn.utils.rnn.pad_sequence.append", "torch.nn.utils.rnn.pad_sequence.append", "torch.nn.utils.rnn.pad_sequence.append", "memory_bank.permute", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "tuple.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "lengths_as_a_batch.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "rnn_encoder.RNNEncoder.view", "memory_bank_unpadded_list.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.pad", "torch.pad", "torch.pad", "torch.pad.unsqueeze", "rnn_encoder.RNNEncoder._bridge", "tuple", "current_sequence[].unsqueeze", "feeding_as_a_batch.append", "range", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "current_sequence[].unsqueeze.permute", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "x[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder.sent_level_encoder", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder._bridge"], ["", "def", "forward_new", "(", "self", ",", "src", ",", "src_sents", "=", "None", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"New Forward`\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "\n", "s_len", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "# (185 16 128), s_len is sequence_len.", "\n", "\n", "# 2333 TODO: change starts here", "\n", "\n", "\n", "# Feb15: we break this into sentences", "\n", "\n", "# iterate each batch..", "\n", "input_embeddings", "=", "emb", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "final_memory_bank", "=", "[", "]", "\n", "final_encoder_final", "=", "[", "]", "\n", "\n", "final_sent_output", "=", "[", "]", "\n", "\n", "for", "batch_id", "in", "range", "(", "batch", ")", ":", "\n", "\n", "# this is the input to word-level lstm", "\n", "            ", "current_sequence", "=", "input_embeddings", "[", "batch_id", "]", "# size id (sequence_len, emb_dim)", "\n", "# break this into multiple sentences according to the sentence lengths, and input to the rnn", "\n", "# sent len check, define len_sequence to be: tensor([26, 17, 21, 23, 19, 26, 10, 42], device='cuda:0')", "\n", "if", "torch", ".", "sum", "(", "src_sents", "[", "batch_id", "]", ")", ">=", "s_len", ":", "\n", "# if exceeds the total length, then their is a bug", "\n", "                ", "len_sequence", "=", "src_sents", "[", "batch_id", "]", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "len_sequence", "=", "src_sents", "[", "batch_id", "]", "\n", "\n", "", "counter", "=", "0", "\n", "\n", "\n", "feeding_as_a_batch", "=", "[", "]", "\n", "lengths_as_a_batch", "=", "[", "]", "\n", "lengths", "=", "[", "]", "\n", "actual_len", "=", "0", "\n", "for", "idx", "in", "len_sequence", ":", "\n", "                ", "if", "(", "counter", "<", "s_len", ")", "and", "(", "idx", "!=", "0", ")", ":", "\n", "                    ", "actual_len", "+=", "1", "\n", "# from the current_sequence, add to the rnn", "\n", "feeding_sequence", "=", "current_sequence", "[", "counter", ":", "counter", "+", "idx", "]", ".", "unsqueeze", "(", "0", ")", "\n", "feeding_as_a_batch", ".", "append", "(", "feeding_sequence", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ")", "#feeding_sequence size = [1,26,128]", "\n", "counter", "+=", "idx", "\n", "# feed into rnn", "\n", "", "lengths_as_a_batch", ".", "append", "(", "idx", ")", "\n", "\n", "", "feeding_as_a_batch_padded", "=", "torch", ".", "cat", "(", "[", "x", "for", "x", "in", "pad_sequence", "(", "feeding_as_a_batch", ",", "batch_first", "=", "True", ")", "]", ",", "1", ")", "\n", "# feed into rnn size: torch.Size([42, 9, 128]) -> [max, batch_size, dim]", "\n", "max_dim", "=", "feeding_as_a_batch_padded", ".", "size", "(", ")", "[", "0", "]", "\n", "lengths_as_a_batch", "=", "[", "max_dim", "for", "x", "in", "range", "(", "actual_len", ")", "]", "\n", "# lengths_as_a_batch = [item for sublist in lengths_as_a_batch for item in sublist]", "\n", "\n", "if", "lengths_as_a_batch", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Tensor.", "\n", "                ", "packed_emb_rnn_input", "=", "pack", "(", "feeding_as_a_batch_padded", ",", "lengths_as_a_batch", ")", "\n", "\n", "\n", "# feed into!", "\n", "", "memory_bank", ",", "encoder_final", "=", "self", ".", "rnn", "(", "packed_emb_rnn_input", ")", "\n", "\n", "# feed into sentence_level", "\n", "sent_output", "=", "self", ".", "sent_level_encoder", "(", "memory_bank", ")", "\n", "final_sent_output", ".", "append", "(", "sent_output", ".", "view", "(", "-", "1", ",", "4", "*", "emb_dim", ")", ")", "\n", "\n", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "                ", "memory_bank", "=", "unpack", "(", "memory_bank", ")", "[", "0", "]", "\n", "\n", "\n", "# we need to get the original output, before padded", "\n", "", "revised_memory_bank", "=", "memory_bank", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "memory_bank_unpadded_list", "=", "[", "]", "\n", "\n", "\n", "\n", "for", "idx", "in", "range", "(", "actual_len", ")", ":", "\n", "                ", "memory_bank_unpadded_list", ".", "append", "(", "revised_memory_bank", "[", "idx", "]", "[", ":", "len_sequence", "[", "idx", "]", "]", ")", "\n", "", "unpadded_memory_bank", "=", "torch", ".", "cat", "(", "memory_bank_unpadded_list", ",", "0", ")", "# size is [sequence_len,512] # need to pad or truncate", "\n", "actual_size", "=", "unpadded_memory_bank", ".", "size", "(", ")", "[", "0", "]", "\n", "if", "actual_size", ">=", "s_len", ":", "\n", "                ", "padded_memory_bank", "=", "unpadded_memory_bank", "[", ":", "s_len", "]", "\n", "# print ('Size is okk..', padded_memory_bank.size())", "\n", "", "else", ":", "\n", "# pad with zero", "\n", "                ", "pad_size", "=", "s_len", "-", "actual_size", "\n", "padded_memory_bank", "=", "F", ".", "pad", "(", "unpadded_memory_bank", ",", "(", "0", ",", "0", ",", "0", ",", "pad_size", ")", ",", "'constant'", ",", "0.0", ")", "\n", "# print ('Padded...',unpadded_memory_bank.size(),pad_size,padded_memory_bank.size())", "\n", "# print (actual_size,s_len,padded_memory_bank.size())", "\n", "", "final_memory_bank", ".", "append", "(", "padded_memory_bank", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# finish processing on memory bank", "\n", "\n", "\n", "if", "self", ".", "use_bridge", ":", "\n", "                ", "encoder_final", "=", "self", ".", "_bridge", "(", "encoder_final", ")", "\n", "\n", "", "final_encoder_final", ".", "append", "(", "tuple", "(", "[", "x", "[", ":", ",", "-", "1", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "for", "x", "in", "encoder_final", "]", ")", ")", "\n", "\n", "# add unpacked from final_memory_bank", "\n", "", "final_memory_bank", "=", "torch", ".", "cat", "(", "final_memory_bank", ",", "1", ")", "# [200, 2, 512], ready to return", "\n", "\n", "\n", "# join the encoder_final", "\n", "hs", "=", "[", "]", "\n", "cs", "=", "[", "]", "\n", "for", "(", "h", ",", "c", ")", "in", "final_encoder_final", ":", "\n", "            ", "hs", ".", "append", "(", "h", ")", "\n", "cs", ".", "append", "(", "c", ")", "\n", "", "hs", "=", "torch", ".", "cat", "(", "hs", ",", "1", ")", "\n", "cs", "=", "torch", ".", "cat", "(", "cs", ",", "1", ")", "\n", "# encoder_final", "\n", "final_encoder_final", "=", "tuple", "(", "[", "hs", ",", "cs", "]", ")", "# ready to return", "\n", "\n", "# sent output", "\n", "final_sent_output", "=", "pad_sequence", "(", "final_sent_output", ")", "# size [9,2,512], ready to return", "\n", "\n", "# 2333 TODO: change finish here", "\n", "\n", "# import pdb;pdb.set_trace()", "\n", "\n", "return", "final_encoder_final", ",", "final_memory_bank", ",", "final_sent_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder.forward": [[53, 74], ["rnn_encoder.RNNEncoder._check_args", "rnn_encoder.RNNEncoder.embeddings", "rnn_encoder.RNNEncoder.rnn", "lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "rnn_encoder.RNNEncoder._bridge", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder._bridge"], ["bidirectional", "=", "bidirectional", ")", "\n", "# self.rnn is a LSTM(128, 256, bidirectional=True)  # input dim; output dim;", "\n", "\n", "\n", "# init another sentence-level layer: this is shared by all the sentences, why 4?", "\n", "self", ".", "sent_rnn", "=", "nn", ".", "LSTM", "(", "4", "*", "embeddings", ".", "embedding_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "True", ")", "\n", "# (512,256)", "\n", "# import pdb;pdb.set_trace()", "\n", "\n", "\n", "# Initialize the bridge layer", "\n", "self", ".", "use_bridge", "=", "use_bridge", "\n", "if", "self", ".", "use_bridge", ":", "\n", "            ", "self", ".", "_initialize_bridge", "(", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", "\n", "\n", "\n", "", "", "def", "build_sentence_layer", "(", "self", ",", "memory_bank", ",", "src_sents", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder._initialize_bridge": [[75, 89], ["torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "range"], "methods", ["None"], ["\n", "# print('Memory..', memory_bank.size()) # torch.Size([200, 2, 512]) TODO: this is the output", "\n", "# #", "\n", "# print ('encoder_final..',encoder_final) #", "\n", "\n", "\n", "if", "isinstance", "(", "memory_bank", ",", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", ")", ":", "\n", "\n", "            ", "memory_bank", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "memory_bank", ")", "[", "0", "]", "# as after unpack it is a tuple", "\n", "\n", "", "hidden", "=", "memory_bank", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# size: (2,200,512)", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder.RNNEncoder._bridge": [[90, 108], ["isinstance", "states.size", "linear", "torch.relu().view", "torch.relu().view", "tuple", "rnn_encoder.RNNEncoder._bridge.bottle_hidden"], "methods", ["None"], ["# print ('in func...', src_sents)", "\n", "\n", "# in each case for the current batch, send the last hidden output as the input to the sent_lstm layer", "\n", "batch_input_list", "=", "[", "]", "\n", "for", "output", ",", "sent_id", "in", "zip", "(", "hidden", ",", "src_sents", ")", ":", "# so we have batch_size to be 1", "\n", "\n", "            ", "common_len", "=", "len", "(", "sent_id", ")", "\n", "\n", "output", "=", "output", ".", "unsqueeze", "(", "1", ")", "\n", "sent_input_list", "=", "[", "]", "\n", "\n", "# firs id", "\n", "start_ind_sent_id", "=", "0", "\n", "start_ind", "=", "sent_id", "[", "start_ind_sent_id", "]", "\n", "\n", "\n", "while", "(", "start_ind", "<", "output", ".", "size", "(", ")", "[", "0", "]", ")", "and", "(", "start_ind_sent_id", "<", "sent_id", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.audio_encoder.AudioEncoder.__init__": [[22, 44], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "int", "int", "int", "torch.LSTM", "torch.LSTM", "math.floor", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "bidirectional", ",", "rnn_size", ",", "dropout", ",", "\n", "sample_rate", ",", "window_size", ")", ":", "\n", "        ", "super", "(", "AudioEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "kernel_size", "=", "(", "41", ",", "11", ")", ",", "\n", "padding", "=", "(", "0", ",", "10", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "(", "21", ",", "11", ")", ",", "\n", "padding", "=", "(", "0", ",", "0", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "(", "sample_rate", "*", "window_size", ")", "/", "2", ")", "+", "1", ")", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "input_size", "-", "41", ")", "/", "2", "+", "1", ")", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "input_size", "-", "21", ")", "/", "2", "+", "1", ")", "\n", "input_size", "*=", "32", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "input_size", ",", "rnn_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.audio_encoder.AudioEncoder.load_pretrained_vectors": [[45, 48], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\" Pass in needed options only when modify function definition.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.audio_encoder.AudioEncoder.forward": [[49, 73], ["audio_encoder.AudioEncoder.batch_norm1", "torch.hardtanh", "torch.hardtanh", "audio_encoder.AudioEncoder.batch_norm2", "torch.hardtanh", "torch.hardtanh", "src.transpose().transpose.transpose().transpose.size", "src.transpose().transpose.transpose().transpose.size", "src.transpose().transpose.transpose().transpose.view", "src.transpose().transpose.transpose().transpose.transpose().transpose", "audio_encoder.AudioEncoder.rnn", "audio_encoder.AudioEncoder.layer1", "audio_encoder.AudioEncoder.layer2", "src.transpose().transpose.transpose().transpose.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`onmt.encoders.encoder.EncoderBase.forward()`\"", "\n", "# (batch_size, 1, nfft, t)", "\n", "# layer 1", "\n", "src", "=", "self", ".", "batch_norm1", "(", "self", ".", "layer1", "(", "src", "[", ":", ",", ":", ",", ":", ",", ":", "]", ")", ")", "\n", "\n", "# (batch_size, 32, nfft/2, t/2)", "\n", "src", "=", "F", ".", "hardtanh", "(", "src", ",", "0", ",", "20", ",", "inplace", "=", "True", ")", "\n", "\n", "# (batch_size, 32, nfft/2/2, t/2)", "\n", "# layer 2", "\n", "src", "=", "self", ".", "batch_norm2", "(", "self", ".", "layer2", "(", "src", ")", ")", "\n", "\n", "# (batch_size, 32, nfft/2/2, t/2)", "\n", "src", "=", "F", ".", "hardtanh", "(", "src", ",", "0", ",", "20", ",", "inplace", "=", "True", ")", "\n", "\n", "batch_size", "=", "src", ".", "size", "(", "0", ")", "\n", "length", "=", "src", ".", "size", "(", "3", ")", "\n", "src", "=", "src", ".", "view", "(", "batch_size", ",", "-", "1", ",", "length", ")", "\n", "src", "=", "src", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "src", ")", "\n", "\n", "return", "hidden", ",", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoder.__init__": [[24, 57], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "range", "cnn_decoder.CNNDecoder.conv_layers.append", "cnn_decoder.CNNDecoder.attn_layers.append", "onmt.modules.GlobalAttention", "onmt.utils.cnn_factory.GatedConv", "onmt.modules.ConvMultiStepAttention"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "attn_type", ",", "\n", "copy_attn", ",", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'cnn'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "cnn_kernel_width", "=", "cnn_kernel_width", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "# Build the CNN.", "\n", "input_size", "=", "self", ".", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "conv_layers", ".", "append", "(", "\n", "GatedConv", "(", "self", ".", "hidden_size", ",", "self", ".", "cnn_kernel_width", ",", "\n", "self", ".", "dropout", ",", "True", ")", ")", "\n", "\n", "", "self", ".", "attn_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "attn_layers", ".", "append", "(", "\n", "onmt", ".", "modules", ".", "ConvMultiStepAttention", "(", "self", ".", "hidden_size", ")", ")", "\n", "\n", "# CNNDecoder has its own attention mechanism.", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoder.forward": [[58, 123], ["isinstance", "torch.cat.size", "torch.cat.size", "memory_bank.size", "onmt.utils.misc.aeq", "cnn_decoder.CNNDecoder.embeddings", "cnn_decoder.CNNDecoder.transpose().contiguous", "memory_bank.transpose().contiguous", "state.init_src.transpose().contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous().view", "cnn_decoder.CNNDecoder.linear", "cnn_decoder.CNNDecoder.view", "onmt.utils.cnn_factory.shape_transform", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "pad.type_as.type_as.type_as", "zip", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose().contiguous", "state.update_state", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cnn_decoder.CNNDecoder.dim", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.size", "onmt.utils.cnn_factory.shape_transform.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv", "attention", "attn[].squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "cnn_decoder.CNNDecoder.transpose", "memory_bank.transpose", "state.init_src.transpose", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose", "state.previous_input.size", "state.previous_input.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.cnn_factory.shape_transform", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.update_state", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.RNNDecoderBase.forward()`\"\"\"", "\n", "# NOTE: memory_lengths is only here for compatibility reasons", "\n", "#       with onmt.modules.RNNDecoderBase.forward()", "\n", "# CHECKS", "\n", "assert", "isinstance", "(", "state", ",", "CNNDecoderState", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "_", ",", "contxt_batch", ",", "_", "=", "memory_bank", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "contxt_batch", ")", "\n", "# END CHECKS", "\n", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "tgt", "=", "torch", ".", "cat", "(", "[", "state", ".", "previous_input", ",", "tgt", "]", ",", "0", ")", "\n", "\n", "# Initialize return variables.", "\n", "", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "assert", "not", "self", ".", "_copy", ",", "\"Copy mechanism not yet tested in conv2conv\"", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "tgt_emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The output of CNNEncoder.", "\n", "src_memory_bank_t", "=", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The combination of output of CNNEncoder and source embeddings.", "\n", "src_memory_bank_c", "=", "state", ".", "init_src", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Run the forward pass of the CNNDecoder.", "\n", "emb_reshape", "=", "tgt_emb", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_emb", ".", "size", "(", "0", ")", "*", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "linear_out", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "x", "=", "linear_out", ".", "view", "(", "tgt_emb", ".", "size", "(", "0", ")", ",", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "x", "=", "shape_transform", "(", "x", ")", "\n", "\n", "pad", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "\n", "self", ".", "cnn_kernel_width", "-", "1", ",", "1", ")", "\n", "\n", "pad", "=", "pad", ".", "type_as", "(", "x", ")", "\n", "base_target_emb", "=", "x", "\n", "\n", "for", "conv", ",", "attention", "in", "zip", "(", "self", ".", "conv_layers", ",", "self", ".", "attn_layers", ")", ":", "\n", "            ", "new_target_input", "=", "torch", ".", "cat", "(", "[", "pad", ",", "x", "]", ",", "2", ")", "\n", "out", "=", "conv", "(", "new_target_input", ")", "\n", "c", ",", "attn", "=", "attention", "(", "base_target_emb", ",", "out", ",", "\n", "src_memory_bank_t", ",", "src_memory_bank_c", ")", "\n", "x", "=", "(", "x", "+", "(", "c", "+", "out", ")", "*", "SCALE_WEIGHT", ")", "*", "SCALE_WEIGHT", "\n", "", "output", "=", "x", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "outputs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "outputs", "[", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", ".", "squeeze", "(", ")", "\n", "attn", "=", "torch", ".", "stack", "(", "[", "attn", "]", ")", "\n", "", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "# Update the state.", "\n", "", "state", ".", "update_state", "(", "tgt", ")", "\n", "\n", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoder.init_decoder_state": [[124, 129], ["cnn_decoder.CNNDecoderState"], "methods", ["None"], ["", "def", "init_decoder_state", "(", "self", ",", "_", ",", "memory_bank", ",", "enc_hidden", ",", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Init decoder state.\n        \"\"\"", "\n", "return", "CNNDecoderState", "(", "memory_bank", ",", "enc_hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoderState.__init__": [[136, 139], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "self", ".", "init_src", "=", "(", "memory_bank", "+", "enc_hidden", ")", "*", "SCALE_WEIGHT", "\n", "self", ".", "previous_input", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoderState._all": [[140, 146], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "return", "(", "self", ".", "previous_input", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoderState.detach": [[147, 149], ["cnn_decoder.CNNDecoderState.previous_input.detach"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach"], ["", "def", "detach", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_input", "=", "self", ".", "previous_input", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoderState.update_state": [[150, 153], ["None"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_input", ")", ":", "\n", "        ", "\"\"\" Called for every decoder forward pass. \"\"\"", "\n", "self", ".", "previous_input", "=", "new_input", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.cnn_decoder.CNNDecoderState.repeat_beam_size_times": [[154, 157], ["cnn_decoder.CNNDecoderState.init_src.data.repeat"], "methods", ["None"], ["", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "init_src", "=", "self", ".", "init_src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.mean_encoder.MeanEncoder.__init__": [[15, 19], ["onmt.encoders.encoder.EncoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "MeanEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.mean_encoder.MeanEncoder.forward": [[20, 30], ["mean_encoder.MeanEncoder._check_args", "mean_encoder.MeanEncoder.embeddings", "mean_encoder.MeanEncoder.size", "mean_encoder.MeanEncoder.mean().expand", "mean_encoder.MeanEncoder.mean"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase._check_args"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "_", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "mean", "=", "emb", ".", "mean", "(", "0", ")", ".", "expand", "(", "self", ".", "num_layers", ",", "batch", ",", "emb_dim", ")", "\n", "memory_bank", "=", "emb", "\n", "encoder_final", "=", "(", "mean", ",", "mean", ")", "\n", "return", "encoder_final", ",", "memory_bank", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderBase.__init__": [[60, 111], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "decoder.RNNDecoderBase._build_rnn", "onmt.modules.GlobalAttention", "decoder.RNNDecoderBase._init_mmr", "onmt.modules.context_gate_factory", "onmt.modules.GlobalAttention"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._build_rnn", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._init_mmr", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.modules.gate.context_gate_factory"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", "=", "\"general\"", ",", "attn_func", "=", "\"softmax\"", ",", "\n", "coverage_attn", "=", "False", ",", "context_gate", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "reuse_copy_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNDecoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'rnn'", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Build the RNN.", "\n", "self", ".", "rnn", "=", "self", ".", "_build_rnn", "(", "rnn_type", ",", "\n", "input_size", "=", "self", ".", "_input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "# Set up the context gate.", "\n", "self", ".", "context_gate", "=", "None", "\n", "if", "context_gate", "is", "not", "None", ":", "\n", "            ", "self", ".", "context_gate", "=", "onmt", ".", "modules", ".", "context_gate_factory", "(", "\n", "context_gate", ",", "self", ".", "_input_size", ",", "\n", "hidden_size", ",", "hidden_size", ",", "hidden_size", "\n", ")", "\n", "\n", "# Set up the standard attention.", "\n", "", "self", ".", "_coverage", "=", "coverage_attn", "\n", "# 2333 TODO: the following is init only, we are using this one", "\n", "self", ".", "attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "coverage", "=", "coverage_attn", ",", "\n", "attn_type", "=", "attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "self", ".", "_copy", "=", "False", "\n", "\n", "if", "copy_attn", "and", "not", "reuse_copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ",", "attn_func", "=", "attn_func", "\n", ")", "\n", "", "if", "copy_attn", ":", "\n", "            ", "self", ".", "_copy", "=", "True", "\n", "", "self", ".", "_reuse_copy_attn", "=", "reuse_copy_attn", "\n", "\n", "# init mmr param", "\n", "self", ".", "_init_mmr", "(", "hidden_size", ")", "\n", "# print('Initialized the parameters,',hidden_size)", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderBase.forward": [[115, 171], ["isinstance", "tgt.size", "memory_bank.size", "onmt.utils.misc.aeq", "decoder.RNNDecoderBase._run_forward_pass", "state.update_state", "[].unsqueeze", "final_output.unsqueeze", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._run_forward_pass", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.update_state"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "step", "=", "None", ",", "sent_encoder", "=", "None", ",", "src_sents", "=", "None", ",", "dec", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tgt (`LongTensor`): sequences of padded tokens\n                 `[tgt_len x batch x nfeats]`.\n            memory_bank (`FloatTensor`): vectors from the encoder\n                 `[src_len x batch x hidden]`.\n            state (:obj:`onmt.models.DecoderState`):\n                 decoder state object to initialize the decoder\n            memory_lengths (`LongTensor`): the padded source lengths\n                `[batch]`.\n        Returns:\n            (`FloatTensor`,:obj:`onmt.Models.DecoderState`,`FloatTensor`):\n                * decoder_outputs: output from the decoder (after attn)\n                         `[tgt_len x batch x hidden]`.\n                * decoder_state: final hidden state from the decoder\n                * attns: distribution over src at each tgt\n                        `[tgt_len x batch x src_len]`.\n        \"\"\"", "\n", "# Check", "\n", "assert", "isinstance", "(", "state", ",", "RNNDecoderState", ")", "\n", "# tgt.size() returns tgt length and batch", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "_", ",", "memory_batch", ",", "_", "=", "memory_bank", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "memory_batch", ")", "\n", "# END", "\n", "\n", "\n", "# 23333: TODO I changed this return value 'sent_decoder'", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "decoder_final", ",", "decoder_outputs", ",", "attns", "=", "self", ".", "_run_forward_pass", "(", "\n", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "memory_lengths", ",", "sent_encoder", "=", "sent_encoder", ",", "src_sents", "=", "src_sents", ",", "dec", "=", "dec", ")", "\n", "\n", "# Update the state with the result.", "\n", "final_output", "=", "decoder_outputs", "[", "-", "1", "]", "\n", "coverage", "=", "None", "\n", "if", "\"coverage\"", "in", "attns", ":", "\n", "            ", "coverage", "=", "attns", "[", "\"coverage\"", "]", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "state", ".", "update_state", "(", "decoder_final", ",", "final_output", ".", "unsqueeze", "(", "0", ")", ",", "coverage", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "# NOTE: v0.3 to 0.4: decoder_outputs / attns[*] may not be list", "\n", "#       (in particular in case of SRU) it was not raising error in 0.3", "\n", "#       since stack(Variable) was allowed.", "\n", "#       In 0.4, SRU returns a tensor that shouldn't be stacke", "\n", "\n", "\n", "if", "type", "(", "decoder_outputs", ")", "==", "list", ":", "\n", "            ", "decoder_outputs", "=", "torch", ".", "stack", "(", "decoder_outputs", ")", "\n", "\n", "for", "k", "in", "attns", ":", "\n", "                ", "if", "type", "(", "attns", "[", "k", "]", ")", "==", "list", ":", "\n", "\n", "                    ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderBase.init_decoder_state": [[172, 190], ["isinstance", "decoder.RNNDecoderState", "decoder.RNNDecoderState", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tuple", "decoder.RNNDecoderBase.init_decoder_state._fix_enc_hidden"], "methods", ["None"], ["", "", "", "return", "decoder_outputs", ",", "state", ",", "attns", "\n", "\n", "", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "encoder_final", ",", "\n", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\" Init decoder state with last state of the encoder \"\"\"", "\n", "def", "_fix_enc_hidden", "(", "hidden", ")", ":", "\n", "# The encoder hidden is  (layers*directions) x batch x dim.", "\n", "# We need to convert it to layers x batch x (directions*dim).", "\n", "            ", "if", "self", ".", "bidirectional_encoder", ":", "\n", "                ", "hidden", "=", "torch", ".", "cat", "(", "[", "hidden", "[", "0", ":", "hidden", ".", "size", "(", "0", ")", ":", "2", "]", ",", "\n", "hidden", "[", "1", ":", "hidden", ".", "size", "(", "0", ")", ":", "2", "]", "]", ",", "2", ")", "\n", "", "return", "hidden", "\n", "\n", "", "if", "isinstance", "(", "encoder_final", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "return", "RNNDecoderState", "(", "self", ".", "hidden_size", ",", "\n", "tuple", "(", "[", "_fix_enc_hidden", "(", "enc_hid", ")", "\n", "for", "enc_hid", "in", "encoder_final", "]", ")", ")", "\n", "", "else", ":", "# GRU", "\n", "            ", "return", "RNNDecoderState", "(", "self", ".", "hidden_size", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.StdRNNDecoder._run_forward_pass": [[208, 271], ["decoder.StdRNNDecoder.embeddings", "isinstance", "tgt.size", "rnn_output.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "decoder.StdRNNDecoder.attn", "decoder.StdRNNDecoder.dropout", "decoder.StdRNNDecoder.rnn", "decoder.StdRNNDecoder.rnn", "rnn_output.transpose().contiguous", "memory_bank.transpose", "decoder.StdRNNDecoder.context_gate", "decoder_outputs.view.view.view", "decoder.StdRNNDecoder.view", "rnn_output.view", "decoder_outputs.view.view.view", "rnn_output.transpose", "decoder.StdRNNDecoder.size", "rnn_output.size", "decoder_outputs.view.view.size"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq"], ["\n", "\n", "def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "dec", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n        Args:\n            tgt (LongTensor): a sequence of input tokens tensors\n                                 [len x batch x nfeats].\n            memory_bank (FloatTensor): output(tensor sequence) from the encoder\n                        RNN of size (src_len x batch x hidden_size).\n            state (FloatTensor): hidden state from the encoder RNN for\n                                 initializing the decoder.\n            memory_lengths (LongTensor): the source memory_bank lengths.\n        Returns:\n            decoder_final (Tensor): final hidden state from the decoder.\n            decoder_outputs ([FloatTensor]): an array of output of every time\n                                     step from the decoder.\n            attns (dict of (str, [FloatTensor]): a dictionary of different\n                            type of attention Tensor array of every time\n                            step from the decoder.\n        \"\"\"", "\n", "assert", "not", "self", ".", "_copy", "# TODO, no support yet.", "\n", "assert", "not", "self", ".", "_coverage", "# TODO, no support yet.", "\n", "\n", "# Initialize local and return variables.", "\n", "attns", "=", "{", "}", "\n", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "if", "isinstance", "(", "self", ".", "rnn", ",", "nn", ".", "GRU", ")", ":", "\n", "            ", "rnn_output", ",", "decoder_final", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "rnn_output", ",", "decoder_final", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", ")", "\n", "\n", "# Check", "\n", "", "tgt_len", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "output_len", ",", "output_batch", ",", "_", "=", "rnn_output", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_len", ",", "output_len", ")", "\n", "aeq", "(", "tgt_batch", ",", "output_batch", ")", "\n", "# END", "\n", "\n", "# Calculate the attention.", "\n", "decoder_outputs", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "p_attn", "\n", "\n", "# Calculate the context gate.", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "            ", "decoder_outputs", "=", "self", ".", "context_gate", "(", "\n", "emb", ".", "view", "(", "-", "1", ",", "emb", ".", "size", "(", "2", ")", ")", ",", "\n", "rnn_output", ".", "view", "(", "-", "1", ",", "rnn_output", ".", "size", "(", "2", ")", ")", ",", "\n", "decoder_outputs", ".", "view", "(", "-", "1", ",", "decoder_outputs", ".", "size", "(", "2", ")", ")", "\n", ")", "\n", "decoder_outputs", "=", "decoder_outputs", ".", "view", "(", "tgt_len", ",", "tgt_batch", ",", "self", ".", "hidden_size", ")", "\n", "\n", "", "decoder_outputs", "=", "self", ".", "dropout", "(", "decoder_outputs", ")", "\n", "\n", "\n", "return", "decoder_final", ",", "decoder_outputs", ",", "attns", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.StdRNNDecoder._build_rnn": [[272, 275], ["onmt.utils.rnn_factory.rnn_factory"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.rnn_factory.rnn_factory"], ["\n", "", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "rnn", ",", "_", "=", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", "\n", "return", "rnn", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.StdRNNDecoder._input_size": [[276, 282], ["None"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Private helper returning the number of expected features.\n        \"\"\"", "\n", "return", "self", ".", "embeddings", ".", "embedding_size", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._init_mmr": [[314, 321], ["torch.Linear().cuda", "torch.Linear().cuda", "torch.Linear().cuda", "torch.Linear().cuda", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["\n", "", "def", "_run_mmr", "(", "self", ",", "sent_encoder", ",", "sent_decoder", ",", "src_sents", ",", "input_step", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._run_mmr_attention": [[324, 383], ["torch.PairwiseDistance", "torch.PairwiseDistance", "sent_decoder.permute.permute.permute", "torch.t", "torch.t", "torch.t", "torch.t", "torch.softmax().permute", "torch.softmax().permute", "torch.softmax().permute", "torch.softmax().permute", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "scores.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat.append", "torch.cat.append", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax().permute.size", "torch.softmax().permute.size", "range", "len", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.zeros().float().cuda.append", "torch.zeros().float().cuda.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "decoder.InputFeedRNNDecoder.mmr_W", "sent.unsqueeze", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.PairwiseDistance.", "sent_encoder.permute", "sent.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["\n", "pdist", "=", "nn", ".", "PairwiseDistance", "(", "p", "=", "2", ")", "\n", "sent_decoder", "=", "sent_decoder", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# (2,1,512)", "\n", "\n", "scores", "=", "[", "]", "\n", "# define sent matrix and current vector distance as the Euclidean distance", "\n", "for", "sent", "in", "sent_encoder", ":", "# iterate over each batch sample", "\n", "# distance: https://pytorch.org/docs/stable/_modules/torch/nn/modules/distance.html", "\n", "\n", "# import pdb;", "\n", "# pdb.set_trace()", "\n", "\n", "# sim1=torch.sum(pdist(sent_encoder.permute(1,0,2),sent.unsqueeze(1)),1).unsqueeze(1)  # -> this is sim2 on my equation, note this is distance!", "\n", "\n", "            ", "sim1", "=", "1", "-", "torch", ".", "mean", "(", "pdist", "(", "sent_encoder", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ",", "sent", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", "# this is a similarity function", "\n", "# sim1 shape: (batch_size,1)", "\n", "\n", "sim2", "=", "torch", ".", "bmm", "(", "self", ".", "mmr_W", "(", "sent_decoder", ")", ",", "sent", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "# (2,1) -> this is sim1 on my equation", "\n", "\n", "# scores.append(sim1-sim2)", "\n", "scores", ".", "append", "(", "sim2", "-", "sim1", ")", "\n", "\n", "\n", "", "sent_ranking_att", "=", "torch", ".", "t", "(", "torch", ".", "cat", "(", "scores", ",", "1", ")", ")", "#(sent_len=9,batch_size)", "\n", "sent_ranking_att", "=", "torch", ".", "softmax", "(", "sent_ranking_att", ",", "dim", "=", "0", ")", ".", "permute", "(", "1", ",", "0", ")", "#(sent_len=9,batch_size)", "\n", "# scores is a list of score (sent_len=9, tensor shape (batch_size, 1))", "\n", "mmr_among_words", "=", "[", "]", "# should be (batch=2,input_step=200)", "\n", "for", "batch_id", "in", "range", "(", "sent_ranking_att", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "# iterate each batch, create zero weight on the input steps", "\n", "# mmr= torch.zeros([input_step], dtype=torch.float32).cuda()", "\n", "\n", "            ", "tmp", "=", "[", "]", "\n", "for", "id", ",", "position", "in", "enumerate", "(", "src_sents", "[", "batch_id", "]", ")", ":", "\n", "\n", "                ", "for", "x", "in", "range", "(", "position", ")", ":", "\n", "                    ", "tmp", ".", "append", "(", "sent_ranking_att", "[", "batch_id", "]", "[", "id", "]", ")", "\n", "\n", "\n", "", "", "mmr", "=", "torch", ".", "stack", "(", "tmp", ")", "# make to 1-d", "\n", "\n", "\n", "if", "len", "(", "mmr", ")", "<", "input_step", ":", "# pad with 0", "\n", "                ", "tmp", "=", "torch", ".", "zeros", "(", "input_step", "-", "len", "(", "mmr", ")", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "# for x in range(input_step-len(mmr)):", "\n", "mmr", "=", "torch", ".", "cat", "(", "(", "mmr", ",", "tmp", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "mmr", "=", "mmr", "[", ":", "input_step", "]", "\n", "\n", "", "mmr_among_words", ".", "append", "(", "mmr", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "mmr_among_words", "=", "torch", ".", "cat", "(", "mmr_among_words", ",", "0", ")", "\n", "\n", "# shape: (batch=2, input_step=200)", "\n", "\n", "return", "mmr_among_words", "\n", "\n", "", "def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "sent_encoder", "=", "None", ",", "src_sents", "=", "None", ",", "dec", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._run_forward_pass": [[385, 491], ["state.input_feed.squeeze", "state.input_feed.squeeze.size", "tgt.size", "onmt.utils.misc.aeq", "decoder.InputFeedRNNDecoder.embeddings", "enumerate", "decoder_outputs[].unsqueeze", "print", "decoder.InputFeedRNNDecoder._run_mmr_attention", "decoder.InputFeedRNNDecoder.dim", "state.coverage.squeeze", "decoder.InputFeedRNNDecoder.split", "emb_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.InputFeedRNNDecoder.rnn", "decoder.InputFeedRNNDecoder.attn", "decoder.InputFeedRNNDecoder.dropout", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "attns[].append", "memory_bank.transpose", "decoder.InputFeedRNNDecoder.context_gate", "decoder.InputFeedRNNDecoder.copy_attn", "[].size", "torch.mul.cuda", "torch.mul.cuda", "memory_bank.transpose"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.aeq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._run_mmr_attention", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["\n", "\n", "# Additional args check.", "\n", "input_feed", "=", "state", ".", "input_feed", ".", "squeeze", "(", "0", ")", "\n", "#print(\"input feed size: {}\\n\".format(input_feed.size()))", "\n", "input_feed_batch", ",", "_", "=", "input_feed", ".", "size", "(", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "input_feed_batch", ")", "\n", "# END Additional args check.", "\n", "\n", "# Initialize local and return variables.", "\n", "decoder_outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "_coverage", ":", "\n", "            ", "attns", "[", "\"coverage\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "hidden", "=", "state", ".", "hidden", "\n", "coverage", "=", "state", ".", "coverage", ".", "squeeze", "(", "0", ")", "if", "state", ".", "coverage", "is", "not", "None", "else", "None", "\n", "\n", "# Input feed concatenates hidden state with", "\n", "# input at every time step.", "\n", "\n", "#print(\"emb size: {}\\n\".format(emb.size()));exit()", "\n", "for", "_", ",", "emb_t", "in", "enumerate", "(", "emb", ".", "split", "(", "1", ")", ")", ":", "\n", "# for each output time step in the loop", "\n", "\n", "            ", "emb_t", "=", "emb_t", ".", "squeeze", "(", "0", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "[", "emb_t", ",", "input_feed", "]", ",", "1", ")", "\n", "\n", "# TODO: the following is where we get attention!", "\n", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "decoder_input", ",", "hidden", ")", "\n", "decoder_output", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", ")", "\n", "# p_attn: size (batch=2,input_step=200)", "\n", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "# TODO: context gate should be employed (not me)", "\n", "# instead of second RNN transform.", "\n", "                ", "decoder_output", "=", "self", ".", "context_gate", "(", "\n", "decoder_input", ",", "rnn_output", ",", "decoder_output", "\n", ")", "\n", "", "decoder_output", "=", "self", ".", "dropout", "(", "decoder_output", ")", "\n", "input_feed", "=", "decoder_output", "\n", "\n", "decoder_outputs", "+=", "[", "decoder_output", "]", "\n", "attns", "[", "\"std\"", "]", "+=", "[", "p_attn", "]", "\n", "\n", "\n", "# Update the coverage attention.", "\n", "if", "self", ".", "_coverage", ":", "\n", "                ", "coverage", "=", "coverage", "+", "p_attn", "if", "coverage", "is", "not", "None", "else", "p_attn", "\n", "attns", "[", "\"coverage\"", "]", "+=", "[", "coverage", "]", "\n", "\n", "# Run the forward pass of the copy attention layer.", "\n", "#", "\n", "\n", "", "if", "self", ".", "_copy", "and", "not", "self", ".", "_reuse_copy_attn", ":", "\n", "\n", "                ", "_", ",", "copy_attn", "=", "self", ".", "copy_attn", "(", "decoder_output", ",", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "attns", "[", "\"copy\"", "]", "+=", "[", "copy_attn", "]", "\n", "", "elif", "self", ".", "_copy", ":", "\n", "                ", "attns", "[", "\"copy\"", "]", "=", "attns", "[", "\"std\"", "]", "# attns[\"copy\"] is a list of tensor for each output step=51, each size: [batch_size=2, input_step=200]", "\n", "\n", "\n", "", "", "if", "not", "dec", ":", "#if this is not dec?", "\n", "            ", "attns", "[", "\"mmr\"", "]", "=", "[", "]", "\n", "# 2333: TODO : the sentence representation for decoder", "\n", "sent_decoder", "=", "decoder_outputs", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "# shape: (1, batch_size=2,dim=512)", "\n", "\n", "# Return result.", "\n", "# 2333: TODO: attns['std'] is a list of tensors, length is output_step, each tensor shape is (batch=2,input_step=200)", "\n", "\n", "# 2333: TODO: compute mmr attention here:", "\n", "\n", "mmr_among_words", "=", "self", ".", "_run_mmr", "(", "sent_encoder", ",", "sent_decoder", ",", "src_sents", ",", "attns", "[", "\"std\"", "]", "[", "0", "]", ".", "size", "(", ")", "[", "-", "1", "]", ")", "\n", "\n", "#  2333: TODO: bring mmr to attention...", "\n", "\n", "for", "output_step", "in", "attns", "[", "\"std\"", "]", ":", "\n", "                ", "attention_weight", "=", "output_step", "\n", "# pairwise multiplication", "\n", "attention_weight", "=", "torch", ".", "mul", "(", "mmr_among_words", ",", "attention_weight", ")", "\n", "attns", "[", "\"mmr\"", "]", ".", "append", "(", "attention_weight", ".", "cuda", "(", ")", ")", "\n", "# pdb.set_trace()", "\n", "\n", "", "attns", "[", "\"std\"", "]", "=", "attns", "[", "\"mmr\"", "]", "\n", "\n", "# decoder_outputs is a list of tensors for each output step=51, each tensor: (batch_size=2,dim=512)", "\n", "", "return", "hidden", ",", "decoder_outputs", ",", "attns", "\n", "\n", "", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ")", ":", "\n", "        ", "assert", "not", "rnn_type", "==", "\"SRU\"", ",", "\"SRU doesn't support input feed! \"", "\"Please set -input_feed 0!\"", "\n", "if", "rnn_type", "==", "\"LSTM\"", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._build_rnn": [[492, 502], ["stacked_cell"], "methods", ["None"], ["            ", "stacked_cell", "=", "onmt", ".", "models", ".", "stacked_rnn", ".", "StackedLSTM", "\n", "", "else", ":", "\n", "            ", "stacked_cell", "=", "onmt", ".", "models", ".", "stacked_rnn", ".", "StackedGRU", "\n", "", "return", "stacked_cell", "(", "num_layers", ",", "input_size", ",", "\n", "hidden_size", ",", "dropout", ")", "\n", "\n", "", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Using input feed by concatenating input with attention vectors.\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.InputFeedRNNDecoder._input_size": [[503, 509], ["None"], "methods", ["None"], ["return", "self", ".", "embeddings", ".", "embedding_size", "+", "self", ".", "hidden_size", "\n", "\n", "\n", "", "", "class", "DecoderState", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach": [[519, 523], ["tuple", "decoder.DecoderState.input_feed.detach", "_.detach"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.detach"], ["", "def", "beam_update", "(", "self", ",", "idx", ",", "positions", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Need to document this \"\"\"", "\n", "for", "e", "in", "self", ".", "_all", ":", "\n", "            ", "sizes", "=", "e", ".", "size", "(", ")", "\n", "br", "=", "sizes", "[", "1", "]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.beam_update": [[524, 540], ["e.size", "sent_states.data.copy_", "len", "sent_states.data.index_select", "e.view", "e.view"], "methods", ["None"], ["if", "len", "(", "sizes", ")", "==", "3", ":", "\n", "                ", "sent_states", "=", "e", ".", "view", "(", "sizes", "[", "0", "]", ",", "beam_size", ",", "br", "//", "beam_size", ",", "\n", "sizes", "[", "2", "]", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "", "else", ":", "\n", "                ", "sent_states", "=", "e", ".", "view", "(", "sizes", "[", "0", "]", ",", "beam_size", ",", "\n", "br", "//", "beam_size", ",", "\n", "sizes", "[", "2", "]", ",", "\n", "sizes", "[", "3", "]", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "\n", "", "sent_states", ".", "data", ".", "copy_", "(", "\n", "sent_states", ".", "data", ".", "index_select", "(", "1", ",", "positions", ")", ")", "\n", "\n", "", "", "def", "map_batch_fn", "(", "self", ",", "fn", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "\n", "", "", "class", "RNNDecoderState", "(", "DecoderState", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.DecoderState.map_batch_fn": [[541, 543], ["NotImplementedError"], "methods", ["None"], ["    ", "\"\"\" Base class for RNN decoder state \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "hidden_size", ",", "rnnstate", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.__init__": [[548, 566], ["decoder.RNNDecoderState.hidden[].size", "decoder.RNNDecoderState.hidden[].data.new().zero_().unsqueeze", "isinstance", "decoder.RNNDecoderState.hidden[].data.new().zero_", "decoder.RNNDecoderState.hidden[].data.new"], "methods", ["None"], ["\n", "if", "not", "isinstance", "(", "rnnstate", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "hidden", "=", "(", "rnnstate", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hidden", "=", "rnnstate", "\n", "", "self", ".", "coverage", "=", "None", "\n", "\n", "# Init the input feed.", "\n", "batch_size", "=", "self", ".", "hidden", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "h_size", "=", "(", "batch_size", ",", "hidden_size", ")", "\n", "self", ".", "input_feed", "=", "self", ".", "hidden", "[", "0", "]", ".", "data", ".", "new", "(", "*", "h_size", ")", ".", "zero_", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "hidden", "+", "(", "self", ".", "input_feed", ",", ")", "\n", "\n", "", "def", "update_state", "(", "self", ",", "rnnstate", ",", "input_feed", ",", "coverage", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState._all": [[567, 570], ["None"], "methods", ["None"], ["        ", "\"\"\" Update decoder state \"\"\"", "\n", "if", "not", "isinstance", "(", "rnnstate", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "hidden", "=", "(", "rnnstate", ",", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.update_state": [[571, 579], ["isinstance"], "methods", ["None"], ["            ", "self", ".", "hidden", "=", "rnnstate", "\n", "", "self", ".", "input_feed", "=", "input_feed", "\n", "self", ".", "coverage", "=", "coverage", "\n", "\n", "", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "vars", "=", "[", "e", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", "\n", "for", "e", "in", "self", ".", "_all", "]", "\n", "self", ".", "hidden", "=", "tuple", "(", "vars", "[", ":", "-", "1", "]", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.repeat_beam_size_times": [[580, 586], ["tuple", "e.data.repeat"], "methods", ["None"], ["self", ".", "input_feed", "=", "vars", "[", "-", "1", "]", "\n", "\n", "", "def", "map_batch_fn", "(", "self", ",", "fn", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "tuple", "(", "map", "(", "lambda", "x", ":", "fn", "(", "x", ",", "1", ")", ",", "self", ".", "hidden", ")", ")", "\n", "self", ".", "input_feed", "=", "fn", "(", "self", ".", "input_feed", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.decoder.RNNDecoderState.map_batch_fn": [[587, 590], ["tuple", "fn", "map", "fn"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder.__init__": [[27, 52], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "rnn_encoder_hi.RNNEncoder._initialize_bridge"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder._initialize_bridge"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "use_bridge", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "self", ".", "rnn", ",", "self", ".", "no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "# this is 1.", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "# Initialize the bridge layer", "\n", "self", ".", "use_bridge", "=", "use_bridge", "\n", "if", "self", ".", "use_bridge", ":", "\n", "            ", "self", ".", "_initialize_bridge", "(", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder.forward": [[53, 83], ["rnn_encoder_hi.RNNEncoder._check_args", "rnn_encoder_hi.RNNEncoder.embeddings", "rnn_encoder_hi.RNNEncoder.size", "rnn_encoder_hi.RNNEncoder.rnn", "print", "lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "rnn_encoder_hi.RNNEncoder._bridge", "memory_bank.size", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder._bridge"], ["", "", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "\n", "s_len", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "# (185 16 128), s_len is changeable.", "\n", "\n", "packed_emb", "=", "emb", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Tensor.", "\n", "            ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "packed_emb", "=", "pack", "(", "emb", ",", "lengths", ")", "\n", "\n", "", "memory_bank", ",", "encoder_final", "=", "self", ".", "rnn", "(", "packed_emb", ")", "# output, (hidden, cell), unpack using pad_packed_sequence()", "\n", "# memory_bank is the output", "\n", "# self.rnn is a LSTM(128, 256, bidirectional=True) # input dim; output dim;", "\n", "\n", "# print('Hidden..', encoder_final[0].size(), encoder_final[1].size()) # both torch.Size([2, 16, 256]), 2 directions.", "\n", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "            ", "memory_bank", "=", "unpack", "(", "memory_bank", ")", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "use_bridge", ":", "\n", "            ", "encoder_final", "=", "self", ".", "_bridge", "(", "encoder_final", ")", "\n", "\n", "", "print", "(", "'Out..'", ",", "memory_bank", ".", "size", "(", ")", ")", "\n", "#Out.. torch.Size([16, 512]) torch.Size([16, 512]) : two dir?", "\n", "\n", "return", "encoder_final", ",", "memory_bank", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder._initialize_bridge": [[84, 98], ["torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "range"], "methods", ["None"], ["", "def", "_initialize_bridge", "(", "self", ",", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", ":", "\n", "\n", "# LSTM has hidden and cell state, other only one", "\n", "        ", "number_of_states", "=", "2", "if", "rnn_type", "==", "\"LSTM\"", "else", "1", "\n", "# Total number of states", "\n", "self", ".", "total_hidden_dim", "=", "hidden_size", "*", "num_layers", "\n", "\n", "# Build a linear layer for each", "\n", "self", ".", "bridge", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "total_hidden_dim", ",", "\n", "self", ".", "total_hidden_dim", ",", "\n", "bias", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "number_of_states", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.rnn_encoder_hi.RNNEncoder._bridge": [[99, 117], ["isinstance", "states.size", "linear", "torch.relu().view", "torch.relu().view", "tuple", "rnn_encoder_hi.RNNEncoder._bridge.bottle_hidden"], "methods", ["None"], ["", "def", "_bridge", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"\n        Forward hidden state through bridge\n        \"\"\"", "\n", "def", "bottle_hidden", "(", "linear", ",", "states", ")", ":", "\n", "            ", "\"\"\"\n            Transform from 3D to 2D, apply linear and return initial size\n            \"\"\"", "\n", "size", "=", "states", ".", "size", "(", ")", "\n", "result", "=", "linear", "(", "states", ".", "view", "(", "-", "1", ",", "self", ".", "total_hidden_dim", ")", ")", "\n", "return", "F", ".", "relu", "(", "result", ")", ".", "view", "(", "size", ")", "\n", "\n", "", "if", "isinstance", "(", "hidden", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "outs", "=", "tuple", "(", "[", "bottle_hidden", "(", "layer", ",", "hidden", "[", "ix", "]", ")", "\n", "for", "ix", ",", "layer", "in", "enumerate", "(", "self", ".", "bridge", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "outs", "=", "bottle_hidden", "(", "self", ".", "bridge", "[", "0", "]", ",", "hidden", ")", "\n", "", "return", "outs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.image_encoder.ImageEncoder.__init__": [[19, 49], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Embedding", "torch.Embedding", "torch.Embedding", "int"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "bidirectional", ",", "rnn_size", ",", "dropout", ",", "\n", "image_chanel_size", "=", "3", ")", ":", "\n", "        ", "super", "(", "ImageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "image_chanel_size", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer4", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer5", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer6", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "batch_norm3", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "src_size", "=", "512", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "src_size", ",", "int", "(", "rnn_size", "/", "self", ".", "num_directions", ")", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "self", ".", "pos_lut", "=", "nn", ".", "Embedding", "(", "1000", ",", "src_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.image_encoder.ImageEncoder.load_pretrained_vectors": [[50, 53], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\" Pass in needed options only when modify function definition.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.image_encoder.ImageEncoder.forward": [[54, 110], ["torch.relu.size", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_encoder.ImageEncoder.layer1", "image_encoder.ImageEncoder.layer2", "image_encoder.ImageEncoder.batch_norm1", "image_encoder.ImageEncoder.layer4", "image_encoder.ImageEncoder.batch_norm2", "image_encoder.ImageEncoder.batch_norm3", "torch.relu.size", "src[].transpose().transpose", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "image_encoder.ImageEncoder.pos_lut", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_encoder.ImageEncoder.rnn", "all_outputs.append", "image_encoder.ImageEncoder.layer3", "image_encoder.ImageEncoder.layer5", "image_encoder.ImageEncoder.layer6", "src[].transpose", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "image_encoder.ImageEncoder.view", "image_encoder.ImageEncoder.size", "image_encoder.ImageEncoder.size", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`onmt.encoders.encoder.EncoderBase.forward()`\"", "\n", "\n", "batch_size", "=", "src", ".", "size", "(", "0", ")", "\n", "# (batch_size, 64, imgH, imgW)", "\n", "# layer 1", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer1", "(", "src", "[", ":", ",", ":", ",", ":", ",", ":", "]", "-", "0.5", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 64, imgH/2, imgW/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 128, imgH/2, imgW/2)", "\n", "# layer 2", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer2", "(", "src", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 128, imgH/2/2, imgW/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "#  (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer 3", "\n", "# batch norm 1", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm1", "(", "self", ".", "layer3", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer4", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer4", "(", "src", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2/2, imgW/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "1", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2)", "\n", "# layer 5", "\n", "# batch norm 2", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm2", "(", "self", ".", "layer5", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm3", "(", "self", ".", "layer6", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# # (batch_size, 512, H, W)", "\n", "all_outputs", "=", "[", "]", "\n", "for", "row", "in", "range", "(", "src", ".", "size", "(", "2", ")", ")", ":", "\n", "            ", "inp", "=", "src", "[", ":", ",", ":", ",", "row", ",", ":", "]", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "row_vec", "=", "torch", ".", "Tensor", "(", "batch_size", ")", ".", "type_as", "(", "inp", ".", "data", ")", ".", "long", "(", ")", ".", "fill_", "(", "row", ")", "\n", "pos_emb", "=", "self", ".", "pos_lut", "(", "row_vec", ")", "\n", "with_pos", "=", "torch", ".", "cat", "(", "\n", "(", "pos_emb", ".", "view", "(", "1", ",", "pos_emb", ".", "size", "(", "0", ")", ",", "pos_emb", ".", "size", "(", "1", ")", ")", ",", "inp", ")", ",", "0", ")", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "with_pos", ")", "\n", "all_outputs", ".", "append", "(", "outputs", ")", "\n", "", "out", "=", "torch", ".", "cat", "(", "all_outputs", ",", "0", ")", "\n", "\n", "return", "hidden_t", ",", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.transformer.TransformerEncoderLayer.__init__": [[26, 34], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.position_ffn.PositionwiseFeedForward", "onmt.modules.LayerNorm", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["\n", "\n", "def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ")", ":", "\n", "        ", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn_type", "=", "self_attn_type", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.transformer.TransformerEncoderLayer.forward": [[35, 53], ["transformer.TransformerEncoderLayer.layer_norm", "transformer.TransformerEncoderLayer.self_attn", "transformer.TransformerEncoderLayer.feed_forward", "transformer.TransformerEncoderLayer.dropout"], "methods", ["None"], ["            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "AverageAttention", "(", "\n", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "\n", "", "self", ".", "context_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "layer_norm_2", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "mask", "=", "self", ".", "_get_attn_subsequent_mask", "(", "MAX_SIZE", ")", "\n", "# Register self.mask as a buffer in TransformerDecoderLayer, so", "\n", "# it gets TransformerDecoderLayer's cuda behavior automatically.", "\n", "self", ".", "register_buffer", "(", "'mask'", ",", "mask", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.transformer.TransformerEncoder.__init__": [[87, 97], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.ModuleList", "onmt.modules.LayerNorm", "transformer.TransformerEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "output", "=", "self", ".", "feed_forward", "(", "self", ".", "drop", "(", "mid", ")", "+", "query", ")", "\n", "\n", "return", "output", ",", "attn", ",", "all_input", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.transformer.TransformerEncoder.forward": [[98, 116], ["transformer.TransformerEncoder._check_args", "transformer.TransformerEncoder.embeddings", "transformer.TransformerEncoder.transpose().contiguous", "src[].transpose", "src[].transpose.size", "src[].transpose.data.eq().unsqueeze().expand", "range", "transformer.TransformerEncoder.layer_norm", "transformer.TransformerEncoder.transpose().contiguous", "transformer.TransformerEncoder.transpose", "src[].transpose.data.eq().unsqueeze", "transformer.TransformerEncoder.transpose", "src[].transpose.data.eq"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.encoder.EncoderBase._check_args"], ["\n", "", "def", "_get_attn_subsequent_mask", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n        Get an attention mask to avoid using the subsequent info.\n\n        Args:\n            size: int\n\n        Returns:\n            (`LongTensor`):\n\n            * subsequent_mask `[1 x size x size]`\n        \"\"\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "subsequent_mask", "=", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "\n", "return", "subsequent_mask", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.__init__": [[20, 22], ["tuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_decoder_states", ")", ":", "\n", "        ", "self", ".", "model_decoder_states", "=", "tuple", "(", "model_decoder_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.beam_update": [[23, 26], ["model_state.beam_update"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.beam_update"], ["", "def", "beam_update", "(", "self", ",", "idx", ",", "positions", ",", "beam_size", ")", ":", "\n", "        ", "for", "model_state", "in", "self", ".", "model_decoder_states", ":", "\n", "            ", "model_state", ".", "beam_update", "(", "idx", ",", "positions", ",", "beam_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.repeat_beam_size_times": [[27, 31], ["model_state.repeat_beam_size_times"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.repeat_beam_size_times"], ["", "", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "for", "model_state", "in", "self", ".", "model_decoder_states", ":", "\n", "            ", "model_state", ".", "repeat_beam_size_times", "(", "beam_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderState.__getitem__": [[32, 34], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "model_decoder_states", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.__init__": [[38, 40], ["tuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_outputs", ")", ":", "\n", "        ", "self", ".", "model_outputs", "=", "tuple", "(", "model_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze": [[41, 48], ["ensemble.EnsembleDecoderOutput", "x.squeeze"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.squeeze"], ["", "def", "squeeze", "(", "self", ",", "dim", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Delegate squeeze to avoid modifying\n        :obj:`Translator.translate_batch()`\n        \"\"\"", "\n", "return", "EnsembleDecoderOutput", "(", "[", "\n", "x", ".", "squeeze", "(", "dim", ")", "for", "x", "in", "self", ".", "model_outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoderOutput.__getitem__": [[49, 51], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "model_outputs", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleEncoder.__init__": [[55, 58], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.ModuleList", "torch.ModuleList", "list"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "model_encoders", ")", ":", "\n", "        ", "super", "(", "EnsembleEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_encoders", "=", "nn", ".", "ModuleList", "(", "list", "(", "model_encoders", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleEncoder.forward": [[59, 64], ["zip", "model_encoder.forward"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "enc_hidden", ",", "memory_bank", "=", "zip", "(", "*", "[", "\n", "model_encoder", ".", "forward", "(", "src", ",", "lengths", ")", "\n", "for", "model_encoder", "in", "self", ".", "model_encoders", "]", ")", "\n", "return", "enc_hidden", ",", "memory_bank", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.__init__": [[68, 71], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "list"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "model_decoders", ")", ":", "\n", "        ", "super", "(", "EnsembleDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_decoders", "=", "nn", ".", "ModuleList", "(", "list", "(", "model_decoders", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.forward": [[72, 88], ["zip", "ensemble.EnsembleDecoder.combine_attns", "ensemble.EnsembleDecoderOutput", "ensemble.EnsembleDecoderState", "model_decoder.forward", "enumerate"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.combine_attns", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`RNNDecoderBase.forward()` \"\"\"", "\n", "# Memory_lengths is a single tensor shared between all models.", "\n", "# This assumption will not hold if Translator is modified", "\n", "# to calculate memory_lengths as something other than the length", "\n", "# of the input.", "\n", "outputs", ",", "states", ",", "attns", "=", "zip", "(", "*", "[", "\n", "model_decoder", ".", "forward", "(", "\n", "tgt", ",", "memory_bank", "[", "i", "]", ",", "state", "[", "i", "]", ",", "memory_lengths", ",", "step", "=", "step", ")", "\n", "for", "(", "i", ",", "model_decoder", ")", "\n", "in", "enumerate", "(", "self", ".", "model_decoders", ")", "]", ")", "\n", "mean_attns", "=", "self", ".", "combine_attns", "(", "attns", ")", "\n", "return", "(", "EnsembleDecoderOutput", "(", "outputs", ")", ",", "\n", "EnsembleDecoderState", "(", "states", ")", ",", "\n", "mean_attns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.combine_attns": [[89, 94], ["attns[].keys", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "combine_attns", "(", "self", ",", "attns", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "for", "key", "in", "attns", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "result", "[", "key", "]", "=", "torch", ".", "stack", "(", "[", "attn", "[", "key", "]", "for", "attn", "in", "attns", "]", ")", ".", "mean", "(", "0", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.init_decoder_state": [[95, 102], ["ensemble.EnsembleDecoderState", "model_decoder.init_decoder_state", "enumerate"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleDecoder.init_decoder_state"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "\"\"\" See :obj:`RNNDecoderBase.init_decoder_state()` \"\"\"", "\n", "return", "EnsembleDecoderState", "(", "\n", "[", "model_decoder", ".", "init_decoder_state", "(", "src", ",", "\n", "memory_bank", "[", "i", "]", ",", "\n", "enc_hidden", "[", "i", "]", ")", "\n", "for", "(", "i", ",", "model_decoder", ")", "in", "enumerate", "(", "self", ".", "model_decoders", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.__init__": [[109, 112], ["tuple", "torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "model_generators", ")", ":", "\n", "        ", "self", ".", "model_generators", "=", "tuple", "(", "model_generators", ")", "\n", "super", "(", "EnsembleGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward": [[113, 123], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "model_generator.forward", "enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleGenerator.forward"], ["", "def", "forward", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        by averaging distributions from models in the ensemble.\n        All models in the ensemble must share a target vocabulary.\n        \"\"\"", "\n", "distributions", "=", "[", "model_generator", ".", "forward", "(", "hidden", "[", "i", "]", ")", "\n", "for", "(", "i", ",", "model_generator", ")", "\n", "in", "enumerate", "(", "self", ".", "model_generators", ")", "]", "\n", "return", "torch", ".", "stack", "(", "distributions", ")", ".", "mean", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.EnsembleModel.__init__": [[127, 133], ["ensemble.EnsembleEncoder", "ensemble.EnsembleDecoder", "onmt.models.NMTModel.__init__", "ensemble.EnsembleGenerator", "torch.ModuleList", "torch.ModuleList"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__"], ["def", "__init__", "(", "self", ",", "models", ")", ":", "\n", "        ", "encoder", "=", "EnsembleEncoder", "(", "model", ".", "encoder", "for", "model", "in", "models", ")", "\n", "decoder", "=", "EnsembleDecoder", "(", "model", ".", "decoder", "for", "model", "in", "models", ")", "\n", "super", "(", "EnsembleModel", ",", "self", ")", ".", "__init__", "(", "encoder", ",", "decoder", ")", "\n", "self", ".", "generator", "=", "EnsembleGenerator", "(", "model", ".", "generator", "for", "model", "in", "models", ")", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model": [[135, 158], ["ensemble.EnsembleModel", "onmt.model_builder.load_test_model", "pdb.set_trace", "models.append", "fields.items"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.encoders.ensemble.load_test_model"], ["", "", "def", "load_test_model", "(", "opt", ",", "dummy_opt", ")", ":", "\n", "    ", "\"\"\" Read in multiple models for ensemble \"\"\"", "\n", "shared_fields", "=", "None", "\n", "shared_model_opt", "=", "None", "\n", "models", "=", "[", "]", "\n", "for", "model_path", "in", "opt", ".", "models", ":", "\n", "        ", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "model_builder", ".", "load_test_model", "(", "opt", ",", "\n", "dummy_opt", ",", "\n", "model_path", "=", "model_path", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "if", "shared_fields", "is", "None", ":", "\n", "            ", "shared_fields", "=", "fields", "\n", "", "else", ":", "\n", "            ", "for", "key", ",", "field", "in", "fields", ".", "items", "(", ")", ":", "\n", "                ", "if", "field", "is", "not", "None", "and", "'vocab'", "in", "field", ".", "__dict__", ":", "\n", "                    ", "assert", "field", ".", "vocab", ".", "stoi", "==", "shared_fields", "[", "key", "]", ".", "vocab", ".", "stoi", ",", "'Ensemble models must use the same preprocessed data'", "\n", "", "", "", "models", ".", "append", "(", "model", ")", "\n", "if", "shared_model_opt", "is", "None", ":", "\n", "            ", "shared_model_opt", "=", "model_opt", "\n", "", "", "ensemble_model", "=", "EnsembleModel", "(", "models", ")", "\n", "return", "shared_fields", ",", "ensemble_model", ",", "shared_model_opt", "\n", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.translate.main": [[18, 25], ["onmt.translate.translator.build_translator", "onmt.translate.translator.build_translator.translate"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.build_translator", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translator.Translator.translate"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "translator", "=", "build_translator", "(", "opt", ",", "report_score", "=", "True", ")", "\n", "translator", ".", "translate", "(", "src_path", "=", "opt", ".", "src", ",", "\n", "tgt_path", "=", "opt", ".", "tgt", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "attn_debug", "=", "opt", ".", "attn_debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.ErrorHandler.__init__": [[76, 86], ["threading.Thread", "train.ErrorHandler.error_thread.start", "signal.signal"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start"], ["\n", "\n", "", "", "class", "ErrorHandler", "(", "object", ")", ":", "\n", "    ", "\"\"\"A class that listens for exceptions in children processes and propagates\n    the tracebacks to the parent process.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "        ", "\"\"\" init error handler \"\"\"", "\n", "import", "signal", "\n", "import", "threading", "\n", "self", ".", "error_queue", "=", "error_queue", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.ErrorHandler.add_child": [[87, 90], ["train.ErrorHandler.children_pids.append"], "methods", ["None"], ["self", ".", "children_pids", "=", "[", "]", "\n", "self", ".", "error_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "error_listener", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_thread", ".", "start", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.ErrorHandler.error_listener": [[91, 96], ["train.ErrorHandler.error_queue.get", "train.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n", "", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\" error handler \"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.ErrorHandler.signal_handler": [[97, 106], ["train.ErrorHandler.error_queue.get", "Exception", "os.kill"], "methods", ["None"], ["", "def", "error_listener", "(", "self", ")", ":", "\n", "        ", "\"\"\" error listener \"\"\"", "\n", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "self", ".", "error_queue", ".", "put", "(", "(", "rank", ",", "original_trace", ")", ")", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n", "", "def", "signal_handler", "(", "self", ",", "signalnum", ",", "stackframe", ")", ":", "\n", "        ", "\"\"\" signal handler \"\"\"", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "# kill children processes", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.main": [[18, 54], ["len", "AssertionError", "AssertionError", "AssertionError", "len", "AssertionError", "torch.multiprocessing.get_context", "torch.multiprocessing.get_context.SimpleQueue", "train.ErrorHandler", "range", "procs.append", "procs[].start", "onmt.utils.logging.logger.info", "train.ErrorHandler.add_child", "p.join", "onmt.train_single.main", "onmt.train_single.main", "torch.multiprocessing.get_context.Process"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.ErrorHandler.add_child", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.main", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.main"], ["import", "onmt", ".", "utils", ".", "distributed", "\n", "\n", "from", "onmt", ".", "utils", ".", "logging", "import", "logger", "\n", "from", "onmt", ".", "train_single", "import", "main", "as", "single_main", "\n", "\n", "\n", "def", "main", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "rnn_type", "==", "\"SRU\"", "and", "not", "opt", ".", "gpu_ranks", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Using SRU requires -gpu_ranks set.\"", ")", "\n", "\n", "", "if", "opt", ".", "epochs", ":", "\n", "        ", "raise", "AssertionError", "(", "\"-epochs is deprecated please use -train_steps.\"", ")", "\n", "\n", "", "if", "opt", ".", "truncated_decoder", ">", "0", "and", "opt", ".", "accum_count", ">", "1", ":", "\n", "        ", "raise", "AssertionError", "(", "\"BPTT is not compatible with -accum > 1\"", ")", "\n", "\n", "", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "raise", "AssertionError", "(", "\"gpuid is deprecated \\\n              see world_size and gpu_ranks\"", ")", "\n", "\n", "", "nb_gpu", "=", "len", "(", "opt", ".", "gpu_ranks", ")", "\n", "\n", "if", "opt", ".", "world_size", ">", "1", ":", "\n", "        ", "mp", "=", "torch", ".", "multiprocessing", ".", "get_context", "(", "'spawn'", ")", "\n", "# Create a thread to listen for errors in the child processes.", "\n", "error_queue", "=", "mp", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "# Train with multiprocessing.", "\n", "procs", "=", "[", "]", "\n", "for", "device_id", "in", "range", "(", "nb_gpu", ")", ":", "\n", "            ", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "run", ",", "args", "=", "(", "\n", "opt", ",", "device_id", ",", "error_queue", ",", ")", ",", "daemon", "=", "True", ")", ")", "\n", "procs", "[", "device_id", "]", ".", "start", "(", ")", "\n", "logger", ".", "info", "(", "\" Starting process pid: %d  \"", "%", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "error_handler", ".", "add_child", "(", "procs", "[", "device_id", "]", ".", "pid", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.train.run": [[56, 70], ["onmt.utils.distributed.multi_init", "onmt.utils.distributed.multi_init", "onmt.train_single.main", "AssertionError", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.multi_init", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.distributed.multi_init", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.main"], ["", "", "elif", "nb_gpu", "==", "1", ":", "# case 1 GPU only", "\n", "        ", "single_main", "(", "opt", ",", "0", ")", "\n", "", "else", ":", "# case only CPU", "\n", "        ", "single_main", "(", "opt", ",", "-", "1", ")", "\n", "\n", "\n", "", "", "def", "run", "(", "opt", ",", "device_id", ",", "error_queue", ")", ":", "\n", "    ", "\"\"\" run process \"\"\"", "\n", "try", ":", "\n", "        ", "gpu_rank", "=", "onmt", ".", "utils", ".", "distributed", ".", "multi_init", "(", "opt", ",", "device_id", ")", "\n", "if", "gpu_rank", "!=", "opt", ".", "gpu_ranks", "[", "device_id", "]", ":", "\n", "            ", "raise", "AssertionError", "(", "\"An error occurred in \\\n                  Distributed initialization\"", ")", "\n", "", "single_main", "(", "opt", ",", "device_id", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.check_existing_pt_files": [[20, 31], ["glob.glob", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Checking if there are existing .pt files to avoid tampering \"\"\"", "\n", "# We will use glob.glob() to find sharded {train|valid}.[0-9]*.pt", "\n", "# when training, so check to avoid tampering with existing pt files", "\n", "# or mixing them up.", "\n", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "pattern", "=", "opt", ".", "save_data", "+", "'.'", "+", "t", "+", "'*.pt'", "\n", "if", "glob", ".", "glob", "(", "pattern", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup existing pt file: %s, \"", "\n", "\"to avoid tampering!\\n\"", "%", "pattern", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args": [[33, 48], ["argparse.ArgumentParser", "onmt.add_md_help_argument", "onmt.preprocess_opts", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "preprocess.check_existing_pt_files"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.add_md_help_argument", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.preprocess_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.check_existing_pt_files"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\" Parsing arguments \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'preprocess.py'", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n", "opts", ".", "add_md_help_argument", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_in_shards": [[50, 121], ["os.path.getsize", "onmt.ShardedTextCorpusIterator", "onmt.ShardedTextCorpusIterator", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "inputters.ShardedTextCorpusIterator.hit_end", "onmt.TextDataset", "onmt.utils.logging.logger.info", "torch.save", "ret_list.append"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.text_dataset.ShardedTextCorpusIterator.hit_end"], ["", "def", "build_save_in_shards", "(", "src_corpus", ",", "tgt_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Divide the big corpus into shards, and build dataset separately.\n    This is currently only for data_type=='text'.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n\n    To tackle this, we only read in part of the corpus file of size\n    `max_shard_size`(actually it is multiples of 64 bytes that equals\n    or is slightly larger than this size), and process it into dataset,\n    then write it to disk along the way. By doing this, we only focus on\n    part of the corpus at any moment, thus effectively reducing memory use.\n    According to test, this method can reduce memory footprint by ~50%.\n\n    Note! As we process along the shards, previous shards might still\n    stay in memory, but since we are done with them, and no more\n    reference to them, if there is memory tight situation, the OS could\n    easily reclaim these memory.\n\n    If `max_shard_size` is 0 or is larger than the corpus size, it is\n    effectively preprocessed into one dataset, i.e. no sharding.\n\n    NOTE! `max_shard_size` is measuring the input corpus size, not the\n    output pt file size. So a shard pt file consists of examples of size\n    2 * `max_shard_size`(source + target).\n    \"\"\"", "\n", "\n", "corpus_size", "=", "os", ".", "path", ".", "getsize", "(", "src_corpus", ")", "\n", "if", "corpus_size", ">", "10", "*", "(", "1024", "**", "2", ")", "and", "opt", ".", "max_shard_size", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"Warning. The corpus %s is larger than 10M bytes, \"", "\n", "\"you can set '-max_shard_size' to process it by \"", "\n", "\"small shards to use less memory.\"", "%", "src_corpus", ")", "\n", "\n", "", "if", "opt", ".", "max_shard_size", "!=", "0", ":", "\n", "        ", "logger", ".", "info", "(", "' * divide corpus into shards and build dataset '", "\n", "'separately (shard_size = %d bytes).'", "\n", "%", "opt", ".", "max_shard_size", ")", "\n", "\n", "", "ret_list", "=", "[", "]", "\n", "src_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "src_corpus", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"src\"", ",", "opt", ".", "max_shard_size", ")", "\n", "tgt_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "tgt_corpus", ",", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "\"tgt\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "\n", "index", "=", "0", "\n", "while", "not", "src_iter", ".", "hit_end", "(", ")", ":", "\n", "        ", "index", "+=", "1", "\n", "dataset", "=", "inputters", ".", "TextDataset", "(", "\n", "fields", ",", "src_iter", ",", "tgt_iter", ",", "\n", "src_iter", ".", "num_feats", ",", "tgt_iter", ".", "num_feats", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ")", "\n", "\n", "# We save fields in vocab.pt separately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "logger", ".", "info", "(", "\" * saving %s data shard to %s.\"", "\n", "%", "(", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "", "return", "ret_list", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_in_shards_using_shards_size": [[123, 189], ["open().readlines", "open().readlines", "range", "sorted", "sorted", "enumerate", "int", "open().writelines", "open().writelines", "glob.glob", "glob.glob", "onmt.build_dataset", "onmt.utils.logging.logger.info", "torch.save", "ret_list.append", "gc.collect", "gc.collect", "open", "open", "src_corpus.split", "tgt_corpus.split", "len", "open", "open"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset"], ["\n", "", "def", "build_save_in_shards_using_shards_size", "(", "src_corpus", ",", "tgt_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Divide src_corpus and tgt_corpus into smaller multiples\n    src_copus and tgt corpus files, then build shards, each\n    shard will have opt.shard_size samples except last shard.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n    \"\"\"", "\n", "\n", "src_data", "=", "open", "(", "src_corpus", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "\n", "tgt_data", "=", "open", "(", "tgt_corpus", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "\n", "\n", "src_corpus", "=", "\"\"", ".", "join", "(", "src_corpus", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", "\n", "tgt_corpus", "=", "\"\"", ".", "join", "(", "tgt_corpus", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", "\n", "\n", "for", "x", "in", "range", "(", "int", "(", "len", "(", "src_data", ")", "/", "opt", ".", "shard_size", ")", ")", ":", "\n", "        ", "open", "(", "src_corpus", "+", "\".{0}.txt\"", ".", "format", "(", "x", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", ".", "writelines", "(", "\n", "src_data", "[", "x", "*", "opt", ".", "shard_size", ":", "(", "x", "+", "1", ")", "*", "opt", ".", "shard_size", "]", ")", "\n", "open", "(", "tgt_corpus", "+", "\".{0}.txt\"", ".", "format", "(", "x", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", ".", "writelines", "(", "\n", "tgt_data", "[", "x", "*", "opt", ".", "shard_size", ":", "(", "x", "+", "1", ")", "*", "opt", ".", "shard_size", "]", ")", "\n", "\n", "", "src_list", "=", "sorted", "(", "glob", ".", "glob", "(", "src_corpus", "+", "'.*.txt'", ")", ")", "\n", "tgt_list", "=", "sorted", "(", "glob", ".", "glob", "(", "tgt_corpus", "+", "'.*.txt'", ")", ")", "\n", "\n", "ret_list", "=", "[", "]", "\n", "\n", "for", "index", ",", "src", "in", "enumerate", "(", "src_list", ")", ":", "\n", "        ", "dataset", "=", "inputters", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "\n", "src_path", "=", "src", ",", "\n", "tgt_path", "=", "tgt_list", "[", "index", "]", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ",", "\n", "image_channel_size", "=", "opt", ".", "image_channel_size", "\n", ")", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "logger", ".", "info", "(", "\" * saving %sth %s data image shard to %s.\"", "\n", "%", "(", "index", ",", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "del", "dataset", ".", "examples", "\n", "gc", ".", "collect", "(", ")", "\n", "del", "dataset", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "", "return", "ret_list", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_dataset": [[191, 243], ["onmt.build_dataset", "onmt.utils.logging.logger.info", "torch.save", "preprocess.build_save_in_shards", "preprocess.build_save_in_shards_using_shards_size"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_in_shards", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_in_shards_using_shards_size"], ["\n", "", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the dataset \"\"\"", "\n", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "train_src", "\n", "tgt_corpus", "=", "opt", ".", "train_tgt", "\n", "", "else", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "valid_src", "\n", "tgt_corpus", "=", "opt", ".", "valid_tgt", "\n", "\n", "# Currently we only do preprocess sharding for corpus: data_type=='text'.", "\n", "", "if", "opt", ".", "data_type", "==", "'text'", ":", "\n", "        ", "return", "build_save_in_shards", "(", "\n", "src_corpus", ",", "tgt_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", "\n", "\n", "", "if", "(", "opt", ".", "shard_size", ">", "0", ")", ":", "\n", "        ", "return", "build_save_in_shards_using_shards_size", "(", "src_corpus", ",", "\n", "tgt_corpus", ",", "\n", "fields", ",", "\n", "corpus_type", ",", "\n", "opt", ")", "\n", "\n", "# For data_type == 'img' or 'audio', currently we don't do", "\n", "# preprocess sharding. We only build a monolithic dataset.", "\n", "# But since the interfaces are uniform, it would be not hard", "\n", "# to do this should users need this feature.", "\n", "", "dataset", "=", "inputters", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "\n", "src_path", "=", "src_corpus", ",", "\n", "tgt_path", "=", "tgt_corpus", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ",", "\n", "image_channel_size", "=", "opt", ".", "image_channel_size", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ")", "\n", "logger", ".", "info", "(", "\" * saving %s dataset to %s.\"", "%", "(", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "return", "[", "pt_file", "]", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_vocab": [[245, 259], ["onmt.build_vocab", "torch.save", "onmt.save_fields_to_vocab"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.save_fields_to_vocab"], ["\n", "", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the vocab \"\"\"", "\n", "fields", "=", "inputters", ".", "build_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "\n", "opt", ".", "share_vocab", ",", "\n", "opt", ".", "src_vocab", ",", "\n", "opt", ".", "src_vocab_size", ",", "\n", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab", ",", "\n", "opt", ".", "tgt_vocab_size", ",", "\n", "opt", ".", "tgt_words_min_frequency", ")", "\n", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "vocab_file", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "inputters", ".", "save_fields_to_vocab", "(", "fields", ")", ",", "vocab_file", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.main": [[261, 286], ["preprocess.parse_args", "onmt.utils.logging.init_logger", "onmt.utils.logging.logger.info", "onmt.get_num_features", "onmt.get_num_features", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.get_fields", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_vocab"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.logging.init_logger", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.build_save_vocab"], ["\n", "", "def", "main", "(", ")", ":", "\n", "#pdb.set_trace()", "\n", "    ", "opt", "=", "parse_args", "(", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "logger", ".", "info", "(", "\"Extracting features...\"", ")", "\n", "\n", "# If there are special features added -- not in our case", "\n", "src_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_src", ",", "'src'", ")", "\n", "tgt_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_tgt", ",", "'tgt'", ")", "\n", "logger", ".", "info", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "logger", ".", "info", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building `Fields` object...\"", ")", "\n", "fields", "=", "inputters", ".", "get_fields", "(", "opt", ".", "data_type", ",", "src_nfeats", ",", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving training data...\"", ")", "\n", "train_dataset_files", "=", "build_save_dataset", "(", "'train'", ",", "fields", ",", "opt", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving validation data...\"", ")", "\n", "valid_dataset_files", "=", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "opt", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving vocabulary...\"", ")", "\n", "build_save_vocab", "(", "train_dataset_files", "+", "valid_dataset_files", ",", "fields", ",", "opt", ")", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.server.start": [[11, 104], ["flask.Flask", "server.start.prefix_route"], "function", ["None"], ["def", "start", "(", "config_file", ",", "\n", "url_root", "=", "\"./translator\"", ",", "\n", "host", "=", "\"0.0.0.0\"", ",", "\n", "port", "=", "5000", ",", "\n", "debug", "=", "True", ")", ":", "\n", "    ", "def", "prefix_route", "(", "route_function", ",", "prefix", "=", "''", ",", "mask", "=", "'{0}{1}'", ")", ":", "\n", "        ", "def", "newroute", "(", "route", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "route_function", "(", "mask", ".", "format", "(", "prefix", ",", "route", ")", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "newroute", "\n", "\n", "", "app", "=", "Flask", "(", "__name__", ")", "\n", "app", ".", "route", "=", "prefix_route", "(", "app", ".", "route", ",", "url_root", ")", "\n", "translation_server", "=", "TranslationServer", "(", ")", "\n", "translation_server", ".", "start", "(", "config_file", ")", "\n", "\n", "@", "app", ".", "route", "(", "'/models'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "get_models", "(", ")", ":", "\n", "        ", "out", "=", "translation_server", ".", "list_models", "(", ")", "\n", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/clone_model/<int:model_id>'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "clone_model", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "}", "\n", "data", "=", "request", ".", "get_json", "(", "force", "=", "True", ")", "\n", "timeout", "=", "-", "1", "\n", "if", "'timeout'", "in", "data", ":", "\n", "            ", "timeout", "=", "data", "[", "'timeout'", "]", "\n", "del", "data", "[", "'timeout'", "]", "\n", "\n", "", "opt", "=", "data", ".", "get", "(", "'opt'", ",", "None", ")", "\n", "try", ":", "\n", "            ", "model_id", ",", "load_time", "=", "translation_server", ".", "clone_model", "(", "\n", "model_id", ",", "opt", ",", "timeout", ")", "\n", "", "except", "ServerModelError", "as", "e", ":", "\n", "            ", "out", "[", "'status'", "]", "=", "STATUS_ERROR", "\n", "out", "[", "'error'", "]", "=", "str", "(", "e", ")", "\n", "", "else", ":", "\n", "            ", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "out", "[", "'model_id'", "]", "=", "model_id", "\n", "out", "[", "'load_time'", "]", "=", "load_time", "\n", "\n", "", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/unload_model/<int:model_id>'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "unload_model", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "\"model_id\"", ":", "model_id", "}", "\n", "\n", "try", ":", "\n", "            ", "translation_server", ".", "unload_model", "(", "model_id", ")", "\n", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "out", "[", "'status'", "]", "=", "STATUS_ERROR", "\n", "out", "[", "'error'", "]", "=", "str", "(", "e", ")", "\n", "\n", "", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/translate'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "translate", "(", ")", ":", "\n", "        ", "inputs", "=", "request", ".", "get_json", "(", "force", "=", "True", ")", "\n", "out", "=", "{", "}", "\n", "try", ":", "\n", "            ", "translation", ",", "scores", ",", "n_best", ",", "times", "=", "translation_server", ".", "run", "(", "inputs", ")", "\n", "assert", "len", "(", "translation", ")", "==", "len", "(", "inputs", ")", "\n", "assert", "len", "(", "scores", ")", "==", "len", "(", "inputs", ")", "\n", "\n", "out", "=", "[", "[", "{", "\"src\"", ":", "inputs", "[", "i", "]", "[", "'src'", "]", ",", "\"tgt\"", ":", "translation", "[", "i", "]", ",", "\n", "\"n_best\"", ":", "n_best", ",", "\n", "\"pred_score\"", ":", "scores", "[", "i", "]", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "translation", ")", ")", "]", "]", "\n", "", "except", "ServerModelError", "as", "e", ":", "\n", "            ", "out", "[", "'error'", "]", "=", "str", "(", "e", ")", "\n", "out", "[", "'status'", "]", "=", "STATUS_ERROR", "\n", "\n", "", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/to_cpu/<int:model_id>'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "to_cpu", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "'model_id'", ":", "model_id", "}", "\n", "translation_server", ".", "models", "[", "model_id", "]", ".", "to_cpu", "(", ")", "\n", "\n", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "@", "app", ".", "route", "(", "'/to_gpu/<int:model_id>'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "def", "to_gpu", "(", "model_id", ")", ":", "\n", "        ", "out", "=", "{", "'model_id'", ":", "model_id", "}", "\n", "translation_server", ".", "models", "[", "model_id", "]", ".", "to_gpu", "(", ")", "\n", "\n", "out", "[", "'status'", "]", "=", "STATUS_OK", "\n", "return", "jsonify", "(", "out", ")", "\n", "\n", "", "app", ".", "run", "(", "debug", "=", "debug", ",", "host", "=", "host", ",", "port", "=", "port", ",", "use_reloader", "=", "False", ",", "\n", "threaded", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.test_rouge.test_rouge": [[13, 49], ["time.strftime", "time.localtime", "len", "range", "pyrouge.Rouge155", "pyrouge.Rouge155.convert_and_evaluate", "pyrouge.Rouge155.output_to_dict", "os.path.isdir", "os.path.isdir", "os.mkdir", "os.mkdir", "os.mkdir", "line.strip", "line.strip", "len", "len", "shutil.rmtree", "len", "open", "f.write", "open", "f.write"], "function", ["None"], ["def", "test_rouge", "(", "cand", ",", "ref", ")", ":", "\n", "    ", "\"\"\"Calculate ROUGE scores of sequences passed as an iterator\n       e.g. a list of str, an open file, StringIO or even sys.stdin\n    \"\"\"", "\n", "current_time", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "tmp_dir", "=", "\".rouge-tmp-{}\"", ".", "format", "(", "current_time", ")", "\n", "try", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/candidate\"", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/reference\"", ")", "\n", "", "candidates", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "cand", "]", "\n", "references", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "ref", "]", "\n", "assert", "len", "(", "candidates", ")", "==", "len", "(", "references", ")", "\n", "cnt", "=", "len", "(", "candidates", ")", "\n", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "            ", "if", "len", "(", "references", "[", "i", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/candidate/cand.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "candidates", "[", "i", "]", ")", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/reference/ref.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "references", "[", "i", "]", ")", "\n", "", "", "r", "=", "pyrouge", ".", "Rouge155", "(", ")", "\n", "r", ".", "model_dir", "=", "tmp_dir", "+", "\"/reference/\"", "\n", "r", ".", "system_dir", "=", "tmp_dir", "+", "\"/candidate/\"", "\n", "r", ".", "model_filename_pattern", "=", "'ref.#ID#.txt'", "\n", "r", ".", "system_filename_pattern", "=", "'cand.(\\d+).txt'", "\n", "rouge_results", "=", "r", ".", "convert_and_evaluate", "(", ")", "\n", "results_dict", "=", "r", ".", "output_to_dict", "(", "rouge_results", ")", "\n", "return", "results_dict", "\n", "", "finally", ":", "\n", "        ", "pass", "\n", "if", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.test_rouge.rouge_results_to_str": [[51, 58], ["None"], "function", ["None"], ["", "", "", "def", "rouge_results_to_str", "(", "results_dict", ")", ":", "\n", "    ", "return", "\">> ROUGE(1/2/3/L/SU4): {:.2f}/{:.2f}/{:.2f}/{:.2f}/{:.2f}\"", ".", "format", "(", "\n", "results_dict", "[", "\"rouge_1_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_3_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_l_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_su*_f_score\"", "]", "*", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.get_vocabs": [[13, 32], ["torch.load", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "len", "len"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["def", "get_vocabs", "(", "dict_file", ")", ":", "\n", "    ", "vocabs", "=", "torch", ".", "load", "(", "dict_file", ")", "\n", "\n", "enc_vocab", ",", "dec_vocab", "=", "None", ",", "None", "\n", "\n", "# the vocab object is a list of tuple (name, torchtext.Vocab)", "\n", "# we iterate over this list and associate vocabularies based on the name", "\n", "for", "vocab", "in", "vocabs", ":", "\n", "        ", "if", "vocab", "[", "0", "]", "==", "'src'", ":", "\n", "            ", "enc_vocab", "=", "vocab", "[", "1", "]", "\n", "", "if", "vocab", "[", "0", "]", "==", "'tgt'", ":", "\n", "            ", "dec_vocab", "=", "vocab", "[", "1", "]", "\n", "", "", "assert", "enc_vocab", "is", "not", "None", "and", "dec_vocab", "is", "not", "None", "\n", "\n", "logger", ".", "info", "(", "\"From: %s\"", "%", "dict_file", ")", "\n", "logger", ".", "info", "(", "\"\\t* source vocab: %d words\"", "%", "len", "(", "enc_vocab", ")", ")", "\n", "logger", ".", "info", "(", "\"\\t* target vocab: %d words\"", "%", "len", "(", "dec_vocab", ")", ")", "\n", "\n", "return", "enc_vocab", ",", "dec_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.get_embeddings": [[34, 66], ["dict", "enumerate", "onmt.utils.logging.logger.info", "enumerate", "onmt.utils.logging.logger.info", "open", "l.decode().strip().split", "open", "l.decode().strip().split", "len", "len", "float", "len", "len", "len", "float", "len", "l.decode().strip", "l.decode().strip", "l.decode", "l.decode"], "function", ["None"], ["", "def", "get_embeddings", "(", "file_enc", ",", "opt", ",", "flag", ")", ":", "\n", "    ", "embs", "=", "dict", "(", ")", "\n", "if", "flag", "==", "'enc'", ":", "\n", "        ", "for", "(", "i", ",", "l", ")", "in", "enumerate", "(", "open", "(", "file_enc", ",", "'rb'", ")", ")", ":", "\n", "            ", "if", "i", "<", "opt", ".", "skip_lines", ":", "\n", "                ", "continue", "\n", "", "if", "not", "l", ":", "\n", "                ", "break", "\n", "", "if", "len", "(", "l", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "l_split", "=", "l", ".", "decode", "(", "'utf8'", ")", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "l_split", ")", "==", "2", ":", "\n", "                ", "continue", "\n", "", "embs", "[", "l_split", "[", "0", "]", "]", "=", "[", "float", "(", "em", ")", "for", "em", "in", "l_split", "[", "1", ":", "]", "]", "\n", "", "logger", ".", "info", "(", "\"Got {} encryption embeddings from {}\"", ".", "format", "(", "len", "(", "embs", ")", ",", "\n", "file_enc", ")", ")", "\n", "", "else", ":", "\n", "\n", "        ", "for", "(", "i", ",", "l", ")", "in", "enumerate", "(", "open", "(", "file_enc", ",", "'rb'", ")", ")", ":", "\n", "            ", "if", "not", "l", ":", "\n", "                ", "break", "\n", "", "if", "len", "(", "l", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "l_split", "=", "l", ".", "decode", "(", "'utf8'", ")", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "l_split", ")", "==", "2", ":", "\n", "                ", "continue", "\n", "", "embs", "[", "l_split", "[", "0", "]", "]", "=", "[", "float", "(", "em", ")", "for", "em", "in", "l_split", "[", "1", ":", "]", "]", "\n", "", "logger", ".", "info", "(", "\"Got {} decryption embeddings from {}\"", ".", "format", "(", "len", "(", "embs", ")", ",", "\n", "file_enc", ")", ")", "\n", "", "return", "embs", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.match_embeddings": [[68, 82], ["len", "numpy.zeros", "vocab.stoi.items", "six.next", "torch.Tensor", "six.itervalues", "len", "onmt.utils.logging.logger.info"], "function", ["None"], ["", "def", "match_embeddings", "(", "vocab", ",", "emb", ",", "opt", ")", ":", "\n", "    ", "dim", "=", "len", "(", "six", ".", "next", "(", "six", ".", "itervalues", "(", "emb", ")", ")", ")", "\n", "filtered_embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "vocab", ")", ",", "dim", ")", ")", "\n", "count", "=", "{", "\"match\"", ":", "0", ",", "\"miss\"", ":", "0", "}", "\n", "for", "w", ",", "w_id", "in", "vocab", ".", "stoi", ".", "items", "(", ")", ":", "\n", "        ", "if", "w", "in", "emb", ":", "\n", "            ", "filtered_embeddings", "[", "w_id", "]", "=", "emb", "[", "w", "]", "\n", "count", "[", "'match'", "]", "+=", "1", "\n", "", "else", ":", "\n", "            ", "if", "opt", ".", "verbose", ":", "\n", "                ", "logger", ".", "info", "(", "u\"not found:\\t{}\"", ".", "format", "(", "w", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "count", "[", "'miss'", "]", "+=", "1", "\n", "\n", "", "", "return", "torch", ".", "Tensor", "(", "filtered_embeddings", ")", ",", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.main": [[87, 140], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "embeddings_to_torch.get_vocabs", "embeddings_to_torch.get_embeddings", "embeddings_to_torch.get_embeddings", "embeddings_to_torch.match_embeddings", "embeddings_to_torch.match_embeddings", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "onmt.utils.logging.logger.info", "str", "str", "filtered_enc_embeddings.size", "filtered_dec_embeddings.size"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.get_vocabs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.get_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.get_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.match_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.embeddings_to_torch.match_embeddings"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'embeddings_to_torch.py'", ")", "\n", "parser", ".", "add_argument", "(", "'-emb_file_enc'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"source Embeddings from this file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-emb_file_dec'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"target Embeddings from this file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-output_file'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "parser", ".", "add_argument", "(", "'-dict_file'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Dictionary file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'-skip_lines'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Skip first lines of the embedding file\"", ")", "\n", "parser", ".", "add_argument", "(", "'-type'", ",", "choices", "=", "TYPES", ",", "default", "=", "\"GloVe\"", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "enc_vocab", ",", "dec_vocab", "=", "get_vocabs", "(", "opt", ".", "dict_file", ")", "\n", "if", "opt", ".", "type", "==", "\"word2vec\"", ":", "\n", "        ", "opt", ".", "skip_lines", "=", "1", "\n", "\n", "", "embeddings_enc", "=", "get_embeddings", "(", "opt", ".", "emb_file_enc", ",", "opt", ",", "flag", "=", "'enc'", ")", "\n", "embeddings_dec", "=", "get_embeddings", "(", "opt", ".", "emb_file_dec", ",", "opt", ",", "flag", "=", "'dec'", ")", "\n", "\n", "filtered_enc_embeddings", ",", "enc_count", "=", "match_embeddings", "(", "enc_vocab", ",", "\n", "embeddings_enc", ",", "\n", "opt", ")", "\n", "filtered_dec_embeddings", ",", "dec_count", "=", "match_embeddings", "(", "dec_vocab", ",", "\n", "embeddings_dec", ",", "\n", "opt", ")", "\n", "logger", ".", "info", "(", "\"\\nMatching: \"", ")", "\n", "match_percent", "=", "[", "_", "[", "'match'", "]", "/", "(", "_", "[", "'match'", "]", "+", "_", "[", "'miss'", "]", ")", "*", "100", "\n", "for", "_", "in", "[", "enc_count", ",", "dec_count", "]", "]", "\n", "logger", ".", "info", "(", "\"\\t* enc: %d match, %d missing, (%.2f%%)\"", "\n", "%", "(", "enc_count", "[", "'match'", "]", ",", "\n", "enc_count", "[", "'miss'", "]", ",", "\n", "match_percent", "[", "0", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"\\t* dec: %d match, %d missing, (%.2f%%)\"", "\n", "%", "(", "dec_count", "[", "'match'", "]", ",", "\n", "dec_count", "[", "'miss'", "]", ",", "\n", "match_percent", "[", "1", "]", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"\\nFiltered embeddings:\"", ")", "\n", "logger", ".", "info", "(", "\"\\t* enc: %s\"", "%", "str", "(", "filtered_enc_embeddings", ".", "size", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"\\t* dec: %s\"", "%", "str", "(", "filtered_dec_embeddings", ".", "size", "(", ")", ")", ")", "\n", "\n", "enc_output_file", "=", "opt", ".", "output_file", "+", "\".enc.pt\"", "\n", "dec_output_file", "=", "opt", ".", "output_file", "+", "\".dec.pt\"", "\n", "logger", ".", "info", "(", "\"\\nSaving embedding as:\\n\\t* enc: %s\\n\\t* dec: %s\"", "\n", "%", "(", "enc_output_file", ",", "dec_output_file", ")", ")", "\n", "torch", ".", "save", "(", "filtered_enc_embeddings", ",", "enc_output_file", ")", "\n", "torch", ".", "save", "(", "filtered_dec_embeddings", ",", "dec_output_file", ")", "\n", "logger", ".", "info", "(", "\"\\nDone.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.create_parser": [[30, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input text (default: standard input).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file for BPE codes (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--symbols'", ",", "'-s'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Create this many new symbols (each representing a character n-gram) (default: %(default)s))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--min-frequency'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "metavar", "=", "'FREQ'", ",", "\n", "help", "=", "'Stop if no symbol pair has frequency >= FREQ (default: %(default)s))'", ")", "\n", "parser", ".", "add_argument", "(", "'--dict-input'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If set, input file is interpreted as a dictionary where each line contains a word-count pair\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verbose'", ",", "'-v'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"verbose mode.\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.get_vocabulary": [[59, 71], ["collections.Counter", "line.strip().split", "int", "line.split", "line.strip"], "function", ["None"], ["", "def", "get_vocabulary", "(", "fobj", ",", "is_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Read text and return dictionary that encodes vocabulary\n    \"\"\"", "\n", "vocab", "=", "Counter", "(", ")", "\n", "for", "line", "in", "fobj", ":", "\n", "        ", "if", "is_dict", ":", "\n", "            ", "word", ",", "count", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "vocab", "[", "word", "]", "=", "int", "(", "count", ")", "\n", "", "else", ":", "\n", "            ", "for", "word", "in", "line", ".", "split", "(", ")", ":", "\n", "                ", "vocab", "[", "word", "]", "+=", "1", "\n", "", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.update_pair_statistics": [[73, 130], ["collections.defaultdict", "old_word.index", "word.index", "len", "len", "len", "len"], "function", ["None"], ["", "def", "update_pair_statistics", "(", "pair", ",", "changed", ",", "stats", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Minimally update the indices and frequency of symbol pairs\n\n    if we merge a pair of symbols, only pairs that overlap with occurrences\n    of this pair are affected, and need to be updated.\n    \"\"\"", "\n", "stats", "[", "pair", "]", "=", "0", "\n", "indices", "[", "pair", "]", "=", "defaultdict", "(", "int", ")", "\n", "first", ",", "second", "=", "pair", "\n", "new_pair", "=", "first", "+", "second", "\n", "for", "j", ",", "word", ",", "old_word", ",", "freq", "in", "changed", ":", "\n", "\n", "# find all instances of pair, and update frequency/indices around it", "\n", "        ", "i", "=", "0", "\n", "while", "True", ":", "\n", "# find first symbol", "\n", "            ", "try", ":", "\n", "                ", "i", "=", "old_word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# if first symbol is followed by second symbol, we've found an occurrence of pair (old_word[i:i+2])", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "1", "and", "old_word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "# assuming a symbol sequence \"A B C\", if \"B C\" is merged, reduce the frequency of \"A B\"", "\n", "                ", "if", "i", ":", "\n", "                    ", "prev", "=", "old_word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "-=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "-=", "1", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "2", ":", "\n", "# assuming a symbol sequence \"A B C B\", if \"B C\" is merged, reduce the frequency of \"C B\".", "\n", "# however, skip this if the sequence is A B C B C, because the frequency of \"C B\" will be reduced by the previous code block", "\n", "                    ", "if", "old_word", "[", "i", "+", "2", "]", "!=", "first", "or", "i", ">=", "len", "(", "old_word", ")", "-", "3", "or", "old_word", "[", "i", "+", "3", "]", "!=", "second", ":", "\n", "                        ", "nex", "=", "old_word", "[", "i", "+", "1", ":", "i", "+", "3", "]", "\n", "stats", "[", "nex", "]", "-=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "-=", "1", "\n", "", "", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "i", "+=", "1", "\n", "\n", "", "", "i", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "# find new pair", "\n", "                ", "i", "=", "word", ".", "index", "(", "new_pair", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# assuming a symbol sequence \"A BC D\", if \"B C\" is merged, increase the frequency of \"A BC\"", "\n", "", "if", "i", ":", "\n", "                ", "prev", "=", "word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "+=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "+=", "1", "\n", "# assuming a symbol sequence \"A BC B\", if \"B C\" is merged, increase the frequency of \"BC B\"", "\n", "# however, if the sequence is A BC BC, skip this step because the count of \"BC BC\" will be incremented by the previous code block", "\n", "", "if", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "!=", "new_pair", ":", "\n", "                ", "nex", "=", "word", "[", "i", ":", "i", "+", "2", "]", "\n", "stats", "[", "nex", "]", "+=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "+=", "1", "\n", "", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.get_pair_statistics": [[132, 149], ["collections.defaultdict", "collections.defaultdict", "enumerate", "collections.defaultdict"], "function", ["None"], ["", "", "", "def", "get_pair_statistics", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Count frequency of all symbol pairs, and create index\"\"\"", "\n", "\n", "# data structure of pair frequencies", "\n", "stats", "=", "defaultdict", "(", "int", ")", "\n", "\n", "# index from pairs to words", "\n", "indices", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "\n", "for", "i", ",", "(", "word", ",", "freq", ")", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "            ", "stats", "[", "prev_char", ",", "char", "]", "+=", "freq", "\n", "indices", "[", "prev_char", ",", "char", "]", "[", "i", "]", "+=", "1", "\n", "prev_char", "=", "char", "\n", "\n", "", "", "return", "stats", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.replace_pair": [[151, 175], ["pair_str.replace.replace", "re.compile", "indices[].iteritems", "indices[].items", "re.compile.sub", "tuple", "changes.append", "tuple.split", "re.escape"], "function", ["None"], ["", "def", "replace_pair", "(", "pair", ",", "vocab", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\"\"\"", "\n", "first", ",", "second", "=", "pair", "\n", "pair_str", "=", "''", ".", "join", "(", "pair", ")", "\n", "pair_str", "=", "pair_str", ".", "replace", "(", "'\\\\'", ",", "'\\\\\\\\'", ")", "\n", "changes", "=", "[", "]", "\n", "pattern", "=", "re", ".", "compile", "(", "\n", "r'(?<!\\S)'", "+", "re", ".", "escape", "(", "first", "+", "' '", "+", "second", ")", "+", "r'(?!\\S)'", ")", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", "0", ")", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "iteritems", "(", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "items", "(", ")", "\n", "", "for", "j", ",", "freq", "in", "iterator", ":", "\n", "        ", "if", "freq", "<", "1", ":", "\n", "            ", "continue", "\n", "", "word", ",", "freq", "=", "vocab", "[", "j", "]", "\n", "new_word", "=", "' '", ".", "join", "(", "word", ")", "\n", "new_word", "=", "pattern", ".", "sub", "(", "pair_str", ",", "new_word", ")", "\n", "new_word", "=", "tuple", "(", "new_word", ".", "split", "(", ")", ")", "\n", "\n", "vocab", "[", "j", "]", "=", "(", "new_word", ",", "freq", ")", "\n", "changes", ".", "append", "(", "(", "j", ",", "new_word", ",", "word", ",", "freq", ")", ")", "\n", "\n", "", "return", "changes", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.prune_stats": [[177, 191], ["list", "stats.items"], "function", ["None"], ["", "def", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Prune statistics dict for efficiency of max()\n\n    The frequency of a symbol pair never increases, so pruning is generally safe\n    (until we the most frequent pair is less frequent than a pair we previously pruned)\n    big_stats keeps full statistics for when we need to access pruned items\n    \"\"\"", "\n", "for", "item", ",", "freq", "in", "list", "(", "stats", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "freq", "<", "threshold", ":", "\n", "            ", "del", "stats", "[", "item", "]", "\n", "if", "freq", "<", "0", ":", "\n", "                ", "big_stats", "[", "item", "]", "+=", "freq", "\n", "", "else", ":", "\n", "                ", "big_stats", "[", "item", "]", "=", "freq", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.main": [[193, 237], ["outfile.write", "learn_bpe.get_vocabulary", "dict", "sorted", "learn_bpe.get_pair_statistics", "copy.deepcopy", "range", "dict.items", "max", "outfile.write", "learn_bpe.replace_pair", "learn_bpe.update_pair_statistics", "copy.deepcopy.values", "max", "learn_bpe.prune_stats", "copy.deepcopy", "max", "learn_bpe.prune_stats", "sys.stderr.write", "sys.stderr.write", "learn_bpe.prune_stats", "dict.items", "tuple"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.get_vocabulary", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.get_pair_statistics", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.replace_pair", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.update_pair_statistics", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.prune_stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.prune_stats", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.learn_bpe.prune_stats"], ["", "", "", "", "def", "main", "(", "infile", ",", "outfile", ",", "num_symbols", ",", "min_frequency", "=", "2", ",", "verbose", "=", "False", ",", "is_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n    \"\"\"", "\n", "\n", "# version 0.2 changes the handling of the end-of-word token ('</w>');", "\n", "# version numbering allows bckward compatibility", "\n", "outfile", ".", "write", "(", "'#version: 0.2\\n'", ")", "\n", "\n", "vocab", "=", "get_vocabulary", "(", "infile", ",", "is_dict", ")", "\n", "vocab", "=", "dict", "(", "[", "(", "tuple", "(", "x", "[", ":", "-", "1", "]", ")", "+", "(", "x", "[", "-", "1", "]", "+", "'</w>'", ",", ")", ",", "y", ")", "\n", "for", "(", "x", ",", "y", ")", "in", "vocab", ".", "items", "(", ")", "]", ")", "\n", "sorted_vocab", "=", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "stats", ",", "indices", "=", "get_pair_statistics", "(", "sorted_vocab", ")", "\n", "big_stats", "=", "copy", ".", "deepcopy", "(", "stats", ")", "\n", "# threshold is inspired by Zipfian assumption, but should only affect speed", "\n", "threshold", "=", "max", "(", "stats", ".", "values", "(", ")", ")", "/", "10", "\n", "for", "i", "in", "range", "(", "num_symbols", ")", ":", "\n", "        ", "if", "stats", ":", "\n", "            ", "most_frequent", "=", "max", "(", "stats", ",", "key", "=", "lambda", "x", ":", "(", "stats", "[", "x", "]", ",", "x", ")", ")", "\n", "\n", "# we probably missed the best pair because of pruning; go back to full statistics", "\n", "", "if", "not", "stats", "or", "(", "i", "and", "stats", "[", "most_frequent", "]", "<", "threshold", ")", ":", "\n", "            ", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "stats", "=", "copy", ".", "deepcopy", "(", "big_stats", ")", "\n", "most_frequent", "=", "max", "(", "stats", ",", "key", "=", "lambda", "x", ":", "(", "stats", "[", "x", "]", ",", "x", ")", ")", "\n", "# threshold is inspired by Zipfian assumption, but should only affect speed", "\n", "threshold", "=", "stats", "[", "most_frequent", "]", "*", "i", "/", "(", "i", "+", "10000.0", ")", "\n", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "\n", "", "if", "stats", "[", "most_frequent", "]", "<", "min_frequency", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\n", "'no pair has frequency >= {0}. Stopping\\n'", ".", "format", "(", "min_frequency", ")", ")", "\n", "break", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "'pair {0}: {1} {2} -> {1}{2} (frequency {3})\\n'", ".", "format", "(", "\n", "i", ",", "most_frequent", "[", "0", "]", ",", "most_frequent", "[", "1", "]", ",", "stats", "[", "most_frequent", "]", ")", ")", "\n", "", "outfile", ".", "write", "(", "'{0} {1}\\n'", ".", "format", "(", "*", "most_frequent", ")", ")", "\n", "changes", "=", "replace_pair", "(", "most_frequent", ",", "sorted_vocab", ",", "indices", ")", "\n", "update_pair_statistics", "(", "most_frequent", ",", "changes", ",", "stats", ",", "indices", ")", "\n", "stats", "[", "most_frequent", "]", "=", "0", "\n", "if", "not", "i", "%", "100", ":", "\n", "            ", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.average_models.average_models": [[6, 31], ["enumerate", "torch.load", "avg_model.items", "avg_generator.items", "avg_model[].mul_().add_().div_", "avg_generator[].mul_().add_().div_", "avg_model[].mul_().add_", "avg_generator[].mul_().add_", "avg_model[].mul_", "avg_generator[].mul_"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load"], ["def", "average_models", "(", "model_files", ")", ":", "\n", "    ", "vocab", "=", "None", "\n", "opt", "=", "None", "\n", "avg_model", "=", "None", "\n", "avg_generator", "=", "None", "\n", "\n", "for", "i", ",", "model_file", "in", "enumerate", "(", "model_files", ")", ":", "\n", "        ", "m", "=", "torch", ".", "load", "(", "model_file", ")", "\n", "model_weights", "=", "m", "[", "'model'", "]", "\n", "generator_weights", "=", "m", "[", "'generator'", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "            ", "vocab", ",", "opt", "=", "m", "[", "'vocab'", "]", ",", "m", "[", "'opt'", "]", "\n", "avg_model", "=", "model_weights", "\n", "avg_generator", "=", "generator_weights", "\n", "", "else", ":", "\n", "            ", "for", "(", "k", ",", "v", ")", "in", "avg_model", ".", "items", "(", ")", ":", "\n", "                ", "avg_model", "[", "k", "]", ".", "mul_", "(", "i", ")", ".", "add_", "(", "model_weights", "[", "k", "]", ")", ".", "div_", "(", "i", "+", "1", ")", "\n", "\n", "", "for", "(", "k", ",", "v", ")", "in", "avg_generator", ".", "items", "(", ")", ":", "\n", "                ", "avg_generator", "[", "k", "]", ".", "mul_", "(", "i", ")", ".", "add_", "(", "generator_weights", "[", "k", "]", ")", ".", "div_", "(", "i", "+", "1", ")", "\n", "\n", "", "", "", "final", "=", "{", "\"vocab\"", ":", "vocab", ",", "\"opt\"", ":", "opt", ",", "\"optim\"", ":", "None", ",", "\n", "\"generator\"", ":", "avg_generator", ",", "\"model\"", ":", "avg_model", "}", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.average_models.main": [[33, 43], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "average_models.average_models", "torch.save"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.average_models.average_models"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-models\"", ",", "\"-m\"", ",", "nargs", "=", "\"+\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"List of models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-output\"", ",", "\"-o\"", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file\"", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "final", "=", "average_models", "(", "opt", ".", "models", ")", "\n", "torch", ".", "save", "(", "final", ",", "opt", ".", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.BPE.__init__": [[33, 60], ["codes.readline", "codes.readline.startswith", "dict", "dict", "tuple", "codes.seek", "tuple", "item.split", "int", "reversed", "apply_bpe.BPE.bpe_codes.items", "re.sub().split", "list", "enumerate", "re.sub", "codes.readline.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "codes", ",", "separator", "=", "'@@'", ",", "vocab", "=", "None", ",", "glossaries", "=", "None", ")", ":", "\n", "\n", "# check version information", "\n", "        ", "firstline", "=", "codes", ".", "readline", "(", ")", "\n", "if", "firstline", ".", "startswith", "(", "'#version:'", ")", ":", "\n", "            ", "self", ".", "version", "=", "tuple", "(", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "sub", "(", "\n", "r'(\\.0+)*$'", ",", "''", ",", "firstline", ".", "split", "(", ")", "[", "-", "1", "]", ")", ".", "split", "(", "\".\"", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "version", "=", "(", "0", ",", "1", ")", "\n", "codes", ".", "seek", "(", "0", ")", "\n", "\n", "", "self", ".", "bpe_codes", "=", "[", "tuple", "(", "item", ".", "split", "(", ")", ")", "for", "item", "in", "codes", "]", "\n", "\n", "# some hacking to deal with duplicates (only consider first instance)", "\n", "self", ".", "bpe_codes", "=", "dict", "(", "\n", "[", "(", "code", ",", "i", ")", "for", "(", "i", ",", "code", ")", "in", "reversed", "(", "list", "(", "enumerate", "(", "self", ".", "bpe_codes", ")", ")", ")", "]", ")", "\n", "\n", "self", ".", "bpe_codes_reverse", "=", "dict", "(", "\n", "[", "(", "pair", "[", "0", "]", "+", "pair", "[", "1", "]", ",", "pair", ")", "for", "pair", ",", "i", "in", "self", ".", "bpe_codes", ".", "items", "(", ")", "]", ")", "\n", "\n", "self", ".", "separator", "=", "separator", "\n", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "glossaries", "=", "glossaries", "if", "glossaries", "else", "[", "]", "\n", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.BPE.segment": [[61, 80], ["sentence.split", "output.append", "output.append", "apply_bpe.BPE._isolate_glossaries", "apply_bpe.encode"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.BPE._isolate_glossaries", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.encode"], ["", "def", "segment", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "\"\"\"segment single sentence (whitespace-tokenized string) with BPE encoding\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "word", "in", "sentence", ".", "split", "(", ")", ":", "\n", "            ", "new_word", "=", "[", "out", "for", "segment", "in", "self", ".", "_isolate_glossaries", "(", "word", ")", "\n", "for", "out", "in", "encode", "(", "segment", ",", "\n", "self", ".", "bpe_codes", ",", "\n", "self", ".", "bpe_codes_reverse", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "separator", ",", "\n", "self", ".", "version", ",", "\n", "self", ".", "cache", ",", "\n", "self", ".", "glossaries", ")", "]", "\n", "\n", "for", "item", "in", "new_word", "[", ":", "-", "1", "]", ":", "\n", "                ", "output", ".", "append", "(", "item", "+", "self", ".", "separator", ")", "\n", "", "output", ".", "append", "(", "new_word", "[", "-", "1", "]", ")", "\n", "\n", "", "return", "' '", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.BPE._isolate_glossaries": [[81, 87], ["apply_bpe.isolate_glossary"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.isolate_glossary"], ["", "def", "_isolate_glossaries", "(", "self", ",", "word", ")", ":", "\n", "        ", "word_segments", "=", "[", "word", "]", "\n", "for", "gloss", "in", "self", ".", "glossaries", ":", "\n", "            ", "word_segments", "=", "[", "out_segments", "for", "segment", "in", "word_segments", "\n", "for", "out_segments", "in", "isolate_glossary", "(", "segment", ",", "gloss", ")", "]", "\n", "", "return", "word_segments", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.create_parser": [[89, 124], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["", "", "def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input file (default: standard input).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--codes'", ",", "'-c'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "metavar", "=", "'PATH'", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"File with BPE codes (created by learn_bpe.py).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--separator'", ",", "'-s'", ",", "type", "=", "str", ",", "default", "=", "'@@'", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "\"Separator between non-final subword units (default: '%(default)s'))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vocabulary'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"PATH\"", ",", "\n", "help", "=", "\"Vocabulary file (built with get_vocab.py). If provided, this script reverts any merge operations that produce an OOV.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vocabulary-threshold'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"INT\"", ",", "\n", "help", "=", "\"Vocabulary threshold. If vocabulary is provided, any word with frequency < threshold will be treated as OOV\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--glossaries'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"Glossaries. The strings provided in glossaries will not be affected\"", "+", "\n", "\"by the BPE (i.e. they will neither be broken into subwords, nor concatenated with other subwords\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.get_pairs": [[126, 137], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.encode": [[139, 202], ["apply_bpe.get_pairs", "min", "tuple", "word[].endswith", "apply_bpe.check_vocab_and_split", "tuple", "len", "len", "apply_bpe.get_pairs", "tuple", "check_vocab_and_split.index", "tuple.extend", "tuple.append", "tuple.append", "bpe_codes.get", "tuple.extend", "word[].replace", "float", "len"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.get_pairs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.check_vocab_and_split", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.get_pairs"], ["", "def", "encode", "(", "orig", ",", "bpe_codes", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ",", "version", ",", "cache", ",", "glossaries", "=", "None", ")", ":", "\n", "    ", "\"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\n    \"\"\"", "\n", "\n", "if", "orig", "in", "cache", ":", "\n", "        ", "return", "cache", "[", "orig", "]", "\n", "\n", "", "if", "orig", "in", "glossaries", ":", "\n", "        ", "cache", "[", "orig", "]", "=", "(", "orig", ",", ")", "\n", "return", "(", "orig", ",", ")", "\n", "\n", "", "if", "version", "==", "(", "0", ",", "1", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "orig", ")", "+", "(", "'</w>'", ",", ")", "\n", "", "elif", "version", "==", "(", "0", ",", "2", ")", ":", "# more consistent handling of word-final segments", "\n", "        ", "word", "=", "tuple", "(", "orig", "[", ":", "-", "1", "]", ")", "+", "(", "orig", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "        ", "return", "orig", "\n", "\n", "", "while", "True", ":", "\n", "        ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "bpe_codes", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "bpe_codes", ":", "\n", "            ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "# don't print end-of-word symbols", "\n", "", "", "if", "word", "[", "-", "1", "]", "==", "'</w>'", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "\n", "", "elif", "word", "[", "-", "1", "]", ".", "endswith", "(", "'</w>'", ")", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "+", "(", "word", "[", "-", "1", "]", ".", "replace", "(", "'</w>'", ",", "''", ")", ",", ")", "\n", "\n", "", "if", "vocab", ":", "\n", "        ", "word", "=", "check_vocab_and_split", "(", "word", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ")", "\n", "\n", "", "cache", "[", "orig", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.recursive_split": [[204, 230], ["apply_bpe.recursive_split", "apply_bpe.recursive_split"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.recursive_split", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.recursive_split"], ["", "def", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", "=", "False", ")", ":", "\n", "    ", "\"\"\"Recursively split segment into smaller units (by reversing BPE merges)\n    until all units are either in-vocabulary, or cannot be split futher.\"\"\"", "\n", "\n", "try", ":", "\n", "        ", "if", "final", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "+", "'</w>'", "]", "\n", "right", "=", "right", "[", ":", "-", "4", "]", "\n", "", "else", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "]", "\n", "", "", "except", ":", "\n", "#sys.stderr.write('cannot split {0} further.\\n'.format(segment))", "\n", "        ", "yield", "segment", "\n", "return", "\n", "\n", "", "if", "left", "+", "separator", "in", "vocab", ":", "\n", "        ", "yield", "left", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "left", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "            ", "yield", "item", "\n", "\n", "", "", "if", "(", "final", "and", "right", "in", "vocab", ")", "or", "(", "not", "final", "and", "right", "+", "separator", "in", "vocab", ")", ":", "\n", "        ", "yield", "right", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "right", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", ")", ":", "\n", "            ", "yield", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.check_vocab_and_split": [[232, 255], ["out.append", "apply_bpe.recursive_split", "out.append", "apply_bpe.recursive_split", "out.append", "out.append"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.recursive_split", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.recursive_split"], ["", "", "", "def", "check_vocab_and_split", "(", "orig", ",", "bpe_codes", ",", "vocab", ",", "separator", ")", ":", "\n", "    ", "\"\"\"Check for each segment in word if it is in-vocabulary,\n    and segment OOV segments into smaller units by reversing the BPE merge operations\"\"\"", "\n", "\n", "out", "=", "[", "]", "\n", "\n", "for", "segment", "in", "orig", "[", ":", "-", "1", "]", ":", "\n", "        ", "if", "segment", "+", "separator", "in", "vocab", ":", "\n", "            ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "            ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "                ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "segment", "=", "orig", "[", "-", "1", "]", "\n", "if", "segment", "in", "vocab", ":", "\n", "        ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "        ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "True", ")", ":", "\n", "            ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.read_vocabulary": [[257, 270], ["set", "line.split", "int", "set.add"], "function", ["None"], ["", "def", "read_vocabulary", "(", "vocab_file", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"read vocabulary file produced by get_vocab.py, and filter according to frequency threshold.\n    \"\"\"", "\n", "\n", "vocabulary", "=", "set", "(", ")", "\n", "\n", "for", "line", "in", "vocab_file", ":", "\n", "        ", "word", ",", "freq", "=", "line", ".", "split", "(", ")", "\n", "freq", "=", "int", "(", "freq", ")", "\n", "if", "threshold", "==", "None", "or", "freq", ">=", "threshold", ":", "\n", "            ", "vocabulary", ".", "add", "(", "word", ")", "\n", "\n", "", "", "return", "vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.isolate_glossary": [[272, 288], ["word.split", "segment.strip", "splits[].strip"], "function", ["None"], ["", "def", "isolate_glossary", "(", "word", ",", "glossary", ")", ":", "\n", "    ", "\"\"\"\n    Isolate a glossary present inside a word.\n\n    Returns a list of subwords. In which all 'glossary' glossaries are isolated \n\n    For example, if 'USA' is the glossary and '1934USABUSA' the word, the return value is:\n        ['1934', 'USA', 'B', 'USA']\n    \"\"\"", "\n", "if", "word", "==", "glossary", "or", "glossary", "not", "in", "word", ":", "\n", "        ", "return", "[", "word", "]", "\n", "", "else", ":", "\n", "        ", "splits", "=", "word", ".", "split", "(", "glossary", ")", "\n", "segments", "=", "[", "segment", ".", "strip", "(", ")", "for", "split", "in", "splits", "[", ":", "-", "1", "]", "\n", "for", "segment", "in", "[", "split", ",", "glossary", "]", "if", "segment", "!=", "''", "]", "\n", "return", "segments", "+", "[", "splits", "[", "-", "1", "]", ".", "strip", "(", ")", "]", "if", "splits", "[", "-", "1", "]", "!=", "''", "else", "segments", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.write_embeddings": [[22, 29], ["open", "range", "min", "dict.itos[].encode", "range", "file.write", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.apply_bpe.encode"], ["def", "write_embeddings", "(", "filename", ",", "dict", ",", "embeddings", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "file", ":", "\n", "        ", "for", "i", "in", "range", "(", "min", "(", "len", "(", "embeddings", ")", ",", "len", "(", "dict", ".", "itos", ")", ")", ")", ":", "\n", "            ", "str", "=", "dict", ".", "itos", "[", "i", "]", ".", "encode", "(", "\"utf-8\"", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "embeddings", "[", "0", "]", ")", ")", ":", "\n", "                ", "str", "=", "str", "+", "(", "\" %5f\"", "%", "(", "embeddings", "[", "i", "]", "[", "j", "]", ")", ")", ".", "encode", "(", "\"utf-8\"", ")", "\n", "", "file", ".", "write", "(", "str", "+", "b\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.main": [[31, 81], ["argparse.ArgumentParser", "onmt.opts.model_opts", "onmt.opts.model_opts", "onmt.opts.model_opts", "onmt.opts.model_opts", "parser.parse_args", "torch.load", "onmt.inputters.load_fields_from_vocab", "onmt.inputters.load_fields_from_vocab", "onmt.inputters.load_fields_from_vocab", "onmt.inputters.load_fields_from_vocab", "onmt.model_builder.build_base_model", "onmt.model_builder.build_base_model", "onmt.model_builder.build_base_model", "onmt.model_builder.build_base_model", "encoder.embeddings.word_lut.weight.data.tolist", "decoder.embeddings.word_lut.weight.data.tolist", "onmt.utils.logging.logger.info", "extract_embeddings.write_embeddings", "onmt.utils.logging.logger.info", "extract_embeddings.write_embeddings", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "argparse.ArgumentParser.parse_known_args", "torch.cuda.set_device", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.OpenNMT-py-baselines.preprocess.parse_args", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.onmt.model_builder.build_base_model", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.write_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.tools.extract_embeddings.write_embeddings", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.utils.misc.use_gpu"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "onmt", ".", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "# Add in default model arguments, possibly added since training.", "\n", "", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "\n", "src_dict", ",", "tgt_dict", "=", "None", ",", "None", "\n", "\n", "# the vocab object is a list of tuple (name, torchtext.Vocab)", "\n", "# we iterate over this list and associate vocabularies based on the name", "\n", "for", "vocab", "in", "checkpoint", "[", "'vocab'", "]", ":", "\n", "        ", "if", "vocab", "[", "0", "]", "==", "'src'", ":", "\n", "            ", "src_dict", "=", "vocab", "[", "1", "]", "\n", "", "if", "vocab", "[", "0", "]", "==", "'tgt'", ":", "\n", "            ", "tgt_dict", "=", "vocab", "[", "1", "]", "\n", "", "", "assert", "src_dict", "is", "not", "None", "and", "tgt_dict", "is", "not", "None", "\n", "\n", "fields", "=", "onmt", ".", "inputters", ".", "load_fields_from_vocab", "(", "checkpoint", "[", "'vocab'", "]", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "for", "arg", "in", "dummy_opt", ".", "__dict__", ":", "\n", "        ", "if", "arg", "not", "in", "model_opt", ":", "\n", "            ", "model_opt", ".", "__dict__", "[", "arg", "]", "=", "dummy_opt", ".", "__dict__", "[", "arg", "]", "\n", "\n", "", "", "model", "=", "onmt", ".", "model_builder", ".", "build_base_model", "(", "\n", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "encoder", "=", "model", ".", "encoder", "\n", "decoder", "=", "model", ".", "decoder", "\n", "\n", "encoder_embeddings", "=", "encoder", ".", "embeddings", ".", "word_lut", ".", "weight", ".", "data", ".", "tolist", "(", ")", "\n", "decoder_embeddings", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", ".", "data", ".", "tolist", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing source embeddings\"", ")", "\n", "write_embeddings", "(", "opt", ".", "output_dir", "+", "\"/src_embeddings.txt\"", ",", "src_dict", ",", "\n", "encoder_embeddings", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing target embeddings\"", ")", "\n", "write_embeddings", "(", "opt", ".", "output_dir", "+", "\"/tgt_embeddings.txt\"", ",", "tgt_dict", ",", "\n", "decoder_embeddings", ")", "\n", "\n", "logger", ".", "info", "(", "'... done.'", ")", "\n", "logger", ".", "info", "(", "'Converting model...'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.extractive_code.lexrank.read_in_train_set": [[6, 12], ["open", "corpus.append", "line.strip"], "function", ["None"], ["def", "read_in_train_set", "(", "input_path", ",", "filename", ")", ":", "\n", "\t", "corpus", "=", "[", "]", "\n", "with", "open", "(", "input_path", "+", "filename", ",", "'r'", ")", "as", "fr", ":", "\n", "\t\t", "for", "line", "in", "fr", ":", "\n", "\t\t\t", "corpus", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.extractive_code.lexrank.lexrank_summarize": [[13, 55], ["print", "print", "lexrank.LexRank", "print", "range", "gensim.summarization.textcleaner.split_sentences", "len", "lexrank.LexRank.get_summary", "corpus[].split", "range", "list_of_summarization.append", "sample.replace", "range", "len", "print", "print", "print", "str", "time.strftime", "time.strftime", "len", "range", "len", "len", "print", "len", "time.localtime", "time.localtime", "len", "tmp_summary[].append", "len", "summary[].split"], "function", ["None"], ["", "def", "lexrank_summarize", "(", "corpus", ")", ":", "\n", "\t", "list_of_summarization", "=", "[", "]", "\n", "\n", "documents", "=", "[", "split_sentences", "(", "sample", ".", "replace", "(", "\"story_separator_special_tag\"", ",", "\"\\n\"", ")", ")", "for", "sample", "in", "corpus", "]", "\n", "print", "(", "\"[\"", "+", "\"Document Size: \"", "+", "str", "(", "len", "(", "documents", ")", ")", "+", "\"]\"", ")", "\n", "print", "(", "\"[\"", "+", "time", ".", "strftime", "(", "\"%H:%M:%S\"", ",", "time", ".", "localtime", "(", ")", ")", "+", "\"]\"", ",", "\"Begin building LexRank model...\"", ")", "\n", "lxr", "=", "LexRank", "(", "documents", ",", "stopwords", "=", "STOPWORDS", "[", "'en'", "]", ")", "\n", "print", "(", "\"[\"", "+", "time", ".", "strftime", "(", "\"%H:%M:%S\"", ",", "time", ".", "localtime", "(", ")", ")", "+", "\"]\"", ",", "\"LexRank model successfully built...\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "documents", ")", ")", ":", "\n", "\t\t", "sample", "=", "documents", "[", "i", "]", "\n", "summary", "=", "lxr", ".", "get_summary", "(", "sample", ",", "summary_size", "=", "len", "(", "sample", ")", ")", "\n", "articles", "=", "corpus", "[", "i", "]", ".", "split", "(", "\"story_separator_special_tag\"", ")", "\n", "\n", "words_counter", "=", "0", "\n", "summary_counter", "=", "0", "\n", "tmp_summary", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "articles", ")", ")", "]", "\n", "\n", "while", "words_counter", "<", "500", "and", "summary_counter", "<", "len", "(", "summary", ")", ":", "\n", "\t\t\t", "flag", "=", "0", "\n", "for", "j", "in", "range", "(", "len", "(", "articles", ")", ")", ":", "\n", "\t\t\t\t", "if", "summary", "[", "summary_counter", "]", "in", "articles", "[", "j", "]", ":", "\n", "\t\t\t\t\t", "tmp_summary", "[", "j", "]", ".", "append", "(", "summary", "[", "summary_counter", "]", ")", "\n", "words_counter", "+=", "len", "(", "summary", "[", "summary_counter", "]", ".", "split", "(", "\" \"", ")", ")", "\n", "flag", "=", "1", "\n", "", "", "if", "flag", "==", "0", ":", "\n", "\t\t\t\t", "print", "(", "\"[Error] Summary not in original sample.\"", ",", "summary", "[", "summary_counter", "]", ",", "i", ")", "\n", "", "summary_counter", "+=", "1", "\n", "\n", "# print(\"words_counter, summary_counter, total summary\", words_counter, summary_counter, len(summary))", "\n", "", "for", "k", "in", "range", "(", "len", "(", "tmp_summary", ")", ")", ":", "\n", "\t\t\t", "tmp_summary", "[", "k", "]", "=", "\" newline_char \"", ".", "join", "(", "tmp_summary", "[", "k", "]", ")", "\n", "", "list_of_summarization", ".", "append", "(", "\" story_separator_special_tag \"", ".", "join", "(", "tmp_summary", ")", ")", "\n", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "\t\t\t", "print", "(", "\"------\"", ")", "\n", "print", "(", "i", ")", "\n", "print", "(", "\"------\"", ")", "\n", "# if i == 100:", "\n", "# \tbreak", "\n", "\n", "", "", "return", "list_of_summarization", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.extractive_code.textrank.read_in_train_set": [[5, 11], ["open", "corpus.append", "line.strip"], "function", ["None"], ["def", "read_in_train_set", "(", "input_path", ",", "filename", ")", ":", "\n", "\t", "corpus", "=", "[", "]", "\n", "with", "open", "(", "input_path", "+", "filename", ",", "'r'", ")", "as", "fr", ":", "\n", "\t\t", "for", "line", "in", "fr", ":", "\n", "\t\t\t", "corpus", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.extractive_code.textrank.textrank_summarize": [[12, 59], ["print", "range", "len", "corpus[].strip", "corpus[].strip.split", "range", "list_of_summarization.append", "gensim.summarization.summarizer.summarize", "range", "len", "print", "print", "len", "gensim.summarization.textcleaner.split_sentences", "print", "list_of_summarization.append", "range", "len", "print", "len", "print", "len", "tmp_list_of_summarization[].append"], "function", ["None"], ["", "def", "textrank_summarize", "(", "corpus", ")", ":", "\n", "\t", "print", "(", "\"Begin summarizing...\"", ")", "\n", "\n", "list_of_summarization", "=", "[", "]", "\n", "\n", "error_counter", "=", "0", "\n", "null_summarization_counter", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "corpus", ")", ")", ":", "\n", "\t\t", "sample", "=", "corpus", "[", "i", "]", ".", "strip", "(", ")", "\n", "articles", "=", "sample", ".", "split", "(", "\"story_separator_special_tag\"", ")", "\n", "\n", "try", ":", "\n", "\t\t\t", "summarization", "=", "summarize", "(", "\"\\n\"", ".", "join", "(", "articles", ")", ",", "word_count", "=", "500", ",", "split", "=", "True", ")", "\n", "if", "len", "(", "summarization", ")", "==", "0", ":", "\n", "\t\t\t\t", "null_summarization_counter", "+=", "1", "\n", "summarization", "=", "split_sentences", "(", "\"\\n\"", ".", "join", "(", "articles", ")", ")", "\n", "if", "len", "(", "summarization", ")", "==", "0", ":", "\n", "\t\t\t\t\t", "print", "(", "\"*** No Summarization ***\"", ",", "i", ")", "\n", "", "", "", "except", "ValueError", ":", "\n", "\t\t\t", "print", "(", "\"ValueError, sample\"", ",", "sample", ")", "\n", "summarization", "=", "sample", "\n", "list_of_summarization", ".", "append", "(", "summarization", ")", "\n", "error_counter", "+=", "1", "\n", "continue", "\n", "\n", "", "tmp_list_of_summarization", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "articles", ")", ")", "]", "\n", "for", "sent", "in", "summarization", ":", "\n", "\t\t\t", "flag", "=", "0", "\n", "for", "j", "in", "range", "(", "len", "(", "articles", ")", ")", ":", "\n", "\t\t\t\t", "if", "sent", "in", "articles", "[", "j", "]", ":", "\n", "\t\t\t\t\t", "tmp_list_of_summarization", "[", "j", "]", ".", "append", "(", "sent", ")", "\n", "flag", "=", "1", "\n", "", "", "if", "flag", "==", "0", ":", "\n", "\t\t\t\t", "print", "(", "i", ",", "\"****\"", ",", "sent", ",", "(", "sent", "in", "\" \"", ".", "join", "(", "articles", ")", ")", ")", "\n", "\n", "", "", "for", "k", "in", "range", "(", "len", "(", "tmp_list_of_summarization", ")", ")", ":", "\n", "\t\t\t", "tmp_list_of_summarization", "[", "k", "]", "=", "\" newline_char \"", ".", "join", "(", "tmp_list_of_summarization", "[", "k", "]", ")", "\n", "\n", "", "list_of_summarization", ".", "append", "(", "\" story_separator_special_tag \"", ".", "join", "(", "tmp_list_of_summarization", ")", ")", "\n", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "\t\t\t", "print", "(", "i", ")", "\n", "print", "(", "\"------\"", ")", "\n", "# if i == 5000:", "\n", "# \tbreak", "\n", "\n", "", "", "return", "list_of_summarization", ",", "error_counter", ",", "null_summarization_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.__init__": [[18, 23], ["sentence.sentence.sentenceWordFreq"], "methods", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.sentenceWordFreq"], ["\t", "def", "__init__", "(", "self", ",", "preproWords", ",", "originalWords", ")", ":", "\n", "# self.docName = docName", "\n", "\t\t", "self", ".", "preproWords", "=", "preproWords", "\n", "self", ".", "wordFrequencies", "=", "self", ".", "sentenceWordFreq", "(", ")", "\n", "self", ".", "originalWords", "=", "originalWords", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getDocName": [[29, 32], ["None"], "methods", ["None"], ["", "def", "getDocName", "(", "self", ")", ":", "\n", "# return self.docName", "\n", "\t\t", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getPreProWords": [[38, 40], ["None"], "methods", ["None"], ["", "def", "getPreProWords", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "preproWords", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getOriginalWords": [[47, 49], ["None"], "methods", ["None"], ["", "def", "getOriginalWords", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "originalWords", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getWordFreq": [[56, 58], ["None"], "methods", ["None"], ["", "def", "getWordFreq", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "wordFrequencies", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.sentenceWordFreq": [[65, 76], ["wordFreq.keys"], "methods", ["None"], ["", "def", "sentenceWordFreq", "(", "self", ")", ":", "\n", "\t\t", "wordFreq", "=", "{", "}", "\n", "for", "word", "in", "self", ".", "preproWords", ":", "\n", "\t\t\t", "if", "word", "not", "in", "wordFreq", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "wordFreq", "[", "word", "]", "=", "1", "\n", "", "else", ":", "\n", "# if word in stopwords.words('english'):", "\n", "# \twordFreq[word] = 1", "\n", "# else:\t\t\t", "\n", "\t\t\t\t", "wordFreq", "[", "word", "]", "=", "wordFreq", "[", "word", "]", "+", "1", "\n", "", "", "return", "wordFreq", "", "", "", ""]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.load_data": [[15, 25], ["print", "open", "dataset.append", "line.strip"], "function", ["None"], ["def", "load_data", "(", "data_path", ",", "file_name", ")", ":", "\n", "\t", "counter", "=", "0", "\n", "dataset", "=", "[", "]", "\n", "with", "open", "(", "data_path", "+", "file_name", ",", "'r'", ")", "as", "fr", ":", "\n", "\t\t", "for", "line", "in", "fr", ":", "\n", "\t\t\t", "dataset", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "counter", "+=", "1", "\n", "\n", "", "", "print", "(", "\"[Data Loaded]: %s lines has been loaded.\"", "%", "counter", ")", "\n", "return", "dataset", "\n", "#---------------------------------------------------------------------------------", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.processFile": [[33, 84], ["gensim.summarization.textcleaner.split_sentences", "nltk.PorterStemmer", "line.strip().lower.strip().lower", "nltk.word_tokenize", "nltk.PorterStemmer.stem", "sentences.append", "line.strip().lower.strip", "sentence.sentence"], "function", ["None"], ["", "def", "processFile", "(", "sample", ")", ":", "\n", "\n", "# read file from provided folder path", "\n", "# f = open(file_name,'r')", "\n", "# text_0 = f.read()", "\n", "\t", "text_0", "=", "sample", "\n", "\n", "# extract content in TEXT tag and remove tags", "\n", "# text_1 = re.search(r\"<TEXT>.*</TEXT>\",text_0, re.DOTALL)", "\n", "# text_1 = re.sub(\"<TEXT>\\n\",\"\",text_1.group(0))", "\n", "# text_1 = re.sub(\"\\n</TEXT>\",\"\",text_1)", "\n", "\n", "# # replace all types of quotations by normal quotes", "\n", "# text_1 = re.sub(\"\\n\",\" \",text_1)", "\n", "\n", "# text_1 = re.sub(\"\\\"\",\"\\\"\",text_1)", "\n", "# text_1 = re.sub(\"''\",\"\\\"\",text_1)", "\n", "# text_1 = re.sub(\"``\",\"\\\"\",text_1)\t", "\n", "\n", "# text_1 = re.sub(\" +\",\" \",text_1)", "\n", "\n", "# segment data into a list of sentences", "\n", "# sentence_token = nltk.data.load('tokenizers/punkt/english.pickle')", "\n", "# lines = sentence_token.tokenize(text_1.strip())\t", "\n", "lines", "=", "split_sentences", "(", "text_0", "+", "\"\\n\"", ")", "\n", "\n", "# setting the stemmer", "\n", "sentences", "=", "[", "]", "\n", "porter", "=", "nltk", ".", "PorterStemmer", "(", ")", "\n", "\n", "# modelling each sentence in file as sentence object", "\n", "for", "line", "in", "lines", ":", "\n", "\n", "# original words of the sentence before stemming", "\n", "\t\t", "originalWords", "=", "line", "[", ":", "]", "\n", "line", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "\n", "# word tokenization", "\n", "sent", "=", "nltk", ".", "word_tokenize", "(", "line", ")", "\n", "\n", "# stemming words", "\n", "stemmedSent", "=", "[", "porter", ".", "stem", "(", "word", ")", "for", "word", "in", "sent", "]", "\n", "# stemmedSent = filter(lambda x: x!='.'and x!='`'and x!=','and x!='?'and x!=\"'\" ", "\n", "# \tand x!='!' and x!='''\"''' and x!=\"''\" and x!=\"'s\", stemmedSent)", "\n", "\n", "# list of sentence objects", "\n", "if", "stemmedSent", "!=", "[", "]", ":", "\n", "# sentences.append(sentence.sentence(file_name, stemmedSent, originalWords))\t", "\n", "\t\t\t", "sentences", ".", "append", "(", "sentence", ".", "sentence", "(", "stemmedSent", ",", "originalWords", ")", ")", "\n", "\n", "", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.TFs": [[91, 109], ["sent.getWordFreq", "sent.getWordFreq.keys", "tfs.get"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getWordFreq"], ["", "def", "TFs", "(", "sentences", ")", ":", "\n", "# initialize tfs dictonary", "\n", "\t", "tfs", "=", "{", "}", "\n", "\n", "# for every sentence in document cluster", "\n", "for", "sent", "in", "sentences", ":", "\n", "# retrieve word frequencies from sentence object", "\n", "\t\t", "wordFreqs", "=", "sent", ".", "getWordFreq", "(", ")", "\n", "\n", "# for every word", "\n", "for", "word", "in", "wordFreqs", ".", "keys", "(", ")", ":", "\n", "# if word already present in the dictonary", "\n", "\t\t\t", "if", "tfs", ".", "get", "(", "word", ",", "0", ")", "!=", "0", ":", "\n", "\t\t\t\t", "tfs", "[", "word", "]", "=", "tfs", "[", "word", "]", "+", "wordFreqs", "[", "word", "]", "\n", "# else if word is being added for the first time", "\n", "", "else", ":", "\n", "\t\t\t\t", "tfs", "[", "word", "]", "=", "wordFreqs", "[", "word", "]", "\n", "", "", "", "return", "tfs", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.IDFs": [[116, 148], ["len", "sent.getPreProWords", "w2.append", "math.log10", "sent.getWordFreq().get", "words.get", "float", "sent.getWordFreq"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getPreProWords", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getWordFreq"], ["", "def", "IDFs", "(", "sentences", ")", ":", "\n", "    ", "N", "=", "len", "(", "sentences", ")", "\n", "idf", "=", "0", "\n", "idfs", "=", "{", "}", "\n", "words", "=", "{", "}", "\n", "w2", "=", "[", "]", "\n", "\n", "# every sentence in our cluster", "\n", "for", "sent", "in", "sentences", ":", "\n", "# print(\"In IDFs sent.getPreProWords() preproWords\", sent.preproWords)", "\n", "# every word in a sentence", "\n", "        ", "for", "word", "in", "sent", ".", "getPreProWords", "(", ")", ":", "\n", "\n", "# not to calculate a word's IDF value more than once", "\n", "            ", "if", "sent", ".", "getWordFreq", "(", ")", ".", "get", "(", "word", ",", "0", ")", "!=", "0", ":", "\n", "                ", "words", "[", "word", "]", "=", "words", ".", "get", "(", "word", ",", "0", ")", "+", "1", "\n", "\n", "# for each word in words", "\n", "", "", "", "for", "word", "in", "words", ":", "\n", "        ", "n", "=", "words", "[", "word", "]", "\n", "\n", "# avoid zero division errors", "\n", "try", ":", "\n", "            ", "w2", ".", "append", "(", "n", ")", "\n", "idf", "=", "math", ".", "log10", "(", "float", "(", "N", ")", "/", "n", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "            ", "idf", "=", "0", "\n", "\n", "# reset variables", "\n", "", "idfs", "[", "word", "]", "=", "idf", "\n", "\n", "", "return", "idfs", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.TF_IDF": [[154, 176], ["mmr_summarizer.TFs", "mmr_summarizer.IDFs", "retval.get", "retval[].append", "print"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.TFs", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.IDFs"], ["", "def", "TF_IDF", "(", "sentences", ")", ":", "\n", "# Method variables", "\n", "    ", "tfs", "=", "TFs", "(", "sentences", ")", "\n", "idfs", "=", "IDFs", "(", "sentences", ")", "\n", "retval", "=", "{", "}", "\n", "\n", "# for every word", "\n", "for", "word", "in", "tfs", ":", "\n", "#calculate every word's tf-idf score", "\n", "        ", "try", ":", "\n", "            ", "tf_idfs", "=", "tfs", "[", "word", "]", "*", "idfs", "[", "word", "]", "\n", "# print(\"OK!\", word)", "\n", "", "except", "KeyError", ":", "\n", "        \t", "print", "(", "\"No OK\"", ",", "word", ")", "\n", "\n", "# add word and its tf-idf score to dictionary", "\n", "", "if", "retval", ".", "get", "(", "tf_idfs", ",", "None", ")", "==", "None", ":", "\n", "            ", "retval", "[", "tf_idfs", "]", "=", "[", "word", "]", "\n", "", "else", ":", "\n", "            ", "retval", "[", "tf_idfs", "]", ".", "append", "(", "word", ")", "\n", "\n", "", "", "return", "retval", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.sentenceSim": [[185, 201], ["sentence2.getPreProWords", "sentence1.getPreProWords", "math.sqrt", "sentence1.getWordFreq().get", "sentence2.getWordFreq().get", "IDF_w.get", "sentence1.getWordFreq().get", "IDF_w.get", "sentence1.getWordFreq", "sentence2.getWordFreq", "sentence1.getWordFreq"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getPreProWords", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getPreProWords", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getWordFreq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getWordFreq", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getWordFreq"], ["", "def", "sentenceSim", "(", "sentence1", ",", "sentence2", ",", "IDF_w", ")", ":", "\n", "\t", "numerator", "=", "0", "\n", "denominator", "=", "0", "\n", "# print(\"sentence to compare\",sentence1.originalWords, sentence2.originalWords)", "\n", "for", "word", "in", "sentence2", ".", "getPreProWords", "(", ")", ":", "\n", "\t\t", "numerator", "+=", "sentence1", ".", "getWordFreq", "(", ")", ".", "get", "(", "word", ",", "0", ")", "*", "sentence2", ".", "getWordFreq", "(", ")", ".", "get", "(", "word", ",", "0", ")", "*", "IDF_w", ".", "get", "(", "word", ",", "0", ")", "**", "2", "\n", "\n", "", "for", "word", "in", "sentence1", ".", "getPreProWords", "(", ")", ":", "\n", "\t\t", "denominator", "+=", "(", "sentence1", ".", "getWordFreq", "(", ")", ".", "get", "(", "word", ",", "0", ")", "*", "IDF_w", ".", "get", "(", "word", ",", "0", ")", ")", "**", "2", "\n", "\n", "# check for divide by zero cases and return back minimal similarity", "\n", "", "try", ":", "\n", "\t\t", "return", "numerator", "/", "math", ".", "sqrt", "(", "denominator", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "# return float(\"-inf\")", "\n", "\t\t", "return", "sentence_sim_exception", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.buildQuery": [[209, 234], ["TF_IDF_w.keys", "sorted", "sentence.sentence", "queryWords.append"], "function", ["None"], ["", "", "def", "buildQuery", "(", "sentences", ",", "TF_IDF_w", ",", "n", ")", ":", "\n", "#sort in descending order of TF-IDF values", "\n", "\t", "scores", "=", "TF_IDF_w", ".", "keys", "(", ")", "\n", "scores", "=", "sorted", "(", "scores", ",", "reverse", "=", "True", ")", "\n", "\n", "i", "=", "0", "\n", "j", "=", "0", "\n", "queryWords", "=", "[", "]", "\n", "\n", "# print(\"n, len(scores):\", n, len(scores))", "\n", "# if len(scores) == 1:", "\n", "# \tprint(TF_IDF_w)", "\n", "# select top n words", "\n", "while", "(", "i", "<", "n", ")", ":", "\n", "\t\t", "words", "=", "TF_IDF_w", "[", "scores", "[", "j", "]", "]", "\n", "for", "word", "in", "words", ":", "\n", "\t\t\t", "queryWords", ".", "append", "(", "word", ")", "\n", "i", "=", "i", "+", "1", "\n", "if", "(", "i", ">", "n", ")", ":", "\n", "\t\t\t\t", "break", "\n", "", "", "j", "=", "j", "+", "1", "\n", "\n", "# return the top selected words as a sentence", "\n", "# return sentence.sentence(\"query\", queryWords, queryWords)", "\n", "", "return", "sentence", ".", "sentence", "(", "queryWords", ",", "queryWords", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.bestSentence": [[242, 263], ["float", "sentences.remove", "mmr_summarizer.sentenceSim", "print"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.sentenceSim"], ["", "def", "bestSentence", "(", "sentences", ",", "query", ",", "IDF", ")", ":", "\n", "\t", "best_sentence", "=", "None", "\n", "maxVal", "=", "float", "(", "\"-inf\"", ")", "\n", "\n", "for", "sent", "in", "sentences", ":", "\n", "\t\t", "similarity", "=", "sentenceSim", "(", "sent", ",", "query", ",", "IDF", ")", "\n", "\n", "if", "similarity", ">", "maxVal", ":", "\n", "\t\t\t", "best_sentence", "=", "sent", "\n", "maxVal", "=", "similarity", "\n", "# print(\"query\", query.originalWords)", "\n", "# if best_sentence == None:", "\n", "# print([ sent.originalWords for sent in sentences ])", "\n", "", "", "global", "counter_sim_devide0", "\n", "# print(\"maxVal\", maxVal)", "\n", "if", "maxVal", "==", "sentence_sim_exception", ":", "\n", "\t\t", "print", "(", "\"Some errors\"", ")", "\n", "counter_sim_devide0", "+=", "1", "\n", "", "sentences", ".", "remove", "(", "best_sentence", ")", "\n", "\n", "return", "best_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.makeSummary": [[274, 293], ["len", "best_sentence.getPreProWords", "max", "summary.append", "sentences.remove", "len", "len", "mmr_summarizer.MMRScore", "max.getPreProWords"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getPreProWords", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.MMRScore", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.sentence.sentence.getPreProWords"], ["", "def", "makeSummary", "(", "sentences", ",", "best_sentence", ",", "query", ",", "summary_length", ",", "lambta", ",", "IDF", ")", ":", "\n", "\t", "summary", "=", "[", "best_sentence", "]", "\n", "sum_len", "=", "len", "(", "best_sentence", ".", "getPreProWords", "(", ")", ")", "\n", "\n", "MMRval", "=", "{", "}", "\n", "\n", "# keeping adding sentences until number of words exceeds summary length", "\n", "while", "(", "sum_len", "<", "summary_length", "and", "len", "(", "sentences", ")", "!=", "0", ")", ":", "\n", "\t\t", "MMRval", "=", "{", "}", "\n", "\n", "for", "sent", "in", "sentences", ":", "\n", "\t\t\t", "MMRval", "[", "sent", "]", "=", "MMRScore", "(", "sent", ",", "query", ",", "summary", ",", "lambta", ",", "IDF", ")", "\n", "\n", "", "maxxer", "=", "max", "(", "MMRval", ",", "key", "=", "MMRval", ".", "get", ")", "\n", "summary", ".", "append", "(", "maxxer", ")", "\n", "sentences", ".", "remove", "(", "maxxer", ")", "\n", "sum_len", "+=", "len", "(", "maxxer", ".", "getPreProWords", "(", ")", ")", "\n", "\n", "", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.MMRScore": [[304, 318], ["mmr_summarizer.sentenceSim", "float", "mmr_summarizer.sentenceSim", "value.append", "max"], "function", ["home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.sentenceSim", "home.repos.pwc.inspect_result.Alex-Fabbri_Multi-News.mmr.mmr_summarizer.sentenceSim"], ["", "def", "MMRScore", "(", "Si", ",", "query", ",", "Sj", ",", "lambta", ",", "IDF", ")", ":", "\n", "\t", "Sim1", "=", "sentenceSim", "(", "Si", ",", "query", ",", "IDF", ")", "\n", "l_expr", "=", "lambta", "*", "Sim1", "\n", "value", "=", "[", "float", "(", "\"-inf\"", ")", "]", "\n", "\n", "for", "sent", "in", "Sj", ":", "\n", "\t\t", "Sim2", "=", "sentenceSim", "(", "Si", ",", "sent", ",", "IDF", ")", "\n", "value", ".", "append", "(", "Sim2", ")", "\n", "\n", "", "r_expr", "=", "(", "1", "-", "lambta", ")", "*", "max", "(", "value", ")", "\n", "MMR_SCORE", "=", "l_expr", "-", "r_expr", "\n", "\n", "# return MMRScore", "\n", "return", "l_expr", "-", "r_expr", "\n", "\n"]]}