{"home.repos.pwc.inspect_result.princeton-nlp_semsup.None.run.parse_arg_with_default": [[15, 21], ["getattr", "getattr", "Exception"], "function", ["None"], ["def", "parse_arg_with_default", "(", "default_config", ",", "args", ",", "key", ",", "required", "=", "False", ")", ":", "\n", "    ", "default", "=", "default_config", "[", "key", "]", "if", "key", "in", "default_config", "else", "None", "\n", "ret", "=", "getattr", "(", "args", ",", "key", ")", "if", "getattr", "(", "args", ",", "key", ")", "else", "default", "\n", "if", "required", "and", "ret", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "f\"{key} is a required argument\"", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.None.run_eval.parse_arg_with_default": [[16, 22], ["getattr", "getattr", "Exception"], "function", ["None"], ["def", "parse_arg_with_default", "(", "default_config", ",", "args", ",", "key", ",", "required", "=", "False", ")", ":", "\n", "    ", "default", "=", "default_config", "[", "key", "]", "if", "key", "in", "default_config", "else", "None", "\n", "ret", "=", "getattr", "(", "args", ",", "key", ")", "if", "getattr", "(", "args", ",", "key", ")", "else", "default", "\n", "if", "required", "and", "ret", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "f\"{key} is a required argument\"", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.run_rcv1.run_rcv1_label_descriptions.main": [[70, 429], ["transformers.HfArgumentParser", "logging.basicConfig", "training_args.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "logger.info", "transformers.set_seed", "data_files.keys", "data_args.train_file.endswith", "list.sort", "len", "src.get_label_lists", "transformers.AutoConfig.from_pretrained", "src.modify_config", "transformers.AutoTokenizer.from_pretrained", "src.AutoModelForSemanticEmbedding.from_pretrained", "src.get_label_embedding_model", "src.LabelDescriptionsDataloaderBase", "min", "src.RCV1TrainerLabelDescriptions", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "logger.info", "datasets.load_dataset", "datasets.load_dataset", "datasets.load_dataset", "list", "logger.warning", "AutoTokenizer.from_pretrained.", "training_args.main_process_first", "raw_datasets.map.map", "random.sample", "src.multilabel_label_descriptions_ranking_metrics", "src.RCV1TrainerLabelDescriptions.train", "min", "src.RCV1TrainerLabelDescriptions.save_model", "src.RCV1TrainerLabelDescriptions.log_metrics", "src.RCV1TrainerLabelDescriptions.save_metrics", "src.RCV1TrainerLabelDescriptions.save_state", "logger.info", "zip", "logger.info", "zip", "src.RCV1TrainerLabelDescriptions.push_to_hub", "src.RCV1TrainerLabelDescriptions.create_model_card", "len", "ValueError", "ValueError", "set", "bool", "enumerate", "src.modify_config.label2id.items", "ValueError", "train_dataset.select.select", "ValueError", "eval_dataset.select.select", "ValueError", "predict_dataset.select.select", "range", "logger.info", "transformers.DataCollatorWithPadding", "len", "len", "src.RCV1TrainerLabelDescriptions.evaluate", "trainer.evaluate.pop", "min", "src.RCV1TrainerLabelDescriptions.log_metrics", "src.RCV1TrainerLabelDescriptions.save_metrics", "src.multilabel_label_descriptions_ranking_metrics", "src.RCV1TrainerLabelDescriptions.evaluate", "trainer.evaluate.pop", "min", "src.RCV1TrainerLabelDescriptions.log_metrics", "src.RCV1TrainerLabelDescriptions.save_metrics", "os.path.abspath", "logging.StreamHandler", "len", "logger.info", "data_args.train_file.split", "data_args.test_file.split", "itertools.chain", "range", "range", "range", "len", "len", "len", "len", "len", "data_args.task_name.upper", "bool", "os.listdir", "range", "len"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.get_label_lists", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.modify_config", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.get_label_embedding_model", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_label_descriptions_ranking_metrics", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.evaluate", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_label_descriptions_ranking_metrics", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.evaluate"], ["def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", "and", "training_args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)", "\n", "# or specify a GLUE benchmark task (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use as labels the column called 'label' and as pair of sentences the", "\n", "# sentences in columns called 'sentence1' and 'sentence2' if such column exists or the first two columns not named", "\n", "# label if at least two columns are provided.", "\n", "#", "\n", "# If the CSVs/JSONs contain only one non-label column, the script does single sentence classification on this", "\n", "# single column. You can easily tweak this behavior (see below)", "\n", "\n", "\n", "# Load the RCV1 datasets", "\n", "\n", "# Loading a dataset from your local files.", "\n", "# CSV/JSON training and evaluation files are needed.", "\n", "data_files", "=", "{", "\"train\"", ":", "data_args", ".", "train_file", ",", "\"validation\"", ":", "data_args", ".", "validation_file", "}", "\n", "\n", "# Get the test dataset: you can provide your own CSV/JSON test file (see below)", "\n", "# when you use `do_predict` without specifying a GLUE benchmark task.", "\n", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "if", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "            ", "train_extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "test_extension", "=", "data_args", ".", "test_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "(", "\n", "test_extension", "==", "train_extension", "\n", ")", ",", "\"`test_file` should have the same extension (csv or json) as `train_file`.\"", "\n", "data_files", "[", "\"test\"", "]", "=", "data_args", ".", "test_file", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a GLUE task or a test file for `do_predict`.\"", ")", "\n", "\n", "", "", "for", "key", "in", "data_files", ".", "keys", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"load a local file for {key}: {data_files[key]}\"", ")", "\n", "\n", "", "if", "data_args", ".", "train_file", ".", "endswith", "(", "\".csv\"", ")", ":", "\n", "# Loading a dataset from local csv files", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\"csv\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "# Loading a dataset from local json files", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\"json\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "\n", "# See more about loading any type of standard or custom dataset at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Labels", "\n", "", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "# Use the data file which contains all the data so that the label2id and id2label dictionaries can be frozen", "\n", "        ", "all_data_dataset", "=", "load_dataset", "(", "\"json\"", ",", "data_files", "=", "{", "\"train\"", ":", "data_args", ".", "all_labels_file", "}", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "label_list", "=", "list", "(", "set", "(", "itertools", ".", "chain", "(", "*", "all_data_dataset", "[", "\"train\"", "]", "[", "\"bip:topics:1.0\"", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "(", "\"Support available only for 'rcv1' dataset right now.\"", ")", "\n", "", "label_list", ".", "sort", "(", ")", "# Let's sort it for determinism", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "# TODO: Might have to get 'bip:industries:1.0' and 'bip:countries:1.0' labels as well", "\n", "\n", "# Get label lists for train, validation, and test", "\n", "label_list_dict", "=", "get_label_lists", "(", "raw_datasets", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "data_args", ".", "task_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "# Modify the config to mention that it is a multi-label classification problem", "\n", "config", "=", "modify_config", "(", "config", ",", "data_args", ",", "model_args", ")", "\n", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForSemanticEmbedding", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# Preprocessing the raw_datasets", "\n", "# RCV1 specific preprocessing", "\n", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "        ", "sentence1_key", ",", "sentence2_key", "=", "\"text\"", ",", "None", "\n", "label_key", "=", "\"bip:topics:1.0\"", "\n", "\n", "# Padding strategy", "\n", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "padding", "=", "\"max_length\"", "\n", "", "else", ":", "\n", "# We will pad later, dynamically at batch creation, to the max sequence length in each batch", "\n", "        ", "padding", "=", "False", "\n", "\n", "# Some models have set the order of the labels to use, so let's make sure we do use it.", "\n", "", "model", ".", "config", ".", "label2id", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "label_list", ")", "}", "\n", "label_to_id", "=", "model", ".", "config", ".", "label2id", "\n", "model", ".", "config", ".", "id2label", "=", "{", "id", ":", "label", "for", "label", ",", "id", "in", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "\n", "# label_to_id = None", "\n", "# if (", "\n", "#     model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id", "\n", "#     and data_args.task_name is not None", "\n", "# ):", "\n", "#     # Some have all caps in their config, some don't.", "\n", "#     # BUG: This is a HF bug. Don't do lower here.", "\n", "#     # BUG: label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}", "\n", "#     label_name_to_id = {k: v for k, v in model.config.label2id.items()}", "\n", "#     if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):", "\n", "#         label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}", "\n", "#     else:", "\n", "#         logger.warning(", "\n", "#             \"Your model seems to have been trained with labels, but they don't match the dataset: \",", "\n", "#             f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"", "\n", "#             \"\\nIgnoring the model labels as a result.\",", "\n", "#         )", "\n", "# else:", "\n", "#     label_to_id = {v: i for i, v in enumerate(label_list)}", "\n", "\n", "# if label_to_id is not None:", "\n", "#     model.config.label2id = label_to_id", "\n", "#     model.config.id2label = {id: label for label, id in config.label2id.items()}", "\n", "# elif data_args.task_name is not None:", "\n", "#     model.config.label2id = {l: i for i, l in enumerate(label_list)}", "\n", "#     model.config.id2label = {id: label for label, id in config.label2id.items()}", "\n", "\n", "# Instantiate the label embedding model", "\n", "# model now has model.label_model_name, model.label_model, model.label_tokenizer", "\n", "model", "=", "get_label_embedding_model", "(", "model", ",", "data_args", ",", "model_args", ")", "\n", "\n", "# Get the label dataset object", "\n", "label_descriptions_dataloader", "=", "LabelDescriptionsDataloaderBase", "(", "\n", "data_args", ",", "\n", "training_args", ",", "\n", "model", ".", "label_tokenizer", ",", "\n", "label_list_dict", ",", "\n", "model", ".", "config", ".", "label2id", ",", "\n", "model", ".", "config", ".", "id2label", "\n", ")", "\n", "\n", "if", "data_args", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "max_seq_length", "=", "min", "(", "data_args", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "        ", "args", "=", "(", "\n", "(", "examples", "[", "sentence1_key", "]", ",", ")", "if", "sentence2_key", "is", "None", "else", "(", "examples", "[", "sentence1_key", "]", ",", "examples", "[", "sentence2_key", "]", ")", "\n", ")", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "\n", "# Map labels to IDs (not necessary for GLUE tasks)", "\n", "if", "label_to_id", "is", "not", "None", "and", "label_key", "in", "examples", ":", "\n", "# NOTE: Multi-label dataset", "\n", "# 0 if that label is not present, 1 if the label is present.", "\n", "            ", "result", "[", "\"label\"", "]", "=", "[", "[", "0", "if", "model", ".", "config", ".", "id2label", "[", "i", "]", "not", "in", "l", "else", "1", "for", "i", "in", "range", "(", "len", "(", "label_to_id", ")", ")", "]", "for", "l", "in", "examples", "[", "label_key", "]", "]", "\n", "", "return", "result", "\n", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"dataset map pre-processing\"", ")", ":", "\n", "        ", "raw_datasets", "=", "raw_datasets", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on dataset\"", ",", "\n", ")", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "\"train\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_train requires a train dataset\"", ")", "\n", "", "train_dataset", "=", "raw_datasets", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "if", "\"validation\"", "not", "in", "raw_datasets", "and", "\"validation_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_eval requires a validation dataset\"", ")", "\n", "", "eval_dataset", "=", "raw_datasets", "[", "\"validation_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"validation\"", "]", "\n", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_eval_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", "and", "(", "data_args", ".", "task_name", "is", "not", "None", "or", "data_args", ".", "test_file", "is", "not", "None", ")", ":", "\n", "        ", "if", "\"test\"", "not", "in", "raw_datasets", "and", "\"test_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_predict requires a test dataset\"", ")", "\n", "", "predict_dataset", "=", "raw_datasets", "[", "\"test_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"test\"", "]", "\n", "if", "data_args", ".", "max_predict_samples", "is", "not", "None", ":", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_predict_samples", ")", ")", "\n", "\n", "# Log a few random samples from the training set:", "\n", "", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "for", "index", "in", "random", ".", "sample", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ",", "3", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Sample {index} of the training set: {train_dataset[index]}.\"", ")", "\n", "\n", "# Get the metric function", "\n", "", "", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "        ", "compute_metrics", "=", "multilabel_label_descriptions_ranking_metrics", "(", "data_args", ",", "model", ".", "config", ".", "id2label", ",", "model", ".", "config", ".", "label2id", ",", "label_list_dict", ",", "{", "}", ")", "\n", "", "else", ":", "\n", "        ", "raise", "(", "\"Only RCV1 supported.\"", ")", "\n", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.", "\n", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "elif", "training_args", ".", "fp16", ":", "\n", "        ", "data_collator", "=", "DataCollatorWithPadding", "(", "tokenizer", ",", "pad_to_multiple_of", "=", "8", ")", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "None", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "RCV1TrainerLabelDescriptions", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "label_descriptions_dataloader", "=", "label_descriptions_dataloader", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "if", "training_args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "training_args", ".", "resume_from_checkpoint", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "last_checkpoint", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "max_train_samples", "=", "(", "\n", "data_args", ".", "max_train_samples", "if", "data_args", ".", "max_train_samples", "is", "not", "None", "else", "len", "(", "train_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "min", "(", "max_train_samples", ",", "len", "(", "train_dataset", ")", ")", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "tasks", "=", "[", "data_args", ".", "task_name", "]", "\n", "eval_datasets", "=", "[", "eval_dataset", "]", "\n", "\n", "for", "eval_dataset", ",", "task", "in", "zip", "(", "eval_datasets", ",", "tasks", ")", ":", "\n", "            ", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "eval_dataset", ")", "\n", "\n", "# Pop the key 'fbr' so that it can be passed to the predict block below", "\n", "fbr", "=", "metrics", ".", "pop", "(", "'eval_fbr'", ")", "\n", "\n", "max_eval_samples", "=", "(", "\n", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "# Prediction", "\n", "", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "tasks", "=", "[", "data_args", ".", "task_name", "]", "\n", "eval_datasets", "=", "[", "predict_dataset", "]", "\n", "\n", "# New metric function using the fbr computed on the validation set", "\n", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "            ", "compute_metrics", "=", "multilabel_label_descriptions_ranking_metrics", "(", "data_args", ",", "model", ".", "config", ".", "id2label", ",", "model", ".", "config", ".", "label2id", ",", "label_list_dict", ",", "fbr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "(", "\"Only RCV1 supported.\"", ")", "\n", "", "trainer", ".", "compute_metrics", "=", "compute_metrics", "\n", "\n", "for", "eval_dataset", ",", "task", "in", "zip", "(", "eval_datasets", ",", "tasks", ")", ":", "\n", "            ", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "eval_dataset", ",", "metric_key_prefix", "=", "\"predict\"", ")", "\n", "metrics", ".", "pop", "(", "\"predict_fbr\"", ")", "\n", "\n", "max_eval_samples", "=", "(", "\n", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"predict\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"predict\"", ",", "metrics", ")", "\n", "\n", "", "", "kwargs", "=", "{", "\"finetuned_from\"", ":", "model_args", ".", "model_name_or_path", ",", "\"tasks\"", ":", "\"text-classification\"", "}", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "kwargs", "[", "\"language\"", "]", "=", "\"en\"", "\n", "kwargs", "[", "\"dataset_tags\"", "]", "=", "\"glue\"", "\n", "kwargs", "[", "\"dataset_args\"", "]", "=", "data_args", ".", "task_name", "\n", "kwargs", "[", "\"dataset\"", "]", "=", "f\"GLUE {data_args.task_name.upper()}\"", "\n", "\n", "", "if", "training_args", ".", "push_to_hub", ":", "\n", "        ", "trainer", ".", "push_to_hub", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "create_model_card", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.run_rcv1.run_rcv1_label_descriptions._mp_fn": [[431, 434], ["run_rcv1_label_descriptions.main"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.main"], ["", "", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.run_rcv1.run_rcv1_word2vec_descriptions.main": [[72, 432], ["transformers.HfArgumentParser", "logging.basicConfig", "training_args.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "logger.info", "transformers.set_seed", "data_files.keys", "data_args.train_file.endswith", "list.sort", "len", "src.get_label_lists", "transformers.AutoConfig.from_pretrained", "src.modify_config", "transformers.AutoTokenizer.from_pretrained", "src.AutoModelForWord2vec.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "src.LabelDescriptionsDataloaderWord2Vec", "min", "src.RCV1TrainerLabelDescriptions", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "logger.info", "datasets.load_dataset", "datasets.load_dataset", "datasets.load_dataset", "list", "logger.warning", "AutoTokenizer.from_pretrained.", "training_args.main_process_first", "raw_datasets.map.map", "random.sample", "src.multilabel_label_descriptions_ranking_metrics", "src.RCV1TrainerLabelDescriptions.train", "min", "src.RCV1TrainerLabelDescriptions.save_model", "src.RCV1TrainerLabelDescriptions.log_metrics", "src.RCV1TrainerLabelDescriptions.save_metrics", "src.RCV1TrainerLabelDescriptions.save_state", "logger.info", "zip", "logger.info", "zip", "src.RCV1TrainerLabelDescriptions.push_to_hub", "src.RCV1TrainerLabelDescriptions.create_model_card", "len", "ValueError", "ValueError", "set", "bool", "enumerate", "src.modify_config.label2id.items", "ValueError", "train_dataset.select.select", "ValueError", "eval_dataset.select.select", "ValueError", "predict_dataset.select.select", "range", "logger.info", "transformers.DataCollatorWithPadding", "len", "len", "src.RCV1TrainerLabelDescriptions.evaluate", "trainer.evaluate.pop", "min", "src.RCV1TrainerLabelDescriptions.log_metrics", "src.RCV1TrainerLabelDescriptions.save_metrics", "src.multilabel_label_descriptions_ranking_metrics", "src.RCV1TrainerLabelDescriptions.evaluate", "trainer.evaluate.pop", "min", "src.RCV1TrainerLabelDescriptions.log_metrics", "src.RCV1TrainerLabelDescriptions.save_metrics", "os.path.abspath", "logging.StreamHandler", "len", "logger.info", "data_args.train_file.split", "data_args.test_file.split", "itertools.chain", "range", "range", "range", "len", "len", "len", "len", "len", "data_args.task_name.upper", "bool", "os.listdir", "range", "len"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.get_label_lists", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.modify_config", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_label_descriptions_ranking_metrics", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.evaluate", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_label_descriptions_ranking_metrics", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.evaluate"], ["def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", "and", "training_args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)", "\n", "# or specify a GLUE benchmark task (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use as labels the column called 'label' and as pair of sentences the", "\n", "# sentences in columns called 'sentence1' and 'sentence2' if such column exists or the first two columns not named", "\n", "# label if at least two columns are provided.", "\n", "#", "\n", "# If the CSVs/JSONs contain only one non-label column, the script does single sentence classification on this", "\n", "# single column. You can easily tweak this behavior (see below)", "\n", "\n", "\n", "# Load the RCV1 datasets", "\n", "\n", "# Loading a dataset from your local files.", "\n", "# CSV/JSON training and evaluation files are needed.", "\n", "data_files", "=", "{", "\"train\"", ":", "data_args", ".", "train_file", ",", "\"validation\"", ":", "data_args", ".", "validation_file", "}", "\n", "\n", "# Get the test dataset: you can provide your own CSV/JSON test file (see below)", "\n", "# when you use `do_predict` without specifying a GLUE benchmark task.", "\n", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "if", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "            ", "train_extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "test_extension", "=", "data_args", ".", "test_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "(", "\n", "test_extension", "==", "train_extension", "\n", ")", ",", "\"`test_file` should have the same extension (csv or json) as `train_file`.\"", "\n", "data_files", "[", "\"test\"", "]", "=", "data_args", ".", "test_file", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a GLUE task or a test file for `do_predict`.\"", ")", "\n", "\n", "", "", "for", "key", "in", "data_files", ".", "keys", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"load a local file for {key}: {data_files[key]}\"", ")", "\n", "\n", "", "if", "data_args", ".", "train_file", ".", "endswith", "(", "\".csv\"", ")", ":", "\n", "# Loading a dataset from local csv files", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\"csv\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "# Loading a dataset from local json files", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\"json\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "\n", "# See more about loading any type of standard or custom dataset at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Labels", "\n", "", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "# Use the data file which contains all the data so that the label2id and id2label dictionaries can be frozen", "\n", "        ", "all_data_dataset", "=", "load_dataset", "(", "\"json\"", ",", "data_files", "=", "{", "\"train\"", ":", "data_args", ".", "all_labels_file", "}", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "label_list", "=", "list", "(", "set", "(", "itertools", ".", "chain", "(", "*", "all_data_dataset", "[", "\"train\"", "]", "[", "\"bip:topics:1.0\"", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "(", "\"Support available only for 'rcv1' dataset right now.\"", ")", "\n", "", "label_list", ".", "sort", "(", ")", "# Let's sort it for determinism", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "# TODO: Might have to get 'bip:industries:1.0' and 'bip:countries:1.0' labels as well", "\n", "\n", "# Get label lists for train, validation, and test", "\n", "label_list_dict", "=", "get_label_lists", "(", "raw_datasets", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "data_args", ".", "task_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "# Modify the config to mention that it is a multi-label classification problem", "\n", "config", "=", "modify_config", "(", "config", ",", "data_args", ",", "model_args", ")", "\n", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForWord2vec", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# Preprocessing the raw_datasets", "\n", "# RCV1 specific preprocessing", "\n", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "        ", "sentence1_key", ",", "sentence2_key", "=", "\"text\"", ",", "None", "\n", "label_key", "=", "\"bip:topics:1.0\"", "\n", "\n", "# Padding strategy", "\n", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "padding", "=", "\"max_length\"", "\n", "", "else", ":", "\n", "# We will pad later, dynamically at batch creation, to the max sequence length in each batch", "\n", "        ", "padding", "=", "False", "\n", "\n", "# Some models have set the order of the labels to use, so let's make sure we do use it.", "\n", "", "model", ".", "config", ".", "label2id", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "label_list", ")", "}", "\n", "label_to_id", "=", "model", ".", "config", ".", "label2id", "\n", "model", ".", "config", ".", "id2label", "=", "{", "id", ":", "label", "for", "label", ",", "id", "in", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "\n", "# label_to_id = None", "\n", "# if (", "\n", "#     model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id", "\n", "#     and data_args.task_name is not None", "\n", "# ):", "\n", "#     # Some have all caps in their config, some don't.", "\n", "#     # BUG: This is a HF bug. Don't do lower here.", "\n", "#     # BUG: label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}", "\n", "#     label_name_to_id = {k: v for k, v in model.config.label2id.items()}", "\n", "#     if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):", "\n", "#         label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}", "\n", "#     else:", "\n", "#         logger.warning(", "\n", "#             \"Your model seems to have been trained with labels, but they don't match the dataset: \",", "\n", "#             f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"", "\n", "#             \"\\nIgnoring the model labels as a result.\",", "\n", "#         )", "\n", "# else:", "\n", "#     label_to_id = {v: i for i, v in enumerate(label_list)}", "\n", "\n", "# if label_to_id is not None:", "\n", "#     model.config.label2id = label_to_id", "\n", "#     model.config.id2label = {id: label for label, id in config.label2id.items()}", "\n", "# elif data_args.task_name is not None:", "\n", "#     model.config.label2id = {l: i for i, l in enumerate(label_list)}", "\n", "#     model.config.id2label = {id: label for label, id in config.label2id.items()}", "\n", "\n", "# Instantiate the label embedding model", "\n", "# model now has model.label_model_name, model.label_model, model.label_tokenizer", "\n", "# model = get_label_embedding_model(model, data_args, model_args)", "\n", "label_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "data_args", ".", "label_model_name_or_path", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ")", "\n", "\n", "# Get the label dataset object", "\n", "label_descriptions_dataloader", "=", "LabelDescriptionsDataloaderWord2Vec", "(", "\n", "data_args", ",", "\n", "training_args", ",", "\n", "label_tokenizer", ",", "\n", "label_list_dict", ",", "\n", "model", ".", "config", ".", "label2id", ",", "\n", "model", ".", "config", ".", "id2label", "\n", ")", "\n", "\n", "if", "data_args", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "max_seq_length", "=", "min", "(", "data_args", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "        ", "args", "=", "(", "\n", "(", "examples", "[", "sentence1_key", "]", ",", ")", "if", "sentence2_key", "is", "None", "else", "(", "examples", "[", "sentence1_key", "]", ",", "examples", "[", "sentence2_key", "]", ")", "\n", ")", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "\n", "# Map labels to IDs (not necessary for GLUE tasks)", "\n", "if", "label_to_id", "is", "not", "None", "and", "label_key", "in", "examples", ":", "\n", "# NOTE: Multi-label dataset", "\n", "# 0 if that label is not present, 1 if the label is present.", "\n", "            ", "result", "[", "\"label\"", "]", "=", "[", "[", "0", "if", "model", ".", "config", ".", "id2label", "[", "i", "]", "not", "in", "l", "else", "1", "for", "i", "in", "range", "(", "len", "(", "label_to_id", ")", ")", "]", "for", "l", "in", "examples", "[", "label_key", "]", "]", "\n", "", "return", "result", "\n", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"dataset map pre-processing\"", ")", ":", "\n", "        ", "raw_datasets", "=", "raw_datasets", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on dataset\"", ",", "\n", ")", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "\"train\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_train requires a train dataset\"", ")", "\n", "", "train_dataset", "=", "raw_datasets", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "if", "\"validation\"", "not", "in", "raw_datasets", "and", "\"validation_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_eval requires a validation dataset\"", ")", "\n", "", "eval_dataset", "=", "raw_datasets", "[", "\"validation_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"validation\"", "]", "\n", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_eval_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", "and", "(", "data_args", ".", "task_name", "is", "not", "None", "or", "data_args", ".", "test_file", "is", "not", "None", ")", ":", "\n", "        ", "if", "\"test\"", "not", "in", "raw_datasets", "and", "\"test_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_predict requires a test dataset\"", ")", "\n", "", "predict_dataset", "=", "raw_datasets", "[", "\"test_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"test\"", "]", "\n", "if", "data_args", ".", "max_predict_samples", "is", "not", "None", ":", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_predict_samples", ")", ")", "\n", "\n", "# Log a few random samples from the training set:", "\n", "", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "for", "index", "in", "random", ".", "sample", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ",", "3", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Sample {index} of the training set: {train_dataset[index]}.\"", ")", "\n", "\n", "# Get the metric function", "\n", "", "", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "        ", "compute_metrics", "=", "multilabel_label_descriptions_ranking_metrics", "(", "data_args", ",", "model", ".", "config", ".", "id2label", ",", "model", ".", "config", ".", "label2id", ",", "label_list_dict", ",", "{", "}", ")", "\n", "", "else", ":", "\n", "        ", "raise", "(", "\"Only RCV1 supported.\"", ")", "\n", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.", "\n", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "elif", "training_args", ".", "fp16", ":", "\n", "        ", "data_collator", "=", "DataCollatorWithPadding", "(", "tokenizer", ",", "pad_to_multiple_of", "=", "8", ")", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "None", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "RCV1TrainerLabelDescriptions", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "label_descriptions_dataloader", "=", "label_descriptions_dataloader", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "if", "training_args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "training_args", ".", "resume_from_checkpoint", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "last_checkpoint", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "max_train_samples", "=", "(", "\n", "data_args", ".", "max_train_samples", "if", "data_args", ".", "max_train_samples", "is", "not", "None", "else", "len", "(", "train_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "min", "(", "max_train_samples", ",", "len", "(", "train_dataset", ")", ")", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "tasks", "=", "[", "data_args", ".", "task_name", "]", "\n", "eval_datasets", "=", "[", "eval_dataset", "]", "\n", "\n", "for", "eval_dataset", ",", "task", "in", "zip", "(", "eval_datasets", ",", "tasks", ")", ":", "\n", "            ", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "eval_dataset", ")", "\n", "\n", "# Pop the key 'fbr' so that it can be passed to the predict block below", "\n", "fbr", "=", "metrics", ".", "pop", "(", "'eval_fbr'", ")", "\n", "\n", "max_eval_samples", "=", "(", "\n", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "# Prediction", "\n", "", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "tasks", "=", "[", "data_args", ".", "task_name", "]", "\n", "eval_datasets", "=", "[", "predict_dataset", "]", "\n", "\n", "# New metric function using the fbr computed on the validation set", "\n", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "            ", "compute_metrics", "=", "multilabel_label_descriptions_ranking_metrics", "(", "data_args", ",", "model", ".", "config", ".", "id2label", ",", "model", ".", "config", ".", "label2id", ",", "label_list_dict", ",", "fbr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "(", "\"Only RCV1 supported.\"", ")", "\n", "", "trainer", ".", "compute_metrics", "=", "compute_metrics", "\n", "\n", "for", "eval_dataset", ",", "task", "in", "zip", "(", "eval_datasets", ",", "tasks", ")", ":", "\n", "            ", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "eval_dataset", ",", "metric_key_prefix", "=", "\"predict\"", ")", "\n", "metrics", ".", "pop", "(", "\"predict_fbr\"", ")", "\n", "\n", "max_eval_samples", "=", "(", "\n", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"predict\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"predict\"", ",", "metrics", ")", "\n", "\n", "", "", "kwargs", "=", "{", "\"finetuned_from\"", ":", "model_args", ".", "model_name_or_path", ",", "\"tasks\"", ":", "\"text-classification\"", "}", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "kwargs", "[", "\"language\"", "]", "=", "\"en\"", "\n", "kwargs", "[", "\"dataset_tags\"", "]", "=", "\"glue\"", "\n", "kwargs", "[", "\"dataset_args\"", "]", "=", "data_args", ".", "task_name", "\n", "kwargs", "[", "\"dataset\"", "]", "=", "f\"GLUE {data_args.task_name.upper()}\"", "\n", "\n", "", "if", "training_args", ".", "push_to_hub", ":", "\n", "        ", "trainer", ".", "push_to_hub", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "create_model_card", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.run_rcv1.run_rcv1_word2vec_descriptions._mp_fn": [[434, 437], ["run_rcv1_word2vec_descriptions.main"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.main"], ["", "", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.training_arguments.DataTrainingArguments.__post_init__": [[101, 116], ["training_arguments.DataTrainingArguments.task_name.lower", "ValueError", "training_arguments.DataTrainingArguments.train_file.split", "training_arguments.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "task_name", "is", "not", "None", ":", "\n", "            ", "self", ".", "task_name", "=", "self", ".", "task_name", ".", "lower", "(", ")", "\n", "# TODO: Assert that the task_name is one of the allowed datasets", "\n", "", "elif", "self", ".", "dataset_name", "is", "not", "None", ":", "\n", "            ", "pass", "\n", "", "elif", "self", ".", "train_file", "is", "None", "or", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a GLUE task, a training/validation file or a dataset name.\"", ")", "\n", "", "else", ":", "\n", "            ", "train_extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "train_extension", "in", "[", "\"csv\"", ",", "\"json\"", "]", ",", "\"`train_file` should be a csv or a json file.\"", "\n", "validation_extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "(", "\n", "validation_extension", "==", "train_extension", "\n", ")", ",", "\"`validation_file` should have the same extension (csv or json) as `train_file`.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForSemanticEmbedding.from_pretrained": [[43, 53], ["MODEL_TO_CONFIG.keys", "MODEL_FOR_SEMANTIC_EMBEDDING.keys", "type", "getattr", "getattr.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["@", "staticmethod", "\n", "def", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Check what type of model it is", "\n", "        ", "for", "key", "in", "MODEL_TO_CONFIG", ".", "keys", "(", ")", ":", "\n", "            ", "if", "type", "(", "kwargs", "[", "'config'", "]", ")", "==", "MODEL_TO_CONFIG", "[", "key", "]", ":", "\n", "                ", "class_name", "=", "getattr", "(", "sys", ".", "modules", "[", "__name__", "]", ",", "MODEL_FOR_SEMANTIC_EMBEDDING", "[", "key", "]", ")", "\n", "return", "class_name", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# If none of the models were chosen", "\n", "", "", "raise", "(", "\"This model type is not supported. Please choose one of {}\"", ".", "format", "(", "MODEL_FOR_SEMANTIC_EMBEDDING", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained": [[61, 71], ["MODEL_TO_CONFIG.keys", "MODEL_FOR_WORD2VEC.keys", "type", "getattr", "getattr.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["@", "staticmethod", "\n", "def", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Check what type of model it is", "\n", "        ", "for", "key", "in", "MODEL_TO_CONFIG", ".", "keys", "(", ")", ":", "\n", "            ", "if", "type", "(", "kwargs", "[", "'config'", "]", ")", "==", "MODEL_TO_CONFIG", "[", "key", "]", ":", "\n", "                ", "class_name", "=", "getattr", "(", "sys", ".", "modules", "[", "__name__", "]", ",", "MODEL_FOR_WORD2VEC", "[", "key", "]", ")", "\n", "return", "class_name", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# If none of the models were chosen", "\n", "", "", "raise", "(", "\"This model type is not supported. Please choose one of {}\"", ".", "format", "(", "MODEL_FOR_WORD2VEC", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.RobertaForSemanticEmbedding.__init__": [[187, 198], ["transformers.models.roberta.modeling_roberta.RobertaPreTrainedModel.__init__", "transformers.models.roberta.modeling_roberta.RobertaModel", "models.RobertaForSemanticEmbedding.post_init", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "# self.label_model is initialized by the training script", "\n", "\n", "# Projection layer for label embedding model", "\n", "if", "not", "self", ".", "config", ".", "share_label_model", ":", "\n", "            ", "self", ".", "label_projection", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "label_model_hidden_size", ")", "\n", "\n", "# Initialize weights and apply final processing", "\n", "", "self", ".", "post_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.RobertaForSemanticEmbedding.forward": [[199, 240], ["input_loader.pop", "models.RobertaForSemanticEmbedding.roberta", "label_loader.keys", "models.semantic_model_forward_pass", "label_loader.pop", "torch.squeeze", "torch.set_grad_enabled", "models.RobertaForSemanticEmbedding.roberta", "models.RobertaForSemanticEmbedding.label_model"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.semantic_model_forward_pass"], ["", "def", "forward", "(", "self", ",", "input_loader", "=", "None", ",", "label_loader", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :input_loader contains the inputs to be fed to self.roberta\n        :label_loader contains the inputs to be fed to \n        \"\"\"", "\n", "\n", "# STEP 1: Store the labels", "\n", "# During training, some classes might be held-out", "\n", "# Mask those classes so that they are not treated as negatives", "\n", "labels", "=", "input_loader", ".", "pop", "(", "'labels'", ")", "\n", "represented_labels", "=", "label_loader", ".", "pop", "(", "'represented_labels'", ")", "[", "0", "]", "\n", "labels", "=", "labels", "[", ":", ",", "represented_labels", "]", "\n", "\n", "# STEP 2: Forward pass through the input model", "\n", "outputs", "=", "self", ".", "roberta", "(", "**", "input_loader", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "input_cls_repr", "=", "sequence_output", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "# STEP 3: Forward pass through the label model", "\n", "# The label loader adds an extra dimension at the beginning of the tensors", "\n", "# Remove them", "\n", "for", "key", "in", "label_loader", ".", "keys", "(", ")", ":", "\n", "            ", "label_loader", "[", "key", "]", "=", "torch", ".", "squeeze", "(", "label_loader", "[", "key", "]", ",", "0", ")", "\n", "", "with", "torch", ".", "set_grad_enabled", "(", "not", "self", ".", "config", ".", "freeze_label_model", ")", ":", "\n", "            ", "if", "self", ".", "config", ".", "share_label_model", ":", "\n", "                ", "label_representations", "=", "self", ".", "roberta", "(", "**", "label_loader", ")", ".", "pooler_output", "# (n_class, d_model)", "\n", "", "else", ":", "\n", "                ", "label_representations", "=", "self", ".", "label_model", "(", "**", "label_loader", ")", ".", "pooler_output", "# (n_class, d_model)", "\n", "label_representations", "=", "label_representations", "@", "self", ".", "label_projection", ".", "weight", "\n", "\n", "# Call function for forward pass", "\n", "", "", "return", "semantic_model_forward_pass", "(", "\n", "config", "=", "self", ".", "config", ",", "\n", "input_loader", "=", "input_loader", ",", "\n", "input_cls_repr", "=", "input_cls_repr", ",", "\n", "outputs", "=", "outputs", ",", "\n", "labels", "=", "labels", ",", "\n", "represented_labels", "=", "represented_labels", ",", "\n", "label_representations", "=", "label_representations", ",", "\n", "num_labels", "=", "None", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.BertForSemanticEmbedding.__init__": [[244, 261], ["transformers.models.bert.modeling_bert.BertPreTrainedModel.__init__", "transformers.models.bert.modeling_bert.BertModel", "transformers.models.bert.modeling_bert.BertModel", "models.BertForSemanticEmbedding.post_init", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "\n", "# Create a placeholder for the label_model", "\n", "self", ".", "label_model", "=", "BertModel", "(", "config", ")", "\n", "# self.label_model = AutoModel.from_pretrained(", "\n", "#     config.label_model_name_or_path,", "\n", "#     cache_dir=config.cache_dir", "\n", "# )", "\n", "\n", "# Projection layer for label embedding model", "\n", "if", "not", "self", ".", "config", ".", "share_label_model", ":", "\n", "            ", "self", ".", "label_projection", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "label_model_hidden_size", ")", "\n", "\n", "# Initialize weights and apply final processing", "\n", "", "self", ".", "post_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.BertForSemanticEmbedding.forward": [[262, 306], ["input_loader.pop", "models.BertForSemanticEmbedding.bert", "label_loader.keys", "models.semantic_model_forward_pass", "label_loader.pop", "torch.squeeze", "torch.set_grad_enabled", "models.BertForSemanticEmbedding.label_model", "models.BertForSemanticEmbedding.bert", "models.BertForSemanticEmbedding.label_model"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.semantic_model_forward_pass"], ["", "def", "forward", "(", "self", ",", "input_loader", "=", "None", ",", "label_loader", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :input_loader contains the inputs to be fed to self.roberta\n        :label_loader contains the inputs to be fed to the label model self.label_model\n        \"\"\"", "\n", "\n", "# STEP 1: Store the labels", "\n", "# During training, some classes might be held-out", "\n", "# Mask those classes so that they are not treated as negatives", "\n", "labels", "=", "input_loader", ".", "pop", "(", "'labels'", ")", "\n", "represented_labels", "=", "label_loader", ".", "pop", "(", "'represented_labels'", ")", "[", "0", "]", "\n", "labels", "=", "labels", "[", ":", ",", "represented_labels", "]", "\n", "\n", "# STEP 2: Forward pass through the input model", "\n", "outputs", "=", "self", ".", "bert", "(", "**", "input_loader", ")", "\n", "# outputs[1] for the BERT model and outputs[0] for the RoBERTa model", "\n", "sequence_output", "=", "outputs", "[", "1", "]", "\n", "input_cls_repr", "=", "sequence_output", "\n", "\n", "# STEP 3: Forward pass through the label model", "\n", "# The label loader adds an extra dimension at the beginning of the tensors", "\n", "# Remove them", "\n", "for", "key", "in", "label_loader", ".", "keys", "(", ")", ":", "\n", "            ", "label_loader", "[", "key", "]", "=", "torch", ".", "squeeze", "(", "label_loader", "[", "key", "]", ",", "0", ")", "\n", "", "with", "torch", ".", "set_grad_enabled", "(", "not", "self", ".", "config", ".", "freeze_label_model", ")", ":", "\n", "            ", "label_representations", "=", "self", ".", "label_model", "(", "**", "label_loader", ")", "[", "1", "]", "# (n_class, d_model)", "\n", "if", "self", ".", "config", ".", "share_label_model", ":", "\n", "                ", "label_representations", "=", "self", ".", "bert", "(", "**", "label_loader", ")", "[", "1", "]", "# (n_class, d_model)", "\n", "", "else", ":", "\n", "                ", "label_representations", "=", "self", ".", "label_model", "(", "**", "label_loader", ")", "[", "1", "]", "# (n_class, d_model)", "\n", "label_representations", "=", "label_representations", "@", "self", ".", "label_projection", ".", "weight", "\n", "\n", "\n", "# Call function for forward pass", "\n", "", "", "return", "semantic_model_forward_pass", "(", "\n", "config", "=", "self", ".", "config", ",", "\n", "input_loader", "=", "input_loader", ",", "\n", "input_cls_repr", "=", "input_cls_repr", ",", "\n", "outputs", "=", "outputs", ",", "\n", "labels", "=", "labels", ",", "\n", "represented_labels", "=", "represented_labels", ",", "\n", "label_representations", "=", "label_representations", ",", "\n", "num_labels", "=", "None", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.BertForWord2Vec.__init__": [[310, 323], ["transformers.models.bert.modeling_bert.BertPreTrainedModel.__init__", "transformers.models.bert.modeling_bert.BertModel", "models.BertForWord2Vec.post_init", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "\n", "# NOTE: No label model", "\n", "\n", "# Projection layer for label embedding model", "\n", "if", "not", "self", ".", "config", ".", "share_label_model", ":", "\n", "# self.label_projection = nn.Linear(config.hidden_size, config.label_model_hidden_size)", "\n", "            ", "self", ".", "label_projection", "=", "nn", ".", "Linear", "(", "config", ".", "label_model_hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# Initialize weights and apply final processing", "\n", "", "self", ".", "post_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.BertForWord2Vec.forward": [[324, 369], ["input_loader.pop", "models.BertForWord2Vec.bert", "label_loader.keys", "models.semantic_model_forward_pass", "label_loader.pop", "torch.tanh", "torch.squeeze", "torch.tanh"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.semantic_model_forward_pass"], ["", "def", "forward", "(", "self", ",", "input_loader", "=", "None", ",", "label_loader", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :input_loader contains the inputs to be fed to self.roberta\n        :label_loader contains the inputs to be fed to the label model self.label_model\n        \"\"\"", "\n", "\n", "# STEP 1: Store the labels", "\n", "# During training, some classes might be held-out", "\n", "# Mask those classes so that they are not treated as negatives", "\n", "labels", "=", "input_loader", ".", "pop", "(", "'labels'", ")", "\n", "represented_labels", "=", "label_loader", ".", "pop", "(", "'represented_labels'", ")", "[", "0", "]", "\n", "labels", "=", "labels", "[", ":", ",", "represented_labels", "]", "\n", "\n", "# STEP 2: Forward pass through the input model", "\n", "outputs", "=", "self", ".", "bert", "(", "**", "input_loader", ")", "\n", "# outputs[1] for the BERT model and outputs[0] for the RoBERTa model", "\n", "sequence_output", "=", "outputs", "[", "1", "]", "\n", "input_cls_repr", "=", "sequence_output", "\n", "\n", "# If GILE model, compute the sigmoid", "\n", "if", "self", ".", "config", ".", "use_gile", ":", "\n", "            ", "input_cls_repr", "=", "torch", ".", "tanh", "(", "input_cls_repr", ")", "\n", "\n", "# STEP 3: Get the label model vectors", "\n", "# The label loader adds an extra dimension at the beginning of the tensors", "\n", "# Remove them", "\n", "", "for", "key", "in", "label_loader", ".", "keys", "(", ")", ":", "\n", "            ", "label_loader", "[", "key", "]", "=", "torch", ".", "squeeze", "(", "label_loader", "[", "key", "]", ",", "0", ")", "\n", "\n", "", "label_representations", "=", "label_loader", "[", "'embeddings'", "]", "@", "self", ".", "label_projection", ".", "weight", ".", "T", "\n", "\n", "if", "self", ".", "config", ".", "use_gile", ":", "\n", "            ", "label_representations", "=", "torch", ".", "tanh", "(", "label_representations", ")", "\n", "\n", "# Call function for forward pass", "\n", "", "return", "semantic_model_forward_pass", "(", "\n", "config", "=", "self", ".", "config", ",", "\n", "input_loader", "=", "input_loader", ",", "\n", "input_cls_repr", "=", "input_cls_repr", ",", "\n", "outputs", "=", "outputs", ",", "\n", "labels", "=", "labels", ",", "\n", "represented_labels", "=", "represented_labels", ",", "\n", "label_representations", "=", "label_representations", ",", "\n", "num_labels", "=", "None", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.margin_loss_formatting": [[73, 93], ["torch.arange().repeat", "torch.where", "torch.sort", "torch.ones", "labels.bool", "torch.arange"], "function", ["None"], ["", "", "def", "margin_loss_formatting", "(", "labels", ",", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Format the labels such that it can be used by MultiLabelMarginLoss\n    Convert multilabel one-hot labels to a list of positive classes\n    \"\"\"", "\n", "\n", "# Create a tensor with element values as column number", "\n", "# E.g., [[0, 1, 2], [0, 1, 2], [0, 1, 2]]", "\n", "arange_tensor", "=", "torch", ".", "arange", "(", "labels", ".", "shape", "[", "1", "]", ",", "device", "=", "device", ")", ".", "repeat", "(", "labels", ".", "shape", "[", "0", "]", ",", "1", ")", "\n", "\n", "# Create a tensor with all -1's", "\n", "# E.g., [[-1, -1, -1], [-1, -1, -1], [-1, -1, -1]]", "\n", "ones_tensor", "=", "-", "1", "*", "torch", ".", "ones", "(", "labels", ".", "shape", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "formatted_labels", "=", "torch", ".", "where", "(", "labels", ".", "bool", "(", ")", ",", "arange_tensor", ",", "ones_tensor", ")", "\n", "\n", "# Sort each row of formatted labels such that all the -1s appear in the end", "\n", "formatted_labels", ",", "_", "=", "torch", ".", "sort", "(", "formatted_labels", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "return", "formatted_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.semantic_model_forward_pass": [[95, 183], ["transformers.modeling_outputs.SequenceClassifierOutput", "torch.nn.functional.normalize", "torch.nn.MSELoss", "input_loader.keys", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.BCEWithLogitsLoss.", "logits.squeeze", "labels.squeeze", "logits.view", "labels.view", "models.margin_loss_formatting", "torch.nn.MultiLabelMarginLoss", "torch.nn.functional.logsigmoid", "torch.nn.functional.logsigmoid", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss", "torch.exp", "torch.mean", "torch.ones", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "torch.ones"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.margin_loss_formatting"], ["", "def", "semantic_model_forward_pass", "(", "\n", "config", "=", "None", ",", "\n", "input_loader", "=", "None", ",", "\n", "input_cls_repr", "=", "None", ",", "\n", "outputs", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "represented_labels", "=", "None", ",", "\n", "label_representations", "=", "None", ",", "\n", "num_labels", "=", "None", ",", "\n", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Common forward pass for RoBERTa and BERT models\n    \"\"\"", "\n", "\n", "# Normalize the label representations if required", "\n", "if", "config", ".", "normalize_label_embeddings", ":", "\n", "        ", "label_representations", "=", "nn", ".", "functional", ".", "normalize", "(", "label_representations", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute the logits", "\n", "", "logits", "=", "input_cls_repr", "@", "label_representations", ".", "T", "# (bs, n_class)", "\n", "\n", "# Compute the loss", "\n", "# Code copied from RobertaForSequenceClassification", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "        ", "if", "config", ".", "problem_type", "is", "None", ":", "\n", "            ", "if", "num_labels", "==", "1", ":", "\n", "                ", "config", ".", "problem_type", "=", "\"regression\"", "\n", "", "elif", "num_labels", ">", "1", "and", "(", "labels", ".", "dtype", "==", "torch", ".", "long", "or", "labels", ".", "dtype", "==", "torch", ".", "int", ")", ":", "\n", "                ", "config", ".", "problem_type", "=", "\"single_label_classification\"", "\n", "", "else", ":", "\n", "                ", "config", ".", "problem_type", "=", "\"multi_label_classification\"", "\n", "\n", "", "", "if", "config", ".", "problem_type", "==", "\"regression\"", ":", "\n", "            ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "if", "num_labels", "==", "1", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "squeeze", "(", ")", ",", "labels", ".", "squeeze", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "", "", "elif", "config", ".", "problem_type", "==", "\"single_label_classification\"", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "elif", "config", ".", "problem_type", "==", "\"multi_label_classification\"", ":", "\n", "# Check if it is hinge loss or not", "\n", "            ", "if", "config", ".", "label_loss_type", "==", "'hinge'", ":", "\n", "# MultiLabelMarginLoss needs the labels to be formatted in a specific way", "\n", "                ", "formatted_labels", "=", "margin_loss_formatting", "(", "labels", ",", "device", "=", "device", ")", "\n", "\n", "# MultiLabelMarginLoss doesn't have a margin argument. HACK to allow margin usage", "\n", "loss_fct", "=", "MultiLabelMarginLoss", "(", ")", "\n", "\n", "# Convert logits to logsigmoid", "\n", "logsigmoid_logits", "=", "nn", ".", "functional", ".", "logsigmoid", "(", "logits", ")", "\n", "\n", "negative_logsigmoid_logits", "=", "nn", ".", "functional", ".", "logsigmoid", "(", "-", "logits", ")", "\n", "\n", "# HACK: Use hack to include a margin parameter in the loss function", "\n", "# NOTE: MultiLabelMarginLoss doesn't have a margin parameter", "\n", "loss", "=", "config", ".", "hinge_margin_value", "*", "loss_fct", "(", "1.", "/", "config", ".", "hinge_margin_value", "*", "logsigmoid_logits", ",", "formatted_labels", ")", "\n", "", "elif", "config", ".", "label_loss_type", "==", "'focal'", ":", "\n", "                ", "pos_weights", "=", "config", ".", "relative_weight_positive_samples", "*", "torch", ".", "ones", "(", "[", "represented_labels", ".", "shape", "[", "0", "]", "]", ",", "device", "=", "device", ")", "\n", "loss_fct", "=", "BCEWithLogitsLoss", "(", "pos_weight", "=", "pos_weights", ",", "reduction", "=", "'none'", ")", "\n", "\n", "# Compute log(p) or log(1-p) depending on the label", "\n", "log_pt", "=", "-", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "pt", "=", "torch", ".", "exp", "(", "log_pt", ")", "\n", "\n", "loss", "=", "-", "(", "(", "1", "-", "pt", ")", "**", "config", ".", "focal_loss_gamma", ")", "*", "log_pt", "\n", "\n", "# Take the mean", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "", "elif", "config", ".", "label_loss_type", "==", "'bce'", ":", "\n", "# Use standard BCE loss", "\n", "                ", "pos_weights", "=", "config", ".", "relative_weight_positive_samples", "*", "torch", ".", "ones", "(", "[", "represented_labels", ".", "shape", "[", "0", "]", "]", ",", "device", "=", "device", ")", "\n", "loss_fct", "=", "BCEWithLogitsLoss", "(", "pos_weight", "=", "pos_weights", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "", "else", ":", "\n", "                ", "raise", "(", "'Choose one of the available loss functions.'", ")", "\n", "\n", "", "", "", "if", "'return_dict'", "in", "input_loader", ".", "keys", "(", ")", "and", "not", "input_loader", "[", "'return_dict'", "]", ":", "\n", "        ", "output", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.get_ancestors": [[21, 62], ["open().readlines", "copy.deepcopy", "parents.keys", "ancestors.keys", "line.strip().split", "metrics.get_ancestors.get_ancestors_recursion"], "function", ["None"], ["def", "get_ancestors", "(", "data_args", ",", "label2id", ")", ":", "\n", "    ", "\"\"\"\n    Get the ancestors of all the nodes using the hierarchy file given.\n    \"\"\"", "\n", "\n", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "# Open the file and get all the lines", "\n", "        ", "lines", "=", "open", "(", "data_args", ".", "hierarchy_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "\n", "# Store the parents for each node as a list", "\n", "# Store all the lists in a dict", "\n", "parents", "=", "{", "}", "\n", "\n", "# Go over all the lines in the file", "\n", "label2id_copy", "=", "copy", ".", "deepcopy", "(", "label2id", ")", "\n", "label2id_copy", "[", "'Root'", "]", "=", "-", "1", "\n", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "split_line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "split_line", "[", "1", "]", "!=", "\"None\"", "and", "split_line", "[", "3", "]", "in", "label2id_copy", ".", "keys", "(", ")", ":", "\n", "                ", "parents", "[", "split_line", "[", "3", "]", "]", "=", "split_line", "[", "1", "]", "\n", "\n", "", "", "def", "get_ancestors_recursion", "(", "node", ")", ":", "\n", "            ", "if", "node", "==", "'Root'", ":", "\n", "                ", "return", "[", "'Root'", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "node", "]", "+", "get_ancestors_recursion", "(", "parents", "[", "node", "]", ")", "\n", "\n", "# Collect all the ancestors", "\n", "", "", "ancestors", "=", "{", "}", "\n", "for", "key", "in", "parents", ".", "keys", "(", ")", ":", "\n", "            ", "ancestors", "[", "key", "]", "=", "get_ancestors_recursion", "(", "key", ")", "\n", "\n", "# Convert labels to IDS", "\n", "", "for", "key", "in", "ancestors", ".", "keys", "(", ")", ":", "\n", "            ", "ancestors", "[", "key", "]", "=", "[", "label2id_copy", "[", "i", "]", "for", "i", "in", "ancestors", "[", "key", "]", "]", "\n", "\n", "", "return", "ancestors", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "(", "\"Hierarchal metrics support only for RCV1.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.compute_hierarchical_micro_f1": [[64, 110], ["range", "range", "len", "len", "len", "len", "set", "set", "set", "set", "set", "set"], "function", ["None"], ["", "", "def", "compute_hierarchical_micro_f1", "(", "preds", ",", "label_ids", ",", "ancestor_dict", ",", "id2label", ")", ":", "\n", "    ", "\"\"\"\n    Compute the hierarchical micro F-1.\n    \"\"\"", "\n", "precision", "=", "[", "0", ",", "0", "]", "\n", "recall", "=", "[", "0", ",", "0", "]", "\n", "\n", "# Loop over all the instances", "\n", "for", "i", "in", "range", "(", "preds", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "true_nodes", "=", "[", "]", "\n", "predicted_nodes", "=", "[", "]", "\n", "\n", "# Collect true node ancestors", "\n", "for", "j", "in", "range", "(", "preds", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "label_ids", "[", "i", "]", "[", "j", "]", "==", "1", ":", "\n", "                ", "true_nodes", "=", "true_nodes", "+", "ancestor_dict", "[", "id2label", "[", "j", "]", "]", "\n", "", "if", "preds", "[", "i", "]", "[", "j", "]", "==", "1", ":", "\n", "                ", "predicted_nodes", "=", "predicted_nodes", "+", "ancestor_dict", "[", "id2label", "[", "j", "]", "]", "\n", "\n", "# Compute the intersection", "\n", "# Numerator", "\n", "", "", "precision", "[", "0", "]", "+=", "len", "(", "set", "(", "true_nodes", ")", "&", "set", "(", "predicted_nodes", ")", ")", "\n", "recall", "[", "0", "]", "+=", "len", "(", "set", "(", "true_nodes", ")", "&", "set", "(", "predicted_nodes", ")", ")", "\n", "\n", "# Denominator", "\n", "precision", "[", "1", "]", "+=", "len", "(", "set", "(", "predicted_nodes", ")", ")", "\n", "recall", "[", "1", "]", "+=", "len", "(", "set", "(", "true_nodes", ")", ")", "\n", "\n", "# Compute precision and recall", "\n", "# Handle zero-division errors", "\n", "", "if", "precision", "[", "1", "]", "==", "0", ":", "\n", "        ", "h_precision", "=", "1", "\n", "", "else", ":", "\n", "        ", "h_precision", "=", "precision", "[", "0", "]", "/", "precision", "[", "1", "]", "\n", "\n", "", "if", "recall", "[", "1", "]", "==", "0", ":", "\n", "        ", "h_recall", "=", "1", "\n", "", "else", ":", "\n", "        ", "h_recall", "=", "recall", "[", "0", "]", "/", "recall", "[", "1", "]", "\n", "\n", "", "if", "h_precision", "==", "0", "and", "h_recall", "==", "0", ":", "\n", "        ", "h_f1", "=", "0", "\n", "", "else", ":", "\n", "        ", "h_f1", "=", "2", "*", "h_precision", "*", "h_recall", "/", "(", "h_precision", "+", "h_recall", ")", "\n", "\n", "", "return", "h_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_metrics": [[112, 214], ["scipy.special.expit", "metrics.get_ancestors", "sklearn.metrics.classification_report", "print", "isinstance", "fbr.keys", "numpy.arange", "max", "numpy.where", "fbr.keys", "numpy.arange", "max", "numpy.where", "sklearn.metrics.accuracy_score", "fbr.keys", "numpy.arange", "max", "numpy.where", "sklearn.metrics.f1_score", "fbr.keys", "numpy.arange", "max", "numpy.where", "sklearn.metrics.f1_score", "fbr.keys", "numpy.arange", "max", "numpy.where", "metrics.compute_hierarchical_micro_f1", "numpy.where", "numpy.where", "sklearn.metrics.accuracy_score", "numpy.where", "sklearn.metrics.f1_score", "numpy.where", "sklearn.metrics.f1_score", "numpy.where", "metrics.compute_hierarchical_micro_f1", "numpy.sum", "numpy.sum", "range", "len"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.get_ancestors", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.compute_hierarchical_micro_f1", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.compute_hierarchical_micro_f1"], ["", "def", "multilabel_metrics", "(", "data_args", ",", "id2label", ",", "label2id", ",", "fbr", ")", ":", "\n", "    ", "\"\"\"\n    Metrics function used for multilabel classification.\n    Datasets: RCV1-V2\n\n    :fbr : A dict containing global thresholds to be used for selecting a class.\n    We use global thresholds because we want to handle unseen classes,\n    for which the threshold is not known in advance.\n    \"\"\"", "\n", "def", "compute_metrics", "(", "p", ")", ":", "\n", "# Collect the logits", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "\n", "# Compute the logistic sigmoid", "\n", "preds", "=", "expit", "(", "preds", ")", "\n", "\n", "# METRIC 1: Compute accuracy", "\n", "if", "'accuracy'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "0.1", ",", "1", ",", "0.1", ")", ":", "\n", "                ", "accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "np", ".", "sum", "(", "p", ".", "label_ids", "==", "accuracy_preds", ")", "/", "accuracy_preds", ".", "size", "*", "100", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'accuracy'", "]", "=", "best_threshold", "\n", "accuracy", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'accuracy'", "]", ",", "1", ",", "0", ")", "\n", "accuracy", "=", "np", ".", "sum", "(", "p", ".", "label_ids", "==", "accuracy_preds", ")", "/", "accuracy_preds", ".", "size", "*", "100", "\n", "\n", "# METRIC 2: Compute the subset accuracy", "\n", "", "if", "'subset_accuracy'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "0.1", ",", "1", ",", "0.1", ")", ":", "\n", "                ", "subset_accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "accuracy_score", "(", "p", ".", "label_ids", ",", "subset_accuracy_preds", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'subset_accuracy'", "]", "=", "best_threshold", "\n", "subset_accuracy", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "subset_accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'subset_accuracy'", "]", ",", "1", ",", "0", ")", "\n", "subset_accuracy", "=", "accuracy_score", "(", "p", ".", "label_ids", ",", "subset_accuracy_preds", ")", "\n", "\n", "# METRIC 3: Macro F-1", "\n", "", "if", "'macro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "0.1", ",", "1", ",", "0.1", ")", ":", "\n", "                ", "macro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", ",", "macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'macro_f1'", "]", "=", "best_threshold", "\n", "macro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "macro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'macro_f1'", "]", ",", "1", ",", "0", ")", "\n", "macro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "\n", "# METRIC 4: Micro F-1", "\n", "", "if", "'micro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "0.1", ",", "1", ",", "0.1", ")", ":", "\n", "                ", "micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", ",", "micro_f1_preds", ",", "average", "=", "'micro'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'micro_f1'", "]", "=", "best_threshold", "\n", "micro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'micro_f1'", "]", ",", "1", ",", "0", ")", "\n", "micro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "micro_f1_preds", ",", "average", "=", "'micro'", ")", "\n", "\n", "# METRIC 5: Hierarchical micro F-1", "\n", "", "ancestor_dict", "=", "get_ancestors", "(", "data_args", ",", "label2id", ")", "\n", "if", "'hier_micro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "0.1", ",", "1", ",", "0.1", ")", ":", "\n", "                ", "hier_micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "compute_hierarchical_micro_f1", "(", "hier_micro_f1_preds", ",", "p", ".", "label_ids", ",", "ancestor_dict", ",", "id2label", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'hier_micro_f1'", "]", "=", "best_threshold", "\n", "hier_micro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "hier_micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'hier_micro_f1'", "]", ",", "1", ",", "0", ")", "\n", "hier_micro_f1", "=", "compute_hierarchical_micro_f1", "(", "hier_micro_f1_preds", ",", "p", ".", "label_ids", ",", "ancestor_dict", ",", "id2label", ")", "\n", "\n", "# Multi-label classification report", "\n", "# Optimized for Micro F-1", "\n", "", "report", "=", "classification_report", "(", "p", ".", "label_ids", ",", "micro_f1_preds", ",", "target_names", "=", "[", "id2label", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "id2label", ")", ")", "]", ")", "\n", "print", "(", "report", ")", "\n", "\n", "return", "{", "\n", "\"accuracy\"", ":", "accuracy", ",", "\n", "\"subset_accuracy\"", ":", "subset_accuracy", ",", "\n", "\"macro_f1\"", ":", "macro_f1", ",", "\n", "\"micro_f1\"", ":", "micro_f1", ",", "\n", "\"hier_micro_f1\"", ":", "hier_micro_f1", ",", "\n", "\"fbr\"", ":", "fbr", "\n", "}", "\n", "\n", "", "return", "compute_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_label_descriptions_metrics": [[216, 388], ["scipy.special.expit", "metrics.get_ancestors", "print", "numpy.where", "sklearn.metrics.classification_report", "print", "print", "print", "print", "print", "isinstance", "fbr.keys", "numpy.arange", "max", "numpy.where", "fbr.keys", "numpy.arange", "max", "numpy.where", "sklearn.metrics.accuracy_score", "fbr.keys", "numpy.arange", "max", "numpy.where", "sklearn.metrics.f1_score", "fbr.keys", "numpy.arange", "max", "numpy.where", "sklearn.metrics.f1_score", "fbr.keys", "numpy.arange", "max", "numpy.where", "metrics.compute_hierarchical_micro_f1", "fbr.keys", "numpy.arange", "max", "print", "numpy.where", "print", "print", "numpy.where", "sklearn.metrics.f1_score", "print", "print", "print", "list", "list", "list.sort", "numpy.average", "numpy.average", "numpy.where", "numpy.where", "sklearn.metrics.accuracy_score", "numpy.where", "sklearn.metrics.f1_score", "numpy.where", "sklearn.metrics.f1_score", "numpy.where", "metrics.compute_hierarchical_micro_f1", "numpy.where", "sklearn.metrics.f1_score", "set().difference", "set().intersection", "len", "print", "numpy.arange", "max", "sklearn.metrics.classification_report", "print", "print", "print", "numpy.sum", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "set", "set", "numpy.where", "sklearn.metrics.f1_score", "numpy.where", "numpy.sum", "set", "set"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.get_ancestors", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.compute_hierarchical_micro_f1", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.compute_hierarchical_micro_f1"], ["", "def", "multilabel_label_descriptions_metrics", "(", "data_args", ",", "id2label", ",", "label2id", ",", "label_list_dict", ",", "fbr", ")", ":", "\n", "    ", "\"\"\"\n    Metrics function used for multilabel classification.\n    Datasets: RCV1-V2\n\n    :fbr : A dict containing global thresholds to be used for selecting a class.\n    We use global thresholds because we want to handle unseen classes,\n    for which the threshold is not known in advance.\n    \"\"\"", "\n", "def", "compute_metrics", "(", "p", ")", ":", "\n", "# Collect the logits", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "\n", "# Compute the logistic sigmoid", "\n", "preds", "=", "expit", "(", "preds", ")", "\n", "\n", "# Determine if it's validation or prediction", "\n", "is_validation", "=", "False", "if", "fbr", "else", "True", "\n", "\n", "# Define the range over which the best fbr value is chosen", "\n", "fbr_low", "=", "0.0", "\n", "fbr_high", "=", "1.0", "\n", "fbr_step", "=", "0.05", "\n", "\n", "# METRIC 1: Compute accuracy", "\n", "if", "'accuracy'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                ", "accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "np", ".", "sum", "(", "p", ".", "label_ids", "==", "accuracy_preds", ")", "/", "accuracy_preds", ".", "size", "*", "100", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'accuracy'", "]", "=", "best_threshold", "\n", "accuracy", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'accuracy'", "]", ",", "1", ",", "0", ")", "\n", "accuracy", "=", "np", ".", "sum", "(", "p", ".", "label_ids", "==", "accuracy_preds", ")", "/", "accuracy_preds", ".", "size", "*", "100", "\n", "\n", "# METRIC 2: Compute the subset accuracy", "\n", "", "if", "'subset_accuracy'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                ", "subset_accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "accuracy_score", "(", "p", ".", "label_ids", ",", "subset_accuracy_preds", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'subset_accuracy'", "]", "=", "best_threshold", "\n", "subset_accuracy", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "subset_accuracy_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'subset_accuracy'", "]", ",", "1", ",", "0", ")", "\n", "subset_accuracy", "=", "accuracy_score", "(", "p", ".", "label_ids", ",", "subset_accuracy_preds", ")", "\n", "\n", "# METRIC 3: Macro F-1", "\n", "", "if", "'macro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                ", "macro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", ",", "macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'macro_f1'", "]", "=", "best_threshold", "\n", "macro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "macro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'macro_f1'", "]", ",", "1", ",", "0", ")", "\n", "macro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "\n", "# METRIC 4: Micro F-1", "\n", "", "if", "'micro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                ", "micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", ",", "micro_f1_preds", ",", "average", "=", "'micro'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'micro_f1'", "]", "=", "best_threshold", "\n", "micro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'micro_f1'", "]", ",", "1", ",", "0", ")", "\n", "micro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "micro_f1_preds", ",", "average", "=", "'micro'", ")", "\n", "\n", "# METRIC 5: Hierarchical micro F-1", "\n", "", "ancestor_dict", "=", "get_ancestors", "(", "data_args", ",", "label2id", ")", "\n", "if", "'hier_micro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                ", "hier_micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "compute_hierarchical_micro_f1", "(", "hier_micro_f1_preds", ",", "p", ".", "label_ids", ",", "ancestor_dict", ",", "id2label", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'hier_micro_f1'", "]", "=", "best_threshold", "\n", "hier_micro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "hier_micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'hier_micro_f1'", "]", ",", "1", ",", "0", ")", "\n", "hier_micro_f1", "=", "compute_hierarchical_micro_f1", "(", "hier_micro_f1_preds", ",", "p", ".", "label_ids", ",", "ancestor_dict", ",", "id2label", ")", "\n", "\n", "# METRIC X: DELETE ##############################", "\n", "", "if", "'m14_micro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", "*", "0.1", ")", ":", "\n", "                ", "m14_micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "m14_micro_f1_preds", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "average", "=", "'binary'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'m14_micro_f1'", "]", "=", "best_threshold", "\n", "M14_score", "=", "performance", "[", "best_threshold", "]", "\n", "print", "(", "\"M14 score is: {}\"", ".", "format", "(", "M14_score", ")", ")", "\n", "m14_micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'m14_micro_f1'", "]", ",", "1", ",", "0", ")", "\n", "print", "(", "\"M14 precision is: {}\"", ".", "format", "(", "precision_score", "(", "p", ".", "label_ids", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "m14_micro_f1_preds", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "average", "=", "'binary'", ")", ")", ")", "\n", "print", "(", "\"M14 recall is: {}\"", ".", "format", "(", "recall_score", "(", "p", ".", "label_ids", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "m14_micro_f1_preds", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "average", "=", "'binary'", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "m14_micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'m14_micro_f1'", "]", ",", "1", ",", "0", ")", "\n", "M14_score", "=", "f1_score", "(", "p", ".", "label_ids", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "m14_micro_f1_preds", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "average", "=", "'binary'", ")", "\n", "print", "(", "\"M14 score is: {}\"", ".", "format", "(", "M14_score", ")", ")", "\n", "print", "(", "\"M14 precision is: {}\"", ".", "format", "(", "precision_score", "(", "p", ".", "label_ids", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "m14_micro_f1_preds", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "average", "=", "'binary'", ")", ")", ")", "\n", "print", "(", "\"M14 recall is: {}\"", ".", "format", "(", "recall_score", "(", "p", ".", "label_ids", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "m14_micro_f1_preds", "[", ":", ",", "label2id", "[", "'M14'", "]", "]", ",", "average", "=", "'binary'", ")", ")", ")", "\n", "#################################################", "\n", "\n", "# Multi-label classification report", "\n", "# Optimized for Micro F-1 (the use of micro_f1_preds)", "\n", "", "print", "(", "\"*** Classification report for all the classes ***\"", ")", "\n", "micro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'micro_f1'", "]", ",", "1", ",", "0", ")", "\n", "report", "=", "classification_report", "(", "p", ".", "label_ids", ",", "micro_f1_preds", ",", "target_names", "=", "[", "id2label", "[", "i", "]", "for", "i", "in", "p", ".", "represented_labels", "]", ")", "\n", "print", "(", "report", ")", "\n", "print", "(", "\"********************************************\"", ")", "\n", "\n", "# Classification report only for classes that appeared in the validation/prediction set but not the train set", "\n", "# Get the classes which belong to the validation set but not the train set", "\n", "if", "data_args", ".", "evaluation_type", "==", "'gzs'", ":", "\n", "            ", "key", "=", "'validation'", "if", "is_validation", "else", "'test'", "\n", "set_difference", "=", "list", "(", "set", "(", "label_list_dict", "[", "key", "]", ")", ".", "difference", "(", "set", "(", "label_list_dict", "[", "'train'", "]", ")", ")", ")", "\n", "set_difference", "=", "[", "label2id", "[", "label", "]", "for", "label", "in", "set_difference", "]", "\n", "# Take an intersection with the labels that are represented in the current data", "\n", "set_difference", "=", "list", "(", "set", "(", "set_difference", ")", ".", "intersection", "(", "set", "(", "p", ".", "represented_labels", ")", ")", ")", "\n", "set_difference", ".", "sort", "(", ")", "\n", "\n", "if", "len", "(", "set_difference", ")", ">", "0", ":", "\n", "                ", "print", "(", "\"*** Classification report for classes not in the train set ***\"", ")", "\n", "target_names", "=", "[", "id2label", "[", "i", "]", "for", "i", "in", "set_difference", "]", "\n", "\n", "# HACK: Find macro F-1 optimized for the unseen labels", "\n", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                    ", "unseen_macro_f1_preds", "=", "np", ".", "where", "(", "preds", "[", ":", ",", "set_difference", "]", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", "[", ":", ",", "set_difference", "]", ",", "unseen_macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "unseen_macro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "\n", "report", "=", "classification_report", "(", "p", ".", "label_ids", "[", ":", ",", "set_difference", "]", ",", "np", ".", "where", "(", "preds", "[", ":", ",", "set_difference", "]", ">", "best_threshold", ",", "1", ",", "0", ")", ",", "target_names", "=", "target_names", ")", "\n", "print", "(", "report", ")", "\n", "\n", "print", "(", "\"Best threshold for unseen macro F-1: {}\"", ".", "format", "(", "best_threshold", ")", ")", "\n", "print", "(", "\"********************************************\"", ")", "\n", "\n", "# Print the thresholds used", "\n", "", "", "print", "(", "\"********************************************\"", ")", "\n", "print", "(", "\"Thresholds used: {}\"", ".", "format", "(", "fbr", ")", ")", "\n", "print", "(", "\"********************************************\"", ")", "\n", "\n", "return", "{", "\n", "\"accuracy\"", ":", "accuracy", ",", "\n", "\"subset_accuracy\"", ":", "subset_accuracy", ",", "\n", "\"macro_f1\"", ":", "macro_f1", ",", "\n", "\"micro_f1\"", ":", "micro_f1", ",", "\n", "\"hier_micro_f1\"", ":", "hier_micro_f1", ",", "\n", "\"unseen_micro_f1\"", ":", "unseen_macro_f1", ",", "\n", "\"fbr\"", ":", "fbr", ",", "\n", "\"unseen_average_prediction_score\"", ":", "np", ".", "average", "(", "preds", "[", ":", ",", "set_difference", "]", ")", ",", "\n", "\"seen_average_prediction_score\"", ":", "np", ".", "average", "(", "preds", "[", ":", ",", "[", "label2id", "[", "label", "]", "for", "label", "in", "label_list_dict", "[", "'train'", "]", "]", "]", ")", ",", "\n", "}", "\n", "\n", "", "return", "compute_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_label_descriptions_per_class_threshold_metrics": [[390, 523], ["scipy.special.expit", "sklearn.metrics.label_ranking_average_precision_score", "print", "numpy.where", "sklearn.metrics.classification_report", "print", "print", "isinstance", "fbr.keys", "range", "numpy.array", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "fbr.keys", "numpy.arange", "max", "numpy.where", "sklearn.metrics.f1_score", "list", "list", "list.sort", "numpy.average", "numpy.average", "numpy.arange", "best_thresholds.append", "numpy.where", "numpy.where", "numpy.where", "sklearn.metrics.f1_score", "set().difference", "set().intersection", "len", "numpy.array", "sklearn.metrics.f1_score", "numpy.arange", "max", "sklearn.metrics.label_ranking_average_precision_score", "print", "sklearn.metrics.classification_report", "print", "print", "print", "numpy.where", "sklearn.metrics.f1_score", "max", "set", "set", "numpy.arange", "best_thresholds.append", "numpy.where", "numpy.where", "sklearn.metrics.f1_score", "numpy.where", "set", "set", "numpy.where", "sklearn.metrics.f1_score", "max"], "function", ["None"], ["", "def", "multilabel_label_descriptions_per_class_threshold_metrics", "(", "data_args", ",", "id2label", ",", "label2id", ",", "label_list_dict", ",", "fbr", ")", ":", "\n", "    ", "\"\"\"\n    Metrics function used for multilabel classification.\n    Choose a different threshold for each class.\n\n    Don't compute accuracy and subset accuracy.\n\n    Datasets: RCV1-V2\n\n    :fbr : A dict containing global thresholds to be used for selecting a class.\n    We use global thresholds because we want to handle unseen classes,\n    for which the threshold is not known in advance.\n    \"\"\"", "\n", "def", "compute_metrics", "(", "p", ")", ":", "\n", "# Collect the logits", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "\n", "# Compute the logistic sigmoid", "\n", "preds", "=", "expit", "(", "preds", ")", "\n", "\n", "# Determine if it's validation or prediction", "\n", "is_validation", "=", "False", "if", "fbr", "else", "True", "\n", "\n", "# Define the range over which the best fbr value is chosen", "\n", "fbr_low", "=", "0.0", "\n", "fbr_high", "=", "1.0", "\n", "fbr_step", "=", "0.05", "\n", "\n", "# METRIC 3: Macro F-1", "\n", "if", "'macro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "# Store the best threshold for each class", "\n", "            ", "best_thresholds", "=", "[", "]", "\n", "# Loop over all the classes", "\n", "for", "i", "in", "range", "(", "preds", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                    ", "macro_f1_preds", "=", "np", ".", "where", "(", "preds", "[", ":", ",", "i", "]", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", "[", ":", ",", "i", "]", ",", "macro_f1_preds", ",", "average", "=", "'binary'", ")", "\n", "# Choose the best threshold", "\n", "", "best_thresholds", ".", "append", "(", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", ")", "\n", "", "fbr", "[", "'macro_f1'", "]", "=", "np", ".", "array", "(", "best_thresholds", ")", "\n", "macro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'macro_f1'", "]", ",", "1", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "", "else", ":", "\n", "            ", "macro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'macro_f1'", "]", ",", "1", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "# NOTE: The following function was only for debugging purposes", "\n", "# METRIC: Macro F-1 with global threshold", "\n", "", "if", "'global_macro_f1'", "not", "in", "fbr", ".", "keys", "(", ")", ":", "\n", "            ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                ", "global_macro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", ",", "global_macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "fbr", "[", "'global_macro_f1'", "]", "=", "best_threshold", "\n", "global_macro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "", "else", ":", "\n", "            ", "global_macro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'global_macro_f1'", "]", ",", "1", ",", "0", ")", "\n", "global_macro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "global_macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "\n", "# METRIC: LRAP (Label ranking average precision)", "\n", "", "total_lrap", "=", "label_ranking_average_precision_score", "(", "p", ".", "label_ids", ",", "preds", ")", "\n", "\n", "# Multi-label classification report", "\n", "# Optimized for Micro F-1 (the use of micro_f1_preds)", "\n", "print", "(", "\"*** Classification report for all the classes ***\"", ")", "\n", "macro_f1_preds", "=", "np", ".", "where", "(", "preds", ">", "fbr", "[", "'macro_f1'", "]", ",", "1", ",", "0", ")", "\n", "report", "=", "classification_report", "(", "p", ".", "label_ids", ",", "macro_f1_preds", ",", "target_names", "=", "[", "id2label", "[", "i", "]", "for", "i", "in", "p", ".", "represented_labels", "]", ")", "\n", "print", "(", "report", ")", "\n", "print", "(", "\"********************************************\"", ")", "\n", "\n", "# Classification report only for classes that appeared in the validation/prediction set but not the train set", "\n", "# Get the classes which belong to the validation set but not the train set", "\n", "unseen_macro_f1", "=", "0.", "\n", "if", "data_args", ".", "evaluation_type", "==", "'gzs'", ":", "\n", "            ", "key", "=", "'validation'", "if", "is_validation", "else", "'test'", "\n", "set_difference", "=", "list", "(", "set", "(", "label_list_dict", "[", "key", "]", ")", ".", "difference", "(", "set", "(", "label_list_dict", "[", "'train'", "]", ")", ")", ")", "\n", "set_difference", "=", "[", "label2id", "[", "label", "]", "for", "label", "in", "set_difference", "]", "\n", "# Take an intersection with the labels that are represented in the current data", "\n", "set_difference", "=", "list", "(", "set", "(", "set_difference", ")", ".", "intersection", "(", "set", "(", "p", ".", "represented_labels", ")", ")", ")", "\n", "set_difference", ".", "sort", "(", ")", "\n", "\n", "if", "len", "(", "set_difference", ")", ">", "0", ":", "\n", "\n", "# METRIC: Unseen Macro F-1", "\n", "# Store the best threshold for each class", "\n", "                ", "best_thresholds", "=", "[", "]", "\n", "# Loop over all the classes", "\n", "for", "i", "in", "set_difference", ":", "\n", "                    ", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", "*", "0.1", ")", ":", "\n", "                        ", "unseen_micro_f1_preds", "=", "np", ".", "where", "(", "preds", "[", ":", ",", "i", "]", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", "[", ":", ",", "i", "]", ",", "unseen_micro_f1_preds", ",", "average", "=", "'binary'", ")", "\n", "# Choose the best threshold", "\n", "", "best_thresholds", ".", "append", "(", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", ")", "\n", "", "fbr", "[", "'unseen_macro_f1'", "]", "=", "np", ".", "array", "(", "best_thresholds", ")", "\n", "unseen_macro_f1", "=", "f1_score", "(", "p", ".", "label_ids", "[", ":", ",", "set_difference", "]", ",", "np", ".", "where", "(", "preds", "[", ":", ",", "set_difference", "]", ">", "fbr", "[", "'unseen_macro_f1'", "]", ",", "1", ",", "0", ")", ",", "average", "=", "'macro'", ")", "\n", "\n", "# METRIC: Unseen Macro F-1 with a global threshold", "\n", "performance", "=", "{", "}", "\n", "for", "threshold", "in", "np", ".", "arange", "(", "fbr_low", ",", "fbr_high", ",", "fbr_step", ")", ":", "\n", "                    ", "global_unseen_macro_f1_preds", "=", "np", ".", "where", "(", "preds", "[", ":", ",", "set_difference", "]", ">", "threshold", ",", "1", ",", "0", ")", "\n", "performance", "[", "threshold", "]", "=", "f1_score", "(", "p", ".", "label_ids", "[", ":", ",", "set_difference", "]", ",", "global_unseen_macro_f1_preds", ",", "average", "=", "'macro'", ")", "\n", "# Choose the best threshold", "\n", "", "best_threshold", "=", "max", "(", "performance", ",", "key", "=", "performance", ".", "get", ")", "\n", "global_unseen_macro_f1", "=", "performance", "[", "best_threshold", "]", "\n", "fbr", "[", "'global_unseen_macro_f1'", "]", "=", "best_threshold", "\n", "\n", "# METRIC: Unseen LRAP", "\n", "unseen_lrap", "=", "label_ranking_average_precision_score", "(", "p", ".", "label_ids", "[", ":", ",", "set_difference", "]", ",", "preds", "[", ":", ",", "set_difference", "]", ")", "\n", "\n", "# Print the classification report", "\n", "print", "(", "\"*** Classification report for classes not in the train set ***\"", ")", "\n", "target_names", "=", "[", "id2label", "[", "i", "]", "for", "i", "in", "set_difference", "]", "\n", "report", "=", "classification_report", "(", "p", ".", "label_ids", "[", ":", ",", "set_difference", "]", ",", "np", ".", "where", "(", "preds", "[", ":", ",", "set_difference", "]", ">", "fbr", "[", "'unseen_macro_f1'", "]", ",", "1", ",", "0", ")", ",", "target_names", "=", "target_names", ")", "\n", "print", "(", "report", ")", "\n", "\n", "print", "(", "\"Best thresholds for unseen micro F-1: {}\"", ".", "format", "(", "best_thresholds", ")", ")", "\n", "print", "(", "\"********************************************\"", ")", "\n", "\n", "", "", "return", "{", "\n", "\"macro_f1\"", ":", "macro_f1", ",", "\n", "\"global_macro_f1\"", ":", "global_macro_f1", ",", "\n", "\"unseen_macro_f1\"", ":", "unseen_macro_f1", ",", "\n", "\"global_unseen_macro_f1\"", ":", "global_unseen_macro_f1", ",", "\n", "\"total_lrap\"", ":", "total_lrap", ",", "\n", "\"unseen_lrap\"", ":", "unseen_lrap", ",", "\n", "\"fbr\"", ":", "fbr", ",", "\n", "\"unseen_average_prediction_score\"", ":", "np", ".", "average", "(", "preds", "[", ":", ",", "set_difference", "]", ")", ",", "\n", "\"seen_average_prediction_score\"", ":", "np", ".", "average", "(", "preds", "[", ":", ",", "[", "label2id", "[", "label", "]", "for", "label", "in", "label_list_dict", "[", "'train'", "]", "]", "]", ")", ",", "\n", "}", "\n", "\n", "", "return", "compute_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.multilabel_label_descriptions_ranking_metrics": [[525, 602], ["scipy.special.expit", "sklearn.metrics.label_ranking_average_precision_score", "sklearn.metrics.coverage_error", "isinstance", "numpy.sum", "list", "list", "list.sort", "sklearn.metrics.label_ranking_average_precision_score", "sklearn.metrics.coverage_error", "set().difference", "set().intersection", "numpy.sum", "len", "sklearn.metrics.label_ranking_average_precision_score", "set", "set", "numpy.sum", "set", "set"], "function", ["None"], ["", "def", "multilabel_label_descriptions_ranking_metrics", "(", "data_args", ",", "id2label", ",", "label2id", ",", "label_list_dict", ",", "fbr", ")", ":", "\n", "    ", "\"\"\"\n    Ranking metrics for multilabel classification.\n    LRAP and coverage error.\n    Higher is better for LRAP and lower is better for coverage error.\n\n    fbr is a flag which tells us if it is train or validation\n\n    Datasets: RCV1-V2\n    \"\"\"", "\n", "def", "compute_metrics", "(", "p", ")", ":", "\n", "# Collect the logits", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "\n", "# Compute the logistic sigmoid", "\n", "preds", "=", "expit", "(", "preds", ")", "\n", "\n", "# Determine if it's validation or prediction", "\n", "is_validation", "=", "False", "if", "fbr", "else", "True", "\n", "\n", "# Compute the metrics over all the labels", "\n", "\n", "# Choose only examples which have at least one positive in train_labels", "\n", "bool_arr", "=", "np", ".", "sum", "(", "p", ".", "label_ids", ",", "axis", "=", "1", ")", ">", "0", "\n", "\n", "# METRIC: LRAP (Label ranking average precision)", "\n", "total_lrap", "=", "label_ranking_average_precision_score", "(", "p", ".", "label_ids", "[", "bool_arr", "]", ",", "preds", "[", "bool_arr", "]", ")", "\n", "\n", "# METRIC: Coverage error", "\n", "total_coverage_error", "=", "coverage_error", "(", "p", ".", "label_ids", "[", "bool_arr", "]", ",", "preds", "[", "bool_arr", "]", ")", "\n", "\n", "# Compute the metrics for seen and unseen classes", "\n", "seen_lrap", ",", "seen_coverage_error", ",", "unseen_lrap", ",", "unseen_coverage_error", "=", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "if", "data_args", ".", "evaluation_type", "!=", "'seen'", ":", "\n", "            ", "key", "=", "'validation'", "if", "is_validation", "else", "'test'", "\n", "set_difference", "=", "list", "(", "set", "(", "label_list_dict", "[", "key", "]", ")", ".", "difference", "(", "set", "(", "label_list_dict", "[", "'train'", "]", ")", ")", ")", "\n", "set_difference", "=", "[", "label2id", "[", "label", "]", "for", "label", "in", "set_difference", "]", "\n", "# Take an intersection with the labels that are represented in the current data", "\n", "validation_labels", "=", "list", "(", "set", "(", "set_difference", ")", ".", "intersection", "(", "set", "(", "p", ".", "represented_labels", ")", ")", ")", "\n", "validation_labels", ".", "sort", "(", ")", "\n", "\n", "train_labels", "=", "[", "label2id", "[", "label", "]", "for", "label", "in", "label_list_dict", "[", "'train'", "]", "]", "\n", "\n", "# Compute metrics only on the train labels", "\n", "# Choose only examples which have at least one positive in train_labels", "\n", "bool_arr", "=", "np", ".", "sum", "(", "p", ".", "label_ids", "[", ":", ",", "train_labels", "]", ",", "axis", "=", "1", ")", ">", "0", "\n", "\n", "# METRIC: LRAP (Label ranking average precision)", "\n", "seen_lrap", "=", "label_ranking_average_precision_score", "(", "p", ".", "label_ids", "[", "bool_arr", "]", "[", ":", ",", "train_labels", "]", ",", "preds", "[", "bool_arr", "]", "[", ":", ",", "train_labels", "]", ")", "\n", "\n", "# METRIC: Coverage error", "\n", "seen_coverage_error", "=", "coverage_error", "(", "p", ".", "label_ids", "[", "bool_arr", "]", "[", ":", ",", "train_labels", "]", ",", "preds", "[", "bool_arr", "]", "[", ":", ",", "train_labels", "]", ")", "\n", "\n", "# Copmute metrics only on the eval labels            ", "\n", "if", "len", "(", "validation_labels", ")", ">", "0", ":", "\n", "\n", "# Choose only examples which have at least one positive in validation_labels", "\n", "                ", "bool_arr", "=", "np", ".", "sum", "(", "p", ".", "label_ids", "[", ":", ",", "validation_labels", "]", ",", "axis", "=", "1", ")", ">", "0", "\n", "\n", "# METRIC: LRAP (Label ranking average precision)", "\n", "unseen_lrap", "=", "label_ranking_average_precision_score", "(", "p", ".", "label_ids", "[", "bool_arr", "]", "[", ":", ",", "validation_labels", "]", ",", "preds", "[", "bool_arr", "]", "[", ":", ",", "validation_labels", "]", ")", "\n", "\n", "# METRIC: Coverage error", "\n", "# BUG: The following line does not work for some reason", "\n", "# unseen_coverage_error = coverage_error(p.label_ids[bool_arr][:,validation_labels], preds[bool_arr][:,validation_labels])", "\n", "\n", "", "", "return", "{", "\n", "\"total_lrap\"", ":", "total_lrap", ",", "\n", "\"total_coverage_error\"", ":", "total_coverage_error", ",", "\n", "\"seen_lrap\"", ":", "seen_lrap", ",", "\n", "\"seen_coverage_error\"", ":", "seen_coverage_error", ",", "\n", "\"unseen_lrap\"", ":", "unseen_lrap", ",", "\n", "# \"unseen_coverage_error\": unseen_coverage_error,", "\n", "\"fbr\"", ":", "{", "\"total_lrap\"", ":", "total_lrap", "}", ",", "\n", "}", "\n", "\n", "", "return", "compute_metrics", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1Trainer.__init__": [[31, 34], ["transformers.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "label_descriptions_dataloader", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Initialize the parent class", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1Trainer.log": [[36, 54], ["copy.deepcopy", "trainer.RCV1Trainer.state.log_history.append", "trainer.RCV1Trainer.callback_handler.on_log", "round", "output.pop", "copy.deepcopy.pop", "output.keys"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "logs", ":", "Dict", "[", "str", ",", "float", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Remove unnecessary keys in the logs to keep the Wandb dashboard clean\n        \"\"\"", "\n", "if", "self", ".", "state", ".", "epoch", "is", "not", "None", ":", "\n", "            ", "logs", "[", "\"epoch\"", "]", "=", "round", "(", "self", ".", "state", ".", "epoch", ",", "2", ")", "\n", "\n", "", "output", "=", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "self", ".", "state", ".", "global_step", "}", "}", "\n", "\n", "# Remove any key which contains fbr in it because it is a threshold", "\n", "logs_copy", "=", "copy", ".", "deepcopy", "(", "logs", ")", "\n", "remove_keys", "=", "[", "key", "for", "key", "in", "output", ".", "keys", "(", ")", "if", "'fbr'", "in", "key", "]", "\n", "for", "key", "in", "remove_keys", ":", "\n", "            ", "output", ".", "pop", "(", "key", ")", "\n", "logs_copy", ".", "pop", "(", "key", ")", "\n", "\n", "", "self", ".", "state", ".", "log_history", ".", "append", "(", "output", ")", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_log", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ",", "logs_copy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.__init__": [[57, 63], ["transformers.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "label_descriptions_dataloader", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Label descriptions", "\n", "        ", "self", ".", "label_descriptions_dataloader", "=", "label_descriptions_dataloader", "\n", "\n", "# Initialize the parent class", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.floating_point_ops": [[65, 70], ["hasattr", "trainer.RCV1TrainerLabelDescriptions.model.floating_point_ops"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.floating_point_ops"], ["", "def", "floating_point_ops", "(", "self", ",", "inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "model", ",", "\"floating_point_ops\"", ")", ":", "\n", "            ", "return", "self", ".", "model", ".", "floating_point_ops", "(", "inputs", "[", "'input_loader'", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.num_examples": [[72, 83], ["type", "len", "len"], "methods", ["None"], ["", "", "def", "num_examples", "(", "self", ",", "dataloader", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Helper to get number of samples in a :class:`~torch.utils.data.DataLoader` by accessing its dataset.\n\n        Will raise an exception if the underlying dataset does not implement method :obj:`__len__`\n        \"\"\"", "\n", "\n", "if", "type", "(", "dataloader", ")", "==", "CombinedLoader", ":", "\n", "            ", "return", "len", "(", "dataloader", ".", "loaders", "[", "'input_loader'", "]", ".", "dataset", ")", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "dataloader", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions._remove_unused_columns": [[85, 112], ["list", "inspect.signature", "list", "len", "logger.info", "packaging.version.parse", "packaging.version.parse", "dataset.set_format", "dataset.remove_columns", "inspect.signature.parameters.keys", "set", "set"], "methods", ["None"], ["", "", "def", "_remove_unused_columns", "(", "self", ",", "dataset", ",", "description", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "if", "not", "self", ".", "args", ".", "remove_unused_columns", ":", "\n", "            ", "return", "dataset", "\n", "", "if", "self", ".", "_signature_columns", "is", "None", ":", "\n", "# Inspect model forward signature to keep only the arguments it accepts.", "\n", "            ", "signature", "=", "inspect", ".", "signature", "(", "self", ".", "model", ".", "forward", ")", "\n", "self", ".", "_signature_columns", "=", "list", "(", "signature", ".", "parameters", ".", "keys", "(", ")", ")", "\n", "# Labels may be named label or label_ids, the default data collator handles that.", "\n", "# NOTE: Adding signature columns here", "\n", "self", ".", "_signature_columns", "+=", "[", "\"label\"", ",", "\"label_ids\"", ",", "]", "\n", "self", ".", "_signature_columns", "+=", "[", "'input_ids'", ",", "'attention_mask'", ",", "'token_type_ids'", ",", "'position_ids'", ",", "'head_mask'", ",", "'inputs_embeds'", ",", "'labels'", "]", "\n", "", "columns", "=", "[", "k", "for", "k", "in", "self", ".", "_signature_columns", "if", "k", "in", "dataset", ".", "column_names", "]", "\n", "ignored_columns", "=", "list", "(", "set", "(", "dataset", ".", "column_names", ")", "-", "set", "(", "self", ".", "_signature_columns", ")", ")", "\n", "if", "len", "(", "ignored_columns", ")", ">", "0", ":", "\n", "            ", "dset_description", "=", "\"\"", "if", "description", "is", "None", "else", "f\"in the {description} set \"", "\n", "logger", ".", "info", "(", "\n", "f\"The following columns {dset_description} don't have a corresponding argument in \"", "\n", "f\"`{self.model.__class__.__name__}.forward` and have been ignored: {', '.join(ignored_columns)}.\"", "\n", ")", "\n", "\n", "", "if", "version", ".", "parse", "(", "datasets", ".", "__version__", ")", "<", "version", ".", "parse", "(", "\"1.4.0\"", ")", ":", "\n", "            ", "dataset", ".", "set_format", "(", "\n", "type", "=", "dataset", ".", "format", "[", "\"type\"", "]", ",", "columns", "=", "columns", ",", "format_kwargs", "=", "dataset", ".", "format", "[", "\"format_kwargs\"", "]", "\n", ")", "\n", "return", "dataset", "\n", "", "else", ":", "\n", "            ", "return", "dataset", ".", "remove_columns", "(", "ignored_columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.log": [[114, 132], ["copy.deepcopy", "trainer.RCV1TrainerLabelDescriptions.state.log_history.append", "trainer.RCV1TrainerLabelDescriptions.callback_handler.on_log", "round", "output.pop", "copy.deepcopy.pop", "output.keys"], "methods", ["None"], ["", "", "def", "log", "(", "self", ",", "logs", ":", "Dict", "[", "str", ",", "float", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Remove unnecessary keys in the logs to keep the Wandb dashboard clean\n        \"\"\"", "\n", "if", "self", ".", "state", ".", "epoch", "is", "not", "None", ":", "\n", "            ", "logs", "[", "\"epoch\"", "]", "=", "round", "(", "self", ".", "state", ".", "epoch", ",", "2", ")", "\n", "\n", "", "output", "=", "{", "**", "logs", ",", "**", "{", "\"step\"", ":", "self", ".", "state", ".", "global_step", "}", "}", "\n", "\n", "# Remove any key which contains fbr in it because it is a threshold", "\n", "logs_copy", "=", "copy", ".", "deepcopy", "(", "logs", ")", "\n", "remove_keys", "=", "[", "key", "for", "key", "in", "output", ".", "keys", "(", ")", "if", "'fbr'", "in", "key", "]", "\n", "for", "key", "in", "remove_keys", ":", "\n", "            ", "output", ".", "pop", "(", "key", ")", "\n", "logs_copy", ".", "pop", "(", "key", ")", "\n", "\n", "", "self", ".", "state", ".", "log_history", ".", "append", "(", "output", ")", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_log", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ",", "logs_copy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions._prepare_input": [[134, 150], ["isinstance", "super()._prepare_input", "next", "isinstance", "iter", "data.keys", "type", "super()._prepare_input", "data.items"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions._prepare_input", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions._prepare_input"], ["", "def", "_prepare_input", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Prepares one :obj:`data` before feeding it to the model, be it a tensor or a nested list/dictionary of tensors.\n        \"\"\"", "\n", "if", "isinstance", "(", "data", ",", "Mapping", ")", ":", "\n", "# If the values are also mappings, then both the input and label descriptions are present", "\n", "# So recursively call this function", "\n", "# first_key = data.keys()[0]", "\n", "            ", "first_key", "=", "next", "(", "iter", "(", "data", ".", "keys", "(", ")", ")", ")", "\n", "if", "isinstance", "(", "data", "[", "first_key", "]", ",", "Mapping", ")", ":", "\n", "                ", "prepared_inputs", "=", "type", "(", "data", ")", "(", "{", "k", ":", "super", "(", "RCV1TrainerLabelDescriptions", ",", "self", ")", ".", "_prepare_input", "(", "v", ")", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", "}", ")", "\n", "return", "prepared_inputs", "\n", "\n", "# If the type of the inputs is not the one specified above,", "\n", "# call the function from the parent class", "\n", "", "", "return", "super", "(", "RCV1TrainerLabelDescriptions", ",", "self", ")", ".", "_prepare_input", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.get_train_dataloader": [[152, 165], ["super().get_train_dataloader", "trainer.RCV1TrainerLabelDescriptions.label_descriptions_dataloader.get_dataloader", "pytorch_lightning.trainer.supporters.CombinedLoader"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.get_train_dataloader", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_dataloader"], ["", "def", "get_train_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Combine the input dataloader with the label descriptions dataloader.\n        \"\"\"", "\n", "\n", "train_loader", "=", "super", "(", ")", ".", "get_train_dataloader", "(", ")", "\n", "label_loader", "=", "self", ".", "label_descriptions_dataloader", ".", "get_dataloader", "(", "'train'", ")", "\n", "\n", "# Combine the two dataloaders", "\n", "return", "CombinedLoader", "(", "{", "\n", "\"input_loader\"", ":", "train_loader", ",", "\n", "\"label_loader\"", ":", "label_loader", "\n", "}", ",", "\"min_size\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.get_eval_dataloader": [[167, 186], ["super().get_eval_dataloader", "pytorch_lightning.trainer.supporters.CombinedLoader", "trainer.RCV1TrainerLabelDescriptions.label_descriptions_dataloader.get_dataloader", "trainer.RCV1TrainerLabelDescriptions.label_descriptions_dataloader.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.get_eval_dataloader", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_dataloader", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_dataloader"], ["", "def", "get_eval_dataloader", "(", "self", ",", "eval_dataset", "=", "None", ",", "metric_key_prefix", "=", "\"eval\"", ")", ":", "\n", "\n", "        ", "eval_loader", "=", "super", "(", ")", ".", "get_eval_dataloader", "(", "eval_dataset", ")", "\n", "\n", "if", "metric_key_prefix", "==", "'eval'", ":", "\n", "            ", "label_loader", "=", "self", ".", "label_descriptions_dataloader", ".", "get_dataloader", "(", "'validation'", ")", "\n", "", "elif", "metric_key_prefix", "==", "'predict'", ":", "\n", "            ", "label_loader", "=", "self", ".", "label_descriptions_dataloader", ".", "get_dataloader", "(", "'test'", ")", "\n", "\n", "", "combined_dataloader", "=", "CombinedLoader", "(", "{", "\n", "\"input_loader\"", ":", "eval_loader", ",", "\n", "\"label_loader\"", ":", "label_loader", "\n", "}", ",", "\"min_size\"", ")", "\n", "\n", "# Add some attributes that will be used later", "\n", "combined_dataloader", ".", "batch_size", "=", "combined_dataloader", ".", "loaders", "[", "'input_loader'", "]", ".", "batch_size", "\n", "\n", "# Combine the two dataloaders", "\n", "return", "combined_dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.evaluate": [[188, 229], ["trainer.RCV1TrainerLabelDescriptions._memory_tracker.start", "trainer.RCV1TrainerLabelDescriptions.get_eval_dataloader", "time.time", "eval_loop", "eval_loop.metrics.update", "trainer.RCV1TrainerLabelDescriptions.log", "trainer.RCV1TrainerLabelDescriptions.callback_handler.on_evaluate", "trainer.RCV1TrainerLabelDescriptions._memory_tracker.stop_and_update_metrics", "transformers.trainer_utils.speed_metrics", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.get_eval_dataloader", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.log"], ["", "def", "evaluate", "(", "\n", "self", ",", "\n", "eval_dataset", "=", "None", ",", "\n", "ignore_keys", "=", "None", ",", "\n", "metric_key_prefix", ":", "str", "=", "\"eval\"", ",", "\n", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "\n", "# memory metrics - must set up as early as possible", "\n", "        ", "self", ".", "_memory_tracker", ".", "start", "(", ")", "\n", "\n", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", "eval_dataset", ",", "metric_key_prefix", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "eval_loop", "=", "self", ".", "prediction_loop", "if", "self", ".", "args", ".", "use_legacy_prediction_loop", "else", "self", ".", "evaluation_loop", "\n", "output", "=", "eval_loop", "(", "\n", "eval_dataloader", ",", "\n", "description", "=", "\"Evaluation\"", ",", "\n", "# No point gathering the predictions if there are no metrics, otherwise we defer to", "\n", "# self.args.prediction_loss_only", "\n", "prediction_loss_only", "=", "True", "if", "self", ".", "compute_metrics", "is", "None", "else", "None", ",", "\n", "ignore_keys", "=", "ignore_keys", ",", "\n", "metric_key_prefix", "=", "metric_key_prefix", ",", "\n", ")", "\n", "\n", "total_batch_size", "=", "self", ".", "args", ".", "eval_batch_size", "*", "self", ".", "args", ".", "world_size", "\n", "output", ".", "metrics", ".", "update", "(", "\n", "speed_metrics", "(", "\n", "metric_key_prefix", ",", "\n", "start_time", ",", "\n", "num_samples", "=", "output", ".", "num_samples", ",", "\n", "num_steps", "=", "math", ".", "ceil", "(", "output", ".", "num_samples", "/", "total_batch_size", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "log", "(", "output", ".", "metrics", ")", "\n", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_evaluate", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ",", "output", ".", "metrics", ")", "\n", "\n", "self", ".", "_memory_tracker", ".", "stop_and_update_metrics", "(", "output", ".", "metrics", ")", "\n", "\n", "return", "output", ".", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.evaluation_loop": [[231, 387], ["trainer.RCV1TrainerLabelDescriptions._wrap_model", "logger.info", "isinstance", "logger.info", "model.to.to.eval", "enumerate", "transformers.trainer_utils.denumpify_detensorize", "list", "transformers.trainer_utils.EvalLoopOutput", "logger.info", "logger.info", "transformers.trainer_pt_utils.find_batch_size", "trainer.RCV1TrainerLabelDescriptions.prediction_step", "trainer.RCV1TrainerLabelDescriptions.callback_handler.on_prediction_step", "hasattr", "delattr", "transformers.trainer_pt_utils.nested_numpify", "transformers.trainer_pt_utils.nested_numpify", "transformers.trainer_pt_utils.nested_numpify", "isinstance", "len", "transformers.trainer_pt_utils.nested_truncate", "transformers.trainer_pt_utils.nested_truncate", "eval_dataset.datasets[].label_order_dict.numpy", "trainer.RCV1TrainerLabelDescriptions.compute_metrics", "all_losses.mean().item", "trainer.RCV1TrainerLabelDescriptions.keys", "model.to.to.to", "trainer.RCV1TrainerLabelDescriptions._nested_gather", "trainer.RCV1TrainerLabelDescriptions._pad_across_processes", "trainer.RCV1TrainerLabelDescriptions._nested_gather", "trainer.RCV1TrainerLabelDescriptions._pad_across_processes", "trainer.RCV1TrainerLabelDescriptions._nested_gather", "numpy.concatenate", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_pt_utils.nested_concat", "isinstance", "hasattr", "utils.EvalPredictionLabelDescriptions", "key.startswith", "trainer.RCV1TrainerLabelDescriptions.pop", "model.to.to.to", "loss.repeat", "torch.cat", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_pt_utils.nested_numpify", "transformers.trainer_pt_utils.nested_numpify", "transformers.trainer_pt_utils.nested_numpify", "all_losses.mean", "trainer.RCV1TrainerLabelDescriptions.num_examples", "numpy.concatenate", "transformers.trainer_pt_utils.nested_concat", "transformers.trainer_pt_utils.nested_concat"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.prediction_step", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.num_examples"], ["", "def", "evaluation_loop", "(", "\n", "self", ",", "\n", "dataloader", ",", "\n", "description", ":", "str", ",", "\n", "prediction_loss_only", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "ignore_keys", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "metric_key_prefix", ":", "str", "=", "\"eval\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Prediction/evaluation loop, shared by :obj:`Trainer.evaluate()` and :obj:`Trainer.predict()`.\n\n        Works both with or without labels.\n        \"\"\"", "\n", "args", "=", "self", ".", "args", "\n", "\n", "prediction_loss_only", "=", "prediction_loss_only", "if", "prediction_loss_only", "is", "not", "None", "else", "args", ".", "prediction_loss_only", "\n", "\n", "model", "=", "self", ".", "_wrap_model", "(", "self", ".", "model", ",", "training", "=", "False", ")", "\n", "\n", "# if full fp16 or bf16 eval is wanted and this ``evaluation`` or ``predict`` isn't called", "\n", "# while ``train`` is running, cast it to the right dtype first and then put on device", "\n", "if", "not", "self", ".", "is_in_train", ":", "\n", "            ", "if", "args", ".", "fp16_full_eval", ":", "\n", "                ", "model", "=", "model", ".", "to", "(", "dtype", "=", "torch", ".", "float16", ",", "device", "=", "args", ".", "device", ")", "\n", "", "elif", "args", ".", "bf16_full_eval", ":", "\n", "                ", "model", "=", "model", ".", "to", "(", "dtype", "=", "torch", ".", "bfloat16", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "", "", "batch_size", "=", "dataloader", ".", "batch_size", "\n", "\n", "logger", ".", "info", "(", "f\"***** Running {description} *****\"", ")", "\n", "if", "isinstance", "(", "dataloader", ".", "dataset", ",", "collections", ".", "abc", ".", "Sized", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"  Num examples = {self.num_examples(dataloader)}\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Num examples: Unknown\"", ")", "\n", "", "logger", ".", "info", "(", "f\"  Batch size = {batch_size}\"", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "self", ".", "callback_handler", ".", "eval_dataloader", "=", "dataloader", "\n", "# Do this before wrapping.", "\n", "eval_dataset", "=", "dataloader", ".", "dataset", "\n", "\n", "if", "args", ".", "past_index", ">=", "0", ":", "\n", "            ", "self", ".", "_past", "=", "None", "\n", "\n", "# Initialize containers", "\n", "# losses/preds/labels on GPU/TPU (accumulated for eval_accumulation_steps)", "\n", "", "losses_host", "=", "None", "\n", "preds_host", "=", "None", "\n", "labels_host", "=", "None", "\n", "# losses/preds/labels on CPU (final containers)", "\n", "all_losses", "=", "None", "\n", "all_preds", "=", "None", "\n", "all_labels", "=", "None", "\n", "# Will be useful when we have an iterable dataset so don't know its length.", "\n", "\n", "observed_num_examples", "=", "0", "\n", "# Main evaluation loop", "\n", "for", "step", ",", "inputs", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "# Update the observed num examples", "\n", "            ", "observed_batch_size", "=", "find_batch_size", "(", "inputs", ")", "\n", "if", "observed_batch_size", "is", "not", "None", ":", "\n", "                ", "observed_num_examples", "+=", "observed_batch_size", "\n", "# For batch samplers, batch_size is not known by the dataloader in advance.", "\n", "if", "batch_size", "is", "None", ":", "\n", "                    ", "batch_size", "=", "observed_batch_size", "\n", "\n", "# Prediction step", "\n", "", "", "loss", ",", "logits", ",", "labels", "=", "self", ".", "prediction_step", "(", "model", ",", "inputs", ",", "prediction_loss_only", ",", "ignore_keys", "=", "ignore_keys", ")", "\n", "\n", "# Update containers on host", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "losses", "=", "self", ".", "_nested_gather", "(", "loss", ".", "repeat", "(", "batch_size", ")", ")", "\n", "losses_host", "=", "losses", "if", "losses_host", "is", "None", "else", "torch", ".", "cat", "(", "(", "losses_host", ",", "losses", ")", ",", "dim", "=", "0", ")", "\n", "", "if", "logits", "is", "not", "None", ":", "\n", "                ", "logits", "=", "self", ".", "_pad_across_processes", "(", "logits", ")", "\n", "logits", "=", "self", ".", "_nested_gather", "(", "logits", ")", "\n", "preds_host", "=", "logits", "if", "preds_host", "is", "None", "else", "nested_concat", "(", "preds_host", ",", "logits", ",", "padding_index", "=", "-", "100", ")", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "                ", "labels", "=", "self", ".", "_pad_across_processes", "(", "labels", ")", "\n", "labels", "=", "self", ".", "_nested_gather", "(", "labels", ")", "\n", "labels_host", "=", "labels", "if", "labels_host", "is", "None", "else", "nested_concat", "(", "labels_host", ",", "labels", ",", "padding_index", "=", "-", "100", ")", "\n", "", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_prediction_step", "(", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "\n", "# Gather all tensors and put them back on the CPU if we have done enough accumulation steps.", "\n", "if", "args", ".", "eval_accumulation_steps", "is", "not", "None", "and", "(", "step", "+", "1", ")", "%", "args", ".", "eval_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "losses_host", "is", "not", "None", ":", "\n", "                    ", "losses", "=", "nested_numpify", "(", "losses_host", ")", "\n", "all_losses", "=", "losses", "if", "all_losses", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_losses", ",", "losses", ")", ",", "axis", "=", "0", ")", "\n", "", "if", "preds_host", "is", "not", "None", ":", "\n", "                    ", "logits", "=", "nested_numpify", "(", "preds_host", ")", "\n", "all_preds", "=", "logits", "if", "all_preds", "is", "None", "else", "nested_concat", "(", "all_preds", ",", "logits", ",", "padding_index", "=", "-", "100", ")", "\n", "", "if", "labels_host", "is", "not", "None", ":", "\n", "                    ", "labels", "=", "nested_numpify", "(", "labels_host", ")", "\n", "all_labels", "=", "(", "\n", "labels", "if", "all_labels", "is", "None", "else", "nested_concat", "(", "all_labels", ",", "labels", ",", "padding_index", "=", "-", "100", ")", "\n", ")", "\n", "\n", "# Set back to None to begin a new accumulation", "\n", "", "losses_host", ",", "preds_host", ",", "labels_host", "=", "None", ",", "None", ",", "None", "\n", "\n", "", "", "if", "args", ".", "past_index", "and", "hasattr", "(", "self", ",", "\"_past\"", ")", ":", "\n", "# Clean the state at the end of the evaluation loop", "\n", "            ", "delattr", "(", "self", ",", "\"_past\"", ")", "\n", "\n", "# Gather all remaining tensors and put them back on the CPU", "\n", "", "if", "losses_host", "is", "not", "None", ":", "\n", "            ", "losses", "=", "nested_numpify", "(", "losses_host", ")", "\n", "all_losses", "=", "losses", "if", "all_losses", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_losses", ",", "losses", ")", ",", "axis", "=", "0", ")", "\n", "", "if", "preds_host", "is", "not", "None", ":", "\n", "            ", "logits", "=", "nested_numpify", "(", "preds_host", ")", "\n", "all_preds", "=", "logits", "if", "all_preds", "is", "None", "else", "nested_concat", "(", "all_preds", ",", "logits", ",", "padding_index", "=", "-", "100", ")", "\n", "", "if", "labels_host", "is", "not", "None", ":", "\n", "            ", "labels", "=", "nested_numpify", "(", "labels_host", ")", "\n", "all_labels", "=", "labels", "if", "all_labels", "is", "None", "else", "nested_concat", "(", "all_labels", ",", "labels", ",", "padding_index", "=", "-", "100", ")", "\n", "\n", "# Number of samples", "\n", "", "if", "not", "isinstance", "(", "eval_dataset", ".", "datasets", "[", "'input_loader'", "]", ",", "IterableDataset", ")", ":", "\n", "            ", "num_samples", "=", "len", "(", "eval_dataset", ".", "datasets", "[", "'input_loader'", "]", ")", "\n", "# The instance check is weird and does not actually check for the type, but whether the dataset has the right", "\n", "# methods. Therefore we need to make sure it also has the attribute.", "\n", "", "elif", "isinstance", "(", "eval_dataset", ".", "datasets", "[", "'input_loader'", "]", ",", "IterableDatasetShard", ")", "and", "hasattr", "(", "eval_dataset", ".", "datasets", "[", "'input_loader'", "]", ",", "\"num_examples\"", ")", ":", "\n", "            ", "num_samples", "=", "eval_dataset", ".", "datasets", "[", "'input_loader'", "]", ".", "num_examples", "\n", "", "else", ":", "\n", "            ", "num_samples", "=", "observed_num_examples", "\n", "\n", "# Number of losses has been rounded to a multiple of batch_size and in a distributed training, the number of", "\n", "# samplers has been rounded to a multiple of batch_size, so we truncate.", "\n", "", "if", "all_losses", "is", "not", "None", ":", "\n", "            ", "all_losses", "=", "all_losses", "[", ":", "num_samples", "]", "\n", "", "if", "all_preds", "is", "not", "None", ":", "\n", "            ", "all_preds", "=", "nested_truncate", "(", "all_preds", ",", "num_samples", ")", "\n", "", "if", "all_labels", "is", "not", "None", ":", "\n", "            ", "all_labels", "=", "nested_truncate", "(", "all_labels", ",", "num_samples", ")", "\n", "\n", "# Metrics!", "\n", "", "if", "self", ".", "compute_metrics", "is", "not", "None", "and", "all_preds", "is", "not", "None", "and", "all_labels", "is", "not", "None", ":", "\n", "# Choose only the labels that are required", "\n", "            ", "represented_labels", "=", "eval_dataset", ".", "datasets", "[", "'label_loader'", "]", ".", "label_order_dict", ".", "numpy", "(", ")", "\n", "all_labels", "=", "all_labels", "[", ":", ",", "represented_labels", "]", "\n", "metrics", "=", "self", ".", "compute_metrics", "(", "EvalPredictionLabelDescriptions", "(", "predictions", "=", "all_preds", ",", "label_ids", "=", "all_labels", ",", "represented_labels", "=", "represented_labels", ")", ")", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "\n", "# To be JSON-serializable, we need to remove numpy types or zero-d tensors", "\n", "", "metrics", "=", "denumpify_detensorize", "(", "metrics", ")", "\n", "\n", "if", "all_losses", "is", "not", "None", ":", "\n", "            ", "metrics", "[", "f\"{metric_key_prefix}_loss\"", "]", "=", "all_losses", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Prefix all keys with metric_key_prefix + '_'", "\n", "", "for", "key", "in", "list", "(", "metrics", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "not", "key", ".", "startswith", "(", "f\"{metric_key_prefix}_\"", ")", ":", "\n", "                ", "metrics", "[", "f\"{metric_key_prefix}_{key}\"", "]", "=", "metrics", ".", "pop", "(", "key", ")", "\n", "\n", "", "", "return", "EvalLoopOutput", "(", "predictions", "=", "all_preds", ",", "label_ids", "=", "all_labels", ",", "metrics", "=", "metrics", ",", "num_samples", "=", "num_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.prediction_step": [[389, 443], ["all", "trainer.RCV1TrainerLabelDescriptions._prepare_inputs", "transformers.trainer_pt_utils.nested_detach", "hasattr", "transformers.trainer_pt_utils.nested_detach", "torch.no_grad", "len", "getattr", "tuple", "len", "loss.mean().detach.mean().detach.mean().detach", "isinstance", "isinstance", "inputs[].get", "trainer.RCV1TrainerLabelDescriptions.autocast_smart_context_manager", "trainer.RCV1TrainerLabelDescriptions.compute_loss", "tuple", "trainer.RCV1TrainerLabelDescriptions.autocast_smart_context_manager", "model", "tuple", "inputs[].get", "loss.mean().detach.mean().detach.mean", "model.items", "model.items"], "methods", ["None"], ["", "def", "prediction_step", "(", "\n", "self", ",", "\n", "model", ",", "\n", "inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ",", "\n", "prediction_loss_only", ":", "bool", ",", "\n", "ignore_keys", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "\n", "        ", "has_labels", "=", "all", "(", "inputs", "[", "'input_loader'", "]", ".", "get", "(", "k", ")", "is", "not", "None", "for", "k", "in", "self", ".", "label_names", ")", "\n", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "if", "ignore_keys", "is", "None", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "model", ",", "\"config\"", ")", ":", "\n", "                ", "ignore_keys", "=", "getattr", "(", "self", ".", "model", ".", "config", ",", "\"keys_to_ignore_at_inference\"", ",", "[", "]", ")", "\n", "", "else", ":", "\n", "                ", "ignore_keys", "=", "[", "]", "\n", "\n", "# labels may be popped when computing the loss (label smoothing for instance) so we grab them first.", "\n", "", "", "if", "has_labels", ":", "\n", "            ", "labels", "=", "nested_detach", "(", "tuple", "(", "inputs", "[", "'input_loader'", "]", ".", "get", "(", "name", ")", "for", "name", "in", "self", ".", "label_names", ")", ")", "\n", "if", "len", "(", "labels", ")", "==", "1", ":", "\n", "                ", "labels", "=", "labels", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "labels", "=", "None", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "has_labels", ":", "\n", "                ", "with", "self", ".", "autocast_smart_context_manager", "(", ")", ":", "\n", "                    ", "loss", ",", "outputs", "=", "self", ".", "compute_loss", "(", "model", ",", "inputs", ",", "return_outputs", "=", "True", ")", "\n", "", "loss", "=", "loss", ".", "mean", "(", ")", ".", "detach", "(", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "dict", ")", ":", "\n", "                    ", "logits", "=", "tuple", "(", "v", "for", "k", ",", "v", "in", "outputs", ".", "items", "(", ")", "if", "k", "not", "in", "ignore_keys", "+", "[", "\"loss\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "logits", "=", "outputs", "[", "1", ":", "]", "\n", "", "", "else", ":", "\n", "                ", "loss", "=", "None", "\n", "with", "self", ".", "autocast_smart_context_manager", "(", ")", ":", "\n", "                    ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "", "if", "isinstance", "(", "outputs", ",", "dict", ")", ":", "\n", "                    ", "logits", "=", "tuple", "(", "v", "for", "k", ",", "v", "in", "outputs", ".", "items", "(", ")", "if", "k", "not", "in", "ignore_keys", ")", "\n", "", "else", ":", "\n", "                    ", "logits", "=", "outputs", "\n", "# TODO: this needs to be fixed and made cleaner later.", "\n", "", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "                    ", "self", ".", "_past", "=", "outputs", "[", "self", ".", "args", ".", "past_index", "-", "1", "]", "\n", "\n", "", "", "", "if", "prediction_loss_only", ":", "\n", "            ", "return", "(", "loss", ",", "None", ",", "None", ")", "\n", "\n", "", "logits", "=", "nested_detach", "(", "logits", ")", "\n", "if", "len", "(", "logits", ")", "==", "1", ":", "\n", "            ", "logits", "=", "logits", "[", "0", "]", "\n", "\n", "", "return", "(", "loss", ",", "logits", ",", "labels", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.TokenLabelDataset.__init__": [[20, 34], ["torch.utils.data.IterableDataset.__init__", "torch.LongTensor", "label_order_dict.items"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["def", "__init__", "(", "self", ",", "class_labels", ",", "tokenized_labels", ",", "label_order_dict", ",", "key_to_use", "=", "'input_ids'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# List of class labels", "\n", "self", ".", "class_labels", "=", "class_labels", "\n", "self", ".", "tokenized_labels", "=", "tokenized_labels", "\n", "\n", "# Create a mapping between order of label names to the integer id", "\n", "# For example, if the first class name in self.label_list_dict['train'] corresponds to integer ID 3, then store {1: 3}", "\n", "self", ".", "label_order_dict", "=", "torch", ".", "LongTensor", "(", "[", "value", "for", "_", ",", "value", "in", "label_order_dict", ".", "items", "(", ")", "]", ")", "\n", "\n", "# Get number of label descriptions for each class", "\n", "self", ".", "num_descriptions", "=", "{", "\n", "c", ":", "tokenized_labels", "[", "c", "]", "[", "key_to_use", "]", ".", "shape", "[", "0", "]", "for", "c", "in", "self", ".", "class_labels", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.TokenLabelDataset.__next__": [[36, 50], ["collections.defaultdict", "random.choice", "label_dataloader.TokenLabelDataset.tokenized_labels[].items", "torch.stack", "range", "fused[].append", "collections.defaultdict.items"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "fused", "=", "defaultdict", "(", "list", ")", "\n", "for", "c", "in", "self", ".", "class_labels", ":", "\n", "            ", "choice", "=", "random", ".", "choice", "(", "range", "(", "self", ".", "num_descriptions", "[", "c", "]", ")", ")", "\n", "# Choose the right descriptions for all the keys like `input_ids`, `attention_mask` etc.", "\n", "for", "k", ",", "v", "in", "self", ".", "tokenized_labels", "[", "c", "]", ".", "items", "(", ")", ":", "\n", "                ", "fused", "[", "k", "]", ".", "append", "(", "v", "[", "choice", "]", ")", "# choose random label", "\n", "# each key will return a tensor (num_classes, max_seq_len)", "\n", "", "", "label_output", "=", "{", "k", ":", "torch", ".", "stack", "(", "v", ")", "for", "k", ",", "v", "in", "fused", ".", "items", "(", ")", "}", "\n", "\n", "# Add a key to `label_output`", "\n", "label_output", "[", "'represented_labels'", "]", "=", "self", ".", "label_order_dict", "\n", "\n", "return", "label_output", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.TokenLabelDataset.__iter__": [[51, 53], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.__init__": [[63, 92], ["list", "label_dataloader.LabelDescriptionsDataloaderBase.get_datasets", "label_dataloader.LabelDescriptionsDataloaderBase.splits.append", "label_dataloader.LabelDescriptionsDataloaderBase.splits.append", "label_dataloader.LabelDescriptionsDataloaderBase.splits.append"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_datasets"], ["def", "__init__", "(", "self", ",", "data_args", ",", "training_args", ",", "tokenizer", ",", "label_list_dict", ",", "label2id", ",", "id2label", ")", ":", "\n", "        ", "\"\"\"\n        Args\n        tokenizer: Tokenizer to use for label descriptions.\n        label_list_dict: List of labels in train, validation, and test datasets.\n        label2id: Label name to integer ID that is fixed globally. This is useful for evaluation.\n        \"\"\"", "\n", "# Store all the arguments", "\n", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "training_args", "=", "training_args", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "label_list_dict", "=", "label_list_dict", "\n", "self", ".", "label2id", "=", "label2id", "\n", "self", ".", "id2label", "=", "id2label", "\n", "self", ".", "num_workers", "=", "self", ".", "training_args", ".", "dataloader_num_workers", "\n", "\n", "# Splits", "\n", "self", ".", "splits", "=", "list", "(", ")", "\n", "if", "training_args", ".", "do_train", ":", "\n", "            ", "self", ".", "splits", ".", "append", "(", "'train'", ")", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "            ", "self", ".", "splits", ".", "append", "(", "'validation'", ")", "\n", "", "if", "training_args", ".", "do_predict", ":", "\n", "            ", "self", ".", "splits", ".", "append", "(", "'test'", ")", "\n", "\n", "# Create the train, val, and test datasets", "\n", "# self.datasets is a dictionary with keys `train`, `validation`, and `test`", "\n", "# self.label_order_dict is a dictionary containing mapping from label to the integer ID corresponding to that label", "\n", "", "self", ".", "datasets", ",", "self", ".", "label_order_dict", "=", "self", ".", "get_datasets", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_train_dataset": [[94, 118], ["json.load.pop", "min", "collections.OrderedDict", "label_dataloader.TokenLabelDataset", "pathlib.Path().open", "json.load", "label_dataloader.LabelDescriptionsDataloaderBase.tokenizer", "pathlib.Path", "enumerate"], "methods", ["None"], ["", "def", "get_train_dataset", "(", "self", ",", "split", "=", "'train'", ")", ":", "\n", "\n", "# Get the train dataset", "\n", "        ", "with", "Path", "(", "self", ".", "data_args", ".", "label_descriptions_train_file", ")", ".", "open", "(", ")", "as", "f", ":", "\n", "            ", "train_labels", "=", "json", ".", "load", "(", "f", ")", "\n", "", "train_labels", ".", "pop", "(", "'Root'", ",", "None", ")", "\n", "\n", "# Tokenize the train dataset", "\n", "padding", "=", "\"max_length\"", "if", "self", ".", "data_args", ".", "pad_to_max_length", "else", "False", "\n", "max_seq_length", "=", "min", "(", "self", ".", "data_args", ".", "label_max_seq_length", ",", "self", ".", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "tokenized_labels", "=", "{", "\n", "c", ":", "self", ".", "tokenizer", "(", "\n", "train_labels", "[", "c", "]", ",", "truncation", "=", "True", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "return_tensors", "=", "'pt'", ")", "\n", "for", "c", "in", "self", ".", "label_list_dict", "[", "'train'", "]", "\n", "}", "\n", "# Create a mapping between order of label names to the integer id", "\n", "# For example, if the first class name in self.label_list_dict['train'] corresponds to integer ID 3, then store {1: 3}", "\n", "label_order_dict", "=", "OrderedDict", "(", "[", "(", "idx", ",", "self", ".", "label2id", "[", "value", "]", ")", "for", "idx", ",", "value", "in", "enumerate", "(", "self", ".", "label_list_dict", "[", "'train'", "]", ")", "]", ")", "\n", "\n", "# Create the dataset for label descriptions", "\n", "label_dataset", "=", "TokenLabelDataset", "(", "class_labels", "=", "self", ".", "label_list_dict", "[", "'train'", "]", ",", "tokenized_labels", "=", "tokenized_labels", ",", "label_order_dict", "=", "label_order_dict", ")", "\n", "\n", "return", "label_dataset", ",", "label_order_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_validation_dataset": [[120, 164], ["getattr", "json.load.pop", "min", "label_dataloader.TokenLabelDataset", "pathlib.Path().open", "json.load", "collections.OrderedDict", "label_dataloader.LabelDescriptionsDataloaderBase.tokenizer", "collections.OrderedDict", "pathlib.Path", "len", "len", "json.load.keys", "len", "len", "label_dataloader.LabelDescriptionsDataloaderBase.tokenizer", "enumerate", "range", "collections.OrderedDict.keys", "range", "len", "len"], "methods", ["None"], ["", "def", "get_validation_dataset", "(", "self", ",", "split", "=", "'validation'", ")", ":", "\n", "\n", "# Get the validation label dataset", "\n", "        ", "label_file_name", "=", "getattr", "(", "self", ".", "data_args", ",", "'label_descriptions_{}_file'", ".", "format", "(", "split", ")", ")", "\n", "label_file", "=", "label_file_name", "if", "label_file_name", "else", "self", ".", "data_args", ".", "label_descriptions_train_file", "\n", "\n", "with", "Path", "(", "label_file", ")", ".", "open", "(", ")", "as", "f", ":", "\n", "            ", "validation_labels", "=", "json", ".", "load", "(", "f", ")", "\n", "", "validation_labels", ".", "pop", "(", "'Root'", ",", "None", ")", "\n", "\n", "# Tokenize the train dataset", "\n", "padding", "=", "\"max_length\"", "if", "self", ".", "data_args", ".", "pad_to_max_length", "else", "False", "\n", "max_seq_length", "=", "min", "(", "self", ".", "data_args", ".", "label_max_seq_length", ",", "self", ".", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "# Create a mapping between order of label names to the integer id", "\n", "# For example, if the first class name in self.label_list_dict[split] corresponds to integer ID 3, then store {1: 3}", "\n", "# Check if it is the zero-shot setting or the generalized zero-shot setting", "\n", "if", "self", ".", "data_args", ".", "evaluation_type", "==", "'zs'", ":", "\n", "            ", "label_order_dict", "=", "OrderedDict", "(", "[", "(", "idx", ",", "self", ".", "label2id", "[", "value", "]", ")", "for", "idx", ",", "value", "in", "enumerate", "(", "self", ".", "label_list_dict", "[", "split", "]", ")", "]", ")", "\n", "class_labels", "=", "self", ".", "label_list_dict", "[", "split", "]", "\n", "\n", "tokenized_labels", "=", "{", "\n", "c", ":", "self", ".", "tokenizer", "(", "\n", "validation_labels", "[", "c", "]", ",", "truncation", "=", "True", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "return_tensors", "=", "'pt'", ")", "\n", "for", "c", "in", "self", ".", "label_list_dict", "[", "split", "]", "\n", "}", "\n", "", "elif", "self", ".", "data_args", ".", "evaluation_type", "==", "'gzs'", ":", "\n", "# Make sure all the classes are represented in the label descriptions", "\n", "            ", "assert", "len", "(", "validation_labels", ")", "==", "len", "(", "self", ".", "label2id", ")", ",", "\"Some classes are missing in the label descriptions file of {}.\\\n                                                                Only following classes represented: {} \\\n                                                                Total classes = {}. Expected = {}\"", ".", "format", "(", "split", ",", "validation_labels", ".", "keys", "(", ")", ",", "len", "(", "validation_labels", ")", ",", "len", "(", "self", ".", "label2id", ")", ")", "\n", "label_order_dict", "=", "OrderedDict", "(", "[", "(", "idx", ",", "idx", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "label2id", ")", ")", "]", ")", "\n", "class_labels", "=", "[", "self", ".", "id2label", "[", "idx", "]", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "id2label", ")", ")", "]", "\n", "\n", "tokenized_labels", "=", "{", "\n", "self", ".", "id2label", "[", "c", "]", ":", "self", ".", "tokenizer", "(", "\n", "validation_labels", "[", "self", ".", "id2label", "[", "c", "]", "]", ",", "truncation", "=", "True", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "return_tensors", "=", "'pt'", ")", "\n", "for", "c", "in", "label_order_dict", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "# Create the dataset for label descriptions", "\n", "", "label_dataset", "=", "TokenLabelDataset", "(", "class_labels", "=", "class_labels", ",", "tokenized_labels", "=", "tokenized_labels", ",", "label_order_dict", "=", "label_order_dict", ")", "\n", "\n", "return", "label_dataset", ",", "label_order_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_test_dataset": [[166, 168], ["label_dataloader.LabelDescriptionsDataloaderBase.get_validation_dataset"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_validation_dataset"], ["", "def", "get_test_dataset", "(", "self", ",", "split", "=", "'test'", ")", ":", "\n", "        ", "return", "self", ".", "get_validation_dataset", "(", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_datasets": [[170, 185], ["dict", "collections.OrderedDict", "getattr", "getattr."], "methods", ["None"], ["", "def", "get_datasets", "(", "self", ")", ":", "\n", "# Open all the datasets specified", "\n", "# The train dataset is the dataset for all splits", "\n", "        ", "datasets", "=", "dict", "(", ")", "\n", "label_order_dict", "=", "OrderedDict", "(", ")", "\n", "\n", "# Iterate over the required functions", "\n", "# self.split is usually ['train', 'validation', 'test']", "\n", "for", "key", "in", "self", ".", "splits", ":", "\n", "            ", "function", "=", "getattr", "(", "self", ",", "'get_{}_dataset'", ".", "format", "(", "key", ")", ")", "\n", "dataset", ",", "label_order", "=", "function", "(", ")", "\n", "datasets", "[", "key", "]", "=", "dataset", "\n", "label_order_dict", "[", "key", "]", "=", "label_order", "\n", "\n", "", "return", "datasets", ",", "label_order_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderBase.get_dataloader": [[187, 192], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "get_dataloader", "(", "self", ",", "split", "=", "'train'", ")", ":", "\n", "        ", "\"\"\"\n        Return the dataloader corresponding to the split name\n        \"\"\"", "\n", "return", "DataLoader", "(", "self", ".", "datasets", "[", "split", "]", ",", "num_workers", "=", "self", ".", "num_workers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.__init__": [[202, 215], ["gensim.downloader.load", "label_dataloader.LabelDescriptionsDataloaderWord2Vec.glove_vectors.key_to_index.keys", "label_dataloader.LabelDescriptionsDataloaderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args\n        tokenizer: Tokenizer to use for label descriptions.\n        label_list_dict: List of labels in train, validation, and test datasets.\n        label2id: Label name to integer ID that is fixed globally. This is useful for evaluation.\n        \"\"\"", "\n", "\n", "# Load the word2vec model", "\n", "self", ".", "glove_vectors", "=", "gensim", ".", "downloader", ".", "load", "(", "'glove-wiki-gigaword-300'", ")", "\n", "self", ".", "glove_vectors_keys", "=", "self", ".", "glove_vectors", ".", "key_to_index", ".", "keys", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_average_embeddings": [[217, 243], ["sentence.strip().split", "len", "average_embeddings.append", "torch.Tensor", "word.lower.lower.lower", "sentence.strip().split", "sentence.strip", "sentence.strip", "label_dataloader.LabelDescriptionsDataloaderWord2Vec.glove_vectors.get_index"], "methods", ["None"], ["", "def", "get_average_embeddings", "(", "self", ",", "list_of_sentences", ")", ":", "\n", "        ", "\"\"\"\n        Average word embeddings of words in a sentence and return a list.\n        Only lowercase.\n\n        Treating unknown words as zero vectors.\n        \"\"\"", "\n", "\n", "average_embeddings", "=", "[", "]", "\n", "\n", "for", "sentence", "in", "list_of_sentences", ":", "\n", "            ", "sum_of_embeddings", "=", "0.", "\n", "for", "word", "in", "sentence", ".", "strip", "(", ")", ".", "split", "(", ")", ":", "\n", "                ", "word", "=", "word", ".", "lower", "(", ")", "\n", "if", "word", "in", "self", ".", "glove_vectors_keys", ":", "\n", "                    ", "sum_of_embeddings", "+=", "self", ".", "glove_vectors", ".", "vectors", "[", "self", ".", "glove_vectors", ".", "get_index", "(", "word", ")", "]", "\n", "\n", "# Average the embeddings", "\n", "", "", "sum_of_embeddings", "/=", "len", "(", "sentence", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "\n", "# Append to a list", "\n", "average_embeddings", ".", "append", "(", "sum_of_embeddings", ")", "\n", "\n", "", "average_embeddings", "=", "{", "'embeddings'", ":", "torch", ".", "Tensor", "(", "average_embeddings", ")", "}", "\n", "\n", "return", "average_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_train_dataset": [[245, 263], ["json.load.pop", "collections.OrderedDict", "label_dataloader.TokenLabelDataset", "pathlib.Path().open", "json.load", "label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_average_embeddings", "pathlib.Path", "enumerate"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_average_embeddings"], ["", "def", "get_train_dataset", "(", "self", ",", "split", "=", "'train'", ")", ":", "\n", "\n", "# Get the train dataset", "\n", "        ", "with", "Path", "(", "self", ".", "data_args", ".", "label_descriptions_train_file", ")", ".", "open", "(", ")", "as", "f", ":", "\n", "            ", "train_labels", "=", "json", ".", "load", "(", "f", ")", "\n", "", "train_labels", ".", "pop", "(", "'Root'", ",", "None", ")", "\n", "\n", "# Get the average embeddings for all the descriptions by using the gensim model", "\n", "average_embeddings", "=", "{", "c", ":", "self", ".", "get_average_embeddings", "(", "train_labels", "[", "c", "]", ")", "for", "c", "in", "self", ".", "label_list_dict", "[", "'train'", "]", "}", "\n", "\n", "# Create a mapping between order of label names to the integer id", "\n", "# For example, if the first class name in self.label_list_dict['train'] corresponds to integer ID 3, then store {1: 3}", "\n", "label_order_dict", "=", "OrderedDict", "(", "[", "(", "idx", ",", "self", ".", "label2id", "[", "value", "]", ")", "for", "idx", ",", "value", "in", "enumerate", "(", "self", ".", "label_list_dict", "[", "'train'", "]", ")", "]", ")", "\n", "\n", "# Create the dataset for label descriptions", "\n", "label_dataset", "=", "TokenLabelDataset", "(", "class_labels", "=", "self", ".", "label_list_dict", "[", "'train'", "]", ",", "tokenized_labels", "=", "average_embeddings", ",", "label_order_dict", "=", "label_order_dict", ",", "key_to_use", "=", "'embeddings'", ")", "\n", "\n", "return", "label_dataset", ",", "label_order_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_validation_dataset": [[265, 298], ["getattr", "json.load.pop", "label_dataloader.TokenLabelDataset", "pathlib.Path().open", "json.load", "collections.OrderedDict", "label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_average_embeddings", "collections.OrderedDict", "pathlib.Path", "len", "len", "json.load.keys", "len", "len", "label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_average_embeddings", "enumerate", "range", "collections.OrderedDict.keys", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_average_embeddings", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.label_dataloader.LabelDescriptionsDataloaderWord2Vec.get_average_embeddings"], ["", "def", "get_validation_dataset", "(", "self", ",", "split", "=", "'validation'", ")", ":", "\n", "\n", "# Get the validation label dataset", "\n", "        ", "label_file_name", "=", "getattr", "(", "self", ".", "data_args", ",", "'label_descriptions_{}_file'", ".", "format", "(", "split", ")", ")", "\n", "label_file", "=", "label_file_name", "if", "label_file_name", "else", "self", ".", "data_args", ".", "label_descriptions_train_file", "\n", "\n", "with", "Path", "(", "label_file", ")", ".", "open", "(", ")", "as", "f", ":", "\n", "            ", "validation_labels", "=", "json", ".", "load", "(", "f", ")", "\n", "", "validation_labels", ".", "pop", "(", "'Root'", ",", "None", ")", "\n", "\n", "# Create a mapping between order of label names to the integer id", "\n", "# For example, if the first class name in self.label_list_dict[split] corresponds to integer ID 3, then store {1: 3}", "\n", "# Check if it is the zero-shot setting or the generalized zero-shot setting", "\n", "if", "self", ".", "data_args", ".", "evaluation_type", "==", "'zs'", ":", "\n", "            ", "label_order_dict", "=", "OrderedDict", "(", "[", "(", "idx", ",", "self", ".", "label2id", "[", "value", "]", ")", "for", "idx", ",", "value", "in", "enumerate", "(", "self", ".", "label_list_dict", "[", "split", "]", ")", "]", ")", "\n", "class_labels", "=", "self", ".", "label_list_dict", "[", "split", "]", "\n", "\n", "average_embeddings", "=", "{", "c", ":", "self", ".", "get_average_embeddings", "(", "validation_labels", "[", "c", "]", ")", "for", "c", "in", "self", ".", "label_list_dict", "[", "split", "]", "}", "\n", "\n", "", "elif", "self", ".", "data_args", ".", "evaluation_type", "==", "'gzs'", ":", "\n", "# Make sure all the classes are represented in the label descriptions", "\n", "            ", "assert", "len", "(", "validation_labels", ")", "==", "len", "(", "self", ".", "label2id", ")", ",", "\"Some classes are missing in the label descriptions file of {}.\\\n                                                                Only following classes represented: {} \\\n                                                                Total classes = {}. Expected = {}\"", ".", "format", "(", "split", ",", "validation_labels", ".", "keys", "(", ")", ",", "len", "(", "validation_labels", ")", ",", "len", "(", "self", ".", "label2id", ")", ")", "\n", "label_order_dict", "=", "OrderedDict", "(", "[", "(", "idx", ",", "idx", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "label2id", ")", ")", "]", ")", "\n", "class_labels", "=", "[", "self", ".", "id2label", "[", "idx", "]", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "id2label", ")", ")", "]", "\n", "\n", "average_embeddings", "=", "{", "self", ".", "id2label", "[", "c", "]", ":", "self", ".", "get_average_embeddings", "(", "validation_labels", "[", "self", ".", "id2label", "[", "c", "]", "]", ")", "for", "c", "in", "label_order_dict", ".", "keys", "(", ")", "}", "\n", "\n", "# Create the dataset for label descriptions", "\n", "", "label_dataset", "=", "TokenLabelDataset", "(", "class_labels", "=", "class_labels", ",", "tokenized_labels", "=", "average_embeddings", ",", "label_order_dict", "=", "label_order_dict", ",", "key_to_use", "=", "'embeddings'", ")", "\n", "\n", "return", "label_dataset", ",", "label_order_dict", "", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.legacy.multilabel_metrics": [[7, 55], ["expit", "np.where", "accuracy_score", "f1_score", "f1_score", "get_ancestors", "compute_hierarchical_micro_f1", "classification_report", "print", "isinstance", "np.sum", "range", "len"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.get_ancestors", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.metrics.compute_hierarchical_micro_f1"], ["def", "multilabel_metrics", "(", "data_args", ",", "id2label", ",", "label2id", ",", "fbr", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Metrics function used for multilabel classification.\n    Datasets: RCV1-V2\n\n    :fbr : A dict containing global thresholds to be used for selecting a class.\n    We use global thresholds because we want to handle unseen classes,\n    for which the threshold is not known in advance.\n    \"\"\"", "\n", "def", "compute_metrics", "(", "p", ")", ":", "\n", "# Collect the logits", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "\n", "# Compute the logistic sigmoid", "\n", "preds", "=", "expit", "(", "preds", ")", "\n", "\n", "# Convert them to 0 and 1's based on prediction", "\n", "threshold", "=", "0.5", "\n", "preds", "=", "np", ".", "where", "(", "preds", ">", "threshold", ",", "1", ",", "0", ")", "\n", "\n", "# Compute the subset accuracy", "\n", "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html", "\n", "subset_accuracy", "=", "accuracy_score", "(", "p", ".", "label_ids", ",", "preds", ")", "\n", "\n", "# Compute the standard accuracy", "\n", "accuracy", "=", "np", ".", "sum", "(", "p", ".", "label_ids", "==", "preds", ")", "/", "preds", ".", "size", "*", "100", "\n", "\n", "# Multi-label F-1", "\n", "macro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "preds", ",", "average", "=", "'macro'", ")", "\n", "micro_f1", "=", "f1_score", "(", "p", ".", "label_ids", ",", "preds", ",", "average", "=", "'micro'", ")", "\n", "\n", "# Hierarchical micro F1", "\n", "ancestor_dict", "=", "get_ancestors", "(", "data_args", ",", "label2id", ")", "\n", "hier_micro_f1", "=", "compute_hierarchical_micro_f1", "(", "preds", ",", "p", ".", "label_ids", ",", "ancestor_dict", ",", "id2label", ")", "\n", "\n", "# Multi-label classification report", "\n", "report", "=", "classification_report", "(", "p", ".", "label_ids", ",", "preds", ",", "target_names", "=", "[", "id2label", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "id2label", ")", ")", "]", ")", "\n", "print", "(", "report", ")", "\n", "\n", "return", "{", "\n", "\"accuracy\"", ":", "accuracy", ",", "\n", "\"subset_accuracy\"", ":", "subset_accuracy", ",", "\n", "\"macro_f1\"", ":", "macro_f1", ",", "\n", "\"micro_f1\"", ":", "micro_f1", ",", "\n", "\"hier_micro_f1\"", ":", "hier_micro_f1", ",", "\n", "}", "\n", "\n", "", "return", "compute_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.modify_config": [[16, 34], ["transformers.AutoConfig.from_pretrained", "dir", "setattr", "getattr"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["def", "modify_config", "(", "config", ",", "data_args", ",", "model_args", "=", "None", ")", ":", "\n", "    ", "if", "data_args", ".", "task_name", "==", "'rcv1'", ":", "\n", "        ", "config", ".", "problem_type", "=", "\"multi_label_classification\"", "\n", "\n", "# Add attributes from data_args to config", "\n", "# If they already exist in the config, then use that", "\n", "", "attributes_to_add", "=", "[", "'freeze_label_model'", ",", "'share_label_model'", ",", "'relative_weight_positive_samples'", ",", "'label_model_hidden_size'", ",", "'normalize_label_embeddings'", ",", "'use_hinge_loss'", ",", "'hinge_margin_value'", ",", "'label_loss_type'", ",", "'focal_loss_gamma'", ",", "'use_gile'", "]", "\n", "\n", "for", "attribute", "in", "attributes_to_add", ":", "\n", "        ", "if", "attribute", "not", "in", "dir", "(", "config", ")", ":", "\n", "            ", "setattr", "(", "config", ",", "attribute", ",", "getattr", "(", "data_args", ",", "attribute", ")", ")", "\n", "\n", "", "", "if", "not", "config", ".", "label_model_hidden_size", "and", "not", "data_args", ".", "share_label_model", "and", "model_args", ":", "\n", "        ", "label_config", "=", "AutoConfig", ".", "from_pretrained", "(", "data_args", ".", "label_model_name_or_path", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "config", ".", "label_model_hidden_size", "=", "label_config", ".", "hidden_size", "\n", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.get_label_lists": [[36, 48], ["dict", "list", "label_list_dict[].sort", "set", "itertools.chain"], "function", ["None"], ["", "def", "get_label_lists", "(", "datasets", ")", ":", "\n", "    ", "\"\"\"\n    Get the list of labels being used in train, validation, and test datasets\n    \"\"\"", "\n", "\n", "label_list_dict", "=", "dict", "(", ")", "\n", "\n", "for", "key", "in", "datasets", ":", "\n", "        ", "label_list_dict", "[", "key", "]", "=", "list", "(", "set", "(", "itertools", ".", "chain", "(", "*", "datasets", "[", "key", "]", "[", "\"bip:topics:1.0\"", "]", ")", ")", ")", "\n", "label_list_dict", "[", "key", "]", ".", "sort", "(", ")", "\n", "\n", "", "return", "label_list_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.utils.get_label_embedding_model": [[50, 84], ["transformers.AutoTokenizer.from_pretrained", "print", "print", "print", "print", "transformers.AutoModel.from_pretrained"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["", "def", "get_label_embedding_model", "(", "model", ",", "data_args", ",", "model_args", ")", ":", "\n", "    ", "\"\"\"\n    Get the config, tokenizer, and model for label embedding\n    \"\"\"", "\n", "\n", "# Instantiate the tokenizer", "\n", "label_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "data_args", ".", "label_model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "model", ".", "label_tokenizer", "=", "label_tokenizer", "\n", "\n", "# Print a warning about where the label model is coming from", "\n", "print", "(", "\"*********** Source of label model ***********\"", ")", "\n", "if", "data_args", ".", "use_label_model_from_checkpoint", ":", "\n", "        ", "print", "(", "\"Being initialized from checkpoint: {}\"", ".", "format", "(", "model_args", ".", "model_name_or_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Being initialized from data_args.label_model_name_or_path: {}\"", ".", "format", "(", "data_args", ".", "label_model_name_or_path", ")", ")", "\n", "\n", "label_model", "=", "AutoModel", ".", "from_pretrained", "(", "\n", "data_args", ".", "label_model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "model", ".", "label_model", "=", "label_model", "\n", "", "print", "(", "\"*********************************************\"", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_rcv1_heldout_split.create_dataset_split": [[18, 58], ["random.seed", "collections.Counter", "list", "open", "open.close", "jsonlines.open", "collections.Counter.update", "random.sample", "int", "os.path.join", "open.write", "all_docs.append", "len", "new_docs.append", "int", "str", "json.dumps", "len"], "function", ["None"], ["def", "create_dataset_split", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "# Read the JSON file containing one JSON per line and store the dict", "\n", "\n", "all_docs", "=", "[", "]", "\n", "\n", "with", "jsonlines", ".", "open", "(", "args", ".", "file", ")", "as", "reader", ":", "\n", "        ", "for", "obj", "in", "reader", ":", "\n", "            ", "all_docs", ".", "append", "(", "obj", ")", "\n", "\n", "# Get a list of all the labels    ", "\n", "", "", "label_statistics", "=", "Counter", "(", ")", "\n", "for", "doc", "in", "all_docs", ":", "\n", "        ", "label_statistics", ".", "update", "(", "doc", "[", "'bip:topics:1.0'", "]", ")", "\n", "", "all_labels", "=", "list", "(", "label_statistics", ")", "\n", "\n", "# Ignore some labels and always place them in the train set", "\n", "# ignore_labels = ['CCAT', 'MCAT', 'ECAT', 'GCAT']", "\n", "ignore_labels", "=", "[", "'CCAT'", ",", "'C15'", ",", "'C151'", ",", "'C17'", ",", "'C18'", ",", "'C31'", ",", "'C33'", ",", "'C41'", ",", "'ECAT'", ",", "'E12'", ",", "'E13'", ",", "'E14'", ",", "'E21'", ",", "'E31'", ",", "'E41'", ",", "'E51'", ",", "'GCAT'", ",", "'G15'", ",", "'MCAT'", ",", "'M13'", ",", "'M14'", "]", "\n", "all_labels", "=", "[", "label", "for", "label", "in", "all_labels", "if", "label", "not", "in", "ignore_labels", "]", "\n", "\n", "# Choose a certain fraction of labels as the train labels", "\n", "train_labels", "=", "ignore_labels", "+", "random", ".", "sample", "(", "all_labels", ",", "k", "=", "int", "(", "len", "(", "all_labels", ")", "*", "args", ".", "train_fraction", ")", ")", "\n", "\n", "# Remove labels in train_labels from the train data", "\n", "new_docs", "=", "[", "]", "\n", "for", "doc", "in", "all_docs", ":", "\n", "        ", "doc", "[", "'bip:topics:1.0'", "]", "=", "[", "topic", "for", "topic", "in", "doc", "[", "'bip:topics:1.0'", "]", "if", "topic", "in", "train_labels", "]", "\n", "if", "len", "(", "doc", "[", "'bip:topics:1.0'", "]", ")", "!=", "0", ":", "\n", "            ", "new_docs", ".", "append", "(", "doc", ")", "\n", "\n", "# Create a new file", "\n", "# Store list of dicts as a json", "\n", "", "", "save_name", "=", "'rcv1_train_{}_{}.json'", ".", "format", "(", "int", "(", "args", ".", "train_fraction", "*", "100", ")", ",", "args", ".", "seed", ")", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "save_name", ")", ",", "'w'", ",", "encoding", "=", "\"ISO-8859-1\"", ")", "\n", "\n", "for", "document", "in", "new_docs", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "json", ".", "dumps", "(", "document", ")", ")", "+", "'\\n'", ")", "\n", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_rcv1_heldout_split.main": [[60, 72], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "create_rcv1_heldout_split.create_dataset_split"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.create_dataset_split"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Dataset Arguments", "\n", "parser", ".", "add_argument", "(", "\"--file\"", ",", "default", "=", "'/n/fs/nlp-asd/asd/asd/Projects/SemanticLabelEmbeddings/data/RCV1/rcv1_processed/rcv1_train.json'", ",", "type", "=", "str", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_fraction\"", ",", "default", "=", "0.75", ",", "type", "=", "float", ",", "help", "=", "\"Percentage of classes that should be in the train dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "default", "=", "'/n/fs/nlp-asd/asd/asd/Projects/SemanticLabelEmbeddings/data/RCV1/rcv1_heldout'", ",", "type", "=", "str", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "\"Random seed for splitting classes.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "create_dataset_split", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.convert_raw_rcv1_to_json.process_rcv1": [[13, 62], ["list", "os.walk", "tqdm.tqdm", "open", "open.close", "filename.endswith", "os.path.join", "open.write", "os.path.join", "bs4.BeautifulSoup", "dict", "bs4.BeautifulSoup.find().get", "open().read", "bs4.BeautifulSoup.find", "bs4.BeautifulSoup.find", "filename.strip().split", "document_list.append", "str", "bs4.BeautifulSoup.find", "bs4.BeautifulSoup.find", "bs4.BeautifulSoup.find().find_all", "json.dumps", "open", "filename.strip", "bs4.BeautifulSoup.find().find_all", "document[].append", "bs4.BeautifulSoup.find", "code.get", "bs4.BeautifulSoup.find"], "function", ["None"], ["def", "process_rcv1", "(", "args", ")", ":", "\n", "# Read all the XML files in the folder", "\n", "    ", "list_of_files", "=", "list", "(", ")", "\n", "for", "(", "dirpath", ",", "dirnames", ",", "filenames", ")", "in", "os", ".", "walk", "(", "args", ".", "path_to_rcv1", ")", ":", "\n", "        ", "list_of_files", "+=", "[", "os", ".", "path", ".", "join", "(", "dirpath", ",", "file", ")", "for", "file", "in", "filenames", "]", "\n", "\n", "# Store list of dicts", "\n", "", "document_list", "=", "[", "]", "\n", "\n", "# Read each XML file and store it in a JSON", "\n", "for", "filename", "in", "tqdm", "(", "list_of_files", ")", ":", "\n", "        ", "if", "filename", ".", "endswith", "(", "'.xml'", ")", ":", "\n", "            ", "flag", "=", "True", "\n", "bs_data", "=", "BeautifulSoup", "(", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "\"ISO-8859-1\"", ")", ".", "read", "(", ")", ",", "\"lxml\"", ")", "\n", "\n", "# Construct a dictionary with required fields", "\n", "document", "=", "dict", "(", ")", "\n", "document", "[", "'title'", "]", "=", "bs_data", ".", "find", "(", "'title'", ")", ".", "text", "\n", "document", "[", "'headline'", "]", "=", "bs_data", ".", "find", "(", "'headline'", ")", ".", "text", "\n", "document", "[", "'newsitem'", "]", "=", "bs_data", ".", "find", "(", "'newsitem'", ")", ".", "get", "(", "'itemid'", ")", "\n", "document", "[", "'folder'", "]", "=", "filename", ".", "strip", "(", ")", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "\n", "# Text", "\n", "document", "[", "'text'", "]", "=", "' '", ".", "join", "(", "[", "data", ".", "text", "for", "data", "in", "bs_data", ".", "find", "(", "'text'", ")", ".", "find_all", "(", "'p'", ")", "]", ")", "\n", "\n", "# Codes", "\n", "code_types", "=", "[", "'bip:topics:1.0'", ",", "'bip:industries:1.0'", ",", "'bip:countries:1.0'", "]", "\n", "for", "code_type", "in", "code_types", ":", "\n", "                ", "if", "bs_data", ".", "find", "(", "'codes'", ",", "{", "'class'", ":", "code_type", "}", ")", "is", "None", ":", "\n", "                    ", "if", "code_type", "==", "'bip:topics:1.0'", ":", "\n", "                        ", "flag", "=", "False", "\n", "", "else", ":", "\n", "                        ", "document", "[", "code_type", "]", "=", "None", "\n", "", "", "else", ":", "\n", "                    ", "document", "[", "code_type", "]", "=", "[", "]", "\n", "for", "code", "in", "bs_data", ".", "find", "(", "'codes'", ",", "{", "'class'", ":", "code_type", "}", ")", ".", "find_all", "(", "'code'", ")", ":", "\n", "                        ", "document", "[", "code_type", "]", ".", "append", "(", "code", ".", "get", "(", "'code'", ")", ")", "\n", "\n", "# Append to the dictionary", "\n", "", "", "", "if", "flag", ":", "\n", "                ", "document_list", ".", "append", "(", "document", ")", "\n", "\n", "# Store list of dicts as a json", "\n", "", "", "", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "args", ".", "save_name", ")", ",", "'w'", ",", "encoding", "=", "\"ISO-8859-1\"", ")", "\n", "\n", "for", "document", "in", "document_list", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "json", ".", "dumps", "(", "document", ")", ")", "+", "'\\n'", ")", "\n", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.convert_raw_rcv1_to_json.main": [[64, 75], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "convert_raw_rcv1_to_json.process_rcv1"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.convert_raw_rcv1_to_json.process_rcv1"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Dataset Arguments", "\n", "parser", ".", "add_argument", "(", "\"--path_to_rcv1\"", ",", "type", "=", "str", ",", "default", "=", "\"/n/fs/nlp-asd/asd/asd/Projects/SemanticLabelEmbeddings/data/RCV1/rcv1_small\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_name\"", ",", "type", "=", "str", ",", "default", "=", "\"rcv1_all.json\"", ",", "help", "=", "\"\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "process_rcv1", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_rcv1_heldout_split_stratified.create_dataset_split": [[18, 76], ["random.seed", "collections.Counter", "list", "open", "open.close", "jsonlines.open", "collections.Counter.update", "train_labels.extend", "int", "os.path.join", "open.write", "all_docs.append", "random.sample", "len", "new_docs.append", "[].split", "str", "int", "json.dumps", "os.path.split", "len"], "function", ["None"], ["def", "create_dataset_split", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "# Read the JSON file containing one JSON per line and store the dict", "\n", "\n", "all_docs", "=", "[", "]", "\n", "\n", "with", "jsonlines", ".", "open", "(", "args", ".", "file", ")", "as", "reader", ":", "\n", "        ", "for", "obj", "in", "reader", ":", "\n", "            ", "all_docs", ".", "append", "(", "obj", ")", "\n", "\n", "# Get a list of all the labels    ", "\n", "", "", "label_statistics", "=", "Counter", "(", ")", "\n", "for", "doc", "in", "all_docs", ":", "\n", "        ", "label_statistics", ".", "update", "(", "doc", "[", "'bip:topics:1.0'", "]", ")", "\n", "", "all_labels", "=", "list", "(", "label_statistics", ")", "\n", "\n", "# Ignore some labels and always place them in the train set", "\n", "# ignore_labels = ['CCAT', 'MCAT', 'ECAT', 'GCAT']", "\n", "ignore_labels", "=", "[", "'CCAT'", ",", "'C15'", ",", "'C151'", ",", "'C17'", ",", "'C18'", ",", "'C31'", ",", "'C33'", ",", "'C41'", ",", "'ECAT'", ",", "'E12'", ",", "'E13'", ",", "'E14'", ",", "'E21'", ",", "'E31'", ",", "'E41'", ",", "'E51'", ",", "'GCAT'", ",", "'G15'", ",", "'MCAT'", ",", "'M13'", ",", "'M14'", "]", "\n", "sibling_leaves", "=", "[", "[", "'C11'", ",", "'C12'", ",", "'C13'", ",", "'C14'", ",", "'C16'", ",", "'C17'", "]", ",", "\n", "[", "'C151'", ",", "'C152'", "]", ",", "\n", "[", "'C171'", ",", "'C172'", ",", "'C173'", ",", "'C174'", "]", ",", "\n", "[", "'C181'", ",", "'C182'", ",", "'C183'", "]", ",", "\n", "[", "'C21'", ",", "'C22'", ",", "'C23'", ",", "'C24'", "]", ",", "\n", "[", "'C311'", ",", "'C312'", ",", "'C313'", "]", ",", "\n", "[", "'C32'", ",", "'C34'", "]", ",", "\n", "[", "'E131'", ",", "'E132'", "]", ",", "\n", "[", "'E141'", ",", "'E142'", ",", "'E143'", "]", ",", "\n", "[", "'E211'", ",", "'E212'", "]", ",", "\n", "[", "'E311'", ",", "'E312'", ",", "'E313'", "]", ",", "\n", "[", "'E511'", ",", "'E512'", ",", "'E513'", "]", ",", "\n", "[", "'G151'", ",", "'G152'", ",", "'G153'", ",", "'G154'", ",", "'G155'", ",", "'G156'", ",", "'G157'", ",", "'G158'", ",", "'G159'", "]", ",", "\n", "[", "\"GCRIM\"", ",", "\"GDEF\"", ",", "\"GDIP\"", ",", "\"GDIS\"", ",", "\"GENT\"", ",", "\"GENV\"", ",", "\"GFAS\"", ",", "\"GHEA\"", ",", "\"GJOB\"", ",", "\"GMIL\"", ",", "\"GOBIT\"", ",", "\"GODD\"", ",", "\"GPOL\"", ",", "\"GPRO\"", ",", "\"GREL\"", ",", "\"GSCI\"", ",", "\"GSPO\"", ",", "\"GTOUR\"", ",", "\"GVIO\"", ",", "\"GVOTE\"", ",", "\"GWEA\"", ",", "\"GWELF\"", "]", ",", "\n", "[", "'M131'", ",", "'M132'", "]", ",", "\n", "[", "'M141'", ",", "'M142'", ",", "'M143'", "]", ",", "\n", "]", "\n", "\n", "# Choose a certain fraction of labels as the train labels", "\n", "train_labels", "=", "ignore_labels", "\n", "for", "siblings", "in", "sibling_leaves", ":", "\n", "        ", "train_labels", ".", "extend", "(", "random", ".", "sample", "(", "siblings", ",", "k", "=", "int", "(", "len", "(", "siblings", ")", "*", "args", ".", "train_fraction", ")", ")", ")", "\n", "\n", "# Remove labels in train_labels from the train data", "\n", "", "new_docs", "=", "[", "]", "\n", "for", "doc", "in", "all_docs", ":", "\n", "        ", "doc", "[", "'bip:topics:1.0'", "]", "=", "[", "topic", "for", "topic", "in", "doc", "[", "'bip:topics:1.0'", "]", "if", "topic", "in", "train_labels", "]", "\n", "if", "len", "(", "doc", "[", "'bip:topics:1.0'", "]", ")", "!=", "0", ":", "\n", "            ", "new_docs", ".", "append", "(", "doc", ")", "\n", "\n", "# Create a new file", "\n", "# Store list of dicts as a json", "\n", "", "", "save_name", "=", "'{}_stratified_heldout_{}_{}.json'", ".", "format", "(", "os", ".", "path", ".", "split", "(", "args", ".", "file", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ",", "int", "(", "args", ".", "train_fraction", "*", "100", ")", ",", "args", ".", "seed", ")", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "save_name", ")", ",", "'w'", ",", "encoding", "=", "\"ISO-8859-1\"", ")", "\n", "\n", "for", "document", "in", "new_docs", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "json", ".", "dumps", "(", "document", ")", ")", "+", "'\\n'", ")", "\n", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_rcv1_heldout_split_stratified.main": [[78, 90], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "create_rcv1_heldout_split_stratified.create_dataset_split"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.create_dataset_split"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Dataset Arguments", "\n", "parser", ".", "add_argument", "(", "\"--file\"", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_fraction\"", ",", "default", "=", "0.75", ",", "type", "=", "float", ",", "help", "=", "\"Percentage of classes that should be in the train dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "\"Random seed for splitting classes.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "create_dataset_split", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_rcv1_superclass_split.create_dataset_split": [[17, 54], ["random.seed", "collections.Counter", "list", "open", "open.close", "jsonlines.open", "collections.Counter.update", "os.path.split", "os.path.join", "open.write", "all_docs.append", "len", "new_docs.append", "str", "json.dumps"], "function", ["None"], ["def", "create_dataset_split", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "# Read the JSON file containing one JSON per line and store the dict", "\n", "\n", "all_docs", "=", "[", "]", "\n", "\n", "with", "jsonlines", ".", "open", "(", "args", ".", "file", ")", "as", "reader", ":", "\n", "        ", "for", "obj", "in", "reader", ":", "\n", "            ", "all_docs", ".", "append", "(", "obj", ")", "\n", "\n", "# Get a list of all the labels    ", "\n", "", "", "label_statistics", "=", "Counter", "(", ")", "\n", "for", "doc", "in", "all_docs", ":", "\n", "        ", "label_statistics", ".", "update", "(", "doc", "[", "'bip:topics:1.0'", "]", ")", "\n", "", "all_labels", "=", "list", "(", "label_statistics", ")", "\n", "\n", "# Ignore superclass labels during training", "\n", "super_class_labels", "=", "[", "'C15'", ",", "'C151'", ",", "'C17'", ",", "'C18'", ",", "'C31'", ",", "'C33'", ",", "'C41'", ",", "'E12'", ",", "'E13'", ",", "'E14'", ",", "'E21'", ",", "'E31'", ",", "'E41'", ",", "'E51'", ",", "'G15'", ",", "'M13'", ",", "'M14'", "]", "\n", "train_labels", "=", "[", "label", "for", "label", "in", "all_labels", "if", "label", "not", "in", "super_class_labels", "]", "\n", "\n", "# Remove labels in train_labels from the train data", "\n", "new_docs", "=", "[", "]", "\n", "for", "doc", "in", "all_docs", ":", "\n", "        ", "doc", "[", "'bip:topics:1.0'", "]", "=", "[", "topic", "for", "topic", "in", "doc", "[", "'bip:topics:1.0'", "]", "if", "topic", "in", "train_labels", "]", "\n", "if", "len", "(", "doc", "[", "'bip:topics:1.0'", "]", ")", "!=", "0", ":", "\n", "            ", "new_docs", ".", "append", "(", "doc", ")", "\n", "\n", "# Create a new file", "\n", "# Store list of dicts as a json", "\n", "", "", "save_name", "=", "'rcv1_superclass_{}.json'", ".", "format", "(", "args", ".", "seed", ")", "\n", "args", ".", "save_dir", "=", "os", ".", "path", ".", "split", "(", "args", ".", "file", ")", "[", "0", "]", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "save_name", ")", ",", "'w'", ",", "encoding", "=", "\"ISO-8859-1\"", ")", "\n", "\n", "for", "document", "in", "new_docs", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "json", ".", "dumps", "(", "document", ")", ")", "+", "'\\n'", ")", "\n", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_rcv1_superclass_split.main": [[56, 66], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "create_rcv1_superclass_split.create_dataset_split"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.create_dataset_split"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Dataset Arguments", "\n", "parser", ".", "add_argument", "(", "\"--file\"", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "\"Random seed for splitting classes.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "create_dataset_split", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.create_dataset_split": [[17, 49], ["random.seed", "random.shuffle", "int", "zip", "jsonlines.open", "open", "open.close", "all_docs.append", "int", "int", "len", "os.path.split", "os.path.join", "open.write", "len", "len", "str", "json.dumps"], "function", ["None"], ["def", "create_dataset_split", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "# Read the JSON file containing one JSON per line and store the dict", "\n", "\n", "all_docs", "=", "[", "]", "\n", "\n", "with", "jsonlines", ".", "open", "(", "args", ".", "file", ")", "as", "reader", ":", "\n", "        ", "for", "obj", "in", "reader", ":", "\n", "            ", "all_docs", ".", "append", "(", "obj", ")", "\n", "\n", "# Randomly split into train, val, and test", "\n", "", "", "random", ".", "shuffle", "(", "all_docs", ")", "\n", "train_docs", "=", "all_docs", "[", ":", "int", "(", "len", "(", "all_docs", ")", "*", "args", ".", "train_fraction", ")", "]", "\n", "remaining", "=", "all_docs", "[", "int", "(", "len", "(", "all_docs", ")", "*", "args", ".", "train_fraction", ")", ":", "]", "\n", "\n", "# Randomly split into val and test", "\n", "split", "=", "int", "(", "args", ".", "val_fraction", "/", "(", "1", "-", "args", ".", "train_fraction", ")", "*", "len", "(", "remaining", ")", ")", "\n", "val_docs", "=", "remaining", "[", ":", "split", "]", "\n", "test_docs", "=", "remaining", "[", "split", ":", "]", "\n", "\n", "# Store all the files", "\n", "files", "=", "[", "train_docs", ",", "val_docs", ",", "test_docs", "]", "\n", "\n", "for", "docs", ",", "name", "in", "zip", "(", "files", ",", "[", "'train'", ",", "'val'", ",", "'test'", "]", ")", ":", "\n", "        ", "save_name", "=", "'rcv1_{}.json'", ".", "format", "(", "name", ")", "\n", "args", ".", "save_dir", "=", "os", ".", "path", ".", "split", "(", "args", ".", "file", ")", "[", "0", "]", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "save_name", ")", ",", "'w'", ",", "encoding", "=", "\"ISO-8859-1\"", ")", "\n", "\n", "for", "document", "in", "docs", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "json", ".", "dumps", "(", "document", ")", ")", "+", "'\\n'", ")", "\n", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.main": [[51, 63], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "create_train_val_test_splits.create_dataset_split"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.preprocessing.create_train_val_test_splits.create_dataset_split"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Dataset Arguments", "\n", "parser", ".", "add_argument", "(", "\"--file\"", ",", "default", "=", "'/n/fs/nlp-asd/asd/asd/Projects/SemanticLabelEmbeddings/data/RCV1/rcv1_processed/rcv1_train.json'", ",", "type", "=", "str", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_fraction\"", ",", "default", "=", "0.75", ",", "type", "=", "float", ",", "help", "=", "\"Amount of data in the train dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_fraction\"", ",", "default", "=", "0.20", ",", "type", "=", "float", ",", "help", "=", "\"Amount of data in the validation dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "\"Random seed for splitting classes.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "create_dataset_split", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.SemSupModelArgs.__post_init__": [[69, 72], ["warnings.warn"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "pretrained_label_model", "and", "not", "self", ".", "tune_label_model", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"not tuning a scratch label model\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.BaseModel.__init__": [[77, 84], ["pytorch_lightning.LightningModule.__init__", "core.BaseModel.save_hyperparameters", "dict"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["def", "__init__", "(", "self", ",", "args", ":", "BaseModelArgs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "\n", "# a dictionary, where key is the metric name and value is torchmetrics.Metric object", "\n", "self", ".", "metrics", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.BaseModel.forward": [[85, 96], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"All inheriting classes should override this\n        Args:\n            batch: the batch from the input_loader\n\n        Return (tuple): logits, targets, loss. Can be anything, as long as compatible with training_step(), validation_step()\n            logits (Any): the logits generated by the model\n            targets (Any): the targets\n            loss (Any): the loss\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.BaseModel.step": [[97, 99], ["core.BaseModel."], "methods", ["None"], ["", "def", "step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "self", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.BaseModel.configure_optimizers": [[100, 106], ["transformers.AdamW", "core.BaseModel.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "AdamW", "(", "\n", "self", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "args", ".", "lr", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", "\n", "weight_decay", "=", "self", ".", "args", ".", "weight_decay", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.BaseModel.training_step": [[108, 112], ["core.BaseModel.step", "core.BaseModel.log"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.SemSupModel.step", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.log"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "logits", ",", "targets", ",", "loss", "=", "self", ".", "step", "(", "batch", ")", "\n", "self", ".", "log", "(", "\"train_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.BaseModel.validation_step": [[113, 118], ["core.BaseModel.step", "core.BaseModel.metrics.items", "metric"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.SemSupModel.step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "dataloader_idx", "=", "0", ")", ":", "\n", "        ", "logits", ",", "targets", ",", "loss", "=", "self", ".", "step", "(", "batch", ")", "\n", "for", "name", ",", "metric", "in", "self", ".", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "metric", "(", "logits", ",", "targets", ")", "\n", "", "return", "{", "\"loss\"", ":", "loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.BaseModel.validation_epoch_end": [[119, 125], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "core.BaseModel.log", "core.BaseModel.metrics.items", "core.BaseModel.log", "metric.reset", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "metric.compute"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.log", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.trainer.RCV1TrainerLabelDescriptions.log"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "self", ".", "log", "(", "\"val_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ")", "\n", "for", "name", ",", "metric", "in", "self", ".", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "log", "(", "name", ",", "metric", ".", "compute", "(", ")", ",", "prog_bar", "=", "True", ")", "\n", "metric", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.SemSupModel.__init__": [[130, 135], ["core.BaseModel.__init__", "core.get_text_model"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__", "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.get_text_model"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "label_model", "=", "get_text_model", "(", "\n", "model", "=", "self", ".", "args", ".", "label_model", ",", "pretrained", "=", "self", ".", "args", ".", "pretrained_label_model", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.SemSupModel.forward": [[137, 149], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "label_rep", ")", ":", "\n", "        ", "\"\"\"All inheriting classes should override this\n        Args:\n            batch: the batch from the input_loader\n            label_rep (torch.Tensor[d_model, n_class]): torch tensor of the label representation from the label encoder\n\n        Return (tuple): logits, targets, loss. Can be anything, as long as compatible with training_step(), validation_step()\n            logits (Any): the logits generated by the model\n            targets (Any): the targets\n            loss (Any): the loss\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.SemSupModel.step": [[150, 158], ["core.SemSupModel.", "v.squeeze", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "label_rep.t.t.t", "batch[].items", "core.SemSupModel.label_model"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "label_batch", "=", "{", "k", ":", "v", ".", "squeeze", "(", "0", ")", "for", "k", ",", "v", "in", "batch", "[", "\"label_loader\"", "]", ".", "items", "(", ")", "}", "\n", "with", "torch", ".", "set_grad_enabled", "(", "self", ".", "args", ".", "tune_label_model", ")", ":", "\n", "            ", "label_rep", "=", "self", ".", "label_model", "(", "\n", "**", "label_batch", "\n", ")", ".", "pooler_output", "# (n_class, d_model)", "\n", "label_rep", "=", "label_rep", ".", "t", "(", ")", "# (d_model, n_class)", "\n", "", "return", "self", "(", "batch", "[", "\"input_loader\"", "]", ",", "label_rep", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.get_text_model": [[19, 41], ["isinstance", "isinstance", "Exception", "ModelMakerCls.from_pretrained", "transformers.AutoConfig.from_pretrained", "ModelMakerCls.from_config"], "function", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["def", "get_text_model", "(", "\n", "model", ":", "Union", "[", "nn", ".", "Module", ",", "str", "]", ",", "pretrained", ":", "bool", ",", "classifier", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "nn", ".", "Module", ":", "\n", "    ", "\"\"\"Helper function for instantiating text models\n    Args:\n        model (nn.Module or str): the model to instantiate. If nn.Module, all other params ignored.\n        pretrained (bool): whether to instantiate a pretrained-model\n        classifier (bool): whether to add a classification head to the model\n        **kwargs: goes to the from_pretrained() function for instance to pass num_labels for classifier\n    \"\"\"", "\n", "ModelMakerCls", "=", "AutoModelForSequenceClassification", "if", "classifier", "else", "AutoModel", "\n", "\n", "if", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "        ", "return", "model", "\n", "", "elif", "isinstance", "(", "model", ",", "str", ")", ":", "\n", "        ", "if", "pretrained", ":", "\n", "            ", "return", "ModelMakerCls", ".", "from_pretrained", "(", "model", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "model_config", "=", "AutoConfig", ".", "from_pretrained", "(", "model", ",", "**", "kwargs", ")", "\n", "return", "ModelMakerCls", ".", "from_config", "(", "model_config", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"model must be a str or nn.Module\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text.BertSemSup.__init__": [[40, 49], ["core.SemSupModel.__init__", "core.get_text_model", "torch.Linear", "torch.Linear", "torch.Linear", "torchmetrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__", "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.get_text_model"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "BertSemSupArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "get_text_model", "(", "\n", "model", "=", "self", ".", "args", ".", "model", ",", "\n", "pretrained", "=", "self", ".", "args", ".", "pretrained_model", ",", "\n", ")", "\n", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "512", ",", "512", ",", "bias", "=", "False", ")", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text.BertSemSup.forward": [[50, 57], ["batch.pop", "text.BertSemSup.projection", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "text.BertSemSup.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "label_rep", ")", ":", "\n", "        ", "targets", "=", "batch", ".", "pop", "(", "\"labels\"", ")", "\n", "input_rep", "=", "self", ".", "model", "(", "**", "batch", ")", ".", "pooler_output", "# (bs, d_model)", "\n", "input_rep", "=", "self", ".", "projection", "(", "input_rep", ")", "\n", "logits", "=", "input_rep", "@", "label_rep", "# (bs, n_class)", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text.BertBaseline.__init__": [[60, 72], ["core.BaseModel.__init__", "core.get_text_model", "torchmetrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__", "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.get_text_model"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "BertBaselineArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "self", ".", "label_model", "=", "None", "\n", "self", ".", "model", "=", "get_text_model", "(", "\n", "model", "=", "self", ".", "args", ".", "model", ",", "\n", "pretrained", "=", "self", ".", "args", ".", "pretrained_model", ",", "\n", "classifier", "=", "True", ",", "\n", "num_labels", "=", "args", ".", "num_labels", "\n", ")", "\n", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text.BertBaseline.forward": [[73, 79], ["batch.pop", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "text.BertBaseline.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch", "=", "batch", "[", "\"input_loader\"", "]", "\n", "targets", "=", "batch", ".", "pop", "(", "\"labels\"", ")", "\n", "logits", "=", "self", ".", "model", "(", "**", "batch", ")", ".", "logits", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text.DEVISEBaseline.__init__": [[82, 92], ["core.BaseModel.__init__", "core.get_text_model", "torch.Linear", "torch.Linear", "torch.Linear", "torchmetrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__", "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.core.get_text_model"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "DEVISEBaselineArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "self", ".", "label_model", "=", "None", "\n", "self", ".", "model", "=", "get_text_model", "(", "\n", "model", "=", "self", ".", "args", ".", "model", ",", "\n", "pretrained", "=", "self", ".", "args", ".", "pretrained_model", ",", "\n", ")", "\n", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "512", ",", "300", ",", "bias", "=", "False", ")", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text.DEVISEBaseline.forward": [[93, 108], ["[].squeeze().t", "batch.pop", "text.DEVISEBaseline.projection", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "text.DEVISEBaseline.model", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "[].squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "label_rep", "=", "batch", "[", "\"label_loader\"", "]", "[", "\"glove_emb\"", "]", ".", "squeeze", "(", ")", ".", "t", "(", ")", "#(300, n_class)", "\n", "\n", "batch", "=", "batch", "[", "\"input_loader\"", "]", "\n", "targets", "=", "batch", ".", "pop", "(", "\"labels\"", ")", "\n", "input_rep", "=", "self", ".", "model", "(", "**", "batch", ")", ".", "pooler_output", "# (bs, d_model)", "\n", "input_rep", "=", "self", ".", "projection", "(", "input_rep", ")", "# (bs, 300)", "\n", "\n", "if", "self", ".", "args", ".", "use_gile", ":", "\n", "            ", "label_rep", "=", "torch", ".", "tanh", "(", "label_rep", ")", "\n", "input_rep", "=", "torch", ".", "tanh", "(", "input_rep", ")", "\n", "\n", "", "logits", "=", "input_rep", "@", "label_rep", "# (bs, n_class)", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertForSemanticEmbedding.__init__": [[14, 23], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "transformers.BertModel", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "# Create a placeholder for the label_model", "\n", "self", ".", "label_model", "=", "BertModel", "(", "config", ")", "\n", "\n", "# Projection layer for label embedding model", "\n", "if", "not", "self", ".", "config", ".", "share_label_model", ":", "\n", "            ", "self", ".", "label_projection", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "label_model_hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertForSemanticEmbedding.forward": [[27, 67], ["input_loader.pop", "text_transfer.BertForSemanticEmbedding.bert", "label_loader.keys", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "text_transfer.BertForSemanticEmbedding.label_model", "text_transfer.BertForSemanticEmbedding.bert", "text_transfer.BertForSemanticEmbedding.label_model"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_loader", "=", "None", ",", "label_loader", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :input_loader contains the inputs to be fed to self.roberta\n        :label_loader contains the inputs to be fed to the label model self.label_model\n        \"\"\"", "\n", "\n", "# STEP 1: Store the labels", "\n", "# During training, some classes might be held-out", "\n", "# Mask those classes so that they are not treated as negatives", "\n", "targets", "=", "input_loader", ".", "pop", "(", "'labels'", ")", "\n", "# represented_labels = label_loader.pop('represented_labels')[0]", "\n", "# labels = labels[:, represented_labels]", "\n", "\n", "# STEP 2: Forward pass through the input model", "\n", "outputs", "=", "self", ".", "bert", "(", "**", "input_loader", ")", "\n", "# outputs[1] for the BERT model and outputs[0] for the RoBERTa model", "\n", "sequence_output", "=", "outputs", "[", "1", "]", "\n", "input_cls_repr", "=", "sequence_output", "\n", "\n", "# STEP 3: Forward pass through the label model", "\n", "# The label loader adds an extra dimension at the beginning of the tensors", "\n", "# Remove them", "\n", "for", "key", "in", "label_loader", ".", "keys", "(", ")", ":", "\n", "            ", "label_loader", "[", "key", "]", "=", "torch", ".", "squeeze", "(", "label_loader", "[", "key", "]", ",", "0", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "label_representations", "=", "self", ".", "label_model", "(", "**", "label_loader", ")", "[", "1", "]", "# (n_class, d_model)", "\n", "if", "self", ".", "config", ".", "share_label_model", ":", "\n", "                ", "label_representations", "=", "self", ".", "bert", "(", "**", "label_loader", ")", "[", "1", "]", "# (n_class, d_model)", "\n", "", "else", ":", "\n", "                ", "label_representations", "=", "self", ".", "label_model", "(", "**", "label_loader", ")", "[", "1", "]", "# (n_class, d_model)", "\n", "label_representations", "=", "label_representations", "@", "self", ".", "label_projection", ".", "weight", "\n", "\n", "# Normalize the label representations if required", "\n", "", "", "if", "self", ".", "config", ".", "normalize_label_embeddings", ":", "\n", "            ", "label_representations", "=", "nn", ".", "functional", ".", "normalize", "(", "label_representations", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute the logits", "\n", "", "logits", "=", "input_cls_repr", "@", "label_representations", ".", "T", "# (bs, n_class)", "\n", "\n", "return", "logits", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertForWord2Vec.__init__": [[70, 80], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "\n", "# NOTE: No label model", "\n", "\n", "# Projection layer for label embedding model", "\n", "if", "not", "self", ".", "config", ".", "share_label_model", ":", "\n", "# self.label_projection = nn.Linear(config.hidden_size, config.label_model_hidden_size)", "\n", "            ", "self", ".", "label_projection", "=", "nn", ".", "Linear", "(", "config", ".", "label_model_hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertForWord2Vec.forward": [[84, 126], ["input_loader.pop", "text_transfer.BertForWord2Vec.bert", "label_loader.keys", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_loader", "=", "None", ",", "label_loader", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :input_loader contains the inputs to be fed to self.roberta\n        :label_loader contains the inputs to be fed to the label model self.label_model\n        \"\"\"", "\n", "\n", "# STEP 1: Store the labels", "\n", "# During training, some classes might be held-out", "\n", "# Mask those classes so that they are not treated as negatives", "\n", "targets", "=", "input_loader", ".", "pop", "(", "'labels'", ")", "\n", "# represented_labels = label_loader.pop('represented_labels')[0]", "\n", "# labels = labels[:, represented_labels]", "\n", "\n", "# STEP 2: Forward pass through the input model", "\n", "outputs", "=", "self", ".", "bert", "(", "**", "input_loader", ")", "\n", "# outputs[1] for the BERT model and outputs[0] for the RoBERTa model", "\n", "sequence_output", "=", "outputs", "[", "1", "]", "\n", "input_cls_repr", "=", "sequence_output", "\n", "\n", "# If GILE model, compute the sigmoid", "\n", "if", "self", ".", "config", ".", "use_gile", ":", "\n", "            ", "input_cls_repr", "=", "torch", ".", "tanh", "(", "input_cls_repr", ")", "\n", "\n", "# STEP 3: Get the label model vectors", "\n", "# The label loader adds an extra dimension at the beginning of the tensors", "\n", "# Remove them", "\n", "", "for", "key", "in", "label_loader", ".", "keys", "(", ")", ":", "\n", "            ", "label_loader", "[", "key", "]", "=", "torch", ".", "squeeze", "(", "label_loader", "[", "key", "]", ",", "0", ")", "\n", "\n", "", "label_representations", "=", "label_loader", "[", "'glove_emb'", "]", "@", "self", ".", "label_projection", ".", "weight", ".", "T", "\n", "\n", "if", "self", ".", "config", ".", "use_gile", ":", "\n", "            ", "label_representations", "=", "torch", ".", "tanh", "(", "label_representations", ")", "\n", "\n", "# Normalize the label representations if required", "\n", "", "if", "self", ".", "config", ".", "normalize_label_embeddings", ":", "\n", "            ", "label_representations", "=", "nn", ".", "functional", ".", "normalize", "(", "label_representations", ",", "dim", "=", "1", ")", "\n", "\n", "# Compute the logits", "\n", "", "logits", "=", "input_cls_repr", "@", "label_representations", ".", "T", "# (bs, n_class)", "\n", "\n", "return", "logits", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertRCV1toNG.__init__": [[138, 145], ["core.BaseModel.__init__", "BertForSemanticEmbedding.from_pretrained", "torchmetrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "BertRCV1toNGArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "BertForSemanticEmbedding", ".", "from_pretrained", "(", "\n", "self", ".", "args", ".", "checkpoint", "\n", ")", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertRCV1toNG.forward": [[146, 153], ["text_transfer.BertRCV1toNG.model", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "input_batch", "=", "batch", "[", "\"input_loader\"", "]", "\n", "label_batch", "=", "batch", "[", "\"label_loader\"", "]", "\n", "\n", "logits", ",", "targets", "=", "self", ".", "model", "(", "input_batch", ",", "label_batch", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertRCV1toNGDEVISE.__init__": [[156, 163], ["core.BaseModel.__init__", "BertForWord2Vec.from_pretrained", "torchmetrics.Accuracy"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "BertRCV1toNGArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "BertForWord2Vec", ".", "from_pretrained", "(", "\n", "self", ".", "args", ".", "checkpoint", "\n", ")", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.text_transfer.BertRCV1toNGDEVISE.forward": [[164, 171], ["text_transfer.BertRCV1toNGDEVISE.model", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "input_batch", "=", "batch", "[", "\"input_loader\"", "]", "\n", "label_batch", "=", "batch", "[", "\"label_loader\"", "]", "\n", "\n", "logits", ",", "targets", "=", "self", ".", "model", "(", "input_batch", ",", "label_batch", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.vision.ResNetSemSup.__init__": [[40, 58], ["core.SemSupModel.__init__", "torchvision.resnet18", "torch.Linear", "torch.Linear", "torch.Linear", "torchmetrics.Accuracy", "vision.ResNetSemSup.args.image_type.lower", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "ResNetSemSupArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "model", "=", "models", ".", "resnet18", "(", "pretrained", "=", "self", ".", "args", ".", "pretrained_model", ")", "\n", "# modify architecture to fit the smaller 32 x 32 cifar image dims", "\n", "if", "self", ".", "args", ".", "image_type", ".", "lower", "(", ")", "==", "\"cifar\"", ":", "\n", "            ", "self", ".", "model", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "model", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "# modify the fc layer", "\n", "", "self", ".", "model", ".", "fc", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "model", ".", "fc", ".", "in_features", ",", "self", ".", "label_model", ".", "config", ".", "hidden_size", ",", "bias", "=", "False", "\n", ")", "\n", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.vision.ResNetSemSup.forward": [[59, 65], ["vision.ResNetSemSup.model", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "label_rep", ")", ":", "\n", "        ", "input_data", ",", "targets", "=", "batch", "\n", "input_rep", "=", "self", ".", "model", "(", "input_data", ")", "# (bs, d_model)", "\n", "logits", "=", "input_rep", "@", "label_rep", "# (bs, n_class)", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.vision.ResNetBaseline.__init__": [[68, 87], ["core.BaseModel.__init__", "torchvision.resnet18", "torch.Linear", "torch.Linear", "torch.Linear", "torchmetrics.Accuracy", "vision.ResNetBaseline.args.image_type.lower", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "ResNetBaselineArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "label_model", "=", "None", "\n", "self", ".", "model", "=", "models", ".", "resnet18", "(", "pretrained", "=", "self", ".", "args", ".", "pretrained_model", ")", "\n", "# modify architecture to fit the smaller 32 x 32 cifar image dims", "\n", "if", "self", ".", "args", ".", "image_type", ".", "lower", "(", ")", "==", "\"cifar\"", ":", "\n", "            ", "self", ".", "model", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "model", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "# modify the fc layer", "\n", "", "self", ".", "model", ".", "fc", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "model", ".", "fc", ".", "in_features", ",", "self", ".", "args", ".", "num_classes", "\n", ")", "\n", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.vision.ResNetBaseline.forward": [[88, 94], ["vision.ResNetBaseline.model", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch", "=", "batch", "[", "\"input_loader\"", "]", "\n", "input_data", ",", "targets", "=", "batch", "\n", "logits", "=", "self", ".", "model", "(", "input_data", ")", "# (bs, d_model)", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.vision.DEVISEVisBaseline.__init__": [[97, 110], ["core.BaseModel.__init__", "torchvision.resnet18", "torch.Linear", "torch.Linear", "torch.Linear", "torchmetrics.Accuracy", "vision.DEVISEVisBaseline.args.image_type.lower", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ":", "DEVISEVisBaselineArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "self", ".", "label_model", "=", "None", "\n", "self", ".", "model", "=", "models", ".", "resnet18", "(", "pretrained", "=", "self", ".", "args", ".", "pretrained_model", ")", "\n", "# modify architecture to fit the smaller 32 x 32 cifar image dims", "\n", "if", "self", ".", "args", ".", "image_type", ".", "lower", "(", ")", "==", "\"cifar\"", ":", "\n", "            ", "self", ".", "model", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "model", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "model", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "fc", ".", "in_features", ",", "300", ",", "bias", "=", "False", ")", "\n", "self", ".", "accuracy", "=", "torchmetrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "metrics", "=", "{", "\"val_acc\"", ":", "self", ".", "accuracy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.models.vision.DEVISEVisBaseline.forward": [[111, 123], ["[].squeeze().t", "vision.DEVISEVisBaseline.model", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "[].squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "label_rep", "=", "batch", "[", "\"label_loader\"", "]", "[", "\"glove_emb\"", "]", ".", "squeeze", "(", ")", ".", "t", "(", ")", "#(300, n_class)", "\n", "input_data", ",", "targets", "=", "batch", "[", "\"input_loader\"", "]", "\n", "input_rep", "=", "self", ".", "model", "(", "input_data", ")", "#(bs, 300)", "\n", "\n", "if", "self", ".", "args", ".", "use_gile", ":", "\n", "            ", "label_rep", "=", "torch", ".", "tanh", "(", "label_rep", ")", "\n", "input_rep", "=", "torch", ".", "tanh", "(", "input_rep", ")", "\n", "\n", "", "logits", "=", "input_rep", "@", "label_rep", "# (bs, n_class)", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "logits", ",", "target", "=", "targets", ")", "\n", "return", "logits", ",", "targets", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.LabelDataset.__init__": [[28, 33], ["torch.utils.data.IterableDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["\n", "ModelMakerCls", "=", "AutoModelForSequenceClassification", "if", "classifier", "else", "AutoModel", "\n", "\n", "if", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "        ", "return", "model", "\n", "", "elif", "isinstance", "(", "model", ",", "str", ")", ":", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.LabelDataset.__next__": [[34, 42], ["collections.defaultdict", "range", "core.LabelDataset.classlabels.int2str", "int", "core.LabelDataset.dataset[].items", "torch.stack", "numpy.random.choice", "fused[].append", "collections.defaultdict.items"], "methods", ["None"], ["        ", "if", "pretrained", ":", "\n", "            ", "return", "ModelMakerCls", ".", "from_pretrained", "(", "model", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "model_config", "=", "AutoConfig", ".", "from_pretrained", "(", "model", ",", "**", "kwargs", ")", "\n", "return", "ModelMakerCls", ".", "from_config", "(", "model_config", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"model must be a str or nn.Module\"", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.LabelDataset.__iter__": [[43, 45], ["None"], "methods", ["None"], ["", "", "@", "dataclass", "\n", "class", "BaseModelArgs", ":", "\n", "    "]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataArgs.__post_init__": [[83, 106], ["pathlib.Path().is_file", "pathlib.Path().is_dir", "str", "str", "core.SemSupDataArgs.hash_func", "core.SemSupDataArgs.hash_func", "str", "str", "pathlib.Path().is_file", "pathlib.Path().absolute", "pathlib.Path().absolute", "pathlib.Path().joinpath", "pathlib.Path().joinpath", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataArgs.hash_func", "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataArgs.hash_func"], ["self", ".", "metrics", "=", "dict", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"All inheriting classes should override this\n        Args:\n            batch: the batch from the input_loader\n\n        Return (tuple): logits, targets, loss. Can be anything, as long as compatible with training_step(), validation_step()\n            logits (Any): the logits generated by the model\n            targets (Any): the targets\n            loss (Any): the loss\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "self", "(", "batch", ")", "\n", "\n", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "AdamW", "(", "\n", "self", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "args", ".", "lr", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", "\n", "weight_decay", "=", "self", ".", "args", ".", "weight_decay", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataArgs.hash_func": [[109, 111], ["hashlib.md5().hexdigest", "hashlib.md5", "json.dumps().encode", "json.dumps"], "methods", ["None"], ["        ", "logits", ",", "targets", ",", "loss", "=", "self", ".", "step", "(", "batch", ")", "\n", "self", ".", "log", "(", "\"train_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataArgs.hash": [[112, 116], ["core.SemSupDataArgs.hash_func", "dataclasses.asdict"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataArgs.hash_func"], ["\n", "", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ",", "dataloader_idx", "=", "0", ")", ":", "\n", "        ", "logits", ",", "targets", ",", "loss", "=", "self", ".", "step", "(", "batch", ")", "\n", "for", "name", ",", "metric", "in", "self", ".", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "metric", "(", "logits", ",", "targets", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.__init__": [[128, 151], ["pytorch_lightning.LightningDataModule.__init__", "datasets.ClassLabel", "datasets.ClassLabel", "dict"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["    ", "\"\"\"Base class for all contclass models. Inheriting models should override the forward() method and optionally define self.metrics\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "label_model", "=", "get_text_model", "(", "\n", "model", "=", "self", ".", "args", ".", "label_model", ",", "pretrained", "=", "self", ".", "args", ".", "pretrained_label_model", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "batch", ",", "label_rep", ")", ":", "\n", "        ", "\"\"\"All inheriting classes should override this\n        Args:\n            batch: the batch from the input_loader\n            label_rep (torch.Tensor[d_model, n_class]): torch tensor of the label representation from the label encoder\n\n        Return (tuple): logits, targets, loss. Can be anything, as long as compatible with training_step(), validation_step()\n            logits (Any): the logits generated by the model\n            targets (Any): the targets\n            loss (Any): the loss\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "label_batch", "=", "{", "k", ":", "v", ".", "squeeze", "(", "0", ")", "for", "k", ",", "v", "in", "batch", "[", "\"label_loader\"", "]", ".", "items", "(", ")", "}", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.prepare_label_data": [[152, 193], ["transformers.AutoTokenizer.from_pretrained", "datasets.load_dataset", "train_label_dataset.map.map.map", "train_label_dataset.map.map.save_to_disk", "transformers.AutoTokenizer.from_pretrained", "datasets.load_dataset", "val_label_dataset.map.map.map", "val_label_dataset.map.map.save_to_disk", "pathlib.Path().exists", "pathlib.Path().exists", "transformers.AutoTokenizer.from_pretrained.", "transformers.AutoTokenizer.from_pretrained.", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained"], ["with", "torch", ".", "set_grad_enabled", "(", "self", ".", "args", ".", "tune_label_model", ")", ":", "\n", "            ", "label_rep", "=", "self", ".", "label_model", "(", "\n", "**", "label_batch", "\n", ")", ".", "pooler_output", "# (n_class, d_model)", "\n", "label_rep", "=", "label_rep", ".", "t", "(", ")", "# (d_model, n_class)", "\n", "", "return", "self", "(", "batch", "[", "\"input_loader\"", "]", ",", "label_rep", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule._get_glove_embedding": [[194, 213], ["glove_vectors.key_to_index.keys", "sentence.strip().split", "numpy.array().astype", "word.lower.lower.lower", "numpy.random.randn().astype", "sentence.strip", "numpy.array", "numpy.random.randn", "glove_vectors.get_index"], "methods", ["None"], []], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule._setup_label_dataset": [[214, 231], ["collections.defaultdict", "dataset.map.map.map", "core.LabelDataset", "gensim.downloader.load", "dataset.map.map.map", "dataset.map.map.set_format", "dataset.map.map.set_format", "label_to_idx[].append", "core.SemSupDataModule._get_glove_embedding"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule._get_glove_embedding"], []], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels": [[232, 241], ["datasets.load_from_disk", "core.SemSupDataModule._setup_label_dataset", "datasets.load_from_disk", "core.SemSupDataModule._setup_label_dataset"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule._setup_label_dataset", "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule._setup_label_dataset"], []], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.train_dataloader": [[243, 257], ["pytorch_lightning.trainer.supporters.CombinedLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], []], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.val_dataloader": [[259, 272], ["pytorch_lightning.trainer.supporters.CombinedLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], []], "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.test_dataloader": [[274, 279], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.heldout.CIFARHeldoutDataArgs.__post_init__": [[52, 71], ["super().__post_init__", "tuple", "tuple", "list", "list"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__post_init__", "(", ")", "\n", "\n", "self", ".", "heldout_classes", "=", "tuple", "(", "list", "(", "self", ".", "val_names", ")", "+", "list", "(", "self", ".", "test_names", ")", ")", "\n", "for", "n", "in", "self", ".", "heldout_classes", ":", "# sanity check", "\n", "            ", "assert", "n", "in", "self", ".", "classes", ",", "f\"{n} not a valid class name\"", "\n", "\n", "", "self", ".", "train_classes", "=", "tuple", "(", "\n", "[", "x", "for", "x", "in", "self", ".", "classes", "if", "x", "not", "in", "self", ".", "heldout_classes", "]", "\n", ")", "\n", "self", ".", "val_classes", "=", "self", ".", "classes", "if", "self", ".", "gzsl", "else", "self", ".", "val_names", "\n", "\n", "if", "self", ".", "run_test", ":", "\n", "            ", "self", ".", "val_classes", "=", "self", ".", "test_names", "\n", "self", ".", "val_names", "=", "self", ".", "test_names", "\n", "\n", "", "if", "self", ".", "eval_train", ":", "\n", "            ", "self", ".", "val_classes", "=", "self", ".", "train_classes", "\n", "self", ".", "val_names", "=", "self", ".", "train_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.heldout.CIFARHeldoutDM.__init__": [[76, 78], ["base.CIFAR100DataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["def", "__init__", "(", "self", ",", "args", ":", "CIFARHeldoutDataArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.heldout.CIFARHeldoutDM.setup": [[79, 160], ["heldout.CIFARHeldoutDM.setup_labels", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "range", "range", "torch.utils.data.Subset", "torch.utils.data.Subset", "torchvision.datasets.vision.StandardTransform", "torchvision.datasets.vision.StandardTransform", "heldout.CIFARHeldoutDM.all_classlabel.str2int", "heldout.CIFARHeldoutDM.all_classlabel.str2int", "len", "train_idx_heldout.append", "len", "val_idx_heldout.append", "heldout.CIFARHeldoutDM.train_classlabel.str2int", "heldout.CIFARHeldoutDM.val_classlabel.str2int", "torchvision.datasets.CIFAR100", "range", "torch.utils.data.Subset", "torchvision.datasets.vision.StandardTransform", "heldout.CIFARHeldoutDM.all_classlabel.int2str", "heldout.CIFARHeldoutDM.all_classlabel.int2str", "heldout.CIFARHeldoutDM.all_classlabel.str2int", "len", "test_idx_heldout.append"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], ["", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "setup_labels", "(", ")", "\n", "\n", "# get the dataset", "\n", "train_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "False", "\n", ")", "\n", "val_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "False", "\n", ")", "\n", "\n", "# class_ids that should not be in training / val", "\n", "train_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "for", "x", "in", "self", ".", "args", ".", "heldout_classes", "\n", "]", "\n", "val_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "for", "x", "in", "self", ".", "args", ".", "classes", "if", "x", "not", "in", "self", ".", "args", ".", "val_names", "\n", "]", "\n", "\n", "# filter the train and val examples", "\n", "train_idx_heldout", ",", "val_idx_heldout", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "train_dataset", ")", ")", ":", "\n", "            ", "_", ",", "class_id", "=", "train_dataset", "[", "idx", "]", "\n", "if", "class_id", "in", "train_heldout_ids", ":", "\n", "                ", "continue", "\n", "", "train_idx_heldout", ".", "append", "(", "idx", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "val_dataset", ")", ")", ":", "\n", "            ", "_", ",", "class_id", "=", "val_dataset", "[", "idx", "]", "\n", "if", "class_id", "in", "val_heldout_ids", ":", "\n", "                ", "continue", "\n", "", "val_idx_heldout", ".", "append", "(", "idx", ")", "\n", "\n", "", "train_dataset", "=", "Subset", "(", "train_dataset", ",", "train_idx_heldout", ")", "\n", "val_dataset", "=", "Subset", "(", "val_dataset", ",", "val_idx_heldout", ")", "\n", "\n", "# get the label transforms for ZSL", "\n", "def", "train_target_transform", "(", "class_id", ":", "int", ")", "->", "int", ":", "\n", "# converts the id from the original class label to the correct zsl training set label", "\n", "            ", "return", "self", ".", "train_classlabel", ".", "str2int", "(", "self", ".", "all_classlabel", ".", "int2str", "(", "class_id", ")", ")", "\n", "\n", "", "def", "val_target_transform", "(", "class_id", ":", "int", ")", "->", "int", ":", "\n", "            ", "return", "self", ".", "val_classlabel", ".", "str2int", "(", "self", ".", "all_classlabel", ".", "int2str", "(", "class_id", ")", ")", "\n", "\n", "# add transforms to the datasets", "\n", "# we can't do this earlier, because we need the original target_transforms to do the", "\n", "# heldout sets", "\n", "", "val_dataset", ".", "dataset", ".", "transform", "=", "self", ".", "eval_transform", "\n", "val_dataset", ".", "dataset", ".", "target_transform", "=", "val_target_transform", "\n", "val_dataset", ".", "dataset", ".", "transforms", "=", "StandardTransform", "(", "\n", "transform", "=", "self", ".", "eval_transform", ",", "target_transform", "=", "val_target_transform", "\n", ")", "\n", "train_dataset", ".", "dataset", ".", "transform", "=", "self", ".", "train_transform", "\n", "train_dataset", ".", "dataset", ".", "target_transform", "=", "train_target_transform", "\n", "train_dataset", ".", "dataset", ".", "transforms", "=", "StandardTransform", "(", "\n", "transform", "=", "self", ".", "train_transform", ",", "target_transform", "=", "train_target_transform", "\n", ")", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "=", "train_dataset", "\n", "self", ".", "dataset", "[", "\"val\"", "]", "=", "val_dataset", "\n", "\n", "if", "self", ".", "args", ".", "run_test", "and", "self", ".", "args", ".", "eval_train", ":", "\n", "            ", "test_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "False", ",", "download", "=", "False", "\n", ")", "\n", "test_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "for", "x", "in", "self", ".", "args", ".", "classes", "if", "x", "not", "in", "self", ".", "args", ".", "val_names", "\n", "]", "\n", "test_idx_heldout", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "test_dataset", ")", ")", ":", "\n", "                ", "_", ",", "class_id", "=", "test_dataset", "[", "idx", "]", "\n", "if", "class_id", "in", "test_heldout_ids", ":", "\n", "                    ", "continue", "\n", "", "test_idx_heldout", ".", "append", "(", "idx", ")", "\n", "\n", "", "test_dataset", "=", "Subset", "(", "test_dataset", ",", "test_idx_heldout", ")", "\n", "test_dataset", ".", "dataset", ".", "transform", "=", "self", ".", "eval_transform", "\n", "test_dataset", ".", "dataset", ".", "target_transform", "=", "val_target_transform", "\n", "test_dataset", ".", "dataset", ".", "transforms", "=", "StandardTransform", "(", "\n", "transform", "=", "self", ".", "eval_transform", ",", "target_transform", "=", "val_target_transform", "\n", ")", "\n", "self", ".", "dataset", "[", "\"val\"", "]", "=", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.base.CIFARDataArgs.__post_init__": [[34, 50], ["super().__post_init__", "pathlib.Path().joinpath", "tuple", "pathlib.Path().joinpath.exists", "torchvision.datasets.CIFAR100", "pathlib.Path().joinpath.open", "pickle.load", "pathlib.Path", "c.decode"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__post_init__", "(", ")", "\n", "\n", "metadata_path", "=", "Path", "(", "self", ".", "cache_dir", ")", ".", "joinpath", "(", "\"cifar-100-python\"", ",", "\"meta\"", ")", "\n", "if", "not", "metadata_path", ".", "exists", "(", ")", ":", "\n", "            ", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "True", "\n", ")", "\n", "\n", "", "with", "metadata_path", ".", "open", "(", "mode", "=", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "metadata", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"bytes\"", ")", "\n", "", "self", ".", "classes", "=", "tuple", "(", "\n", "[", "c", ".", "decode", "(", "\"utf-8\"", ")", "for", "c", "in", "self", ".", "metadata", "[", "b\"fine_label_names\"", "]", "]", "\n", ")", "\n", "self", ".", "train_classes", "=", "self", ".", "classes", "\n", "self", ".", "val_classes", "=", "self", ".", "train_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.base.CIFAR100DataModule.__init__": [[55, 88], ["core.SemSupDataModule.__init__", "datasets.ClassLabel", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "args", ":", "CIFARDataArgs", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "\n", "num_workers", ":", "int", "=", "0", ",", "\n", "val_batch_size", ":", "int", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", "=", "args", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "val_batch_size", "=", "val_batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "# classlabel for all classes", "\n", "self", ".", "all_classlabel", "=", "ClassLabel", "(", "names", "=", "self", ".", "args", ".", "classes", ")", "\n", "\n", "# CIFAR stats", "\n", "self", ".", "mean", "=", "[", "0.4914", ",", "0.4822", ",", "0.4465", "]", "\n", "self", ".", "std", "=", "[", "0.2023", ",", "0.1994", ",", "0.2010", "]", "\n", "\n", "# transforms", "\n", "self", ".", "train_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "self", ".", "mean", ",", "self", ".", "std", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "eval_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.base.CIFAR100DataModule.prepare_data": [[90, 97], ["base.CIFAR100DataModule.prepare_label_data", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.prepare_label_data"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "prepare_label_data", "(", ")", "\n", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "True", "\n", ")", "\n", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "False", ",", "download", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.base.CIFAR100DataModule.setup": [[99, 135], ["base.CIFAR100DataModule.setup_labels", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "sklearn.model_selection.train_test_split", "torch.utils.data.Subset", "torch.utils.data.Subset", "torchvision.datasets.CIFAR100", "list", "range", "len"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], ["", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "setup_labels", "(", ")", "\n", "train_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "train_transform", ",", "\n", ")", "\n", "val_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", ")", "\n", "if", "self", ".", "args", ".", "run_test", ":", "\n", "            ", "self", ".", "test_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", ")", "\n", "self", ".", "dataset", "[", "\"test\"", "]", "=", "self", ".", "test_dataset", "\n", "\n", "# make stratified split of train and val datasets", "\n", "", "train_idx", ",", "val_idx", "=", "train_test_split", "(", "\n", "list", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ")", ",", "\n", "test_size", "=", "self", ".", "args", ".", "val_size", ",", "\n", "random_state", "=", "self", ".", "args", ".", "split_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "stratify", "=", "train_dataset", ".", "targets", ",", "\n", ")", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "=", "Subset", "(", "train_dataset", ",", "train_idx", ")", "\n", "self", ".", "dataset", "[", "\"val\"", "]", "=", "Subset", "(", "val_dataset", ",", "val_idx", ")", "\n", "\n", "if", "self", ".", "args", ".", "run_test", ":", "\n", "            ", "self", ".", "dataset", "[", "\"val\"", "]", "=", "self", ".", "dataset", "[", "\"test\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.superclass.CIFARSuperClassDataArgs.__post_init__": [[135, 156], ["super().__post_init__", "set", "set", "superclass.CIFARSuperClassDataArgs.train_level.lower", "superclass.CIFARSuperClassDataArgs.val_level.lower", "superclass.CIFARSuperClassDataArgs.superclass_to_classes.items", "list", "list"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__post_init__", "(", ")", "\n", "assert", "set", "(", "self", ".", "superclasses", ")", "==", "set", "(", "\n", "list", "(", "self", ".", "val_superclasses", ")", "+", "list", "(", "self", ".", "test_superclasses", ")", "\n", ")", "\n", "assert", "self", ".", "train_level", ".", "lower", "(", ")", "in", "(", "\"fine\"", ",", "\"coarse\"", ")", "\n", "assert", "self", ".", "val_level", ".", "lower", "(", ")", "in", "(", "\"fine\"", ",", "\"coarse\"", ")", "\n", "\n", "self", ".", "classes_to_superclass", "=", "{", "# map class -> superclass", "\n", "x", ":", "k", "for", "k", ",", "v", "in", "self", ".", "superclass_to_classes", ".", "items", "(", ")", "for", "x", "in", "v", "\n", "}", "\n", "self", ".", "train_classes", "=", "(", "\n", "self", ".", "superclasses", "if", "self", ".", "train_level", "==", "\"coarse\"", "else", "self", ".", "classes", "\n", ")", "\n", "self", ".", "val_classes", "=", "(", "\n", "self", ".", "val_superclasses", "if", "self", ".", "val_level", "==", "\"coarse\"", "else", "self", ".", "classes", "\n", ")", "\n", "\n", "if", "self", ".", "run_test", ":", "\n", "            ", "self", ".", "val_classes", "=", "self", ".", "test_superclasses", "\n", "self", ".", "val_superclasses", "=", "self", ".", "test_superclasses", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.superclass.CIFARSuperClassDM.__init__": [[161, 163], ["base.CIFAR100DataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["def", "__init__", "(", "self", ",", "args", ":", "CIFARSuperClassDataArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.cifar.superclass.CIFARSuperClassDM.setup": [[164, 255], ["superclass.CIFARSuperClassDM.setup_labels", "torchvision.datasets.CIFAR100", "sklearn.model_selection.train_test_split", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torch.utils.data.Subset", "torch.utils.data.Subset", "list", "superclass.CIFARSuperClassDM.all_classlabel.int2str", "superclass.CIFARSuperClassDM.train_classlabel.str2int", "superclass.CIFARSuperClassDM.all_classlabel.int2str", "superclass.CIFARSuperClassDM.val_classlabel.str2int", "superclass.CIFARSuperClassDM.args.val_level.lower", "torchvision.datasets.CIFAR100", "range", "torchvision.datasets.CIFAR100", "torch.utils.data.Subset", "range", "superclass.CIFARSuperClassDM.args.train_level.lower", "superclass.CIFARSuperClassDM.args.val_level.lower", "superclass.CIFARSuperClassDM.all_classlabel.str2int", "val_idx_heldout.append", "len", "test_idx_heldout.append", "len"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], ["", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "setup_labels", "(", ")", "\n", "\n", "dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", ")", "# download without any transforms to do train-val split", "\n", "\n", "# make stratified split of train and val datasets", "\n", "train_idx", ",", "val_idx", "=", "train_test_split", "(", "\n", "list", "(", "range", "(", "len", "(", "dataset", ")", ")", ")", ",", "\n", "test_size", "=", "self", ".", "args", ".", "val_size", ",", "\n", "random_state", "=", "self", ".", "args", ".", "split_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "stratify", "=", "dataset", ".", "targets", ",", "\n", ")", "\n", "\n", "def", "train_target_transform", "(", "class_id", ":", "int", ")", "->", "int", ":", "\n", "            ", "if", "self", ".", "args", ".", "train_level", ".", "lower", "(", ")", "==", "\"fine\"", ":", "\n", "                ", "return", "class_id", "\n", "", "classname", "=", "self", ".", "all_classlabel", ".", "int2str", "(", "class_id", ")", "\n", "superclass", "=", "self", ".", "args", ".", "classes_to_superclass", "[", "classname", "]", "\n", "return", "self", ".", "train_classlabel", ".", "str2int", "(", "superclass", ")", "\n", "\n", "", "def", "val_target_transform", "(", "class_id", ":", "int", ")", "->", "int", ":", "\n", "            ", "if", "self", ".", "args", ".", "val_level", ".", "lower", "(", ")", "==", "\"fine\"", ":", "\n", "                ", "return", "class_id", "\n", "", "classname", "=", "self", ".", "all_classlabel", ".", "int2str", "(", "class_id", ")", "\n", "superclass", "=", "self", ".", "args", ".", "classes_to_superclass", "[", "classname", "]", "\n", "return", "self", ".", "val_classlabel", ".", "str2int", "(", "superclass", ")", "\n", "\n", "# further filter the val dataset to remove instances where superclass not in self.val_superclass", "\n", "", "if", "self", ".", "args", ".", "val_level", ".", "lower", "(", ")", "==", "\"coarse\"", ":", "\n", "            ", "val_idx_heldout", "=", "[", "]", "\n", "val_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "\n", "for", "x", "in", "self", ".", "args", ".", "classes", "\n", "if", "self", ".", "args", ".", "classes_to_superclass", "[", "x", "]", "not", "in", "self", ".", "args", ".", "val_superclasses", "\n", "]", "\n", "\n", "for", "idx", "in", "val_idx", ":", "\n", "                ", "_", ",", "class_id", "=", "dataset", "[", "idx", "]", "\n", "if", "class_id", "in", "val_heldout_ids", ":", "\n", "                    ", "continue", "\n", "", "val_idx_heldout", ".", "append", "(", "idx", ")", "\n", "", "val_idx", "=", "val_idx_heldout", "\n", "\n", "# get the dataset", "\n", "", "train_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "train_transform", ",", "\n", "target_transform", "=", "train_target_transform", ",", "\n", ")", "\n", "val_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", "target_transform", "=", "val_target_transform", ",", "\n", ")", "\n", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "=", "Subset", "(", "train_dataset", ",", "train_idx", ")", "\n", "self", ".", "dataset", "[", "\"val\"", "]", "=", "Subset", "(", "val_dataset", ",", "val_idx", ")", "\n", "\n", "if", "self", ".", "args", ".", "run_test", ":", "\n", "            ", "self", ".", "dataset", "[", "\"test\"", "]", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "False", ",", "\n", ")", "\n", "\n", "test_idx_heldout", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "dataset", "[", "\"test\"", "]", ")", ")", ":", "\n", "                ", "_", ",", "class_id", "=", "self", ".", "dataset", "[", "\"test\"", "]", "[", "idx", "]", "\n", "if", "class_id", "in", "val_heldout_ids", ":", "\n", "                    ", "continue", "\n", "", "test_idx_heldout", ".", "append", "(", "idx", ")", "\n", "\n", "# get the dataset again, but this time with the right target transform", "\n", "", "self", ".", "dataset", "[", "\"test\"", "]", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", "target_transform", "=", "val_target_transform", ",", "\n", ")", "\n", "\n", "self", ".", "dataset", "[", "\"val\"", "]", "=", "Subset", "(", "self", ".", "dataset", "[", "\"test\"", "]", ",", "test_idx_heldout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.heldout.AWAHeldoutArgs.__post_init__": [[31, 46], ["super().__post_init__", "str", "pathlib.Path().joinpath", "tuple", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__"], ["\"rabbit\"", ",", "\n", "\"man\"", ",", "\n", ")", "\n", "test_names", ":", "tuple", "=", "(", "\n", "\"motorcycle\"", ",", "\n", "\"pine_tree\"", ",", "\n", "\"bottle\"", ",", "\n", "\"trout\"", ",", "\n", "\"chair\"", ",", "\n", "\"butterfly\"", ",", "\n", "\"chimpanzee\"", ",", "\n", "\"orange\"", ",", "\n", "\"leopard\"", ",", "\n", "\"possum\"", ",", "\n", ")", "\n", "gzsl", ":", "bool", "=", "False", "# generalized ZSL setting", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.heldout.AWAHeldoutDM.__init__": [[52, 74], ["core.SemSupDataModule.__init__", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__post_init__", "(", ")", "\n", "\n", "self", ".", "heldout_classes", "=", "tuple", "(", "list", "(", "self", ".", "val_names", ")", "+", "list", "(", "self", ".", "test_names", ")", ")", "\n", "for", "n", "in", "self", ".", "heldout_classes", ":", "# sanity check", "\n", "            ", "assert", "n", "in", "self", ".", "classes", ",", "f\"{n} not a valid class name\"", "\n", "\n", "", "self", ".", "train_classes", "=", "tuple", "(", "\n", "[", "x", "for", "x", "in", "self", ".", "classes", "if", "x", "not", "in", "self", ".", "heldout_classes", "]", "\n", ")", "\n", "self", ".", "val_classes", "=", "self", ".", "classes", "if", "self", ".", "gzsl", "else", "self", ".", "val_names", "\n", "\n", "if", "self", ".", "run_test", ":", "\n", "            ", "self", ".", "val_classes", "=", "self", ".", "test_names", "\n", "self", ".", "val_names", "=", "self", ".", "test_names", "\n", "\n", "", "if", "self", ".", "eval_train", ":", "\n", "            ", "self", ".", "val_classes", "=", "self", ".", "train_classes", "\n", "self", ".", "val_names", "=", "self", ".", "train_classes", "\n", "\n", "\n", "", "", "", "class", "CIFARHeldoutDM", "(", "CIFAR100DataModule", ")", ":", "\n", "    ", "\"\"\"class which iplements zero-shot cifar\"\"\"", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.heldout.AWAHeldoutDM.prepare_data": [[77, 83], ["heldout.AWAHeldoutDM.prepare_label_data", "pathlib.Path().exists", "torchvision.datasets.utils.download_and_extract_archive", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.prepare_label_data"], ["        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "setup_labels", "(", ")", "\n", "\n", "# get the dataset", "\n", "train_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.heldout.AWAHeldoutDM.setup": [[85, 98], ["heldout.AWAHeldoutDM.setup_labels", "str", "base.AWADataset", "base.AWADataset", "pathlib.Path().joinpath", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], [")", "\n", "val_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "False", "\n", ")", "\n", "\n", "# class_ids that should not be in training / val", "\n", "train_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "for", "x", "in", "self", ".", "args", ".", "heldout_classes", "\n", "]", "\n", "val_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "for", "x", "in", "self", ".", "args", ".", "classes", "if", "x", "not", "in", "self", ".", "args", ".", "val_names", "\n", "]", "\n", "\n", "# filter the train and val examples", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.AWADataset.__init__": [[32, 35], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["classes", ":", "tuple", "=", "None", "# all classes built from metadata", "\n", "\n", "def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__post_init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.AWADataset.find_classes": [[36, 43], ["super().find_classes", "list", "dict", "base.AWADataset.classlabel.str2int"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.AWADataset.find_classes"], ["\n", "metadata_path", "=", "Path", "(", "self", ".", "cache_dir", ")", ".", "joinpath", "(", "\"cifar-100-python\"", ",", "\"meta\"", ")", "\n", "if", "not", "metadata_path", ".", "exists", "(", ")", ":", "\n", "            ", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "True", "\n", ")", "\n", "\n", "", "with", "metadata_path", ".", "open", "(", "mode", "=", "\"rb\"", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.AWADataArgs.__post_init__": [[60, 69], ["super().__post_init__", "str", "pathlib.Path().joinpath", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__"], ["val_batch_size", ":", "int", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "args", "=", "args", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "val_batch_size", "=", "val_batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.AWADataModule.__init__": [[74, 96], ["core.SemSupDataModule.__init__", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["self", ".", "mean", "=", "[", "0.4914", ",", "0.4822", ",", "0.4465", "]", "\n", "self", ".", "std", "=", "[", "0.2023", ",", "0.1994", ",", "0.2010", "]", "\n", "\n", "# transforms", "\n", "self", ".", "train_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "self", ".", "mean", ",", "self", ".", "std", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "eval_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "self", ".", "mean", ",", "self", ".", "std", ")", "]", "\n", ")", "\n", "\n", "", "def", "prepare_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "prepare_label_data", "(", ")", "\n", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "True", "\n", ")", "\n", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "False", ",", "download", "=", "True", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.AWADataModule.prepare_data": [[99, 105], ["base.AWADataModule.prepare_label_data", "pathlib.Path().exists", "torchvision.datasets.utils.download_and_extract_archive", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.prepare_label_data"], ["", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "setup_labels", "(", ")", "\n", "train_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "train_transform", ",", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.AWADataModule.setup": [[107, 147], ["base.AWADataModule.setup_labels", "str", "base.AWADataset", "base.AWADataset", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "torch.utils.data.Subset", "pathlib.Path().joinpath", "list", "len", "len", "len", "torch.utils.data.Subset", "torch.utils.data.Subset", "range", "set().intersection", "set().intersection", "set().intersection", "pathlib.Path", "len", "set", "set", "set", "set", "set", "set"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], ["val_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", ")", "\n", "if", "self", ".", "args", ".", "run_test", ":", "\n", "            ", "self", ".", "test_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", ")", "\n", "self", ".", "dataset", "[", "\"test\"", "]", "=", "self", ".", "test_dataset", "\n", "\n", "# make stratified split of train and val datasets", "\n", "", "train_idx", ",", "val_idx", "=", "train_test_split", "(", "\n", "list", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ")", ",", "\n", "test_size", "=", "self", ".", "args", ".", "val_size", ",", "\n", "random_state", "=", "self", ".", "args", ".", "split_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "stratify", "=", "train_dataset", ".", "targets", ",", "\n", ")", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "=", "Subset", "(", "train_dataset", ",", "train_idx", ")", "\n", "self", ".", "dataset", "[", "\"val\"", "]", "=", "Subset", "(", "val_dataset", ",", "val_idx", ")", "\n", "\n", "if", "self", ".", "args", ".", "run_test", ":", "\n", "            ", "self", ".", "dataset", "[", "\"val\"", "]", "=", "self", ".", "dataset", "[", "\"test\"", "]", "\n", "\n", "\n", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "# unit tests", "\n", "    ", "data_args", "=", "CIFARDataArgs", "(", "\n", "label_tokenizer", "=", "\"prajjwal1/bert-small\"", ",", "\n", "train_label_json", "=", "\"../class_descrs/cifar/google_cifar100_autoclean.labels\"", ",", "\n", "cache_dir", "=", "\"../data_cache\"", ",", "\n", ")", "\n", "data_mod", "=", "CIFAR100DataModule", "(", "args", "=", "data_args", ")", "\n", "data_mod", ".", "prepare_data", "(", ")", "\n", "data_mod", ".", "setup", "(", ")", "\n", "for", "_", "in", "data_mod", ".", "train_dataloader", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.awa.base.read_awa_file": [[17, 25], ["pathlib.Path().open", "tuple", "[].strip", "all_names.append", "pathlib.Path", "line.split"], "function", ["None"], ["class", "CIFARDataArgs", "(", "SemSupDataArgs", ")", ":", "\n", "    ", "\"\"\"Base argument dataclass for all CIFAR100 tasks\n    Args:\n        split_seed (int): seed to make train-val split\n        test_size (float): size of the test size of each class (from total)\n        val_size (float): size of the val set of each class (from train)\n        load_test (bool): load the test dataset\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.heldout.NewsgroupsHeldoutArgs.__post_init__": [[38, 62], ["super().__post_init__", "tuple", "tuple", "tuple", "tuple", "list", "list"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__"], ["\"trout\"", ",", "\n", "\"chair\"", ",", "\n", "\"butterfly\"", ",", "\n", "\"chimpanzee\"", ",", "\n", "\"orange\"", ",", "\n", "\"leopard\"", ",", "\n", "\"possum\"", ",", "\n", ")", "\n", "gzsl", ":", "bool", "=", "False", "# generalized ZSL setting", "\n", "eval_train", ":", "bool", "=", "False", "\n", "\n", "# filled in for you in __post_init__()", "\n", "heldout_classes", ":", "tuple", "=", "None", "# val_names and class_names union", "\n", "\n", "def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__post_init__", "(", ")", "\n", "\n", "self", ".", "heldout_classes", "=", "tuple", "(", "list", "(", "self", ".", "val_names", ")", "+", "list", "(", "self", ".", "test_names", ")", ")", "\n", "for", "n", "in", "self", ".", "heldout_classes", ":", "# sanity check", "\n", "            ", "assert", "n", "in", "self", ".", "classes", ",", "f\"{n} not a valid class name\"", "\n", "\n", "", "self", ".", "train_classes", "=", "tuple", "(", "\n", "[", "x", "for", "x", "in", "self", ".", "classes", "if", "x", "not", "in", "self", ".", "heldout_classes", "]", "\n", ")", "\n", "self", ".", "val_classes", "=", "self", ".", "classes", "if", "self", ".", "gzsl", "else", "self", ".", "val_names", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.heldout.NewsgroupsHeldoutDM.__init__": [[65, 67], ["base.NewsgroupsDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["            ", "self", ".", "val_classes", "=", "self", ".", "test_names", "\n", "self", ".", "val_names", "=", "self", ".", "test_names", "\n", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.heldout.NewsgroupsHeldoutDM.setup": [[68, 95], ["heldout.NewsgroupsHeldoutDM.setup_labels", "datasets.DatasetDict", "datasets.load_from_disk", "loaded_dataset[].filter", "dataset[].map", "loaded_dataset[].filter", "dataset[].map", "datasets.DatasetDict.set_format", "heldout.NewsgroupsHeldoutDM.train_classlabel.str2int", "heldout.NewsgroupsHeldoutDM.val_classlabel.str2int"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], ["", "if", "self", ".", "eval_train", ":", "\n", "            ", "self", ".", "val_classes", "=", "self", ".", "train_classes", "\n", "self", ".", "val_names", "=", "self", ".", "train_classes", "\n", "\n", "\n", "", "", "", "class", "CIFARHeldoutDM", "(", "CIFAR100DataModule", ")", ":", "\n", "    ", "\"\"\"class which iplements zero-shot cifar\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "args", ":", "CIFARHeldoutDataArgs", ",", "*", "margs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "args", ",", "*", "margs", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "setup_labels", "(", ")", "\n", "\n", "# get the dataset", "\n", "train_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "False", "\n", ")", "\n", "val_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "train", "=", "True", ",", "download", "=", "False", "\n", ")", "\n", "\n", "# class_ids that should not be in training / val", "\n", "train_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "for", "x", "in", "self", ".", "args", ".", "heldout_classes", "\n", "]", "\n", "val_heldout_ids", "=", "[", "\n", "self", ".", "all_classlabel", ".", "str2int", "(", "x", ")", "for", "x", "in", "self", ".", "args", ".", "classes", "if", "x", "not", "in", "self", ".", "args", ".", "val_names", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.base.NewsgroupsDataArgs.__post_init__": [[64, 84], ["super().__post_init__", "base.NewsgroupsDataArgs.hash_func", "str", "pathlib.Path().joinpath", "sorted", "list", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__", "home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataArgs.hash_func"], ["args", "=", "args", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "val_batch_size", "=", "val_batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "# classlabel for all classes", "\n", "self", ".", "all_classlabel", "=", "ClassLabel", "(", "names", "=", "self", ".", "args", ".", "classes", ")", "\n", "\n", "# CIFAR stats", "\n", "self", ".", "mean", "=", "[", "0.4914", ",", "0.4822", ",", "0.4465", "]", "\n", "self", ".", "std", "=", "[", "0.2023", ",", "0.1994", ",", "0.2010", "]", "\n", "\n", "# transforms", "\n", "self", ".", "train_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "self", ".", "mean", ",", "self", ".", "std", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.base.NewsgroupsDataModule.__init__": [[98, 112], ["core.SemSupDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["\n", "", "def", "setup", "(", "self", ",", "stage", "=", "None", ")", ":", "\n", "        ", "self", ".", "setup_labels", "(", ")", "\n", "train_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "train_transform", ",", "\n", ")", "\n", "val_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.base.NewsgroupsDataModule._configure_dataset": [[114, 129], ["dataset.map.map.map", "dataset.map.map.map", "tokenizer", "len"], "methods", ["None"], ["            ", "self", ".", "test_dataset", "=", "torchvision", ".", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "self", ".", "args", ".", "cache_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "False", ",", "\n", "transform", "=", "self", ".", "eval_transform", ",", "\n", ")", "\n", "self", ".", "dataset", "[", "\"test\"", "]", "=", "self", ".", "test_dataset", "\n", "\n", "# make stratified split of train and val datasets", "\n", "", "train_idx", ",", "val_idx", "=", "train_test_split", "(", "\n", "list", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ")", ",", "\n", "test_size", "=", "self", ".", "args", ".", "val_size", ",", "\n", "random_state", "=", "self", ".", "args", ".", "split_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "stratify", "=", "train_dataset", ".", "targets", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.base.NewsgroupsDataModule.prepare_data": [[130, 161], ["base.NewsgroupsDataModule.prepare_label_data", "pathlib.Path().exists", "transformers.AutoTokenizer.from_pretrained", "datasets.concatenate_datasets", "datasets.DatasetDict", "datasets.concatenate_datasets.train_test_split", "train_test[].train_test_split", "datasets.DatasetDict.save_to_disk", "dataset_list.append", "pathlib.Path", "base.NewsgroupsDataModule._configure_dataset", "datasets.load_dataset"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.prepare_label_data", "home.repos.pwc.inspect_result.princeton-nlp_semsup.src.models.AutoModelForWord2vec.from_pretrained", "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.base.NewsgroupsDataModule._configure_dataset"], ["self", ".", "dataset", "[", "\"train\"", "]", "=", "Subset", "(", "train_dataset", ",", "train_idx", ")", "\n", "self", ".", "dataset", "[", "\"val\"", "]", "=", "Subset", "(", "val_dataset", ",", "val_idx", ")", "\n", "\n", "if", "self", ".", "args", ".", "run_test", ":", "\n", "            ", "self", ".", "dataset", "[", "\"val\"", "]", "=", "self", ".", "dataset", "[", "\"test\"", "]", "\n", "\n", "\n", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "# unit tests", "\n", "    ", "data_args", "=", "CIFARDataArgs", "(", "\n", "label_tokenizer", "=", "\"prajjwal1/bert-small\"", ",", "\n", "train_label_json", "=", "\"../class_descrs/cifar/google_cifar100_autoclean.labels\"", ",", "\n", "cache_dir", "=", "\"../data_cache\"", ",", "\n", ")", "\n", "data_mod", "=", "CIFAR100DataModule", "(", "args", "=", "data_args", ")", "\n", "data_mod", ".", "prepare_data", "(", ")", "\n", "data_mod", ".", "setup", "(", ")", "\n", "for", "_", "in", "data_mod", ".", "train_dataloader", "(", ")", ":", "\n", "        ", "pass", "\n", "", "for", "_", "in", "data_mod", ".", "val_dataloader", "(", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.base.NewsgroupsDataModule.setup": [[162, 177], ["base.NewsgroupsDataModule.setup_labels", "datasets.load_from_disk", "dataset.map.map.map", "dataset.map.map.set_format", "base.NewsgroupsDataModule.train_classlabel.str2int"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], []], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__": [[67, 85], ["super().__post_init__", "tuple", "superclass.NewsgroupsSuperClassArgs.train_level.lower", "superclass.NewsgroupsSuperClassArgs.val_level.lower", "list", "list", "superclass.NewsgroupsSuperClassArgs.superclass_to_classes.items"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassArgs.__post_init__"], ["\"aquatic_mammals\"", ",", "\n", "\"trees\"", ",", "\n", "\"vehicles_1\"", ",", "\n", ")", "\n", "superclass_to_classes", ":", "dict", "=", "field", "(", "\n", "default_factory", "=", "lambda", ":", "{", "\n", "\"aquatic_mammals\"", ":", "[", "\"otter\"", ",", "\"beaver\"", ",", "\"whale\"", ",", "\"dolphin\"", ",", "\"seal\"", "]", ",", "\n", "\"fish\"", ":", "[", "\"trout\"", ",", "\"aquarium_fish\"", ",", "\"shark\"", ",", "\"flatfish\"", ",", "\"ray\"", "]", ",", "\n", "\"flowers\"", ":", "[", "\"poppy\"", ",", "\"rose\"", ",", "\"orchid\"", ",", "\"sunflower\"", ",", "\"tulip\"", "]", ",", "\n", "\"food_containers\"", ":", "[", "\"plate\"", ",", "\"bowl\"", ",", "\"bottle\"", ",", "\"can\"", ",", "\"cup\"", "]", ",", "\n", "\"fruit_and_vegetables\"", ":", "[", "\n", "\"orange\"", ",", "\n", "\"apple\"", ",", "\n", "\"pear\"", ",", "\n", "\"sweet_pepper\"", ",", "\n", "\"mushroom\"", ",", "\n", "]", ",", "\n", "\"household_electrical_devices\"", ":", "[", "\n", "\"clock\"", ",", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__": [[88, 90], ["base.NewsgroupsDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.__init__"], ["\"television\"", ",", "\n", "\"lamp\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.princeton-nlp_semsup.newsgroups.superclass.NewsgroupsSuperClassDM.setup": [[91, 134], ["superclass.NewsgroupsSuperClassDM.setup_labels", "datasets.load_from_disk", "datasets.load_from_disk.set_format", "dataset[].filter", "dataset[].map", "dataset[].map", "dataset[].filter", "dataset[].map", "dataset[].map", "superclass.NewsgroupsSuperClassDM.train_classlabel.str2int", "superclass.NewsgroupsSuperClassDM.train_classlabel.str2int", "superclass.NewsgroupsSuperClassDM.val_classlabel.str2int", "superclass.NewsgroupsSuperClassDM.val_classlabel.str2int"], "methods", ["home.repos.pwc.inspect_result.princeton-nlp_semsup.data.core.SemSupDataModule.setup_labels"], ["\"household_furniture\"", ":", "[", "\"table\"", ",", "\"chair\"", ",", "\"couch\"", ",", "\"wardrobe\"", ",", "\"bed\"", "]", ",", "\n", "\"insects\"", ":", "[", "\"caterpillar\"", ",", "\"bee\"", ",", "\"cockroach\"", ",", "\"beetle\"", ",", "\"butterfly\"", "]", ",", "\n", "\"large_carnivores\"", ":", "[", "\"leopard\"", ",", "\"lion\"", ",", "\"tiger\"", ",", "\"bear\"", ",", "\"wolf\"", "]", ",", "\n", "\"large_man-made_outdoor_things\"", ":", "[", "\n", "\"house\"", ",", "\n", "\"bridge\"", ",", "\n", "\"skyscraper\"", ",", "\n", "\"road\"", ",", "\n", "\"castle\"", ",", "\n", "]", ",", "\n", "\"large_natural_outdoor_scenes\"", ":", "[", "\n", "\"forest\"", ",", "\n", "\"cloud\"", ",", "\n", "\"plain\"", ",", "\n", "\"mountain\"", ",", "\n", "\"sea\"", ",", "\n", "]", ",", "\n", "\"large_omnivores_and_herbivores\"", ":", "[", "\n", "\"kangaroo\"", ",", "\n", "\"cattle\"", ",", "\n", "\"elephant\"", ",", "\n", "\"camel\"", ",", "\n", "\"chimpanzee\"", ",", "\n", "]", ",", "\n", "\"medium_mammals\"", ":", "[", "\"raccoon\"", ",", "\"fox\"", ",", "\"porcupine\"", ",", "\"possum\"", ",", "\"skunk\"", "]", ",", "\n", "\"non-insect_invertebrates\"", ":", "[", "\"snail\"", ",", "\"lobster\"", ",", "\"spider\"", ",", "\"worm\"", ",", "\"crab\"", "]", ",", "\n", "\"people\"", ":", "[", "\"girl\"", ",", "\"woman\"", ",", "\"man\"", ",", "\"baby\"", ",", "\"boy\"", "]", ",", "\n", "\"reptiles\"", ":", "[", "\"turtle\"", ",", "\"snake\"", ",", "\"lizard\"", ",", "\"crocodile\"", ",", "\"dinosaur\"", "]", ",", "\n", "\"small_mammals\"", ":", "[", "\"mouse\"", ",", "\"shrew\"", ",", "\"hamster\"", ",", "\"squirrel\"", ",", "\"rabbit\"", "]", ",", "\n", "\"trees\"", ":", "[", "\n", "\"palm_tree\"", ",", "\n", "\"willow_tree\"", ",", "\n", "\"pine_tree\"", ",", "\n", "\"oak_tree\"", ",", "\n", "\"maple_tree\"", ",", "\n", "]", ",", "\n", "\"vehicles_1\"", ":", "[", "\"bus\"", ",", "\"bicycle\"", ",", "\"motorcycle\"", ",", "\"train\"", ",", "\"pickup_truck\"", "]", ",", "\n", "\"vehicles_2\"", ":", "[", "\"streetcar\"", ",", "\"tank\"", ",", "\"lawn_mower\"", ",", "\"tractor\"", ",", "\"rocket\"", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "# filled in for you in __post_init__()", "\n", "classes_to_superclass", ":", "dict", "=", "None", "\n", "\n"]]}