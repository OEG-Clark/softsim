{"home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.None.gen_table.check_lines": [[8, 17], ["pattern.lower().replace", "l.lower().startswith", "float", "pattern.lower", "l.lower", "l.split"], "function", ["None"], ["def", "check_lines", "(", "lines", ",", "pattern_lists", ")", ":", "\n", "    ", "res", "=", "{", "}", "\n", "for", "l", "in", "lines", ":", "\n", "        ", "for", "pattern", "in", "pattern_lists", ":", "\n", "            ", "pattern_l", "=", "pattern", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", "\n", "if", "l", ".", "lower", "(", ")", ".", "startswith", "(", "pattern_l", ")", ":", "\n", "                ", "number", "=", "float", "(", "l", ".", "split", "(", "\":\"", ")", "[", "1", "]", ")", "\n", "res", "[", "pattern", "]", "=", "number", "\n", "", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.None.gen_table.process_file_list": [[18, 36], ["fn.split", "int", "int", "open", "f.readlines", "gen_table.check_lines", "print", "print"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.None.gen_table.check_lines"], ["", "def", "process_file_list", "(", "filelist", ")", ":", "\n", "    ", "results", "=", "{", "}", "\n", "for", "fn", "in", "filelist", ":", "\n", "        ", "names", "=", "fn", ".", "split", "(", "'_'", ")", "\n", "c", "=", "int", "(", "names", "[", "1", "]", ")", "\n", "kappa", "=", "int", "(", "names", "[", "2", "]", ")", "\n", "with", "open", "(", "fn", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "res", "=", "check_lines", "(", "lines", ",", "patterns", ")", "\n", "# skip empty files", "\n", "if", "res", ":", "\n", "                ", "if", "c", "not", "in", "results", ":", "\n", "                    ", "results", "[", "c", "]", "=", "{", "}", "\n", "", "results", "[", "c", "]", "[", "kappa", "]", "=", "res", "\n", "print", "(", "\"Processed {}: c={}, kappa={}, results={}\"", ".", "format", "(", "fn", ",", "c", ",", "kappa", ",", "res", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Skipped {}\"", ".", "format", "(", "fn", ")", ")", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.__init__": [[27, 334], ["print", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.tanh", "model.predict", "tensorflow.reduce_sum", "set", "l2_attack.CarliniL2.adam_optimizer_tf", "tensorflow.global_variables", "l2_attack.CarliniL2.const.assign", "l2_attack.CarliniL2.setup.append", "l2_attack.CarliniL2.setup.append", "l2_attack.CarliniL2.setup.append", "l2_attack.CarliniL2.setup.append", "l2_attack.CarliniL2.setup.append", "l2_attack.CarliniL2.setup.append", "l2_attack.CarliniL2.reset_input.append", "l2_attack.CarliniL2.reset_input.append", "tensorflow.variables_initializer", "print", "print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "tensorflow.reduce_sum", "tensorflow.cast", "print", "tensorflow.reduce_max", "tensorflow.gather", "print", "tensorflow.cast", "tensorflow.reduce_max", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.scatter_nd", "l2_attack.CarliniL2.key_words.assign", "l2_attack.CarliniL2.key_words_mask.assign", "l2_attack.CarliniL2.timg.assign", "l2_attack.CarliniL2.input_feed.assign", "l2_attack.CarliniL2.input_mask.assign", "l2_attack.CarliniL2.input_feed.assign", "l2_attack.CarliniL2.input_mask.assign", "tensorflow.square", "tensorflow.reduce_max", "ValueError", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.argmax", "tensorflow.cast", "tensorflow.ones", "tensorflow.cast", "tensorflow.concat", "tensorflow.scatter_nd", "tensorflow.reduce_max", "print", "tensorflow.maximum", "print", "tensorflow.reduce_min", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "print", "tensorflow.reduce_max", "tensorflow.gather", "tensorflow.reduce_max", "tensorflow.log", "tensorflow.cast", "print", "print", "tensorflow.cast", "print", "tensorflow.transpose", "print", "tensorflow.gather_nd", "print", "tensorflow.scatter_nd", "tensorflow.reduce_max", "tensorflow.reduce_max", "print", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.abs", "tensorflow.reduce_sum", "tensorflow.equal", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.gather", "tensorflow.ones", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.concat", "tensorflow.ones", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.reduce_sum", "tensorflow.global_variables", "tensorflow.tanh", "tensorflow.range", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.tanh", "tensorflow.range", "int", "tensorflow.expand_dims", "int", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.attack_wrapper.AttackWrapper.predict", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.adam_optimizer_tf"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "inf_sess", ",", "attack_graph", ",", "inference_graph", ",", "model", ",", "inf_model", ",", "use_keywords", "=", "True", ",", "use_logits", "=", "True", ",", "batch_size", "=", "1", ",", "confidence", "=", "CONFIDENCE", ",", "\n", "targeted", "=", "TARGETED", ",", "learning_rate", "=", "LEARNING_RATE", ",", "\n", "binary_search_steps", "=", "BINARY_SEARCH_STEPS", ",", "max_iterations", "=", "MAX_ITERATIONS", ",", "print_every", "=", "100", ",", "early_stop_iters", "=", "0", ",", "\n", "abort_early", "=", "ABORT_EARLY", ",", "\n", "initial_const", "=", "-", "1", ",", "\n", "use_log", "=", "False", ",", "norm", "=", "\"inf\"", ",", "adam_beta1", "=", "0.9", ",", "adam_beta2", "=", "0.999", ")", ":", "\n", "        ", "\"\"\"\n        The L_2 optimized attack. \n\n        This attack is the most efficient and should be used as the primary \n        attack to evaluate potential defenses.\n\n        Returns adversarial examples for the supplied model.\n\n        confidence: Confidence of adversarial examples: higher produces examples\n          that are farther away, but more strongly classified as adversarial.\n        batch_size: Number of attacks to run simultaneously.\n        targeted: True if we should perform a targetted attack, False otherwise.\n        learning_rate: The learning rate for the attack algorithm. Smaller values\n          produce better results but are slower to converge.\n        binary_search_steps: The number of times we perform binary search to\n          find the optimal tradeoff-constant between distance and confidence. \n        max_iterations: The maximum number of iterations. Larger values are more\n          accurate; setting too small will require a large learning rate and will\n          produce poor results.\n        abort_early: If true, allows early aborts if gradient descent gets stuck.\n        initial_const: The initial tradeoff-constant to use to tune the relative\n          importance of distance and confidence. If binary_search_steps is large,\n          the initial constant is not important.\n        \"\"\"", "\n", "\n", "if", "initial_const", "!=", "-", "1", ":", "\n", "            ", "print", "(", "\"WARNING: initial_const in l2_attack has no effect!\"", ")", "\n", "print", "(", "\"WARNING: initial_const in l2_attack has no effect!\"", ")", "\n", "\n", "# image_size, num_channels, num_labels = model.image_size, model.num_channels, model.num_labels", "\n", "", "image_size", ",", "num_channels", "=", "model", ".", "image_size", ",", "model", ".", "num_channels", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "TARGETED", "=", "targeted", "\n", "self", ".", "LEARNING_RATE", "=", "learning_rate", "\n", "self", ".", "MAX_ITERATIONS", "=", "max_iterations", "\n", "self", ".", "print_every", "=", "print_every", "\n", "self", ".", "early_stop_iters", "=", "early_stop_iters", "if", "early_stop_iters", "!=", "0", "else", "max_iterations", "//", "10", "\n", "print", "(", "\"early stop:\"", ",", "self", ".", "early_stop_iters", ")", "\n", "self", ".", "BINARY_SEARCH_STEPS", "=", "binary_search_steps", "\n", "self", ".", "ABORT_EARLY", "=", "abort_early", "\n", "self", ".", "CONFIDENCE", "=", "confidence", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "repeat", "=", "binary_search_steps", ">=", "10", "\n", "self", ".", "use_keywords", "=", "use_keywords", "\n", "self", ".", "use_logits", "=", "use_logits", "\n", "# store the two graphs", "\n", "self", ".", "attack_graph", "=", "attack_graph", "\n", "self", ".", "inference_graph", "=", "inference_graph", "\n", "# make sure we are building the attack graph", "\n", "assert", "sess", ".", "graph", "is", "attack_graph", "\n", "\n", "shape", "=", "(", "batch_size", ",", "image_size", ",", "image_size", ",", "num_channels", ")", "\n", "\n", "# the variable we're going to optimize over", "\n", "self", ".", "modifier", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "np", ".", "float32", ")", ",", "name", "=", "\"modifier_var\"", ")", "\n", "# self.modifier = tf.Variable(np.load('black_iter_350.npy').astype(np.float32).reshape(shape))", "\n", "\n", "# these are variables to be more efficient in sending data to tf", "\n", "max_caption_length", "=", "20", "\n", "\n", "self", ".", "timg", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "shape", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"timg_var\"", ")", "\n", "# self.tlab = tf.Variable(np.zeros((batch_size,num_labels)), dtype=tf.float32)", "\n", "self", ".", "const", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "batch_size", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "\"const_var\"", ")", "\n", "self", ".", "input_feed", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", "max_caption_length", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ",", "name", "=", "\"input_feed_var\"", ")", "\n", "self", ".", "input_mask", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "(", "batch_size", ",", "max_caption_length", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ",", "name", "=", "\"input_mask_var\"", ")", "\n", "self", ".", "key_words", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "max_caption_length", ")", ",", "dtype", "=", "tf", ".", "int64", ",", "name", "=", "\"key_words_var\"", ")", "\n", "self", ".", "key_words_mask", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "max_caption_length", ")", ",", "dtype", "=", "tf", ".", "int64", ",", "name", "=", "\"key_words_mask_var\"", ")", "\n", "\n", "# and here's what we use to assign them", "\n", "self", ".", "assign_timg", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", ")", "\n", "# self.assign_tlab = tf.placeholder(tf.float32, (batch_size,num_labels))", "\n", "self", ".", "assign_const", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "batch_size", "]", ")", "\n", "self", ".", "assign_input_feed", "=", "tf", ".", "placeholder", "(", "tf", ".", "int64", ",", "(", "batch_size", ",", "max_caption_length", ")", ",", "name", "=", "\"input_feed\"", ")", "\n", "self", ".", "assign_input_mask", "=", "tf", ".", "placeholder", "(", "tf", ".", "int64", ",", "(", "batch_size", ",", "max_caption_length", ")", ",", "name", "=", "\"input_mask\"", ")", "\n", "self", ".", "assign_key_words", "=", "tf", ".", "placeholder", "(", "tf", ".", "int64", ",", "[", "max_caption_length", "]", ",", "name", "=", "\"key_words\"", ")", "\n", "self", ".", "assign_key_words_mask", "=", "tf", ".", "placeholder", "(", "tf", ".", "int64", ",", "[", "max_caption_length", "]", ",", "name", "=", "\"key_words_mask\"", ")", "\n", "# the resulting image, tanh'd to keep bounded from -0.5 to 0.5", "\n", "# self.newimg = tf.tanh(self.modifier + self.timg)/2", "\n", "self", ".", "newimg", "=", "tf", ".", "tanh", "(", "self", ".", "modifier", "+", "self", ".", "timg", ")", "\n", "\n", "# prediction BEFORE-SOFTMAX of the model", "\n", "self", ".", "output", ",", "self", ".", "softmax", ",", "self", ".", "logits", "=", "model", ".", "predict", "(", "self", ".", "sess", ",", "self", ".", "newimg", ",", "self", ".", "input_feed", ",", "self", ".", "input_mask", ")", "\n", "\n", "# distance to the input data", "\n", "# self.lpdist = tf.reduce_sum(tf.square(self.newimg-tf.tanh(self.timg)/2),[1,2,3])", "\n", "if", "norm", "==", "\"l2\"", ":", "\n", "            ", "self", ".", "lpdist", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "self", ".", "newimg", "-", "tf", ".", "tanh", "(", "self", ".", "timg", ")", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "", "elif", "norm", "==", "\"inf\"", ":", "\n", "            ", "self", ".", "lpdist", "=", "tf", ".", "reduce_max", "(", "tf", ".", "abs", "(", "self", ".", "newimg", "-", "tf", ".", "tanh", "(", "self", ".", "timg", ")", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"unsupported distance metric:\"", "+", "norm", ")", "\n", "\n", "", "'''\n        # compute the probability of the label class versus the maximum other\n        self.real = tf.reduce_sum((self.tlab)*self.output,1)\n        self.other = tf.reduce_max((1-self.tlab)*self.output - (self.tlab*10000),1)\n        \n        if self.TARGETED:\n            if use_log:\n                # loss1 = tf.maximum(- tf.log(self.other), - tf.log(self.real))\n                # loss1 = - tf.log(self.real)\n                loss1 = tf.maximum(0.0, tf.log(self.other + 1e-30) - tf.log(self.real + 1e-30))\n            else:\n                # if targetted, optimize for making the other class most likely\n                loss1 = tf.maximum(0.0, self.other-self.real+self.CONFIDENCE)\n        else:\n            if use_log:\n                # loss1 = tf.log(self.real)\n                loss1 = tf.maximum(0.0, tf.log(self.real + 1e-30) - tf.log(self.other + 1e-30))\n            else:\n            # if untargeted, optimize for making this class least likely.\n                loss1 = tf.maximum(0.0, self.real-self.other+self.CONFIDENCE)\n        '''", "\n", "\n", "# loss1 = - self.output", "\n", "# loss1 = self.output", "\n", "# loss1 = - tf.sum([tf.log(tf.reduce_maximum(self.softmax,axis=1)[self.key_word]) for keyword in self.key_words[0]])", "\n", "# loss1 = tf.reduce_sum(tf.log(tf.reduce_max(tf.gather(self.softmax, self.key_words, axis=2), axis=1)) * self.key_words_mask, axis=1)", "\n", "# loss1 = tf.reduce_sum(tf.log(tf.reduce_max(tf.gather(self.softmax, self.key_words, axis=1), axis=1)) * tf.cast(self.key_words_mask, tf.float32))", "\n", "# t=tf.log(tf.reduce_max(tf.gather(self.softmax, self.key_words, axis=1), axis=1)) * tf.cast(self.key_words_mask, tf.float32)", "\n", "# print(t.get_shape())", "\n", "# loss1 = tf.reduce_sum(tf.log(tf.reduce_max(tf.gather(tf.transpose(self.softmax, perm=[1,0]), self.key_words), axis=1)+ 1e-30) * tf.cast(self.key_words_mask, tf.float32))", "\n", "# print(self.softmax.get_shape())", "\n", "# print(\"softmax:\", self.softmax.get_shape())", "\n", "# print(\"tf.gather(self.softmax, self.key_words, axis=1):\", tf.gather(self.softmax, self.key_words, axis=1))", "\n", "# print(\"key_words_mask:\", tf.cast(self.key_words_mask, tf.float32).get_shape())", "\n", "# print(tf.reduce_max(tf.gather(self.softmax, self.key_words, axis=1), axis=0).get_shape())", "\n", "\n", "\n", "# self.keywords_probs = tf.reduce_max(tf.gather(self.softmax, self.key_words, axis=1), axis=0)", "\n", "# loss1 = tf.reduce_sum(tf.log(self.keywords_probs) * tf.cast(self.key_words_mask, tf.float32))", "\n", "\n", "\n", "if", "self", ".", "use_keywords", ":", "\n", "# use the keywords loss", "\n", "# these are the true lenghth of logits and keywords without masked words", "\n", "            ", "true_logits_len", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_sum", "(", "self", ".", "input_mask", ")", ",", "tf", ".", "int32", ")", "-", "1", "\n", "true_keywords_len", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_sum", "(", "self", ".", "key_words_mask", ")", ",", "tf", ".", "int32", ")", "\n", "\n", "# generate masks for masking the position where a keyword is already top-1", "\n", "# reshape logits to true size", "\n", "self", ".", "logits", "=", "self", ".", "logits", "[", ":", "true_logits_len", "]", "\n", "print", "(", "self", ".", "logits", ".", "shape", ")", "\n", "\n", "# current top-1 prediction probability", "\n", "self", ".", "top1_probs", "=", "tf", ".", "reduce_max", "(", "self", ".", "logits", ",", "axis", "=", "1", ")", "\n", "\n", "# select the keywords probability from all", "\n", "self", ".", "keywords_probs", "=", "tf", ".", "gather", "(", "self", ".", "logits", ",", "self", ".", "key_words", "[", ":", "true_keywords_len", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "self", ".", "keywords_probs", ".", "shape", ")", "# 19 * 20, or true_logits_len * true_keywords_len", "\n", "# evalute each word position, and find the maximum probability keyword at each position", "\n", "self", ".", "max_keywords_args", "=", "tf", ".", "cast", "(", "tf", ".", "argmax", "(", "self", ".", "keywords_probs", ",", "axis", "=", "1", ")", ",", "tf", ".", "int32", ")", "\n", "# largest probability among all keywords", "\n", "self", ".", "max_keywords_vals", "=", "tf", ".", "reduce_max", "(", "self", ".", "keywords_probs", ",", "axis", "=", "1", ")", "\n", "\n", "# if the top-1 word is a keyword, then decrease all other keywords probability at this position!", "\n", "self", ".", "is_top1_keyword", "=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "self", ".", "top1_probs", ",", "self", ".", "max_keywords_vals", ")", ",", "tf", ".", "float32", ")", ",", "axis", "=", "1", ")", "\n", "# generate the indices for decreasing 10000 (sparse index), by combining a range(3) with the max keyword location at each word", "\n", "self", ".", "keywords_indices_to_dec", "=", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "true_logits_len", ")", ",", "axis", "=", "1", ")", ",", "tf", ".", "expand_dims", "(", "self", ".", "max_keywords_args", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "# convert to dense array. This array indicaties the location of top-1 keywords", "\n", "self", ".", "keywords_mask", "=", "tf", ".", "scatter_nd", "(", "self", ".", "keywords_indices_to_dec", ",", "tf", ".", "ones", "(", "tf", ".", "expand_dims", "(", "true_logits_len", ",", "axis", "=", "0", ")", ")", ",", "shape", "=", "(", "true_logits_len", ",", "true_keywords_len", ")", ")", "\n", "# disable the keywords on the positions where top-1 is already a keyword", "\n", "self", ".", "disabled_mask", "=", "self", ".", "is_top1_keyword", "*", "(", "tf", ".", "ones_like", "(", "self", ".", "keywords_probs", ")", "-", "self", ".", "keywords_mask", ")", "\n", "\n", "if", "self", ".", "use_logits", ":", "\n", "\n", "                ", "\"\"\"\n                # generate the (sparse) indices for the maximum keyw\n                self.keywords_indices_to_dec = tf.concat([tf.expand_dims(tf.range(true_logits_len), axis=1), tf.expand_dims(self.max_keywords_args, axis=1)], axis=1)\n                # convert to dense array\n                self.keywords_mask = tf.scatter_nd(self.keywords_indices_to_dec, tf.ones(tf.expand_dims(true_logits_len, axis=0)), shape=(true_logits_len, true_keywords_len))\n                # new keywords probability with the largest masked\n                self.masked_keywords_probs = self.keywords_probs - 10000 * self.keywords_mask\n                # extract the second largest keyword probability\n                self.top2_keyword = tf.reduce_max(self.masked_keywords_probs, axis = 1)\n                # extract the top-2 loss\n                self.top2_dis = tf.maximum(5 - (self.top1_probs - self.top2_keyword), 0)\n                \"\"\"", "\n", "\n", "# disable them! (at each position, K-1 keywords)", "\n", "self", ".", "masked_keywords_probs", "=", "self", ".", "keywords_probs", "-", "10000", "*", "self", ".", "disabled_mask", "\n", "\n", "\n", "# get the key word IDs for each position", "\n", "self", ".", "key_words_to_dec", "=", "tf", ".", "cast", "(", "tf", ".", "gather", "(", "self", ".", "key_words", ",", "self", ".", "max_keywords_args", ")", ",", "tf", ".", "int32", ")", "\n", "# generate 2-D indices", "\n", "self", ".", "indices_to_dec", "=", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "true_logits_len", ")", ",", "axis", "=", "1", ")", ",", "tf", ".", "expand_dims", "(", "self", ".", "key_words_to_dec", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "# generate a mask for the maximum key word probability at each word position", "\n", "self", ".", "logits_mask", "=", "tf", ".", "scatter_nd", "(", "self", ".", "indices_to_dec", ",", "tf", ".", "ones", "(", "tf", ".", "expand_dims", "(", "true_logits_len", ",", "axis", "=", "0", ")", ")", ",", "shape", "=", "(", "true_logits_len", ",", "int", "(", "self", ".", "logits", ".", "shape", "[", "1", "]", ")", ")", ")", "\n", "# modify the logits, add a large negative number to the corresponding max keyword", "\n", "self", ".", "modified_logits", "=", "self", ".", "logits", "-", "10000", "*", "self", ".", "logits_mask", "\n", "\n", "self", ".", "max_probs", "=", "tf", ".", "reduce_max", "(", "self", ".", "modified_logits", ",", "axis", "=", "1", ")", "\n", "print", "(", "self", ".", "max_probs", ".", "shape", ")", "# 19", "\n", "\n", "self", ".", "diff_probs", "=", "tf", ".", "maximum", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "max_probs", ",", "1", ")", ",", "[", "1", ",", "true_keywords_len", "]", ")", "-", "self", ".", "masked_keywords_probs", ",", "-", "self", ".", "CONFIDENCE", ")", "\n", "print", "(", "self", ".", "diff_probs", ".", "shape", ")", "\n", "\n", "self", ".", "min_diff_probs", "=", "tf", ".", "reduce_min", "(", "self", ".", "diff_probs", ",", "axis", "=", "0", ")", "\n", "\n", "# loss1 = tf.reduce_sum(self.min_diff_probs) + tf.reduce_sum(self.top2_dis)", "\n", "loss1", "=", "tf", ".", "reduce_sum", "(", "self", ".", "min_diff_probs", ")", "\n", "self", ".", "loss1", "=", "tf", ".", "reduce_sum", "(", "self", ".", "const", "*", "loss1", ")", "\n", "print", "(", "loss1", ".", "shape", ")", "\n", "", "else", ":", "\n", "# reshape softmax to true size", "\n", "                ", "self", ".", "softmax", "=", "self", ".", "softmax", "[", ":", "true_logits_len", "]", "\n", "self", ".", "top1_softmax", "=", "tf", ".", "reduce_max", "(", "self", ".", "softmax", ",", "axis", "=", "1", ")", "\n", "\n", "# gather the probability of keywords at each position", "\n", "self", ".", "keywords_softmax", "=", "tf", ".", "gather", "(", "self", ".", "softmax", ",", "self", ".", "key_words", "[", ":", "true_keywords_len", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# disable them! (at each position, K-1 keywords)", "\n", "self", ".", "masked_keywords_softmax", "=", "self", ".", "keywords_softmax", "*", "(", "1", "-", "self", ".", "disabled_mask", ")", "\n", "\n", "self", ".", "max_probs", "=", "tf", ".", "reduce_max", "(", "self", ".", "masked_keywords_softmax", ",", "axis", "=", "0", ")", "\n", "loss1", "=", "tf", ".", "log", "(", "self", ".", "max_probs", "+", "1e-30", ")", "\n", "self", ".", "loss1", "=", "-", "tf", ".", "reduce_sum", "(", "self", ".", "const", "*", "loss1", ")", "\n", "# print(t.get_shape())", "\n", "# loss1 = tf.reduce_sum(tf.log(tf.reduce_max(tf.gather(tf.transpose(self.softmax, perm=[1,0]), self.key_words), axis=1)+ 1e-30)", "\n", "# print(self.softmax.get_shape())", "\n", "# print(\"softmax:\", self.softmax.get_shape())", "\n", "# print(\"tf.gather(self.softmax, self.key_words, axis=1):\", tf.gather(self.softmax, self.key_words, axis=1))", "\n", "# print(\"key_words_mask:\", tf.cast(self.key_words_mask, tf.float32).get_shape())", "\n", "# print(tf.reduce_max(tf.gather(self.softmax, self.key_words, axis=1), axis=0).get_shape())", "\n", "\n", "", "if", "self", ".", "TARGETED", ":", "\n", "                ", "self", ".", "loss", "=", "self", ".", "loss1", "#increase the probability of keywords", "\n", "", "else", ":", "\n", "                ", "self", ".", "loss", "=", "-", "self", ".", "loss1", "#decrease the probability of keywords", "\n", "", "", "else", ":", "\n", "# use a new caption", "\n", "            ", "if", "self", ".", "use_logits", ":", "\n", "                ", "true_cap_len", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_sum", "(", "self", ".", "input_mask", ")", ",", "tf", ".", "int32", ")", "\n", "true_logits_len", "=", "tf", ".", "cast", "(", "tf", ".", "reduce_sum", "(", "self", ".", "input_mask", ")", ",", "tf", ".", "int32", ")", "-", "1", "\n", "self", ".", "logits", "=", "self", ".", "logits", "[", ":", "true_logits_len", "]", "\n", "print", "(", "\"input_feed shape:\"", ",", "self", ".", "input_feed", ".", "shape", ")", "\n", "print", "(", "\"logits shape:\"", ",", "self", ".", "logits", ".", "shape", ")", "\n", "self", ".", "true_input_feed", "=", "tf", ".", "cast", "(", "self", ".", "input_feed", "[", "0", "]", "[", ":", "true_cap_len", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "print", "(", "\"true_input_feed shape:\"", ",", "self", ".", "true_input_feed", ".", "shape", ")", "\n", "self", ".", "cap_indices", "=", "tf", ".", "transpose", "(", "tf", ".", "concat", "(", "[", "[", "tf", ".", "range", "(", "true_logits_len", ")", "]", ",", "[", "self", ".", "true_input_feed", "[", "1", ":", "]", "]", "]", ",", "axis", "=", "0", ")", ")", "\n", "print", "(", "\"cap_indices shape:\"", ",", "self", ".", "cap_indices", ".", "shape", ")", "\n", "self", ".", "cap_logits", "=", "tf", ".", "gather_nd", "(", "self", ".", "logits", ",", "self", ".", "cap_indices", ")", "\n", "print", "(", "\"cap_logits shape:\"", ",", "self", ".", "cap_logits", ".", "shape", ")", "\n", "self", ".", "logits_mask", "=", "tf", ".", "scatter_nd", "(", "self", ".", "cap_indices", ",", "tf", ".", "ones", "(", "[", "true_logits_len", "]", ")", ",", "shape", "=", "(", "true_logits_len", ",", "int", "(", "self", ".", "logits", ".", "shape", "[", "1", "]", ")", ")", ")", "\n", "# we minus 10000 on target word posistion to make sure it is not the largest any more.", "\n", "self", ".", "modified_logits", "=", "self", ".", "logits", "-", "10000", "*", "self", ".", "logits_mask", "\n", "# Then if we pick the max, it is the largest among non-target word.", "\n", "self", ".", "max_probs", "=", "tf", ".", "reduce_max", "(", "self", ".", "modified_logits", ",", "axis", "=", "1", ")", "\n", "self", ".", "original_max_prob", "=", "tf", ".", "reduce_max", "(", "self", ".", "logits", ",", "axis", "=", "1", ")", "\n", "if", "self", ".", "TARGETED", ":", "\n", "                    ", "self", ".", "diff_probs", "=", "tf", ".", "maximum", "(", "self", ".", "max_probs", "-", "self", ".", "cap_logits", ",", "-", "self", ".", "CONFIDENCE", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "diff_probs", "=", "tf", ".", "maximum", "(", "self", ".", "cap_logits", "-", "self", ".", "max_probs", ",", "-", "self", ".", "CONFIDENCE", ")", "\n", "", "print", "(", "\"max_probs shape:\"", ",", "self", ".", "max_probs", ".", "shape", ")", "\n", "loss1", "=", "tf", ".", "reduce_sum", "(", "self", ".", "diff_probs", ")", "\n", "self", ".", "loss1", "=", "tf", ".", "reduce_sum", "(", "self", ".", "const", "*", "loss1", ")", "\n", "self", ".", "loss", "=", "self", ".", "loss1", "\n", "\n", "", "else", ":", "\n", "# use the output probability directly", "\n", "                ", "if", "self", ".", "TARGETED", ":", "\n", "                    ", "self", ".", "loss1", "=", "tf", ".", "reduce_sum", "(", "self", ".", "const", "*", "self", ".", "output", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "self", ".", "loss1", "=", "-", "tf", ".", "reduce_sum", "(", "self", ".", "const", "*", "self", ".", "output", ")", "\n", "", "self", ".", "loss", "=", "self", ".", "loss1", "\n", "\n", "# regularization loss", "\n", "", "", "self", ".", "loss2", "=", "tf", ".", "reduce_sum", "(", "self", ".", "lpdist", ")", "\n", "\n", "self", ".", "loss", "+=", "self", ".", "loss2", "\n", "\n", "# Setup the adam optimizer and keep track of variables we're creating", "\n", "start_vars", "=", "set", "(", "x", ".", "name", "for", "x", "in", "tf", ".", "global_variables", "(", ")", ")", "\n", "# optimizer = tf.train.GradientDescentOptimizer(self.LEARNING_RATE)", "\n", "# optimizer = tf.train.MomentumOptimizer(self.LEARNING_RATE, 0.99, use_nesterov = True)", "\n", "# optimizer = tf.train.RMSPropOptimizer(self.LEARNING_RATE, centered = True, momentum = 0.9)", "\n", "# optimizer = tf.train.AdadeltaOptimizer(self.LEARNING_RATE)", "\n", "# optimizer = tf.train.AdamOptimizer(self.LEARNING_RATE, adam_beta1, adam_beta2)", "\n", "# self.train = optimizer.minimize(self.loss, var_list=[self.modifier])", "\n", "self", ".", "train", "=", "self", ".", "adam_optimizer_tf", "(", "self", ".", "loss", ",", "self", ".", "modifier", ")", "\n", "end_vars", "=", "tf", ".", "global_variables", "(", ")", "\n", "new_vars", "=", "[", "x", "for", "x", "in", "end_vars", "if", "x", ".", "name", "not", "in", "start_vars", "]", "\n", "\n", "# these are the variables to initialize when we run", "\n", "self", ".", "setup", "=", "[", "]", "\n", "self", ".", "assign_const_op", "=", "self", ".", "const", ".", "assign", "(", "self", ".", "assign_const", ")", "\n", "self", ".", "setup", ".", "append", "(", "self", ".", "key_words", ".", "assign", "(", "self", ".", "assign_key_words", ")", ")", "\n", "self", ".", "setup", ".", "append", "(", "self", ".", "key_words_mask", ".", "assign", "(", "self", ".", "assign_key_words_mask", ")", ")", "\n", "self", ".", "setup", ".", "append", "(", "self", ".", "timg", ".", "assign", "(", "self", ".", "assign_timg", ")", ")", "\n", "self", ".", "setup", ".", "append", "(", "self", ".", "input_feed", ".", "assign", "(", "self", ".", "assign_input_feed", ")", ")", "\n", "self", ".", "setup", ".", "append", "(", "self", ".", "input_mask", ".", "assign", "(", "self", ".", "assign_input_mask", ")", ")", "\n", "self", ".", "setup", ".", "append", "(", "self", ".", "assign_const_op", ")", "\n", "# self.grad_op = tf.gradients(self.loss, self.modifier)", "\n", "\n", "self", ".", "reset_input", "=", "[", "]", "\n", "self", ".", "reset_input", ".", "append", "(", "self", ".", "input_feed", ".", "assign", "(", "self", ".", "assign_input_feed", ")", ")", "\n", "self", ".", "reset_input", ".", "append", "(", "self", ".", "input_mask", ".", "assign", "(", "self", ".", "assign_input_mask", ")", ")", "\n", "\n", "self", ".", "init", "=", "tf", ".", "variables_initializer", "(", "var_list", "=", "[", "self", ".", "modifier", "]", "+", "new_vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.adam_optimizer_tf": [[335, 363], ["tensorflow.name_scope", "tensorflow.norm", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.tanh", "tensorflow.assign_sub", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign_add", "tensorflow.group", "tensorflow.gradients", "numpy.zeros", "numpy.zeros", "tensorflow.sqrt", "tensorflow.square", "tensorflow.pow", "tensorflow.pow", "tensorflow.sqrt", "tensorflow.sqrt"], "methods", ["None"], ["", "def", "adam_optimizer_tf", "(", "self", ",", "loss", ",", "var", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "\"adam_optimier\"", ")", ":", "\n", "            ", "self", ".", "grad", "=", "tf", ".", "gradients", "(", "loss", ",", "var", ")", "[", "0", "]", "\n", "self", ".", "grad_norm", "=", "tf", ".", "norm", "(", "self", ".", "grad", ")", "\n", "# self.noise = tf.random_normal(self.grad.shape, 0.0, 1.0)", "\n", "self", ".", "noise", "=", "0", "\n", "self", ".", "beta1", "=", "tf", ".", "constant", "(", "0.9", ")", "\n", "self", ".", "beta2", "=", "tf", ".", "constant", "(", "0.999", ")", "\n", "self", ".", "lr", "=", "tf", ".", "constant", "(", "self", ".", "LEARNING_RATE", ")", "\n", "self", ".", "epsilon", "=", "1e-8", "\n", "self", ".", "epoch", "=", "tf", ".", "Variable", "(", "0", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "mt", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "var", ".", "shape", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "vt", "=", "tf", ".", "Variable", "(", "np", ".", "zeros", "(", "var", ".", "shape", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "new_mt", "=", "self", ".", "beta1", "*", "self", ".", "mt", "+", "(", "1", "-", "self", ".", "beta1", ")", "*", "self", ".", "grad", "\n", "new_vt", "=", "self", ".", "beta2", "*", "self", ".", "vt", "+", "(", "1", "-", "self", ".", "beta2", ")", "*", "tf", ".", "square", "(", "self", ".", "grad", ")", "\n", "corr", "=", "(", "tf", ".", "sqrt", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta2", ",", "self", ".", "epoch", ")", ")", ")", "/", "(", "1", "-", "tf", ".", "pow", "(", "self", ".", "beta1", ",", "self", ".", "epoch", ")", ")", "\n", "# delta = self.lr * corr * (new_mt / (tf.sqrt(new_vt) + self.epsilon))", "\n", "delta", "=", "self", ".", "lr", "*", "corr", "*", "(", "(", "new_mt", "/", "tf", ".", "sqrt", "(", "new_vt", "+", "self", ".", "epsilon", ")", ")", "+", "self", ".", "noise", "/", "tf", ".", "sqrt", "(", "self", ".", "epoch", "+", "1", ")", ")", "\n", "# delta = self.lr * (self.grad + self.noise)", "\n", "\n", "self", ".", "new_var", "=", "var", "-", "delta", "\n", "self", ".", "updated_newimg", "=", "tf", ".", "tanh", "(", "self", ".", "new_var", "+", "self", ".", "timg", ")", "\n", "assign_var", "=", "tf", ".", "assign_sub", "(", "var", ",", "delta", ")", "\n", "assign_mt", "=", "tf", ".", "assign", "(", "self", ".", "mt", ",", "new_mt", ")", "\n", "assign_vt", "=", "tf", ".", "assign", "(", "self", ".", "vt", ",", "new_vt", ")", "\n", "assign_epoch", "=", "tf", ".", "assign_add", "(", "self", ".", "epoch", ",", "1", ")", "\n", "return", "tf", ".", "group", "(", "assign_var", ",", "assign_mt", ",", "assign_vt", ",", "assign_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack": [[364, 378], ["print", "range", "len", "len", "print", "l2_attack.CarliniL2.attack_batch"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack_batch"], ["", "", "def", "attack", "(", "self", ",", "imgs", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "cap_key_words", ",", "cap_key_words_mask", ",", "attackid", ",", "try_id", ",", "beam_size", ",", "iter_per_sentence", "=", "1", ",", "attack_const", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        Perform the L_2 attack on the given images for the given targets.\n\n        If self.targeted is true, then the targets represents the target labels.\n        If self.targeted is false, then targets are the original class labels.\n        \"\"\"", "\n", "r", "=", "[", "]", "\n", "print", "(", "'go up to'", ",", "len", "(", "imgs", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "imgs", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "            ", "print", "(", "'tick'", ",", "i", ")", "\n", "t", "=", "self", ".", "attack_batch", "(", "imgs", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "cap_key_words", ",", "cap_key_words_mask", ",", "iter_per_sentence", ",", "attackid", ",", "try_id", ",", "beam_size", ",", "attack_const", ")", "\n", "# r.extend(t[0])", "\n", "", "return", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack_batch": [[380, 560], ["numpy.arctanh", "numpy.zeros", "l2_attack.CarliniL2.sess.run", "numpy.set_printoptions", "l2_attack.CarliniL2.sess.run", "range", "numpy.ones", "numpy.ones", "im2txt.inference_utils.caption_generator.CaptionGenerator", "im2txt.inference_utils.caption_generator.CaptionGenerator.beam_search", "len", "numpy.append", "time.time", "print", "sys.stdout.flush", "numpy.ones", "numpy.zeros", "numpy.squeeze", "numpy.squeeze", "print", "time.time", "numpy.array", "l2_attack.CarliniL2.sess.run", "l2_attack.CarliniL2.sess.run", "l2_attack.CarliniL2.sess.run", "l2_attack.CarliniL2.sess.run", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "vocab.id_to_word", "top1_sentence.append", "list", "im2txt.inference_utils.caption_generator.CaptionGenerator.beam_search", "print", "len", "numpy.append", "l2_attack.CarliniL2.sess.run", "print", "vocab.id_to_word", "zip", "print", "int", "set().issubset", "l2_attack.CarliniL2.sess.run", "print", "l2_attack.CarliniL2.sess.run", "print", "numpy.array", "numpy.ones", "numpy.zeros", "numpy.argmax", "vocab.id_to_word", "numpy.exp", "numpy.sum", "numpy.array", "bool", "numpy.array", "set", "set", "set"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word"], ["", "def", "attack_batch", "(", "self", ",", "imgs", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "key_words", ",", "key_words_mask", ",", "iter_per_sentence", ",", "attackid", ",", "try_id", ",", "beam_size", ",", "attack_const", "=", "1.0", ")", ":", "\n", "        ", "max_caption_length", "=", "20", "\n", "batch_size", "=", "self", ".", "batch_size", "\n", "\n", "# convert to tanh-space", "\n", "imgs", "=", "np", ".", "arctanh", "(", "imgs", "*", "0.9999", ")", "\n", "\n", "# set the lower and upper bounds accordingly", "\n", "lower_bound", "=", "np", ".", "zeros", "(", "batch_size", ")", "\n", "CONST", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "attack_const", "\n", "upper_bound", "=", "np", ".", "ones", "(", "batch_size", ")", "*", "1e10", "\n", "# completely reset adam's internal state.", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "init", ")", "\n", "batch", "=", "imgs", "[", ":", "batch_size", "]", "\n", "# batchkeywords = key_words[:batch_size]", "\n", "# batchseqs = input_seqs[:batch_size]", "\n", "# batchmasks = input_masks[:batch_size]", "\n", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "3", ",", "linewidth", "=", "150", ")", "\n", "\n", "# set the variables so that we don't have to send them over again", "\n", "if", "self", ".", "use_keywords", ":", "\n", "#use inference mode here", "\n", "            ", "generator", "=", "caption_generator", ".", "CaptionGenerator", "(", "inf_model", ",", "vocab", ",", "beam_size", "=", "beam_size", ")", "\n", "captions", "=", "generator", ".", "beam_search", "(", "inf_sess", ",", "imgs", "[", "0", "]", ")", "\n", "infer_caption", "=", "captions", "[", "0", "]", ".", "sentence", "\n", "# infer_caption = [1, 0, 11, 46, 0, 195, 4, 33, 5, 0, 155, 3, 2]", "\n", "true_infer_cap_len", "=", "len", "(", "infer_caption", ")", "\n", "\n", "infer_caption", "=", "infer_caption", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "true_infer_cap_len", ")", "\n", "infer_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "true_infer_cap_len", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "true_infer_cap_len", ")", ")", "\n", "", "else", ":", "\n", "# if not using keywords, it is the exact sentence", "\n", "            ", "infer_caption", "=", "key_words", "\n", "infer_mask", "=", "key_words_mask", "\n", "\n", "\n", "", "self", ".", "sess", ".", "run", "(", "self", ".", "setup", ",", "{", "self", ".", "assign_timg", ":", "batch", ",", "\n", "self", ".", "assign_input_mask", ":", "[", "infer_mask", "]", ",", "\n", "self", ".", "assign_input_feed", ":", "[", "infer_caption", "]", ",", "\n", "self", ".", "assign_key_words", ":", "np", ".", "squeeze", "(", "key_words", ")", ",", "\n", "self", ".", "assign_key_words_mask", ":", "np", ".", "squeeze", "(", "key_words_mask", ")", ",", "\n", "self", ".", "assign_const", ":", "CONST", "}", ")", "\n", "\n", "prev", "=", "1e6", "\n", "train_timer", "=", "0.0", "\n", "best_lp", "=", "1e10", "\n", "best_img", "=", "None", "\n", "best_loss1", "=", "1e10", "\n", "best_loss2", "=", "1e10", "\n", "best_loss", "=", "1e10", "\n", "for", "iteration", "in", "range", "(", "self", ".", "MAX_ITERATIONS", ")", ":", "\n", "            ", "attack_begin_time", "=", "time", ".", "time", "(", ")", "\n", "# perform the attack ", "\n", "if", "self", ".", "use_logits", ":", "\n", "                ", "if", "self", ".", "use_keywords", ":", "\n", "                    ", "l", ",", "l1", ",", "l2", ",", "lps", ",", "grad_norm", ",", "nimg", ",", "_", ",", "keywords_probs", ",", "top1_probs", ",", "disabled_mask", ",", "masked_keywords_probs", ",", "max_probs", ",", "diff_probs", ",", "min_diff_probs", ",", "last_input", ",", "softmax", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "loss", ",", "self", ".", "loss1", ",", "self", ".", "loss2", ",", "self", ".", "lpdist", ",", "self", ".", "grad_norm", ",", "self", ".", "updated_newimg", ",", "self", ".", "train", ",", "self", ".", "keywords_probs", ",", "self", ".", "top1_probs", ",", "self", ".", "disabled_mask", ",", "self", ".", "masked_keywords_probs", ",", "self", ".", "max_probs", ",", "self", ".", "diff_probs", ",", "self", ".", "min_diff_probs", ",", "self", ".", "input_feed", ",", "self", ".", "softmax", "]", ")", "\n", "", "else", ":", "\n", "                    ", "l", ",", "l1", ",", "l2", ",", "lps", ",", "grad_norm", ",", "nimg", ",", "_", ",", "cap_logits", ",", "diff_probs", ",", "original_max_prob", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "loss", ",", "self", ".", "loss1", ",", "self", ".", "loss2", ",", "self", ".", "lpdist", ",", "self", ".", "grad_norm", ",", "self", ".", "newimg", ",", "self", ".", "train", ",", "self", ".", "cap_logits", ",", "self", ".", "diff_probs", ",", "self", ".", "original_max_prob", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "use_keywords", ":", "\n", "                    ", "l", ",", "l1", ",", "l2", ",", "lps", ",", "grad_norm", ",", "nimg", ",", "_", ",", "disabled_mask", ",", "keywords_softmax", ",", "masked_keywords_softmax", ",", "top1_probs", ",", "max_probs", ",", "last_input", ",", "softmax", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "loss", ",", "self", ".", "loss1", ",", "self", ".", "loss2", ",", "self", ".", "lpdist", ",", "self", ".", "grad_norm", ",", "self", ".", "updated_newimg", ",", "self", ".", "train", ",", "self", ".", "disabled_mask", ",", "self", ".", "keywords_softmax", ",", "self", ".", "masked_keywords_softmax", ",", "self", ".", "top1_softmax", ",", "self", ".", "max_probs", ",", "self", ".", "input_feed", ",", "self", ".", "softmax", "]", ")", "\n", "", "else", ":", "\n", "                    ", "l", ",", "l1", ",", "l2", ",", "lps", ",", "grad_norm", ",", "nimg", ",", "_", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "loss", ",", "self", ".", "loss1", ",", "self", ".", "loss2", ",", "self", ".", "lpdist", ",", "self", ".", "grad_norm", ",", "self", ".", "newimg", ",", "self", ".", "train", "]", ")", "\n", "\n", "", "", "print", "(", "\"[attack No.{}] [try No.{}] [C={:.5g}] iter = {}, time = {:.8f}, grad_norm = {:.5g}, loss = {:.5g}, loss1 = {:.5g}, loss2 = {:.5g}, best_lp = {:.5g}\"", ".", "format", "(", "attackid", ",", "try_id", ",", "CONST", "[", "0", "]", ",", "iteration", ",", "train_timer", ",", "grad_norm", ",", "l", ",", "l1", ",", "l2", ",", "best_lp", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "# update softmax using the latest variable", "\n", "if", "self", ".", "use_logits", ":", "\n", "                ", "if", "self", ".", "use_keywords", ":", "\n", "# keywords_probs, top1_probs, disabled_mask, masked_keywords_probs, max_probs, top2_keyword, top2_dis, diff_probs, min_diff_probs, last_input, softmax, logits, modified_logits = self.sess.run([self.keywords_probs, self.top1_probs, self.disabled_mask, self.masked_keywords_probs, self.max_probs, self.top2_keyword, self.top2_dis, self.diff_probs, self.min_diff_probs, self.input_feed, self.softmax, self.logits, self.modified_logits])", "\n", "# keywords_probs, top1_probs, disabled_mask, masked_keywords_probs, max_probs, diff_probs, min_diff_probs, last_input, softmax, logits, modified_logits = self.sess.run([self.keywords_probs, self.top1_probs, self.disabled_mask, self.masked_keywords_probs, self.max_probs, self.diff_probs, self.min_diff_probs, self.input_feed, self.softmax, self.logits, self.modified_logits])", "\n", "# print(\"keywords probs:\", keywords_probs[:int(np.sum(key_words_mask))])", "\n", "                    ", "print", "(", "\"keywords probs:\\n\"", ",", "keywords_probs", ".", "T", ")", "\n", "print", "(", "\"disabled mask:\\n\"", ",", "disabled_mask", ".", "T", ")", "\n", "print", "(", "\"masked keywords probs:\\n\"", ",", "masked_keywords_probs", ".", "T", ")", "\n", "# print(\"top2 keyword prob:\\n\", top2_keyword)", "\n", "print", "(", "\"top1 probs:\\n\"", ",", "top1_probs", ")", "\n", "print", "(", "\"max probs (after -10000):\\n\"", ",", "max_probs", ")", "\n", "# print(\"top2 distance:\\n\", top2_dis)", "\n", "print", "(", "\"diff probs:\\n\"", ",", "diff_probs", ".", "T", ")", "\n", "print", "(", "\"min diff probs:\\n\"", ",", "min_diff_probs", ")", "\n", "", "else", ":", "\n", "\n", "# cap_logits, diff_probs, original_max_prob= self.sess.run([self.cap_logits, self.diff_probs, self.original_max_prob])", "\n", "# print(\"keywords probs:\", keywords_probs[:int(np.sum(key_words_mask))])", "\n", "                    ", "print", "(", "\"cap_logits:\\n\"", ",", "cap_logits", ")", "\n", "print", "(", "\"diff_probs:\\n\"", ",", "diff_probs", ")", "\n", "print", "(", "\"original_max_prob:\\n\"", ",", "original_max_prob", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "use_keywords", ":", "\n", "                    ", "print", "(", "\"keywords probs:\\n\"", ",", "keywords_softmax", ".", "T", ")", "\n", "print", "(", "\"top1 probs:\\n\"", ",", "top1_probs", ")", "\n", "print", "(", "\"disabled mask:\\n\"", ",", "disabled_mask", ".", "T", ")", "\n", "print", "(", "\"masked keywords probs:\\n\"", ",", "masked_keywords_softmax", ".", "T", ")", "\n", "print", "(", "\"max probs:\\n\"", ",", "max_probs", ")", "\n", "\n", "", "", "if", "self", ".", "use_keywords", ":", "\n", "                ", "last_input", "=", "[", "vocab", ".", "id_to_word", "(", "s", ")", "for", "s", "in", "last_input", "[", "0", "]", "]", "\n", "top1_sentence", "=", "[", "]", "\n", "for", "word", "in", "softmax", ":", "\n", "                    ", "top1_sentence", ".", "append", "(", "vocab", ".", "id_to_word", "(", "np", ".", "argmax", "(", "word", ")", ")", ")", "\n", "", "print", "(", "\"top 1 pred:\"", ",", "list", "(", "zip", "(", "last_input", ",", "top1_sentence", ")", ")", ")", "\n", "\n", "# use beam search in inference mode here if we do key_words based attack", "\n", "", "if", "iteration", "%", "iter_per_sentence", "==", "0", ":", "\n", "# infer_caption = np.argmax(np.array(softmax), axis=1)", "\n", "# infer_caption = np.append([vocab.start_id], infer_caption).tolist()", "\n", "# generator = caption_generator.CaptionGenerator(inf_model, vocab)", "\n", "# print(nimg[0].shape)", "\n", "                ", "if", "self", ".", "use_keywords", ":", "\n", "                    ", "captions", "=", "generator", ".", "beam_search", "(", "inf_sess", ",", "nimg", "[", "0", "]", ")", "\n", "infer_caption", "=", "captions", "[", "0", "]", ".", "sentence", "\n", "print", "(", "\"current sentence:\"", ")", "\n", "for", "new_caption", "in", "captions", ":", "\n", "                        ", "sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "new_caption", ".", "sentence", "]", "\n", "print", "(", "sentence", ",", "\"p =\"", ",", "np", ".", "exp", "(", "new_caption", ".", "logprob", ")", ")", "\n", "\n", "", "", "true_key_words", "=", "key_words", "[", ":", "int", "(", "np", ".", "sum", "(", "key_words_mask", ")", ")", "]", "\n", "if", "self", ".", "use_keywords", ":", "\n", "                    ", "if", "self", ".", "TARGETED", "and", "set", "(", "true_key_words", ")", ".", "issubset", "(", "infer_caption", ")", ":", "\n", "# when attack is successful, we pick the adversarial image with minimum distortion", "\n", "                        ", "l", ",", "l1", ",", "l2", ",", "lps", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "loss", ",", "self", ".", "loss1", ",", "self", ".", "loss2", ",", "self", ".", "lpdist", "]", ")", "\n", "if", "lps", "[", "0", "]", "<", "best_lp", ":", "\n", "                            ", "best_img", "=", "np", ".", "array", "(", "nimg", ")", "\n", "best_loss", "=", "l", "\n", "best_loss1", "=", "l1", "\n", "best_loss2", "=", "l2", "\n", "best_lp", "=", "lps", "[", "0", "]", "\n", "", "print", "(", "\"<<<<<<<<<<<<<< a valid attack is found, lp =\"", ",", "lps", "[", "0", "]", ",", "\", best =\"", ",", "best_lp", ",", "\"best_loss=\"", ",", "best_loss", ",", "\">>>>>>>>>>>>>>>>>>>\"", ")", "\n", "", "if", "not", "self", ".", "TARGETED", "and", "not", "bool", "(", "set", "(", "true_key_words", ")", "&", "set", "(", "infer_caption", ")", ")", ":", "\n", "# when attack is successful, we pick the adversarial image with minimum distortion", "\n", "                        ", "l", ",", "l1", ",", "l2", ",", "lps", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "loss", ",", "self", ".", "loss1", ",", "self", ".", "loss2", ",", "self", ".", "lpdist", "]", ")", "\n", "if", "lps", "[", "0", "]", "<", "best_lp", ":", "\n", "                            ", "best_img", "=", "np", ".", "array", "(", "nimg", ")", "\n", "best_loss", "=", "l", "\n", "best_loss1", "=", "l1", "\n", "best_loss2", "=", "l2", "\n", "best_lp", "=", "lps", "[", "0", "]", "\n", "", "print", "(", "\"<<<<<<<<<<<<<< a valid attack is found, lp =\"", ",", "lps", "[", "0", "]", ",", "\", best =\"", ",", "best_lp", ",", "\"best_loss=\"", ",", "best_loss", ",", "\">>>>>>>>>>>>>>>>>>>\"", ")", "\n", "", "", "else", ":", "\n", "# if the attack is not keywords based, we do not do inference in the iterations. So we do not know the attack is successful or not.", "\n", "# We pick the adversarial example with minimum loss.", "\n", "                    ", "if", "l", "<", "best_loss", ":", "\n", "                        ", "best_img", "=", "np", ".", "array", "(", "nimg", ")", "\n", "best_loss1", "=", "l1", "\n", "best_loss2", "=", "l2", "\n", "best_lp", "=", "lps", "[", "0", "]", "\n", "best_loss", "=", "l", "\n", "\n", "\n", "", "", "if", "self", ".", "use_keywords", ":", "\n", "# print(\"max likelihood id array found:\", infer_caption)", "\n", "                    ", "true_infer_cap_len", "=", "len", "(", "infer_caption", ")", "\n", "infer_caption", "=", "infer_caption", "[", "0", ":", "true_infer_cap_len", "]", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "true_infer_cap_len", ")", "\n", "infer_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "true_infer_cap_len", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "true_infer_cap_len", ")", ")", "\n", "# print(\"input id array for next iteration:\", infer_caption)", "\n", "# print(\"input mask for next iteration:\", infer_mask)", "\n", "# print caption in each iteration", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "reset_input", ",", "{", "self", ".", "assign_input_mask", ":", "[", "infer_mask", "]", ",", "\n", "self", ".", "assign_input_feed", ":", "[", "infer_caption", "]", "}", ")", "\n", "\n", "\n", "# print(grad[0].reshape(-1))", "\n", "# print((old_modifier - new_modifier).reshape(-1))", "\n", "\n", "# check if we should abort search if we're getting nowhere.", "\n", "", "", "if", "self", ".", "ABORT_EARLY", "and", "iteration", "%", "self", ".", "early_stop_iters", "==", "0", ":", "\n", "                ", "if", "l", ">", "prev", "*", ".9999", ":", "\n", "                    ", "print", "(", "\"Early stopping because there is no improvement\"", ")", "\n", "break", "\n", "", "prev", "=", "l", "\n", "", "train_timer", "+=", "time", ".", "time", "(", ")", "-", "attack_begin_time", "\n", "\n", "# no successful attack is found ,return the last iteration image", "\n", "", "if", "best_img", "is", "None", ":", "\n", "            ", "return", "np", ".", "array", "(", "nimg", ")", ",", "best_loss", ",", "best_loss1", ",", "best_loss2", ",", "CONST", "\n", "", "else", ":", "\n", "            ", "return", "best_img", ",", "best_loss", ",", "best_loss1", ",", "best_loss2", ",", "CONST", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModel.build_inputs": [[33, 55], ["super().build_inputs", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_inputs"], ["def", "build_inputs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "mode", "==", "\"inference\"", ":", "\n", "# Inference mode doesn't read from disk, so defer to parent.", "\n", "      ", "return", "super", "(", "ShowAndTellModel", ",", "self", ")", ".", "build_inputs", "(", ")", "\n", "", "else", ":", "\n", "# Replace disk I/O with random Tensors.", "\n", "      ", "self", ".", "images", "=", "tf", ".", "random_uniform", "(", "\n", "shape", "=", "[", "self", ".", "config", ".", "batch_size", ",", "self", ".", "config", ".", "image_height", ",", "\n", "self", ".", "config", ".", "image_width", ",", "3", "]", ",", "\n", "minval", "=", "-", "1", ",", "\n", "maxval", "=", "1", ")", "\n", "self", ".", "input_seqs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "config", ".", "batch_size", ",", "15", "]", ",", "\n", "minval", "=", "0", ",", "\n", "maxval", "=", "self", ".", "config", ".", "vocab_size", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "self", ".", "target_seqs", "=", "tf", ".", "random_uniform", "(", "\n", "[", "self", ".", "config", ".", "batch_size", ",", "15", "]", ",", "\n", "minval", "=", "0", ",", "\n", "maxval", "=", "self", ".", "config", ".", "vocab_size", ",", "\n", "dtype", "=", "tf", ".", "int64", ")", "\n", "self", ".", "input_mask", "=", "tf", ".", "ones_like", "(", "self", ".", "input_seqs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest.setUp": [[59, 62], ["super().setUp", "im2txt.configuration.ModelConfig"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "ShowAndTellModelTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "_model_config", "=", "configuration", ".", "ModelConfig", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._countModelParameters": [[63, 72], ["tensorflow.global_variables", "v.get_shape().num_elements", "v.op.name.split", "counter.get", "v.get_shape"], "methods", ["None"], ["", "def", "_countModelParameters", "(", "self", ")", ":", "\n", "    ", "\"\"\"Counts the number of parameters in the model at top level scope.\"\"\"", "\n", "counter", "=", "{", "}", "\n", "for", "v", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "      ", "name", "=", "v", ".", "op", ".", "name", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "num_params", "=", "v", ".", "get_shape", "(", ")", ".", "num_elements", "(", ")", "\n", "assert", "num_params", "\n", "counter", "[", "name", "]", "=", "counter", ".", "get", "(", "name", ",", "0", ")", "+", "num_params", "\n", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkModelParameters": [[73, 89], ["show_and_tell_model_test.ShowAndTellModelTest._countModelParameters", "show_and_tell_model_test.ShowAndTellModelTest.assertDictEqual"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._countModelParameters"], ["", "def", "_checkModelParameters", "(", "self", ")", ":", "\n", "    ", "\"\"\"Verifies the number of parameters in the model.\"\"\"", "\n", "param_counts", "=", "self", ".", "_countModelParameters", "(", ")", "\n", "expected_param_counts", "=", "{", "\n", "\"InceptionV3\"", ":", "21802784", ",", "\n", "# inception_output_size * embedding_size", "\n", "\"image_embedding\"", ":", "1048576", ",", "\n", "# vocab_size * embedding_size", "\n", "\"seq_embedding\"", ":", "6144000", ",", "\n", "# (embedding_size + num_lstm_units + 1) * 4 * num_lstm_units", "\n", "\"lstm\"", ":", "2099200", ",", "\n", "# (num_lstm_units + 1) * vocab_size", "\n", "\"logits\"", ":", "6156000", ",", "\n", "\"global_step\"", ":", "1", ",", "\n", "}", "\n", "self", ".", "assertDictEqual", "(", "expected_param_counts", ",", "param_counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkOutputs": [[90, 111], ["expected_shapes.keys", "enumerate", "show_and_tell_model_test.ShowAndTellModelTest.test_session", "sess.run", "sess.run", "tensorflow.global_variables_initializer", "show_and_tell_model_test.ShowAndTellModelTest.fail"], "methods", ["None"], ["", "def", "_checkOutputs", "(", "self", ",", "expected_shapes", ",", "feed_dict", "=", "None", ")", ":", "\n", "    ", "\"\"\"Verifies that the model produces expected outputs.\n\n    Args:\n      expected_shapes: A dict mapping Tensor or Tensor name to expected output\n        shape.\n      feed_dict: Values of Tensors to feed into Session.run().\n    \"\"\"", "\n", "fetches", "=", "expected_shapes", ".", "keys", "(", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "outputs", "=", "sess", ".", "run", "(", "fetches", ",", "feed_dict", ")", "\n", "\n", "", "for", "index", ",", "output", "in", "enumerate", "(", "outputs", ")", ":", "\n", "      ", "tensor", "=", "fetches", "[", "index", "]", "\n", "expected", "=", "expected_shapes", "[", "tensor", "]", "\n", "actual", "=", "output", ".", "shape", "\n", "if", "expected", "!=", "actual", ":", "\n", "        ", "self", ".", "fail", "(", "\"Tensor %s has shape %s (expected %s).\"", "%", "\n", "(", "tensor", ",", "actual", ",", "expected", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest.testBuildForTraining": [[112, 139], ["show_and_tell_model_test.ShowAndTellModel", "ShowAndTellModel.build", "show_and_tell_model_test.ShowAndTellModelTest._checkModelParameters", "show_and_tell_model_test.ShowAndTellModelTest._checkOutputs"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkModelParameters", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkOutputs"], ["", "", "", "def", "testBuildForTraining", "(", "self", ")", ":", "\n", "    ", "model", "=", "ShowAndTellModel", "(", "self", ".", "_model_config", ",", "mode", "=", "\"train\"", ")", "\n", "model", ".", "build", "(", ")", "\n", "\n", "self", ".", "_checkModelParameters", "(", ")", "\n", "\n", "expected_shapes", "=", "{", "\n", "# [batch_size, image_height, image_width, 3]", "\n", "model", ".", "images", ":", "(", "32", ",", "299", ",", "299", ",", "3", ")", ",", "\n", "# [batch_size, sequence_length]", "\n", "model", ".", "input_seqs", ":", "(", "32", ",", "15", ")", ",", "\n", "# [batch_size, sequence_length]", "\n", "model", ".", "target_seqs", ":", "(", "32", ",", "15", ")", ",", "\n", "# [batch_size, sequence_length]", "\n", "model", ".", "input_mask", ":", "(", "32", ",", "15", ")", ",", "\n", "# [batch_size, embedding_size]", "\n", "model", ".", "image_embeddings", ":", "(", "32", ",", "512", ")", ",", "\n", "# [batch_size, sequence_length, embedding_size]", "\n", "model", ".", "seq_embeddings", ":", "(", "32", ",", "15", ",", "512", ")", ",", "\n", "# Scalar", "\n", "model", ".", "total_loss", ":", "(", ")", ",", "\n", "# [batch_size * sequence_length]", "\n", "model", ".", "target_cross_entropy_losses", ":", "(", "480", ",", ")", ",", "\n", "# [batch_size * sequence_length]", "\n", "model", ".", "target_cross_entropy_loss_weights", ":", "(", "480", ",", ")", ",", "\n", "}", "\n", "self", ".", "_checkOutputs", "(", "expected_shapes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest.testBuildForEval": [[140, 167], ["show_and_tell_model_test.ShowAndTellModel", "ShowAndTellModel.build", "show_and_tell_model_test.ShowAndTellModelTest._checkModelParameters", "show_and_tell_model_test.ShowAndTellModelTest._checkOutputs"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkModelParameters", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkOutputs"], ["", "def", "testBuildForEval", "(", "self", ")", ":", "\n", "    ", "model", "=", "ShowAndTellModel", "(", "self", ".", "_model_config", ",", "mode", "=", "\"eval\"", ")", "\n", "model", ".", "build", "(", ")", "\n", "\n", "self", ".", "_checkModelParameters", "(", ")", "\n", "\n", "expected_shapes", "=", "{", "\n", "# [batch_size, image_height, image_width, 3]", "\n", "model", ".", "images", ":", "(", "32", ",", "299", ",", "299", ",", "3", ")", ",", "\n", "# [batch_size, sequence_length]", "\n", "model", ".", "input_seqs", ":", "(", "32", ",", "15", ")", ",", "\n", "# [batch_size, sequence_length]", "\n", "model", ".", "target_seqs", ":", "(", "32", ",", "15", ")", ",", "\n", "# [batch_size, sequence_length]", "\n", "model", ".", "input_mask", ":", "(", "32", ",", "15", ")", ",", "\n", "# [batch_size, embedding_size]", "\n", "model", ".", "image_embeddings", ":", "(", "32", ",", "512", ")", ",", "\n", "# [batch_size, sequence_length, embedding_size]", "\n", "model", ".", "seq_embeddings", ":", "(", "32", ",", "15", ",", "512", ")", ",", "\n", "# Scalar", "\n", "model", ".", "total_loss", ":", "(", ")", ",", "\n", "# [batch_size * sequence_length]", "\n", "model", ".", "target_cross_entropy_losses", ":", "(", "480", ",", ")", ",", "\n", "# [batch_size * sequence_length]", "\n", "model", ".", "target_cross_entropy_loss_weights", ":", "(", "480", ",", ")", ",", "\n", "}", "\n", "self", ".", "_checkOutputs", "(", "expected_shapes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest.testBuildForInference": [[168, 197], ["show_and_tell_model_test.ShowAndTellModel", "ShowAndTellModel.build", "show_and_tell_model_test.ShowAndTellModelTest._checkModelParameters", "numpy.random.rand", "show_and_tell_model_test.ShowAndTellModelTest._checkOutputs", "numpy.random.randint", "numpy.random.rand", "show_and_tell_model_test.ShowAndTellModelTest._checkOutputs"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkModelParameters", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkOutputs", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model_test.ShowAndTellModelTest._checkOutputs"], ["", "def", "testBuildForInference", "(", "self", ")", ":", "\n", "    ", "model", "=", "ShowAndTellModel", "(", "self", ".", "_model_config", ",", "mode", "=", "\"inference\"", ")", "\n", "model", ".", "build", "(", ")", "\n", "\n", "self", ".", "_checkModelParameters", "(", ")", "\n", "\n", "# Test feeding an image to get the initial LSTM state.", "\n", "images_feed", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "299", ",", "299", ",", "3", ")", "\n", "feed_dict", "=", "{", "model", ".", "images", ":", "images_feed", "}", "\n", "expected_shapes", "=", "{", "\n", "# [batch_size, embedding_size]", "\n", "model", ".", "image_embeddings", ":", "(", "1", ",", "512", ")", ",", "\n", "# [batch_size, 2 * num_lstm_units]", "\n", "\"lstm/initial_state:0\"", ":", "(", "1", ",", "1024", ")", ",", "\n", "}", "\n", "self", ".", "_checkOutputs", "(", "expected_shapes", ",", "feed_dict", ")", "\n", "\n", "# Test feeding a batch of inputs and LSTM states to get softmax output and", "\n", "# LSTM states.", "\n", "input_feed", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "10", ",", "size", "=", "3", ")", "\n", "state_feed", "=", "np", ".", "random", ".", "rand", "(", "3", ",", "1024", ")", "\n", "feed_dict", "=", "{", "\"input_feed:0\"", ":", "input_feed", ",", "\"lstm/state_feed:0\"", ":", "state_feed", "}", "\n", "expected_shapes", "=", "{", "\n", "# [batch_size, 2 * num_lstm_units]", "\n", "\"lstm/state:0\"", ":", "(", "3", ",", "1024", ")", ",", "\n", "# [batch_size, vocab_size]", "\n", "\"softmax:0\"", ":", "(", "3", ",", "12000", ")", ",", "\n", "}", "\n", "self", ".", "_checkOutputs", "(", "expected_shapes", ",", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.run_inference.main": [[46, 107], ["tensorflow.Graph", "tf.Graph.finalize", "im2txt.inference_utils.vocabulary.Vocabulary", "FLAGS.input_files.split", "tensorflow.logging.info", "tf.Graph.as_default", "im2txt.inference_wrapper.InferenceWrapper", "inference_wrapper.InferenceWrapper.build_graph_from_config", "tensorflow.placeholder", "inference_wrapper.InferenceWrapper.model.process_image", "filenames.extend", "len", "tensorflow.Session", "model.build_graph_from_config.", "im2txt.inference_utils.caption_generator.CaptionGenerator", "im2txt.configuration.ModelConfig", "tensorflow.gfile.Glob", "os.path.splitext", "caption_generator.CaptionGenerator.beam_search", "print", "enumerate", "new_sentence.split.split", "print", "print", "print", "numpy.squeeze", "print", "print", "print", "inference_wrapper.InferenceWrapper.new_caption_prob", "numpy.load", "tensorflow.gfile.GFile", "f.read", "sess.run", "print", "os.path.basename", "vocabulary.Vocabulary.id_to_word", "inference_wrapper.InferenceWrapper.new_caption_prob", "vocabulary.Vocabulary.word_to_id", "math.exp"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_config", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.new_caption_prob", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.new_caption_prob", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id"], ["def", "main", "(", "_", ")", ":", "\n", "# Build the inference graph.", "\n", "  ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "    ", "model", "=", "inference_wrapper", ".", "InferenceWrapper", "(", ")", "\n", "restore_fn", "=", "model", ".", "build_graph_from_config", "(", "configuration", ".", "ModelConfig", "(", ")", ",", "\n", "FLAGS", ".", "checkpoint_path", ")", "\n", "# preprocessing compute graph", "\n", "image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "preprocessor", "=", "model", ".", "model", ".", "process_image", "(", "image_placeholder", ")", "\n", "\n", "", "g", ".", "finalize", "(", ")", "\n", "\n", "# Create the vocabulary.", "\n", "vocab", "=", "vocabulary", ".", "Vocabulary", "(", "FLAGS", ".", "vocab_file", ")", "\n", "\n", "filenames", "=", "[", "]", "\n", "for", "file_pattern", "in", "FLAGS", ".", "input_files", ".", "split", "(", "\",\"", ")", ":", "\n", "    ", "filenames", ".", "extend", "(", "tf", ".", "gfile", ".", "Glob", "(", "file_pattern", ")", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Running caption generation on %d files matching %s\"", ",", "\n", "len", "(", "filenames", ")", ",", "FLAGS", ".", "input_files", ")", "\n", "\n", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "g", ")", "as", "sess", ":", "\n", "# Load the model from checkpoint.", "\n", "    ", "restore_fn", "(", "sess", ")", "\n", "\n", "\n", "# Prepare the caption generator. Here we are implicitly using the default", "\n", "# beam search parameters. See caption_generator.py for a description of the", "\n", "# available beam search parameters.", "\n", "generator", "=", "caption_generator", ".", "CaptionGenerator", "(", "model", ",", "vocab", ")", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "      ", "_", ",", "file_extension", "=", "os", ".", "path", ".", "splitext", "(", "filename", ")", "\n", "if", "file_extension", "==", "\".npy\"", ":", "\n", "# load numpy array", "\n", "        ", "image", "=", "np", ".", "squeeze", "(", "np", ".", "load", "(", "filename", ")", ")", "\n", "", "else", ":", "\n", "        ", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "          ", "image", "=", "f", ".", "read", "(", ")", "\n", "image", "=", "sess", ".", "run", "(", "preprocessor", ",", "{", "image_placeholder", ":", "image", "}", ")", "\n", "print", "(", "'raw image shape is'", ",", "image", ".", "shape", ")", "\n", "\n", "", "", "captions", "=", "generator", ".", "beam_search", "(", "sess", ",", "image", ")", "\n", "print", "(", "\"Captions for image %s:\"", "%", "os", ".", "path", ".", "basename", "(", "filename", ")", ")", "\n", "for", "i", ",", "caption", "in", "enumerate", "(", "captions", ")", ":", "\n", "# Ignore begin and end words.", "\n", "        ", "sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "sentence", "=", "\" \"", ".", "join", "(", "sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "i", ",", "sentence", ",", "math", ".", "exp", "(", "caption", ".", "logprob", ")", ")", ")", "\n", "print", "(", "caption", ".", "sentence", ")", "\n", "# print(generator.new_caption_prob(sess, caption.sentence, image))", "\n", "print", "(", "model", ".", "new_caption_prob", "(", "sess", ",", "caption", ".", "sentence", ",", "image", ")", ")", "\n", "\n", "", "new_sentence", "=", "\"kite\"", "\n", "new_sentence", "=", "new_sentence", ".", "split", "(", ")", "\n", "print", "(", "\"My new sentence:\"", ",", "new_sentence", ")", "\n", "new_caption", "=", "[", "vocab", ".", "start_id", "]", "+", "[", "vocab", ".", "word_to_id", "(", "w", ")", "for", "w", "in", "new_sentence", "]", "+", "[", "vocab", ".", "end_id", "]", "\n", "print", "(", "\"My new id:\"", ",", "new_caption", ")", "\n", "print", "(", "model", ".", "new_caption_prob", "(", "sess", ",", "new_caption", ",", "image", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.run_attack.show": [[47, 57], ["numpy.save", "numpy.around", "fig.astype().squeeze.astype().squeeze", "PIL.Image.fromarray", "Image.fromarray.save", "fig.astype().squeeze.astype"], "function", ["None"], ["def", "show", "(", "img", ",", "name", "=", "\"output.png\"", ")", ":", "\n", "    ", "\"\"\"\n    Show MNSIT digits in the console.\n    \"\"\"", "\n", "np", ".", "save", "(", "name", ",", "img", ")", "\n", "fig", "=", "np", ".", "around", "(", "(", "img", "+", "1.0", ")", "/", "2.0", "*", "255", ")", "\n", "fig", "=", "fig", ".", "astype", "(", "np", ".", "uint8", ")", ".", "squeeze", "(", ")", "\n", "pic", "=", "Image", ".", "fromarray", "(", "fig", ")", "\n", "# pic.resize((512,512), resample=PIL.Image.BICUBIC)", "\n", "pic", ".", "save", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.run_attack.main": [[58, 169], ["tensorflow.set_random_seed", "tensorflow.GPUOptions", "tensorflow.ConfigProto", "im2txt.inference_utils.vocabulary.Vocabulary", "tensorflow.Graph", "tf.Graph.finalize", "tensorflow.Session", "inf_model.build_graph_from_config.", "tensorflow.Graph", "FLAGS.input_files.split", "tensorflow.logging.info", "tf.Graph.as_default", "im2txt.inference_wrapper.InferenceWrapper", "inference_wrapper.InferenceWrapper.build_graph_from_config", "tf.Graph.as_default", "im2txt.attack_wrapper.AttackWrapper", "tensorflow.Session", "l2_attack.CarliniL2", "tensorflow.placeholder", "attack_wrapper.AttackWrapper.model.process_image", "filenames.extend", "len", "tf.Session.run", "print", "new_sentence.split.split", "print", "len", "print", "numpy.append", "FLAGS.input_feed.split", "print", "numpy.append", "numpy.max", "print", "print", "run_attack.show", "run_attack.show", "run_attack.show", "tf.Session.close", "im2txt.configuration.ModelConfig", "tensorflow.gfile.Glob", "tensorflow.gfile.GFile", "f.read", "numpy.ones", "numpy.zeros", "vocabulary.Vocabulary.word_to_id", "numpy.ones", "numpy.zeros", "l2_attack.CarliniL2.attack", "l2_attack.CarliniL2.attack", "numpy.sum", "numpy.abs", "len", "numpy.array", "numpy.array", "vocabulary.Vocabulary.word_to_id", "len", "len"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_config", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "'''\n  # Build the inference graph.\n  g = tf.Graph()\n  with g.as_default():\n    \n    model = attack_wrapper.AttackWrapper()\n    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n                                               FLAGS.checkpoint_path)\n  # g.finalize()\n\n  # Create the vocabulary.\n  '''", "\n", "\n", "tf", ".", "set_random_seed", "(", "1234", ")", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "0.4", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", "\n", "vocab", "=", "vocabulary", ".", "Vocabulary", "(", "FLAGS", ".", "vocab_file", ")", "\n", "\n", "# TODO: build the inference graph", "\n", "inference_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "inference_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "inf_model", "=", "inference_wrapper", ".", "InferenceWrapper", "(", ")", "\n", "inf_restore_fn", "=", "inf_model", ".", "build_graph_from_config", "(", "configuration", ".", "ModelConfig", "(", ")", ",", "FLAGS", ".", "checkpoint_path", ")", "\n", "# inf_image_placeholder = tf.placeholder(dtype=tf.string, shape=[], name=\"inf_image_placeholder\")", "\n", "# inf_preprocessor = inf_model.model.process_image(inf_image_placeholder)", "\n", "", "inference_graph", ".", "finalize", "(", ")", "\n", "inf_sess", "=", "tf", ".", "Session", "(", "graph", "=", "inference_graph", ",", "config", "=", "config", ")", "\n", "# Load the model from checkpoint.", "\n", "inf_restore_fn", "(", "inf_sess", ")", "\n", "\n", "\n", "attack_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "attack_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "model", "=", "attack_wrapper", ".", "AttackWrapper", "(", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "# build the attacker graph", "\n", "attack", "=", "CarliniL2", "(", "sess", ",", "inf_sess", ",", "attack_graph", ",", "inference_graph", ",", "model", ",", "inf_model", ",", "targeted", "=", "FLAGS", ".", "targeted", ",", "use_keywords", "=", "FLAGS", ".", "use_keywords", ",", "use_logits", "=", "FLAGS", ".", "use_logits", ",", "batch_size", "=", "1", ",", "initial_const", "=", "1.0", ",", "max_iterations", "=", "1000", ",", "print_every", "=", "1", ",", "confidence", "=", "2", ",", "use_log", "=", "False", ",", "norm", "=", "FLAGS", ".", "norm", ",", "abort_early", "=", "False", ",", "learning_rate", "=", "0.005", ")", "\n", "# compute graph for preprocessing", "\n", "image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "preprocessor", "=", "model", ".", "model", ".", "process_image", "(", "image_placeholder", ")", "\n", "\n", "", "filenames", "=", "[", "]", "\n", "for", "file_pattern", "in", "FLAGS", ".", "input_files", ".", "split", "(", "\",\"", ")", ":", "\n", "    ", "filenames", ".", "extend", "(", "tf", ".", "gfile", ".", "Glob", "(", "file_pattern", ")", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Running caption generation on %d files matching %s\"", ",", "\n", "len", "(", "filenames", ")", ",", "FLAGS", ".", "input_files", ")", "\n", "\n", "for", "filename", "in", "filenames", ":", "\n", "\n", "    ", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "image", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "raw_image", "=", "sess", ".", "run", "(", "preprocessor", ",", "feed_dict", "=", "{", "image_placeholder", ":", "image", "}", ")", "\n", "\n", "print", "(", "'raw image size:'", ",", "raw_image", ".", "shape", ")", "\n", "\n", "'''\n    new_sentence = \"kite\"\n    new_sentence = \"a man on a surfboard riding a wave .\"\n    new_sentence = \"a dog riding a bike on a road .\"\n    new_sentence = \"a group of giraffe standing next to each other .\" # success, p=0.016556\n    new_sentence = \"a person skiing down a snow covered slope .\" # success, p=0.021917\n    new_sentence = \"a person on a beach flying a kite .\" # success, p=0.019417\n    new_sentence = \"a black and white photo of a train on a track .\" # success, p=0.006146\n    new_sentence = \"a bowl of pasta with meat and vegetables .\"\n    new_sentence = \"a man and girl carrying kites down a sidewalk in front of a metro bus .\" # end up with \"a group of people standing on top of a sandy beach .\" same as a sentence in training set\n    new_sentence = \"a man and girl carrying surfboards down a sidewalk in front of a metro bus .\"# same as in training set\n    '''", "\n", "\n", "new_sentence", "=", "FLAGS", ".", "input_feed", "\n", "new_sentence", "=", "new_sentence", ".", "split", "(", ")", "\n", "print", "(", "\"My new sentence:\"", ",", "new_sentence", ")", "\n", "max_caption_length", "=", "20", "\n", "new_caption", "=", "[", "vocab", ".", "start_id", "]", "+", "[", "vocab", ".", "word_to_id", "(", "w", ")", "for", "w", "in", "new_sentence", "]", "+", "[", "vocab", ".", "end_id", "]", "\n", "true_cap_len", "=", "len", "(", "new_caption", ")", "\n", "new_caption", "=", "new_caption", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "true_cap_len", ")", "\n", "\n", "print", "(", "\"My new id:\"", ",", "new_caption", ")", "\n", "new_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "true_cap_len", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "true_cap_len", ")", ")", "\n", "# print(\"Probability by attack_step:\", model.attack_step(sess, new_caption, new_mask, raw_image))", "\n", "\n", "# adv = attack.attack(np.array([raw_image]), new_caption, [new_mask])", "\n", "# key_words = [vocab.word_to_id(\"surfboard\"),vocab.word_to_id(\"riding\"),vocab.word_to_id(\"man\"),vocab.word_to_id(\"wave\"),vocab.word_to_id(\"dog\"),vocab.word_to_id(\"water\"),vocab.word_to_id(\"woman\"),vocab.word_to_id(\"surfer\"),vocab.word_to_id(\"ocean\"),vocab.word_to_id(\"frisbee\")]", "\n", "# key_words = [vocab.word_to_id(\"surfboard\"), vocab.word_to_id(\"man\"), vocab.word_to_id(\"wave\"), vocab.word_to_id(\"riding\"), vocab.word_to_id(\"water\")]", "\n", "# key_words = [vocab.word_to_id(\"giraffe\"), vocab.word_to_id(\"standing\"), vocab.word_to_id(\"photo\")]", "\n", "# key_words = [vocab.word_to_id(\"photo\"), vocab.word_to_id(\"train\"), vocab.word_to_id(\"track\")]", "\n", "# words = [\"train\", \"photo\", \"track\"]", "\n", "words", "=", "[", "\"riding\"", ",", "\"train\"", ",", "\"long\"", "]", "\n", "words", "=", "FLAGS", ".", "input_feed", ".", "split", "(", ")", "\n", "key_words", "=", "[", "vocab", ".", "word_to_id", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "print", "(", "key_words", ")", "\n", "# key_words = [vocab.word_to_id(\"bird\"), vocab.word_to_id(\"flying\")]", "\n", "key_words_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "len", "(", "key_words", ")", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "len", "(", "key_words", ")", ")", ")", "\n", "key_words", "=", "key_words", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "len", "(", "key_words", ")", ")", "\n", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "# keywords based attack", "\n", "      ", "adv", "=", "attack", ".", "attack", "(", "np", ".", "array", "(", "[", "raw_image", "]", ")", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "key_words", ",", "key_words_mask", ",", "1", ")", "\n", "", "else", ":", "\n", "# exact attack", "\n", "      ", "adv", "=", "attack", ".", "attack", "(", "np", ".", "array", "(", "[", "raw_image", "]", ")", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "new_caption", ",", "new_mask", ",", "1", ")", "\n", "\n", "", "l2_distortion", "=", "np", ".", "sum", "(", "(", "adv", "-", "raw_image", ")", "**", "2", ")", "**", ".5", "\n", "linf_distortion", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "adv", "-", "raw_image", ")", ")", "\n", "print", "(", "\"L2 distortion is\"", ",", "l2_distortion", ")", "\n", "print", "(", "\"L_inf distortion is\"", ",", "linf_distortion", ")", "\n", "show", "(", "raw_image", ",", "\"original.png\"", ")", "\n", "show", "(", "adv", ",", "\"adversarial.png\"", ")", "\n", "show", "(", "adv", "-", "raw_image", ",", "\"diff.png\"", ")", "\n", "inf_sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.train.main": [[44, 111], ["im2txt.configuration.ModelConfig", "im2txt.configuration.TrainingConfig", "tensorflow.Graph", "tensorflow.contrib.slim.learning.train", "tensorflow.gfile.IsDirectory", "tensorflow.logging.info", "tensorflow.gfile.MakeDirs", "tf.Graph.as_default", "im2txt.show_and_tell_model.ShowAndTellModel", "show_and_tell_model.ShowAndTellModel.build", "tensorflow.contrib.layers.optimize_loss", "tensorflow.train.Saver", "tensorflow.constant", "tensorflow.constant", "int", "tensorflow.train.exponential_decay"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build"], ["def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "assert", "FLAGS", ".", "input_file_pattern", ",", "\"--input_file_pattern is required\"", "\n", "assert", "FLAGS", ".", "train_dir", ",", "\"--train_dir is required\"", "\n", "\n", "model_config", "=", "configuration", ".", "ModelConfig", "(", ")", "\n", "model_config", ".", "input_file_pattern", "=", "FLAGS", ".", "input_file_pattern", "\n", "model_config", ".", "inception_checkpoint_file", "=", "FLAGS", ".", "inception_checkpoint_file", "\n", "training_config", "=", "configuration", ".", "TrainingConfig", "(", ")", "\n", "\n", "# Create training directory.", "\n", "train_dir", "=", "FLAGS", ".", "train_dir", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "train_dir", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Creating training directory: %s\"", ",", "train_dir", ")", "\n", "tf", ".", "gfile", ".", "MakeDirs", "(", "train_dir", ")", "\n", "\n", "# Build the TensorFlow graph.", "\n", "", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "# Build the model.", "\n", "    ", "model", "=", "show_and_tell_model", ".", "ShowAndTellModel", "(", "\n", "model_config", ",", "mode", "=", "\"train\"", ",", "train_inception", "=", "FLAGS", ".", "train_inception", ")", "\n", "model", ".", "build", "(", ")", "\n", "\n", "# Set up the learning rate.", "\n", "learning_rate_decay_fn", "=", "None", "\n", "if", "FLAGS", ".", "train_inception", ":", "\n", "      ", "learning_rate", "=", "tf", ".", "constant", "(", "training_config", ".", "train_inception_learning_rate", ")", "\n", "", "else", ":", "\n", "      ", "learning_rate", "=", "tf", ".", "constant", "(", "training_config", ".", "initial_learning_rate", ")", "\n", "if", "training_config", ".", "learning_rate_decay_factor", ">", "0", ":", "\n", "        ", "num_batches_per_epoch", "=", "(", "training_config", ".", "num_examples_per_epoch", "/", "\n", "model_config", ".", "batch_size", ")", "\n", "decay_steps", "=", "int", "(", "num_batches_per_epoch", "*", "\n", "training_config", ".", "num_epochs_per_decay", ")", "\n", "\n", "def", "_learning_rate_decay_fn", "(", "learning_rate", ",", "global_step", ")", ":", "\n", "          ", "return", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "learning_rate", ",", "\n", "global_step", ",", "\n", "decay_steps", "=", "decay_steps", ",", "\n", "decay_rate", "=", "training_config", ".", "learning_rate_decay_factor", ",", "\n", "staircase", "=", "True", ")", "\n", "\n", "", "learning_rate_decay_fn", "=", "_learning_rate_decay_fn", "\n", "\n", "# Set up the training ops.", "\n", "", "", "train_op", "=", "tf", ".", "contrib", ".", "layers", ".", "optimize_loss", "(", "\n", "loss", "=", "model", ".", "total_loss", ",", "\n", "global_step", "=", "model", ".", "global_step", ",", "\n", "learning_rate", "=", "learning_rate", ",", "\n", "optimizer", "=", "training_config", ".", "optimizer", ",", "\n", "clip_gradients", "=", "training_config", ".", "clip_gradients", ",", "\n", "learning_rate_decay_fn", "=", "learning_rate_decay_fn", ")", "\n", "\n", "# Set up the Saver for saving and restoring model checkpoints.", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "training_config", ".", "max_checkpoints_to_keep", ")", "\n", "\n", "# Run training.", "\n", "", "tf", ".", "contrib", ".", "slim", ".", "learning", ".", "train", "(", "\n", "train_op", ",", "\n", "train_dir", ",", "\n", "log_every_n_steps", "=", "FLAGS", ".", "log_every_n_steps", ",", "\n", "graph", "=", "g", ",", "\n", "global_step", "=", "model", ".", "global_step", ",", "\n", "number_of_steps", "=", "FLAGS", ".", "number_of_steps", ",", "\n", "init_fn", "=", "model", ".", "init_fn", ",", "\n", "saver", "=", "saver", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.run_attack_BATCH_search_C.show": [[77, 85], ["numpy.save", "numpy.around", "fig.astype().squeeze.astype().squeeze", "PIL.Image.fromarray", "Image.fromarray.save", "fig.astype().squeeze.astype"], "function", ["None"], ["def", "show", "(", "img", ",", "path", ",", "name", "=", "\"output.png\"", ")", ":", "\n", "\n", "    ", "np", ".", "save", "(", "path", "+", "name", ",", "img", ")", "\n", "fig", "=", "np", ".", "around", "(", "(", "img", "+", "1.0", ")", "/", "2.0", "*", "255", ")", "\n", "fig", "=", "fig", ".", "astype", "(", "np", ".", "uint8", ")", ".", "squeeze", "(", ")", "\n", "pic", "=", "Image", ".", "fromarray", "(", "fig", ")", "\n", "# pic.resize((512,512), resample=PIL.Image.BICUBIC)", "\n", "pic", ".", "save", "(", "path", "+", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.run_attack_BATCH_search_C.main": [[86, 453], ["tensorflow.set_random_seed", "random.seed", "numpy.random.seed", "print", "print", "print", "os.system", "open", "csv.writer", "csv.writer.writerow", "open.close", "open", "csv.writer", "csv.writer.writerow", "open.close", "tensorflow.GPUOptions", "tensorflow.ConfigProto", "im2txt.inference_utils.vocabulary.Vocabulary", "tensorflow.Graph", "tf.Graph.finalize", "tensorflow.Session", "inf_model.build_graph_from_config.", "im2txt.inference_utils.caption_generator.CaptionGenerator", "tensorflow.Graph", "filenames.sort", "random.shuffle", "range", "tf.Session.close", "tf.Session.close", "open", "json.load", "tuple", "tuple", "set", "tuple", "tuple", "tuple", "tuple", "os.path.join", "os.path.join", "tf.Graph.as_default", "im2txt.inference_wrapper.InferenceWrapper", "inference_wrapper.InferenceWrapper.build_graph_from_config", "tensorflow.placeholder", "inference_wrapper.InferenceWrapper.model.process_image", "tensorflow.Graph", "tf.Graph.finalize", "tensorflow.Session", "target_model.build_graph_from_config.", "im2txt.inference_utils.caption_generator.CaptionGenerator", "tf.Graph.as_default", "im2txt.attack_wrapper.AttackWrapper", "tensorflow.Session", "print", "l2_attack.CarliniL2", "tensorflow.placeholder", "attack_wrapper.AttackWrapper.model.process_image", "int", "next", "print", "print", "tf.Session.run", "run_attack_BATCH_search_C.show", "caption_generator.CaptionGenerator.beam_search", "print", "enumerate", "range", "print", "print", "print", "print", "any", "run_attack_BATCH_search_C.show", "run_attack_BATCH_search_C.show", "numpy.max", "print", "print", "numpy.squeeze", "caption_generator.CaptionGenerator.beam_search", "print", "enumerate", "open", "csv.writer", "open.close", "print", "tf.Session.close", "tuple", "tuple", "open", "noun_file.read().split", "open", "verb_file.read().split", "open", "adjective_file.read().split", "open", "adverb_file.read().split", "os.path.join", "im2txt.configuration.ModelConfig", "tf.Graph.as_default", "im2txt.inference_wrapper.InferenceWrapper", "inference_wrapper.InferenceWrapper.build_graph_from_config", "tensorflow.placeholder", "inference_wrapper.InferenceWrapper.model.process_image", "os.listdir", "re.match().group", "tensorflow.gfile.GFile", "f.read", "attack_filename.replace", "print", "print", "caption_generator.CaptionGenerator.beam_search", "enumerate", "list", "caption_generator.CaptionGenerator.beam_search", "print", "print", "print", "numpy.max", "print", "print", "run_attack_BATCH_search_C.save_fail_log", "numpy.sum", "numpy.abs", "attack_filename.replace", "numpy.load", "print", "tuple", "tuple", "csv.writer.writerow", "tuple", "tuple", "csv.writer.writerow", "im2txt.configuration.ModelConfig", "attack_filename.replace", "os.path.basename", "vocabulary.Vocabulary.id_to_word", "tensorflow.gfile.GFile", "f.read", "tf.Session.run", "print", "FLAGS.input_feed.split", "set", "set", "len", "print", "print", "numpy.random.choice", "print", "numpy.append", "l2_attack.CarliniL2.attack", "new_sentence.split.split", "print", "len", "print", "numpy.append", "l2_attack.CarliniL2.attack", "numpy.squeeze", "vocabulary.Vocabulary.id_to_word", "numpy.sum", "numpy.abs", "attack_filename.replace", "attack_filename.replace", "os.path.basename", "vocabulary.Vocabulary.id_to_word", "str", "tuple", "tuple", "str", "tuple", "tuple", "zip", "zip", "noun_file.read", "verb_file.read", "adjective_file.read", "adverb_file.read", "zip", "zip", "zip", "str", "str", "re.match", "math.exp", "os.path.basename", "vocabulary.Vocabulary.id_to_word", "target_sentences[].split", "raw_sentences[].split", "list", "list.sort", "list", "list.sort", "vocabulary.Vocabulary.word_to_id", "numpy.ones", "numpy.zeros", "numpy.array", "numpy.ones", "numpy.zeros", "numpy.array", "math.exp", "str", "math.exp", "math.exp", "len", "math.exp", "ValueError", "any", "any", "math.exp", "zip", "zip", "zip", "zip", "len", "math.exp", "len", "len", "vocabulary.Vocabulary.word_to_id", "set", "set", "bool", "zip", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "str", "range", "adv_sentence.split", "set", "set", "len", "success[].index", "len", "success[].index", "adv_sentence.split"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_config", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_config", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.run_attack_BATCH_search_C.save_fail_log", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id"], ["", "def", "main", "(", "_", ")", ":", "\n", "\n", "  ", "tf", ".", "set_random_seed", "(", "FLAGS", ".", "seed", ")", "\n", "random", ".", "seed", "(", "FLAGS", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "FLAGS", ".", "seed", ")", "\n", "beam_size", "=", "FLAGS", ".", "beam_size", "\n", "record_path", "=", "FLAGS", ".", "result_directory", "\n", "\n", "# we should use os.path.join!", "\n", "if", "record_path", "[", "-", "1", "]", "!=", "\"/\"", ":", "\n", "      ", "record_path", "+=", "\"/\"", "\n", "\n", "", "with", "open", "(", "FLAGS", ".", "caption_file", ")", "as", "data_file", ":", "\n", "    ", "caption_file", "=", "json", ".", "load", "(", "data_file", ")", "\n", "", "caption_info", "=", "caption_file", "[", "'annotations'", "]", "\n", "\n", "print", "(", "\"using \"", "+", "FLAGS", ".", "norm", "+", "\" for attack\"", ")", "\n", "print", "(", "\"targeted?\"", ",", "FLAGS", ".", "targeted", ")", "\n", "print", "(", "\"attack confidence kappa\"", ",", "FLAGS", ".", "confidence", ")", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "    ", "keywords_num", "=", "FLAGS", ".", "keywords_num", "\n", "header", "=", "(", "\"target filename\"", ",", "\"attack filename\"", ",", "\"L2 distortion\"", ",", "\"L_inf distortion\"", ",", "\"loss\"", ",", "\"loss1\"", ",", "\"loss2\"", ",", "\"optimal C\"", ",", "\"attack successful?\"", ",", "\"target_sentence\"", ")", "\n", "header", "+=", "tuple", "(", "[", "\"keywords\"", "]", "*", "keywords_num", ")", "+", "tuple", "(", "[", "\"human caption\"", "]", ")", "\n", "header", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "[", "\"caption before attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ",", "[", "\"prob of caption before attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ")", "for", "val", "in", "pair", "]", ")", "\n", "header", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "[", "\"caption after attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ",", "[", "\"prob of caption after attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ")", "for", "val", "in", "pair", "]", ")", "\n", "with", "open", "(", "'wordPOS/noun.txt'", ")", "as", "noun_file", ":", "\n", "      ", "noun", "=", "noun_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "", "with", "open", "(", "'wordPOS/verb.txt'", ")", "as", "verb_file", ":", "\n", "      ", "verb", "=", "verb_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "", "with", "open", "(", "'wordPOS/adjective.txt'", ")", "as", "adjective_file", ":", "\n", "      ", "adjective", "=", "adjective_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "", "with", "open", "(", "'wordPOS/adverb.txt'", ")", "as", "adverb_file", ":", "\n", "      ", "adverb", "=", "adverb_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "# good words are noun, verb, adj or adv. We do not want words like \"a\" or \"the\" to be our keywords.", "\n", "# Those .txt files are generated by classifying the vocabulary list. ", "\n", "", "good_words", "=", "set", "(", "noun", "+", "verb", "+", "adjective", "+", "adverb", ")", "\n", "", "else", ":", "\n", "    ", "header", "=", "(", "\"target filename\"", ",", "\"attack filename\"", ",", "\"L2 distortion\"", ",", "\"L_inf distortion\"", ",", "\"loss\"", ",", "\"loss1\"", ",", "\"loss2\"", ",", "\"optimal C\"", ",", "\"attack successful?\"", ")", "\n", "header", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "[", "\"target caption \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ",", "[", "\"prob of target caption \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ")", "for", "val", "in", "pair", "]", ")", "\n", "header", "+=", "tuple", "(", "[", "\"human caption\"", "]", ")", "\n", "header", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "[", "\"caption before attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ",", "[", "\"prob of caption before attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ")", "for", "val", "in", "pair", "]", ")", "\n", "header", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "[", "\"caption after attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ",", "[", "\"prob of caption after attack \"", "+", "str", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "beam_size", ")", "]", ")", "for", "val", "in", "pair", "]", ")", "\n", "\n", "", "os", ".", "system", "(", "\"mkdir -p {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "record_path", ",", "\"fail_log\"", ")", ")", ")", "\n", "record", "=", "open", "(", "os", ".", "path", ".", "join", "(", "record_path", ",", "\"record_\"", "+", "str", "(", "FLAGS", ".", "offset", ")", "+", "\".csv\"", ")", ",", "\"a+\"", ")", "\n", "writer", "=", "csv", ".", "writer", "(", "record", ")", "\n", "writer", ".", "writerow", "(", "header", ")", "\n", "record", ".", "close", "(", ")", "\n", "\n", "fail_log", "=", "open", "(", "os", ".", "path", ".", "join", "(", "record_path", ",", "\"fail_log/fail_record_\"", "+", "str", "(", "FLAGS", ".", "offset", ")", "+", "\".csv\"", ")", ",", "\"a+\"", ")", "\n", "fail_log_writer", "=", "csv", ".", "writer", "(", "fail_log", ")", "\n", "fail_log_writer", ".", "writerow", "(", "header", ")", "\n", "fail_log", ".", "close", "(", ")", "\n", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "0.4", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", "\n", "vocab", "=", "vocabulary", ".", "Vocabulary", "(", "FLAGS", ".", "vocab_file", ")", "\n", "\n", "\n", "inference_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "inference_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "inf_model", "=", "inference_wrapper", ".", "InferenceWrapper", "(", ")", "\n", "inf_restore_fn", "=", "inf_model", ".", "build_graph_from_config", "(", "configuration", ".", "ModelConfig", "(", ")", ",", "FLAGS", ".", "checkpoint_path", ")", "\n", "inf_image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "inf_preprocessor", "=", "inf_model", ".", "model", ".", "process_image", "(", "inf_image_placeholder", ")", "\n", "", "inference_graph", ".", "finalize", "(", ")", "\n", "inf_sess", "=", "tf", ".", "Session", "(", "graph", "=", "inference_graph", ",", "config", "=", "config", ")", "\n", "# Load the model from checkpoint.", "\n", "inf_restore_fn", "(", "inf_sess", ")", "\n", "inf_generator", "=", "caption_generator", ".", "CaptionGenerator", "(", "inf_model", ",", "vocab", ",", "beam_size", "=", "beam_size", ")", "\n", "\n", "if", "FLAGS", ".", "targeted", "or", "FLAGS", ".", "use_keywords", ":", "\n", "    ", "target_g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "target_g", ".", "as_default", "(", ")", ":", "\n", "      ", "target_model", "=", "inference_wrapper", ".", "InferenceWrapper", "(", ")", "\n", "target_restore_fn", "=", "target_model", ".", "build_graph_from_config", "(", "configuration", ".", "ModelConfig", "(", ")", ",", "FLAGS", ".", "checkpoint_path", ")", "\n", "target_image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "target_preprocessor", "=", "target_model", ".", "model", ".", "process_image", "(", "target_image_placeholder", ")", "\n", "", "target_g", ".", "finalize", "(", ")", "\n", "target_sess", "=", "tf", ".", "Session", "(", "graph", "=", "target_g", ",", "config", "=", "config", ")", "\n", "target_restore_fn", "(", "target_sess", ")", "\n", "target_generator", "=", "caption_generator", ".", "CaptionGenerator", "(", "target_model", ",", "vocab", ",", "beam_size", "=", "beam_size", ")", "\n", "\n", "\n", "", "attack_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "attack_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "model", "=", "attack_wrapper", ".", "AttackWrapper", "(", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "# build the attacker graph", "\n", "print", "(", "\"target:\"", ",", "FLAGS", ".", "targeted", ")", "\n", "attack", "=", "CarliniL2", "(", "sess", ",", "inf_sess", ",", "attack_graph", ",", "inference_graph", ",", "model", ",", "inf_model", ",", "targeted", "=", "FLAGS", ".", "targeted", ",", "use_keywords", "=", "FLAGS", ".", "use_keywords", ",", "use_logits", "=", "FLAGS", ".", "use_logits", ",", "batch_size", "=", "1", ",", "initial_const", "=", "FLAGS", ".", "C", ",", "max_iterations", "=", "FLAGS", ".", "iters", ",", "print_every", "=", "1", ",", "confidence", "=", "FLAGS", ".", "confidence", ",", "use_log", "=", "False", ",", "norm", "=", "FLAGS", ".", "norm", ",", "abort_early", "=", "False", ",", "learning_rate", "=", "0.005", ")", "\n", "# compute graph for preprocessing", "\n", "image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "preprocessor", "=", "model", ".", "model", ".", "process_image", "(", "image_placeholder", ")", "\n", "\n", "\n", "# get all the files in the directory", "\n", "", "image_directory", "=", "FLAGS", ".", "image_directory", "\n", "filenames", "=", "[", "file", "for", "file", "in", "os", ".", "listdir", "(", "image_directory", ")", "]", "\n", "filenames", ".", "sort", "(", ")", "\n", "random", ".", "shuffle", "(", "filenames", ")", "\n", "\n", "\n", "for", "j", "in", "range", "(", "FLAGS", ".", "exp_num", ")", ":", "\n", "\n", "\n", "    ", "attack_filename", "=", "filenames", "[", "len", "(", "filenames", ")", "-", "1", "-", "j", "-", "FLAGS", ".", "offset", "]", "\n", "attack_image_id", "=", "int", "(", "re", ".", "match", "(", "r\"^.*\\_(.*)\\..*$\"", ",", "attack_filename", ")", ".", "group", "(", "1", ")", ")", "\n", "human_cap", "=", "next", "(", "(", "item", "for", "item", "in", "caption_info", "if", "item", "[", "\"image_id\"", "]", "==", "attack_image_id", ")", ")", "\n", "human_cap", "=", "human_cap", "[", "'caption'", "]", "\n", "\n", "print", "(", "\"attack filename:\"", ",", "attack_filename", ")", "\n", "print", "(", "\"human's caption:\"", ",", "human_cap", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "image_directory", "+", "attack_filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "image", "=", "f", ".", "read", "(", ")", "\n", "", "raw_image", "=", "sess", ".", "run", "(", "preprocessor", ",", "feed_dict", "=", "{", "image_placeholder", ":", "image", "}", ")", "\n", "\n", "\n", "show", "(", "raw_image", ",", "record_path", ",", "\"original_\"", "+", "attack_filename", ".", "replace", "(", "\".jpg\"", ",", "\".png\"", ")", ")", "\n", "raw_filename", "=", "record_path", "+", "\"original_\"", "+", "attack_filename", ".", "replace", "(", "\".jpg\"", ",", "\".png.npy\"", ")", "\n", "# raw_image = np.squeeze(np.load(raw_filename))", "\n", "raw_captions", "=", "inf_generator", ".", "beam_search", "(", "inf_sess", ",", "raw_image", ")", "\n", "print", "(", "\"Captions for original image %s:\"", "%", "os", ".", "path", ".", "basename", "(", "raw_filename", ")", ")", "\n", "raw_sentences", "=", "[", "]", "\n", "raw_probs", "=", "[", "]", "\n", "for", "indx", ",", "raw_caption", "in", "enumerate", "(", "raw_captions", ")", ":", "\n", "      ", "raw_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "raw_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "raw_sentence", "=", "\" \"", ".", "join", "(", "raw_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "raw_sentence", ",", "math", ".", "exp", "(", "raw_caption", ".", "logprob", ")", ")", ")", "\n", "raw_sentences", "=", "raw_sentences", "+", "[", "raw_sentence", "]", "\n", "raw_probs", "=", "raw_probs", "+", "[", "math", ".", "exp", "(", "raw_caption", ".", "logprob", ")", "]", "\n", "\n", "", "if", "FLAGS", ".", "targeted", ":", "\n", "# If it's targeted attack, we pick another image as our target image to generate target caption for us.", "\n", "      ", "target_filename", "=", "filenames", "[", "j", "+", "FLAGS", ".", "offset", "]", "\n", "print", "(", "\"Captions for target image %s:\"", "%", "os", ".", "path", ".", "basename", "(", "target_filename", ")", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "image_directory", "+", "target_filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "target_image", "=", "f", ".", "read", "(", ")", "\n", "target_image", "=", "target_sess", ".", "run", "(", "target_preprocessor", ",", "{", "target_image_placeholder", ":", "target_image", "}", ")", "\n", "", "target_captions", "=", "target_generator", ".", "beam_search", "(", "target_sess", ",", "target_image", ")", "\n", "target_sentences", "=", "[", "]", "\n", "target_probs", "=", "[", "]", "\n", "for", "indx", ",", "target_caption", "in", "enumerate", "(", "target_captions", ")", ":", "\n", "        ", "target_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "target_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "target_sentence", "=", "\" \"", ".", "join", "(", "target_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "target_sentence", ",", "math", ".", "exp", "(", "target_caption", ".", "logprob", ")", ")", ")", "\n", "target_sentences", "=", "target_sentences", "+", "[", "target_sentence", "]", "\n", "target_probs", "=", "target_probs", "+", "[", "math", ".", "exp", "(", "target_caption", ".", "logprob", ")", "]", "\n", "", "", "else", ":", "\n", "# If it's untargeted, our target sentence is the attack image's own original caption.", "\n", "      ", "target_sentences", "=", "raw_sentences", "\n", "target_probs", "=", "raw_probs", "\n", "target_filename", "=", "attack_filename", "\n", "\n", "", "if", "FLAGS", ".", "use_keywords", ":", "\n", "      ", "if", "FLAGS", ".", "input_feed", ":", "\n", "# If there is an input feed, we use input feed as our keywords.", "\n", "        ", "words", "=", "FLAGS", ".", "input_feed", ".", "split", "(", ")", "\n", "", "else", ":", "\n", "# If there is no input feed, we use select keywords from the target caption. ", "\n", "        ", "target_sentences_words", "=", "set", "(", "target_sentences", "[", "0", "]", ".", "split", "(", ")", ")", "\n", "raw_sentences_words", "=", "set", "(", "raw_sentences", "[", "0", "]", ".", "split", "(", ")", ")", "\n", "if", "FLAGS", ".", "targeted", ":", "\n", "# If tagreted, we also need to exclude the words in the original caption.", "\n", "          ", "word_candidates", "=", "list", "(", "(", "target_sentences_words", "&", "good_words", ")", "-", "raw_sentences_words", ")", "\n", "word_candidates", ".", "sort", "(", ")", "\n", "", "else", ":", "\n", "          ", "word_candidates", "=", "list", "(", "(", "target_sentences_words", "&", "good_words", ")", ")", "\n", "word_candidates", ".", "sort", "(", ")", "\n", "", "", "if", "len", "(", "word_candidates", ")", "<", "keywords_num", ":", "\n", "        ", "print", "(", "\"words not enough for this attack!\"", ")", "\n", "print", "(", "\"****************************************** END OF THIS ATTACK ******************************************\"", ")", "\n", "continue", "\n", "# Randomly select keywords from all candidates.", "\n", "", "words", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "word_candidates", ",", "keywords_num", ",", "replace", "=", "False", ")", ")", "\n", "\n", "\n", "# run multiple attacks", "\n", "", "success", "=", "[", "]", "\n", "C_val", "=", "[", "FLAGS", ".", "C", "]", "\n", "best_adv", "=", "None", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "None", ",", "None", ",", "None", "\n", "l2_distortion_log", "=", "[", "]", "\n", "linf_distortion_log", "=", "[", "]", "\n", "best_l2_distortion", "=", "1e10", "\n", "best_linf_distortion", "=", "1e10", "\n", "adv_log", "=", "[", "]", "\n", "loss1_log", "=", "[", "]", "\n", "loss2_log", "=", "[", "]", "\n", "loss_log", "=", "[", "]", "\n", "\n", "\n", "for", "try_index", "in", "range", "(", "FLAGS", ".", "C_search_times", ")", ":", "\n", "\n", "      ", "attack_const", "=", "C_val", "[", "try_index", "]", "\n", "max_caption_length", "=", "20", "\n", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "# keywords based attack", "\n", "        ", "key_words", "=", "[", "vocab", ".", "word_to_id", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "print", "(", "\"My key words are: \"", ",", "words", ")", "\n", "key_words_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "len", "(", "key_words", ")", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "len", "(", "key_words", ")", ")", ")", "\n", "key_words", "=", "key_words", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "len", "(", "key_words", ")", ")", "\n", "adv", ",", "loss", ",", "loss1", ",", "loss2", ",", "_", "=", "attack", ".", "attack", "(", "np", ".", "array", "(", "[", "raw_image", "]", ")", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "key_words", ",", "key_words_mask", ",", "j", ",", "try_index", ",", "beam_size", ",", "FLAGS", ".", "infer_per_iter", ",", "attack_const", "=", "attack_const", ")", "\n", "", "else", ":", "\n", "# exact attack", "\n", "        ", "if", "FLAGS", ".", "targeted", ":", "\n", "          ", "if", "FLAGS", ".", "input_feed", ":", "\n", "            ", "new_sentence", "=", "FLAGS", ".", "input_feed", "\n", "", "else", ":", "\n", "            ", "new_sentence", "=", "target_sentences", "[", "0", "]", "\n", "", "", "else", ":", "\n", "          ", "new_sentence", "=", "raw_sentences", "[", "0", "]", "\n", "# new_sentence = \"a black and white photo of a train on a track .\"", "\n", "", "new_sentence", "=", "new_sentence", ".", "split", "(", ")", "\n", "print", "(", "\"My target sentence:\"", ",", "new_sentence", ")", "\n", "new_caption", "=", "[", "vocab", ".", "start_id", "]", "+", "[", "vocab", ".", "word_to_id", "(", "w", ")", "for", "w", "in", "new_sentence", "]", "+", "[", "vocab", ".", "end_id", "]", "\n", "true_cap_len", "=", "len", "(", "new_caption", ")", "\n", "new_caption", "=", "new_caption", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "true_cap_len", ")", "\n", "print", "(", "\"My target id:\"", ",", "new_caption", ")", "\n", "new_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "true_cap_len", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "true_cap_len", ")", ")", "\n", "adv", ",", "loss", ",", "loss1", ",", "loss2", ",", "_", "=", "attack", ".", "attack", "(", "np", ".", "array", "(", "[", "raw_image", "]", ")", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "new_caption", ",", "new_mask", ",", "j", ",", "try_index", ",", "1", ",", "attack_const", "=", "attack_const", ")", "\n", "# save information of this image to log array", "\n", "", "adv_log", "+=", "[", "adv", "]", "\n", "loss_log", "+=", "[", "loss", "]", "\n", "loss1_log", "+=", "[", "loss1", "]", "\n", "loss2_log", "+=", "[", "loss2", "]", "\n", "\n", "\n", "adv_captions", "=", "inf_generator", ".", "beam_search", "(", "inf_sess", ",", "np", ".", "squeeze", "(", "adv", ")", ")", "\n", "print", "(", "\"Captions after this attempt:\"", ")", "\n", "adv_caption", "=", "adv_captions", "[", "0", "]", "\n", "adv_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "adv_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "adv_sentence", "=", "\" \"", ".", "join", "(", "adv_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "adv_sentence", ",", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", ")", ")", "\n", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "        ", "if", "FLAGS", ".", "targeted", ":", "\n", "          ", "success", "+=", "[", "set", "(", "words", ")", "<", "set", "(", "adv_sentence", ".", "split", "(", ")", ")", "]", "\n", "", "else", ":", "\n", "          ", "success", "+=", "[", "not", "bool", "(", "set", "(", "words", ")", "&", "set", "(", "adv_sentence", ".", "split", "(", ")", ")", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "FLAGS", ".", "targeted", ":", "\n", "          ", "success", "+=", "[", "(", "adv_sentence", "==", "target_sentences", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "          ", "'''\n          raw_split = [item.split() for item in raw_sentences]\n          nltk_BLEU = nltk.translate.bleu_score.sentence_bleu(raw_split, adv_sentence.split())\n          print(\"BLEU by nltk is:\", nltk_BLEU)\n          success += [nltk_BLEU<0.5]\n          '''", "\n", "# For untargeted and caption based attack, there is no simple criterion to determine an attack is successful or not. We need to calculate the scores.", "\n", "# So here we always assumee the attack is fail, then we save fail log for score calculation.", "\n", "success", "+=", "[", "False", "]", "\n", "\n", "", "", "print", "(", "\"Attack with this C is successful?\"", ",", "success", "[", "try_index", "]", ")", "\n", "\n", "l2_distortion", "=", "np", ".", "sum", "(", "(", "adv", "-", "raw_image", ")", "**", "2", ")", "**", ".5", "\n", "linf_distortion", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "adv", "-", "raw_image", ")", ")", "\n", "l2_distortion_log", "+=", "[", "l2_distortion", "]", "\n", "linf_distortion_log", "+=", "[", "linf_distortion", "]", "\n", "print", "(", "\"L2 distortion is\"", ",", "l2_distortion", ")", "\n", "print", "(", "\"L_inf distortion is\"", ",", "linf_distortion", ")", "\n", "if", "success", "[", "try_index", "]", ":", "\n", "# Among the successful attacks, we select the one with minimum distortion as our final result.", "\n", "# Note this one may not correspond to minimum C.", "\n", "        ", "if", "FLAGS", ".", "norm", "==", "\"l2\"", ":", "\n", "          ", "if", "l2_distortion", "<", "best_l2_distortion", ":", "\n", "            ", "best_adv", "=", "adv", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "loss", ",", "loss1", ",", "loss2", "\n", "best_l2_distortion", "=", "l2_distortion", "\n", "best_linf_distortion", "=", "linf_distortion", "\n", "final_C", "=", "C_val", "[", "try_index", "]", "\n", "", "", "elif", "FLAGS", ".", "norm", "==", "\"inf\"", ":", "\n", "          ", "if", "linf_distortion", "<", "best_linf_distortion", ":", "\n", "            ", "best_adv", "=", "adv", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "loss", ",", "loss1", ",", "loss2", "\n", "best_l2_distortion", "=", "l2_distortion", "\n", "best_linf_distortion", "=", "linf_distortion", "\n", "final_C", "=", "C_val", "[", "try_index", "]", "\n", "", "", "else", ":", "\n", "          ", "raise", "ValueError", "(", "\"unsupported distance metric:\"", "+", "FLAGS", ".", "norm", ")", "\n", "", "", "if", "FLAGS", ".", "targeted", "or", "FLAGS", ".", "use_keywords", ":", "\n", "# We do binary search to find next C.", "\n", "        ", "if", "try_index", "+", "1", "<", "FLAGS", ".", "C_search_times", ":", "\n", "          ", "if", "success", "[", "try_index", "]", ":", "\n", "            ", "if", "any", "(", "not", "_", "for", "_", "in", "success", ")", ":", "\n", "              ", "last_false", "=", "len", "(", "success", ")", "-", "success", "[", ":", ":", "-", "1", "]", ".", "index", "(", "False", ")", "-", "1", "\n", "C_val", "+=", "[", "0.5", "*", "(", "C_val", "[", "try_index", "]", "+", "C_val", "[", "last_false", "]", ")", "]", "\n", "", "else", ":", "\n", "              ", "C_val", "+=", "[", "C_val", "[", "try_index", "]", "*", "0.5", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "any", "(", "_", "for", "_", "in", "success", ")", ":", "\n", "              ", "last_true", "=", "len", "(", "success", ")", "-", "success", "[", ":", ":", "-", "1", "]", ".", "index", "(", "True", ")", "-", "1", "\n", "C_val", "+=", "[", "0.5", "*", "(", "C_val", "[", "try_index", "]", "+", "C_val", "[", "last_true", "]", ")", "]", "\n", "", "else", ":", "\n", "              ", "C_val", "+=", "[", "C_val", "[", "try_index", "]", "*", "10.0", "]", "\n", "", "", "", "", "else", ":", "\n", "        ", "C_val", "+=", "[", "C_val", "[", "try_index", "]", "*", "10.0", "]", "\n", "\n", "", "", "print", "(", "\"results of each attempt:\"", ",", "success", ")", "\n", "print", "(", "\"C values of each attempt:\"", ",", "C_val", ")", "\n", "print", "(", "\"L2 distortion log is\"", ",", "l2_distortion_log", ")", "\n", "print", "(", "\"L_inf distortion log is\"", ",", "linf_distortion_log", ")", "\n", "final_success", "=", "any", "(", "_", "for", "_", "in", "success", ")", "\n", "\n", "if", "not", "final_success", ":", "\n", "      ", "final_C", "=", "C_val", "[", "-", "1", "]", "\n", "best_adv", "=", "adv", "\n", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "loss", ",", "loss1", ",", "loss2", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "        ", "target_info", "=", "{", "\"words\"", ":", "words", ",", "\"target_filename\"", ":", "target_filename", ",", "\"target_sentences\"", ":", "target_sentences", "}", "\n", "", "else", ":", "\n", "        ", "target_info", "=", "{", "'target_filename'", ":", "target_filename", ",", "\"target_sentences\"", ":", "target_sentences", ",", "\"target_probs\"", ":", "target_probs", "}", "\n", "", "save_fail_log", "(", "adv_log", ",", "loss_log", ",", "loss1_log", ",", "loss2_log", ",", "l2_distortion_log", ",", "linf_distortion_log", ",", "success", ",", "C_val", ",", "record_path", ",", "attack_filename", ",", "raw_image", ",", "human_cap", ",", "raw_sentences", ",", "raw_probs", ",", "inf_sess", ",", "inf_generator", ",", "vocab", ",", "target_info", ")", "\n", "\n", "\n", "", "show", "(", "best_adv", ",", "record_path", ",", "\"adversarial_\"", "+", "attack_filename", ".", "replace", "(", "\".jpg\"", ",", "\".png\"", ")", ")", "\n", "show", "(", "best_adv", "-", "raw_image", ",", "record_path", ",", "\"diff_\"", "+", "attack_filename", ".", "replace", "(", "\".jpg\"", ",", "\".png\"", ")", ")", "\n", "\n", "\n", "best_l2_distortion", "=", "np", ".", "sum", "(", "(", "best_adv", "-", "raw_image", ")", "**", "2", ")", "**", ".5", "\n", "best_linf_distortion", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "best_adv", "-", "raw_image", ")", ")", "\n", "print", "(", "\"best L2 distortion is\"", ",", "best_l2_distortion", ")", "\n", "print", "(", "\"best L_inf distortion is\"", ",", "best_linf_distortion", ")", "\n", "\n", "adv_filename", "=", "record_path", "+", "\"adversarial_\"", "+", "attack_filename", ".", "replace", "(", "\".jpg\"", ",", "\".png.npy\"", ")", "\n", "adv_image", "=", "np", ".", "squeeze", "(", "np", ".", "load", "(", "adv_filename", ")", ")", "\n", "adv_captions", "=", "inf_generator", ".", "beam_search", "(", "inf_sess", ",", "adv_image", ")", "\n", "print", "(", "\"Captions for adversarial image %s:\"", "%", "os", ".", "path", ".", "basename", "(", "adv_filename", ")", ")", "\n", "adv_sentences", "=", "[", "]", "\n", "adv_probs", "=", "[", "]", "\n", "for", "indx", ",", "adv_caption", "in", "enumerate", "(", "adv_captions", ")", ":", "\n", "      ", "adv_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "adv_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "adv_sentence", "=", "\" \"", ".", "join", "(", "adv_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "adv_sentence", ",", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", ")", ")", "\n", "adv_sentences", "=", "adv_sentences", "+", "[", "adv_sentence", "]", "\n", "adv_probs", "=", "adv_probs", "+", "[", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", "]", "\n", "\n", "", "record", "=", "open", "(", "record_path", "+", "\"record_\"", "+", "str", "(", "FLAGS", ".", "offset", ")", "+", "\".csv\"", ",", "\"a+\"", ")", "\n", "writer", "=", "csv", ".", "writer", "(", "record", ")", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "\n", "      ", "row", "=", "(", "target_filename", ",", "attack_filename", ",", "best_l2_distortion", ",", "best_linf_distortion", ",", "best_loss", ",", "best_loss1", ",", "best_loss2", ",", "final_C", ",", "str", "(", "final_success", ")", ",", "target_sentences", "[", "0", "]", ")", "\n", "row", "+=", "tuple", "(", "words", ")", "+", "tuple", "(", "[", "human_cap", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "raw_sentences", ",", "raw_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "adv_sentences", ",", "adv_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "writer", ".", "writerow", "(", "row", ")", "\n", "", "else", ":", "\n", "      ", "row", "=", "(", "target_filename", ",", "attack_filename", ",", "best_l2_distortion", ",", "best_linf_distortion", ",", "best_loss", ",", "best_loss1", ",", "best_loss2", ",", "final_C", ",", "str", "(", "final_success", ")", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "target_sentences", ",", "target_probs", ")", "for", "val", "in", "pair", "]", ")", "+", "tuple", "(", "[", "human_cap", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "raw_sentences", ",", "raw_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "adv_sentences", ",", "adv_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "writer", ".", "writerow", "(", "row", ")", "\n", "", "record", ".", "close", "(", ")", "\n", "print", "(", "\"****************************************** END OF THIS ATTACK ******************************************\"", ")", "\n", "\n", "", "sess", ".", "close", "(", ")", "\n", "inf_sess", ".", "close", "(", ")", "\n", "if", "FLAGS", ".", "use_keywords", "or", "FLAGS", ".", "targeted", ":", "\n", "    ", "target_sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.run_attack_BATCH_search_C.save_fail_log": [[458, 500], ["range", "len", "run_attack_BATCH_search_C.show", "run_attack_BATCH_search_C.show", "open", "csv.writer", "inf_generator.beam_search", "open.close", "numpy.squeeze", "enumerate", "tuple", "tuple", "csv.writer.writerow", "enumerate", "tuple", "tuple", "csv.writer.writerow", "attack_filename.replace", "attack_filename.replace", "tuple", "tuple", "tuple", "tuple", "str", "str", "str", "vocab.id_to_word", "vocab.id_to_word", "math.exp", "zip", "zip", "math.exp", "zip", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word"], ["", "", "def", "save_fail_log", "(", "adv_log", ",", "loss_log", ",", "loss1_log", ",", "loss2_log", ",", "l2_distortion_log", ",", "linf_distortion_log", ",", "success", ",", "C_val", ",", "record_path", ",", "attack_filename", ",", "raw_image", ",", "human_cap", ",", "raw_sentences", ",", "raw_probs", ",", "inf_sess", ",", "inf_generator", ",", "vocab", ",", "target_info", ")", ":", "\n", "# This fail log function saves the attack results for each C.", "\n", "  ", "for", "i", "in", "range", "(", "len", "(", "adv_log", ")", ")", ":", "\n", "    ", "show", "(", "adv_log", "[", "i", "]", ",", "record_path", "+", "\"fail_log/\"", ",", "\"fail_adversarial_C_\"", "+", "str", "(", "C_val", "[", "i", "]", ")", "+", "attack_filename", ".", "replace", "(", "\".jpg\"", ",", "\".png\"", ")", ")", "\n", "show", "(", "adv_log", "[", "i", "]", "-", "raw_image", ",", "record_path", "+", "\"fail_log/\"", ",", "\"fail_diff_C_\"", "+", "str", "(", "C_val", "[", "i", "]", ")", "+", "attack_filename", ".", "replace", "(", "\".jpg\"", ",", "\".png\"", ")", ")", "\n", "\n", "fail_log", "=", "open", "(", "record_path", "+", "\"fail_log/fail_record_\"", "+", "str", "(", "FLAGS", ".", "offset", ")", "+", "\".csv\"", ",", "\"a+\"", ")", "\n", "fail_log_writer", "=", "csv", ".", "writer", "(", "fail_log", ")", "\n", "adv_captions", "=", "inf_generator", ".", "beam_search", "(", "inf_sess", ",", "np", ".", "squeeze", "(", "adv_log", "[", "i", "]", ")", ")", "\n", "adv_sentences", "=", "[", "]", "\n", "adv_probs", "=", "[", "]", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "      ", "words", "=", "target_info", "[", "\"words\"", "]", "\n", "target_filename", "=", "target_info", "[", "\"target_filename\"", "]", "\n", "target_sentences", "=", "target_info", "[", "\"target_sentences\"", "]", "\n", "for", "indx", ",", "adv_caption", "in", "enumerate", "(", "adv_captions", ")", ":", "\n", "        ", "adv_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "adv_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "adv_sentence", "=", "\" \"", ".", "join", "(", "adv_sentence", ")", "\n", "adv_sentences", "=", "adv_sentences", "+", "[", "adv_sentence", "]", "\n", "adv_probs", "=", "adv_probs", "+", "[", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", "]", "\n", "", "row", "=", "(", "target_filename", ",", "attack_filename", ",", "l2_distortion_log", "[", "i", "]", ",", "linf_distortion_log", "[", "i", "]", ",", "loss_log", "[", "i", "]", ",", "loss1_log", "[", "i", "]", ",", "loss2_log", "[", "i", "]", ",", "C_val", "[", "i", "]", ",", "success", "[", "i", "]", ",", "target_sentences", "[", "0", "]", ")", "\n", "row", "+=", "tuple", "(", "words", ")", "+", "tuple", "(", "[", "human_cap", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "raw_sentences", ",", "raw_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "adv_sentences", ",", "adv_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "fail_log_writer", ".", "writerow", "(", "row", ")", "\n", "", "else", ":", "\n", "      ", "target_sentences", "=", "target_info", "[", "'target_sentences'", "]", "\n", "target_filename", "=", "target_info", "[", "'target_filename'", "]", "\n", "target_probs", "=", "target_info", "[", "'target_probs'", "]", "\n", "for", "indx", ",", "adv_caption", "in", "enumerate", "(", "adv_captions", ")", ":", "\n", "        ", "adv_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "adv_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "adv_sentence", "=", "\" \"", ".", "join", "(", "adv_sentence", ")", "\n", "adv_sentences", "=", "adv_sentences", "+", "[", "adv_sentence", "]", "\n", "adv_probs", "=", "adv_probs", "+", "[", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", "]", "\n", "", "row", "=", "(", "target_filename", ",", "attack_filename", ",", "l2_distortion_log", "[", "i", "]", ",", "linf_distortion_log", "[", "i", "]", ",", "loss_log", "[", "i", "]", ",", "loss1_log", "[", "i", "]", ",", "loss2_log", "[", "i", "]", ",", "C_val", "[", "i", "]", ",", "success", "[", "i", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "target_sentences", ",", "target_probs", ")", "for", "val", "in", "pair", "]", ")", "+", "tuple", "(", "[", "human_cap", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "raw_sentences", ",", "raw_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "row", "+=", "tuple", "(", "[", "val", "for", "pair", "in", "zip", "(", "adv_sentences", ",", "adv_probs", ")", "for", "val", "in", "pair", "]", ")", "\n", "fail_log_writer", ".", "writerow", "(", "row", ")", "\n", "", "fail_log", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.attack_wrapper.AttackWrapper.__init__": [[23, 28], ["im2txt.inference_utils.inference_wrapper_base.InferenceWrapperBase.__init__"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.ImageDecoder.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", "AttackWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# TODO: change this based on configuration", "\n", "self", ".", "image_size", "=", "299", "\n", "self", ".", "num_channels", "=", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.attack_wrapper.AttackWrapper.build_model": [[29, 34], ["im2txt.show_and_tell_model.ShowAndTellModel", "im2txt.show_and_tell_model.ShowAndTellModel.build"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build"], ["", "def", "build_model", "(", "self", ",", "model_config", ",", "image_raw_feed", "=", "None", ",", "input_feed", "=", "None", ",", "mask_feed", "=", "None", ")", ":", "\n", "    ", "model", "=", "show_and_tell_model", ".", "ShowAndTellModel", "(", "model_config", ",", "mode", "=", "\"attack\"", ")", "\n", "model", ".", "build", "(", "image_raw_feed", ",", "input_feed", ",", "mask_feed", ")", "\n", "self", ".", "model", "=", "model", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.attack_wrapper.AttackWrapper.feed_image": [[35, 40], ["sess.run"], "methods", ["None"], ["", "def", "feed_image", "(", "self", ",", "sess", ",", "encoded_image", ")", ":", "\n", "    ", "initial_state", "=", "sess", ".", "run", "(", "fetches", "=", "\"lstm/initial_state:0\"", ",", "\n", "feed_dict", "=", "{", "\"image_feed:0\"", ":", "encoded_image", "}", ")", "\n", "#feed_dict={\"image_raw_feed:0\": encoded_image})", "\n", "return", "initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.attack_wrapper.AttackWrapper.attack_step": [[43, 54], ["tensorflow.gradients", "sess.run", "print", "math.exp", "numpy.sum"], "methods", ["None"], ["", "def", "attack_step", "(", "self", ",", "sess", ",", "input_feed", ",", "mask_feed", ",", "image_raw_feed", ")", ":", "\n", "    ", "grad_op", "=", "tf", ".", "gradients", "(", "self", ".", "model", ".", "target_cross_entropy_losses", ",", "self", ".", "model", ".", "images", ")", "\n", "grads", ",", "target_cross_entropy_losses", "=", "sess", ".", "run", "(", "\n", "fetches", "=", "[", "grad_op", ",", "self", ".", "model", ".", "target_cross_entropy_losses", "]", ",", "\n", "feed_dict", "=", "{", "\n", "\"input_feed:0\"", ":", "input_feed", ",", "\n", "\"input_mask:0\"", ":", "mask_feed", ",", "\n", "\"image_raw_feed:0\"", ":", "image_raw_feed", "\n", "}", ")", "\n", "print", "(", "grads", ")", "\n", "return", "math", ".", "exp", "(", "-", "np", ".", "sum", "(", "target_cross_entropy_losses", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.attack_wrapper.AttackWrapper.predict": [[57, 71], ["tensorflow.logging.info", "set", "attack_wrapper.AttackWrapper.build_model", "tensorflow.global_variables", "tensorflow.train.Saver", "attack_wrapper.AttackWrapper._create_restore_fn", "attack_wrapper.AttackWrapper.", "sess.graph.get_tensor_by_name", "sess.graph.get_tensor_by_name", "im2txt.configuration.ModelConfig", "tensorflow.global_variables"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_model", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase._create_restore_fn"], ["", "def", "predict", "(", "self", ",", "sess", ",", "image_raw_feed", ",", "input_feed", ",", "mask_feed", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Building model.\"", ")", "\n", "start_vars", "=", "set", "(", "x", ".", "name", "for", "x", "in", "tf", ".", "global_variables", "(", ")", ")", "\n", "self", ".", "build_model", "(", "configuration", ".", "ModelConfig", "(", ")", ",", "image_raw_feed", ",", "input_feed", ",", "mask_feed", ")", "\n", "end_vars", "=", "tf", ".", "global_variables", "(", ")", "\n", "restore_vars", "=", "[", "x", "for", "x", "in", "end_vars", "if", "x", ".", "name", "not", "in", "start_vars", "]", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "restore_vars", ")", "\n", "restore_fn", "=", "self", ".", "_create_restore_fn", "(", "FLAGS", ".", "checkpoint_path", ",", "saver", ")", "\n", "restore_fn", "(", "sess", ")", "\n", "sum_log_probs", "=", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "\"batch_loss:0\"", ")", "\n", "logits", "=", "self", ".", "model", ".", "logits", "\n", "softmax", "=", "sess", ".", "graph", ".", "get_tensor_by_name", "(", "\"softmax:0\"", ")", "\n", "# return sum_log_probs, logits, softmax", "\n", "return", "sum_log_probs", ",", "softmax", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show": [[70, 78], ["numpy.save", "numpy.around", "fig.astype().squeeze.astype().squeeze", "PIL.Image.fromarray", "Image.fromarray.save", "fig.astype().squeeze.astype"], "function", ["None"], ["def", "show", "(", "img", ",", "path", ",", "name", "=", "\"output.png\"", ")", ":", "\n", "\n", "    ", "np", ".", "save", "(", "path", "+", "name", ",", "img", ")", "\n", "fig", "=", "np", ".", "around", "(", "(", "img", "+", "1.0", ")", "/", "2.0", "*", "255", ")", "\n", "fig", "=", "fig", ".", "astype", "(", "np", ".", "uint8", ")", ".", "squeeze", "(", ")", "\n", "pic", "=", "Image", ".", "fromarray", "(", "fig", ")", "\n", "# pic.resize((512,512), resample=PIL.Image.BICUBIC)", "\n", "pic", ".", "save", "(", "path", "+", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.main": [[79, 370], ["tensorflow.set_random_seed", "random.seed", "numpy.random.seed", "print", "print", "print", "tensorflow.GPUOptions", "tensorflow.ConfigProto", "im2txt.inference_utils.vocabulary.Vocabulary", "tensorflow.Graph", "tf.Graph.finalize", "tensorflow.Session", "inf_model.build_graph_from_config.", "im2txt.inference_utils.caption_generator.CaptionGenerator", "tensorflow.Graph", "print", "tf.Session.run", "show_and_fool_demo.show", "caption_generator.CaptionGenerator.beam_search", "print", "enumerate", "range", "print", "print", "print", "print", "any", "os.path.splitext", "show_and_fool_demo.show", "show_and_fool_demo.show", "numpy.max", "print", "print", "numpy.squeeze", "caption_generator.CaptionGenerator.beam_search", "print", "enumerate", "print", "tf.Session.close", "tf.Session.close", "set", "tf.Graph.as_default", "im2txt.inference_wrapper.InferenceWrapper", "inference_wrapper.InferenceWrapper.build_graph_from_config", "tensorflow.placeholder", "inference_wrapper.InferenceWrapper.model.process_image", "tensorflow.Graph", "tf.Graph.finalize", "tensorflow.Session", "target_model.build_graph_from_config.", "im2txt.inference_utils.caption_generator.CaptionGenerator", "tf.Graph.as_default", "im2txt.attack_wrapper.AttackWrapper", "tensorflow.Session", "print", "l2_attack.CarliniL2", "tensorflow.placeholder", "attack_wrapper.AttackWrapper.model.process_image", "tensorflow.gfile.GFile", "f.read", "os.path.basename().replace", "print", "print", "caption_generator.CaptionGenerator.beam_search", "enumerate", "list", "caption_generator.CaptionGenerator.beam_search", "print", "print", "print", "numpy.max", "print", "print", "numpy.sum", "numpy.abs", "os.path.basename().replace", "numpy.load", "print", "tf.Session.close", "open", "noun_file.read().split", "open", "verb_file.read().split", "open", "adjective_file.read().split", "open", "adverb_file.read().split", "im2txt.configuration.ModelConfig", "tf.Graph.as_default", "im2txt.inference_wrapper.InferenceWrapper", "inference_wrapper.InferenceWrapper.build_graph_from_config", "tensorflow.placeholder", "inference_wrapper.InferenceWrapper.model.process_image", "os.path.basename().replace", "os.path.basename", "vocabulary.Vocabulary.id_to_word", "tensorflow.gfile.GFile", "f.read", "tf.Session.run", "print", "FLAGS.input_feed.split", "set", "set", "len", "print", "print", "ValueError", "numpy.random.choice", "print", "numpy.append", "l2_attack.CarliniL2.attack", "new_sentence.split.split", "print", "len", "print", "numpy.append", "l2_attack.CarliniL2.attack", "numpy.squeeze", "vocabulary.Vocabulary.id_to_word", "numpy.sum", "numpy.abs", "os.path.basename().replace", "os.path.basename().replace", "os.path.basename", "vocabulary.Vocabulary.id_to_word", "im2txt.configuration.ModelConfig", "os.path.basename", "math.exp", "os.path.basename", "vocabulary.Vocabulary.id_to_word", "target_sentences[].split", "raw_sentences[].split", "list", "list.sort", "list", "list.sort", "vocabulary.Vocabulary.word_to_id", "numpy.ones", "numpy.zeros", "numpy.array", "numpy.ones", "numpy.zeros", "numpy.array", "os.path.basename", "math.exp", "noun_file.read", "verb_file.read", "adjective_file.read", "adverb_file.read", "os.path.basename", "math.exp", "math.exp", "len", "math.exp", "ValueError", "any", "any", "os.path.basename", "os.path.basename", "math.exp", "math.exp", "len", "len", "vocabulary.Vocabulary.word_to_id", "set", "set", "bool", "adv_sentence.split", "set", "set", "len", "success[].index", "len", "success[].index", "adv_sentence.split"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_fool_demo.show", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_config", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_config", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.l2_attack.CarliniL2.attack", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id"], ["", "def", "main", "(", "_", ")", ":", "\n", "\n", "  ", "tf", ".", "set_random_seed", "(", "FLAGS", ".", "seed", ")", "\n", "random", ".", "seed", "(", "FLAGS", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "FLAGS", ".", "seed", ")", "\n", "beam_size", "=", "FLAGS", ".", "beam_size", "\n", "record_path", "=", "FLAGS", ".", "result_directory", "\n", "attack_filename", "=", "FLAGS", ".", "attack_filepath", "\n", "target_filename", "=", "FLAGS", ".", "target_filepath", "\n", "# we should use os.path.join!", "\n", "if", "record_path", "[", "-", "1", "]", "!=", "\"/\"", ":", "\n", "      ", "record_path", "+=", "\"/\"", "\n", "\n", "", "print", "(", "\"using \"", "+", "FLAGS", ".", "norm", "+", "\" for attack\"", ")", "\n", "print", "(", "\"targeted?\"", ",", "FLAGS", ".", "targeted", ")", "\n", "print", "(", "\"attack confidence kappa\"", ",", "FLAGS", ".", "confidence", ")", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "    ", "keywords_num", "=", "FLAGS", ".", "keywords_num", "\n", "with", "open", "(", "'wordPOS/noun.txt'", ")", "as", "noun_file", ":", "\n", "      ", "noun", "=", "noun_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "", "with", "open", "(", "'wordPOS/verb.txt'", ")", "as", "verb_file", ":", "\n", "      ", "verb", "=", "verb_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "", "with", "open", "(", "'wordPOS/adjective.txt'", ")", "as", "adjective_file", ":", "\n", "      ", "adjective", "=", "adjective_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "", "with", "open", "(", "'wordPOS/adverb.txt'", ")", "as", "adverb_file", ":", "\n", "      ", "adverb", "=", "adverb_file", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "# good words are noun, verb, adj or adv. We do not want words like \"a\" or \"the\" to be our keywords.", "\n", "# Those .txt files are generated by classifying the vocabulary list. ", "\n", "", "good_words", "=", "set", "(", "noun", "+", "verb", "+", "adjective", "+", "adverb", ")", "\n", "\n", "", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "0.4", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", "\n", "vocab", "=", "vocabulary", ".", "Vocabulary", "(", "FLAGS", ".", "vocab_file", ")", "\n", "\n", "\n", "inference_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "inference_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "inf_model", "=", "inference_wrapper", ".", "InferenceWrapper", "(", ")", "\n", "inf_restore_fn", "=", "inf_model", ".", "build_graph_from_config", "(", "configuration", ".", "ModelConfig", "(", ")", ",", "FLAGS", ".", "checkpoint_path", ")", "\n", "inf_image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "inf_preprocessor", "=", "inf_model", ".", "model", ".", "process_image", "(", "inf_image_placeholder", ")", "\n", "", "inference_graph", ".", "finalize", "(", ")", "\n", "inf_sess", "=", "tf", ".", "Session", "(", "graph", "=", "inference_graph", ",", "config", "=", "config", ")", "\n", "# Load the model from checkpoint.", "\n", "inf_restore_fn", "(", "inf_sess", ")", "\n", "inf_generator", "=", "caption_generator", ".", "CaptionGenerator", "(", "inf_model", ",", "vocab", ",", "beam_size", "=", "beam_size", ")", "\n", "\n", "if", "FLAGS", ".", "targeted", "or", "FLAGS", ".", "use_keywords", ":", "\n", "    ", "target_g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "target_g", ".", "as_default", "(", ")", ":", "\n", "      ", "target_model", "=", "inference_wrapper", ".", "InferenceWrapper", "(", ")", "\n", "target_restore_fn", "=", "target_model", ".", "build_graph_from_config", "(", "configuration", ".", "ModelConfig", "(", ")", ",", "FLAGS", ".", "checkpoint_path", ")", "\n", "target_image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "target_preprocessor", "=", "target_model", ".", "model", ".", "process_image", "(", "target_image_placeholder", ")", "\n", "", "target_g", ".", "finalize", "(", ")", "\n", "target_sess", "=", "tf", ".", "Session", "(", "graph", "=", "target_g", ",", "config", "=", "config", ")", "\n", "target_restore_fn", "(", "target_sess", ")", "\n", "target_generator", "=", "caption_generator", ".", "CaptionGenerator", "(", "target_model", ",", "vocab", ",", "beam_size", "=", "beam_size", ")", "\n", "\n", "\n", "", "attack_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "attack_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "model", "=", "attack_wrapper", ".", "AttackWrapper", "(", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "# build the attacker graph", "\n", "print", "(", "\"targeted:\"", ",", "FLAGS", ".", "targeted", ")", "\n", "attack", "=", "CarliniL2", "(", "sess", ",", "inf_sess", ",", "attack_graph", ",", "inference_graph", ",", "model", ",", "inf_model", ",", "targeted", "=", "FLAGS", ".", "targeted", ",", "use_keywords", "=", "FLAGS", ".", "use_keywords", ",", "use_logits", "=", "FLAGS", ".", "use_logits", ",", "batch_size", "=", "1", ",", "initial_const", "=", "FLAGS", ".", "C", ",", "max_iterations", "=", "FLAGS", ".", "iters", ",", "print_every", "=", "1", ",", "confidence", "=", "FLAGS", ".", "confidence", ",", "use_log", "=", "False", ",", "norm", "=", "FLAGS", ".", "norm", ",", "abort_early", "=", "False", ",", "learning_rate", "=", "0.005", ")", "\n", "# compute graph for preprocessing", "\n", "image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ",", "shape", "=", "[", "]", ")", "\n", "preprocessor", "=", "model", ".", "model", ".", "process_image", "(", "image_placeholder", ")", "\n", "\n", "", "print", "(", "\"attack filename:\"", ",", "attack_filename", ")", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "attack_filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "    ", "image", "=", "f", ".", "read", "(", ")", "\n", "", "raw_image", "=", "sess", ".", "run", "(", "preprocessor", ",", "feed_dict", "=", "{", "image_placeholder", ":", "image", "}", ")", "\n", "\n", "\n", "show", "(", "raw_image", ",", "record_path", ",", "\"original_\"", "+", "os", ".", "path", ".", "basename", "(", "attack_filename", ")", ".", "replace", "(", "\".jpg\"", ",", "\".png\"", ")", ")", "\n", "raw_filename", "=", "record_path", "+", "\"original_\"", "+", "os", ".", "path", ".", "basename", "(", "attack_filename", ")", ".", "replace", "(", "\".jpg\"", ",", "\".png.npy\"", ")", "\n", "# raw_image = np.squeeze(np.load(raw_filename))", "\n", "raw_captions", "=", "inf_generator", ".", "beam_search", "(", "inf_sess", ",", "raw_image", ")", "\n", "print", "(", "\"Captions for original image %s:\"", "%", "os", ".", "path", ".", "basename", "(", "raw_filename", ")", ")", "\n", "raw_sentences", "=", "[", "]", "\n", "raw_probs", "=", "[", "]", "\n", "for", "indx", ",", "raw_caption", "in", "enumerate", "(", "raw_captions", ")", ":", "\n", "    ", "raw_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "raw_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "raw_sentence", "=", "\" \"", ".", "join", "(", "raw_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "raw_sentence", ",", "math", ".", "exp", "(", "raw_caption", ".", "logprob", ")", ")", ")", "\n", "raw_sentences", "=", "raw_sentences", "+", "[", "raw_sentence", "]", "\n", "raw_probs", "=", "raw_probs", "+", "[", "math", ".", "exp", "(", "raw_caption", ".", "logprob", ")", "]", "\n", "\n", "", "if", "FLAGS", ".", "targeted", ":", "\n", "# If it's targeted attack, we pick another image as our target image to generate target caption for us.", "\n", "    ", "print", "(", "\"Captions for target image %s:\"", "%", "os", ".", "path", ".", "basename", "(", "target_filename", ")", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "target_filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "target_image", "=", "f", ".", "read", "(", ")", "\n", "target_image", "=", "target_sess", ".", "run", "(", "target_preprocessor", ",", "{", "target_image_placeholder", ":", "target_image", "}", ")", "\n", "", "target_captions", "=", "target_generator", ".", "beam_search", "(", "target_sess", ",", "target_image", ")", "\n", "target_sentences", "=", "[", "]", "\n", "target_probs", "=", "[", "]", "\n", "for", "indx", ",", "target_caption", "in", "enumerate", "(", "target_captions", ")", ":", "\n", "      ", "target_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "target_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "target_sentence", "=", "\" \"", ".", "join", "(", "target_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "target_sentence", ",", "math", ".", "exp", "(", "target_caption", ".", "logprob", ")", ")", ")", "\n", "target_sentences", "=", "target_sentences", "+", "[", "target_sentence", "]", "\n", "target_probs", "=", "target_probs", "+", "[", "math", ".", "exp", "(", "target_caption", ".", "logprob", ")", "]", "\n", "", "", "else", ":", "\n", "# If it's untargeted, our target sentence is the attack image's own original caption.", "\n", "    ", "target_sentences", "=", "raw_sentences", "\n", "target_probs", "=", "raw_probs", "\n", "target_filename", "=", "attack_filename", "\n", "\n", "", "if", "FLAGS", ".", "use_keywords", ":", "\n", "    ", "if", "FLAGS", ".", "input_feed", ":", "\n", "# If there is an input feed, we use input feed as our keywords.", "\n", "      ", "words", "=", "FLAGS", ".", "input_feed", ".", "split", "(", ")", "\n", "", "else", ":", "\n", "# If there is no input feed, we use select keywords from the target caption. ", "\n", "      ", "target_sentences_words", "=", "set", "(", "target_sentences", "[", "0", "]", ".", "split", "(", ")", ")", "\n", "raw_sentences_words", "=", "set", "(", "raw_sentences", "[", "0", "]", ".", "split", "(", ")", ")", "\n", "if", "FLAGS", ".", "targeted", ":", "\n", "# If tagreted, we also need to exclude the words in the original caption.", "\n", "        ", "word_candidates", "=", "list", "(", "(", "target_sentences_words", "&", "good_words", ")", "-", "raw_sentences_words", ")", "\n", "word_candidates", ".", "sort", "(", ")", "\n", "", "else", ":", "\n", "        ", "word_candidates", "=", "list", "(", "(", "target_sentences_words", "&", "good_words", ")", ")", "\n", "word_candidates", ".", "sort", "(", ")", "\n", "", "", "if", "len", "(", "word_candidates", ")", "<", "keywords_num", ":", "\n", "      ", "print", "(", "\"words not enough for this attack!\"", ")", "\n", "print", "(", "\"****************************************** END OF THIS ATTACK ******************************************\"", ")", "\n", "raise", "ValueError", "(", "\"attack aborted\"", ")", "\n", "\n", "# Randomly select keywords from all candidates.", "\n", "", "words", "=", "list", "(", "np", ".", "random", ".", "choice", "(", "word_candidates", ",", "keywords_num", ",", "replace", "=", "False", ")", ")", "\n", "\n", "# run multiple attacks", "\n", "", "success", "=", "[", "]", "\n", "C_val", "=", "[", "FLAGS", ".", "C", "]", "\n", "best_adv", "=", "None", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "None", ",", "None", ",", "None", "\n", "l2_distortion_log", "=", "[", "]", "\n", "linf_distortion_log", "=", "[", "]", "\n", "best_l2_distortion", "=", "1e10", "\n", "best_linf_distortion", "=", "1e10", "\n", "adv_log", "=", "[", "]", "\n", "loss1_log", "=", "[", "]", "\n", "loss2_log", "=", "[", "]", "\n", "loss_log", "=", "[", "]", "\n", "j", "=", "0", "\n", "\n", "for", "try_index", "in", "range", "(", "FLAGS", ".", "C_search_times", ")", ":", "\n", "\n", "    ", "attack_const", "=", "C_val", "[", "try_index", "]", "\n", "max_caption_length", "=", "20", "\n", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "# keywords based attack", "\n", "      ", "key_words", "=", "[", "vocab", ".", "word_to_id", "(", "word", ")", "for", "word", "in", "words", "]", "\n", "print", "(", "\"My key words are: \"", ",", "words", ")", "\n", "key_words_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "len", "(", "key_words", ")", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "len", "(", "key_words", ")", ")", ")", "\n", "key_words", "=", "key_words", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "len", "(", "key_words", ")", ")", "\n", "adv", ",", "loss", ",", "loss1", ",", "loss2", ",", "_", "=", "attack", ".", "attack", "(", "np", ".", "array", "(", "[", "raw_image", "]", ")", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "key_words", ",", "key_words_mask", ",", "j", ",", "try_index", ",", "beam_size", ",", "FLAGS", ".", "infer_per_iter", ",", "attack_const", "=", "attack_const", ")", "\n", "", "else", ":", "\n", "# exact attack", "\n", "      ", "if", "FLAGS", ".", "targeted", ":", "\n", "        ", "if", "FLAGS", ".", "input_feed", ":", "\n", "          ", "new_sentence", "=", "FLAGS", ".", "input_feed", "\n", "", "else", ":", "\n", "          ", "new_sentence", "=", "target_sentences", "[", "0", "]", "\n", "", "", "else", ":", "\n", "        ", "new_sentence", "=", "raw_sentences", "[", "0", "]", "\n", "# new_sentence = \"a black and white photo of a train on a track .\"", "\n", "", "new_sentence", "=", "new_sentence", ".", "split", "(", ")", "\n", "print", "(", "\"My target sentence:\"", ",", "new_sentence", ")", "\n", "new_caption", "=", "[", "vocab", ".", "start_id", "]", "+", "[", "vocab", ".", "word_to_id", "(", "w", ")", "for", "w", "in", "new_sentence", "]", "+", "[", "vocab", ".", "end_id", "]", "\n", "true_cap_len", "=", "len", "(", "new_caption", ")", "\n", "new_caption", "=", "new_caption", "+", "[", "vocab", ".", "end_id", "]", "*", "(", "max_caption_length", "-", "true_cap_len", ")", "\n", "print", "(", "\"My target id:\"", ",", "new_caption", ")", "\n", "new_mask", "=", "np", ".", "append", "(", "np", ".", "ones", "(", "true_cap_len", ")", ",", "np", ".", "zeros", "(", "max_caption_length", "-", "true_cap_len", ")", ")", "\n", "adv", ",", "loss", ",", "loss1", ",", "loss2", ",", "_", "=", "attack", ".", "attack", "(", "np", ".", "array", "(", "[", "raw_image", "]", ")", ",", "sess", ",", "inf_sess", ",", "model", ",", "inf_model", ",", "vocab", ",", "new_caption", ",", "new_mask", ",", "j", ",", "try_index", ",", "1", ",", "attack_const", "=", "attack_const", ")", "\n", "# save information of this image to log array", "\n", "", "adv_log", "+=", "[", "adv", "]", "\n", "loss_log", "+=", "[", "loss", "]", "\n", "loss1_log", "+=", "[", "loss1", "]", "\n", "loss2_log", "+=", "[", "loss2", "]", "\n", "\n", "adv_captions", "=", "inf_generator", ".", "beam_search", "(", "inf_sess", ",", "np", ".", "squeeze", "(", "adv", ")", ")", "\n", "print", "(", "\"Captions after this attempt:\"", ")", "\n", "adv_caption", "=", "adv_captions", "[", "0", "]", "\n", "adv_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "adv_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "adv_sentence", "=", "\" \"", ".", "join", "(", "adv_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "adv_sentence", ",", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", ")", ")", "\n", "\n", "if", "FLAGS", ".", "use_keywords", ":", "\n", "      ", "if", "FLAGS", ".", "targeted", ":", "\n", "        ", "success", "+=", "[", "set", "(", "words", ")", "<", "set", "(", "adv_sentence", ".", "split", "(", ")", ")", "]", "\n", "", "else", ":", "\n", "        ", "success", "+=", "[", "not", "bool", "(", "set", "(", "words", ")", "&", "set", "(", "adv_sentence", ".", "split", "(", ")", ")", ")", "]", "\n", "", "", "else", ":", "\n", "      ", "if", "FLAGS", ".", "targeted", ":", "\n", "        ", "success", "+=", "[", "(", "adv_sentence", "==", "target_sentences", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "# For untargeted and caption based attack, there is no simple criterion to determine an attack is successful or not. We need to calculate the scores.", "\n", "# So here we always assumee the attack is fail, then we save fail log for score calculation.", "\n", "        ", "success", "+=", "[", "False", "]", "\n", "\n", "", "", "print", "(", "\"Attack with this C is successful?\"", ",", "success", "[", "try_index", "]", ")", "\n", "\n", "l2_distortion", "=", "np", ".", "sum", "(", "(", "adv", "-", "raw_image", ")", "**", "2", ")", "**", ".5", "\n", "linf_distortion", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "adv", "-", "raw_image", ")", ")", "\n", "l2_distortion_log", "+=", "[", "l2_distortion", "]", "\n", "linf_distortion_log", "+=", "[", "linf_distortion", "]", "\n", "print", "(", "\"L2 distortion is\"", ",", "l2_distortion", ")", "\n", "print", "(", "\"L_inf distortion is\"", ",", "linf_distortion", ")", "\n", "if", "success", "[", "try_index", "]", ":", "\n", "# Among the successful attacks, we select the one with minimum distortion as our final result.", "\n", "# Note this one may not correspond to minimum C.", "\n", "      ", "if", "FLAGS", ".", "norm", "==", "\"l2\"", ":", "\n", "        ", "if", "l2_distortion", "<", "best_l2_distortion", ":", "\n", "          ", "best_adv", "=", "adv", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "loss", ",", "loss1", ",", "loss2", "\n", "best_l2_distortion", "=", "l2_distortion", "\n", "best_linf_distortion", "=", "linf_distortion", "\n", "final_C", "=", "C_val", "[", "try_index", "]", "\n", "", "", "elif", "FLAGS", ".", "norm", "==", "\"inf\"", ":", "\n", "        ", "if", "linf_distortion", "<", "best_linf_distortion", ":", "\n", "          ", "best_adv", "=", "adv", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "loss", ",", "loss1", ",", "loss2", "\n", "best_l2_distortion", "=", "l2_distortion", "\n", "best_linf_distortion", "=", "linf_distortion", "\n", "final_C", "=", "C_val", "[", "try_index", "]", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"unsupported distance metric:\"", "+", "FLAGS", ".", "norm", ")", "\n", "", "", "if", "FLAGS", ".", "targeted", "or", "FLAGS", ".", "use_keywords", ":", "\n", "# We do binary search to find next C.", "\n", "      ", "if", "try_index", "+", "1", "<", "FLAGS", ".", "C_search_times", ":", "\n", "        ", "if", "success", "[", "try_index", "]", ":", "\n", "          ", "if", "any", "(", "not", "_", "for", "_", "in", "success", ")", ":", "\n", "            ", "last_false", "=", "len", "(", "success", ")", "-", "success", "[", ":", ":", "-", "1", "]", ".", "index", "(", "False", ")", "-", "1", "\n", "C_val", "+=", "[", "0.5", "*", "(", "C_val", "[", "try_index", "]", "+", "C_val", "[", "last_false", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "C_val", "+=", "[", "C_val", "[", "try_index", "]", "*", "0.5", "]", "\n", "", "", "else", ":", "\n", "          ", "if", "any", "(", "_", "for", "_", "in", "success", ")", ":", "\n", "            ", "last_true", "=", "len", "(", "success", ")", "-", "success", "[", ":", ":", "-", "1", "]", ".", "index", "(", "True", ")", "-", "1", "\n", "C_val", "+=", "[", "0.5", "*", "(", "C_val", "[", "try_index", "]", "+", "C_val", "[", "last_true", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "C_val", "+=", "[", "C_val", "[", "try_index", "]", "*", "10.0", "]", "\n", "", "", "", "", "else", ":", "\n", "      ", "break", "\n", "\n", "", "", "print", "(", "\"results of each attempt:\"", ",", "success", ")", "\n", "print", "(", "\"C values of each attempt:\"", ",", "C_val", ")", "\n", "print", "(", "\"L2 distortion log is\"", ",", "l2_distortion_log", ")", "\n", "print", "(", "\"L_inf distortion log is\"", ",", "linf_distortion_log", ")", "\n", "final_success", "=", "any", "(", "_", "for", "_", "in", "success", ")", "\n", "\n", "if", "not", "final_success", ":", "\n", "    ", "final_C", "=", "C_val", "[", "-", "1", "]", "\n", "best_adv", "=", "adv", "\n", "best_loss", ",", "best_loss1", ",", "best_loss2", "=", "loss", ",", "loss1", ",", "loss2", "\n", "\n", "", "_", ",", "attack_ext", "=", "os", ".", "path", ".", "splitext", "(", "attack_filename", ")", "\n", "show", "(", "best_adv", ",", "record_path", ",", "\"adversarial_\"", "+", "os", ".", "path", ".", "basename", "(", "attack_filename", ")", ".", "replace", "(", "attack_ext", ",", "\".png\"", ")", ")", "\n", "show", "(", "best_adv", "-", "raw_image", ",", "record_path", ",", "\"diff_\"", "+", "os", ".", "path", ".", "basename", "(", "attack_filename", ")", ".", "replace", "(", "attack_ext", ",", "\".png\"", ")", ")", "\n", "\n", "\n", "best_l2_distortion", "=", "np", ".", "sum", "(", "(", "best_adv", "-", "raw_image", ")", "**", "2", ")", "**", ".5", "\n", "best_linf_distortion", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "best_adv", "-", "raw_image", ")", ")", "\n", "print", "(", "\"best L2 distortion is\"", ",", "best_l2_distortion", ")", "\n", "print", "(", "\"best L_inf distortion is\"", ",", "best_linf_distortion", ")", "\n", "\n", "adv_filename", "=", "record_path", "+", "\"adversarial_\"", "+", "os", ".", "path", ".", "basename", "(", "attack_filename", ")", ".", "replace", "(", "attack_ext", ",", "\".png.npy\"", ")", "\n", "adv_image", "=", "np", ".", "squeeze", "(", "np", ".", "load", "(", "adv_filename", ")", ")", "\n", "adv_captions", "=", "inf_generator", ".", "beam_search", "(", "inf_sess", ",", "adv_image", ")", "\n", "print", "(", "\"Captions for adversarial image %s:\"", "%", "os", ".", "path", ".", "basename", "(", "adv_filename", ")", ")", "\n", "adv_sentences", "=", "[", "]", "\n", "adv_probs", "=", "[", "]", "\n", "for", "indx", ",", "adv_caption", "in", "enumerate", "(", "adv_captions", ")", ":", "\n", "    ", "adv_sentence", "=", "[", "vocab", ".", "id_to_word", "(", "w", ")", "for", "w", "in", "adv_caption", ".", "sentence", "[", "1", ":", "-", "1", "]", "]", "\n", "adv_sentence", "=", "\" \"", ".", "join", "(", "adv_sentence", ")", "\n", "print", "(", "\"  %d) %s (p=%f)\"", "%", "(", "1", ",", "adv_sentence", ",", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", ")", ")", "\n", "adv_sentences", "=", "adv_sentences", "+", "[", "adv_sentence", "]", "\n", "adv_probs", "=", "adv_probs", "+", "[", "math", ".", "exp", "(", "adv_caption", ".", "logprob", ")", "]", "\n", "", "print", "(", "\"****************************************** END OF THIS ATTACK ******************************************\"", ")", "\n", "\n", "sess", ".", "close", "(", ")", "\n", "inf_sess", ".", "close", "(", ")", "\n", "if", "FLAGS", ".", "use_keywords", "or", "FLAGS", ".", "targeted", ":", "\n", "    ", "target_sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.inference_wrapper.InferenceWrapper.__init__": [[32, 34], ["im2txt.inference_utils.inference_wrapper_base.InferenceWrapperBase.__init__"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.ImageDecoder.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", "InferenceWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.inference_wrapper.InferenceWrapper.build_model": [[35, 40], ["im2txt.show_and_tell_model.ShowAndTellModel", "im2txt.show_and_tell_model.ShowAndTellModel.build"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build"], ["", "def", "build_model", "(", "self", ",", "model_config", ")", ":", "\n", "    ", "model", "=", "show_and_tell_model", ".", "ShowAndTellModel", "(", "model_config", ",", "mode", "=", "\"inference\"", ")", "\n", "model", ".", "build", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.inference_wrapper.InferenceWrapper.feed_image": [[41, 45], ["sess.run"], "methods", ["None"], ["", "def", "feed_image", "(", "self", ",", "sess", ",", "encoded_image", ")", ":", "\n", "    ", "initial_state", "=", "sess", ".", "run", "(", "fetches", "=", "\"lstm/initial_state:0\"", ",", "\n", "feed_dict", "=", "{", "\"image_feed:0\"", ":", "encoded_image", "}", ")", "\n", "return", "initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.inference_wrapper.InferenceWrapper.inference_step": [[46, 54], ["sess.run"], "methods", ["None"], ["", "def", "inference_step", "(", "self", ",", "sess", ",", "input_feed", ",", "state_feed", ")", ":", "\n", "    ", "softmax_output", ",", "state_output", "=", "sess", ".", "run", "(", "\n", "fetches", "=", "[", "\"softmax:0\"", ",", "\"lstm/state:0\"", "]", ",", "\n", "feed_dict", "=", "{", "\n", "\"input_feed:0\"", ":", "input_feed", ",", "\n", "\"lstm/state_feed:0\"", ":", "state_feed", ",", "\n", "}", ")", "\n", "return", "softmax_output", ",", "state_output", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.inference_wrapper.InferenceWrapper.new_caption_prob": [[55, 67], ["inference_wrapper.InferenceWrapper.feed_image", "numpy.array", "print", "range", "math.exp", "len", "numpy.array", "inference_wrapper.InferenceWrapper.inference_step", "len", "math.log"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.feed_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.inference_step"], ["", "def", "new_caption_prob", "(", "self", ",", "sess", ",", "cap_sentence", ",", "encoded_image", ")", ":", "\n", "    ", "logprob", "=", "0.0", "\n", "state_feed", "=", "self", ".", "feed_image", "(", "sess", ",", "encoded_image", ")", "\n", "state_feed", "=", "np", ".", "array", "(", "[", "state_feed", "[", "0", "]", "]", ")", "\n", "print", "(", "len", "(", "cap_sentence", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "cap_sentence", ")", "-", "1", ")", ":", "\n", "      ", "input_feed", "=", "np", ".", "array", "(", "[", "cap_sentence", "[", "i", "]", "]", ")", "\n", "softmax", ",", "new_state", ",", "metadata", "=", "self", ".", "inference_step", "(", "sess", ",", "input_feed", ",", "state_feed", ")", "\n", "state_feed", "=", "new_state", "\n", "next_word_probability", "=", "softmax", "[", "0", "]", "[", "cap_sentence", "[", "i", "+", "1", "]", "]", "\n", "logprob", "=", "logprob", "+", "math", ".", "log", "(", "next_word_probability", ")", "\n", "", "return", "math", ".", "exp", "(", "logprob", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.__init__": [[43, 100], ["tensorflow.TFRecordReader", "tensorflow.random_uniform_initializer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "config", ",", "mode", ",", "train_inception", "=", "False", ")", ":", "\n", "    ", "\"\"\"Basic setup.\n\n    Args:\n      config: Object containing configuration parameters.\n      mode: \"train\", \"eval\" or \"inference\".\n      train_inception: Whether the inception submodel variables are trainable.\n    \"\"\"", "\n", "assert", "mode", "in", "[", "\"train\"", ",", "\"eval\"", ",", "\"inference\"", ",", "\"attack\"", "]", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "train_inception", "=", "train_inception", "\n", "\n", "# Reader for the input data.", "\n", "self", ".", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "\n", "# To match the \"Show and Tell\" paper we initialize all variables with a", "\n", "# random uniform initializer.", "\n", "self", ".", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "minval", "=", "-", "self", ".", "config", ".", "initializer_scale", ",", "\n", "maxval", "=", "self", ".", "config", ".", "initializer_scale", ")", "\n", "\n", "# A float32 Tensor with shape [batch_size, height, width, channels].", "\n", "self", ".", "images", "=", "None", "\n", "\n", "# An int32 Tensor with shape [batch_size, padded_length].", "\n", "self", ".", "input_seqs", "=", "None", "\n", "\n", "# An int32 Tensor with shape [batch_size, padded_length].", "\n", "self", ".", "target_seqs", "=", "None", "\n", "\n", "# An int32 0/1 Tensor with shape [batch_size, padded_length].", "\n", "self", ".", "input_mask", "=", "None", "\n", "\n", "# A float32 Tensor with shape [batch_size, embedding_size].", "\n", "self", ".", "image_embeddings", "=", "None", "\n", "\n", "# A float32 Tensor with shape [batch_size, padded_length, embedding_size].", "\n", "self", ".", "seq_embeddings", "=", "None", "\n", "\n", "# A float32 scalar Tensor; the total loss for the trainer to optimize.", "\n", "self", ".", "total_loss", "=", "None", "\n", "\n", "# A float32 Tensor with shape [batch_size * padded_length].", "\n", "self", ".", "target_cross_entropy_losses", "=", "None", "\n", "\n", "# A float32 Tensor with shape [batch_size * padded_length].", "\n", "self", ".", "target_cross_entropy_loss_weights", "=", "None", "\n", "\n", "# Collection of variables from the inception submodel.", "\n", "self", ".", "inception_variables", "=", "[", "]", "\n", "\n", "# Function to restore the inception submodel from checkpoint.", "\n", "self", ".", "init_fn", "=", "None", "\n", "\n", "# Global step Tensor.", "\n", "self", ".", "global_step", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.is_training": [[101, 104], ["None"], "methods", ["None"], ["", "def", "is_training", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns true if the model is built for training mode.\"\"\"", "\n", "return", "self", ".", "mode", "==", "\"train\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.process_image": [[105, 123], ["im2txt.ops.image_processing.process_image", "show_and_tell_model.ShowAndTellModel.is_training"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.is_training"], ["", "def", "process_image", "(", "self", ",", "encoded_image", ",", "thread_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Decodes and processes an image string.\n\n    Args:\n      encoded_image: A scalar string Tensor; the encoded image.\n      thread_id: Preprocessing thread id used to select the ordering of color\n        distortions.\n\n    Returns:\n      A float32 Tensor of shape [height, width, 3]; the processed image.\n    \"\"\"", "\n", "\n", "return", "image_processing", ".", "process_image", "(", "encoded_image", ",", "\n", "is_training", "=", "self", ".", "is_training", "(", ")", ",", "\n", "height", "=", "self", ".", "config", ".", "image_height", ",", "\n", "width", "=", "self", ".", "config", ".", "image_width", ",", "\n", "thread_id", "=", "thread_id", ",", "\n", "image_format", "=", "self", ".", "config", ".", "image_format", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_inputs": [[124, 201], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.slice", "tensorflow.slice", "tensorflow.slice", "im2txt.ops.inputs.prefetch_input_data", "range", "im2txt.ops.inputs.batch_with_dynamic_pad", "im2txt.ops.inputs.prefetch_input_data.dequeue", "im2txt.ops.inputs.parse_sequence_example", "show_and_tell_model.ShowAndTellModel.process_image", "images_and_captions.append", "show_and_tell_model.ShowAndTellModel.is_training", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.inputs.prefetch_input_data", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.inputs.batch_with_dynamic_pad", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.inputs.parse_sequence_example", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.is_training"], ["", "def", "build_inputs", "(", "self", ",", "image_feed", "=", "None", ",", "input_feed", "=", "None", ",", "input_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"Input prefetching, preprocessing and batching.\n\n    Outputs:\n      self.images\n      self.input_seqs\n      self.target_seqs (training and eval only)\n      self.input_mask (training and eval only)\n    \"\"\"", "\n", "if", "self", ".", "mode", "==", "\"inference\"", ":", "\n", "# In inference mode, images and inputs are fed via placeholders.", "\n", "\n", "      ", "image_feed", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "self", ".", "config", ".", "image_height", ",", "self", ".", "config", ".", "image_width", ",", "3", "]", ",", "name", "=", "\"image_feed\"", ")", "\n", "\n", "\n", "input_feed", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int64", ",", "\n", "shape", "=", "[", "None", "]", ",", "# batch_size", "\n", "name", "=", "\"input_feed\"", ")", "\n", "\n", "# Process image and insert batch dimensions.", "\n", "\n", "\n", "images", "=", "tf", ".", "expand_dims", "(", "image_feed", ",", "0", ")", "\n", "input_seqs", "=", "tf", ".", "expand_dims", "(", "input_feed", ",", "1", ")", "\n", "\n", "# No target sequences or input mask in inference mode.", "\n", "target_seqs", "=", "None", "\n", "input_mask", "=", "None", "\n", "", "elif", "self", ".", "mode", "==", "\"attack\"", ":", "\n", "# In attack mode, images and inputs are fed via placeholders.", "\n", "# Image is feed as [None, 299, 299, 3]", "\n", "# TODO: batch size is fixed at 1", "\n", "\n", "# Process image and insert batch dimensions.", "\n", "# images = tf.expand_dims(image_feed, 0)", "\n", "      ", "images", "=", "image_feed", "\n", "# input_seqs = input_feed", "\n", "input_seqs", "=", "tf", ".", "slice", "(", "input_feed", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "input_feed", ")", "[", "1", "]", "-", "1", "]", ")", "\n", "target_seqs", "=", "tf", ".", "slice", "(", "input_feed", ",", "[", "0", ",", "1", "]", ",", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "input_mask", "=", "tf", ".", "slice", "(", "input_mask", ",", "[", "0", ",", "1", "]", ",", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "\n", "", "else", ":", "\n", "# Prefetch serialized SequenceExample protos.", "\n", "      ", "input_queue", "=", "input_ops", ".", "prefetch_input_data", "(", "\n", "self", ".", "reader", ",", "\n", "self", ".", "config", ".", "input_file_pattern", ",", "\n", "is_training", "=", "self", ".", "is_training", "(", ")", ",", "\n", "batch_size", "=", "self", ".", "config", ".", "batch_size", ",", "\n", "values_per_shard", "=", "self", ".", "config", ".", "values_per_input_shard", ",", "\n", "input_queue_capacity_factor", "=", "self", ".", "config", ".", "input_queue_capacity_factor", ",", "\n", "num_reader_threads", "=", "self", ".", "config", ".", "num_input_reader_threads", ")", "\n", "\n", "# Image processing and random distortion. Split across multiple threads", "\n", "# with each thread applying a slightly different distortion.", "\n", "assert", "self", ".", "config", ".", "num_preprocess_threads", "%", "2", "==", "0", "\n", "images_and_captions", "=", "[", "]", "\n", "for", "thread_id", "in", "range", "(", "self", ".", "config", ".", "num_preprocess_threads", ")", ":", "\n", "        ", "serialized_sequence_example", "=", "input_queue", ".", "dequeue", "(", ")", "\n", "encoded_image", ",", "caption", "=", "input_ops", ".", "parse_sequence_example", "(", "\n", "serialized_sequence_example", ",", "\n", "image_feature", "=", "self", ".", "config", ".", "image_feature_name", ",", "\n", "caption_feature", "=", "self", ".", "config", ".", "caption_feature_name", ")", "\n", "image", "=", "self", ".", "process_image", "(", "encoded_image", ",", "thread_id", "=", "thread_id", ")", "\n", "images_and_captions", ".", "append", "(", "[", "image", ",", "caption", "]", ")", "\n", "\n", "# Batch inputs.", "\n", "", "queue_capacity", "=", "(", "2", "*", "self", ".", "config", ".", "num_preprocess_threads", "*", "\n", "self", ".", "config", ".", "batch_size", ")", "\n", "images", ",", "input_seqs", ",", "target_seqs", ",", "input_mask", "=", "(", "\n", "input_ops", ".", "batch_with_dynamic_pad", "(", "images_and_captions", ",", "\n", "batch_size", "=", "self", ".", "config", ".", "batch_size", ",", "\n", "queue_capacity", "=", "queue_capacity", ")", ")", "\n", "\n", "", "self", ".", "images", "=", "images", "\n", "self", ".", "input_seqs", "=", "input_seqs", "\n", "self", ".", "target_seqs", "=", "target_seqs", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_image_embeddings": [[202, 232], ["im2txt.ops.image_embedding.inception_v3", "tensorflow.get_collection", "tensorflow.constant", "tensorflow.variable_scope", "tensorflow.contrib.layers.fully_connected", "show_and_tell_model.ShowAndTellModel.is_training"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding.inception_v3", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.is_training"], ["", "def", "build_image_embeddings", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds the image model subgraph and generates image embeddings.\n\n    Inputs:\n      self.images\n\n    Outputs:\n      self.image_embeddings\n    \"\"\"", "\n", "inception_output", "=", "image_embedding", ".", "inception_v3", "(", "\n", "self", ".", "images", ",", "\n", "trainable", "=", "self", ".", "train_inception", ",", "\n", "is_training", "=", "self", ".", "is_training", "(", ")", ")", "\n", "self", ".", "inception_variables", "=", "tf", ".", "get_collection", "(", "\n", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "\"InceptionV3\"", ")", "\n", "\n", "# Map inception output into embedding space.", "\n", "with", "tf", ".", "variable_scope", "(", "\"image_embedding\"", ")", "as", "scope", ":", "\n", "      ", "image_embeddings", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "\n", "inputs", "=", "inception_output", ",", "\n", "num_outputs", "=", "self", ".", "config", ".", "embedding_size", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_initializer", "=", "self", ".", "initializer", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "scope", "=", "scope", ")", "\n", "\n", "# Save the embedding size in the graph.", "\n", "", "tf", ".", "constant", "(", "self", ".", "config", ".", "embedding_size", ",", "name", "=", "\"embedding_size\"", ")", "\n", "\n", "self", ".", "image_embeddings", "=", "image_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_seq_embeddings": [[233, 250], ["tensorflow.variable_scope", "tensorflow.device", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "def", "build_seq_embeddings", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds the input sequence embeddings.\n\n    Inputs:\n      self.input_seqs\n\n    Outputs:\n      self.seq_embeddings\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"seq_embedding\"", ")", ",", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "      ", "embedding_map", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "\"map\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "vocab_size", ",", "self", ".", "config", ".", "embedding_size", "]", ",", "\n", "initializer", "=", "self", ".", "initializer", ")", "\n", "seq_embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding_map", ",", "self", ".", "input_seqs", ")", "\n", "\n", "", "self", ".", "seq_embeddings", "=", "seq_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_model": [[251, 357], ["tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.reshape", "print", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.variable_scope", "tensorflow.contrib.rnn.DropoutWrapper.zero_state", "tensorflow.contrib.rnn.DropoutWrapper.", "lstm_scope.reuse_variables", "tensorflow.reshape.get_shape", "tensorflow.variable_scope", "tensorflow.contrib.layers.fully_connected", "print", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_sum", "tensorflow.losses.add_loss", "tensorflow.losses.get_total_loss", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.concat", "tensorflow.placeholder", "tensorflow.split", "tensorflow.contrib.rnn.DropoutWrapper.", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.nn.dynamic_rnn", "print", "show_and_tell_model.ShowAndTellModel.logits.get_shape", "tensorflow.reshape", "tensorflow.multiply", "tensorflow.summary.histogram", "tensorflow.reshape.get_shape", "show_and_tell_model.ShowAndTellModel.image_embeddings.get_shape", "tensorflow.squeeze", "sum"], "methods", ["None"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds the model.\n\n    Inputs:\n      self.image_embeddings\n      self.seq_embeddings\n      self.target_seqs (training and eval only)\n      self.input_mask (training and eval only)\n\n    Outputs:\n      self.total_loss (training and eval only)\n      self.target_cross_entropy_losses (training and eval only)\n      self.target_cross_entropy_loss_weights (training and eval only)\n    \"\"\"", "\n", "# This LSTM cell has biases and outputs tanh(new_c) * sigmoid(o), but the", "\n", "# modified LSTM in the \"Show and Tell\" paper has no biases and outputs", "\n", "# new_c * sigmoid(o).", "\n", "lstm_cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "num_units", "=", "self", ".", "config", ".", "num_lstm_units", ",", "state_is_tuple", "=", "True", ")", "\n", "if", "self", ".", "mode", "==", "\"train\"", ":", "\n", "      ", "lstm_cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "DropoutWrapper", "(", "\n", "lstm_cell", ",", "\n", "input_keep_prob", "=", "self", ".", "config", ".", "lstm_dropout_keep_prob", ",", "\n", "output_keep_prob", "=", "self", ".", "config", ".", "lstm_dropout_keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"lstm\"", ",", "initializer", "=", "self", ".", "initializer", ")", "as", "lstm_scope", ":", "\n", "# Feed the image embeddings to set the initial LSTM state.", "\n", "      ", "zero_state", "=", "lstm_cell", ".", "zero_state", "(", "\n", "batch_size", "=", "self", ".", "image_embeddings", ".", "get_shape", "(", ")", "[", "0", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "_", ",", "initial_state", "=", "lstm_cell", "(", "self", ".", "image_embeddings", ",", "zero_state", ")", "\n", "\n", "# Allow the LSTM variables to be reused.", "\n", "lstm_scope", ".", "reuse_variables", "(", ")", "\n", "\n", "if", "self", ".", "mode", "==", "\"inference\"", ":", "\n", "# In inference mode, use concatenated states for convenient feeding and", "\n", "# fetching.", "\n", "        ", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "initial_state", ",", "name", "=", "\"initial_state\"", ")", "\n", "\n", "# Placeholder for feeding a batch of concatenated states.", "\n", "state_feed", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "None", ",", "sum", "(", "lstm_cell", ".", "state_size", ")", "]", ",", "\n", "name", "=", "\"state_feed\"", ")", "\n", "state_tuple", "=", "tf", ".", "split", "(", "value", "=", "state_feed", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", "\n", "\n", "# Run a single LSTM step.", "\n", "lstm_outputs", ",", "state_tuple", "=", "lstm_cell", "(", "\n", "inputs", "=", "tf", ".", "squeeze", "(", "self", ".", "seq_embeddings", ",", "axis", "=", "[", "1", "]", ")", ",", "\n", "state", "=", "state_tuple", ")", "\n", "\n", "# Concatentate the resulting state.", "\n", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "state_tuple", ",", "name", "=", "\"state\"", ")", "\n", "", "else", ":", "\n", "# Run the batch of sequence embeddings through the LSTM.", "\n", "        ", "sequence_length", "=", "tf", ".", "reduce_sum", "(", "self", ".", "input_mask", ",", "1", ")", "\n", "lstm_outputs", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell", "=", "lstm_cell", ",", "\n", "inputs", "=", "self", ".", "seq_embeddings", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "scope", "=", "lstm_scope", ")", "\n", "print", "(", "\"lstm_outputs shape:\"", ",", "lstm_outputs", ".", "get_shape", "(", ")", ")", "\n", "\n", "# Stack batches vertically.", "\n", "", "", "lstm_outputs", "=", "tf", ".", "reshape", "(", "lstm_outputs", ",", "[", "-", "1", ",", "lstm_cell", ".", "output_size", "]", ")", "\n", "print", "(", "\"lstm_outputs shape:\"", ",", "lstm_outputs", ".", "get_shape", "(", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"logits\"", ")", "as", "logits_scope", ":", "\n", "      ", "self", ".", "logits", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "\n", "inputs", "=", "lstm_outputs", ",", "\n", "num_outputs", "=", "self", ".", "config", ".", "vocab_size", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_initializer", "=", "self", ".", "initializer", ",", "\n", "scope", "=", "logits_scope", ")", "\n", "# name=\"logits\")", "\n", "print", "(", "\"fully connected size:\"", ",", "self", ".", "logits", ".", "get_shape", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "mode", "==", "\"inference\"", ":", "\n", "      ", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "logits", ",", "name", "=", "\"softmax\"", ")", "\n", "", "else", ":", "\n", "      ", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "logits", ",", "name", "=", "\"softmax\"", ")", "\n", "targets", "=", "tf", ".", "reshape", "(", "self", ".", "target_seqs", ",", "[", "-", "1", "]", ")", "\n", "weights", "=", "tf", ".", "to_float", "(", "tf", ".", "reshape", "(", "self", ".", "input_mask", ",", "[", "-", "1", "]", ")", ")", "\n", "\n", "# Compute losses.", "\n", "losses", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "targets", ",", "\n", "logits", "=", "self", ".", "logits", ",", "\n", "name", "=", "\"softmax_and_cross_entropy\"", ")", "\n", "\"\"\"\n      batch_loss = tf.div(tf.reduce_sum(tf.multiply(losses, weights)),\n                          tf.reduce_sum(weights),\n                          name=\"batch_loss\")\n      \"\"\"", "\n", "batch_loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "losses", ",", "weights", ")", ",", "name", "=", "\"batch_loss\"", ")", "\n", "tf", ".", "losses", ".", "add_loss", "(", "batch_loss", ")", "\n", "total_loss", "=", "tf", ".", "losses", ".", "get_total_loss", "(", ")", "\n", "\n", "# Add summaries.", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"losses/batch_loss\"", ",", "batch_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"losses/total_loss\"", ",", "total_loss", ")", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "\"parameters/\"", "+", "var", ".", "op", ".", "name", ",", "var", ")", "\n", "\n", "", "self", ".", "total_loss", "=", "total_loss", "\n", "self", ".", "target_cross_entropy_losses", "=", "losses", "# Used in evaluation.", "\n", "self", ".", "target_cross_entropy_loss_weights", "=", "weights", "# Used in evaluation.", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.setup_inception_initializer": [[358, 370], ["tensorflow.train.Saver", "tensorflow.logging.info", "tensorflow.train.Saver.restore"], "methods", ["None"], ["", "", "def", "setup_inception_initializer", "(", "self", ")", ":", "\n", "    ", "\"\"\"Sets up the function to restore inception variables from checkpoint.\"\"\"", "\n", "if", "self", ".", "mode", "!=", "\"inference\"", ":", "\n", "# Restore inception variables only.", "\n", "      ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "self", ".", "inception_variables", ")", "\n", "\n", "def", "restore_fn", "(", "sess", ")", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "\"Restoring Inception variables from checkpoint file %s\"", ",", "\n", "self", ".", "config", ".", "inception_checkpoint_file", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "self", ".", "config", ".", "inception_checkpoint_file", ")", "\n", "\n", "", "self", ".", "init_fn", "=", "restore_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.setup_global_step": [[371, 380], ["tensorflow.Variable"], "methods", ["None"], ["", "", "def", "setup_global_step", "(", "self", ")", ":", "\n", "    ", "\"\"\"Sets up the global step Tensor.\"\"\"", "\n", "global_step", "=", "tf", ".", "Variable", "(", "\n", "initial_value", "=", "0", ",", "\n", "name", "=", "\"global_step\"", ",", "\n", "trainable", "=", "False", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "GLOBAL_STEP", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ")", "\n", "\n", "self", ".", "global_step", "=", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build": [[381, 392], ["show_and_tell_model.ShowAndTellModel.build_image_embeddings", "show_and_tell_model.ShowAndTellModel.build_seq_embeddings", "show_and_tell_model.ShowAndTellModel.build_model", "show_and_tell_model.ShowAndTellModel.setup_inception_initializer", "show_and_tell_model.ShowAndTellModel.setup_global_step", "show_and_tell_model.ShowAndTellModel.build_inputs", "show_and_tell_model.ShowAndTellModel.build_inputs"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_image_embeddings", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_seq_embeddings", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_model", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.setup_inception_initializer", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.setup_global_step", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_inputs", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.show_and_tell_model.ShowAndTellModel.build_inputs"], ["", "def", "build", "(", "self", ",", "image_feed", "=", "None", ",", "input_feed", "=", "None", ",", "input_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates all ops for training and evaluation.\"\"\"", "\n", "if", "self", ".", "mode", "==", "\"attack\"", ":", "\n", "      ", "self", ".", "build_inputs", "(", "image_feed", "=", "image_feed", ",", "input_feed", "=", "input_feed", ",", "input_mask", "=", "input_mask", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "build_inputs", "(", ")", "\n", "", "self", ".", "build_image_embeddings", "(", ")", "\n", "self", ".", "build_seq_embeddings", "(", ")", "\n", "self", ".", "build_model", "(", ")", "\n", "self", ".", "setup_inception_initializer", "(", ")", "\n", "self", ".", "setup_global_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.configuration.ModelConfig.__init__": [[26, 79], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Sets the default model hyperparameters.\"\"\"", "\n", "# File pattern of sharded TFRecord file containing SequenceExample protos.", "\n", "# Must be provided in training and evaluation modes.", "\n", "self", ".", "input_file_pattern", "=", "None", "\n", "\n", "# Image format (\"jpeg\" or \"png\").", "\n", "self", ".", "image_format", "=", "\"jpeg\"", "\n", "\n", "# Approximate number of values per input shard. Used to ensure sufficient", "\n", "# mixing between shards in training.", "\n", "self", ".", "values_per_input_shard", "=", "2300", "\n", "# Minimum number of shards to keep in the input queue.", "\n", "self", ".", "input_queue_capacity_factor", "=", "2", "\n", "# Number of threads for prefetching SequenceExample protos.", "\n", "self", ".", "num_input_reader_threads", "=", "1", "\n", "\n", "# Name of the SequenceExample context feature containing image data.", "\n", "self", ".", "image_feature_name", "=", "\"image/data\"", "\n", "# Name of the SequenceExample feature list containing integer captions.", "\n", "self", ".", "caption_feature_name", "=", "\"image/caption_ids\"", "\n", "\n", "# Number of unique words in the vocab (plus 1, for <UNK>).", "\n", "# The default value is larger than the expected actual vocab size to allow", "\n", "# for differences between tokenizer versions used in preprocessing. There is", "\n", "# no harm in using a value greater than the actual vocab size, but using a", "\n", "# value less than the actual vocab size will result in an error.", "\n", "self", ".", "vocab_size", "=", "12000", "\n", "\n", "# Number of threads for image preprocessing. Should be a multiple of 2.", "\n", "self", ".", "num_preprocess_threads", "=", "4", "\n", "\n", "# Batch size.", "\n", "self", ".", "batch_size", "=", "32", "\n", "\n", "# File containing an Inception v3 checkpoint to initialize the variables", "\n", "# of the Inception model. Must be provided when starting training for the", "\n", "# first time.", "\n", "self", ".", "inception_checkpoint_file", "=", "None", "\n", "\n", "# Dimensions of Inception v3 input images.", "\n", "self", ".", "image_height", "=", "299", "\n", "self", ".", "image_width", "=", "299", "\n", "\n", "# Scale used to initialize model variables.", "\n", "self", ".", "initializer_scale", "=", "0.08", "\n", "\n", "# LSTM input and output dimensionality, respectively.", "\n", "self", ".", "embedding_size", "=", "512", "\n", "self", ".", "num_lstm_units", "=", "512", "\n", "\n", "# If < 1.0, the dropout keep probability applied to LSTM variables.", "\n", "self", ".", "lstm_dropout_keep_prob", "=", "0.7", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.im2txt.configuration.TrainingConfig.__init__": [[84, 105], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Sets the default training hyperparameters.\"\"\"", "\n", "# Number of examples per epoch of training data.", "\n", "self", ".", "num_examples_per_epoch", "=", "586363", "\n", "\n", "# Optimizer for training the model.", "\n", "self", ".", "optimizer", "=", "\"SGD\"", "\n", "\n", "# Learning rate for the initial phase of training.", "\n", "self", ".", "initial_learning_rate", "=", "2.0", "\n", "self", ".", "learning_rate_decay_factor", "=", "0.5", "\n", "self", ".", "num_epochs_per_decay", "=", "8.0", "\n", "\n", "# Learning rate when fine tuning the Inception v3 parameters.", "\n", "self", ".", "train_inception_learning_rate", "=", "0.0005", "\n", "\n", "# If not None, clip gradients to this value.", "\n", "self", ".", "clip_gradients", "=", "5.0", "\n", "\n", "# How many model checkpoints to keep.", "\n", "self", ".", "max_checkpoints_to_keep", "=", "5", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.__init__": [[28, 65], ["tensorflow.logging.info", "dict", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.logging.fatal", "tensorflow.gfile.GFile", "list", "list.append", "f.readlines", "line.split", "len", "enumerate"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_file", ",", "\n", "start_word", "=", "\"<S>\"", ",", "\n", "end_word", "=", "\"</S>\"", ",", "\n", "unk_word", "=", "\"<UNK>\"", ")", ":", "\n", "    ", "\"\"\"Initializes the vocabulary.\n\n    Args:\n      vocab_file: File containing the vocabulary, where the words are the first\n        whitespace-separated token on each line (other tokens are ignored) and\n        the word ids are the corresponding line numbers.\n      start_word: Special word denoting sentence start.\n      end_word: Special word denoting sentence end.\n      unk_word: Special word denoting unknown words.\n    \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "vocab_file", ")", ":", "\n", "      ", "tf", ".", "logging", ".", "fatal", "(", "\"Vocab file %s not found.\"", ",", "vocab_file", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Initializing vocabulary from file: %s\"", ",", "vocab_file", ")", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "vocab_file", ",", "mode", "=", "\"r\"", ")", "as", "f", ":", "\n", "      ", "reverse_vocab", "=", "list", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "reverse_vocab", "=", "[", "line", ".", "split", "(", ")", "[", "0", "]", "for", "line", "in", "reverse_vocab", "]", "\n", "assert", "start_word", "in", "reverse_vocab", "\n", "assert", "end_word", "in", "reverse_vocab", "\n", "if", "unk_word", "not", "in", "reverse_vocab", ":", "\n", "      ", "reverse_vocab", ".", "append", "(", "unk_word", ")", "\n", "", "vocab", "=", "dict", "(", "[", "(", "x", ",", "y", ")", "for", "(", "y", ",", "x", ")", "in", "enumerate", "(", "reverse_vocab", ")", "]", ")", "\n", "\n", "tf", ".", "logging", ".", "info", "(", "\"Created vocabulary with %d words\"", "%", "len", "(", "vocab", ")", ")", "\n", "\n", "self", ".", "vocab", "=", "vocab", "# vocab[word] = id", "\n", "self", ".", "reverse_vocab", "=", "reverse_vocab", "# reverse_vocab[id] = word", "\n", "\n", "# Save special word ids.", "\n", "self", ".", "start_id", "=", "vocab", "[", "start_word", "]", "\n", "self", ".", "end_id", "=", "vocab", "[", "end_word", "]", "\n", "self", ".", "unk_id", "=", "vocab", "[", "unk_word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.word_to_id": [[66, 72], ["None"], "methods", ["None"], ["", "def", "word_to_id", "(", "self", ",", "word", ")", ":", "\n", "    ", "\"\"\"Returns the integer word id of a word string.\"\"\"", "\n", "if", "word", "in", "self", ".", "vocab", ":", "\n", "      ", "return", "self", ".", "vocab", "[", "word", "]", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "unk_id", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.vocabulary.Vocabulary.id_to_word": [[73, 79], ["len"], "methods", ["None"], ["", "", "def", "id_to_word", "(", "self", ",", "word_id", ")", ":", "\n", "    ", "\"\"\"Returns the word string of an integer word id.\"\"\"", "\n", "if", "word_id", ">=", "len", "(", "self", ".", "reverse_vocab", ")", ":", "\n", "      ", "return", "self", ".", "reverse_vocab", "[", "self", ".", "unk_id", "]", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "reverse_vocab", "[", "word_id", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.__init__": [[59, 61], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_model": [[62, 72], ["tensorflow.logging.fatal"], "methods", ["None"], ["", "def", "build_model", "(", "self", ",", "model_config", ")", ":", "\n", "    ", "\"\"\"Builds the model for inference.\n\n    Args:\n      model_config: Object containing configuration for building the model.\n\n    Returns:\n      model: The model object.\n    \"\"\"", "\n", "tf", ".", "logging", ".", "fatal", "(", "\"Please implement build_model in subclass\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase._create_restore_fn": [[73, 101], ["tensorflow.gfile.IsDirectory", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "saver.restore", "tensorflow.logging.info", "ValueError", "os.path.basename"], "methods", ["None"], ["", "def", "_create_restore_fn", "(", "self", ",", "checkpoint_path", ",", "saver", ")", ":", "\n", "    ", "\"\"\"Creates a function that restores a model from checkpoint.\n\n    Args:\n      checkpoint_path: Checkpoint file or a directory containing a checkpoint\n        file.\n      saver: Saver for restoring variables from the checkpoint file.\n\n    Returns:\n      restore_fn: A function such that restore_fn(sess) loads model variables\n        from the checkpoint file.\n\n    Raises:\n      ValueError: If checkpoint_path does not refer to a checkpoint file or a\n        directory containing a checkpoint file.\n    \"\"\"", "\n", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "checkpoint_path", ")", ":", "\n", "      ", "checkpoint_path", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_path", ")", "\n", "if", "not", "checkpoint_path", ":", "\n", "        ", "raise", "ValueError", "(", "\"No checkpoint file found in: %s\"", "%", "checkpoint_path", ")", "\n", "\n", "", "", "def", "_restore_fn", "(", "sess", ")", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"Loading model from checkpoint: %s\"", ",", "checkpoint_path", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint_path", ")", "\n", "tf", ".", "logging", ".", "info", "(", "\"Successfully loaded checkpoint: %s\"", ",", "\n", "os", ".", "path", ".", "basename", "(", "checkpoint_path", ")", ")", "\n", "\n", "", "return", "_restore_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_config": [[102, 119], ["tensorflow.logging.info", "inference_wrapper_base.InferenceWrapperBase.build_model", "tensorflow.train.Saver", "inference_wrapper_base.InferenceWrapperBase._create_restore_fn"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_model", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase._create_restore_fn"], ["", "def", "build_graph_from_config", "(", "self", ",", "model_config", ",", "checkpoint_path", ")", ":", "\n", "    ", "\"\"\"Builds the inference graph from a configuration object.\n\n    Args:\n      model_config: Object containing configuration for building the model.\n      checkpoint_path: Checkpoint file or a directory containing a checkpoint\n        file.\n\n    Returns:\n      restore_fn: A function such that restore_fn(sess) loads model variables\n        from the checkpoint file.\n    \"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "\"Building model.\"", ")", "\n", "self", ".", "build_model", "(", "model_config", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "return", "self", ".", "_create_restore_fn", "(", "checkpoint_path", ",", "saver", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.build_graph_from_proto": [[120, 149], ["tensorflow.logging.info", "tensorflow.GraphDef", "tensorflow.import_graph_def", "tensorflow.logging.info", "tensorflow.train.SaverDef", "tensorflow.train.Saver", "inference_wrapper_base.InferenceWrapperBase._create_restore_fn", "tensorflow.gfile.FastGFile", "tensorflow.GraphDef.ParseFromString", "tensorflow.gfile.FastGFile", "tensorflow.train.SaverDef.ParseFromString", "f.read", "f.read"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase._create_restore_fn"], ["", "def", "build_graph_from_proto", "(", "self", ",", "graph_def_file", ",", "saver_def_file", ",", "\n", "checkpoint_path", ")", ":", "\n", "    ", "\"\"\"Builds the inference graph from serialized GraphDef and SaverDef protos.\n\n    Args:\n      graph_def_file: File containing a serialized GraphDef proto.\n      saver_def_file: File containing a serialized SaverDef proto.\n      checkpoint_path: Checkpoint file or a directory containing a checkpoint\n        file.\n\n    Returns:\n      restore_fn: A function such that restore_fn(sess) loads model variables\n        from the checkpoint file.\n    \"\"\"", "\n", "# Load the Graph.", "\n", "tf", ".", "logging", ".", "info", "(", "\"Loading GraphDef from file: %s\"", ",", "graph_def_file", ")", "\n", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "graph_def_file", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "graph_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "", "tf", ".", "import_graph_def", "(", "graph_def", ",", "name", "=", "\"\"", ")", "\n", "\n", "# Load the Saver.", "\n", "tf", ".", "logging", ".", "info", "(", "\"Loading SaverDef from file: %s\"", ",", "saver_def_file", ")", "\n", "saver_def", "=", "tf", ".", "train", ".", "SaverDef", "(", ")", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "saver_def_file", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "saver_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "saver_def", "=", "saver_def", ")", "\n", "\n", "return", "self", ".", "_create_restore_fn", "(", "checkpoint_path", ",", "saver", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.feed_image": [[150, 163], ["tensorflow.logging.fatal"], "methods", ["None"], ["", "def", "feed_image", "(", "self", ",", "sess", ",", "encoded_image", ")", ":", "\n", "    ", "\"\"\"Feeds an image and returns the initial model state.\n\n    See comments at the top of file.\n\n    Args:\n      sess: TensorFlow Session object.\n      encoded_image: An encoded image string.\n\n    Returns:\n      state: A numpy array of shape [1, state_size].\n    \"\"\"", "\n", "tf", ".", "logging", ".", "fatal", "(", "\"Please implement feed_image in subclass\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.inference_wrapper_base.InferenceWrapperBase.inference_step": [[164, 180], ["tensorflow.logging.fatal"], "methods", ["None"], ["", "def", "inference_step", "(", "self", ",", "sess", ",", "input_feed", ",", "state_feed", ")", ":", "\n", "    ", "\"\"\"Runs one step of inference.\n\n    Args:\n      sess: TensorFlow Session object.\n      input_feed: A numpy array of shape [batch_size].\n      state_feed: A numpy array of shape [batch_size, state_size].\n\n    Returns:\n      softmax_output: A numpy array of shape [batch_size, vocab_size].\n      new_state: A numpy array of shape [batch_size, state_size].\n      metadata: Optional. If not None, a string containing metadata about the\n        current inference step (e.g. serialized numpy array containing\n        activations from a particular model layer.).\n    \"\"\"", "\n", "tf", ".", "logging", ".", "fatal", "(", "\"Please implement inference_step in subclass\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.Caption.__init__": [[31, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sentence", ",", "state", ",", "logprob", ",", "score", ",", "metadata", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initializes the Caption.\n\n    Args:\n      sentence: List of word ids in the caption.\n      state: Model state after generating the previous word.\n      logprob: Log-probability of the caption.\n      score: Score of the caption.\n      metadata: Optional metadata associated with the partial sentence. If not\n        None, a list of strings with the same length as 'sentence'.\n    \"\"\"", "\n", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "state", "=", "state", "\n", "self", ".", "logprob", "=", "logprob", "\n", "self", ".", "score", "=", "score", "\n", "self", ".", "metadata", "=", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.Caption.__cmp__": [[48, 57], ["isinstance"], "methods", ["None"], ["", "def", "__cmp__", "(", "self", ",", "other", ")", ":", "\n", "    ", "\"\"\"Compares Captions by score.\"\"\"", "\n", "assert", "isinstance", "(", "other", ",", "Caption", ")", "\n", "if", "self", ".", "score", "==", "other", ".", "score", ":", "\n", "      ", "return", "0", "\n", "", "elif", "self", ".", "score", "<", "other", ".", "score", ":", "\n", "      ", "return", "-", "1", "\n", "", "else", ":", "\n", "      ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.Caption.__lt__": [[59, 62], ["isinstance"], "methods", ["None"], ["", "", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "    ", "assert", "isinstance", "(", "other", ",", "Caption", ")", "\n", "return", "self", ".", "score", "<", "other", ".", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.Caption.__eq__": [[64, 67], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "    ", "assert", "isinstance", "(", "other", ",", "Caption", ")", "\n", "return", "self", ".", "score", "==", "other", ".", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.__init__": [[72, 75], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n", ")", ":", "\n", "    ", "self", ".", "_n", "=", "n", "\n", "self", ".", "_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.size": [[76, 79], ["len"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "_data", "is", "not", "None", "\n", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.push": [[80, 87], ["len", "heapq.heappush", "heapq.heappushpop"], "methods", ["None"], ["", "def", "push", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Pushes a new element.\"\"\"", "\n", "assert", "self", ".", "_data", "is", "not", "None", "\n", "if", "len", "(", "self", ".", "_data", ")", "<", "self", ".", "_n", ":", "\n", "      ", "heapq", ".", "heappush", "(", "self", ".", "_data", ",", "x", ")", "\n", "", "else", ":", "\n", "      ", "heapq", ".", "heappushpop", "(", "self", ".", "_data", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.extract": [[88, 105], ["data.sort"], "methods", ["None"], ["", "", "def", "extract", "(", "self", ",", "sort", "=", "False", ")", ":", "\n", "    ", "\"\"\"Extracts all elements from the TopN. This is a destructive operation.\n\n    The only method that can be called immediately after extract() is reset().\n\n    Args:\n      sort: Whether to return the elements in descending sorted order.\n\n    Returns:\n      A list of data; the top n elements provided to the set.\n    \"\"\"", "\n", "assert", "self", ".", "_data", "is", "not", "None", "\n", "data", "=", "self", ".", "_data", "\n", "self", ".", "_data", "=", "None", "\n", "if", "sort", ":", "\n", "      ", "data", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.reset": [[106, 109], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the TopN to an empty state.\"\"\"", "\n", "self", ".", "_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.__init__": [[114, 140], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "vocab", ",", "\n", "beam_size", "=", "3", ",", "\n", "max_caption_length", "=", "20", ",", "\n", "length_normalization_factor", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Initializes the generator.\n\n    Args:\n      model: Object encapsulating a trained image-to-text model. Must have\n        methods feed_image() and inference_step(). For example, an instance of\n        InferenceWrapperBase.\n      vocab: A Vocabulary object.\n      beam_size: Beam size to use when generating captions.\n      max_caption_length: The maximum caption length before stopping the search.\n      length_normalization_factor: If != 0, a number x such that captions are\n        scored by logprob/length^x, rather than logprob. This changes the\n        relative scores of captions depending on their lengths. For example, if\n        x > 0 then longer captions will be favored.\n    \"\"\"", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "model", "=", "model", "\n", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "max_caption_length", "=", "max_caption_length", "\n", "self", ".", "length_normalization_factor", "=", "length_normalization_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search": [[141, 212], ["caption_generator.CaptionGenerator.model.feed_image", "caption_generator.Caption", "caption_generator.TopN", "caption_generator.TopN.push", "caption_generator.TopN", "range", "caption_generator.TopN.extract", "caption_generator.TopN.extract", "caption_generator.TopN.reset", "numpy.array", "numpy.array", "caption_generator.CaptionGenerator.model.inference_step", "enumerate", "caption_generator.TopN.size", "list", "list.sort", "caption_generator.TopN.size", "enumerate", "math.log", "caption_generator.Caption", "caption_generator.TopN.push", "caption_generator.Caption", "caption_generator.TopN.push", "len"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.feed_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.push", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.extract", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.extract", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.reset", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.inference_step", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.size", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.size", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.push", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.push"], ["", "def", "beam_search", "(", "self", ",", "sess", ",", "encoded_image", ")", ":", "\n", "    ", "\"\"\"Runs beam search caption generation on a single image.\n\n    Args:\n      sess: TensorFlow Session object.\n      encoded_image: An encoded image string.\n\n    Returns:\n      A list of Caption sorted by descending score.\n    \"\"\"", "\n", "# Feed in the image to get the initial state.", "\n", "initial_state", "=", "self", ".", "model", ".", "feed_image", "(", "sess", ",", "encoded_image", ")", "\n", "\n", "initial_beam", "=", "Caption", "(", "\n", "sentence", "=", "[", "self", ".", "vocab", ".", "start_id", "]", ",", "\n", "state", "=", "initial_state", "[", "0", "]", ",", "\n", "logprob", "=", "0.0", ",", "\n", "score", "=", "0.0", ",", "\n", "metadata", "=", "[", "\"\"", "]", ")", "\n", "partial_captions", "=", "TopN", "(", "self", ".", "beam_size", ")", "\n", "partial_captions", ".", "push", "(", "initial_beam", ")", "\n", "complete_captions", "=", "TopN", "(", "self", ".", "beam_size", ")", "\n", "\n", "# Run beam search.", "\n", "for", "_", "in", "range", "(", "self", ".", "max_caption_length", "-", "1", ")", ":", "\n", "      ", "partial_captions_list", "=", "partial_captions", ".", "extract", "(", ")", "\n", "partial_captions", ".", "reset", "(", ")", "\n", "input_feed", "=", "np", ".", "array", "(", "[", "c", ".", "sentence", "[", "-", "1", "]", "for", "c", "in", "partial_captions_list", "]", ")", "\n", "state_feed", "=", "np", ".", "array", "(", "[", "c", ".", "state", "for", "c", "in", "partial_captions_list", "]", ")", "\n", "\n", "softmax", ",", "new_states", ",", "metadata", "=", "self", ".", "model", ".", "inference_step", "(", "sess", ",", "\n", "input_feed", ",", "\n", "state_feed", ")", "\n", "\n", "for", "i", ",", "partial_caption", "in", "enumerate", "(", "partial_captions_list", ")", ":", "\n", "        ", "word_probabilities", "=", "softmax", "[", "i", "]", "\n", "state", "=", "new_states", "[", "i", "]", "\n", "# For this partial caption, get the beam_size most probable next words.", "\n", "words_and_probs", "=", "list", "(", "enumerate", "(", "word_probabilities", ")", ")", "\n", "words_and_probs", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "words_and_probs", "=", "words_and_probs", "[", "0", ":", "self", ".", "beam_size", "]", "\n", "# Each next word gives a new partial caption.", "\n", "for", "w", ",", "p", "in", "words_and_probs", ":", "\n", "          ", "if", "p", "<", "1e-12", ":", "\n", "            ", "continue", "# Avoid log(0).", "\n", "", "sentence", "=", "partial_caption", ".", "sentence", "+", "[", "w", "]", "\n", "logprob", "=", "partial_caption", ".", "logprob", "+", "math", ".", "log", "(", "p", ")", "\n", "score", "=", "logprob", "\n", "if", "metadata", ":", "\n", "            ", "metadata_list", "=", "partial_caption", ".", "metadata", "+", "[", "metadata", "[", "i", "]", "]", "\n", "", "else", ":", "\n", "            ", "metadata_list", "=", "None", "\n", "", "if", "w", "==", "self", ".", "vocab", ".", "end_id", ":", "\n", "            ", "if", "self", ".", "length_normalization_factor", ">", "0", ":", "\n", "              ", "score", "/=", "len", "(", "sentence", ")", "**", "self", ".", "length_normalization_factor", "\n", "", "beam", "=", "Caption", "(", "sentence", ",", "state", ",", "logprob", ",", "score", ",", "metadata_list", ")", "\n", "complete_captions", ".", "push", "(", "beam", ")", "\n", "", "else", ":", "\n", "            ", "beam", "=", "Caption", "(", "sentence", ",", "state", ",", "logprob", ",", "score", ",", "metadata_list", ")", "\n", "partial_captions", ".", "push", "(", "beam", ")", "\n", "", "", "", "if", "partial_captions", ".", "size", "(", ")", "==", "0", ":", "\n", "# We have run out of partial candidates; happens when beam_size = 1.", "\n", "        ", "break", "\n", "\n", "# If we have no complete captions then fall back to the partial captions.", "\n", "# But never output a mixture of complete and partial captions because a", "\n", "# partial caption could have a higher score than all the complete captions.", "\n", "", "", "if", "not", "complete_captions", ".", "size", "(", ")", ":", "\n", "      ", "complete_captions", "=", "partial_captions", "\n", "\n", "", "return", "complete_captions", ".", "extract", "(", "sort", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.new_caption_prob": [[213, 224], ["caption_generator.CaptionGenerator.model.feed_image", "numpy.array", "range", "math.exp", "numpy.array", "caption_generator.CaptionGenerator.model.inference_step", "len", "math.log"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.feed_image", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.inference_step"], ["", "def", "new_caption_prob", "(", "self", ",", "sess", ",", "cap_sentence", ",", "encoded_image", ")", ":", "\n", "    ", "logprob", "=", "0.0", "\n", "state_feed", "=", "self", ".", "model", ".", "feed_image", "(", "sess", ",", "encoded_image", ")", "\n", "state_feed", "=", "np", ".", "array", "(", "[", "state_feed", "[", "0", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "cap_sentence", ")", "-", "1", ")", ":", "\n", "      ", "input_feed", "=", "np", ".", "array", "(", "[", "cap_sentence", "[", "i", "]", "]", ")", "\n", "softmax", ",", "new_state", ",", "metadata", "=", "self", ".", "model", ".", "inference_step", "(", "sess", ",", "input_feed", ",", "state_feed", ")", "\n", "state_feed", "=", "new_state", "\n", "next_word_probability", "=", "softmax", "[", "0", "]", "[", "cap_sentence", "[", "i", "+", "1", "]", "]", "\n", "logprob", "=", "logprob", "+", "math", ".", "log", "(", "next_word_probability", ")", "\n", "", "return", "math", ".", "exp", "(", "logprob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeVocab.__init__": [[30, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "start_id", "=", "0", "# Word id denoting sentence start.", "\n", "self", ".", "end_id", "=", "1", "# Word id denoting sentence end.", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.__init__": [[38, 67], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Number of words in the vocab.", "\n", "    ", "self", ".", "_vocab_size", "=", "12", "\n", "\n", "# Dimensionality of the nominal model state.", "\n", "self", ".", "_state_size", "=", "1", "\n", "\n", "# Map of previous word to the probability distribution of the next word.", "\n", "self", ".", "_probabilities", "=", "{", "\n", "0", ":", "{", "1", ":", "0.1", ",", "\n", "2", ":", "0.2", ",", "\n", "3", ":", "0.3", ",", "\n", "4", ":", "0.4", "}", ",", "\n", "2", ":", "{", "5", ":", "0.1", ",", "\n", "6", ":", "0.9", "}", ",", "\n", "3", ":", "{", "1", ":", "0.1", ",", "\n", "7", ":", "0.4", ",", "\n", "8", ":", "0.5", "}", ",", "\n", "4", ":", "{", "1", ":", "0.3", ",", "\n", "9", ":", "0.3", ",", "\n", "10", ":", "0.4", "}", ",", "\n", "5", ":", "{", "1", ":", "1.0", "}", ",", "\n", "6", ":", "{", "1", ":", "1.0", "}", ",", "\n", "7", ":", "{", "1", ":", "1.0", "}", ",", "\n", "8", ":", "{", "1", ":", "1.0", "}", ",", "\n", "9", ":", "{", "1", ":", "0.5", ",", "\n", "11", ":", "0.5", "}", ",", "\n", "10", ":", "{", "1", ":", "1.0", "}", ",", "\n", "11", ":", "{", "1", ":", "1.0", "}", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.feed_image": [[71, 74], ["numpy.zeros"], "methods", ["None"], ["", "def", "feed_image", "(", "self", ",", "sess", ",", "encoded_image", ")", ":", "\n", "# Return a nominal model state.", "\n", "    ", "return", "np", ".", "zeros", "(", "[", "1", ",", "self", ".", "_state_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.FakeModel.inference_step": [[75, 88], ["numpy.zeros", "enumerate", "numpy.zeros", "caption_generator_test.FakeModel._probabilities[].items"], "methods", ["None"], ["", "def", "inference_step", "(", "self", ",", "sess", ",", "input_feed", ",", "state_feed", ")", ":", "\n", "# Compute the matrix of softmax distributions for the next batch of words.", "\n", "    ", "batch_size", "=", "input_feed", ".", "shape", "[", "0", "]", "\n", "softmax_output", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_vocab_size", "]", ")", "\n", "for", "batch_index", ",", "word_id", "in", "enumerate", "(", "input_feed", ")", ":", "\n", "      ", "for", "next_word", ",", "probability", "in", "self", ".", "_probabilities", "[", "word_id", "]", ".", "items", "(", ")", ":", "\n", "        ", "softmax_output", "[", "batch_index", ",", "next_word", "]", "=", "probability", "\n", "\n", "# Nominal state and metadata.", "\n", "", "", "new_state", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_state_size", "]", ")", "\n", "metadata", "=", "None", "\n", "\n", "return", "softmax_output", ",", "new_state", ",", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions": [[94, 125], ["im2txt.inference_utils.caption_generator.CaptionGenerator", "im2txt.inference_utils.caption_generator.CaptionGenerator.beam_search", "caption_generator_test.CaptionGeneratorTest.assertEqual", "caption_generator_test.CaptionGeneratorTest.assertAllClose", "math.exp", "caption_generator_test.FakeModel", "caption_generator_test.FakeVocab"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.CaptionGenerator.beam_search"], ["  ", "def", "_assertExpectedCaptions", "(", "self", ",", "\n", "expected_captions", ",", "\n", "beam_size", "=", "3", ",", "\n", "max_caption_length", "=", "20", ",", "\n", "length_normalization_factor", "=", "0", ")", ":", "\n", "    ", "\"\"\"Tests that beam search generates the expected captions.\n\n    Args:\n      expected_captions: A sequence of pairs (sentence, probability), where\n        sentence is a list of integer ids and probability is a float in [0, 1].\n      beam_size: Parameter passed to beam_search().\n      max_caption_length: Parameter passed to beam_search().\n      length_normalization_factor: Parameter passed to beam_search().\n    \"\"\"", "\n", "expected_sentences", "=", "[", "c", "[", "0", "]", "for", "c", "in", "expected_captions", "]", "\n", "expected_probabilities", "=", "[", "c", "[", "1", "]", "for", "c", "in", "expected_captions", "]", "\n", "\n", "# Generate captions.", "\n", "generator", "=", "caption_generator", ".", "CaptionGenerator", "(", "\n", "model", "=", "FakeModel", "(", ")", ",", "\n", "vocab", "=", "FakeVocab", "(", ")", ",", "\n", "beam_size", "=", "beam_size", ",", "\n", "max_caption_length", "=", "max_caption_length", ",", "\n", "length_normalization_factor", "=", "length_normalization_factor", ")", "\n", "actual_captions", "=", "generator", ".", "beam_search", "(", "sess", "=", "None", ",", "encoded_image", "=", "None", ")", "\n", "\n", "actual_sentences", "=", "[", "c", ".", "sentence", "for", "c", "in", "actual_captions", "]", "\n", "actual_probabilities", "=", "[", "math", ".", "exp", "(", "c", ".", "logprob", ")", "for", "c", "in", "actual_captions", "]", "\n", "\n", "self", ".", "assertEqual", "(", "expected_sentences", ",", "actual_sentences", ")", "\n", "self", ".", "assertAllClose", "(", "expected_probabilities", ",", "actual_probabilities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest.testBeamSize": [[126, 140], ["caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions"], ["", "def", "testBeamSize", "(", "self", ")", ":", "\n", "# Beam size = 1.", "\n", "    ", "expected", "=", "[", "(", "[", "0", ",", "4", ",", "10", ",", "1", "]", ",", "0.16", ")", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "expected", ",", "beam_size", "=", "1", ")", "\n", "\n", "# Beam size = 2.", "\n", "expected", "=", "[", "(", "[", "0", ",", "4", ",", "10", ",", "1", "]", ",", "0.16", ")", ",", "(", "[", "0", ",", "3", ",", "8", ",", "1", "]", ",", "0.15", ")", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "expected", ",", "beam_size", "=", "2", ")", "\n", "\n", "# Beam size = 3.", "\n", "expected", "=", "[", "\n", "(", "[", "0", ",", "2", ",", "6", ",", "1", "]", ",", "0.18", ")", ",", "(", "[", "0", ",", "4", ",", "10", ",", "1", "]", ",", "0.16", ")", ",", "(", "[", "0", ",", "3", ",", "8", ",", "1", "]", ",", "0.15", ")", "\n", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "expected", ",", "beam_size", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest.testMaxLength": [[141, 162], ["caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions"], ["", "def", "testMaxLength", "(", "self", ")", ":", "\n", "# Max length = 1.", "\n", "    ", "expected", "=", "[", "(", "[", "0", "]", ",", "1.0", ")", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "expected", ",", "max_caption_length", "=", "1", ")", "\n", "\n", "# Max length = 2.", "\n", "# There are no complete sentences, so partial sentences are returned.", "\n", "expected", "=", "[", "(", "[", "0", ",", "4", "]", ",", "0.4", ")", ",", "(", "[", "0", ",", "3", "]", ",", "0.3", ")", ",", "(", "[", "0", ",", "2", "]", ",", "0.2", ")", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "expected", ",", "max_caption_length", "=", "2", ")", "\n", "\n", "# Max length = 3.", "\n", "# There is at least one complete sentence, so only complete sentences are", "\n", "# returned.", "\n", "expected", "=", "[", "(", "[", "0", ",", "4", ",", "1", "]", ",", "0.12", ")", ",", "(", "[", "0", ",", "3", ",", "1", "]", ",", "0.03", ")", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "expected", ",", "max_caption_length", "=", "3", ")", "\n", "\n", "# Max length = 4.", "\n", "expected", "=", "[", "\n", "(", "[", "0", ",", "2", ",", "6", ",", "1", "]", ",", "0.18", ")", ",", "(", "[", "0", ",", "4", ",", "10", ",", "1", "]", ",", "0.16", ")", ",", "(", "[", "0", ",", "3", ",", "8", ",", "1", "]", ",", "0.15", ")", "\n", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "expected", ",", "max_caption_length", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest.testLengthNormalization": [[163, 175], ["caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator_test.CaptionGeneratorTest._assertExpectedCaptions"], ["", "def", "testLengthNormalization", "(", "self", ")", ":", "\n", "# Length normalization factor = 3.", "\n", "# The longest caption is returned first, despite having low probability,", "\n", "# because it has the highest log(probability)/length**3.", "\n", "    ", "expected", "=", "[", "\n", "(", "[", "0", ",", "4", ",", "9", ",", "11", ",", "1", "]", ",", "0.06", ")", ",", "\n", "(", "[", "0", ",", "2", ",", "6", ",", "1", "]", ",", "0.18", ")", ",", "\n", "(", "[", "0", ",", "4", ",", "10", ",", "1", "]", ",", "0.16", ")", ",", "\n", "(", "[", "0", ",", "3", ",", "8", ",", "1", "]", ",", "0.15", ")", ",", "\n", "]", "\n", "self", ".", "_assertExpectedCaptions", "(", "\n", "expected", ",", "beam_size", "=", "4", ",", "length_normalization_factor", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test.setUp": [[30, 40], ["super().setUp", "tensorflow.placeholder"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "InceptionV3Test", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "batch_size", "=", "4", "\n", "height", "=", "299", "\n", "width", "=", "299", "\n", "num_channels", "=", "3", "\n", "self", ".", "_images", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "\n", "[", "batch_size", ",", "height", ",", "width", ",", "num_channels", "]", ")", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._countInceptionParameters": [[41, 52], ["tensorflow.global_variables", "v.op.name.split", "v.get_shape().num_elements", "counter.get", "v.get_shape"], "methods", ["None"], ["", "def", "_countInceptionParameters", "(", "self", ")", ":", "\n", "    ", "\"\"\"Counts the number of parameters in the inception model at top scope.\"\"\"", "\n", "counter", "=", "{", "}", "\n", "for", "v", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "      ", "name_tokens", "=", "v", ".", "op", ".", "name", ".", "split", "(", "\"/\"", ")", "\n", "if", "name_tokens", "[", "0", "]", "==", "\"InceptionV3\"", ":", "\n", "        ", "name", "=", "\"InceptionV3/\"", "+", "name_tokens", "[", "1", "]", "\n", "num_params", "=", "v", ".", "get_shape", "(", ")", ".", "num_elements", "(", ")", "\n", "assert", "num_params", "\n", "counter", "[", "name", "]", "=", "counter", ".", "get", "(", "name", ",", "0", ")", "+", "num_params", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._verifyParameterCounts": [[53, 75], ["image_embedding_test.InceptionV3Test._countInceptionParameters", "image_embedding_test.InceptionV3Test.assertDictEqual"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._countInceptionParameters"], ["", "def", "_verifyParameterCounts", "(", "self", ")", ":", "\n", "    ", "\"\"\"Verifies the number of parameters in the inception model.\"\"\"", "\n", "param_counts", "=", "self", ".", "_countInceptionParameters", "(", ")", "\n", "expected_param_counts", "=", "{", "\n", "\"InceptionV3/Conv2d_1a_3x3\"", ":", "960", ",", "\n", "\"InceptionV3/Conv2d_2a_3x3\"", ":", "9312", ",", "\n", "\"InceptionV3/Conv2d_2b_3x3\"", ":", "18624", ",", "\n", "\"InceptionV3/Conv2d_3b_1x1\"", ":", "5360", ",", "\n", "\"InceptionV3/Conv2d_4a_3x3\"", ":", "138816", ",", "\n", "\"InceptionV3/Mixed_5b\"", ":", "256368", ",", "\n", "\"InceptionV3/Mixed_5c\"", ":", "277968", ",", "\n", "\"InceptionV3/Mixed_5d\"", ":", "285648", ",", "\n", "\"InceptionV3/Mixed_6a\"", ":", "1153920", ",", "\n", "\"InceptionV3/Mixed_6b\"", ":", "1298944", ",", "\n", "\"InceptionV3/Mixed_6c\"", ":", "1692736", ",", "\n", "\"InceptionV3/Mixed_6d\"", ":", "1692736", ",", "\n", "\"InceptionV3/Mixed_6e\"", ":", "2143872", ",", "\n", "\"InceptionV3/Mixed_7a\"", ":", "1699584", ",", "\n", "\"InceptionV3/Mixed_7b\"", ":", "5047872", ",", "\n", "\"InceptionV3/Mixed_7c\"", ":", "6080064", ",", "\n", "}", "\n", "self", ".", "assertDictEqual", "(", "expected_param_counts", ",", "param_counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize": [[76, 81], ["len", "tensorflow.get_collection", "image_embedding_test.InceptionV3Test.fail"], "methods", ["None"], ["", "def", "_assertCollectionSize", "(", "self", ",", "expected_size", ",", "collection", ")", ":", "\n", "    ", "actual_size", "=", "len", "(", "tf", ".", "get_collection", "(", "collection", ")", ")", "\n", "if", "expected_size", "!=", "actual_size", ":", "\n", "      ", "self", ".", "fail", "(", "\"Found %d items in collection %s (expected %d).\"", "%", "\n", "(", "actual_size", ",", "collection", ",", "expected_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test.testTrainableTrueIsTrainingTrue": [[82, 94], ["im2txt.ops.image_embedding.inception_v3", "image_embedding_test.InceptionV3Test.assertEqual", "image_embedding_test.InceptionV3Test._verifyParameterCounts", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "im2txt.ops.image_embedding.inception_v3.get_shape().as_list", "im2txt.ops.image_embedding.inception_v3.get_shape"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding.inception_v3", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._verifyParameterCounts", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize"], ["", "", "def", "testTrainableTrueIsTrainingTrue", "(", "self", ")", ":", "\n", "    ", "embeddings", "=", "image_embedding", ".", "inception_v3", "(", "\n", "self", ".", "_images", ",", "trainable", "=", "True", ",", "is_training", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "[", "self", ".", "_batch_size", ",", "2048", "]", ",", "embeddings", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "\n", "self", ".", "_verifyParameterCounts", "(", ")", "\n", "self", ".", "_assertCollectionSize", "(", "376", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "188", ",", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "188", ",", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "_assertCollectionSize", "(", "94", ",", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "23", ",", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test.testTrainableTrueIsTrainingFalse": [[95, 107], ["im2txt.ops.image_embedding.inception_v3", "image_embedding_test.InceptionV3Test.assertEqual", "image_embedding_test.InceptionV3Test._verifyParameterCounts", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "im2txt.ops.image_embedding.inception_v3.get_shape().as_list", "im2txt.ops.image_embedding.inception_v3.get_shape"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding.inception_v3", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._verifyParameterCounts", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize"], ["", "def", "testTrainableTrueIsTrainingFalse", "(", "self", ")", ":", "\n", "    ", "embeddings", "=", "image_embedding", ".", "inception_v3", "(", "\n", "self", ".", "_images", ",", "trainable", "=", "True", ",", "is_training", "=", "False", ")", "\n", "self", ".", "assertEqual", "(", "[", "self", ".", "_batch_size", ",", "2048", "]", ",", "embeddings", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "\n", "self", ".", "_verifyParameterCounts", "(", ")", "\n", "self", ".", "_assertCollectionSize", "(", "376", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "188", ",", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "_assertCollectionSize", "(", "94", ",", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "23", ",", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test.testTrainableFalseIsTrainingTrue": [[108, 120], ["im2txt.ops.image_embedding.inception_v3", "image_embedding_test.InceptionV3Test.assertEqual", "image_embedding_test.InceptionV3Test._verifyParameterCounts", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "im2txt.ops.image_embedding.inception_v3.get_shape().as_list", "im2txt.ops.image_embedding.inception_v3.get_shape"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding.inception_v3", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._verifyParameterCounts", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize"], ["", "def", "testTrainableFalseIsTrainingTrue", "(", "self", ")", ":", "\n", "    ", "embeddings", "=", "image_embedding", ".", "inception_v3", "(", "\n", "self", ".", "_images", ",", "trainable", "=", "False", ",", "is_training", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "[", "self", ".", "_batch_size", ",", "2048", "]", ",", "embeddings", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "\n", "self", ".", "_verifyParameterCounts", "(", ")", "\n", "self", ".", "_assertCollectionSize", "(", "376", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "23", ",", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test.testTrainableFalseIsTrainingFalse": [[121, 133], ["im2txt.ops.image_embedding.inception_v3", "image_embedding_test.InceptionV3Test.assertEqual", "image_embedding_test.InceptionV3Test._verifyParameterCounts", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "image_embedding_test.InceptionV3Test._assertCollectionSize", "im2txt.ops.image_embedding.inception_v3.get_shape().as_list", "im2txt.ops.image_embedding.inception_v3.get_shape"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding.inception_v3", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._verifyParameterCounts", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding_test.InceptionV3Test._assertCollectionSize"], ["", "def", "testTrainableFalseIsTrainingFalse", "(", "self", ")", ":", "\n", "    ", "embeddings", "=", "image_embedding", ".", "inception_v3", "(", "\n", "self", ".", "_images", ",", "trainable", "=", "False", ",", "is_training", "=", "False", ")", "\n", "self", ".", "assertEqual", "(", "[", "self", ".", "_batch_size", ",", "2048", "]", ",", "embeddings", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "\n", "self", ".", "_verifyParameterCounts", "(", ")", "\n", "self", ".", "_assertCollectionSize", "(", "376", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "0", ",", "tf", ".", "GraphKeys", ".", "LOSSES", ")", "\n", "self", ".", "_assertCollectionSize", "(", "23", ",", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.inputs.parse_sequence_example": [[26, 52], ["tensorflow.parse_single_sequence_example", "tensorflow.FixedLenFeature", "tensorflow.FixedLenSequenceFeature"], "function", ["None"], ["def", "parse_sequence_example", "(", "serialized", ",", "image_feature", ",", "caption_feature", ")", ":", "\n", "  ", "\"\"\"Parses a tensorflow.SequenceExample into an image and caption.\n\n  Args:\n    serialized: A scalar string Tensor; a single serialized SequenceExample.\n    image_feature: Name of SequenceExample context feature containing image\n      data.\n    caption_feature: Name of SequenceExample feature list containing integer\n      captions.\n\n  Returns:\n    encoded_image: A scalar string Tensor containing a JPEG encoded image.\n    caption: A 1-D uint64 Tensor with dynamically specified length.\n  \"\"\"", "\n", "context", ",", "sequence", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized", ",", "\n", "context_features", "=", "{", "\n", "image_feature", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "}", ",", "\n", "sequence_features", "=", "{", "\n", "caption_feature", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "}", ")", "\n", "\n", "encoded_image", "=", "context", "[", "image_feature", "]", "\n", "caption", "=", "sequence", "[", "caption_feature", "]", "\n", "return", "encoded_image", ",", "caption", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.inputs.prefetch_input_data": [[54, 124], ["file_pattern.split", "range", "tensorflow.train.queue_runner.add_queue_runner", "tensorflow.summary.scalar", "data_files.extend", "tensorflow.logging.fatal", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.RandomShuffleQueue", "tensorflow.train.string_input_producer", "tensorflow.FIFOQueue", "reader.read", "enqueue_ops.append", "tensorflow.train.queue_runner.QueueRunner", "tensorflow.gfile.Glob", "len", "tf.FIFOQueue.enqueue", "tensorflow.cast", "tf.FIFOQueue.size"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.inference_utils.caption_generator.TopN.size"], ["", "def", "prefetch_input_data", "(", "reader", ",", "\n", "file_pattern", ",", "\n", "is_training", ",", "\n", "batch_size", ",", "\n", "values_per_shard", ",", "\n", "input_queue_capacity_factor", "=", "16", ",", "\n", "num_reader_threads", "=", "1", ",", "\n", "shard_queue_name", "=", "\"filename_queue\"", ",", "\n", "value_queue_name", "=", "\"input_queue\"", ")", ":", "\n", "  ", "\"\"\"Prefetches string values from disk into an input queue.\n\n  In training the capacity of the queue is important because a larger queue\n  means better mixing of training examples between shards. The minimum number of\n  values kept in the queue is values_per_shard * input_queue_capacity_factor,\n  where input_queue_memory factor should be chosen to trade-off better mixing\n  with memory usage.\n\n  Args:\n    reader: Instance of tf.ReaderBase.\n    file_pattern: Comma-separated list of file patterns (e.g.\n        /tmp/train_data-?????-of-00100).\n    is_training: Boolean; whether prefetching for training or eval.\n    batch_size: Model batch size used to determine queue capacity.\n    values_per_shard: Approximate number of values per shard.\n    input_queue_capacity_factor: Minimum number of values to keep in the queue\n      in multiples of values_per_shard. See comments above.\n    num_reader_threads: Number of reader threads to fill the queue.\n    shard_queue_name: Name for the shards filename queue.\n    value_queue_name: Name for the values input queue.\n\n  Returns:\n    A Queue containing prefetched string values.\n  \"\"\"", "\n", "data_files", "=", "[", "]", "\n", "for", "pattern", "in", "file_pattern", ".", "split", "(", "\",\"", ")", ":", "\n", "    ", "data_files", ".", "extend", "(", "tf", ".", "gfile", ".", "Glob", "(", "pattern", ")", ")", "\n", "", "if", "not", "data_files", ":", "\n", "    ", "tf", ".", "logging", ".", "fatal", "(", "\"Found no input files matching %s\"", ",", "file_pattern", ")", "\n", "", "else", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Prefetching values from %d files matching %s\"", ",", "\n", "len", "(", "data_files", ")", ",", "file_pattern", ")", "\n", "\n", "", "if", "is_training", ":", "\n", "    ", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "data_files", ",", "shuffle", "=", "True", ",", "capacity", "=", "16", ",", "name", "=", "shard_queue_name", ")", "\n", "min_queue_examples", "=", "values_per_shard", "*", "input_queue_capacity_factor", "\n", "capacity", "=", "min_queue_examples", "+", "100", "*", "batch_size", "\n", "values_queue", "=", "tf", ".", "RandomShuffleQueue", "(", "\n", "capacity", "=", "capacity", ",", "\n", "min_after_dequeue", "=", "min_queue_examples", ",", "\n", "dtypes", "=", "[", "tf", ".", "string", "]", ",", "\n", "name", "=", "\"random_\"", "+", "value_queue_name", ")", "\n", "", "else", ":", "\n", "    ", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "data_files", ",", "shuffle", "=", "False", ",", "capacity", "=", "1", ",", "name", "=", "shard_queue_name", ")", "\n", "capacity", "=", "values_per_shard", "+", "3", "*", "batch_size", "\n", "values_queue", "=", "tf", ".", "FIFOQueue", "(", "\n", "capacity", "=", "capacity", ",", "dtypes", "=", "[", "tf", ".", "string", "]", ",", "name", "=", "\"fifo_\"", "+", "value_queue_name", ")", "\n", "\n", "", "enqueue_ops", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_reader_threads", ")", ":", "\n", "    ", "_", ",", "value", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "enqueue_ops", ".", "append", "(", "values_queue", ".", "enqueue", "(", "[", "value", "]", ")", ")", "\n", "", "tf", ".", "train", ".", "queue_runner", ".", "add_queue_runner", "(", "tf", ".", "train", ".", "queue_runner", ".", "QueueRunner", "(", "\n", "values_queue", ",", "enqueue_ops", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\n", "\"queue/%s/fraction_of_%d_full\"", "%", "(", "values_queue", ".", "name", ",", "capacity", ")", ",", "\n", "tf", ".", "cast", "(", "values_queue", ".", "size", "(", ")", ",", "tf", ".", "float32", ")", "*", "(", "1.", "/", "capacity", ")", ")", "\n", "\n", "return", "values_queue", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.inputs.batch_with_dynamic_pad": [[126, 205], ["tensorflow.train.batch_join", "tensorflow.expand_dims", "tensorflow.slice", "tensorflow.slice", "tensorflow.ones", "enqueue_list.append", "tensorflow.add", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.shape", "tensorflow.subtract", "tensorflow.reduce_sum", "tensorflow.reduce_min", "tensorflow.reduce_max", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "batch_with_dynamic_pad", "(", "images_and_captions", ",", "\n", "batch_size", ",", "\n", "queue_capacity", ",", "\n", "add_summaries", "=", "True", ")", ":", "\n", "  ", "\"\"\"Batches input images and captions.\n\n  This function splits the caption into an input sequence and a target sequence,\n  where the target sequence is the input sequence right-shifted by 1. Input and\n  target sequences are batched and padded up to the maximum length of sequences\n  in the batch. A mask is created to distinguish real words from padding words.\n\n  Example:\n    Actual captions in the batch ('-' denotes padded character):\n      [\n        [ 1 2 3 4 5 ],\n        [ 1 2 3 4 - ],\n        [ 1 2 3 - - ],\n      ]\n\n    input_seqs:\n      [\n        [ 1 2 3 4 ],\n        [ 1 2 3 - ],\n        [ 1 2 - - ],\n      ]\n\n    target_seqs:\n      [\n        [ 2 3 4 5 ],\n        [ 2 3 4 - ],\n        [ 2 3 - - ],\n      ]\n\n    mask:\n      [\n        [ 1 1 1 1 ],\n        [ 1 1 1 0 ],\n        [ 1 1 0 0 ],\n      ]\n\n  Args:\n    images_and_captions: A list of pairs [image, caption], where image is a\n      Tensor of shape [height, width, channels] and caption is a 1-D Tensor of\n      any length. Each pair will be processed and added to the queue in a\n      separate thread.\n    batch_size: Batch size.\n    queue_capacity: Queue capacity.\n    add_summaries: If true, add caption length summaries.\n\n  Returns:\n    images: A Tensor of shape [batch_size, height, width, channels].\n    input_seqs: An int32 Tensor of shape [batch_size, padded_length].\n    target_seqs: An int32 Tensor of shape [batch_size, padded_length].\n    mask: An int32 0/1 Tensor of shape [batch_size, padded_length].\n  \"\"\"", "\n", "enqueue_list", "=", "[", "]", "\n", "for", "image", ",", "caption", "in", "images_and_captions", ":", "\n", "    ", "caption_length", "=", "tf", ".", "shape", "(", "caption", ")", "[", "0", "]", "\n", "input_length", "=", "tf", ".", "expand_dims", "(", "tf", ".", "subtract", "(", "caption_length", ",", "1", ")", ",", "0", ")", "\n", "\n", "input_seq", "=", "tf", ".", "slice", "(", "caption", ",", "[", "0", "]", ",", "input_length", ")", "\n", "target_seq", "=", "tf", ".", "slice", "(", "caption", ",", "[", "1", "]", ",", "input_length", ")", "\n", "indicator", "=", "tf", ".", "ones", "(", "input_length", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "enqueue_list", ".", "append", "(", "[", "image", ",", "input_seq", ",", "target_seq", ",", "indicator", "]", ")", "\n", "\n", "", "images", ",", "input_seqs", ",", "target_seqs", ",", "mask", "=", "tf", ".", "train", ".", "batch_join", "(", "\n", "enqueue_list", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "queue_capacity", ",", "\n", "dynamic_pad", "=", "True", ",", "\n", "name", "=", "\"batch_and_pad\"", ")", "\n", "\n", "if", "add_summaries", ":", "\n", "    ", "lengths", "=", "tf", ".", "add", "(", "tf", ".", "reduce_sum", "(", "mask", ",", "1", ")", ",", "1", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"caption_length/batch_min\"", ",", "tf", ".", "reduce_min", "(", "lengths", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"caption_length/batch_max\"", ",", "tf", ".", "reduce_max", "(", "lengths", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"caption_length/batch_mean\"", ",", "tf", ".", "reduce_mean", "(", "lengths", ")", ")", "\n", "\n", "", "return", "images", ",", "input_seqs", ",", "target_seqs", ",", "mask", "\n", "", ""]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_embedding.inception_v3": [[30, 115], ["tensorflow.contrib.layers.l2_regularizer", "tensorflow.variable_scope", "end_points.values", "slim.arg_scope", "tensorflow.contrib.layers.summaries.summarize_activation", "slim.arg_scope", "tensorflow.contrib.slim.python.slim.nets.inception_v3.inception_v3_base", "tensorflow.variable_scope", "slim.flatten.get_shape", "slim.avg_pool2d", "slim.dropout", "slim.flatten", "tensorflow.truncated_normal_initializer"], "function", ["None"], ["def", "inception_v3", "(", "images", ",", "\n", "trainable", "=", "True", ",", "\n", "is_training", "=", "True", ",", "\n", "weight_decay", "=", "0.00004", ",", "\n", "stddev", "=", "0.1", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "use_batch_norm", "=", "True", ",", "\n", "batch_norm_params", "=", "None", ",", "\n", "add_summaries", "=", "True", ",", "\n", "scope", "=", "\"InceptionV3\"", ")", ":", "\n", "  ", "\"\"\"Builds an Inception V3 subgraph for image embeddings.\n\n  Args:\n    images: A float32 Tensor of shape [batch, height, width, channels].\n    trainable: Whether the inception submodel should be trainable or not.\n    is_training: Boolean indicating training mode or not.\n    weight_decay: Coefficient for weight regularization.\n    stddev: The standard deviation of the trunctated normal weight initializer.\n    dropout_keep_prob: Dropout keep probability.\n    use_batch_norm: Whether to use batch normalization.\n    batch_norm_params: Parameters for batch normalization. See\n      tf.contrib.layers.batch_norm for details.\n    add_summaries: Whether to add activation summaries.\n    scope: Optional Variable scope.\n\n  Returns:\n    end_points: A dictionary of activations from inception_v3 layers.\n  \"\"\"", "\n", "# Only consider the inception model to be in training mode if it's trainable.", "\n", "is_inception_model_training", "=", "trainable", "and", "is_training", "\n", "\n", "if", "use_batch_norm", ":", "\n", "# Default parameters for batch normalization.", "\n", "    ", "if", "not", "batch_norm_params", ":", "\n", "      ", "batch_norm_params", "=", "{", "\n", "\"is_training\"", ":", "is_inception_model_training", ",", "\n", "\"trainable\"", ":", "trainable", ",", "\n", "# Decay for the moving averages.", "\n", "\"decay\"", ":", "0.9997", ",", "\n", "# Epsilon to prevent 0s in variance.", "\n", "\"epsilon\"", ":", "0.001", ",", "\n", "# Collection containing the moving mean and moving variance.", "\n", "\"variables_collections\"", ":", "{", "\n", "\"beta\"", ":", "None", ",", "\n", "\"gamma\"", ":", "None", ",", "\n", "\"moving_mean\"", ":", "[", "\"moving_vars\"", "]", ",", "\n", "\"moving_variance\"", ":", "[", "\"moving_vars\"", "]", ",", "\n", "}", "\n", "}", "\n", "", "", "else", ":", "\n", "    ", "batch_norm_params", "=", "None", "\n", "\n", "", "if", "trainable", ":", "\n", "    ", "weights_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "", "else", ":", "\n", "    ", "weights_regularizer", "=", "None", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "\"InceptionV3\"", ",", "[", "images", "]", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_regularizer", "=", "weights_regularizer", ",", "\n", "trainable", "=", "trainable", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "stddev", ")", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "normalizer_params", "=", "batch_norm_params", ")", ":", "\n", "        ", "net", ",", "end_points", "=", "inception_v3_base", "(", "images", ",", "scope", "=", "scope", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"logits\"", ")", ":", "\n", "          ", "shape", "=", "net", ".", "get_shape", "(", ")", "\n", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "shape", "[", "1", ":", "3", "]", ",", "padding", "=", "\"VALID\"", ",", "scope", "=", "\"pool\"", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "\n", "net", ",", "\n", "keep_prob", "=", "dropout_keep_prob", ",", "\n", "is_training", "=", "is_inception_model_training", ",", "\n", "scope", "=", "\"dropout\"", ")", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ",", "scope", "=", "\"flatten\"", ")", "\n", "\n", "# Add summaries.", "\n", "", "", "", "", "if", "add_summaries", ":", "\n", "    ", "for", "v", "in", "end_points", ".", "values", "(", ")", ":", "\n", "      ", "tf", ".", "contrib", ".", "layers", ".", "summaries", ".", "summarize_activation", "(", "v", ")", "\n", "\n", "", "", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.distort_image": [[26, 60], ["tensorflow.name_scope", "tensorflow.image.random_flip_left_right", "tensorflow.name_scope", "tensorflow.clip_by_value", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_hue", "tensorflow.image.random_contrast", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.random_saturation", "tensorflow.image.random_hue"], "function", ["None"], ["def", "distort_image", "(", "image", ",", "thread_id", ")", ":", "\n", "  ", "\"\"\"Perform random distortions on an image.\n\n  Args:\n    image: A float32 Tensor of shape [height, width, 3] with values in [0, 1).\n    thread_id: Preprocessing thread id used to select the ordering of color\n      distortions. There should be a multiple of 2 preprocessing threads.\n\n  Returns:\n    distorted_image: A float32 Tensor of shape [height, width, 3] with values in\n      [0, 1].\n  \"\"\"", "\n", "# Randomly flip horizontally.", "\n", "with", "tf", ".", "name_scope", "(", "\"flip_horizontal\"", ",", "values", "=", "[", "image", "]", ")", ":", "\n", "    ", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "\n", "# Randomly distort the colors based on thread id.", "\n", "", "color_ordering", "=", "thread_id", "%", "2", "\n", "with", "tf", ".", "name_scope", "(", "\"distort_color\"", ",", "values", "=", "[", "image", "]", ")", ":", "\n", "    ", "if", "color_ordering", "==", "0", ":", "\n", "      ", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.032", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "", "elif", "color_ordering", "==", "1", ":", "\n", "      ", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.032", ")", "\n", "\n", "# The random_* ops do not necessarily clamp.", "\n", "", "image", "=", "tf", ".", "clip_by_value", "(", "image", ",", "0.0", ",", "1.0", ")", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.ops.image_processing.process_image": [[62, 134], ["tensorflow.image.convert_image_dtype", "image_processing.process_image.image_summary"], "function", ["None"], ["", "def", "process_image", "(", "encoded_image", ",", "\n", "is_training", ",", "\n", "height", ",", "\n", "width", ",", "\n", "resize_height", "=", "346", ",", "\n", "resize_width", "=", "346", ",", "\n", "thread_id", "=", "0", ",", "\n", "image_format", "=", "\"jpeg\"", ")", ":", "\n", "  ", "\"\"\"Decode an image, resize and apply random distortions.\n\n  In training, images are distorted slightly differently depending on thread_id.\n\n  Args:\n    encoded_image: String Tensor containing the image.\n    is_training: Boolean; whether preprocessing for training or eval.\n    height: Height of the output image.\n    width: Width of the output image.\n    resize_height: If > 0, resize height before crop to final dimensions.\n    resize_width: If > 0, resize width before crop to final dimensions.\n    thread_id: Preprocessing thread id used to select the ordering of color\n      distortions. There should be a multiple of 2 preprocessing threads.\n    image_format: \"jpeg\" or \"png\".\n\n  Returns:\n    A float32 Tensor of shape [height, width, 3] with values in [-1, 1].\n\n  Raises:\n    ValueError: If image_format is invalid.\n  \"\"\"", "\n", "# Helper function to log an image summary to the visualizer. Summaries are", "\n", "# only logged in thread 0.", "\n", "def", "image_summary", "(", "name", ",", "image", ")", ":", "\n", "    ", "if", "not", "thread_id", ":", "\n", "      ", "tf", ".", "summary", ".", "image", "(", "name", ",", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", ")", "\n", "\n", "# Decode image into a float32 Tensor of shape [?, ?, 3] with values in [0, 1).", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"decode\"", ",", "values", "=", "[", "encoded_image", "]", ")", ":", "\n", "    ", "if", "image_format", "==", "\"jpeg\"", ":", "\n", "      ", "image", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "encoded_image", ",", "channels", "=", "3", ")", "\n", "", "elif", "image_format", "==", "\"png\"", ":", "\n", "      ", "image", "=", "tf", ".", "image", ".", "decode_png", "(", "encoded_image", ",", "channels", "=", "3", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Invalid image format: %s\"", "%", "image_format", ")", "\n", "", "", "image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "image_summary", "(", "\"original_image\"", ",", "image", ")", "\n", "\n", "# Resize image.", "\n", "assert", "(", "resize_height", ">", "0", ")", "==", "(", "resize_width", ">", "0", ")", "\n", "if", "resize_height", ":", "\n", "    ", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "\n", "size", "=", "[", "resize_height", ",", "resize_width", "]", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ")", "\n", "\n", "# Crop to final dimensions.", "\n", "", "if", "is_training", ":", "\n", "    ", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "height", ",", "width", ",", "3", "]", ")", "\n", "", "else", ":", "\n", "# Central crop, assuming resize_height > height, resize_width > width.", "\n", "    ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "height", ",", "width", ")", "\n", "\n", "", "image_summary", "(", "\"resized_image\"", ",", "image", ")", "\n", "\n", "# Randomly distort the image.", "\n", "if", "is_training", ":", "\n", "    ", "image", "=", "distort_image", "(", "image", ",", "thread_id", ")", "\n", "\n", "", "image_summary", "(", "\"final_image\"", ",", "image", ")", "\n", "\n", "# Rescale to [-1,1] instead of [0, 1]", "\n", "image", "=", "tf", ".", "subtract", "(", "image", ",", "0.5", ")", "\n", "image", "=", "tf", ".", "multiply", "(", "image", ",", "2.0", ")", "\n", "return", "image", "\n", "", ""]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.__init__": [[145, 154], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_id", ")", ":", "\n", "    ", "\"\"\"Initializes the vocabulary.\n\n    Args:\n      vocab: A dictionary of word to word_id.\n      unk_id: Id of the special 'unknown' word.\n    \"\"\"", "\n", "self", ".", "_vocab", "=", "vocab", "\n", "self", ".", "_unk_id", "=", "unk_id", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id": [[155, 161], ["None"], "methods", ["None"], ["", "def", "word_to_id", "(", "self", ",", "word", ")", ":", "\n", "    ", "\"\"\"Returns the integer id of a word string.\"\"\"", "\n", "if", "word", "in", "self", ".", "_vocab", ":", "\n", "      ", "return", "self", ".", "_vocab", "[", "word", "]", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "_unk_id", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.ImageDecoder.__init__": [[166, 173], ["tensorflow.Session", "tensorflow.placeholder", "tensorflow.image.decode_jpeg"], "methods", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.ImageDecoder.decode_jpeg"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Create a single TensorFlow Session for all image decoding calls.", "\n", "    ", "self", ".", "_sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "# TensorFlow ops for JPEG decoding.", "\n", "self", ".", "_encoded_jpeg", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ")", "\n", "self", ".", "_decode_jpeg", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "self", ".", "_encoded_jpeg", ",", "channels", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.ImageDecoder.decode_jpeg": [[174, 180], ["build_mscoco_data.ImageDecoder._sess.run", "len"], "methods", ["None"], ["", "def", "decode_jpeg", "(", "self", ",", "encoded_jpeg", ")", ":", "\n", "    ", "image", "=", "self", ".", "_sess", ".", "run", "(", "self", ".", "_decode_jpeg", ",", "\n", "feed_dict", "=", "{", "self", ".", "_encoded_jpeg", ":", "encoded_jpeg", "}", ")", "\n", "assert", "len", "(", "image", ".", "shape", ")", "==", "3", "\n", "assert", "image", ".", "shape", "[", "2", "]", "==", "3", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._int64_feature": [[182, 185], ["tensorflow.train.Feature", "tensorflow.train.Int64List"], "function", ["None"], ["", "", "def", "_int64_feature", "(", "value", ")", ":", "\n", "  ", "\"\"\"Wrapper for inserting an int64 Feature into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._bytes_feature": [[187, 192], ["tensorflow.train.Feature", "type", "value.encode.encode", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "_bytes_feature", "(", "value", ")", ":", "\n", "  ", "\"\"\"Wrapper for inserting a bytes Feature into a SequenceExample proto.\"\"\"", "\n", "if", "type", "(", "value", ")", "is", "str", ":", "\n", "    ", "value", "=", "value", ".", "encode", "(", ")", "\n", "", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._int64_feature_list": [[194, 197], ["tensorflow.train.FeatureList", "build_mscoco_data._int64_feature"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._int64_feature"], ["", "def", "_int64_feature_list", "(", "values", ")", ":", "\n", "  ", "\"\"\"Wrapper for inserting an int64 FeatureList into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "FeatureList", "(", "feature", "=", "[", "_int64_feature", "(", "v", ")", "for", "v", "in", "values", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._bytes_feature_list": [[199, 202], ["tensorflow.train.FeatureList", "build_mscoco_data._bytes_feature"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._bytes_feature"], ["", "def", "_bytes_feature_list", "(", "values", ")", ":", "\n", "  ", "\"\"\"Wrapper for inserting a bytes FeatureList into a SequenceExample proto.\"\"\"", "\n", "return", "tf", ".", "train", ".", "FeatureList", "(", "feature", "=", "[", "_bytes_feature", "(", "v", ")", "for", "v", "in", "values", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._to_sequence_example": [[204, 240], ["tensorflow.train.Features", "tensorflow.train.FeatureLists", "tensorflow.train.SequenceExample", "tensorflow.gfile.FastGFile", "f.read", "decoder.decode_jpeg", "len", "vocab.word_to_id", "print", "build_mscoco_data._int64_feature", "build_mscoco_data._bytes_feature", "build_mscoco_data._bytes_feature_list", "build_mscoco_data._int64_feature_list"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.ImageDecoder.decode_jpeg", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.Vocabulary.word_to_id", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._int64_feature", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._bytes_feature", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._bytes_feature_list", "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._int64_feature_list"], ["", "def", "_to_sequence_example", "(", "image", ",", "decoder", ",", "vocab", ")", ":", "\n", "  ", "\"\"\"Builds a SequenceExample proto for an image-caption pair.\n\n  Args:\n    image: An ImageMetadata object.\n    decoder: An ImageDecoder object.\n    vocab: A Vocabulary object.\n\n  Returns:\n    A SequenceExample proto.\n  \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "image", ".", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "    ", "encoded_image", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "try", ":", "\n", "    ", "decoder", ".", "decode_jpeg", "(", "encoded_image", ")", "\n", "", "except", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "AssertionError", ")", ":", "\n", "    ", "print", "(", "\"Skipping file with invalid JPEG data: %s\"", "%", "image", ".", "filename", ")", "\n", "return", "\n", "\n", "", "context", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "\"image/image_id\"", ":", "_int64_feature", "(", "image", ".", "image_id", ")", ",", "\n", "\"image/data\"", ":", "_bytes_feature", "(", "encoded_image", ")", ",", "\n", "}", ")", "\n", "\n", "assert", "len", "(", "image", ".", "captions", ")", "==", "1", "\n", "caption", "=", "image", ".", "captions", "[", "0", "]", "\n", "caption_ids", "=", "[", "vocab", ".", "word_to_id", "(", "word", ")", "for", "word", "in", "caption", "]", "\n", "feature_lists", "=", "tf", ".", "train", ".", "FeatureLists", "(", "feature_list", "=", "{", "\n", "\"image/caption\"", ":", "_bytes_feature_list", "(", "caption", ")", ",", "\n", "\"image/caption_ids\"", ":", "_int64_feature_list", "(", "caption_ids", ")", "\n", "}", ")", "\n", "sequence_example", "=", "tf", ".", "train", ".", "SequenceExample", "(", "\n", "context", "=", "context", ",", "feature_lists", "=", "feature_lists", ")", "\n", "\n", "return", "sequence_example", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._process_image_files": [[242, 299], ["len", "int", "numpy.linspace().astype", "range", "print", "sys.stdout.flush", "os.path.join", "tensorflow.python_io.TFRecordWriter", "numpy.arange", "tf.python_io.TFRecordWriter.close", "print", "sys.stdout.flush", "numpy.linspace", "build_mscoco_data._to_sequence_example", "tf.python_io.TFRecordWriter.write", "print", "sys.stdout.flush", "datetime.datetime.now", "_to_sequence_example.SerializeToString", "datetime.datetime.now", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._to_sequence_example"], ["", "def", "_process_image_files", "(", "thread_index", ",", "ranges", ",", "name", ",", "images", ",", "decoder", ",", "vocab", ",", "\n", "num_shards", ")", ":", "\n", "  ", "\"\"\"Processes and saves a subset of images as TFRecord files in one thread.\n\n  Args:\n    thread_index: Integer thread identifier within [0, len(ranges)].\n    ranges: A list of pairs of integers specifying the ranges of the dataset to\n      process in parallel.\n    name: Unique identifier specifying the dataset.\n    images: List of ImageMetadata.\n    decoder: An ImageDecoder object.\n    vocab: A Vocabulary object.\n    num_shards: Integer number of shards for the output files.\n  \"\"\"", "\n", "# Each thread produces N shards where N = num_shards / num_threads. For", "\n", "# instance, if num_shards = 128, and num_threads = 2, then the first thread", "\n", "# would produce shards [0, 64).", "\n", "num_threads", "=", "len", "(", "ranges", ")", "\n", "assert", "not", "num_shards", "%", "num_threads", "\n", "num_shards_per_batch", "=", "int", "(", "num_shards", "/", "num_threads", ")", "\n", "\n", "shard_ranges", "=", "np", ".", "linspace", "(", "ranges", "[", "thread_index", "]", "[", "0", "]", ",", "ranges", "[", "thread_index", "]", "[", "1", "]", ",", "\n", "num_shards_per_batch", "+", "1", ")", ".", "astype", "(", "int", ")", "\n", "num_images_in_thread", "=", "ranges", "[", "thread_index", "]", "[", "1", "]", "-", "ranges", "[", "thread_index", "]", "[", "0", "]", "\n", "\n", "counter", "=", "0", "\n", "for", "s", "in", "range", "(", "num_shards_per_batch", ")", ":", "\n", "# Generate a sharded version of the file name, e.g. 'train-00002-of-00010'", "\n", "    ", "shard", "=", "thread_index", "*", "num_shards_per_batch", "+", "s", "\n", "output_filename", "=", "\"%s-%.5d-of-%.5d\"", "%", "(", "name", ",", "shard", ",", "num_shards", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "output_filename", ")", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_file", ")", "\n", "\n", "shard_counter", "=", "0", "\n", "images_in_shard", "=", "np", ".", "arange", "(", "shard_ranges", "[", "s", "]", ",", "shard_ranges", "[", "s", "+", "1", "]", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "images_in_shard", ":", "\n", "      ", "image", "=", "images", "[", "i", "]", "\n", "\n", "sequence_example", "=", "_to_sequence_example", "(", "image", ",", "decoder", ",", "vocab", ")", "\n", "if", "sequence_example", "is", "not", "None", ":", "\n", "        ", "writer", ".", "write", "(", "sequence_example", ".", "SerializeToString", "(", ")", ")", "\n", "shard_counter", "+=", "1", "\n", "counter", "+=", "1", "\n", "\n", "", "if", "not", "counter", "%", "1000", ":", "\n", "        ", "print", "(", "\"%s [thread %d]: Processed %d of %d items in thread batch.\"", "%", "\n", "(", "datetime", ".", "now", "(", ")", ",", "thread_index", ",", "counter", ",", "num_images_in_thread", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"%s [thread %d]: Wrote %d image-caption pairs to %s\"", "%", "\n", "(", "datetime", ".", "now", "(", ")", ",", "thread_index", ",", "shard_counter", ",", "output_file", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "shard_counter", "=", "0", "\n", "", "print", "(", "\"%s [thread %d]: Wrote %d image-caption pairs to %d shards.\"", "%", "\n", "(", "datetime", ".", "now", "(", ")", ",", "thread_index", ",", "counter", ",", "num_shards_per_batch", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._process_dataset": [[301, 345], ["random.seed", "random.shuffle", "min", "numpy.linspace().astype", "range", "tensorflow.train.Coordinator", "build_mscoco_data.ImageDecoder", "print", "range", "tf.train.Coordinator.join", "print", "ImageMetadata", "ranges.append", "len", "threading.Thread", "threading.Thread.start", "threads.append", "numpy.linspace", "len", "len", "datetime.datetime.now", "len"], "function", ["None"], ["", "def", "_process_dataset", "(", "name", ",", "images", ",", "vocab", ",", "num_shards", ")", ":", "\n", "  ", "\"\"\"Processes a complete data set and saves it as a TFRecord.\n\n  Args:\n    name: Unique identifier specifying the dataset.\n    images: List of ImageMetadata.\n    vocab: A Vocabulary object.\n    num_shards: Integer number of shards for the output files.\n  \"\"\"", "\n", "# Break up each image into a separate entity for each caption.", "\n", "images", "=", "[", "ImageMetadata", "(", "image", ".", "image_id", ",", "image", ".", "filename", ",", "[", "caption", "]", ")", "\n", "for", "image", "in", "images", "for", "caption", "in", "image", ".", "captions", "]", "\n", "\n", "# Shuffle the ordering of images. Make the randomization repeatable.", "\n", "random", ".", "seed", "(", "12345", ")", "\n", "random", ".", "shuffle", "(", "images", ")", "\n", "\n", "# Break the images into num_threads batches. Batch i is defined as", "\n", "# images[ranges[i][0]:ranges[i][1]].", "\n", "num_threads", "=", "min", "(", "num_shards", ",", "FLAGS", ".", "num_threads", ")", "\n", "spacing", "=", "np", ".", "linspace", "(", "0", ",", "len", "(", "images", ")", ",", "num_threads", "+", "1", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "ranges", "=", "[", "]", "\n", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "spacing", ")", "-", "1", ")", ":", "\n", "    ", "ranges", ".", "append", "(", "[", "spacing", "[", "i", "]", ",", "spacing", "[", "i", "+", "1", "]", "]", ")", "\n", "\n", "# Create a mechanism for monitoring when all threads are finished.", "\n", "", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "\n", "# Create a utility for decoding JPEG images to run sanity checks.", "\n", "decoder", "=", "ImageDecoder", "(", ")", "\n", "\n", "# Launch a thread for each batch.", "\n", "print", "(", "\"Launching %d threads for spacings: %s\"", "%", "(", "num_threads", ",", "ranges", ")", ")", "\n", "for", "thread_index", "in", "range", "(", "len", "(", "ranges", ")", ")", ":", "\n", "    ", "args", "=", "(", "thread_index", ",", "ranges", ",", "name", ",", "images", ",", "decoder", ",", "vocab", ",", "num_shards", ")", "\n", "t", "=", "threading", ".", "Thread", "(", "target", "=", "_process_image_files", ",", "args", "=", "args", ")", "\n", "t", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "t", ")", "\n", "\n", "# Wait for all the threads to terminate.", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "print", "(", "\"%s: Finished processing all %d image-caption pairs in data set '%s'.\"", "%", "\n", "(", "datetime", ".", "now", "(", ")", ",", "len", "(", "images", ")", ",", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._create_vocab": [[347, 382], ["print", "collections.Counter", "print", "word_counts.sort", "print", "print", "len", "dict", "build_mscoco_data.Vocabulary", "collections.Counter.update", "len", "len", "tensorflow.gfile.FastGFile", "f.write", "list", "collections.Counter.items", "enumerate"], "function", ["None"], ["", "def", "_create_vocab", "(", "captions", ")", ":", "\n", "  ", "\"\"\"Creates the vocabulary of word to word_id.\n\n  The vocabulary is saved to disk in a text file of word counts. The id of each\n  word in the file is its corresponding 0-based line number.\n\n  Args:\n    captions: A list of lists of strings.\n\n  Returns:\n    A Vocabulary object.\n  \"\"\"", "\n", "print", "(", "\"Creating vocabulary.\"", ")", "\n", "counter", "=", "Counter", "(", ")", "\n", "for", "c", "in", "captions", ":", "\n", "    ", "counter", ".", "update", "(", "c", ")", "\n", "", "print", "(", "\"Total words:\"", ",", "len", "(", "counter", ")", ")", "\n", "\n", "# Filter uncommon words and sort by descending count.", "\n", "word_counts", "=", "[", "x", "for", "x", "in", "list", "(", "counter", ".", "items", "(", ")", ")", "if", "x", "[", "1", "]", ">=", "FLAGS", ".", "min_word_count", "]", "\n", "word_counts", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "\"Words in vocabulary:\"", ",", "len", "(", "word_counts", ")", ")", "\n", "\n", "# Write out the word counts file.", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "FLAGS", ".", "word_counts_output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "[", "\"%s %d\"", "%", "(", "w", ",", "c", ")", "for", "w", ",", "c", "in", "word_counts", "]", ")", ")", "\n", "", "print", "(", "\"Wrote vocabulary file:\"", ",", "FLAGS", ".", "word_counts_output_file", ")", "\n", "\n", "# Create the vocabulary dictionary.", "\n", "reverse_vocab", "=", "[", "x", "[", "0", "]", "for", "x", "in", "word_counts", "]", "\n", "unk_id", "=", "len", "(", "reverse_vocab", ")", "\n", "vocab_dict", "=", "dict", "(", "[", "(", "x", ",", "y", ")", "for", "(", "y", ",", "x", ")", "in", "enumerate", "(", "reverse_vocab", ")", "]", ")", "\n", "vocab", "=", "Vocabulary", "(", "vocab_dict", ",", "unk_id", ")", "\n", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._process_caption": [[384, 397], ["tokenized_caption.extend", "tokenized_caption.append", "nltk.tokenize.word_tokenize", "caption.lower"], "function", ["None"], ["", "def", "_process_caption", "(", "caption", ")", ":", "\n", "  ", "\"\"\"Processes a caption string into a list of tonenized words.\n\n  Args:\n    caption: A string caption.\n\n  Returns:\n    A list of strings; the tokenized caption.\n  \"\"\"", "\n", "tokenized_caption", "=", "[", "FLAGS", ".", "start_word", "]", "\n", "tokenized_caption", ".", "extend", "(", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "caption", ".", "lower", "(", ")", ")", ")", "\n", "tokenized_caption", ".", "append", "(", "FLAGS", ".", "end_word", ")", "\n", "return", "tokenized_caption", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._load_and_process_metadata": [[399, 441], ["print", "print", "print", "tensorflow.gfile.FastGFile", "json.load", "id_to_captions.setdefault", "id_to_captions[].append", "len", "len", "set", "set", "os.path.join", "image_metadata.append", "len", "id_to_captions.keys", "build_mscoco_data._process_caption", "ImageMetadata", "len", "len"], "function", ["home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data._process_caption"], ["", "def", "_load_and_process_metadata", "(", "captions_file", ",", "image_dir", ")", ":", "\n", "  ", "\"\"\"Loads image metadata from a JSON file and processes the captions.\n\n  Args:\n    captions_file: JSON file containing caption annotations.\n    image_dir: Directory containing the image files.\n\n  Returns:\n    A list of ImageMetadata.\n  \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "captions_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "caption_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# Extract the filenames.", "\n", "", "id_to_filename", "=", "[", "(", "x", "[", "\"id\"", "]", ",", "x", "[", "\"file_name\"", "]", ")", "for", "x", "in", "caption_data", "[", "\"images\"", "]", "]", "\n", "\n", "# Extract the captions. Each image_id is associated with multiple captions.", "\n", "id_to_captions", "=", "{", "}", "\n", "for", "annotation", "in", "caption_data", "[", "\"annotations\"", "]", ":", "\n", "    ", "image_id", "=", "annotation", "[", "\"image_id\"", "]", "\n", "caption", "=", "annotation", "[", "\"caption\"", "]", "\n", "id_to_captions", ".", "setdefault", "(", "image_id", ",", "[", "]", ")", "\n", "id_to_captions", "[", "image_id", "]", ".", "append", "(", "caption", ")", "\n", "\n", "", "assert", "len", "(", "id_to_filename", ")", "==", "len", "(", "id_to_captions", ")", "\n", "assert", "set", "(", "[", "x", "[", "0", "]", "for", "x", "in", "id_to_filename", "]", ")", "==", "set", "(", "id_to_captions", ".", "keys", "(", ")", ")", "\n", "print", "(", "\"Loaded caption metadata for %d images from %s\"", "%", "\n", "(", "len", "(", "id_to_filename", ")", ",", "captions_file", ")", ")", "\n", "\n", "# Process the captions and combine the data into a list of ImageMetadata.", "\n", "print", "(", "\"Processing captions.\"", ")", "\n", "image_metadata", "=", "[", "]", "\n", "num_captions", "=", "0", "\n", "for", "image_id", ",", "base_filename", "in", "id_to_filename", ":", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "base_filename", ")", "\n", "captions", "=", "[", "_process_caption", "(", "c", ")", "for", "c", "in", "id_to_captions", "[", "image_id", "]", "]", "\n", "image_metadata", ".", "append", "(", "ImageMetadata", "(", "image_id", ",", "filename", ",", "captions", ")", ")", "\n", "num_captions", "+=", "len", "(", "captions", ")", "\n", "", "print", "(", "\"Finished processing %d captions for %d images in %s\"", "%", "\n", "(", "num_captions", ",", "len", "(", "id_to_filename", ")", ",", "captions_file", ")", ")", "\n", "\n", "return", "image_metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.huanzhang12_ImageCaptioningAttack.data.build_mscoco_data.main": [[443, 481], ["build_mscoco_data.main._is_valid_num_shards"], "function", ["None"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "def", "_is_valid_num_shards", "(", "num_shards", ")", ":", "\n", "    ", "\"\"\"Returns True if num_shards is compatible with FLAGS.num_threads.\"\"\"", "\n", "return", "num_shards", "<", "FLAGS", ".", "num_threads", "or", "not", "num_shards", "%", "FLAGS", ".", "num_threads", "\n", "\n", "", "assert", "_is_valid_num_shards", "(", "FLAGS", ".", "train_shards", ")", ",", "(", "\n", "\"Please make the FLAGS.num_threads commensurate with FLAGS.train_shards\"", ")", "\n", "assert", "_is_valid_num_shards", "(", "FLAGS", ".", "val_shards", ")", ",", "(", "\n", "\"Please make the FLAGS.num_threads commensurate with FLAGS.val_shards\"", ")", "\n", "assert", "_is_valid_num_shards", "(", "FLAGS", ".", "test_shards", ")", ",", "(", "\n", "\"Please make the FLAGS.num_threads commensurate with FLAGS.test_shards\"", ")", "\n", "\n", "if", "not", "tf", ".", "gfile", ".", "IsDirectory", "(", "FLAGS", ".", "output_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "FLAGS", ".", "output_dir", ")", "\n", "\n", "# Load image metadata from caption files.", "\n", "", "mscoco_train_dataset", "=", "_load_and_process_metadata", "(", "FLAGS", ".", "train_captions_file", ",", "\n", "FLAGS", ".", "train_image_dir", ")", "\n", "mscoco_val_dataset", "=", "_load_and_process_metadata", "(", "FLAGS", ".", "val_captions_file", ",", "\n", "FLAGS", ".", "val_image_dir", ")", "\n", "\n", "# Redistribute the MSCOCO data as follows:", "\n", "#   train_dataset = 100% of mscoco_train_dataset + 85% of mscoco_val_dataset.", "\n", "#   val_dataset = 5% of mscoco_val_dataset (for validation during training).", "\n", "#   test_dataset = 10% of mscoco_val_dataset (for final evaluation).", "\n", "train_cutoff", "=", "int", "(", "0.85", "*", "len", "(", "mscoco_val_dataset", ")", ")", "\n", "val_cutoff", "=", "int", "(", "0.90", "*", "len", "(", "mscoco_val_dataset", ")", ")", "\n", "train_dataset", "=", "mscoco_train_dataset", "+", "mscoco_val_dataset", "[", "0", ":", "train_cutoff", "]", "\n", "val_dataset", "=", "mscoco_val_dataset", "[", "train_cutoff", ":", "val_cutoff", "]", "\n", "test_dataset", "=", "mscoco_val_dataset", "[", "val_cutoff", ":", "]", "\n", "\n", "# Create vocabulary from the training captions.", "\n", "train_captions", "=", "[", "c", "for", "image", "in", "train_dataset", "for", "c", "in", "image", ".", "captions", "]", "\n", "vocab", "=", "_create_vocab", "(", "train_captions", ")", "\n", "\n", "_process_dataset", "(", "\"train\"", ",", "train_dataset", ",", "vocab", ",", "FLAGS", ".", "train_shards", ")", "\n", "_process_dataset", "(", "\"val\"", ",", "val_dataset", ",", "vocab", ",", "FLAGS", ".", "val_shards", ")", "\n", "_process_dataset", "(", "\"test\"", ",", "test_dataset", ",", "vocab", ",", "FLAGS", ".", "test_shards", ")", "\n", "\n"]]}