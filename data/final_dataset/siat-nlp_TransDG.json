{"home.repos.pwc.inspect_result.siat-nlp_TransDG.src.main.main": [[52, 173], ["tensorflow.ConfigProto", "tensorflow.Graph", "tensorflow.Session", "tf.train.Saver.restore", "src.dataset.knowledge_loader.KnowledgeLoader", "src.dataset.knowledge_loader.KnowledgeLoader.load_vocab", "src.dataset.knowledge_loader.KnowledgeLoader.load_entity_relation", "src.dataset.knowledge_loader.KnowledgeLoader.load_csk_entities", "tensorflow.Graph", "tensorflow.Session", "os.path.exists", "os.makedirs", "open", "json.load", "tf.Graph.as_default", "src.kbqa.model.kbqa_model.KbqaModel", "tensorflow.train.Saver", "open", "pickle.load", "tf.Graph.as_default", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.get_checkpoint_state", "src.dataset.data_batcher.DataBatcher", "print", "src.dataset.data_loader.DataLoader", "src.dataset.data_loader.DataLoader.load_data", "src.utils.trainer.Trainer", "range", "print", "tf.train.Saver.restore", "src.dataset.data_loader.DataLoader", "src.dataset.data_loader.DataLoader.load_data", "src.utils.generator.Generator", "src.utils.generator.Generator.generate", "tensorflow.GPUOptions", "len", "src.model.model_multistep.TransDGModelMultistep", "src.model.model.TransDGModel", "tensorflow.train.latest_checkpoint", "print", "tf.train.Saver.restore", "print", "open", "src.dataset.data_batcher.DataBatcher.full", "time.sleep", "print", "print", "src.utils.trainer.Trainer.train", "open", "json.loads", "pickle.load.keys", "tf.Graph.as_default", "tf.Session.run", "src.model.model.TransDGModel.set_vocabs", "train_chunk_list.append", "f.readline", "tensorflow.global_variables_initializer", "src.model.model.TransDGModel.show_parameters", "line.strip"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.knowledge_loader.KnowledgeLoader.load_vocab", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.knowledge_loader.KnowledgeLoader.load_entity_relation", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_csk_entities", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.load_data", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.load_data", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.generator.Generator.generate", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.full", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.trainer.Trainer.train", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.set_vocabs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.show_parameters"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "args", ".", "allow_soft_placement", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "args", ".", "allow_gpu_growth", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ")", "\n", "\n", "# load transferred model params", "\n", "", "config_path", "=", "\"%s/config.json\"", "%", "args", ".", "model_dir", "\n", "with", "open", "(", "config_path", ",", "'r'", ")", "as", "fr", ":", "\n", "        ", "kbqa_model_config", "=", "json", ".", "load", "(", "fr", ")", "\n", "\n", "", "trans_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "trans_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "kbqa_model", "=", "KbqaModel", "(", "**", "kbqa_model_config", ")", "\n", "trans_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "", "trans_sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ",", "graph", "=", "trans_graph", ")", "\n", "model_path", "=", "'%s/model_best/best.model'", "%", "args", ".", "model_dir", "\n", "trans_saver", ".", "restore", "(", "trans_sess", ",", "save_path", "=", "model_path", ")", "\n", "param_path", "=", "'%s/detail/param.best.pkl'", "%", "args", ".", "model_dir", "\n", "\n", "with", "open", "(", "param_path", ",", "'rb'", ")", "as", "fr", ":", "\n", "        ", "param_dict", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "if", "len", "(", "param_dict", ".", "keys", "(", ")", ")", "==", "1", ":", "\n", "            ", "feed_parm", "=", "{", "'bilinear_mat'", ":", "param_dict", "[", "'rm_task/rm_forward/bilinear_mat'", "]", "}", "\n", "", "else", ":", "\n", "            ", "feed_parm", "=", "{", "'fc1_weights'", ":", "param_dict", "[", "'rm_task/rm_forward/fc1/weights'", "]", ",", "\n", "'fc1_biases'", ":", "param_dict", "[", "'rm_task/rm_forward/fc1/biases'", "]", ",", "\n", "'fc2_weights'", ":", "param_dict", "[", "'rm_task/rm_forward/fc2/weights'", "]", ",", "\n", "'fc2_biases'", ":", "param_dict", "[", "'rm_task/rm_forward/fc2/biases'", "]", "}", "\n", "\n", "\n", "# load knowledge", "\n", "", "", "kd_loader", "=", "KnowledgeLoader", "(", "args", ".", "kd_dir", ")", "\n", "word_vocab", ",", "word_embed", "=", "kd_loader", ".", "load_vocab", "(", "vocab_size", "=", "args", ".", "vocab_size", ",", "embed_dim", "=", "args", ".", "dim_emb", ")", "\n", "kd_vocab", ",", "kd_embed", "=", "kd_loader", ".", "load_entity_relation", "(", ")", "\n", "csk_entity_list", "=", "kd_loader", ".", "load_csk_entities", "(", ")", "\n", "\n", "main_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "main_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "use_trans_repr", "=", "False", "if", "args", ".", "no_trans_repr", "else", "True", "\n", "use_trans_select", "=", "False", "if", "args", ".", "no_trans_select", "else", "True", "\n", "use_guiding", "=", "False", "if", "args", ".", "no_use_guiding", "else", "True", "\n", "if", "args", ".", "multi_step", ":", "\n", "            ", "model", "=", "TransDGModelMultistep", "(", "word_embed", ",", "kd_embed", ",", "feed_parm", ",", "\n", "use_trans_repr", "=", "use_trans_repr", ",", "use_trans_select", "=", "use_trans_select", ",", "\n", "use_guiding", "=", "use_guiding", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "dim_emb", "=", "args", ".", "dim_emb", ",", "dim_trans", "=", "args", ".", "dim_trans", ",", "\n", "cell_class", "=", "args", ".", "cell_class", ",", "num_units", "=", "args", ".", "num_units", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "max_length", "=", "args", ".", "max_dec_len", ",", "lr_rate", "=", "args", ".", "lr_rate", ",", "\n", "max_grad_norm", "=", "args", ".", "max_grad_norm", ",", "drop_rate", "=", "args", ".", "drop_rate", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "TransDGModel", "(", "word_embed", ",", "kd_embed", ",", "feed_parm", ",", "\n", "use_trans_repr", "=", "use_trans_repr", ",", "use_trans_select", "=", "use_trans_select", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "dim_emb", "=", "args", ".", "dim_emb", ",", "dim_trans", "=", "args", ".", "dim_trans", ",", "\n", "cell_class", "=", "args", ".", "cell_class", ",", "num_units", "=", "args", ".", "num_units", ",", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "max_length", "=", "args", ".", "max_dec_len", ",", "lr_rate", "=", "args", ".", "lr_rate", ",", "\n", "max_grad_norm", "=", "args", ".", "max_grad_norm", ",", "drop_rate", "=", "args", ".", "drop_rate", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "5", ")", "\n", "best_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ",", "graph", "=", "main_graph", ")", "\n", "\n", "if", "args", ".", "mode", "==", "'train'", ":", "\n", "        ", "if", "tf", ".", "train", ".", "get_checkpoint_state", "(", "\"%s/models\"", "%", "args", ".", "log_dir", ")", ":", "\n", "            ", "model_path", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "\"%s/models\"", "%", "args", ".", "log_dir", ")", "\n", "print", "(", "\"model restored from [%s]\"", "%", "model_path", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "model_path", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"create model with init parameters...\"", ")", "\n", "with", "main_graph", ".", "as_default", "(", ")", ":", "\n", "                ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "model", ".", "set_vocabs", "(", "sess", ",", "word_vocab", ",", "kd_vocab", ")", "\n", "if", "args", ".", "verbose", ">", "0", ":", "\n", "                    ", "model", ".", "show_parameters", "(", ")", "\n", "\n", "", "", "", "train_chunk_list", "=", "[", "]", "\n", "with", "open", "(", "\"%s/all_list\"", "%", "args", ".", "data_dir", ",", "'r'", ")", "as", "fr", ":", "\n", "            ", "for", "line", "in", "fr", ":", "\n", "                ", "train_chunk_list", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "train_batcher", "=", "DataBatcher", "(", "data_dir", "=", "args", ".", "data_dir", ",", "file_list", "=", "train_chunk_list", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "num_epoch", "=", "args", ".", "max_epoch", ",", "shuffle", "=", "True", ")", "\n", "# wait for train_batcher queue caching", "\n", "print", "(", "\"Loading data from [%s/all_list]\"", "%", "args", ".", "data_dir", ")", "\n", "while", "not", "train_batcher", ".", "full", "(", ")", ":", "\n", "            ", "time", ".", "sleep", "(", "5", ")", "\n", "print", "(", "\"loader queue caching...\"", ")", "\n", "\n", "", "valid_loader", "=", "DataLoader", "(", "batch_size", "=", "args", ".", "batch_size", ")", "\n", "valid_path", "=", "\"%s/valid.pkl\"", "%", "args", ".", "data_dir", "\n", "valid_loader", ".", "load_data", "(", "file_path", "=", "valid_path", ")", "\n", "\n", "# train model", "\n", "trainer", "=", "Trainer", "(", "model", "=", "model", ",", "sess", "=", "sess", ",", "trans_model", "=", "kbqa_model", ",", "trans_sess", "=", "trans_sess", ",", "\n", "saver", "=", "saver", ",", "best_saver", "=", "best_saver", ",", "log_dir", "=", "args", ".", "log_dir", ",", "save_per_step", "=", "args", ".", "save_per_step", ")", "\n", "\n", "for", "epoch_idx", "in", "range", "(", "args", ".", "max_epoch", ")", ":", "\n", "            ", "print", "(", "\"Epoch %d:\"", "%", "(", "epoch_idx", "+", "1", ")", ")", "\n", "trainer", ".", "train", "(", "train_batcher", ",", "valid_loader", ",", "epoch_idx", "=", "epoch_idx", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "args", ".", "ckpt", "==", "'best.model'", ":", "\n", "            ", "model_path", "=", "\"%s/models/best_model/best.model\"", "%", "args", ".", "log_dir", "\n", "", "else", ":", "\n", "            ", "model_path", "=", "\"%s/models/model-%s\"", "%", "(", "args", ".", "log_dir", ",", "args", ".", "ckpt", ")", "\n", "", "print", "(", "\"model restored from [%s]\"", "%", "model_path", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "model_path", ")", "\n", "\n", "test_loader", "=", "DataLoader", "(", "batch_size", "=", "args", ".", "batch_size", ")", "\n", "test_path", "=", "\"%s/test.pkl\"", "%", "args", ".", "data_dir", "\n", "test_loader", ".", "load_data", "(", "file_path", "=", "test_path", ")", "\n", "\n", "with", "open", "(", "'%s/stopwords'", "%", "args", ".", "kd_dir", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "stop_words", "=", "json", ".", "loads", "(", "f", ".", "readline", "(", ")", ")", "\n", "\n", "# test model on test set", "\n", "", "generator", "=", "Generator", "(", "model", "=", "model", ",", "sess", "=", "sess", ",", "trans_model", "=", "kbqa_model", ",", "trans_sess", "=", "trans_sess", ",", "\n", "log_dir", "=", "args", ".", "log_dir", ",", "ckpt", "=", "args", ".", "ckpt", ",", "stop_words", "=", "stop_words", ",", "csk_entities", "=", "csk_entity_list", ")", "\n", "generator", ".", "generate", "(", "test_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader.load_data": [[15, 34], ["open", "enumerate", "open", "open", "data_train.append", "data_dev.append", "data_test.append", "json.loads", "print", "json.loads", "json.loads"], "function", ["None"], ["def", "load_data", "(", "data_dir", ",", "is_train", "=", "False", ")", ":", "\n", "    ", "data_train", ",", "data_dev", ",", "data_test", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "is_train", ":", "\n", "        ", "with", "open", "(", "'%s/train.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "data_train", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "if", "idx", ">", "0", "and", "idx", "%", "100000", "==", "0", ":", "\n", "                    ", "print", "(", "'read train file line %d'", "%", "idx", ")", "\n", "", "", "", "with", "open", "(", "'%s/valid.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "data_dev", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "'%s/test.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "data_test", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "", "if", "is_train", ":", "\n", "        ", "return", "data_train", ",", "data_dev", "\n", "", "else", ":", "\n", "        ", "return", "data_test", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader.load_trans_data": [[36, 72], ["list", "print", "print", "range", "str", "numpy.array", "numpy.array", "open", "pickle.load", "open", "pickle.load", "open", "print", "pickle.load", "trans_bucket[].tolist", "trans_bucket[].tolist", "zip", "sent_repr.append", "rm_final_feats.append"], "function", ["None"], ["", "", "def", "load_trans_data", "(", "dir", ",", "is_train", "=", "False", ")", ":", "\n", "    ", "data_trans_train", "=", "{", "}", "\n", "data_trans_valid", "=", "{", "}", "\n", "data_trans_test", "=", "{", "}", "\n", "\n", "if", "is_train", ":", "\n", "# TODO\uff1arevise to automatically check", "\n", "        ", "train_list", "=", "list", "(", "range", "(", "0", ",", "34", ")", ")", "\n", "train_list", "=", "[", "str", "(", "id", ")", "for", "id", "in", "train_list", "]", "\n", "sent_repr", "=", "[", "]", "\n", "rm_final_feats", "=", "[", "]", "\n", "for", "idx", "in", "train_list", ":", "\n", "            ", "with", "open", "(", "'%s/data_trans_train_%s.picke'", "%", "(", "dir", ",", "idx", ")", ",", "'rb'", ")", "as", "fr", ":", "\n", "                ", "print", "(", "\"read data_trans_tran_%s.pickle\"", "%", "idx", ")", "\n", "trans_bucket", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "sent_bucket", "=", "trans_bucket", "[", "'sent_repr'", "]", ".", "tolist", "(", ")", "\n", "rm_feat_bucket", "=", "trans_bucket", "[", "'rm_final_feats'", "]", ".", "tolist", "(", ")", "\n", "for", "sent", ",", "rm_feat", "in", "zip", "(", "sent_bucket", ",", "rm_feat_bucket", ")", ":", "\n", "                    ", "sent_repr", ".", "append", "(", "sent", ")", "\n", "rm_final_feats", ".", "append", "(", "rm_feat", ")", "\n", "\n", "", "", "", "data_trans_train", "=", "{", "'sent_repr'", ":", "np", ".", "array", "(", "sent_repr", ")", ",", "\n", "'rm_final_feats'", ":", "np", ".", "array", "(", "rm_final_feats", ")", "}", "\n", "print", "(", "\"trans_sent_repr:\"", ",", "data_trans_train", "[", "'sent_repr'", "]", ".", "shape", ")", "\n", "print", "(", "\"trans_rm_feats:\"", ",", "data_trans_train", "[", "'rm_final_feats'", "]", ".", "shape", ")", "\n", "\n", "with", "open", "(", "'%s/data_trans_valid.picke'", "%", "dir", ",", "'rb'", ")", "as", "fr", ":", "\n", "            ", "data_trans_valid", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "'%s/data_trans_test.picke'", "%", "dir", ",", "'rb'", ")", "as", "fr", ":", "\n", "            ", "data_trans_test", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "", "", "if", "is_train", ":", "\n", "        ", "return", "data_trans_train", ",", "data_trans_valid", "\n", "", "else", ":", "\n", "        ", "return", "data_trans_test", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader.load_vocab": [[74, 116], ["print", "print", "print", "numpy.array", "open", "json.load", "sorted", "len", "open", "enumerate", "open", "enumerate", "np.array.append", "line.strip", "entity_list.append", "line.strip", "list", "numpy.zeros", "map", "line.strip.find", "vectors[].split", "line.strip.find"], "function", ["None"], ["", "", "def", "load_vocab", "(", "dir", ",", "vocab_size", ",", "embed_units", ")", ":", "\n", "    ", "print", "(", "\"loading word vocabs...\"", ")", "\n", "with", "open", "(", "'%s/vocab'", "%", "dir", ")", "as", "fr", ":", "\n", "        ", "raw_vocab", "=", "json", ".", "load", "(", "fr", ")", "\n", "\n", "", "vocab_list", "=", "START_VOCAB", "+", "sorted", "(", "raw_vocab", ",", "key", "=", "raw_vocab", ".", "get", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "vocab_list", ")", ">", "vocab_size", ":", "\n", "        ", "vocab_list", "=", "vocab_list", "[", ":", "vocab_size", "]", "\n", "\n", "", "print", "(", "\"loading entity list...\"", ")", "\n", "entity_list", "=", "[", "]", "\n", "with", "open", "(", "'%s/csk_entity.txt'", "%", "dir", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "e", "=", "line", ".", "strip", "(", ")", "\n", "entity_list", ".", "append", "(", "e", ")", "\n", "\n", "", "", "print", "(", "\"loading word vectors...\"", ")", "\n", "vectors", "=", "{", "}", "\n", "with", "open", "(", "'%s/glove.840B.300d.txt'", "%", "dir", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "s", "=", "line", ".", "strip", "(", ")", "\n", "word", "=", "s", "[", ":", "s", ".", "find", "(", "' '", ")", "]", "\n", "vector", "=", "s", "[", "s", ".", "find", "(", "' '", ")", "+", "1", ":", "]", "\n", "vectors", "[", "word", "]", "=", "vector", "\n", "", "", "embed", "=", "[", "]", "\n", "for", "word", "in", "vocab_list", ":", "\n", "        ", "if", "word", "in", "vectors", ":", "\n", "            ", "vector", "=", "list", "(", "map", "(", "float", ",", "vectors", "[", "word", "]", ".", "split", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "vector", "=", "np", ".", "zeros", "(", "embed_units", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "embed", ".", "append", "(", "vector", ")", "\n", "", "embed", "=", "np", ".", "array", "(", "embed", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "entity_embed", "=", "[", "]", "\n", "'''\n    for entity_word in entity_list:\n        if entity_word in vectors:\n            vector = list(map(float, vectors[entity_word].split()))\n            entity_embed.append(vector)\n    entity_embed = np.array(entity_embed, dtype=np.float32)\n    '''", "\n", "return", "vocab_list", ",", "embed", ",", "entity_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader.pad_batched_data": [[118, 148], ["item[].split", "item[].split", "max", "max", "posts.append", "posts_length.append", "responses.append", "responses_length.append", "corr_responses.append", "numpy.array", "numpy.array", "numpy.array", "data_loader._padding", "data_loader._padding", "res.split", "data_loader._pad_corr_res", "response_k.append", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader._padding", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader._padding", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader._pad_corr_res"], ["", "def", "pad_batched_data", "(", "batched_data", ")", ":", "\n", "    ", "batched_post_tokens", "=", "[", "item", "[", "'post'", "]", ".", "split", "(", ")", "for", "item", "in", "batched_data", "]", "\n", "batched_res_tokens", "=", "[", "item", "[", "'response'", "]", ".", "split", "(", ")", "for", "item", "in", "batched_data", "]", "\n", "\n", "encoder_len", "=", "max", "(", "[", "len", "(", "p", ")", "for", "p", "in", "batched_post_tokens", "]", ")", "+", "1", "\n", "decoder_len", "=", "max", "(", "[", "len", "(", "r", ")", "for", "r", "in", "batched_res_tokens", "]", ")", "+", "1", "\n", "posts", ",", "responses", ",", "posts_length", ",", "responses_length", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "token_list", "in", "batched_post_tokens", ":", "\n", "        ", "posts", ".", "append", "(", "_padding", "(", "token_list", ",", "encoder_len", ")", ")", "\n", "posts_length", ".", "append", "(", "len", "(", "token_list", ")", "+", "1", ")", "\n", "", "for", "token_list", "in", "batched_res_tokens", ":", "\n", "        ", "responses", ".", "append", "(", "_padding", "(", "token_list", ",", "decoder_len", ")", ")", "\n", "responses_length", ".", "append", "(", "len", "(", "token_list", ")", "+", "1", ")", "\n", "\n", "", "batched_corrs", "=", "[", "item", "[", "'corr_responses'", "]", "for", "item", "in", "batched_data", "]", "\n", "corr_responses", "=", "[", "]", "\n", "for", "corrs", "in", "batched_corrs", ":", "\n", "        ", "response_k", "=", "[", "]", "\n", "for", "res", "in", "corrs", ":", "\n", "            ", "tokens", "=", "res", ".", "split", "(", ")", "\n", "token_pad", "=", "_pad_corr_res", "(", "tokens", ",", "decoder_len", ")", "\n", "response_k", ".", "append", "(", "token_pad", ")", "\n", "", "corr_responses", ".", "append", "(", "response_k", ")", "\n", "\n", "", "paded_data", "=", "{", "'posts'", ":", "np", ".", "array", "(", "posts", ")", ",", "\n", "'responses'", ":", "np", ".", "array", "(", "responses", ")", ",", "\n", "'posts_length'", ":", "posts_length", ",", "\n", "'responses_length'", ":", "responses_length", ",", "\n", "'corr_responses'", ":", "np", ".", "array", "(", "corr_responses", ")", "}", "\n", "return", "paded_data", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader._pad_corr_res": [[150, 156], ["len", "len"], "function", ["None"], ["", "def", "_pad_corr_res", "(", "s", ",", "max_len", ")", ":", "\n", "    ", "if", "len", "(", "s", ")", ">=", "max_len", "-", "1", ":", "\n", "        ", "sentence", "=", "s", "[", ":", "max_len", "-", "1", "]", "+", "[", "'_EOS'", "]", "\n", "", "else", ":", "\n", "        ", "sentence", "=", "s", "+", "[", "'_EOS'", "]", "+", "[", "'_PAD'", "]", "*", "(", "max_len", "-", "len", "(", "s", ")", "-", "1", ")", "\n", "", "return", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.data_loader._padding": [[158, 160], ["len"], "function", ["None"], ["", "def", "_padding", "(", "sent", ",", "l", ")", ":", "\n", "    ", "return", "sent", "+", "[", "'_EOS'", "]", "+", "[", "'_PAD'", "]", "*", "(", "l", "-", "len", "(", "sent", ")", "-", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.bleu._get_ngrams": [[27, 43], ["collections.Counter", "range", "range", "tuple", "len"], "function", ["None"], ["def", "_get_ngrams", "(", "segment", ",", "max_order", ")", ":", "\n", "    ", "\"\"\"Extracts all n-grams upto a given maximum order from an input segment.\n      Args:\n        segment: text segment from which n-grams will be extracted.\n        max_order: maximum length in tokens of the n-grams returned by this\n            methods.\n      Returns:\n        The Counter containing all n-grams upto max_order in segment\n        with a count of how many times each n-gram occurred.\n      \"\"\"", "\n", "ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "segment", ")", "-", "order", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "segment", "[", "i", ":", "i", "+", "order", "]", ")", "\n", "ngram_counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "ngram_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.bleu.compute_bleu": [[45, 105], ["zip", "range", "min", "len", "collections.Counter", "bleu._get_ngrams", "range", "min", "sum", "math.exp", "float", "math.exp", "bleu._get_ngrams", "len", "len", "float", "math.log", "len"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.bleu._get_ngrams", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.bleu._get_ngrams"], ["", "def", "compute_bleu", "(", "reference_corpus", ",", "translation_corpus", ",", "max_order", "=", "4", ",", "smooth", "=", "False", ")", ":", "\n", "    ", "\"\"\"Computes BLEU score of translated segments against one or more references.\n      Args:\n        reference_corpus: list of lists of references for each translation. Each\n            reference should be tokenized into a list of tokens.\n        translation_corpus: list of translations to score. Each translation\n            should be tokenized into a list of tokens.\n        max_order: Maximum n-gram order to use when computing BLEU score.\n        smooth: Whether or not to apply Lin et al. 2004 smoothing.\n      Returns:\n        3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n        precisions and brevity penalty.\n      \"\"\"", "\n", "matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "possible_matches_by_order", "=", "[", "0", "]", "*", "max_order", "\n", "reference_length", "=", "0", "\n", "translation_length", "=", "0", "\n", "for", "(", "references", ",", "translation", ")", "in", "zip", "(", "reference_corpus", ",", "translation_corpus", ")", ":", "\n", "        ", "reference_length", "+=", "min", "(", "len", "(", "r", ")", "for", "r", "in", "references", ")", "\n", "translation_length", "+=", "len", "(", "translation", ")", "\n", "\n", "merged_ref_ngram_counts", "=", "collections", ".", "Counter", "(", ")", "\n", "for", "reference", "in", "references", ":", "\n", "            ", "merged_ref_ngram_counts", "|=", "_get_ngrams", "(", "reference", ",", "max_order", ")", "\n", "", "translation_ngram_counts", "=", "_get_ngrams", "(", "translation", ",", "max_order", ")", "\n", "overlap", "=", "translation_ngram_counts", "&", "merged_ref_ngram_counts", "\n", "for", "ngram", "in", "overlap", ":", "\n", "            ", "matches_by_order", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "overlap", "[", "ngram", "]", "\n", "", "for", "order", "in", "range", "(", "1", ",", "max_order", "+", "1", ")", ":", "\n", "            ", "possible_matches", "=", "len", "(", "translation", ")", "-", "order", "+", "1", "\n", "if", "possible_matches", ">", "0", ":", "\n", "                ", "possible_matches_by_order", "[", "order", "-", "1", "]", "+=", "possible_matches", "\n", "\n", "", "", "", "precisions", "=", "[", "0", "]", "*", "max_order", "\n", "for", "i", "in", "range", "(", "0", ",", "max_order", ")", ":", "\n", "        ", "if", "smooth", ":", "\n", "            ", "precisions", "[", "i", "]", "=", "(", "(", "matches_by_order", "[", "i", "]", "+", "1.", ")", "/", "\n", "(", "possible_matches_by_order", "[", "i", "]", "+", "1.", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "possible_matches_by_order", "[", "i", "]", ">", "0", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "(", "float", "(", "matches_by_order", "[", "i", "]", ")", "/", "\n", "possible_matches_by_order", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "0.0", "\n", "\n", "", "", "", "if", "min", "(", "precisions", ")", ">", "0", ":", "\n", "        ", "p_log_sum", "=", "sum", "(", "(", "1.", "/", "max_order", ")", "*", "math", ".", "log", "(", "p", ")", "for", "p", "in", "precisions", ")", "\n", "geo_mean", "=", "math", ".", "exp", "(", "p_log_sum", ")", "\n", "", "else", ":", "\n", "        ", "geo_mean", "=", "0", "\n", "\n", "", "ratio", "=", "float", "(", "translation_length", ")", "/", "reference_length", "\n", "\n", "if", "ratio", ">", "1.0", ":", "\n", "        ", "bp", "=", "1.", "\n", "", "else", ":", "\n", "        ", "bp", "=", "math", ".", "exp", "(", "1", "-", "1.", "/", "ratio", ")", "\n", "", "bleu", "=", "geo_mean", "*", "bp", "\n", "\n", "return", "bleu", ",", "precisions", ",", "bp", ",", "ratio", ",", "translation_length", ",", "reference_length", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.trainer.Trainer.__init__": [[11, 27], ["os.path.exists", "os.makedirs"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "sess", ",", "trans_model", ",", "trans_sess", ",", "saver", ",", "best_saver", ",", "log_dir", ",", "save_per_step", "=", "1000", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "trans_model", "=", "trans_model", "\n", "self", ".", "trans_sess", "=", "trans_sess", "\n", "self", ".", "saver", "=", "saver", "\n", "self", ".", "best_saver", "=", "best_saver", "\n", "self", ".", "model_dir", "=", "\"%s/models\"", "%", "log_dir", "\n", "self", ".", "best_model_dir", "=", "\"%s/models/best_model\"", "%", "log_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "best_model_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "best_model_dir", ")", "\n", "", "self", ".", "save_per_step", "=", "save_per_step", "\n", "\n", "self", ".", "scan_data", "=", "0", "\n", "self", ".", "scan_batch", "=", "0", "\n", "self", ".", "best_eval_loss", "=", "1e5", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.trainer.Trainer._reset_optm_info": [[28, 31], ["None"], "methods", ["None"], ["", "def", "_reset_optm_info", "(", "self", ")", ":", "\n", "        ", "self", ".", "scan_data", "=", "0", "\n", "self", ".", "scan_batch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.trainer.Trainer._optimize": [[32, 71], ["trainer.Trainer.model.train_batch", "float", "float", "trainer.Trainer.trans_model.transfer_encode", "numpy.mean", "numpy.mean", "print", "trainer.Trainer.saver.save", "range", "numpy.mean", "numpy.mean", "trainer.Trainer.model.global_step.eval", "eval_loader.get_batch", "trainer.Trainer.model.eval_batch", "all_eval_loss.append", "all_eval_ppx.append", "float", "trainer.Trainer.best_saver.save", "print", "trainer.Trainer.trans_model.transfer_encode", "float", "float", "trainer.Trainer.model.global_step.eval", "numpy.exp", "numpy.mean", "numpy.mean", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.train_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.transfer_encode", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.get_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.eval_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.transfer_encode"], ["", "def", "_optimize", "(", "self", ",", "batch_data", ",", "eval_loader", ",", "queue_size", ")", ":", "\n", "        ", "if", "self", ".", "trans_model", "is", "not", "None", ":", "\n", "# transfer representation", "\n", "            ", "trans_repr", "=", "self", ".", "trans_model", ".", "transfer_encode", "(", "self", ".", "trans_sess", ",", "batch_data", ")", "\n", "", "else", ":", "\n", "            ", "trans_repr", "=", "None", "\n", "\n", "# model training", "\n", "", "ppx_loss", ",", "local_loss", "=", "self", ".", "model", ".", "train_batch", "(", "self", ".", "sess", ",", "batch_data", ",", "trans_repr", ")", "\n", "\n", "avg_ppx", "=", "float", "(", "np", ".", "mean", "(", "ppx_loss", ")", ")", "\n", "avg_loss", "=", "float", "(", "np", ".", "mean", "(", "local_loss", ")", ")", "\n", "\n", "if", "self", ".", "model", ".", "global_step", ".", "eval", "(", "session", "=", "self", ".", "sess", ")", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "\"[queue=%d scan=%d] global step: %d loss: %.3f ppx_loss: %.3f perplexity: %.3f\"", "%", "(", "\n", "queue_size", ",", "self", ".", "scan_data", ",", "self", ".", "model", ".", "global_step", ".", "eval", "(", "session", "=", "self", ".", "sess", ")", ",", "\n", "avg_loss", ",", "avg_ppx", ",", "np", ".", "exp", "(", "avg_ppx", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "scan_batch", "%", "self", ".", "save_per_step", "==", "0", ":", "\n", "            ", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "save_path", "=", "\"%s/model\"", "%", "self", ".", "model_dir", ",", "global_step", "=", "self", ".", "model", ".", "global_step", ")", "\n", "# eval model", "\n", "all_eval_loss", "=", "[", "]", "\n", "all_eval_ppx", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "eval_loader", ".", "n_batch", ")", ":", "\n", "                ", "eval_data", ",", "_", "=", "eval_loader", ".", "get_batch", "(", "batch_idx", "=", "idx", ")", "\n", "if", "self", ".", "trans_model", "is", "not", "None", ":", "\n", "                    ", "eval_repr", "=", "self", ".", "trans_model", ".", "transfer_encode", "(", "self", ".", "trans_sess", ",", "eval_data", ")", "\n", "", "else", ":", "\n", "                    ", "eval_repr", "=", "None", "\n", "", "eval_ppx", ",", "eval_loss", "=", "self", ".", "model", ".", "eval_batch", "(", "self", ".", "sess", ",", "eval_data", ",", "eval_repr", ")", "\n", "all_eval_loss", ".", "append", "(", "float", "(", "np", ".", "mean", "(", "eval_loss", ")", ")", ")", "\n", "all_eval_ppx", ".", "append", "(", "float", "(", "np", ".", "mean", "(", "eval_ppx", ")", ")", ")", "\n", "", "avg_eval_loss", "=", "np", ".", "mean", "(", "all_eval_loss", ")", "\n", "avg_eval_ppx", "=", "np", ".", "mean", "(", "all_eval_ppx", ")", "\n", "if", "avg_eval_loss", "<", "self", ".", "best_eval_loss", ":", "\n", "                ", "self", ".", "best_eval_loss", "=", "float", "(", "avg_eval_loss", ")", "\n", "self", ".", "best_saver", ".", "save", "(", "self", ".", "sess", ",", "save_path", "=", "\"%s/best.model\"", "%", "self", ".", "best_model_dir", ")", "\n", "print", "(", "\"Eval loss=%.3f ppx=%.3f. Saved to [%s/best.model]\"", "%", "\n", "(", "self", ".", "best_eval_loss", ",", "np", ".", "exp", "(", "avg_eval_ppx", ")", ",", "self", ".", "best_model_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.trainer.Trainer.train": [[72, 86], ["trainer.Trainer._reset_optm_info", "train_batcher.get_epoch", "train_batcher.get_batch", "trainer.Trainer._optimize"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer._reset_optm_info", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.get_epoch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.get_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer._optimize"], ["", "", "", "def", "train", "(", "self", ",", "train_batcher", ",", "eval_loader", ",", "epoch_idx", ")", ":", "\n", "        ", "self", ".", "_reset_optm_info", "(", ")", "\n", "while", "train_batcher", ".", "get_epoch", "(", ")", "==", "epoch_idx", ":", "\n", "            ", "queue_size", "=", "train_batcher", ".", "loader_queue_size", "\n", "batch_data", ",", "local_size", "=", "train_batcher", ".", "get_batch", "(", ")", "\n", "#print(\"posts:\", batch_data['post'][:2])", "\n", "#print(\"response:\", batch_data['response'][:2])", "\n", "#print(\"triples:\", batch_data['all_triples'][:2])", "\n", "#print(\"entities:\", batch_data['all_entities'][:2])", "\n", "self", ".", "scan_data", "+=", "local_size", "\n", "self", ".", "scan_batch", "+=", "1", "\n", "self", ".", "_optimize", "(", "batch_data", "=", "batch_data", ",", "eval_loader", "=", "eval_loader", ",", "queue_size", "=", "queue_size", ")", "\n", "", "else", ":", "\n", "            ", "return", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.__init__": [[19, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "tick", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run": [[22, 27], ["sys.stdout.write", "sys.stdout.flush", "time.sleep"], "methods", ["None"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "while", "self", ".", "tick", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "'.'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "time", ".", "sleep", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Indexer.__init__": [[32, 40], ["print", "org.apache.lucene.store.SimpleFSDirectory", "org.apache.lucene.analysis.miscellaneous.LimitTokenCountAnalyzer", "org.apache.lucene.index.IndexWriterConfig", "org.apache.lucene.index.IndexWriterConfig.setOpenMode", "org.apache.lucene.index.IndexWriter", "java.nio.file.Paths.get", "org.apache.lucene.analysis.standard.StandardAnalyzer"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index_dir", ")", ":", "\n", "        ", "print", "(", "\"lucene:\"", ",", "lucene", ".", "VERSION", ")", "\n", "self", ".", "index_dir", "=", "index_dir", "\n", "store", "=", "SimpleFSDirectory", "(", "Paths", ".", "get", "(", "self", ".", "index_dir", ")", ")", "\n", "analyzer", "=", "LimitTokenCountAnalyzer", "(", "StandardAnalyzer", "(", ")", ",", "1048576", ")", "\n", "config", "=", "IndexWriterConfig", "(", "analyzer", ")", "\n", "config", ".", "setOpenMode", "(", "IndexWriterConfig", ".", "OpenMode", ".", "CREATE", ")", "\n", "self", ".", "writer", "=", "IndexWriter", "(", "store", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Indexer.build_index": [[41, 66], ["print", "org.apache.lucene.document.FieldType", "org.apache.lucene.document.FieldType.setStored", "org.apache.lucene.document.FieldType.setTokenized", "org.apache.lucene.document.FieldType.setIndexOptions", "org.apache.lucene.document.FieldType", "org.apache.lucene.document.FieldType.setStored", "org.apache.lucene.document.FieldType.setTokenized", "org.apache.lucene.document.FieldType.setIndexOptions", "dict_data.items", "retriever.Ticker", "print", "threading.Thread().start", "retriever.Indexer.writer.commit", "retriever.Indexer.writer.close", "print", "org.apache.lucene.document.Document", "org.apache.lucene.document.Document.add", "org.apache.lucene.document.Document.add", "retriever.Indexer.writer.addDocument", "org.apache.lucene.document.Field", "org.apache.lucene.document.Field", "threading.Thread"], "methods", ["None"], ["", "def", "build_index", "(", "self", ",", "dict_data", ")", ":", "\n", "        ", "print", "(", "\"loading data...\"", ")", "\n", "t1", "=", "FieldType", "(", ")", "\n", "t1", ".", "setStored", "(", "True", ")", "\n", "t1", ".", "setTokenized", "(", "False", ")", "\n", "t1", ".", "setIndexOptions", "(", "IndexOptions", ".", "DOCS_AND_FREQS", ")", "\n", "\n", "t2", "=", "FieldType", "(", ")", "\n", "t2", ".", "setStored", "(", "True", ")", "\n", "t2", ".", "setTokenized", "(", "True", ")", "\n", "t2", ".", "setIndexOptions", "(", "IndexOptions", ".", "DOCS_AND_FREQS_AND_POSITIONS", ")", "\n", "\n", "for", "k", ",", "v", "in", "dict_data", ".", "items", "(", ")", ":", "\n", "            ", "doc", "=", "Document", "(", ")", "\n", "doc", ".", "add", "(", "Field", "(", "\"id\"", ",", "k", ",", "t1", ")", ")", "\n", "doc", ".", "add", "(", "Field", "(", "\"content\"", ",", "v", ",", "t2", ")", ")", "\n", "self", ".", "writer", ".", "addDocument", "(", "doc", ")", "\n", "\n", "", "ticker", "=", "Ticker", "(", ")", "\n", "print", "(", "\"commit index\"", ")", "\n", "threading", ".", "Thread", "(", "target", "=", "ticker", ".", "run", ")", ".", "start", "(", ")", "\n", "self", ".", "writer", ".", "commit", "(", ")", "\n", "self", ".", "writer", ".", "close", "(", ")", "\n", "ticker", ".", "tick", "=", "False", "\n", "print", "(", "\"done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Queryer.__init__": [[69, 74], ["org.apache.lucene.store.SimpleFSDirectory", "org.apache.lucene.search.IndexSearcher", "org.apache.lucene.analysis.standard.StandardAnalyzer", "java.nio.file.Paths.get", "org.apache.lucene.index.DirectoryReader.open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "index_dir", ",", "top_k", "=", "5", ")", ":", "\n", "        ", "self", ".", "directory", "=", "SimpleFSDirectory", "(", "Paths", ".", "get", "(", "index_dir", ")", ")", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "searcher", "=", "IndexSearcher", "(", "DirectoryReader", ".", "open", "(", "self", ".", "directory", ")", ")", "\n", "self", ".", "analyzer", "=", "StandardAnalyzer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Queryer.run_query": [[75, 88], ["org.apache.lucene.queryparser.classic.QueryParser().parse", "retriever.Queryer.searcher.search", "retriever.Queryer.searcher.doc", "ids.append", "contents.append", "org.apache.lucene.queryparser.classic.QueryParser", "retriever.Queryer.get", "retriever.Queryer.get"], "methods", ["None"], ["", "def", "run_query", "(", "self", ",", "query", ")", ":", "\n", "        ", "query", "=", "QueryParser", "(", "\"content\"", ",", "self", ".", "analyzer", ")", ".", "parse", "(", "query", ")", "\n", "scoreDocs", "=", "self", ".", "searcher", ".", "search", "(", "query", ",", "self", ".", "top_k", ")", ".", "scoreDocs", "\n", "\n", "ids", "=", "[", "]", "\n", "contents", "=", "[", "]", "\n", "for", "scoreDoc", "in", "scoreDocs", ":", "\n", "            ", "doc", "=", "self", ".", "searcher", ".", "doc", "(", "scoreDoc", ".", "doc", ")", "\n", "ids", ".", "append", "(", "doc", ".", "get", "(", "\"id\"", ")", ")", "\n", "contents", ".", "append", "(", "doc", ".", "get", "(", "\"content\"", ")", ")", "\n", "", "results", "=", "{", "\"ids\"", ":", "ids", ",", "\n", "\"contents\"", ":", "contents", "}", "\n", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.generator.Generator.__init__": [[12, 25], ["os.path.exists", "os.mkdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "sess", ",", "trans_model", ",", "trans_sess", ",", "log_dir", ",", "ckpt", ",", "stop_words", ",", "csk_entities", ",", "set_num", "=", "5000", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "trans_model", "=", "trans_model", "\n", "self", ".", "trans_sess", "=", "trans_sess", "\n", "self", ".", "output_dir", "=", "\"%s/output\"", "%", "log_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "output_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "output_dir", ")", "\n", "", "self", ".", "ckpt", "=", "ckpt", "\n", "self", ".", "stop_words", "=", "stop_words", "\n", "self", ".", "csk_entities", "=", "csk_entities", "\n", "self", ".", "set_num", "=", "set_num", "\n", "self", ".", "scan_data", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.generator.Generator._decode": [[26, 36], ["generator.Generator.model.decode_batch", "print", "generator.Generator.trans_model.transfer_encode", "numpy.mean", "numpy.mean", "numpy.exp", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.decode_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.transfer_encode"], ["", "def", "_decode", "(", "self", ",", "local_data", ",", "local_size", ")", ":", "\n", "        ", "if", "self", ".", "trans_model", "is", "not", "None", ":", "\n", "            ", "trans_repr", "=", "self", ".", "trans_model", ".", "transfer_encode", "(", "self", ".", "trans_sess", ",", "local_data", ")", "\n", "", "else", ":", "\n", "            ", "trans_repr", "=", "None", "\n", "", "generation_batch", ",", "ppx_loss_batch", ",", "loss_batch", "=", "self", ".", "model", ".", "decode_batch", "(", "self", ".", "sess", ",", "local_data", ",", "trans_repr", ")", "\n", "self", ".", "scan_data", "+=", "local_size", "\n", "print", "(", "\"decoding %d finished. loss_batch=%.3f ppx_loss=%.3f ppx=%.3f\"", "%", "\n", "(", "self", ".", "scan_data", ",", "np", ".", "mean", "(", "loss_batch", ")", ",", "np", ".", "mean", "(", "ppx_loss_batch", ")", ",", "np", ".", "exp", "(", "np", ".", "mean", "(", "ppx_loss_batch", ")", ")", ")", ")", "\n", "return", "generation_batch", ",", "ppx_loss_batch", ",", "loss_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.generator.Generator._post_process": [[37, 90], ["open", "open", "print", "print", "outfile.write", "zip", "nltk.translate.bleu_score.corpus_bleu", "nltk.translate.bleu_score.corpus_bleu", "nltk.translate.bleu_score.corpus_bleu", "nltk.translate.bleu_score.corpus_bleu", "nltk.translate.bleu_score.corpus_bleu", "resfile.write", "print", "references.append", "hypotheses.append", "int", "result.split", "len", "outfile.write", "numpy.exp", "nltk.translate.bleu_score.SmoothingFunction", "result.split", "set", "generator.Generator._post_process.show"], "methods", ["None"], ["", "def", "_post_process", "(", "self", ",", "posts", ",", "responses", ",", "all_entities", ",", "results", ",", "ppx_loss", ")", ":", "\n", "        ", "\"\"\"\n        Write results to files\n        \"\"\"", "\n", "res_path", "=", "\"%s/eval-%s.log\"", "%", "(", "self", ".", "output_dir", ",", "self", ".", "ckpt", ")", "\n", "out_path", "=", "\"%s/out-%s.txt\"", "%", "(", "self", ".", "output_dir", ",", "self", ".", "ckpt", ")", "\n", "\n", "with", "open", "(", "res_path", ",", "'w'", ")", "as", "resfile", ",", "open", "(", "out_path", ",", "'w'", ")", "as", "outfile", ":", "\n", "            ", "print", "(", "\"writing evaluation results to [%s]...\"", "%", "res_path", ")", "\n", "print", "(", "\"writing generation results to [%s]...\"", "%", "out_path", ")", "\n", "outfile", ".", "write", "(", "'model: %s\\n'", "%", "self", ".", "ckpt", ")", "\n", "match_entity_sum", "=", "[", ".0", "]", "*", "4", "\n", "cnt", "=", "0", "\n", "hypotheses", "=", "[", "]", "\n", "references", "=", "[", "]", "\n", "for", "post", ",", "response", ",", "result", ",", "entities", "in", "zip", "(", "posts", ",", "responses", ",", "results", ",", "all_entities", ")", ":", "\n", "                ", "references", ".", "append", "(", "[", "response", ".", "split", "(", ")", "]", ")", "# only 1 reference, shape=[[token1, token2, ...]]", "\n", "hypotheses", ".", "append", "(", "result", ".", "split", "(", ")", ")", "# hypothese = [token1, token2, ...]", "\n", "\n", "setidx", "=", "int", "(", "cnt", "/", "self", ".", "set_num", ")", "\n", "result_matched_entities", "=", "[", "]", "\n", "result_tokens", "=", "result", ".", "split", "(", ")", "\n", "for", "word", "in", "result_tokens", ":", "\n", "                    ", "if", "word", "not", "in", "self", ".", "stop_words", "and", "word", "in", "entities", ":", "\n", "                        ", "if", "word", "not", "in", "result_matched_entities", ":", "\n", "                            ", "result_matched_entities", ".", "append", "(", "word", ")", "\n", "\n", "", "", "", "match_entity_sum", "[", "setidx", "]", "+=", "len", "(", "set", "(", "result_matched_entities", ")", ")", "\n", "cnt", "+=", "1", "\n", "match_entity_str", "=", "\" \"", ".", "join", "(", "result_matched_entities", ")", "\n", "outfile", ".", "write", "(", "'post: %s\\nresponse: %s\\nresult: %s\\nmatch_entity: %s\\n\\n'", "%", "\n", "(", "post", ",", "response", ",", "result", ",", "match_entity_str", ")", ")", "\n", "\n", "", "match_entity_sum", "=", "[", "m", "/", "self", ".", "set_num", "for", "m", "in", "match_entity_sum", "]", "+", "[", "sum", "(", "match_entity_sum", ")", "/", "len", "(", "responses", ")", "]", "\n", "losses", "=", "[", "np", ".", "sum", "(", "ppx_loss", "[", "x", ":", "x", "+", "self", ".", "set_num", "]", ")", "/", "float", "(", "self", ".", "set_num", ")", "for", "x", "in", "range", "(", "0", ",", "self", ".", "set_num", "*", "4", ",", "self", ".", "set_num", ")", "]", "+", "[", "np", ".", "sum", "(", "ppx_loss", ")", "/", "float", "(", "self", ".", "set_num", "*", "4", ")", "]", "\n", "ppxs", "=", "[", "np", ".", "exp", "(", "x", ")", "for", "x", "in", "losses", "]", "\n", "\n", "smooth_func", "=", "SmoothingFunction", "(", "epsilon", "=", "0.1", ")", ".", "method1", "\n", "cor_bleu_1", "=", "corpus_bleu", "(", "references", ",", "hypotheses", ",", "weights", "=", "(", "1", ",", "0", ",", "0", ",", "0", ")", ")", "\n", "cor_bleu_2", "=", "corpus_bleu", "(", "references", ",", "hypotheses", ",", "smoothing_function", "=", "smooth_func", ",", "weights", "=", "(", "0", ",", "1", ",", "0", ",", "0", ")", ")", "\n", "cor_bleu_3", "=", "corpus_bleu", "(", "references", ",", "hypotheses", ",", "smoothing_function", "=", "smooth_func", ",", "weights", "=", "(", "0", ",", "0", ",", "1", ",", "0", ")", ")", "\n", "cor_bleu_4", "=", "corpus_bleu", "(", "references", ",", "hypotheses", ",", "smoothing_function", "=", "smooth_func", ",", "weights", "=", "(", "0", ",", "0", ",", "0", ",", "1", ")", ")", "\n", "cor_bleu", "=", "corpus_bleu", "(", "references", ",", "hypotheses", ")", "\n", "bleus", "=", "[", "cor_bleu_1", ",", "cor_bleu_2", ",", "cor_bleu_3", ",", "cor_bleu_4", ",", "cor_bleu", "]", "\n", "\n", "def", "show", "(", "x", ")", ":", "\n", "                ", "return", "', '", ".", "join", "(", "[", "str", "(", "v", ")", "for", "v", "in", "x", "]", ")", "\n", "\n", "", "eval_res_str", "=", "\"model: %s\\n\\tbleu: %s\\n\\tperplexity: %s\\n\\tmatch_entity_rate: %s\"", "%", "(", "self", ".", "ckpt", ",", "show", "(", "bleus", ")", ",", "show", "(", "ppxs", ")", ",", "show", "(", "match_entity_sum", ")", ")", "\n", "resfile", ".", "write", "(", "eval_res_str", ")", "\n", "print", "(", "eval_res_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.generator.Generator.generate": [[91, 126], ["range", "generator.Generator._post_process", "data_loader.get_batch", "enumerate", "generator.Generator._decode", "posts.append", "responses.append", "set", "all_entities.append", "results.append", "post.split", "resp.split", "str", "result.append"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator._post_process", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.get_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.generator.Generator._decode"], ["", "", "def", "generate", "(", "self", ",", "data_loader", ")", ":", "\n", "        ", "posts", "=", "[", "]", "\n", "responses", "=", "[", "]", "\n", "all_entities", "=", "[", "]", "\n", "ppx_loss", "=", "[", "]", "\n", "results", "=", "[", "]", "\n", "for", "batch_idx", "in", "range", "(", "data_loader", ".", "n_batch", ")", ":", "\n", "            ", "batch_data", ",", "local_size", "=", "data_loader", ".", "get_batch", "(", "batch_idx", "=", "batch_idx", ")", "\n", "batch_post", "=", "batch_data", "[", "'post'", "]", "\n", "batch_resp", "=", "batch_data", "[", "'response'", "]", "\n", "batch_ents", "=", "batch_data", "[", "'entities'", "]", "\n", "for", "idx", ",", "data", "in", "enumerate", "(", "batch_post", ")", ":", "\n", "                ", "post", "=", "\" \"", ".", "join", "(", "data", ")", "\n", "post", "=", "post", ".", "split", "(", "'_EOS'", ")", "[", "0", "]", "\n", "posts", ".", "append", "(", "post", ")", "\n", "resp", "=", "\" \"", ".", "join", "(", "batch_resp", "[", "idx", "]", ")", "\n", "resp", "=", "resp", ".", "split", "(", "'_EOS'", ")", "[", "0", "]", "\n", "responses", ".", "append", "(", "resp", ")", "\n", "\n", "entities", "=", "set", "(", "batch_ents", "[", "idx", "]", ")", "\n", "all_entities", ".", "append", "(", "entities", ")", "\n", "\n", "", "generation_batch", ",", "ppx_loss_batch", ",", "loss_batch", "=", "self", ".", "_decode", "(", "local_data", "=", "batch_data", ",", "local_size", "=", "local_size", ")", "\n", "ppx_loss", "+=", "[", "x", "for", "x", "in", "ppx_loss_batch", "]", "\n", "for", "sent", "in", "generation_batch", ":", "\n", "                ", "tokens", "=", "[", "str", "(", "r", ",", "encoding", "=", "'utf-8'", ")", "for", "r", "in", "sent", "]", "\n", "result", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "                    ", "if", "token", "!=", "'_EOS'", ":", "\n", "                        ", "result", ".", "append", "(", "token", ")", "\n", "", "else", ":", "\n", "                        ", "break", "\n", "", "", "result", "=", "\" \"", ".", "join", "(", "result", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "", "self", ".", "_post_process", "(", "posts", ",", "responses", ",", "all_entities", ",", "results", ",", "ppx_loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.evaluation.moses_multi_bleu": [[25, 81], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile.close", "tempfile.NamedTemporaryFile.close", "numpy.size", "numpy.float32", "six.moves.urllib.request.urlretrieve", "os.chmod", "open", "print", "os.path.dirname", "os.path.abspath", "os.path.join", "subprocess.check_output", "bleu_out.decode.decode", "re.search().group", "float", "os.path.realpath", "os.path.join", "re.search", "print", "print", "numpy.float32"], "function", ["None"], ["def", "moses_multi_bleu", "(", "hypotheses", ",", "references", ",", "lowercase", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate the bleu score for hypotheses and references\n    using the MOSES ulti-bleu.perl script.\n    Args:\n    hypotheses: A numpy array of strings where each string is a single example.\n    references: A numpy array of strings where each string is a single example.\n    lowercase: If true, pass the \"-lc\" flag to the multi-bleu script\n    Returns:\n    The BLEU score as a float32 value.\n    \"\"\"", "\n", "\n", "if", "np", ".", "size", "(", "hypotheses", ")", "==", "0", ":", "\n", "        ", "return", "np", ".", "float32", "(", "0.0", ")", "\n", "\n", "# Get MOSES multi-bleu script", "\n", "", "try", ":", "\n", "        ", "multi_bleu_path", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "\"https://raw.githubusercontent.com/moses-smt/mosesdecoder/master/scripts/generic/multi-bleu.perl\"", ")", "\n", "os", ".", "chmod", "(", "multi_bleu_path", ",", "0o755", ")", "\n", "", "except", ":", "# pylint: disable=W0702", "\n", "        ", "print", "(", "\"Unable to fetch multi-bleu.perl script, using local.\"", ")", "\n", "metrics_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "bin_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "metrics_dir", ",", "\"..\"", ",", "\"..\"", ",", "\"bin\"", ")", ")", "\n", "multi_bleu_path", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "\"tools/multi-bleu.perl\"", ")", "\n", "\n", "# Dump hypotheses and references to tempfiles", "\n", "", "hypothesis_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "hypothesis_file", ".", "write", "(", "\"\\n\"", ".", "join", "(", "hypotheses", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "hypothesis_file", ".", "write", "(", "b\"\\n\"", ")", "\n", "hypothesis_file", ".", "flush", "(", ")", "\n", "reference_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "reference_file", ".", "write", "(", "\"\\n\"", ".", "join", "(", "references", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "reference_file", ".", "write", "(", "b\"\\n\"", ")", "\n", "reference_file", ".", "flush", "(", ")", "\n", "\n", "# Calculate BLEU using multi-bleu script", "\n", "with", "open", "(", "hypothesis_file", ".", "name", ",", "\"r\"", ")", "as", "read_pred", ":", "\n", "        ", "bleu_cmd", "=", "[", "multi_bleu_path", "]", "\n", "if", "lowercase", ":", "\n", "            ", "bleu_cmd", "+=", "[", "\"-lc\"", "]", "\n", "", "bleu_cmd", "+=", "[", "reference_file", ".", "name", "]", "\n", "try", ":", "\n", "            ", "bleu_out", "=", "subprocess", ".", "check_output", "(", "bleu_cmd", ",", "stdin", "=", "read_pred", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "bleu_out", "=", "bleu_out", ".", "decode", "(", "\"utf-8\"", ")", "\n", "bleu_score", "=", "re", ".", "search", "(", "r\"BLEU = (.+?),\"", ",", "bleu_out", ")", ".", "group", "(", "1", ")", "\n", "bleu_score", "=", "float", "(", "bleu_score", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "error", ":", "\n", "            ", "if", "error", ".", "output", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"multi-bleu.perl script returned non-zero exit code\"", ")", "\n", "print", "(", "error", ".", "output", ")", "\n", "bleu_score", "=", "np", ".", "float32", "(", "0.0", ")", "\n", "\n", "# Close temp files", "\n", "", "", "", "hypothesis_file", ".", "close", "(", ")", "\n", "reference_file", ".", "close", "(", ")", "\n", "return", "bleu_score", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.link_data.LinkData.__init__": [[5, 15], ["str"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "category", ",", "start", ",", "end", ",", "mention", ",", "comp", ",", "value", ",", "name", ",", "link_feat", ",", "gl_pos", "=", "None", ")", ":", "\n", "        ", "self", ".", "gl_pos", "=", "gl_pos", "\n", "self", ".", "category", "=", "category", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "self", ".", "mention", "=", "mention", "\n", "self", ".", "comp", "=", "comp", "\n", "self", ".", "value", "=", "str", "(", "value", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "link_feat", "=", "link_feat", "# dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.link_data.LinkData.serialize": [[16, 23], ["ret_list.append", "getattr"], "methods", ["None"], ["", "def", "serialize", "(", "self", ")", ":", "\n", "        ", "ret_list", "=", "[", "]", "\n", "for", "key", "in", "(", "'category'", ",", "'start'", ",", "'end'", ",", "'mention'", ",", "'comp'", ",", "'value'", ",", "'name'", ",", "'link_feat'", ")", ":", "\n", "            ", "ret_list", ".", "append", "(", "(", "key", ",", "getattr", "(", "self", ",", "key", ")", ")", ")", "\n", "", "if", "self", ".", "gl_pos", "is", "not", "None", ":", "\n", "            ", "ret_list", "=", "[", "(", "'gl_pos'", ",", "self", ".", "gl_pos", ")", "]", "+", "ret_list", "\n", "", "return", "ret_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.link_data.LinkData.display": [[24, 34], ["str"], "methods", ["None"], ["", "def", "display", "(", "self", ")", ":", "\n", "        ", "ret_str", "=", "''", "\n", "if", "self", ".", "gl_pos", "is", "not", "None", ":", "\n", "            ", "ret_str", "+=", "'#%02d '", "%", "self", ".", "gl_pos", "\n", "", "ret_str", "+=", "'%s: [%d, %d) (%s) %s %s '", "%", "(", "\n", "self", ".", "category", ",", "self", ".", "start", ",", "self", ".", "end", ",", "self", ".", "mention", ",", "self", ".", "comp", ",", "self", ".", "value", ")", "\n", "if", "self", ".", "name", "!=", "''", ":", "\n", "            ", "ret_str", "+=", "'(%s) '", "%", "self", ".", "name", "\n", "", "ret_str", "+=", "str", "(", "self", ".", "link_feat", ")", "\n", "return", "ret_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.__init__": [[25, 33], ["log_util.LogInfo.begin_track", "log_util.LogInfo.logs", "log_util.LogInfo.logs", "log_util.LogInfo.end_track", "len", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["    ", "def", "__init__", "(", "self", ",", "ent_type_fp", "=", "None", ",", "dep_cache_fp", "=", "None", ")", ":", "\n", "        ", "self", ".", "e_t_dict", "=", "{", "}", "\n", "self", ".", "dep_cache_dict", "=", "{", "}", "\n", "self", ".", "parser", "=", "None", "\n", "LogInfo", ".", "begin_track", "(", "'DependencyUtil reading cache ...'", ")", "\n", "LogInfo", ".", "logs", "(", "\"%d entity type dict loaded.\"", ",", "len", "(", "self", ".", "e_t_dict", ")", ")", "\n", "LogInfo", ".", "logs", "(", "'%d dependency cache loaded.'", ",", "len", "(", "self", ".", "dep_cache_dict", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.context_pattern": [[34, 58], ["dependency_util.DependencyUtil.placeholding", "zip", "len", "max", "cp_tok_lists.append", "min"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.placeholding"], ["", "def", "context_pattern", "(", "self", ",", "tok_list", ",", "linkings", ")", ":", "\n", "        ", "\"\"\"\n        Imitate Bao's context pattern\n        :param tok_list:\n        :param linkings:\n        :return:\n        \"\"\"", "\n", "ph_tok_list", ",", "link_anchor_list", ",", "ans_anchor", "=", "self", ".", "placeholding", "(", "tok_list", "=", "tok_list", ",", "linkings", "=", "linkings", ")", "\n", "\n", "for", "link_anchor", ",", "gl_data", "in", "zip", "(", "link_anchor_list", ",", "linkings", ")", ":", "\n", "            ", "if", "gl_data", ".", "category", "==", "'Entity'", ":", "\n", "                ", "ph_tok_list", "[", "link_anchor", "]", "=", "'<E>'", "\n", "", "elif", "gl_data", ".", "category", "==", "'Time'", ":", "\n", "                ", "ph_tok_list", "[", "link_anchor", "]", "=", "'<Tm>'", "\n", "\n", "", "", "window", "=", "2", "\n", "ph_tok_len", "=", "len", "(", "ph_tok_list", ")", "\n", "cp_tok_lists", "=", "[", "]", "\n", "for", "link_anchor", "in", "link_anchor_list", ":", "\n", "            ", "st_pos", "=", "max", "(", "0", ",", "link_anchor", "-", "window", ")", "\n", "ed_pos", "=", "min", "(", "ph_tok_len", "-", "1", ",", "link_anchor", "+", "window", ")", "+", "1", "\n", "cp_toks", "=", "ph_tok_list", "[", "st_pos", ":", "ed_pos", "]", "\n", "cp_tok_lists", ".", "append", "(", "cp_toks", ")", "\n", "", "return", "cp_tok_lists", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.dep_path_seq": [[59, 99], ["dependency_util.DependencyUtil.placeholding", "zip", "enumerate", "dependency_util.DependencyUtil.parser.parse", "int", "int", "dependency_util.DependencyUtil.find_path", "path_tok_lists.append", "head.rindex", "dep.rindex"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.placeholding", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.find_path"], ["", "def", "dep_path_seq", "(", "self", ",", "tok_list", ",", "linkings", ")", ":", "\n", "        ", "ph_tok_list", ",", "link_anchor_list", ",", "ans_anchor", "=", "self", ".", "placeholding", "(", "tok_list", "=", "tok_list", ",", "linkings", "=", "linkings", ")", "\n", "placeholder_dict", "=", "{", "}", "\n", "for", "link_anchor", ",", "gl_data", "in", "zip", "(", "link_anchor_list", ",", "linkings", ")", ":", "\n", "            ", "if", "gl_data", ".", "category", "==", "'Entity'", ":", "\n", "                ", "placeholder_dict", "[", "link_anchor", "]", "=", "'<E>'", "\n", "", "elif", "gl_data", ".", "category", "==", "'Time'", ":", "\n", "                ", "placeholder_dict", "[", "link_anchor", "]", "=", "'<Tm>'", "\n", "\n", "", "", "utterance", "=", "' '", ".", "join", "(", "ph_tok_list", ")", "\n", "if", "utterance", "not", "in", "self", ".", "dep_cache_dict", ":", "\n", "            ", "parse_result", "=", "self", ".", "parser", ".", "parse", "(", "utterance", ",", "parse_trees", "=", "True", ")", "\n", "dependency_parse", "=", "parse_result", ".", "dependency_parse", "\n", "self", ".", "dep_cache_dict", "[", "utterance", "]", "=", "dependency_parse", "\n", "#with open(self.dep_cache_fp, 'a') as bw:", "\n", "#    tup = (utterance.encode('utf-8'), dependency_parse.encode('utf-8'))", "\n", "#    bw.write(json.dumps(tup) + '\\n')", "\n", "", "else", ":", "\n", "            ", "dependency_parse", "=", "self", ".", "dep_cache_dict", "[", "utterance", "]", "\n", "\n", "", "edge_dict", "=", "{", "}", "\n", "for", "rel", ",", "head", ",", "dep", "in", "dependency_parse", ".", "dependencies", ":", "\n", "            ", "head_pos", "=", "int", "(", "head", "[", "head", ".", "rindex", "(", "'-'", ")", "+", "1", ":", "]", ")", "\n", "dep_pos", "=", "int", "(", "dep", "[", "dep", ".", "rindex", "(", "'-'", ")", "+", "1", ":", "]", ")", "\n", "fwd_key", "=", "'%d-%d'", "%", "(", "head_pos", ",", "dep_pos", ")", "\n", "bkwd_key", "=", "'%d-%d'", "%", "(", "dep_pos", ",", "head_pos", ")", "\n", "edge_dict", "[", "fwd_key", "]", "=", "rel", "\n", "edge_dict", "[", "bkwd_key", "]", "=", "'!%s'", "%", "rel", "\n", "\n", "", "path_tok_lists", "=", "[", "]", "\n", "for", "link_idx", ",", "link_anchor", "in", "enumerate", "(", "link_anchor_list", ")", ":", "\n", "            ", "category", "=", "linkings", "[", "link_idx", "]", ".", "category", "\n", "path_tok_list", "=", "self", ".", "find_path", "(", "dep_parse", "=", "dependency_parse", ",", "\n", "link_anchor", "=", "link_anchor", ",", "\n", "ans_anchor", "=", "ans_anchor", ",", "\n", "link_category", "=", "category", ",", "\n", "edge_dict", "=", "edge_dict", ",", "\n", "ph_dict", "=", "placeholder_dict", ")", "\n", "path_tok_lists", ".", "append", "(", "path_tok_list", ")", "\n", "", "return", "path_tok_lists", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.placeholding": [[100, 157], ["list", "enumerate", "zip", "enumerate", "enumerate", "range", "len", "len", "len", "len", "range", "tok_link_tups.append", "ph_tok.startswith", "dependency_util.DependencyUtil.e_t_dict.get", "len", "set"], "methods", ["None"], ["", "def", "placeholding", "(", "self", ",", "tok_list", ",", "linkings", ")", ":", "\n", "        ", "\"\"\" Given the original tokens, replace detail linking data by specific words or tokens \"\"\"", "\n", "\n", "# Step 1: Shrink each E/Tm link, occupying only one token", "\n", "ph_tok_list", "=", "list", "(", "tok_list", ")", "\n", "link_pos_list", "=", "[", "-", "1", "]", "*", "len", "(", "tok_list", ")", "\n", "\n", "for", "link_idx", ",", "gl_data", "in", "enumerate", "(", "linkings", ")", ":", "\n", "            ", "st", "=", "gl_data", ".", "start", "\n", "ed", "=", "gl_data", ".", "end", "\n", "if", "ed", "<", "len", "(", "link_pos_list", ")", ":", "\n", "                ", "link_pos_list", "[", "ed", "-", "1", "]", "=", "link_idx", "# identifying the anchor word of the current linking", "\n", "", "if", "gl_data", ".", "category", "in", "(", "'Entity'", ",", "'Time'", ")", ":", "# only perform placeholder for E/Tm", "\n", "                ", "for", "tok_idx", "in", "range", "(", "st", ",", "ed", "-", "1", ")", ":", "\n", "                    ", "if", "tok_idx", "<", "len", "(", "ph_tok_list", ")", ":", "\n", "                        ", "ph_tok_list", "[", "tok_idx", "]", "=", "''", "\n", "", "", "", "", "tok_link_tups", "=", "[", "]", "\n", "for", "ph_tok", ",", "link_idx", "in", "zip", "(", "ph_tok_list", ",", "link_pos_list", ")", ":", "\n", "            ", "if", "ph_tok", "!=", "''", ":", "\n", "                ", "tok_link_tups", ".", "append", "(", "[", "ph_tok", ",", "link_idx", "]", ")", "# remove non-trailing words of E/Tm", "\n", "\n", "", "", "link_anchor_list", "=", "[", "-", "1", "]", "*", "len", "(", "linkings", ")", "# the anchor position", "\n", "for", "anchor_idx", ",", "tup", "in", "enumerate", "(", "tok_link_tups", ")", ":", "\n", "            ", "link_idx", "=", "tup", "[", "-", "1", "]", "\n", "if", "link_idx", "!=", "-", "1", ":", "\n", "                ", "link_anchor_list", "[", "link_idx", "]", "=", "anchor_idx", "\n", "\n", "# Step 2: Determine answer's anchor point", "\n", "", "", "ans_anchor", "=", "0", "# find the first wh- word in the sentence, otherwise picking the first word", "\n", "for", "tok_idx", ",", "(", "ph_tok", ",", "link_idx", ")", "in", "enumerate", "(", "tok_link_tups", ")", ":", "\n", "            ", "if", "ph_tok", ".", "startswith", "(", "'wh'", ")", "or", "ph_tok", "==", "'how'", ":", "\n", "                ", "ans_anchor", "=", "tok_idx", "\n", "break", "\n", "\n", "# Step 3: Dynamic replacement", "\n", "", "", "for", "anchor_idx", "in", "range", "(", "len", "(", "tok_link_tups", ")", ")", ":", "\n", "            ", "ph_tok", ",", "link_idx", "=", "tok_link_tups", "[", "anchor_idx", "]", "\n", "if", "link_idx", "==", "-", "1", ":", "\n", "                ", "continue", "\n", "", "gl_data", "=", "linkings", "[", "link_idx", "]", "\n", "cate", "=", "gl_data", ".", "category", "\n", "if", "cate", "in", "(", "'Type'", ",", "'Ordinal'", ")", ":", "\n", "                ", "continue", "\n", "", "elif", "cate", "==", "'Time'", ":", "\n", "                ", "tok_link_tups", "[", "anchor_idx", "]", "[", "0", "]", "=", "'YYYY'", "# fix time", "\n", "", "else", ":", "\n", "                ", "entity_rep", "=", "'ENTITY'", "# default value", "\n", "mid", "=", "gl_data", ".", "value", "\n", "mid_tp_set", "=", "self", ".", "e_t_dict", ".", "get", "(", "mid", ",", "set", "(", "[", "]", ")", ")", "\n", "for", "tp", ",", "rep", "in", "type_replace_tups", ":", "\n", "                    ", "if", "tp", "in", "mid_tp_set", ":", "\n", "                        ", "entity_rep", "=", "rep", "\n", "break", "\n", "", "", "tok_link_tups", "[", "anchor_idx", "]", "[", "0", "]", "=", "entity_rep", "\n", "", "", "final_ph_tok_list", "=", "[", "tup", "[", "0", "]", "for", "tup", "in", "tok_link_tups", "]", "\n", "\n", "return", "final_ph_tok_list", ",", "link_anchor_list", ",", "ans_anchor", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.find_path": [[158, 202], ["len", "log_util.LogInfo.logs", "dep_parse.graph.shortest_path", "range", "path_tok_list.append", "path_tok_list.append", "path_tok_list.append", "path_tok_list.append", "path_tok_list.append", "path_tok_list.append"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "find_path", "(", "self", ",", "dep_parse", ",", "link_anchor", ",", "ans_anchor", ",", "link_category", ",", "edge_dict", ",", "ph_dict", ")", ":", "\n", "        ", "\"\"\"\n        :param dep_parse: dependency graph\n        :param link_anchor: token index of the focus word (0-based)\n        :param ans_anchor: token index of the answer (0-based)\n        :param link_category: the category of the current focus link\n        :param edge_dict: <head-dep, rel> dict\n        :param ph_dict: <token_idx, ph> dict\n        :return:\n        \"\"\"", "\n", "link_anchor", "+=", "1", "# ROOT is at position 0", "\n", "ans_anchor", "+=", "1", "\n", "src_node", "=", "dst_node", "=", "None", "\n", "for", "node", "in", "dep_parse", ".", "graph", ".", "nodes", ":", "\n", "            ", "if", "node", ".", "position", "==", "ans_anchor", ":", "\n", "                ", "src_node", "=", "node", "\n", "", "if", "node", ".", "position", "==", "link_anchor", ":", "\n", "                ", "dst_node", "=", "node", "\n", "", "", "if", "ans_anchor", "!=", "link_anchor", ":", "\n", "            ", "path_nodes", "=", "dep_parse", ".", "graph", ".", "shortest_path", "(", "node_a", "=", "src_node", ",", "node_b", "=", "dst_node", ")", "\n", "", "else", ":", "# just the node itself", "\n", "            ", "path_nodes", "=", "[", "dst_node", "]", "\n", "\n", "", "path_tok_list", "=", "[", "]", "\n", "path_len", "=", "len", "(", "path_nodes", ")", "\n", "if", "path_len", ">", "0", ":", "\n", "            ", "for", "pos", "in", "range", "(", "path_len", "-", "1", ")", ":", "\n", "                ", "key", "=", "'%d-%d'", "%", "(", "path_nodes", "[", "pos", "]", ".", "position", ",", "path_nodes", "[", "pos", "+", "1", "]", ".", "position", ")", "\n", "edge", "=", "edge_dict", "[", "key", "]", "\n", "cur_token_idx", "=", "path_nodes", "[", "pos", "]", ".", "position", "-", "1", "\n", "if", "cur_token_idx", "in", "ph_dict", ":", "# replace other focus in the path", "\n", "                    ", "path_tok_list", ".", "append", "(", "ph_dict", "[", "cur_token_idx", "]", ")", "\n", "", "else", ":", "\n", "                    ", "path_tok_list", ".", "append", "(", "path_nodes", "[", "pos", "]", ".", "word", ")", "\n", "", "path_tok_list", ".", "append", "(", "edge", ")", "\n", "", "if", "link_category", "==", "'Entity'", ":", "\n", "                ", "path_tok_list", ".", "append", "(", "'<E>'", ")", "\n", "", "elif", "link_category", "==", "'Time'", ":", "\n", "                ", "path_tok_list", ".", "append", "(", "'<Tm>'", ")", "\n", "", "else", ":", "\n", "                ", "path_tok_list", ".", "append", "(", "path_nodes", "[", "-", "1", "]", ".", "word", ")", "\n", "", "", "LogInfo", ".", "logs", "(", "'return path_tok_list: %s'", ",", "path_tok_list", ")", "\n", "\n", "return", "path_tok_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.print_func": [[13, 19], ["LogInfo.active_bw.write", "print"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "print_func", "(", "content", ")", ":", "\n", "        ", "if", "LogInfo", ".", "active_bw", "is", "not", "None", ":", "\n", "            ", "LogInfo", ".", "active_bw", ".", "write", "(", "content", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.redirect": [[20, 28], ["log_util.LogInfo.logs"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "@", "staticmethod", "\n", "def", "redirect", "(", "bw", ",", "lvl", "=", "0", ")", ":", "\n", "        ", "if", "bw", "is", "not", "None", "and", "(", "'w'", "in", "bw", ".", "mode", "or", "'a'", "in", "bw", ".", "mode", ")", ":", "\n", "            ", "LogInfo", ".", "active_bw", "=", "bw", "\n", "LogInfo", ".", "lvl_cache", "=", "LogInfo", ".", "lvl", "# save the level of stdout", "\n", "LogInfo", ".", "lvl", "=", "lvl", "# set the new level when outputting to the new file", "\n", "", "else", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'LogInfo: redirect failed.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.stop_redirect": [[29, 33], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "stop_redirect", "(", ")", ":", "\n", "        ", "LogInfo", ".", "active_bw", "=", "None", "\n", "LogInfo", ".", "lvl", "=", "LogInfo", ".", "lvl_cache", "# restore the level", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.get_blank": [[34, 40], ["range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_blank", "(", ")", ":", "\n", "        ", "blank", "=", "''", "\n", "for", "i", "in", "range", "(", "LogInfo", ".", "lvl", ")", ":", "\n", "            ", "blank", "+=", "'  '", "\n", "", "return", "blank", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track": [[41, 51], ["log_util.LogInfo.get_blank", "LogInfo.time_list.append", "len", "log_util.LogInfo.print_func", "log_util.LogInfo.print_func", "time.time"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.get_blank", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.print_func", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.print_func"], ["", "@", "staticmethod", "\n", "def", "begin_track", "(", "fmt_string", "=", "''", ",", "*", "args", ")", ":", "\n", "        ", "blank", "=", "LogInfo", ".", "get_blank", "(", ")", "\n", "if", "len", "(", "args", ")", "==", "0", ":", "\n", "            ", "LogInfo", ".", "print_func", "(", "blank", "+", "'%s'", "%", "fmt_string", "+", "' {'", ")", "\n", "", "else", ":", "\n", "            ", "fmt", "=", "blank", "+", "fmt_string", "+", "' {'", "\n", "LogInfo", ".", "print_func", "(", "fmt", "%", "args", ")", "\n", "", "LogInfo", ".", "lvl", "+=", "1", "\n", "LogInfo", ".", "time_list", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs": [[52, 60], ["log_util.LogInfo.get_blank", "len", "log_util.LogInfo.print_func", "log_util.LogInfo.print_func"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.get_blank", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.print_func", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.print_func"], ["", "@", "staticmethod", "\n", "def", "logs", "(", "fmt_string", "=", "''", ",", "*", "args", ")", ":", "\n", "        ", "blank", "=", "LogInfo", ".", "get_blank", "(", ")", "\n", "if", "len", "(", "args", ")", "==", "0", ":", "\n", "            ", "LogInfo", ".", "print_func", "(", "blank", "+", "'%s'", "%", "fmt_string", ")", "\n", "", "else", ":", "\n", "            ", "fmt", "=", "blank", "+", "fmt_string", "\n", "LogInfo", ".", "print_func", "(", "fmt", "%", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track": [[61, 78], ["log_util.LogInfo.get_blank", "log_util.LogInfo.print_func", "log_util.LogInfo.logs", "len", "time.time", "LogInfo.time_list.pop", "log_util.LogInfo.show_time"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.get_blank", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.print_func", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.show_time"], ["", "", "@", "staticmethod", "\n", "def", "end_track", "(", "fmt_string", "=", "''", ",", "*", "args", ")", ":", "\n", "        ", "if", "fmt_string", "!=", "''", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "fmt_string", ",", "*", "args", ")", "\n", "", "LogInfo", ".", "lvl", "-=", "1", "\n", "if", "LogInfo", ".", "lvl", "<", "0", ":", "\n", "            ", "LogInfo", ".", "lvl", "=", "0", "\n", "", "blank", "=", "LogInfo", ".", "get_blank", "(", ")", "\n", "fmt", "=", "blank", "+", "'}'", "\n", "# if fmt_string != '':", "\n", "#     fmt += ' ' + fmt_string", "\n", "time_str", "=", "''", "\n", "if", "len", "(", "LogInfo", ".", "time_list", ")", ">=", "1", ":", "\n", "            ", "elapse", "=", "time", ".", "time", "(", ")", "-", "LogInfo", ".", "time_list", ".", "pop", "(", ")", "\n", "time_str", "=", "' [%s]'", "%", "LogInfo", ".", "show_time", "(", "elapse", ")", "\n", "", "fmt", "+=", "time_str", "\n", "LogInfo", ".", "print_func", "(", "fmt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.show_time": [[79, 96], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "show_time", "(", "elapse", ")", ":", "\n", "        ", "ret", "=", "''", "\n", "if", "elapse", ">", "86400", ":", "\n", "            ", "d", "=", "elapse", "/", "86400", "\n", "elapse", "%=", "86400", "\n", "ret", "+=", "'%dd'", "%", "d", "\n", "", "if", "elapse", ">", "3600", ":", "\n", "            ", "h", "=", "elapse", "/", "3600", "\n", "elapse", "%=", "3600", "\n", "ret", "+=", "'%dh'", "%", "h", "\n", "", "if", "elapse", ">", "60", ":", "\n", "            ", "m", "=", "elapse", "/", "60", "\n", "elapse", "%=", "60", "\n", "ret", "+=", "'%dm'", "%", "m", "\n", "", "ret", "+=", "'%.3fs'", "%", "elapse", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.show_line": [[97, 101], ["log_util.LogInfo.logs"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "@", "staticmethod", "\n", "def", "show_line", "(", "cnt", ",", "num", ")", ":", "\n", "        ", "if", "cnt", "%", "num", "==", "0", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "\"%d lines loaded.\"", ",", "cnt", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.__init__": [[9, 28], ["embedding_util.WordEmbeddingUtil.load_word_indices", "embedding_util.WordEmbeddingUtil.load_mid_indices", "embedding_util.WordEmbeddingUtil.load_dep_names"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_word_indices", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_mid_indices", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_dep_names"], ["    ", "def", "__init__", "(", "self", ",", "emb_dir", ",", "dim_emb", ")", ":", "\n", "        ", "self", ".", "word_dict_fp", "=", "'%s/word_emb.indices'", "%", "emb_dir", "\n", "self", ".", "word_emb_mat_fp", "=", "'%s/word_emb.glove_%d.npy'", "%", "(", "emb_dir", ",", "dim_emb", ")", "\n", "self", ".", "mid_dict_fp", "=", "'%s/mid_emb.indices'", "%", "emb_dir", "\n", "self", ".", "mid_emb_mat_fp", "=", "'%s/mid_emb.glove_%d.npy'", "%", "(", "emb_dir", ",", "dim_emb", ")", "\n", "self", ".", "dep_name_fp", "=", "'%s/dep_names.txt'", "%", "emb_dir", "\n", "\n", "self", ".", "dim_emb", "=", "dim_emb", "\n", "self", ".", "word_idx_dict", "=", "None", "\n", "self", ".", "word_emb_matrix", "=", "None", "\n", "self", ".", "n_words", "=", "None", "\n", "self", ".", "mid_idx_dict", "=", "None", "\n", "self", ".", "mid_emb_matrix", "=", "None", "\n", "self", ".", "n_mids", "=", "None", "\n", "self", ".", "dep_name_dict", "=", "{", "}", "\n", "\n", "self", ".", "load_word_indices", "(", ")", "\n", "self", ".", "load_mid_indices", "(", ")", "\n", "self", ".", "load_dep_names", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_word_indices": [[29, 36], ["log_util.LogInfo.logs", "log_util.LogInfo.logs", "len", "open", "pickle.load", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "load_word_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "word_idx_dict", "is", "None", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'Loading <word, idx> pairs from [%s] ... '", ",", "self", ".", "word_dict_fp", ")", "\n", "with", "open", "(", "self", ".", "word_dict_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "                ", "self", ".", "word_idx_dict", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d <word, idx> loaded.'", ",", "len", "(", "self", ".", "word_idx_dict", ")", ")", "\n", "self", ".", "n_words", "=", "len", "(", "self", ".", "word_idx_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_mid_indices": [[37, 44], ["log_util.LogInfo.logs", "log_util.LogInfo.logs", "len", "open", "pickle.load", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "def", "load_mid_indices", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mid_idx_dict", "is", "None", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'Loading <mid, idx> pairs from [%s] ... '", ",", "self", ".", "mid_dict_fp", ")", "\n", "with", "open", "(", "self", ".", "mid_dict_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "                ", "self", ".", "mid_idx_dict", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d <mid, idx> loaded.'", ",", "len", "(", "self", ".", "mid_idx_dict", ")", ")", "\n", "self", ".", "n_mids", "=", "len", "(", "self", ".", "mid_idx_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_word_embeddings": [[45, 51], ["log_util.LogInfo.logs", "numpy.load", "log_util.LogInfo.logs"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "def", "load_word_embeddings", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "word_emb_matrix", "is", "None", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'Loading word embeddings for [%s] ...'", ",", "self", ".", "word_emb_mat_fp", ")", "\n", "self", ".", "word_emb_matrix", "=", "np", ".", "load", "(", "self", ".", "word_emb_mat_fp", ")", "\n", "LogInfo", ".", "logs", "(", "'%s word embedding loaded.'", ",", "self", ".", "word_emb_matrix", ".", "shape", ")", "\n", "assert", "self", ".", "word_emb_matrix", ".", "shape", "==", "(", "self", ".", "n_words", ",", "self", ".", "dim_emb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_mid_embeddings": [[52, 58], ["log_util.LogInfo.logs", "numpy.load", "log_util.LogInfo.logs"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "def", "load_mid_embeddings", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mid_emb_matrix", "is", "None", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'Loading mid embeddings for [%s] ...'", ",", "self", ".", "mid_emb_mat_fp", ")", "\n", "self", ".", "mid_emb_matrix", "=", "np", ".", "load", "(", "self", ".", "mid_emb_mat_fp", ")", "\n", "LogInfo", ".", "logs", "(", "'%s mid embedding loaded.'", ",", "self", ".", "mid_emb_matrix", ".", "shape", ")", "\n", "assert", "self", ".", "mid_emb_matrix", ".", "shape", "==", "(", "self", ".", "n_mids", ",", "self", ".", "dim_emb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_dep_names": [[59, 65], ["log_util.LogInfo.logs", "open", "br.readlines", "len", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "def", "load_dep_names", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "dep_name_fp", ",", "'r'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "dep", ",", "name", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "self", ".", "dep_name_dict", "[", "dep", "]", "=", "name", "\n", "", "", "LogInfo", ".", "logs", "(", "'%d dependency name loaded.'", ",", "len", "(", "self", ".", "dep_name_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.get_phrase_emb": [[66, 83], ["embedding_util.WordEmbeddingUtil.load_word_embeddings", "phrase.split", "numpy.mean", "len", "numpy.linalg.norm", "idx_list.append"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_word_embeddings"], ["", "def", "get_phrase_emb", "(", "self", ",", "phrase", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the embedding of a new phrase, by averaging the embeddings of all observed words\n        \"\"\"", "\n", "self", ".", "load_word_embeddings", "(", ")", "\n", "if", "phrase", "==", "''", ":", "\n", "            ", "return", "None", "\n", "", "spt", "=", "phrase", ".", "split", "(", "' '", ")", "\n", "idx_list", "=", "[", "]", "\n", "for", "wd", "in", "spt", ":", "\n", "            ", "if", "wd", "in", "self", ".", "word_idx_dict", ":", "\n", "                ", "idx_list", ".", "append", "(", "self", ".", "word_idx_dict", "[", "wd", "]", ")", "\n", "", "", "if", "len", "(", "idx_list", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "emb", "=", "np", ".", "mean", "(", "self", ".", "word_emb_matrix", "[", "idx_list", "]", ",", "axis", "=", "0", ")", "# (n_words, dim_emb) ==> (dim_emb, )", "\n", "emb", "=", "emb", "/", "np", ".", "linalg", ".", "norm", "(", "emb", ")", "# normalization", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.produce_active_word_embedding": [[84, 115], ["len", "numpy.random.uniform().astype", "embedding_util.WordEmbeddingUtil.load_word_indices", "embedding_util.WordEmbeddingUtil.load_word_embeddings", "active_word_dict.items", "log_util.LogInfo.logs", "log_util.LogInfo.logs", "numpy.random.uniform", "tok.replace", "embedding_util.WordEmbeddingUtil.dep_name_dict[].split", "list", "numpy.zeros", "len", "filter", "len", "tok.startswith"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_word_indices", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_word_embeddings", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "produce_active_word_embedding", "(", "self", ",", "active_word_dict", ",", "dep_simulate", "=", "False", ")", ":", "\n", "        ", "active_size", "=", "len", "(", "active_word_dict", ")", "\n", "word_emb_matrix", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0.1", ",", "high", "=", "0.1", ",", "\n", "size", "=", "(", "active_size", ",", "self", ".", "dim_emb", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "self", ".", "load_word_indices", "(", ")", "\n", "self", ".", "load_word_embeddings", "(", ")", "\n", "for", "tok", ",", "active_idx", "in", "active_word_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "tok", "in", "self", ".", "word_idx_dict", ":", "\n", "                ", "local_idx", "=", "self", ".", "word_idx_dict", "[", "tok", "]", "\n", "word_emb_matrix", "[", "active_idx", "]", "=", "self", ".", "word_emb_matrix", "[", "local_idx", "]", "\n", "", "elif", "dep_simulate", ":", "# try to simulate the embedding of dependency label", "\n", "                ", "dep_tok", "=", "tok", ".", "replace", "(", "'!'", ",", "''", ")", "\n", "if", "dep_tok", "in", "self", ".", "dep_name_dict", ":", "# this is a known dependency label", "\n", "                    ", "dep_name_spt", "=", "self", ".", "dep_name_dict", "[", "dep_tok", "]", ".", "split", "(", "' '", ")", "\n", "filt_dep_name_spt", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "in", "self", ".", "word_idx_dict", ",", "dep_name_spt", ")", ")", "\n", "if", "len", "(", "filt_dep_name_spt", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "# Now simulate dependency embedding by its name", "\n", "", "simu_emb", "=", "np", ".", "zeros", "(", "(", "self", ".", "dim_emb", ",", ")", ",", "dtype", "=", "'float32'", ")", "\n", "for", "term", "in", "filt_dep_name_spt", ":", "\n", "                        ", "term_idx", "=", "self", ".", "word_idx_dict", "[", "term", "]", "\n", "simu_emb", "+=", "self", ".", "word_emb_matrix", "[", "term_idx", "]", "\n", "", "simu_emb", "/=", "len", "(", "filt_dep_name_spt", ")", "\n", "if", "not", "tok", ".", "startswith", "(", "'!'", ")", ":", "\n", "                        ", "word_emb_matrix", "[", "active_idx", "]", "=", "simu_emb", "\n", "", "else", ":", "# reversed label", "\n", "                        ", "word_emb_matrix", "[", "active_idx", "]", "=", "-", "1.", "*", "simu_emb", "\n", "\n", "", "", "", "", "LogInfo", ".", "logs", "(", "'dependency simulate = %s.'", ",", "dep_simulate", ")", "\n", "LogInfo", ".", "logs", "(", "'%s active word embedding created.'", ",", "word_emb_matrix", ".", "shape", ")", "\n", "return", "word_emb_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.produce_active_mid_embedding": [[116, 128], ["len", "numpy.random.uniform().astype", "embedding_util.WordEmbeddingUtil.load_mid_indices", "embedding_util.WordEmbeddingUtil.load_mid_embeddings", "active_mid_dict.items", "log_util.LogInfo.logs", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_mid_indices", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.load_mid_embeddings", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "produce_active_mid_embedding", "(", "self", ",", "active_mid_dict", ")", ":", "\n", "        ", "active_size", "=", "len", "(", "active_mid_dict", ")", "\n", "mid_emb_matrix", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0.1", ",", "high", "=", "0.1", ",", "\n", "size", "=", "(", "active_size", ",", "self", ".", "dim_emb", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "self", ".", "load_mid_indices", "(", ")", "\n", "self", ".", "load_mid_embeddings", "(", ")", "\n", "for", "tok", ",", "active_idx", "in", "active_mid_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "tok", "in", "self", ".", "mid_idx_dict", ":", "\n", "                ", "local_idx", "=", "self", ".", "mid_idx_dict", "[", "tok", "]", "\n", "mid_emb_matrix", "[", "active_idx", "]", "=", "self", ".", "mid_emb_matrix", "[", "local_idx", "]", "\n", "", "", "LogInfo", ".", "logs", "(", "'%s active mid embedding created.'", ",", "mid_emb_matrix", ".", "shape", ")", "\n", "return", "mid_emb_matrix", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.save_model": [[9, 20], ["time.time", "log_util.LogInfo.logs", "saver.save", "log_util.LogInfo.logs", "os.path.exists", "os.makedirs", "open", "bw.write", "bw.write", "time.time"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["def", "save_model", "(", "saver", ",", "sess", ",", "model_dir", ",", "epoch", ",", "valid_metric", ")", ":", "\n", "    ", "t0", "=", "time", ".", "time", "(", ")", "\n", "LogInfo", ".", "logs", "(", "'Saving model into [%s] ...'", ",", "model_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dir", ")", "\n", "", "model_fp", "=", "model_dir", "+", "'/best.model'", "\n", "saver", ".", "save", "(", "sess", ",", "model_fp", ")", "\n", "with", "open", "(", "model_dir", "+", "'/epoch'", ",", "'w'", ")", "as", "bw", ":", "\n", "        ", "bw", ".", "write", "(", "'epoch=%d\\n'", "%", "epoch", ")", "\n", "bw", ".", "write", "(", "'valid_F1=%.6f\\n'", "%", "valid_metric", ")", "\n", "", "LogInfo", ".", "logs", "(", "'Saved [%.3fs]'", ",", "time", ".", "time", "(", ")", "-", "t0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.load_model": [[22, 37], ["time.time", "log_util.LogInfo.logs", "saver.restore", "log_util.LogInfo.logs", "os.path.isfile", "time.time", "open", "int", "float", "br.readline().strip", "br.readline().strip", "br.readline", "br.readline"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "load_model", "(", "saver", ",", "sess", ",", "model_dir", ")", ":", "\n", "    ", "t0", "=", "time", ".", "time", "(", ")", "\n", "LogInfo", ".", "logs", "(", "'Loading model from [%s] ...'", ",", "model_dir", ")", "\n", "model_fp", "=", "model_dir", "+", "'/best.model'", "\n", "saver", ".", "restore", "(", "sess", ",", "model_fp", ")", "\n", "LogInfo", ".", "logs", "(", "'Loaded [%.3fs]'", ",", "time", ".", "time", "(", ")", "-", "t0", ")", "\n", "\n", "start_epoch", "=", "0", "\n", "valid_metric", "=", "0.", "\n", "epoch_nb_fp", "=", "model_dir", "+", "'/epoch'", "\n", "if", "os", ".", "path", ".", "isfile", "(", "epoch_nb_fp", ")", ":", "\n", "        ", "with", "open", "(", "epoch_nb_fp", ",", "'r'", ")", "as", "br", ":", "\n", "            ", "start_epoch", "=", "int", "(", "br", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "valid_metric", "=", "float", "(", "br", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "", "", "return", "start_epoch", ",", "valid_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.analyze_status": [[39, 64], ["enumerate", "lines[].strip().replace().split", "open", "br.readlines", "line.startswith", "ret_dict.setdefault", "line.strip().replace().split", "zip", "lines.append", "lines[].strip().replace", "re.sub().strip", "line.strip().replace", "float", "ret_dict[].append", "lines[].strip", "ret_dict[].append", "re.sub", "line.strip"], "function", ["None"], ["", "def", "analyze_status", "(", "status_fp", ")", ":", "\n", "    ", "\"\"\" Read the status file, and keep the last running information \"\"\"", "\n", "lines", "=", "[", "]", "\n", "with", "open", "(", "status_fp", ",", "'r'", ")", "as", "br", ":", "\n", "        ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "            ", "lines", ".", "append", "(", "re", ".", "sub", "(", "' +'", ",", "'\\t'", ",", "line", ")", ".", "strip", "(", ")", ")", "\n", "", "", "start_idx", "=", "0", "\n", "for", "line_idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "'Epoch'", ")", ":", "\n", "            ", "start_idx", "=", "line_idx", "\n", "\n", "", "", "ret_dict", "=", "{", "}", "# <Key, [Value]>", "\n", "header_spt", "=", "lines", "[", "start_idx", "]", ".", "strip", "(", ")", ".", "replace", "(", "' '", ",", "'\\t'", ")", ".", "split", "(", "'\\t'", ")", "\n", "for", "key", "in", "header_spt", ":", "\n", "        ", "ret_dict", ".", "setdefault", "(", "key", ",", "[", "]", ")", "\n", "", "for", "line", "in", "lines", "[", "start_idx", "+", "1", ":", "]", ":", "\n", "        ", "value_spt", "=", "line", ".", "strip", "(", ")", ".", "replace", "(", "' '", ",", "'\\t'", ")", ".", "split", "(", "'\\t'", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "header_spt", ",", "value_spt", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "v_float", "=", "float", "(", "value", ")", "\n", "ret_dict", "[", "key", "]", ".", "append", "(", "v_float", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "ret_dict", "[", "key", "]", ".", "append", "(", "value", ")", "\n", "\n", "", "", "", "return", "ret_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.construct_display_header": [[66, 82], ["raw_header_list.append", "enumerate", "local_header_list.append", "disp_header_list.append", "header.endswith", "disp_header_list.append", "header.endswith"], "function", ["None"], ["", "def", "construct_display_header", "(", ")", ":", "\n", "    ", "raw_header_list", "=", "[", "'Epoch'", "]", "\n", "local_header_list", "=", "[", "'rm_loss'", "]", "\n", "for", "mark", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "        ", "local_header_list", ".", "append", "(", "'%s_F1'", "%", "mark", ")", "\n", "", "raw_header_list", ".", "append", "(", "' |  '", ")", "\n", "raw_header_list", "+=", "local_header_list", "\n", "raw_header_list", "+=", "[", "' |  '", ",", "'Status'", ",", "'Time'", "]", "\n", "disp_header_list", "=", "[", "]", "\n", "no_tab", "=", "True", "\n", "for", "idx", ",", "header", "in", "enumerate", "(", "raw_header_list", ")", ":", "\n", "        ", "if", "not", "(", "no_tab", "or", "header", ".", "endswith", "(", "' '", ")", ")", ":", "\n", "            ", "disp_header_list", ".", "append", "(", "'\\t'", ")", "\n", "", "disp_header_list", ".", "append", "(", "header", ")", "\n", "no_tab", "=", "header", ".", "endswith", "(", "' '", ")", "\n", "", "return", "disp_header_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.delete_dir": [[84, 89], ["os.path.islink", "os.remove", "os.path.isdir", "shutil.rmtree"], "function", ["None"], ["", "def", "delete_dir", "(", "target_dir", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "islink", "(", "target_dir", ")", ":", "\n", "        ", "os", ".", "remove", "(", "target_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "target_dir", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "target_dir", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.kbqa.main_kbqa.main": [[76, 299], ["src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.utils.embedding_util.WordEmbeddingUtil", "src.kbqa.dataset.freebase_helper.FreebaseHelper", "src.kbqa.utils.log_util.LogInfo.end_track", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.dataset.schema_dataset.SchemaDataset", "src.kbqa.dataset.schema_dataset.SchemaDataset.load_all_data", "src.kbqa.dataset.feature_helper.FeatureHelper", "src.kbqa.dataset.schema_builder.SchemaBuilder", "src.kbqa.utils.log_util.LogInfo.end_track", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.model.kbqa_model.KbqaModel", "src.kbqa.utils.log_util.LogInfo.logs", "tensorflow.global_variables", "src.kbqa.utils.log_util.LogInfo.end_track", "src.kbqa.utils.log_util.LogInfo.begin_track", "zip", "src.kbqa.utils.log_util.LogInfo.end_track", "tensorflow.train.Saver", "tensorflow.GPUOptions", "tensorflow.Session", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.utils.log_util.LogInfo.end_track", "src.kbqa.learner.optimizer.Optimizer", "src.kbqa.learner.evaluator.Evaluator", "src.kbqa.dataset.schema_builder.SchemaBuilder.build_optm_dataloader", "src.kbqa.dataset.schema_builder.SchemaBuilder.build_eval_dataloader", "src.kbqa.utils.log_util.LogInfo.begin_track", "range", "src.kbqa.utils.log_util.LogInfo.end_track", "os.path.exists", "os.mkdir", "open", "json.dump", "src.kbqa.utils.log_util.LogInfo.logs", "tensorflow.variable_scope", "len", "src.kbqa.utils.log_util.LogInfo.logs", "os.path.exists", "src.kbqa.utils.model_util.load_model", "src.kbqa.utils.embedding_util.WordEmbeddingUtil.produce_active_word_embedding", "numpy.random.uniform().astype", "numpy.random.uniform().astype", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.logs", "tf.Session.run", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.learner.optimizer.Optimizer.optimize_all", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.end_track", "src.kbqa.utils.log_util.LogInfo.begin_track", "zip", "src.kbqa.utils.log_util.LogInfo.end_track", "src.kbqa.utils.log_util.LogInfo.logs", "datetime.datetime.now().strftime", "src.kbqa.utils.model_util.construct_display_header", "src.kbqa.utils.log_util.LogInfo.logs", "tf.Session.run", "zip", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.end_track", "tf.get_variable.get_shape().as_list", "tensor.get_shape().as_list", "tensorflow.ConfigProto", "tensorflow.global_variables_initializer", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.learner.evaluator.Evaluator.evaluate_all", "src.kbqa.utils.log_util.LogInfo.end_track", "src.kbqa.utils.model_util.delete_dir", "src.kbqa.utils.model_util.save_model", "str", "open", "enumerate", "bw.write", "open", "pickle.dump", "tensorflow.get_variable", "focus_param_list.append", "numpy.random.uniform", "numpy.random.uniform", "datetime.datetime.now", "open", "bw.write", "open", "pickle.dump", "os.path.isfile", "tf.get_variable.get_shape", "src.kbqa.utils.log_util.LogInfo.logs", "tensor.get_shape", "header.endswith", "disp_item_dict.get", "isinstance", "shutil.move", "str"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_all_data", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder.build_optm_dataloader", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder.build_eval_dataloader", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.load_model", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.embedding_util.WordEmbeddingUtil.produce_active_word_embedding", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer.optimize_all", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.construct_display_header", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator.evaluate_all", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.delete_dir", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.model_util.save_model", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "# ==== Loading necessary utils ====", "\n", "    ", "LogInfo", ".", "begin_track", "(", "'Loading Utils ... '", ")", "\n", "wd_emb_util", "=", "WordEmbeddingUtil", "(", "emb_dir", "=", "args", ".", "emb_dir", ",", "dim_emb", "=", "args", ".", "dim_emb", ")", "\n", "freebase_helper", "=", "FreebaseHelper", "(", "meta_dir", "=", "args", ".", "fb_meta_dir", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "# ==== Loading dataset ====", "\n", "LogInfo", ".", "begin_track", "(", "'Creating Dataset ... '", ")", "\n", "schema_dataset", "=", "SchemaDataset", "(", "data_dir", "=", "args", ".", "data_dir", ",", "candgen_dir", "=", "args", ".", "candgen_dir", ",", "\n", "schema_level", "=", "args", ".", "schema_level", ",", "freebase_helper", "=", "freebase_helper", ")", "\n", "schema_dataset", ".", "load_all_data", "(", ")", "\n", "active_dicts", "=", "schema_dataset", ".", "active_dicts", "\n", "qa_list", "=", "schema_dataset", ".", "qa_list", "\n", "feature_helper", "=", "FeatureHelper", "(", "active_dicts", ",", "qa_list", ",", "freebase_helper", ",", "path_max_size", "=", "args", ".", "path_max_size", ",", "\n", "qw_max_len", "=", "args", ".", "qw_max_len", ",", "pw_max_len", "=", "args", ".", "pw_max_len", ",", "\n", "pseq_max_len", "=", "args", ".", "pseq_max_len", ")", "\n", "ds_builder", "=", "SchemaBuilder", "(", "schema_dataset", "=", "schema_dataset", ",", "feature_helper", "=", "feature_helper", ",", "\n", "neg_f1_ths", "=", "args", ".", "neg_f1_ths", ",", "neg_max_sample", "=", "args", ".", "neg_max_sample", ",", "\n", "neg_strategy", "=", "args", ".", "neg_strategy", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "# ==== Building model ====", "\n", "LogInfo", ".", "begin_track", "(", "'Building Model and Session ... '", ")", "\n", "model_config", "=", "{", "'qw_max_len'", ":", "args", ".", "qw_max_len", ",", "\n", "'pw_max_len'", ":", "args", ".", "pw_max_len", ",", "\n", "'path_max_size'", ":", "args", ".", "path_max_size", ",", "\n", "'pseq_max_len'", ":", "args", ".", "pseq_max_len", ",", "\n", "'dim_emb'", ":", "args", ".", "dim_emb", ",", "\n", "'w_emb_fix'", ":", "args", ".", "w_emb_fix", ",", "\n", "'n_words'", ":", "args", ".", "n_words", ",", "\n", "'n_mids'", ":", "args", ".", "n_mids", ",", "\n", "'n_paths'", ":", "args", ".", "n_paths", ",", "\n", "'drop_rate'", ":", "args", ".", "drop_rate", ",", "\n", "'rnn_config'", ":", "{", "'cell_class'", ":", "args", ".", "cell_class", ",", "\n", "'num_units'", ":", "args", ".", "num_units", ",", "\n", "'num_layers'", ":", "args", ".", "num_layers", "}", ",", "\n", "'att_config'", ":", "{", "'att_func'", ":", "args", ".", "att_func", ",", "\n", "'dim_att_hidden'", ":", "args", ".", "dim_att_hidden", "}", ",", "\n", "'path_usage'", ":", "args", ".", "path_usage", ",", "\n", "'sent_usage'", ":", "args", ".", "sent_usage", ",", "\n", "'seq_merge_mode'", ":", "args", ".", "seq_merge_mode", ",", "\n", "'scoring_mode'", ":", "args", ".", "scoring_mode", ",", "\n", "'final_func'", ":", "args", ".", "final_func", ",", "\n", "'loss_margin'", ":", "args", ".", "loss_margin", ",", "\n", "'optm_name'", ":", "args", ".", "optm_name", ",", "\n", "'learning_rate'", ":", "args", ".", "lr_rate", "\n", "}", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "output_dir", ")", "\n", "", "with", "open", "(", "\"%s/config.json\"", "%", "args", ".", "output_dir", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "model_config", ",", "fw", ")", "\n", "\n", "", "kbqa_model", "=", "KbqaModel", "(", "**", "model_config", ")", "\n", "\n", "LogInfo", ".", "logs", "(", "'Showing final parameters: '", ")", "\n", "for", "var", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "        ", "LogInfo", ".", "logs", "(", "'%s: %s'", ",", "var", ".", "name", ",", "var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "\n", "", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "# ==== Focused on specific params ====", "\n", "if", "args", ".", "final_func", "==", "'bilinear'", ":", "\n", "        ", "focus_param_name_list", "=", "[", "'rm_task/rm_forward/bilinear_mat'", "]", "\n", "", "else", ":", "# mlp", "\n", "        ", "focus_param_name_list", "=", "[", "'rm_task/rm_forward/fc1/weights'", ",", "\n", "'rm_task/rm_forward/fc1/biases'", ",", "\n", "'rm_task/rm_forward/fc2/weights'", ",", "\n", "'rm_task/rm_forward/fc2/biases'", "]", "\n", "", "focus_param_list", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "''", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "for", "param_name", "in", "focus_param_name_list", ":", "\n", "            ", "try", ":", "\n", "                ", "var", "=", "tf", ".", "get_variable", "(", "name", "=", "param_name", ")", "\n", "focus_param_list", ".", "append", "(", "var", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "\"ValueError occured for %s!\"", "%", "param_name", ")", "\n", "pass", "\n", "", "", "", "LogInfo", ".", "begin_track", "(", "'Showing %d concern parameters: '", ",", "len", "(", "focus_param_list", ")", ")", "\n", "for", "name", ",", "tensor", "in", "zip", "(", "focus_param_name_list", ",", "focus_param_list", ")", ":", "\n", "        ", "LogInfo", ".", "logs", "(", "'%s --> %s'", ",", "name", ",", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "# ==== Initializing model ====", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ",", "\n", "per_process_gpu_memory_fraction", "=", "args", ".", "gpu_fraction", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ",", "\n", "intra_op_parallelism_threads", "=", "8", ")", ")", "\n", "LogInfo", ".", "begin_track", "(", "'Running global_variables_initializer ...'", ")", "\n", "start_epoch", "=", "0", "\n", "best_valid_f1", "=", "0.", "\n", "resume_flag", "=", "False", "\n", "model_dir", "=", "None", "\n", "if", "args", ".", "resume_model_name", "not", "in", "(", "''", ",", "'None'", ")", ":", "\n", "        ", "model_dir", "=", "'%s/%s'", "%", "(", "args", ".", "output_dir", ",", "args", ".", "resume_model_name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_dir", ")", ":", "\n", "            ", "resume_flag", "=", "True", "\n", "", "", "if", "resume_flag", ":", "\n", "        ", "start_epoch", ",", "best_valid_f1", "=", "model_util", ".", "load_model", "(", "saver", "=", "saver", ",", "sess", "=", "sess", ",", "model_dir", "=", "model_dir", ")", "\n", "", "else", ":", "\n", "        ", "dep_simulate", "=", "True", "if", "args", ".", "dep_simulate", "==", "'True'", "else", "False", "\n", "wd_emb_mat", "=", "wd_emb_util", ".", "produce_active_word_embedding", "(", "\n", "active_word_dict", "=", "schema_dataset", ".", "active_dicts", "[", "'word'", "]", ",", "\n", "dep_simulate", "=", "dep_simulate", "\n", ")", "\n", "pa_emb_mat", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0.1", ",", "high", "=", "0.1", ",", "\n", "size", "=", "(", "model_config", "[", "'n_paths'", "]", ",", "\n", "model_config", "[", "'dim_emb'", "]", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "mid_emb_mat", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "0.1", ",", "high", "=", "0.1", ",", "\n", "size", "=", "(", "model_config", "[", "'n_mids'", "]", ",", "\n", "model_config", "[", "'dim_emb'", "]", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "LogInfo", ".", "logs", "(", "'%s random path embedding created.'", ",", "pa_emb_mat", ".", "shape", ")", "\n", "LogInfo", ".", "logs", "(", "'%s random mid embedding created.'", ",", "mid_emb_mat", ".", "shape", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ",", "\n", "feed_dict", "=", "{", "kbqa_model", ".", "w_embedding_init", ":", "wd_emb_mat", ",", "\n", "kbqa_model", ".", "p_embedding_init", ":", "pa_emb_mat", ",", "\n", "kbqa_model", ".", "m_embedding_init", ":", "mid_emb_mat", "}", ")", "\n", "", "LogInfo", ".", "end_track", "(", "'Model build complete.'", ")", "\n", "\n", "# ==== Running optm / eval ====", "\n", "optimizer", "=", "Optimizer", "(", "model", "=", "kbqa_model", ",", "sess", "=", "sess", ")", "\n", "evaluator", "=", "Evaluator", "(", "model", "=", "kbqa_model", ",", "sess", "=", "sess", ")", "\n", "optm_data_loader", "=", "ds_builder", ".", "build_optm_dataloader", "(", "optm_batch_size", "=", "args", ".", "optm_batch_size", ")", "\n", "eval_data_list", "=", "ds_builder", ".", "build_eval_dataloader", "(", "eval_batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "'%s/detail'", "%", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/detail'", "%", "args", ".", "output_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'%s/result'", "%", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'%s/result'", "%", "args", ".", "output_dir", ")", "\n", "\n", "", "LogInfo", ".", "begin_track", "(", "'Learning start ...'", ")", "\n", "\n", "patience", "=", "args", ".", "max_patience", "\n", "for", "epoch", "in", "range", "(", "start_epoch", "+", "1", ",", "args", ".", "max_epoch", "+", "1", ")", ":", "\n", "        ", "if", "patience", "==", "0", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'Early stopping at epoch = %d.'", ",", "epoch", ")", "\n", "break", "\n", "", "update_flag", "=", "False", "\n", "disp_item_dict", "=", "{", "'Epoch'", ":", "epoch", "}", "\n", "\n", "LogInfo", ".", "begin_track", "(", "'Epoch %d / %d'", ",", "epoch", ",", "args", ".", "max_epoch", ")", "\n", "\n", "LogInfo", ".", "begin_track", "(", "'Optimizing ... '", ")", "\n", "optimizer", ".", "optimize_all", "(", "optm_data_loader", "=", "optm_data_loader", ")", "\n", "\n", "LogInfo", ".", "logs", "(", "'loss = %.6f'", ",", "optimizer", ".", "ret_loss", ")", "\n", "disp_item_dict", "[", "'rm_loss'", "]", "=", "optimizer", ".", "ret_loss", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "LogInfo", ".", "begin_track", "(", "'Evaluation:'", ")", "\n", "for", "mark", ",", "eval_dl", "in", "zip", "(", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ",", "eval_data_list", ")", ":", "\n", "            ", "LogInfo", ".", "begin_track", "(", "'Eval-%s ...'", ",", "mark", ")", "\n", "disp_key", "=", "'%s_F1'", "%", "mark", "\n", "detail_fp", "=", "'%s/detail/%s.tmp'", "%", "(", "args", ".", "output_dir", ",", "mark", ")", "\n", "result_fp", "=", "'%s/result/%s.%03d.result'", "%", "(", "args", ".", "output_dir", ",", "mark", ",", "epoch", ")", "\n", "disp_item_dict", "[", "disp_key", "]", "=", "evaluator", ".", "evaluate_all", "(", "\n", "eval_data_loader", "=", "eval_dl", ",", "\n", "detail_fp", "=", "detail_fp", ",", "\n", "result_fp", "=", "result_fp", "\n", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "# display & save states (results, details, params)", "\n", "cur_valid_f1", "=", "disp_item_dict", "[", "'valid_F1'", "]", "\n", "if", "cur_valid_f1", ">", "best_valid_f1", ":", "\n", "            ", "best_valid_f1", "=", "cur_valid_f1", "\n", "update_flag", "=", "True", "\n", "patience", "=", "args", ".", "max_patience", "\n", "save_best_dir", "=", "'%s/model_best'", "%", "args", ".", "output_dir", "\n", "model_util", ".", "delete_dir", "(", "save_best_dir", ")", "\n", "model_util", ".", "save_model", "(", "saver", "=", "saver", ",", "sess", "=", "sess", ",", "model_dir", "=", "save_best_dir", ",", "\n", "epoch", "=", "epoch", ",", "valid_metric", "=", "best_valid_f1", ")", "\n", "", "else", ":", "\n", "            ", "patience", "-=", "1", "\n", "", "LogInfo", ".", "logs", "(", "'Model %s, best valid_F1 = %.6f [patience = %d]'", ",", "\n", "'updated'", "if", "update_flag", "else", "'stayed'", ",", "cur_valid_f1", ",", "patience", ")", "\n", "disp_item_dict", "[", "'Status'", "]", "=", "'UPDATE'", "if", "update_flag", "else", "str", "(", "patience", ")", "\n", "disp_item_dict", "[", "'Time'", "]", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d_%H:%M:%S'", ")", "\n", "status_fp", "=", "'%s/status.txt'", "%", "args", ".", "output_dir", "\n", "disp_header_list", "=", "model_util", ".", "construct_display_header", "(", ")", "\n", "if", "epoch", "==", "1", ":", "\n", "            ", "with", "open", "(", "status_fp", ",", "'w'", ")", "as", "bw", ":", "\n", "                ", "write_str", "=", "''", ".", "join", "(", "disp_header_list", ")", "\n", "bw", ".", "write", "(", "write_str", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "status_fp", ",", "'a'", ")", "as", "bw", ":", "\n", "            ", "write_str", "=", "''", "\n", "for", "item_idx", ",", "header", "in", "enumerate", "(", "disp_header_list", ")", ":", "\n", "                ", "if", "header", ".", "endswith", "(", "' '", ")", "or", "header", "==", "'\\t'", ":", "\n", "                    ", "write_str", "+=", "header", "\n", "", "else", ":", "\n", "                    ", "val", "=", "disp_item_dict", ".", "get", "(", "header", ",", "'--------'", ")", "\n", "if", "isinstance", "(", "val", ",", "float", ")", ":", "\n", "                        ", "write_str", "+=", "'%8.6f'", "%", "val", "\n", "", "else", ":", "\n", "                        ", "write_str", "+=", "str", "(", "val", ")", "\n", "", "", "", "bw", ".", "write", "(", "write_str", "+", "'\\n'", ")", "\n", "\n", "", "LogInfo", ".", "logs", "(", "'Output concern parameters ... '", ")", "\n", "# don't need any feeds, since we focus on parameters", "\n", "param_result_list", "=", "sess", ".", "run", "(", "focus_param_list", ")", "\n", "param_result_dict", "=", "{", "}", "\n", "for", "param_name", ",", "param_result", "in", "zip", "(", "focus_param_name_list", ",", "param_result_list", ")", ":", "\n", "            ", "param_result_dict", "[", "param_name", "]", "=", "param_result", "\n", "\n", "", "with", "open", "(", "args", ".", "output_dir", "+", "'/detail/param.%03d.pkl'", "%", "epoch", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "param_result_dict", ",", "bw", ")", "\n", "", "LogInfo", ".", "logs", "(", "'Concern parameters saved.'", ")", "\n", "\n", "if", "update_flag", ":", "\n", "            ", "with", "open", "(", "args", ".", "output_dir", "+", "'/detail/param.best.pkl'", ",", "'wb'", ")", "as", "bw", ":", "\n", "                ", "pickle", ".", "dump", "(", "param_result_dict", ",", "bw", ")", "\n", "# save the latest details", "\n", "", "for", "mode", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "                ", "src", "=", "'%s/detail/%s.tmp'", "%", "(", "args", ".", "output_dir", ",", "mode", ")", "\n", "dest", "=", "'%s/detail/%s.best'", "%", "(", "args", ".", "output_dir", ",", "mode", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "src", ")", ":", "\n", "                    ", "shutil", ".", "move", "(", "src", ",", "dest", ")", "\n", "\n", "", "", "", "LogInfo", ".", "end_track", "(", ")", "# end of epoch", "\n", "", "LogInfo", ".", "end_track", "(", ")", "# end of learning", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.BaseDataLoader.__init__": [[11, 17], ["None"], "methods", ["None"], ["NONE_ID", "=", "0", "\n", "START_VOCAB", "=", "[", "'_PAD'", ",", "'_UNK'", ",", "'_GO'", ",", "'_EOS'", "]", "\n", "\n", "\n", "def", "load_data", "(", "data_dir", ",", "is_train", "=", "False", ")", ":", "\n", "    ", "data_train", ",", "data_dev", ",", "data_test", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "is_train", ":", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.BaseDataLoader.__len__": [[18, 20], ["None"], "methods", ["None"], ["        ", "with", "open", "(", "'%s/train.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "data_train", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.BaseDataLoader.get_batch": [[21, 25], ["None"], "methods", ["None"], ["if", "idx", ">", "0", "and", "idx", "%", "100000", "==", "0", ":", "\n", "                    ", "print", "(", "'read train file line %d'", "%", "idx", ")", "\n", "", "", "", "with", "open", "(", "'%s/valid.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "data_dev", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.BaseDataLoader.prepare_np_input_list": [[26, 57], ["len", "utils.log_util.LogInfo.logs", "global_input_dict.items", "data_loader.BaseDataLoader.batch_np_data_list.append", "min", "data_loader.BaseDataLoader.batch_real_size_list.append", "range", "len", "utils.log_util.LogInfo.logs", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "", "else", ":", "\n", "        ", "with", "open", "(", "'%s/test.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "data_test", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "", "if", "is_train", ":", "\n", "        ", "return", "data_train", ",", "data_dev", "\n", "", "else", ":", "\n", "        ", "return", "data_test", "\n", "\n", "\n", "", "", "def", "load_trans_data", "(", "dir", ",", "is_train", "=", "False", ")", ":", "\n", "    ", "data_trans_train", "=", "{", "}", "\n", "data_trans_valid", "=", "{", "}", "\n", "data_trans_test", "=", "{", "}", "\n", "\n", "if", "is_train", ":", "\n", "# TODO\uff1arevise to automatically check", "\n", "        ", "train_list", "=", "list", "(", "range", "(", "0", ",", "34", ")", ")", "\n", "train_list", "=", "[", "str", "(", "id", ")", "for", "id", "in", "train_list", "]", "\n", "sent_repr", "=", "[", "]", "\n", "rm_final_feats", "=", "[", "]", "\n", "for", "idx", "in", "train_list", ":", "\n", "            ", "with", "open", "(", "'%s/data_trans_train_%s.picke'", "%", "(", "dir", ",", "idx", ")", ",", "'rb'", ")", "as", "fr", ":", "\n", "                ", "print", "(", "\"read data_trans_tran_%s.pickle\"", "%", "idx", ")", "\n", "trans_bucket", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "sent_bucket", "=", "trans_bucket", "[", "'sent_repr'", "]", ".", "tolist", "(", ")", "\n", "rm_feat_bucket", "=", "trans_bucket", "[", "'rm_final_feats'", "]", ".", "tolist", "(", ")", "\n", "for", "sent", ",", "rm_feat", "in", "zip", "(", "sent_bucket", ",", "rm_feat_bucket", ")", ":", "\n", "                    ", "sent_repr", ".", "append", "(", "sent", ")", "\n", "rm_final_feats", ".", "append", "(", "rm_feat", ")", "\n", "\n", "", "", "", "data_trans_train", "=", "{", "'sent_repr'", ":", "np", ".", "array", "(", "sent_repr", ")", ",", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.SchemaEvalDataLoader.__init__": [[61, 91], ["data_loader.BaseDataLoader.__init__", "len", "q_evals_dict.items", "len", "data_loader.SchemaEvalDataLoader.eval_sc_tup_list.sort", "utils.log_util.LogInfo.logs", "data_loader.SchemaEvalDataLoader.prepare_np_input_list", "numpy.random.shuffle", "sc_np_dict.items", "data_loader.SchemaEvalDataLoader.eval_sc_tup_list.append", "global_input_dict.setdefault().append", "global_input_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator.__init__", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.BaseDataLoader.prepare_np_input_list"], ["\n", "with", "open", "(", "'%s/data_trans_valid.picke'", "%", "dir", ",", "'rb'", ")", "as", "fr", ":", "\n", "            ", "data_trans_valid", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "'%s/data_trans_test.picke'", "%", "dir", ",", "'rb'", ")", "as", "fr", ":", "\n", "            ", "data_trans_test", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "", "", "if", "is_train", ":", "\n", "        ", "return", "data_trans_train", ",", "data_trans_valid", "\n", "", "else", ":", "\n", "        ", "return", "data_trans_test", "\n", "\n", "\n", "", "", "def", "load_vocab", "(", "dir", ",", "vocab_size", ",", "embed_units", ")", ":", "\n", "    ", "print", "(", "\"loading word vocabs...\"", ")", "\n", "with", "open", "(", "'%s/vocab'", "%", "dir", ")", "as", "fr", ":", "\n", "        ", "raw_vocab", "=", "json", ".", "load", "(", "fr", ")", "\n", "\n", "", "vocab_list", "=", "START_VOCAB", "+", "sorted", "(", "raw_vocab", ",", "key", "=", "raw_vocab", ".", "get", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "vocab_list", ")", ">", "vocab_size", ":", "\n", "        ", "vocab_list", "=", "vocab_list", "[", ":", "vocab_size", "]", "\n", "\n", "", "print", "(", "\"loading entity list...\"", ")", "\n", "entity_list", "=", "[", "]", "\n", "with", "open", "(", "'%s/csk_entity.txt'", "%", "dir", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "e", "=", "line", ".", "strip", "(", ")", "\n", "entity_list", ".", "append", "(", "e", ")", "\n", "\n", "", "", "print", "(", "\"loading word vectors...\"", ")", "\n", "vectors", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.SchemaOptmDataLoader.__init__": [[95, 125], ["data_loader.BaseDataLoader.__init__", "len", "q_optm_pairs_dict.items", "len", "data_loader.SchemaOptmDataLoader.optm_pair_tup_list.sort", "utils.log_util.LogInfo.logs", "data_loader.SchemaOptmDataLoader.prepare_np_input_list", "numpy.random.shuffle", "data_loader.SchemaOptmDataLoader.optm_pair_tup_list.append", "sc_np_dict.items", "global_input_dict.setdefault().append", "global_input_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator.__init__", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.BaseDataLoader.prepare_np_input_list"], ["word", "=", "s", "[", ":", "s", ".", "find", "(", "' '", ")", "]", "\n", "vector", "=", "s", "[", "s", ".", "find", "(", "' '", ")", "+", "1", ":", "]", "\n", "vectors", "[", "word", "]", "=", "vector", "\n", "", "", "embed", "=", "[", "]", "\n", "for", "word", "in", "vocab_list", ":", "\n", "        ", "if", "word", "in", "vectors", ":", "\n", "            ", "vector", "=", "list", "(", "map", "(", "float", ",", "vectors", "[", "word", "]", ".", "split", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "vector", "=", "np", ".", "zeros", "(", "embed_units", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "embed", ".", "append", "(", "vector", ")", "\n", "", "embed", "=", "np", ".", "array", "(", "embed", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "entity_embed", "=", "[", "]", "\n", "'''\n    for entity_word in entity_list:\n        if entity_word in vectors:\n            vector = list(map(float, vectors[entity_word].split()))\n            entity_embed.append(vector)\n    entity_embed = np.array(entity_embed, dtype=np.float32)\n    '''", "\n", "return", "vocab_list", ",", "embed", ",", "entity_embed", "\n", "\n", "\n", "", "def", "pad_batched_data", "(", "batched_data", ")", ":", "\n", "    ", "batched_post_tokens", "=", "[", "item", "[", "'post'", "]", ".", "split", "(", ")", "for", "item", "in", "batched_data", "]", "\n", "batched_res_tokens", "=", "[", "item", "[", "'response'", "]", ".", "split", "(", ")", "for", "item", "in", "batched_data", "]", "\n", "\n", "encoder_len", "=", "max", "(", "[", "len", "(", "p", ")", "for", "p", "in", "batched_post_tokens", "]", ")", "+", "1", "\n", "decoder_len", "=", "max", "(", "[", "len", "(", "r", ")", "for", "r", "in", "batched_res_tokens", "]", ")", "+", "1", "\n", "posts", ",", "responses", ",", "posts_length", ",", "responses_length", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "token_list", "in", "batched_post_tokens", ":", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.__init__": [[8, 32], ["set", "freebase_helper.FreebaseHelper._load_pred_name", "freebase_helper.FreebaseHelper._load_type_name", "freebase_helper.FreebaseHelper._load_domain_range", "freebase_helper.FreebaseHelper._load_mediator", "freebase_helper.FreebaseHelper._load_sup_sub_types"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_pred_name", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_type_name", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_domain_range", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_mediator", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_sup_sub_types"], ["    ", "def", "__init__", "(", "self", ",", "meta_dir", ")", ":", "\n", "        ", "self", ".", "meta_dir", "=", "meta_dir", "\n", "\n", "self", ".", "type_pred_dict", "=", "{", "}", "# <type, set([pred])>", "\n", "self", ".", "type_name_dict", "=", "{", "}", "\n", "self", ".", "sup_type_dict", "=", "{", "}", "\n", "self", ".", "sub_type_dict", "=", "{", "}", "\n", "self", ".", "med_type_set", "=", "set", "(", "[", "]", ")", "\n", "self", ".", "pred_domain_dict", "=", "{", "}", "\n", "self", ".", "pred_range_dict", "=", "{", "}", "\n", "self", ".", "pred_name_dict", "=", "{", "}", "\n", "self", ".", "pred_inverse_dict", "=", "{", "}", "\n", "self", ".", "time_pred_dict", "=", "{", "}", "# <pred, (target_direction, target_pred)>", "\n", "self", ".", "entity_name_dict", "=", "{", "}", "\n", "\n", "self", ".", "ordinal_type_set", "=", "{", "'type.int'", ",", "'type.float'", ",", "'type.datetime'", "}", "\n", "self", ".", "ignore_type_domain_set", "=", "{", "'base'", ",", "'common'", ",", "'freebase'", ",", "'m'", ",", "'type'", ",", "'user'", "}", "\n", "self", ".", "ignore_pred_domain_set", "=", "{", "'common'", ",", "'freebase'", ",", "'m'", ",", "'type'", "}", "\n", "\n", "self", ".", "_load_pred_name", "(", ")", "\n", "self", ".", "_load_type_name", "(", ")", "\n", "self", ".", "_load_domain_range", "(", ")", "\n", "self", ".", "_load_mediator", "(", ")", "\n", "self", ".", "_load_sup_sub_types", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_pred_name": [[33, 45], ["utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "line.strip().split", "freebase_helper.adjust_name", "freebase_helper.FreebaseHelper.type_pred_dict.setdefault().add", "len", "line.strip", "pred.rfind", "freebase_helper.FreebaseHelper.type_pred_dict.setdefault", "set"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.adjust_name"], ["", "def", "_load_pred_name", "(", "self", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "'%s/PS-name.txt'", "%", "self", ".", "meta_dir", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "spt", ")", "<", "2", ":", "\n", "                    ", "continue", "\n", "", "pred", ",", "raw_name", "=", "spt", "\n", "pred_name", "=", "adjust_name", "(", "raw_name", ")", "\n", "tp", "=", "pred", "[", ":", "pred", ".", "rfind", "(", "'.'", ")", "]", "\n", "self", ".", "type_pred_dict", ".", "setdefault", "(", "tp", ",", "set", "(", "[", "]", ")", ")", ".", "add", "(", "pred", ")", "\n", "self", ".", "pred_name_dict", "[", "pred", "]", "=", "pred_name", "\n", "", "", "LogInfo", ".", "logs", "(", "'FBHelper: %d predicate names loaded.'", ",", "len", "(", "self", ".", "pred_name_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_type_name": [[46, 56], ["utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "line.strip().split", "freebase_helper.adjust_name", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.adjust_name"], ["", "def", "_load_type_name", "(", "self", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "'%s/TS-name.txt'", "%", "self", ".", "meta_dir", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "spt", ")", "<", "2", ":", "\n", "                    ", "continue", "\n", "", "tp", ",", "raw_name", "=", "spt", "\n", "tp_name", "=", "adjust_name", "(", "raw_name", ")", "# lowercased, remove punc, remove (s)", "\n", "self", ".", "type_name_dict", "[", "tp", "]", "=", "tp_name", "\n", "", "", "LogInfo", ".", "logs", "(", "'FBHelper: %d type names loaded.'", ",", "len", "(", "self", ".", "type_name_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_domain_range": [[57, 67], ["utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "len", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_domain_range", "(", "self", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "'%s/PS-TP-triple.txt'", "%", "self", ".", "meta_dir", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "s", ",", "p", ",", "o", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "p", "==", "'type.property.schema'", ":", "\n", "                    ", "self", ".", "pred_domain_dict", "[", "s", "]", "=", "o", "\n", "", "else", ":", "\n", "                    ", "self", ".", "pred_range_dict", "[", "s", "]", "=", "o", "\n", "", "", "", "LogInfo", ".", "logs", "(", "'FBHelper: %d domain + %d range info loaded.'", ",", "\n", "len", "(", "self", ".", "pred_domain_dict", ")", ",", "len", "(", "self", ".", "pred_range_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_mediator": [[68, 73], ["utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "freebase_helper.FreebaseHelper.med_type_set.add", "line.strip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_mediator", "(", "self", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "'%s/mediators.tsv'", "%", "self", ".", "meta_dir", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "self", ".", "med_type_set", ".", "add", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "LogInfo", ".", "logs", "(", "'FBHelper: %d mediator types loaded.'", ",", "len", "(", "self", ".", "med_type_set", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._load_sup_sub_types": [[74, 94], ["utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "codecs.open", "br.readlines", "line.strip().split", "int", "list", "map", "freebase_helper.FreebaseHelper.sup_type_dict.setdefault().add", "freebase_helper.FreebaseHelper.sub_type_dict.setdefault().add", "line.strip", "line.strip().split", "int", "freebase_helper.FreebaseHelper.sup_type_dict.setdefault", "freebase_helper.FreebaseHelper.sub_type_dict.setdefault", "line.strip", "set", "set"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_sup_sub_types", "(", "self", ")", ":", "\n", "        ", "type_uhash", "=", "{", "}", "\n", "with", "codecs", ".", "open", "(", "'%s/type_dict.tsv'", "%", "self", ".", "meta_dir", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "idx", "=", "int", "(", "spt", "[", "0", "]", ")", "\n", "mid", "=", "spt", "[", "1", "]", "\n", "type_uhash", "[", "idx", "]", "=", "mid", "\n", "", "", "with", "codecs", ".", "open", "(", "'%s/version_0.9.txt'", "%", "self", ".", "meta_dir", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "pairs", "=", "0", "\n", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "idx_list", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", ")", ")", "\n", "ch_idx", "=", "idx_list", "[", "0", "]", "\n", "ch_type", "=", "type_uhash", "[", "ch_idx", "]", "\n", "for", "fa_idx", "in", "idx_list", "[", "1", ":", "]", ":", "# ignore child type itself", "\n", "                    ", "pairs", "+=", "1", "\n", "fa_type", "=", "type_uhash", "[", "fa_idx", "]", "\n", "self", ".", "sup_type_dict", ".", "setdefault", "(", "ch_type", ",", "set", "(", "[", "]", ")", ")", ".", "add", "(", "fa_type", ")", "\n", "self", ".", "sub_type_dict", ".", "setdefault", "(", "fa_type", ",", "set", "(", "[", "]", ")", ")", ".", "add", "(", "ch_type", ")", "\n", "", "", "", "LogInfo", ".", "logs", "(", "'FBHelper: %d sub/super type pairs loaded.'", ",", "pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._get_pred_name": [[95, 101], ["use_pred.startswith", "use_pred.endswith", "freebase_helper.FreebaseHelper.pred_name_dict.get"], "methods", ["None"], ["", "def", "_get_pred_name", "(", "self", ",", "pred", ")", ":", "\n", "        ", "use_pred", "=", "pred", "[", "1", ":", "]", "if", "pred", "[", "0", "]", "==", "'!'", "else", "pred", "# consider inverse predicates", "\n", "if", "use_pred", ".", "startswith", "(", "'m.__'", ")", "and", "use_pred", ".", "endswith", "(", "'__'", ")", ":", "# virtual predicate", "\n", "            ", "return", "use_pred", "[", "4", ":", "-", "2", "]", "\n", "", "else", ":", "# normal predicates", "\n", "            ", "return", "self", ".", "pred_name_dict", ".", "get", "(", "use_pred", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._get_type_name": [[102, 104], ["freebase_helper.FreebaseHelper.type_name_dict.get"], "methods", ["None"], ["", "", "def", "_get_type_name", "(", "self", ",", "tp", ")", ":", "\n", "        ", "return", "self", ".", "type_name_dict", ".", "get", "(", "tp", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.get_item_name": [[105, 118], ["freebase_helper.FreebaseHelper._get_pred_name", "freebase_helper.FreebaseHelper._get_type_name", "mid.startswith", "mid.rfind", "last_part.split", "mid.startswith"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._get_pred_name", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper._get_type_name"], ["", "def", "get_item_name", "(", "self", ",", "mid", ")", ":", "\n", "        ", "item_name", "=", "''", "\n", "p_name", "=", "self", ".", "_get_pred_name", "(", "mid", ")", "\n", "if", "p_name", "!=", "''", ":", "\n", "            ", "item_name", "=", "p_name", "\n", "", "t_name", "=", "self", ".", "_get_type_name", "(", "mid", ")", "\n", "if", "t_name", "!=", "''", ":", "\n", "            ", "item_name", "=", "t_name", "\n", "", "if", "mid", ".", "startswith", "(", "'m.'", ")", "and", "not", "mid", ".", "startswith", "(", "'m.0'", ")", ":", "# it's a type/predicate, but not an entity", "\n", "            ", "last_dot", "=", "mid", ".", "rfind", "(", "'.'", ")", "\n", "last_part", "=", "mid", "[", "last_dot", "+", "1", ":", "]", "\n", "item_name", "=", "last_part", ".", "split", "(", "'_'", ")", "# simply pick the name from id", "\n", "", "return", "item_name", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.is_mediator_as_expect": [[119, 125], ["freebase_helper.FreebaseHelper.pred_domain_dict.get", "freebase_helper.FreebaseHelper.pred_range_dict.get"], "methods", ["None"], ["", "def", "is_mediator_as_expect", "(", "self", ",", "pred", ")", ":", "\n", "        ", "if", "pred", "[", "0", "]", "==", "'!'", ":", "# inverse predicate", "\n", "            ", "t", "=", "self", ".", "pred_domain_dict", ".", "get", "(", "pred", "[", "1", ":", "]", ",", "''", ")", "\n", "", "else", ":", "\n", "            ", "t", "=", "self", ".", "pred_range_dict", ".", "get", "(", "pred", ",", "''", ")", "\n", "", "return", "t", "in", "self", ".", "med_type_set", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.is_type_contained_by": [[126, 128], ["freebase_helper.FreebaseHelper.sup_type_dict.get", "set"], "methods", ["None"], ["", "def", "is_type_contained_by", "(", "self", ",", "ta", ",", "tb", ")", ":", "# whether tb is a super type of ta", "\n", "        ", "return", "tb", "in", "self", ".", "sup_type_dict", ".", "get", "(", "ta", ",", "set", "(", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.get_domain": [[129, 134], ["freebase_helper.FreebaseHelper.pred_range_dict.get", "freebase_helper.FreebaseHelper.pred_domain_dict.get"], "methods", ["None"], ["", "def", "get_domain", "(", "self", ",", "pred", ")", ":", "\n", "        ", "if", "pred", "[", "0", "]", "==", "'!'", ":", "# inverse predicate", "\n", "            ", "return", "self", ".", "pred_range_dict", ".", "get", "(", "pred", "[", "1", ":", "]", ",", "''", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "pred_domain_dict", ".", "get", "(", "pred", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.get_range": [[135, 140], ["freebase_helper.FreebaseHelper.pred_domain_dict.get", "freebase_helper.FreebaseHelper.pred_range_dict.get"], "methods", ["None"], ["", "", "def", "get_range", "(", "self", ",", "pred", ")", ":", "\n", "        ", "if", "pred", "[", "0", "]", "==", "'!'", ":", "# inverse predicate", "\n", "            ", "return", "self", ".", "pred_domain_dict", ".", "get", "(", "pred", "[", "1", ":", "]", ",", "''", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "pred_range_dict", ".", "get", "(", "pred", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.adjust_name": [[142, 148], ["re.sub().strip.lower", "freebase_helper.remove_parenthesis", "re.sub", "re.sub().strip", "re.sub"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.remove_parenthesis"], ["", "", "", "def", "adjust_name", "(", "name", ")", ":", "\n", "    ", "name", "=", "name", ".", "lower", "(", ")", "\n", "name", "=", "remove_parenthesis", "(", "name", ")", "\n", "name", "=", "re", ".", "sub", "(", "r'[/|\\\\,.?!@#$%^&*():;\"]'", ",", "''", ",", "name", ")", "# remove puncs", "\n", "name", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "name", ")", ".", "strip", "(", ")", "# remove extra blanks", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.remove_parenthesis": [[150, 160], ["name.find", "name.find", "len"], "function", ["None"], ["", "def", "remove_parenthesis", "(", "name", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "lf_pos", "=", "name", ".", "find", "(", "'('", ")", "\n", "if", "lf_pos", "==", "-", "1", ":", "\n", "            ", "break", "\n", "", "rt_pos", "=", "name", ".", "find", "(", "')'", ",", "lf_pos", "+", "1", ")", "\n", "if", "rt_pos", "==", "-", "1", ":", "\n", "            ", "rt_pos", "=", "len", "(", "name", ")", "-", "1", "\n", "", "name", "=", "name", "[", ":", "lf_pos", "]", "+", "name", "[", "rt_pos", "+", "1", ":", "]", "\n", "", "return", "name", "\n", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.__init__": [[18, 43], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "candgen_dir", ",", "schema_level", ",", "freebase_helper", ",", "\n", "path_max_size", "=", "3", ",", "file_list_name", "=", "'all_list'", ",", "full_constr", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "candgen_dir", "=", "candgen_dir", "\n", "self", ".", "schema_level", "=", "schema_level", "\n", "self", ".", "freebase_helper", "=", "freebase_helper", "\n", "\n", "self", ".", "path_max_size", "=", "path_max_size", "\n", "self", ".", "file_list_name", "=", "file_list_name", "\n", "self", ".", "full_constr", "=", "full_constr", "\n", "\n", "self", ".", "q_idx_fp", "=", "\"%s/q_idx.pkl\"", "%", "self", ".", "candgen_dir", "\n", "self", ".", "spt_q_idx_fp", "=", "\"%s/spt_q_idx.pkl\"", "%", "self", ".", "candgen_dir", "\n", "self", ".", "q_cand_fp", "=", "\"%s/q_cand.pkl\"", "%", "self", ".", "candgen_dir", "\n", "self", ".", "active_dicts_fp", "=", "\"%s/active_dicts.pkl\"", "%", "self", ".", "candgen_dir", "\n", "self", ".", "active_uhashs_fp", "=", "\"%s/active_uhashs.pkl\"", "%", "self", ".", "candgen_dir", "\n", "\n", "# Need to save: Tvt split information & detail schema information", "\n", "self", ".", "q_idx_list", "=", "[", "]", "# indicating all active questions", "\n", "self", ".", "spt_q_idx_lists", "=", "[", "]", "# T/v/t list", "\n", "self", ".", "qa_list", "=", "[", "]", "\n", "self", ".", "smart_q_cand_dict", "=", "{", "}", "\n", "self", ".", "active_dicts", "=", "{", "'word'", ":", "{", "}", ",", "'mid'", ":", "{", "}", ",", "'path'", ":", "{", "}", "}", "\n", "self", ".", "active_uhashs", "=", "{", "'word'", ":", "[", "]", ",", "'mid'", ":", "[", "]", ",", "'path'", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.load_simpq": [[44, 50], ["utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.logs", "open", "pickle.load", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "load_simpq", "(", "self", ")", ":", "\n", "        ", "LogInfo", ".", "logs", "(", "'Loading SimpleQuestions from pickle ...'", ")", "\n", "pickle_fp", "=", "'%s/simpQ.data.pkl'", "%", "self", ".", "data_dir", "\n", "with", "open", "(", "pickle_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "qa_list", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d SimpleQuestions loaded.'", "%", "len", "(", "self", ".", "qa_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.load_all_data": [[51, 76], ["schema_dataset.SchemaDataset.load_simpq", "utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.logs", "numpy.array", "utils.log_util.LogInfo.logs", "numpy.array", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.end_track", "len", "os.path.isfile", "schema_dataset.SchemaDataset.load_simpq_schemas_from_txt", "schema_dataset.SchemaDataset.load_schemas_from_pickle", "len", "len", "len", "len", "numpy.sum", "numpy.mean", "numpy.mean", "len", "len", "len", "schema_dataset.SchemaDataset.smart_q_cand_dict.values"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.load_simpq", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.load_simpq_schemas_from_txt", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.load_schemas_from_pickle"], ["", "def", "load_all_data", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "smart_q_cand_dict", ")", ">", "0", ":", "# already loaded", "\n", "            ", "return", "\n", "# Load qa_list", "\n", "", "self", ".", "load_simpq", "(", ")", "\n", "\n", "# Load schema information", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "self", ".", "q_idx_fp", ")", ":", "# no dump, read from txt", "\n", "            ", "self", ".", "load_simpq_schemas_from_txt", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "load_schemas_from_pickle", "(", ")", "\n", "\n", "", "LogInfo", ".", "begin_track", "(", "'Meta statistics:'", ")", "\n", "LogInfo", ".", "logs", "(", "'Total questions = %d'", ",", "len", "(", "self", ".", "q_idx_list", ")", ")", "\n", "LogInfo", ".", "logs", "(", "'T / v / t questions = %s'", ",", "[", "len", "(", "lst", ")", "for", "lst", "in", "self", ".", "spt_q_idx_lists", "]", ")", "\n", "LogInfo", ".", "logs", "(", "'Active Word / Mid / Path = %d / %d / %d (with PAD, START, UNK)'", ",", "\n", "len", "(", "self", ".", "active_dicts", "[", "'word'", "]", ")", ",", "\n", "len", "(", "self", ".", "active_dicts", "[", "'mid'", "]", ")", ",", "\n", "len", "(", "self", ".", "active_dicts", "[", "'path'", "]", ")", ")", "\n", "cand_size_dist", "=", "np", ".", "array", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "smart_q_cand_dict", ".", "values", "(", ")", "]", ")", "\n", "LogInfo", ".", "logs", "(", "'Total schemas = %d, avg = %.6f.'", ",", "np", ".", "sum", "(", "cand_size_dist", ")", ",", "np", ".", "mean", "(", "cand_size_dist", ")", ")", "\n", "qlen_dist", "=", "np", ".", "array", "(", "[", "len", "(", "qa", "[", "'tokens'", "]", ")", "for", "qa", "in", "self", ".", "qa_list", "]", ")", "\n", "LogInfo", ".", "logs", "(", "'Avg question length = %.6f.'", ",", "np", ".", "mean", "(", "qlen_dist", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.load_schema_kq": [[77, 106], ["codecs.open", "br.readlines", "enumerate", "len", "schema.Schema.Schema", "schema.Schema.Schema.read_schema_from_json", "schema.Schema.Schema.construct_path_list", "len", "sc_len_dist.append", "ans_size_dist.append", "zip", "len", "path_len_dist.append", "candidate_list.append", "len", "schema_dataset.SchemaDataset._schema_classification"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema.Schema.read_schema_from_json", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema.Schema.construct_path_list", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset._schema_classification"], ["", "def", "load_schema_kq", "(", "self", ",", "q_idx", ",", "schema_fp", ",", "gather_linkings", ",", "\n", "sc_len_dist", ",", "path_len_dist", ",", "ans_size_dist", ")", ":", "\n", "        ", "\"\"\"\n        Read the schema files generated by KQ.\n        \"\"\"", "\n", "schema_level", "=", "schema_level_dict", "[", "self", ".", "schema_level", "]", "\n", "\n", "candidate_list", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "schema_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "sc_lines", "=", "br", ".", "readlines", "(", ")", "\n", "for", "ori_idx", ",", "sc_line", "in", "enumerate", "(", "sc_lines", ")", ":", "\n", "                ", "schema", "=", "Schema", "(", ")", "\n", "# load schemas", "\n", "schema", ".", "read_schema_from_json", "(", "q_idx", "=", "q_idx", ",", "json_line", "=", "sc_line", ",", "gather_linkings", "=", "gather_linkings", ",", "\n", "ori_idx", "=", "ori_idx", ",", "full_constr", "=", "self", ".", "full_constr", ")", "\n", "# create the path_list on-the-fly", "\n", "schema", ".", "construct_path_list", "(", ")", "\n", "\n", "real_sc_len", "=", "len", "(", "schema", ".", "path_list", ")", "\n", "sc_len_dist", ".", "append", "(", "len", "(", "schema", ".", "path_list", ")", ")", "\n", "ans_size_dist", ".", "append", "(", "schema", ".", "ans_size", ")", "\n", "\n", "for", "raw_path", ",", "path", "in", "zip", "(", "schema", ".", "raw_paths", ",", "schema", ".", "path_list", ")", ":", "\n", "                    ", "path_len_dist", ".", "append", "(", "len", "(", "path", ")", ")", "\n", "\n", "", "if", "real_sc_len", "<=", "self", ".", "path_max_size", "and", "self", ".", "_schema_classification", "(", "schema", ")", "<=", "schema_level", ":", "\n", "                    ", "candidate_list", ".", "append", "(", "schema", ")", "\n", "\n", "", "", "", "return", "candidate_list", ",", "len", "(", "sc_lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset._schema_classification": [[107, 125], ["len", "schema_dataset.SchemaDataset.freebase_helper.is_mediator_as_expect", "schema_dataset.SchemaDataset.freebase_helper.get_range", "schema_dataset.SchemaDataset.freebase_helper.get_domain", "schema_dataset.SchemaDataset.freebase_helper.is_type_contained_by"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.is_mediator_as_expect", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.get_range", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.get_domain", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.is_type_contained_by"], ["", "def", "_schema_classification", "(", "self", ",", "sc", ")", ":", "\n", "        ", "for", "category", ",", "focus", ",", "pred_seq", "in", "sc", ".", "raw_paths", ":", "\n", "            ", "if", "category", "!=", "'Main'", ":", "\n", "                ", "continue", "# only consider main path", "\n", "", "if", "len", "(", "pred_seq", ")", "==", "1", ":", "\n", "                ", "return", "0", "\n", "", "elif", "self", ".", "freebase_helper", ".", "is_mediator_as_expect", "(", "pred", "=", "pred_seq", "[", "0", "]", ")", ":", "\n", "                ", "return", "0", "\n", "", "else", ":", "\n", "                ", "p1_range", "=", "self", ".", "freebase_helper", ".", "get_range", "(", "pred_seq", "[", "0", "]", ")", "\n", "p2_domain", "=", "self", ".", "freebase_helper", ".", "get_domain", "(", "pred_seq", "[", "1", "]", ")", "\n", "if", "p1_range", "==", "p2_domain", ":", "\n", "                    ", "return", "1", "\n", "", "elif", "self", ".", "freebase_helper", ".", "is_type_contained_by", "(", "p1_range", ",", "p2_domain", ")", ":", "\n", "                    ", "return", "2", "\n", "", "else", ":", "\n", "                    ", "return", "3", "\n", "", "", "", "return", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.load_schemas_from_pickle": [[126, 139], ["utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.end_track", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["", "def", "load_schemas_from_pickle", "(", "self", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Loading smart_candidates from [%s] ...'", ",", "self", ".", "candgen_dir", ")", "\n", "with", "open", "(", "self", ".", "q_idx_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "q_idx_list", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "with", "open", "(", "self", ".", "spt_q_idx_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "spt_q_idx_lists", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "with", "open", "(", "self", ".", "q_cand_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "smart_q_cand_dict", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "with", "open", "(", "self", ".", "active_dicts_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "active_dicts", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "with", "open", "(", "self", ".", "active_uhashs_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "active_uhashs", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.save_smart_cands": [[140, 153], ["utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.end_track", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["", "def", "save_smart_cands", "(", "self", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Saving candidates into [%s] ...'", ",", "self", ".", "candgen_dir", ")", "\n", "with", "open", "(", "self", ".", "q_idx_fp", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "q_idx_list", ",", "bw", ")", "\n", "", "with", "open", "(", "self", ".", "spt_q_idx_fp", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "spt_q_idx_lists", ",", "bw", ")", "\n", "", "with", "open", "(", "self", ".", "q_cand_fp", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "smart_q_cand_dict", ",", "bw", ")", "\n", "", "with", "open", "(", "self", ".", "active_dicts_fp", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "active_dicts", ",", "bw", ")", "\n", "", "with", "open", "(", "self", ".", "active_uhashs_fp", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "active_uhashs", ",", "bw", ")", "\n", "", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.load_simpq_schemas_from_txt": [[154, 221], ["utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.logs", "enumerate", "schema_dataset.SchemaDataset.q_idx_list.sort", "schema_dataset.SchemaDataset.spt_q_idx_lists.append", "schema_dataset.SchemaDataset.spt_q_idx_lists.append", "schema_dataset.SchemaDataset.spt_q_idx_lists.append", "len", "utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.logs", "zip", "utils.log_util.LogInfo.end_track", "utils.log_util.LogInfo.begin_track", "schema_dataset.SchemaDataset.build_active_voc", "utils.log_util.LogInfo.end_track", "schema_dataset.SchemaDataset.save_smart_cands", "open", "list", "len", "int", "schema_dataset.SchemaDataset.q_idx_list.append", "schema_dataset.SchemaDataset.load_schema_kq", "len", "list", "list", "list", "len", "len", "numpy.array", "utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.end_track", "map", "utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "filter", "filter", "filter", "schema_dataset.SchemaDataset.smart_q_cand_dict.values", "numpy.mean", "br.readlines", "len", "[].split", "json.loads", "gather_linkings.append", "schema_fp.rfind", "gl_line.strip", "utils.link_data.LinkData", "line.strip", "schema_fp.split"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.build_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.save_smart_cands", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.load_schema_kq", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "load_simpq_schemas_from_txt", "(", "self", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Loading SimpQ schemas from [%s] ...'", ",", "self", ".", "candgen_dir", ")", "\n", "\n", "# Step 1: Load Auxiliary Information", "\n", "list_fp", "=", "'%s/%s'", "%", "(", "self", ".", "candgen_dir", ",", "self", ".", "file_list_name", ")", "\n", "with", "open", "(", "list_fp", ",", "'r'", ")", "as", "br", ":", "\n", "            ", "schema_fp_list", "=", "list", "(", "map", "(", "lambda", "line", ":", "'%s/%s'", "%", "(", "self", ".", "candgen_dir", ",", "line", ".", "strip", "(", ")", ")", ",", "br", ".", "readlines", "(", ")", ")", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d schema files found in [%s].'", ",", "len", "(", "schema_fp_list", ")", ",", "self", ".", "file_list_name", ")", "\n", "\n", "# Step 2: Traverse & Make Statistics", "\n", "sc_len_dist", "=", "[", "]", "# distribution of number of paths in a schema", "\n", "path_len_dist", "=", "[", "]", "# distribution of length of each path", "\n", "ans_size_dist", "=", "[", "]", "# distribution of answer size", "\n", "total_cand_size", "=", "useful_cand_size", "=", "0", "\n", "\n", "for", "scan_idx", ",", "schema_fp", "in", "enumerate", "(", "schema_fp_list", ")", ":", "\n", "            ", "if", "scan_idx", "%", "1000", "==", "0", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "'%d / %d scanned.'", ",", "scan_idx", ",", "len", "(", "schema_fp_list", ")", ")", "\n", "", "link_fp", "=", "schema_fp", "[", "0", ":", "schema_fp", ".", "rfind", "(", "'_'", ")", "]", "+", "'_links'", "\n", "q_idx", "=", "int", "(", "schema_fp", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "self", ".", "q_idx_list", ".", "append", "(", "q_idx", ")", "\n", "\n", "gather_linkings", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "link_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "                ", "for", "gl_line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                    ", "tup_list", "=", "json", ".", "loads", "(", "gl_line", ".", "strip", "(", ")", ")", "\n", "ld_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "tup_list", "}", "\n", "gather_linkings", ".", "append", "(", "LinkData", "(", "**", "ld_dict", ")", ")", "\n", "\n", "", "", "candidate_list", ",", "total_lines", "=", "self", ".", "load_schema_kq", "(", "\n", "q_idx", "=", "q_idx", ",", "schema_fp", "=", "schema_fp", ",", "gather_linkings", "=", "gather_linkings", ",", "\n", "sc_len_dist", "=", "sc_len_dist", ",", "path_len_dist", "=", "path_len_dist", ",", "ans_size_dist", "=", "ans_size_dist", "\n", ")", "\n", "total_cand_size", "+=", "total_lines", "\n", "useful_cand_size", "+=", "len", "(", "candidate_list", ")", "\n", "self", ".", "smart_q_cand_dict", "[", "q_idx", "]", "=", "candidate_list", "\n", "\n", "# T/v/t split", "\n", "", "self", ".", "q_idx_list", ".", "sort", "(", ")", "\n", "\n", "self", ".", "spt_q_idx_lists", ".", "append", "(", "list", "(", "filter", "(", "lambda", "x", ":", "x", "<", "train_pos", ",", "self", ".", "q_idx_list", ")", ")", ")", "\n", "self", ".", "spt_q_idx_lists", ".", "append", "(", "list", "(", "filter", "(", "lambda", "x", ":", "train_pos", "<=", "x", "<", "valid_pos", ",", "self", ".", "q_idx_list", ")", ")", ")", "\n", "self", ".", "spt_q_idx_lists", ".", "append", "(", "list", "(", "filter", "(", "lambda", "x", ":", "x", ">=", "valid_pos", ",", "self", ".", "q_idx_list", ")", ")", ")", "\n", "\n", "# Step 3: Show Statistics", "\n", "q_size", "=", "len", "(", "self", ".", "smart_q_cand_dict", ")", "\n", "q_len_dist", "=", "[", "len", "(", "qa", "[", "'tokens'", "]", ")", "for", "qa", "in", "self", ".", "qa_list", "]", "\n", "LogInfo", ".", "begin_track", "(", "'[STAT] %d questions scanned:'", ",", "q_size", ")", "\n", "LogInfo", ".", "logs", "(", "'Total schemas = %d'", ",", "total_cand_size", ")", "\n", "LogInfo", ".", "logs", "(", "'Useful schemas = %d (%.3f%%)'", ",", "useful_cand_size", ",", "100.", "*", "useful_cand_size", "/", "total_cand_size", ")", "\n", "LogInfo", ".", "logs", "(", "'Avg candidates = %.3f'", ",", "1.", "*", "useful_cand_size", "/", "q_size", ")", "\n", "cand_size_dist", "=", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "smart_q_cand_dict", ".", "values", "(", ")", "]", "\n", "for", "show_name", ",", "show_dist", "in", "zip", "(", "[", "'q_len'", ",", "'cand_size'", ",", "'sc_len'", ",", "'path_len'", ",", "'ans_size'", "]", ",", "\n", "[", "q_len_dist", ",", "cand_size_dist", ",", "sc_len_dist", ",", "path_len_dist", ",", "ans_size_dist", "]", ")", ":", "\n", "            ", "dist_arr", "=", "np", ".", "array", "(", "show_dist", ")", "\n", "LogInfo", ".", "begin_track", "(", "'Show %s distribution:'", ",", "show_name", ")", "\n", "LogInfo", ".", "logs", "(", "'Average: %.6f'", ",", "np", ".", "mean", "(", "dist_arr", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "# Build path word vocabulary", "\n", "LogInfo", ".", "begin_track", "(", "'Building active word / mid / path vocabulary ... '", ")", "\n", "self", ".", "build_active_voc", "(", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n", "# Save the candidates", "\n", "self", ".", "save_smart_cands", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.add_item_into_active_voc": [[222, 226], ["len", "schema_dataset.SchemaDataset.active_uhashs[].append"], "methods", ["None"], ["", "def", "add_item_into_active_voc", "(", "self", ",", "category", ",", "value", ")", ":", "\n", "        ", "if", "value", "not", "in", "self", ".", "active_dicts", "[", "category", "]", ":", "\n", "            ", "self", ".", "active_dicts", "[", "category", "]", "[", "value", "]", "=", "len", "(", "self", ".", "active_dicts", "[", "category", "]", ")", "\n", "self", ".", "active_uhashs", "[", "category", "]", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_dataset.SchemaDataset.build_active_voc": [[227, 263], ["zip", "schema_dataset.SchemaDataset.add_item_into_active_voc", "utils.log_util.LogInfo.logs", "schema_dataset.SchemaDataset.add_item_into_active_voc", "len", "tok.lower", "schema_dataset.SchemaDataset.add_item_into_active_voc", "schema_dataset.SchemaDataset.add_item_into_active_voc", "schema_dataset.SchemaDataset.add_item_into_active_voc", "zip", "schema_dataset.SchemaDataset.add_item_into_active_voc", "schema_dataset.SchemaDataset.freebase_helper.get_item_name", "schema_dataset.SchemaDataset.add_item_into_active_voc", "schema_dataset.SchemaDataset.split", "schema_dataset.SchemaDataset.add_item_into_active_voc"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.get_item_name", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc"], ["", "", "def", "build_active_voc", "(", "self", ")", ":", "\n", "        ", "for", "category", "in", "(", "'word'", ",", "'mid'", ",", "'path'", ")", ":", "\n", "            ", "for", "mask", "in", "(", "'<PAD>'", ",", "'<START>'", ",", "'<UNK>'", ")", ":", "\n", "                ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "category", ",", "value", "=", "mask", ")", "\n", "", "", "for", "mask", "in", "(", "'<E>'", ",", "'<T>'", ",", "'<Tm>'", ",", "'<Ord>'", ")", ":", "\n", "            ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "mask", ")", "\n", "\n", "# Try collect word from all data, while mid / path from train only", "\n", "", "for", "mode", ",", "q_idx_list", "in", "zip", "(", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ",", "self", ".", "spt_q_idx_lists", ")", ":", "\n", "            ", "for", "q_idx", "in", "q_idx_list", ":", "\n", "# Scanning questions", "\n", "                ", "qa", "=", "self", ".", "qa_list", "[", "q_idx", "]", "\n", "lower_tok_list", "=", "[", "tok", ".", "lower", "(", ")", "for", "tok", "in", "qa", "[", "'tokens'", "]", "]", "\n", "for", "tok", "in", "lower_tok_list", ":", "\n", "                    ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "tok", ")", "\n", "", "for", "rel", ",", "head", ",", "dep", "in", "qa", "[", "'parse'", "]", ":", "\n", "                    ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "rel", ")", "\n", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "'!'", "+", "rel", ")", "\n", "# Scanning schemas", "\n", "", "for", "cand", "in", "self", ".", "smart_q_cand_dict", "[", "q_idx", "]", ":", "\n", "                    ", "for", "raw_path", ",", "mid_seq", "in", "zip", "(", "cand", ".", "raw_paths", ",", "cand", ".", "path_list", ")", ":", "\n", "                        ", "path_cate", ",", "gl_data", ",", "_", "=", "raw_path", "\n", "path_str", "=", "'%s|%s'", "%", "(", "path_cate", ",", "'\\t'", ".", "join", "(", "mid_seq", ")", ")", "\n", "if", "mode", "==", "'train'", ":", "\n", "                            ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'path'", ",", "value", "=", "path_str", ")", "\n", "", "for", "mid", "in", "mid_seq", ":", "\n", "                            ", "if", "mode", "==", "'train'", ":", "\n", "                                ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'mid'", ",", "value", "=", "mid", ")", "\n", "", "p_name", "=", "self", ".", "freebase_helper", ".", "get_item_name", "(", "mid", ")", "\n", "if", "p_name", "!=", "''", ":", "\n", "                                ", "spt", "=", "p_name", ".", "split", "(", "' '", ")", "\n", "for", "tok", "in", "spt", ":", "\n", "                                    ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "tok", ")", "# type / pred name", "\n", "\n", "", "", "", "", "", "", "", "for", "category", "in", "(", "'word'", ",", "'mid'", ",", "'path'", ")", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'Active %s size = %d'", ",", "category", ",", "len", "(", "self", ".", "active_dicts", "[", "category", "]", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder.__init__": [[13, 21], ["utils.log_util.LogInfo.logs", "schema_builder.SchemaBuilder._prepare_optm_eval_data"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._prepare_optm_eval_data"], ["    ", "def", "__init__", "(", "self", ",", "schema_dataset", ",", "feature_helper", ",", "neg_f1_ths", ",", "neg_max_sample", ",", "neg_strategy", ")", ":", "\n", "        ", "LogInfo", ".", "logs", "(", "'SchemaBuilder initializing ...'", ")", "\n", "self", ".", "schema_dataset", "=", "schema_dataset", "\n", "self", ".", "feat_gen_helper", "=", "feature_helper", "\n", "self", ".", "neg_f1_ths", "=", "neg_f1_ths", "\n", "self", ".", "neg_max_sample", "=", "neg_max_sample", "\n", "self", ".", "neg_strategy", "=", "neg_strategy", "\n", "self", ".", "q_optm_pairs_dict", ",", "self", ".", "q_evals_dict", "=", "self", ".", "_prepare_optm_eval_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder.build_eval_dataloader": [[22, 45], ["utils.log_util.LogInfo.begin_track", "sorted", "list", "list", "list", "zip", "utils.log_util.LogInfo.end_track", "q_optm_pairs_dict.keys", "filter", "filter", "filter", "data_loader.SchemaEvalDataLoader", "eval_dl_list.append"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["", "def", "build_eval_dataloader", "(", "self", ",", "eval_batch_size", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Building eval data loader...'", ")", "\n", "q_optm_pairs_dict", "=", "self", ".", "q_optm_pairs_dict", "\n", "q_evals_dict", "=", "self", ".", "q_evals_dict", "\n", "\n", "full_q_idx_list", "=", "sorted", "(", "q_optm_pairs_dict", ".", "keys", "(", ")", ")", "\n", "train_q_idx_list", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "<", "train_pos", ",", "full_q_idx_list", ")", ")", "\n", "valid_q_idx_list", "=", "list", "(", "filter", "(", "lambda", "x", ":", "train_pos", "<=", "x", "<", "valid_pos", ",", "full_q_idx_list", ")", ")", "\n", "test_q_idx_list", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ">=", "valid_pos", ",", "full_q_idx_list", ")", ")", "\n", "\n", "modes", "=", "[", "'train'", ",", "'valid'", ",", "'test'", "]", "\n", "q_idx_lists", "=", "[", "train_q_idx_list", ",", "valid_q_idx_list", ",", "test_q_idx_list", "]", "\n", "eval_dl_list", "=", "[", "]", "\n", "for", "mode", ",", "cur_q_idx_list", "in", "zip", "(", "modes", ",", "q_idx_lists", ")", ":", "\n", "            ", "cur_q_evals_dict", "=", "{", "q_idx", ":", "q_evals_dict", "[", "q_idx", "]", "for", "q_idx", "in", "cur_q_idx_list", "}", "\n", "eval_dl", "=", "SchemaEvalDataLoader", "(", "\n", "q_evals_dict", "=", "cur_q_evals_dict", ",", "\n", "mode", "=", "mode", ",", "batch_size", "=", "eval_batch_size", ",", "shuffle", "=", "shuffle", "\n", ")", "\n", "eval_dl_list", ".", "append", "(", "eval_dl", ")", "\n", "\n", "", "LogInfo", ".", "end_track", "(", "'Eval train/valid/test data loader returned.'", ")", "\n", "return", "eval_dl_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder.build_optm_dataloader": [[46, 59], ["utils.log_util.LogInfo.begin_track", "sorted", "list", "data_loader.SchemaOptmDataLoader", "utils.log_util.LogInfo.end_track", "q_optm_pairs_dict.keys", "filter"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["", "def", "build_optm_dataloader", "(", "self", ",", "optm_batch_size", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Building optm data loader...'", ")", "\n", "q_optm_pairs_dict", "=", "self", ".", "q_optm_pairs_dict", "\n", "full_q_idx_list", "=", "sorted", "(", "q_optm_pairs_dict", ".", "keys", "(", ")", ")", "\n", "train_q_idx_list", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "<", "train_pos", ",", "full_q_idx_list", ")", ")", "\n", "\n", "optm_dl", "=", "SchemaOptmDataLoader", "(", "\n", "q_optm_pairs_dict", "=", "{", "q_idx", ":", "q_optm_pairs_dict", "[", "q_idx", "]", "for", "q_idx", "in", "train_q_idx_list", "}", ",", "\n", "mode", "=", "'optm'", ",", "batch_size", "=", "optm_batch_size", ",", "shuffle", "=", "shuffle", "\n", ")", "\n", "\n", "LogInfo", ".", "end_track", "(", "'Optm dataloader returned.'", ")", "\n", "return", "optm_dl", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._prepare_optm_eval_data": [[60, 125], ["utils.log_util.LogInfo.logs", "enumerate", "utils.log_util.LogInfo.logs", "schema_builder.SchemaBuilder._schema_dedup", "numpy.random.shuffle", "list", "list", "list", "len", "len", "utils.log_util.LogInfo.logs", "filter", "filter", "schema_builder.SchemaBuilder._input_feat_gen", "filter", "len", "numpy.random.shuffle", "schema_builder.SchemaBuilder._weighted_sampling", "optm_sc_pair_list.append", "sc1.run_info.get", "optm_sc_pair_list.append", "sample_tups.append", "sc2.run_info.get"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._schema_dedup", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._input_feat_gen", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._weighted_sampling"], ["", "def", "_prepare_optm_eval_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Given the fixed S-MART based schemas and dynamic generated schemas,\n        build the Optm/T/v/t data loader for the specific epoch.\n        That's to say, we control the negative sampling strategy here.\n        Negative strategy:\n            1. fix: (threshold + random sample)\n            2. dynamic: (threshold + weighed sample based on delta)\n        \"\"\"", "\n", "runtime_score_key", "=", "'rm_score'", "\n", "LogInfo", ".", "logs", "(", "'runtime_score_key = [%s]'", ",", "runtime_score_key", ")", "\n", "\n", "q_optm_pairs_dict", "=", "{", "}", "# < q_idx, [(pos_sc, neg_sc)] >", "\n", "q_evals_dict", "=", "{", "}", "# < q_idx, [sc] >", "\n", "total_optm_pair_size", "=", "0", "\n", "total_eval_sc_size", "=", "0", "\n", "schema_dataset", "=", "self", ".", "schema_dataset", "\n", "\n", "for", "scan_idx", ",", "q_idx", "in", "enumerate", "(", "schema_dataset", ".", "q_idx_list", ")", ":", "\n", "            ", "if", "scan_idx", ">", "0", "and", "scan_idx", "%", "1000", "==", "0", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "'scanned %d / %d questions. optm_pairs = %d, eval_sc = %d.'", ",", "\n", "scan_idx", ",", "len", "(", "schema_dataset", ".", "q_idx_list", ")", ",", "\n", "total_optm_pair_size", ",", "total_eval_sc_size", ")", "\n", "\n", "", "cand_list", "=", "schema_dataset", ".", "smart_q_cand_dict", "[", "q_idx", "]", "\n", "dedup_sc_tups", "=", "self", ".", "_schema_dedup", "(", "sc_list", "=", "cand_list", ")", "# [(sc, sc.f1)]", "\n", "np", ".", "random", ".", "shuffle", "(", "dedup_sc_tups", ")", "# shuffle, avoid data leaking.", "\n", "pos_tups", "=", "list", "(", "filter", "(", "lambda", "_tup", ":", "_tup", "[", "-", "1", "]", ">=", "self", ".", "neg_f1_ths", ",", "dedup_sc_tups", ")", ")", "\n", "neg_tups", "=", "list", "(", "filter", "(", "lambda", "_tup", ":", "_tup", "[", "-", "1", "]", "<", "self", ".", "neg_f1_ths", ",", "dedup_sc_tups", ")", ")", "\n", "\n", "for", "sc", ",", "_", "in", "dedup_sc_tups", ":", "\n", "                ", "self", ".", "_input_feat_gen", "(", "sc", ")", "# Generate input features here", "\n", "\n", "", "eval_sc_list", "=", "list", "(", "filter", "(", "lambda", "_sc", ":", "_sc", ".", "ans_size", ">", "0", ",", "[", "tup", "[", "0", "]", "for", "tup", "in", "dedup_sc_tups", "]", ")", ")", "\n", "\n", "optm_sc_pair_list", "=", "[", "]", "\n", "for", "sc1", ",", "f1_1", "in", "pos_tups", ":", "\n", "                ", "if", "self", ".", "neg_strategy", "==", "'Fix'", ":", "\n", "                    ", "for", "sc2", ",", "f1_2", "in", "pos_tups", ":", "# both sc+ and sc- come from positive list", "\n", "                        ", "if", "f1_1", ">", "f1_2", ":", "\n", "                            ", "optm_sc_pair_list", ".", "append", "(", "(", "sc1", ",", "sc2", ")", ")", "\n", "\n", "", "", "np", ".", "random", ".", "shuffle", "(", "neg_tups", ")", "\n", "for", "sc2", ",", "_", "in", "neg_tups", "[", ":", "self", ".", "neg_max_sample", "]", ":", "# sc- comes from negative list", "\n", "                        ", "optm_sc_pair_list", ".", "append", "(", "(", "sc1", ",", "sc2", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "sample_tups", "=", "[", "]", "\n", "runtime_score_1", "=", "(", "0.", "if", "sc1", ".", "run_info", "is", "None", "else", "\n", "sc1", ".", "run_info", ".", "get", "(", "runtime_score_key", ",", "0.", ")", ")", "\n", "for", "sc2", ",", "f1_2", "in", "pos_tups", "+", "neg_tups", ":", "\n", "                        ", "if", "f1_1", ">", "f1_2", ":", "\n", "                            ", "runtime_score_2", "=", "(", "0.", "if", "sc2", ".", "run_info", "is", "None", "else", "\n", "sc2", ".", "run_info", ".", "get", "(", "runtime_score_key", ",", "0.", ")", ")", "\n", "delta", "=", "runtime_score_2", "-", "runtime_score_1", "# the larger, the more critical", "\n", "sample_tups", ".", "append", "(", "(", "sc1", ",", "sc2", ",", "delta", ")", ")", "\n", "", "", "local_picked_tups", "=", "self", ".", "_weighted_sampling", "(", "sample_tups", "=", "sample_tups", ",", "\n", "neg_max_sample", "=", "self", ".", "neg_max_sample", ")", "\n", "optm_sc_pair_list", "+=", "local_picked_tups", "\n", "", "", "q_optm_pairs_dict", "[", "q_idx", "]", "=", "optm_sc_pair_list", "\n", "q_evals_dict", "[", "q_idx", "]", "=", "eval_sc_list", "\n", "total_optm_pair_size", "+=", "len", "(", "optm_sc_pair_list", ")", "\n", "total_eval_sc_size", "+=", "len", "(", "eval_sc_list", ")", "\n", "\n", "", "LogInfo", ".", "logs", "(", "'In total: optm_pairs = %d, eval_sc = %d.'", ",", "total_optm_pair_size", ",", "total_eval_sc_size", ")", "\n", "return", "q_optm_pairs_dict", ",", "q_evals_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._schema_dedup": [[126, 147], ["key_cands_dict.items", "schema_builder.SchemaBuilder._get_rm_key", "key_cands_dict.setdefault().append", "max", "ret_tup_list.append", "key_cands_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._get_rm_key"], ["", "def", "_schema_dedup", "(", "self", ",", "sc_list", ")", ":", "\n", "        ", "\"\"\"\n        Given all candidates of a question, remove duplicate schemas\n        :return: [(sc, specific_f1)]\n        \"\"\"", "\n", "key_cands_dict", "=", "{", "}", "\n", "ret_tup_list", "=", "[", "]", "\n", "for", "sc", "in", "sc_list", ":", "\n", "            ", "key", "=", "self", ".", "_get_rm_key", "(", "sc", ")", "\n", "# separate schemas by task-specific key", "\n", "key_cands_dict", ".", "setdefault", "(", "key", ",", "[", "]", ")", ".", "append", "(", "sc", ")", "\n", "\n", "", "for", "key", ",", "cand_list", "in", "key_cands_dict", ".", "items", "(", ")", ":", "\n", "# All schemas under the same key could be shrink into one candidate", "\n", "            ", "max_f1", "=", "max", "(", "[", "sc", ".", "f1", "for", "sc", "in", "cand_list", "]", ")", "\n", "for", "sc", "in", "cand_list", ":", "\n", "                ", "sc", ".", "rm_f1", "=", "max_f1", "\n", "# just pick the first schema as representative one", "\n", "", "first_sc", "=", "cand_list", "[", "0", "]", "\n", "ret_tup_list", ".", "append", "(", "(", "first_sc", ",", "max_f1", ")", ")", "\n", "", "return", "ret_tup_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._get_rm_key": [[148, 158], ["zip", "rep_list.sort", "rep_list.append"], "methods", ["None"], ["", "def", "_get_rm_key", "(", "self", ",", "sc", ")", ":", "\n", "# category, start, end, detail_path", "\n", "# Just copy from kq_schema.get_rm_key(), and no need to change \"Main\" into \"Entity\"", "\n", "        ", "rep_list", "=", "[", "]", "\n", "for", "raw_path", ",", "using_pred_seq", "in", "zip", "(", "sc", ".", "raw_paths", ",", "sc", ".", "path_list", ")", ":", "\n", "            ", "category", ",", "gl_data", ",", "_", "=", "raw_path", "\n", "local_rep", "=", "'%s:%s:%s:%s'", "%", "(", "category", ",", "gl_data", ".", "start", ",", "gl_data", ".", "end", ",", "'|'", ".", "join", "(", "using_pred_seq", ")", ")", "\n", "rep_list", ".", "append", "(", "local_rep", ")", "\n", "", "rep_list", ".", "sort", "(", ")", "\n", "return", "'\\t'", ".", "join", "(", "rep_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._input_feat_gen": [[159, 181], ["schema_builder.SchemaBuilder.feat_gen_helper.generate_qw_feat", "schema_builder.SchemaBuilder.feat_gen_helper.generate_dep_feat", "schema_builder.SchemaBuilder.feat_gen_helper.generate_whole_path_feat"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_qw_feat", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_dep_feat", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_whole_path_feat"], ["", "def", "_input_feat_gen", "(", "self", ",", "sc", ")", ":", "\n", "        ", "if", "sc", ".", "input_np_dict", "is", "not", "None", ":", "\n", "            ", "return", "\n", "\n", "", "qw_input", ",", "qw_len", "=", "self", ".", "feat_gen_helper", ".", "generate_qw_feat", "(", "sc", "=", "sc", ")", "\n", "\n", "dep_input", ",", "dep_len", "=", "self", ".", "feat_gen_helper", ".", "generate_dep_feat", "(", "sc", "=", "sc", ")", "\n", "\n", "path_size", ",", "path_ids", ",", "pw_input", ",", "pw_len", ",", "pseq_ids", ",", "pseq_len", "=", "self", ".", "feat_gen_helper", ".", "generate_whole_path_feat", "(", "sc", "=", "sc", ")", "\n", "\n", "sc", ".", "input_np_dict", "=", "{", "\n", "'path_size'", ":", "path_size", ",", "\n", "'path_ids'", ":", "path_ids", ",", "\n", "'pw_input'", ":", "pw_input", ",", "\n", "'pw_len'", ":", "pw_len", ",", "\n", "'pseq_ids'", ":", "pseq_ids", ",", "\n", "'pseq_len'", ":", "pseq_len", ",", "\n", "'qw_input'", ":", "qw_input", ",", "\n", "'qw_len'", ":", "qw_len", ",", "\n", "'dep_input'", ":", "dep_input", ",", "\n", "'dep_len'", ":", "dep_len", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema_builder.SchemaBuilder._weighted_sampling": [[183, 201], ["numpy.array", "numpy.exp", "numpy.random.choice", "len", "numpy.sum", "pick_tups.append", "len"], "methods", ["None"], ["", "def", "_weighted_sampling", "(", "self", ",", "sample_tups", ",", "neg_max_sample", ",", "cool_down", "=", "1.0", ")", ":", "\n", "        ", "\"\"\" weighted sampling without replacements \"\"\"", "\n", "if", "len", "(", "sample_tups", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "delta", "=", "np", ".", "array", "(", "[", "tup", "[", "-", "1", "]", "for", "tup", "in", "sample_tups", "]", ")", "\n", "cd_delta", "=", "delta", "*", "cool_down", "\n", "raw_prob", "=", "np", ".", "exp", "(", "cd_delta", ")", "\n", "prob", "=", "raw_prob", "/", "np", ".", "sum", "(", "raw_prob", ")", "\n", "sample_size", "=", "neg_max_sample", "\n", "pick_idx_list", "=", "np", ".", "random", ".", "choice", "(", "a", "=", "len", "(", "sample_tups", ")", ",", "\n", "size", "=", "sample_size", ",", "\n", "replace", "=", "True", ",", "\n", "p", "=", "prob", ")", "\n", "pick_tups", "=", "[", "]", "\n", "for", "idx", "in", "pick_idx_list", ":", "\n", "            ", "tup", "=", "sample_tups", "[", "idx", "]", "\n", "pick_tups", ".", "append", "(", "(", "tup", "[", "0", "]", ",", "tup", "[", "1", "]", ")", ")", "\n", "", "return", "pick_tups", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema.Schema.__init__": [[23, 55], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "q_idx", "=", "None", "\n", "self", ".", "gather_linkings", "=", "None", "# all related linkings of this question (either used or not used)", "\n", "\n", "self", ".", "use_idx", "=", "None", "# UNIQUE schema index mainly used in dataset & dataloader", "\n", "self", ".", "ori_idx", "=", "None", "# original index, equals to the row number of the schema in the file", "\n", "\n", "self", ".", "p", "=", "self", ".", "r", "=", "self", ".", "f1", "=", "None", "\n", "self", ".", "rm_f1", "=", "self", ".", "el_f1", "=", "None", "# the adjusted F1 for different tasks", "\n", "self", ".", "ans_size", "=", "None", "\n", "self", ".", "hops", "=", "None", "\n", "self", ".", "aggregate", "=", "None", "# whether using COUNT(*) as aggregation operator or not.", "\n", "self", ".", "full_constr", "=", "None", "# whether to use full length of constraints (or ignore predicates at main path)", "\n", "self", ".", "main_pred_seq", "=", "None", "# saving [p1, p2]", "\n", "self", ".", "qa_list", "=", "None", "\n", "self", ".", "path_list", "=", "None", "# a list of PURE mid sequence", "\n", "self", ".", "raw_paths", "=", "[", "]", "\n", "# [ (path category, linking result, predicate sequence) ]", "\n", "# path category: 'Main', 'Entity', 'Type', 'Ordinal', 'Time'", "\n", "# linking result: LinkData", "\n", "#                   old: eff_candgen/combinator.py: LinkData,", "\n", "#                   new: candgen_acl18/global_linker.py: LinkData", "\n", "# predicate sequence: sequences of predicates only", "\n", "#   main path: focus --> answer", "\n", "#   constraint path: answer --> constraint node", "\n", "\n", "self", ".", "replace_linkings", "=", "None", "\n", "# If one linking result is not used in the path list,", "\n", "# we save it here, and replace the corresponding mention by placeholders.", "\n", "\n", "self", ".", "input_np_dict", "=", "None", "# the dictionary storing various input tensors", "\n", "self", ".", "run_info", "=", "None", "# additional attribute to save runtime results", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema.Schema.read_schema_from_json": [[56, 100], ["json.loads", "json.loads.get", "json.loads.get", "json_line.strip", "json.loads.keys", "schema.Schema.raw_paths.append", "len", "RawPath", "len", "len"], "methods", ["None"], ["", "def", "read_schema_from_json", "(", "self", ",", "q_idx", ",", "json_line", ",", "gather_linkings", ",", "ori_idx", ",", "full_constr", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Read the schema from json files. (provided with detail linking results)\n        We will read the following information from the json file:\n            1. p / r / f1\n            2. raw_paths: [ (category, focus_idx, focus_mid, pred_seq) ]\n        :param q_idx: question index\n        :param json_line: a line of schema (json format, usually a dict)\n        :param gather_linkings: [LinkData]\n        :param ori_idx: original index\n        :param full_constr: whether to use full length constraint, or the shorter length one.\n        :return: A schema instance\n        \"\"\"", "\n", "info_dict", "=", "json", ".", "loads", "(", "json_line", ".", "strip", "(", ")", ")", "\n", "\n", "if", "'p'", "in", "info_dict", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "p", "=", "info_dict", "[", "'p'", "]", "\n", "self", ".", "r", "=", "info_dict", "[", "'r'", "]", "\n", "self", ".", "f1", "=", "info_dict", "[", "'f1'", "]", "\n", "self", ".", "ans_size", "=", "info_dict", "[", "'ans_size'", "]", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "ans_size", "=", "info_dict", "[", "'ans_size'", "]", "\n", "\n", "", "self", ".", "q_idx", "=", "q_idx", "\n", "self", ".", "gather_linkings", "=", "gather_linkings", "\n", "self", ".", "ori_idx", "=", "ori_idx", "+", "1", "\n", "self", ".", "full_constr", "=", "full_constr", "\n", "\n", "self", ".", "aggregate", "=", "info_dict", ".", "get", "(", "'agg'", ",", "False", ")", "\n", "self", ".", "hops", "=", "info_dict", ".", "get", "(", "'hops'", ")", "\n", "\n", "for", "raw_path", "in", "info_dict", "[", "'raw_paths'", "]", ":", "\n", "            ", "category", ",", "focus_idx", ",", "focus_mid", ",", "pred_seq", "=", "raw_path", "\n", "if", "category", "==", "'Main'", ":", "\n", "                ", "self", ".", "hops", "=", "len", "(", "pred_seq", ")", "\n", "self", ".", "main_pred_seq", "=", "pred_seq", "\n", "", "elif", "not", "self", ".", "full_constr", ":", "\n", "# shorten constraints, be careful with the constraint direction, still ANS-->CONSTR", "\n", "                ", "assert", "1", "<=", "len", "(", "pred_seq", ")", "<=", "2", "\n", "if", "len", "(", "pred_seq", ")", "==", "2", ":", "\n", "                    ", "pred_seq", "=", "pred_seq", "[", "1", ":", "]", "# ignore the overlapping predicate at the main path", "\n", "", "", "focus", "=", "gather_linkings", "[", "focus_idx", "]", "\n", "self", ".", "raw_paths", ".", "append", "(", "RawPath", "(", "path_cate", "=", "category", ",", "focus", "=", "focus", ",", "pred_seq", "=", "pred_seq", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema.Schema.construct_path_list": [[101, 140], ["schema.Schema.path_list.append", "schema.Schema.replace_linkings.append", "list", "list.append", "schema.Schema.path_list.append", "schema.Schema.path_list.append", "list", "schema.Schema.replace_linkings.append", "list", "list.append", "schema.Schema.replace_linkings.append", "list", "list.append"], "methods", ["None"], ["", "", "def", "construct_path_list", "(", "self", ")", ":", "\n", "# Convert raw path into formal mid sequence", "\n", "        ", "if", "self", ".", "path_list", "is", "not", "None", "and", "self", ".", "replace_linkings", "is", "not", "None", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "path_list", "=", "[", "]", "\n", "self", ".", "replace_linkings", "=", "[", "]", "\n", "\n", "assert", "self", ".", "raw_paths", "is", "not", "None", "\n", "for", "raw_path", "in", "self", ".", "raw_paths", ":", "\n", "            ", "path_cate", ",", "link_data", ",", "pred_seq", "=", "raw_path", "\n", "if", "path_cate", "==", "'Main'", ":", "\n", "                ", "self", ".", "path_list", ".", "append", "(", "pred_seq", ")", "\n", "self", ".", "replace_linkings", ".", "append", "(", "link_data", ")", "\n", "", "elif", "path_cate", "==", "'Type'", ":", "\n", "                ", "type_mid", "=", "link_data", ".", "value", "\n", "use_mid_seq", "=", "list", "(", "pred_seq", ")", "\n", "use_mid_seq", ".", "append", "(", "type_mid", ")", "\n", "self", ".", "path_list", ".", "append", "(", "use_mid_seq", ")", "\n", "", "else", ":", "\n", "# Prepare to fix the direction, if possible", "\n", "                ", "use_mid_seq", "=", "[", "]", "\n", "if", "path_cate", "==", "'Entity'", ":", "\n", "                    ", "use_mid_seq", "=", "list", "(", "pred_seq", ")", "\n", "self", ".", "replace_linkings", ".", "append", "(", "link_data", ")", "\n", "", "elif", "path_cate", "==", "'Time'", ":", "\n", "                    ", "comp", "=", "link_data", ".", "comp", "\n", "assert", "comp", "in", "tml_comp_dict", "\n", "use_mid_seq", "=", "list", "(", "pred_seq", ")", "\n", "# virtual mid for time comparison", "\n", "use_mid_seq", ".", "append", "(", "tml_comp_dict", "[", "comp", "]", ")", "\n", "self", ".", "replace_linkings", ".", "append", "(", "link_data", ")", "\n", "", "elif", "path_cate", "==", "'Ordinal'", ":", "\n", "                    ", "comp", "=", "link_data", ".", "comp", "\n", "assert", "comp", "in", "ordinal_dict", "\n", "use_mid_seq", "=", "list", "(", "pred_seq", ")", "\n", "use_mid_seq", ".", "append", "(", "ordinal_dict", "[", "comp", "]", ")", "\n", "\n", "", "self", ".", "path_list", ".", "append", "(", "use_mid_seq", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.__init__": [[10, 23], ["utils.dependency_util.DependencyUtil"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "active_dicts", ",", "qa_list", ",", "freebase_helper", ",", "\n", "path_max_size", "=", "3", ",", "qw_max_len", "=", "20", ",", "pw_max_len", "=", "8", ",", "pseq_max_len", "=", "3", ")", ":", "\n", "        ", "self", ".", "word_idx_dict", "=", "active_dicts", "[", "'word'", "]", "\n", "self", ".", "path_idx_dict", "=", "active_dicts", "[", "'path'", "]", "\n", "self", ".", "mid_idx_dict", "=", "active_dicts", "[", "'mid'", "]", "\n", "self", ".", "qa_list", "=", "qa_list", "\n", "self", ".", "freebase_helper", "=", "freebase_helper", "\n", "self", ".", "path_max_size", "=", "path_max_size", "\n", "self", ".", "qw_max_len", "=", "qw_max_len", "\n", "self", ".", "pw_max_len", "=", "pw_max_len", "\n", "self", ".", "pseq_max_len", "=", "pseq_max_len", "\n", "\n", "self", ".", "dep_util", "=", "DependencyUtil", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_qw_feat": [[24, 50], ["list", "min", "numpy.zeros", "numpy.zeros", "range", "tok.lower", "filter", "feature_helper.FeatureHelper.word_idx_dict.get", "len", "range", "len", "range", "len"], "methods", ["None"], ["", "def", "generate_qw_feat", "(", "self", ",", "sc", ")", ":", "\n", "        ", "q_idx", "=", "sc", ".", "q_idx", "\n", "qa", "=", "self", ".", "qa_list", "[", "q_idx", "]", "\n", "lower_tok_list", "=", "[", "tok", ".", "lower", "(", ")", "for", "tok", "in", "qa", "[", "'tokens'", "]", "]", "\n", "\n", "for", "raw_path", "in", "sc", ".", "raw_paths", ":", "\n", "            ", "category", ",", "gl_data", ",", "_", "=", "raw_path", "\n", "if", "gl_data", ".", "category", "==", "'Entity'", "and", "gl_data", ".", "end", "<=", "len", "(", "lower_tok_list", ")", ":", "\n", "                ", "for", "idx", "in", "range", "(", "gl_data", ".", "start", ",", "gl_data", ".", "end", "-", "1", ")", ":", "\n", "                    ", "lower_tok_list", "[", "idx", "]", "=", "''", "\n", "", "lower_tok_list", "[", "gl_data", ".", "end", "-", "1", "]", "=", "'<E>'", "\n", "", "elif", "gl_data", ".", "category", "==", "'Tm'", "and", "gl_data", ".", "end", "<=", "len", "(", "lower_tok_list", ")", ":", "\n", "                ", "for", "idx", "in", "range", "(", "gl_data", ".", "start", ",", "gl_data", ".", "end", "-", "1", ")", ":", "\n", "                    ", "lower_tok_list", "[", "idx", "]", "=", "''", "\n", "", "lower_tok_list", "[", "gl_data", ".", "end", "-", "1", "]", "=", "'<Tm>'", "\n", "\n", "", "", "ph_lower_tok_list", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "''", ",", "lower_tok_list", ")", ")", "\n", "ph_qw_idx_seq", "=", "[", "self", ".", "word_idx_dict", ".", "get", "(", "token", ",", "2", ")", "for", "token", "in", "ph_lower_tok_list", "]", "\n", "\n", "ph_len", "=", "min", "(", "self", ".", "qw_max_len", ",", "len", "(", "ph_lower_tok_list", ")", ")", "\n", "qw_input", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", "self", ".", "qw_max_len", ")", ",", "dtype", "=", "'int32'", ")", "\n", "qw_len", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", ")", ",", "dtype", "=", "'int32'", ")", "\n", "for", "path_idx", "in", "range", "(", "self", ".", "path_max_size", ")", ":", "\n", "            ", "qw_input", "[", "path_idx", ",", ":", "ph_len", "]", "=", "ph_qw_idx_seq", "[", ":", "ph_len", "]", "\n", "qw_len", "[", "path_idx", "]", "=", "ph_len", "\n", "", "return", "qw_input", ",", "qw_len", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_dep_feat": [[51, 67], ["feature_helper.FeatureHelper.dep_util.context_pattern", "numpy.zeros", "numpy.zeros", "enumerate", "tok.lower", "min", "len", "feature_helper.FeatureHelper.word_idx_dict.get"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.dependency_util.DependencyUtil.context_pattern"], ["", "def", "generate_dep_feat", "(", "self", ",", "sc", ")", ":", "\n", "        ", "q_idx", "=", "sc", ".", "q_idx", "\n", "qa", "=", "self", ".", "qa_list", "[", "q_idx", "]", "\n", "tok_list", "=", "[", "tok", ".", "lower", "(", ")", "for", "tok", "in", "qa", "[", "'tokens'", "]", "]", "\n", "linkings", "=", "[", "raw_path", "[", "1", "]", "for", "raw_path", "in", "sc", ".", "raw_paths", "]", "\n", "\n", "dep_path_tok_lists", "=", "self", ".", "dep_util", ".", "context_pattern", "(", "tok_list", "=", "tok_list", ",", "linkings", "=", "linkings", ")", "\n", "\n", "dep_input", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", "self", ".", "qw_max_len", ")", ",", "dtype", "=", "'int32'", ")", "\n", "dep_len", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", ")", ",", "dtype", "=", "'int32'", ")", "\n", "for", "path_idx", ",", "local_dep_seq", "in", "enumerate", "(", "dep_path_tok_lists", ")", ":", "\n", "            ", "local_len", "=", "min", "(", "self", ".", "qw_max_len", ",", "len", "(", "local_dep_seq", ")", ")", "\n", "local_dep_idx_seq", "=", "[", "self", ".", "word_idx_dict", ".", "get", "(", "token", ",", "2", ")", "for", "token", "in", "local_dep_seq", "]", "\n", "dep_input", "[", "path_idx", ",", ":", "local_len", "]", "=", "local_dep_idx_seq", "[", ":", "local_len", "]", "\n", "dep_len", "[", "path_idx", "]", "=", "local_len", "\n", "", "return", "dep_input", ",", "dep_len", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_whole_path_feat": [[68, 97], ["len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "zip", "feature_helper.FeatureHelper.path_idx_dict.get", "len", "enumerate", "sc.path_words_list.append", "min", "feature_helper.FeatureHelper.mid_idx_dict.get", "feature_helper.FeatureHelper.freebase_helper.get_item_name", "feature_helper.FeatureHelper.word_idx_dict.get", "len", "feature_helper.FeatureHelper.split"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.freebase_helper.FreebaseHelper.get_item_name"], ["", "def", "generate_whole_path_feat", "(", "self", ",", "sc", ")", ":", "\n", "        ", "path_size", "=", "len", "(", "sc", ".", "raw_paths", ")", "\n", "path_ids", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", ")", ",", "dtype", "=", "'int32'", ")", "\n", "pw_input", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", "self", ".", "pw_max_len", ")", ",", "dtype", "=", "'int32'", ")", "\n", "pw_len", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", ")", ",", "dtype", "=", "'int32'", ")", "\n", "pseq_ids", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", "self", ".", "pseq_max_len", ")", ",", "dtype", "=", "'int32'", ")", "\n", "pseq_len", "=", "np", ".", "zeros", "(", "(", "self", ".", "path_max_size", ",", ")", ",", "dtype", "=", "'int32'", ")", "\n", "sc", ".", "path_words_list", "=", "[", "]", "\n", "\n", "for", "path_idx", ",", "(", "raw_path", ",", "mid_seq", ")", "in", "enumerate", "(", "zip", "(", "sc", ".", "raw_paths", ",", "sc", ".", "path_list", ")", ")", ":", "\n", "            ", "path_cate", "=", "raw_path", "[", "0", "]", "\n", "path_str", "=", "'%s|%s'", "%", "(", "path_cate", ",", "'\\t'", ".", "join", "(", "mid_seq", ")", ")", "\n", "path_ids", "[", "path_idx", "]", "=", "self", ".", "path_idx_dict", ".", "get", "(", "path_str", ",", "2", ")", "\n", "\n", "local_words", "=", "[", "]", "# collect path words", "\n", "pseq_len", "[", "path_idx", "]", "=", "len", "(", "mid_seq", ")", "\n", "for", "mid_pos", ",", "mid", "in", "enumerate", "(", "mid_seq", ")", ":", "\n", "                ", "pseq_ids", "[", "path_idx", ",", "mid_pos", "]", "=", "self", ".", "mid_idx_dict", ".", "get", "(", "mid", ",", "2", ")", "\n", "p_name", "=", "self", ".", "freebase_helper", ".", "get_item_name", "(", "mid", ")", "\n", "if", "p_name", "!=", "''", ":", "\n", "                    ", "spt", "=", "p_name", ".", "split", "(", "' '", ")", "\n", "local_words", "+=", "spt", "\n", "", "", "sc", ".", "path_words_list", ".", "append", "(", "local_words", ")", "\n", "local_pw_idx_seq", "=", "[", "self", ".", "word_idx_dict", ".", "get", "(", "token", ",", "2", ")", "for", "token", "in", "local_words", "]", "\n", "local_pw_len", "=", "min", "(", "self", ".", "pw_max_len", ",", "len", "(", "local_pw_idx_seq", ")", ")", "\n", "pw_input", "[", "path_idx", ",", ":", "local_pw_len", "]", "=", "local_pw_idx_seq", "[", ":", "local_pw_len", "]", "\n", "pw_len", "[", "path_idx", "]", "=", "local_pw_len", "\n", "\n", "", "return", "path_size", ",", "path_ids", ",", "pw_input", ",", "pw_len", ",", "pseq_ids", ",", "pseq_len", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.knowledge_loader.KnowledgeLoader.__init__": [[18, 20], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.knowledge_loader.KnowledgeLoader.load_vocab": [[21, 47], ["print", "print", "print", "numpy.array", "open", "json.load", "sorted", "len", "open", "enumerate", "numpy.array.append", "len", "line.strip", "list", "numpy.zeros", "map", "line.strip.find", "vectors[].split", "line.strip.find"], "methods", ["None"], ["", "def", "load_vocab", "(", "self", ",", "vocab_size", ",", "embed_dim", "=", "300", ")", ":", "\n", "        ", "print", "(", "\"Loading word vocabs...\"", ")", "\n", "with", "open", "(", "'%s/vocab'", "%", "self", ".", "data_dir", ")", "as", "fr", ":", "\n", "            ", "raw_vocab", "=", "json", ".", "load", "(", "fr", ")", "\n", "", "vocab_list", "=", "START_VOCAB", "+", "sorted", "(", "raw_vocab", ",", "key", "=", "raw_vocab", ".", "get", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "vocab_list", ")", ">", "vocab_size", ":", "\n", "            ", "vocab_list", "=", "vocab_list", "[", ":", "vocab_size", "]", "\n", "", "print", "(", "\"%d words loaded.\"", "%", "len", "(", "vocab_list", ")", ")", "\n", "\n", "print", "(", "\"Loading word vectors...\"", ")", "\n", "vectors", "=", "{", "}", "\n", "with", "open", "(", "'%s/glove.840B.300d.txt'", "%", "self", ".", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "s", "=", "line", ".", "strip", "(", ")", "\n", "word", "=", "s", "[", ":", "s", ".", "find", "(", "' '", ")", "]", "\n", "vector", "=", "s", "[", "s", ".", "find", "(", "' '", ")", "+", "1", ":", "]", "\n", "vectors", "[", "word", "]", "=", "vector", "\n", "", "", "embed", "=", "[", "]", "\n", "for", "word", "in", "vocab_list", ":", "\n", "            ", "if", "word", "in", "vectors", ":", "\n", "                ", "vector", "=", "list", "(", "map", "(", "float", ",", "vectors", "[", "word", "]", ".", "split", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "vector", "=", "np", ".", "zeros", "(", "embed_dim", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "embed", ".", "append", "(", "vector", ")", "\n", "", "embed", "=", "np", ".", "array", "(", "embed", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "return", "vocab_list", ",", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.knowledge_loader.KnowledgeLoader.load_entity_relation": [[48, 84], ["print", "print", "print", "print", "print", "print", "numpy.zeros", "numpy.array", "numpy.concatenate", "print", "print", "open", "enumerate", "open", "enumerate", "open", "enumerate", "open", "enumerate", "len", "line.strip", "entity_list.append", "len", "line.strip", "relation_list.append", "len", "line.strip().split", "entity_embed.append", "line.strip().split", "relation_embed.append", "list", "line.strip", "map", "line.strip"], "methods", ["None"], ["", "def", "load_entity_relation", "(", "self", ",", "trans_dim", "=", "100", ")", ":", "\n", "        ", "print", "(", "\"Loading entity vocabs...\"", ")", "\n", "entity_list", "=", "[", "]", "\n", "with", "open", "(", "'%s/entity.txt'", "%", "self", ".", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "e", "=", "line", ".", "strip", "(", ")", "\n", "entity_list", ".", "append", "(", "e", ")", "\n", "", "", "print", "(", "\"%d entities loaded.\"", "%", "len", "(", "entity_list", ")", ")", "\n", "print", "(", "\"Loading relation vocabs...\"", ")", "\n", "relation_list", "=", "[", "]", "\n", "with", "open", "(", "'%s/relation.txt'", "%", "self", ".", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "r", "=", "line", ".", "strip", "(", ")", "\n", "relation_list", ".", "append", "(", "r", ")", "\n", "", "", "print", "(", "\"%d relations loaded.\"", "%", "len", "(", "relation_list", ")", ")", "\n", "\n", "print", "(", "\"Loading entity vectors...\"", ")", "\n", "entity_embed", "=", "[", "]", "\n", "with", "open", "(", "'%s/entity_transE.txt'", "%", "self", ".", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "s", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "entity_embed", ".", "append", "(", "list", "(", "map", "(", "float", ",", "s", ")", ")", ")", "\n", "\n", "", "", "print", "(", "\"Loading relation vectors...\"", ")", "\n", "relation_embed", "=", "[", "]", "\n", "with", "open", "(", "'%s/relation_transE.txt'", "%", "self", ".", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "s", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "relation_embed", ".", "append", "(", "s", ")", "\n", "", "", "pad_embed", "=", "np", ".", "zeros", "(", "(", "4", ",", "trans_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "entity_relation_vocab", "=", "START_KB", "+", "entity_list", "+", "relation_list", "\n", "entity_relation_embed", "=", "np", ".", "array", "(", "entity_embed", "+", "relation_embed", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "entity_relation_embed", "=", "np", ".", "concatenate", "(", "[", "pad_embed", ",", "entity_relation_embed", "]", ",", "axis", "=", "0", ")", "\n", "print", "(", "\"entity_relation_vocab:\"", ",", "len", "(", "entity_relation_vocab", ")", ")", "\n", "print", "(", "\"entity_relation_embed:\"", ",", "entity_relation_embed", ".", "shape", ")", "\n", "return", "entity_relation_vocab", ",", "entity_relation_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.knowledge_loader.KnowledgeLoader.load_csk_entities": [[85, 94], ["print", "print", "open", "enumerate", "csk_entity_list.append", "len", "entity.strip"], "methods", ["None"], ["", "def", "load_csk_entities", "(", "self", ")", ":", "\n", "        ", "csk_entity_list", "=", "[", "]", "\n", "kb_entity_fp", "=", "\"%s/csk_entities.txt\"", "%", "self", ".", "data_dir", "\n", "print", "(", "'Loading commonsense entities from [%s]'", "%", "kb_entity_fp", ")", "\n", "with", "open", "(", "kb_entity_fp", ",", "'r'", ")", "as", "fr", ":", "\n", "            ", "for", "idx", ",", "entity", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "csk_entity_list", ".", "append", "(", "entity", ".", "strip", "(", ")", ")", "\n", "", "", "print", "(", "\"%d csk_entities loaded.\"", "%", "len", "(", "csk_entity_list", ")", ")", "\n", "return", "csk_entity_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.__init__": [[17, 39], ["queue.Queue", "data_batcher.DataBatcher.batch_generator", "data_batcher.DataBatcher.loader_generator", "threading.Thread", "data_batcher.DataBatcher.loader_q_thread.setDaemon", "data_batcher.DataBatcher.loader_q_thread.start", "threading.Thread", "data_batcher.DataBatcher.watch_thread.setDaemon", "data_batcher.DataBatcher.watch_thread.start"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.batch_generator", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.loader_generator"], ["def", "__init__", "(", "self", ",", "data_dir", ",", "file_list", ",", "batch_size", ",", "num_epoch", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "file_list", "=", "file_list", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_epoch", "=", "num_epoch", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "cur_epoch", "=", "0", "\n", "self", ".", "loader_queue", "=", "Queue", "(", "maxsize", "=", "CHUNK_NUM", ")", "\n", "self", ".", "loader_queue_size", "=", "0", "\n", "self", ".", "batch_iter", "=", "self", ".", "batch_generator", "(", ")", "\n", "self", ".", "input_gen", "=", "self", ".", "loader_generator", "(", ")", "\n", "\n", "# Start the threads that load the queues", "\n", "self", ".", "loader_q_thread", "=", "Thread", "(", "target", "=", "self", ".", "fill_loader_queue", ")", "\n", "self", ".", "loader_q_thread", ".", "setDaemon", "(", "True", ")", "\n", "self", ".", "loader_q_thread", ".", "start", "(", ")", "\n", "\n", "# Start a thread that watches the other threads and restarts them if they're dead", "\n", "self", ".", "watch_thread", "=", "Thread", "(", "target", "=", "self", ".", "monitor_threads", ")", "\n", "self", ".", "watch_thread", ".", "setDaemon", "(", "True", ")", "\n", "self", ".", "watch_thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.get_batch": [[40, 47], ["next"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "batch_data", ",", "local_size", "=", "next", "(", "self", ".", "batch_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "batch_data", "=", "None", "\n", "local_size", "=", "0", "\n", "", "return", "batch_data", ",", "local_size", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.get_epoch": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_epoch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.full": [[51, 56], ["None"], "methods", ["None"], ["", "def", "full", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "loader_queue_size", "==", "CHUNK_NUM", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.batch_generator": [[57, 65], ["data_batcher.DataBatcher.loader_queue.get", "range", "data_batcher.DataBatcher.get_batch"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.get_batch"], ["", "", "def", "batch_generator", "(", "self", ")", ":", "\n", "        ", "while", "self", ".", "loader_queue_size", ">", "0", ":", "\n", "            ", "data_loader", "=", "self", ".", "loader_queue", ".", "get", "(", ")", "\n", "n_batch", "=", "data_loader", ".", "n_batch", "\n", "self", ".", "loader_queue_size", "-=", "1", "\n", "for", "batch_idx", "in", "range", "(", "n_batch", ")", ":", "\n", "                ", "batch_data", ",", "local_size", "=", "data_loader", ".", "get_batch", "(", "batch_idx", "=", "batch_idx", ")", "\n", "yield", "batch_data", ",", "local_size", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.loader_generator": [[66, 77], ["range", "enumerate", "numpy.random.shuffle", "open", "pickle.load", "data_loader.DataLoader.DataLoader", "data_loader.DataLoader.DataLoader.feed_by_data"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.feed_by_data"], ["", "", "", "def", "loader_generator", "(", "self", ")", ":", "\n", "        ", "for", "epoch", "in", "range", "(", "self", ".", "num_epoch", ")", ":", "\n", "            ", "self", ".", "cur_epoch", "=", "epoch", "\n", "if", "self", ".", "shuffle", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "file_list", ")", "\n", "", "for", "idx", ",", "f", "in", "enumerate", "(", "self", ".", "file_list", ")", ":", "\n", "                ", "reader", "=", "open", "(", "\"%s/%s\"", "%", "(", "self", ".", "data_dir", ",", "f", ")", ",", "'br'", ")", "\n", "q_dict", "=", "pickle", ".", "load", "(", "reader", ")", "\n", "data_loader", "=", "DataLoader", "(", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "data_loader", ".", "feed_by_data", "(", "q_dict", ")", "\n", "yield", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.fill_loader_queue": [[78, 87], ["next", "data_batcher.DataBatcher.loader_queue.put"], "methods", ["None"], ["", "", "", "def", "fill_loader_queue", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "if", "self", ".", "loader_queue_size", "<=", "CHUNK_NUM", ":", "\n", "                ", "try", ":", "\n", "                    ", "data_loader", "=", "next", "(", "self", ".", "input_gen", ")", "\n", "self", ".", "loader_queue", ".", "put", "(", "data_loader", ")", "\n", "self", ".", "loader_queue_size", "+=", "1", "\n", "", "except", "StopIteration", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_batcher.DataBatcher.monitor_threads": [[88, 98], ["time.sleep", "data_batcher.DataBatcher.loader_q_thread.is_alive", "print", "threading.Thread", "threading.Thread.start"], "methods", ["None"], ["", "", "", "", "def", "monitor_threads", "(", "self", ")", ":", "\n", "        ", "\"\"\"Watch loader queue thread and restart if dead.\"\"\"", "\n", "while", "True", ":", "\n", "            ", "time", ".", "sleep", "(", "60", ")", "\n", "if", "not", "self", ".", "loader_q_thread", ".", "is_alive", "(", ")", ":", "# if the thread is dead", "\n", "                ", "print", "(", "'Found loader queue thread dead. Restarting.'", ")", "\n", "new_t", "=", "Thread", "(", "target", "=", "self", ".", "fill_loader_queue", ")", "\n", "self", ".", "loader_q_thread", "=", "new_t", "\n", "new_t", ".", "daemon", "=", "True", "\n", "new_t", ".", "start", "(", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.__init__": [[12, 20], ["None"], "methods", ["None"], ["START_VOCAB", "=", "[", "'_PAD'", ",", "'_UNK'", ",", "'_GO'", ",", "'_EOS'", "]", "\n", "\n", "\n", "def", "load_data", "(", "data_dir", ",", "is_train", "=", "False", ")", ":", "\n", "    ", "data_train", ",", "data_dev", ",", "data_test", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "is_train", ":", "\n", "        ", "with", "open", "(", "'%s/train.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "data_train", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.__len__": [[21, 23], ["None"], "methods", ["None"], ["if", "idx", ">", "0", "and", "idx", "%", "100000", "==", "0", ":", "\n", "                    ", "print", "(", "'read train file line %d'", "%", "idx", ")", "\n", "", "", "", "with", "open", "(", "'%s/valid.txt'", "%", "data_dir", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.get_batch": [[24, 28], ["None"], "methods", ["None"], ["            ", "for", "line", "in", "f", ":", "\n", "                ", "data_dev", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "'%s/test.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.prepare_input_list": [[29, 55], ["len", "global_input_dict.items", "numpy.random.shuffle", "data_loader.DataLoader.batch_data_list.append", "min", "data_loader.DataLoader.batch_size_list.append", "range", "len", "print", "numpy.array", "len"], "methods", ["None"], ["                ", "data_test", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "", "if", "is_train", ":", "\n", "        ", "return", "data_train", ",", "data_dev", "\n", "", "else", ":", "\n", "        ", "return", "data_test", "\n", "\n", "\n", "", "", "def", "load_trans_data", "(", "dir", ",", "is_train", "=", "False", ")", ":", "\n", "    ", "data_trans_train", "=", "{", "}", "\n", "data_trans_valid", "=", "{", "}", "\n", "data_trans_test", "=", "{", "}", "\n", "\n", "if", "is_train", ":", "\n", "# TODO\uff1arevise to automatically check", "\n", "        ", "train_list", "=", "list", "(", "range", "(", "0", ",", "34", ")", ")", "\n", "train_list", "=", "[", "str", "(", "id", ")", "for", "id", "in", "train_list", "]", "\n", "sent_repr", "=", "[", "]", "\n", "rm_final_feats", "=", "[", "]", "\n", "for", "idx", "in", "train_list", ":", "\n", "            ", "with", "open", "(", "'%s/data_trans_train_%s.picke'", "%", "(", "dir", ",", "idx", ")", ",", "'rb'", ")", "as", "fr", ":", "\n", "                ", "print", "(", "\"read data_trans_tran_%s.pickle\"", "%", "idx", ")", "\n", "trans_bucket", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "sent_bucket", "=", "trans_bucket", "[", "'sent_repr'", "]", ".", "tolist", "(", ")", "\n", "rm_feat_bucket", "=", "trans_bucket", "[", "'rm_final_feats'", "]", ".", "tolist", "(", ")", "\n", "for", "sent", ",", "rm_feat", "in", "zip", "(", "sent_bucket", ",", "rm_feat_bucket", ")", ":", "\n", "                    ", "sent_repr", ".", "append", "(", "sent", ")", "\n", "rm_final_feats", ".", "append", "(", "rm_feat", ")", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.load_data": [[56, 69], ["print", "time.time", "len", "print", "pickle.load.items", "data_loader.DataLoader.prepare_input_list", "open", "pickle.load", "input_np_dict.items", "global_input_dict.setdefault().append", "time.time", "global_input_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.prepare_input_list"], ["\n", "", "", "", "data_trans_train", "=", "{", "'sent_repr'", ":", "np", ".", "array", "(", "sent_repr", ")", ",", "\n", "'rm_final_feats'", ":", "np", ".", "array", "(", "rm_final_feats", ")", "}", "\n", "print", "(", "\"trans_sent_repr:\"", ",", "data_trans_train", "[", "'sent_repr'", "]", ".", "shape", ")", "\n", "print", "(", "\"trans_rm_feats:\"", ",", "data_trans_train", "[", "'rm_final_feats'", "]", ".", "shape", ")", "\n", "\n", "with", "open", "(", "'%s/data_trans_valid.picke'", "%", "dir", ",", "'rb'", ")", "as", "fr", ":", "\n", "            ", "data_trans_valid", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "'%s/data_trans_test.picke'", "%", "dir", ",", "'rb'", ")", "as", "fr", ":", "\n", "            ", "data_trans_test", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "", "", "if", "is_train", ":", "\n", "        ", "return", "data_trans_train", ",", "data_trans_valid", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.feed_by_data": [[70, 77], ["len", "q_dict.items", "data_loader.DataLoader.prepare_input_list", "input_np_dict.items", "global_input_dict.setdefault().append", "global_input_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.prepare_input_list"], ["", "else", ":", "\n", "        ", "return", "data_trans_test", "\n", "\n", "\n", "", "", "def", "load_vocab", "(", "dir", ",", "vocab_size", ",", "embed_units", ")", ":", "\n", "    ", "print", "(", "\"loading word vocabs...\"", ")", "\n", "with", "open", "(", "'%s/vocab'", "%", "dir", ")", "as", "fr", ":", "\n", "        ", "raw_vocab", "=", "json", ".", "load", "(", "fr", ")", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.UnidirectionalRNNEncoder.__init__": [[19, 26], ["copy.deepcopy"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "mode", ")", ":", "\n", "        ", "self", ".", "params", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "# only keep dropout during training", "\n", "if", "mode", "!=", "tf", ".", "contrib", ".", "learn", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "            ", "self", ".", "params", "[", "\"dropout_input_keep_prob\"", "]", "=", "1.0", "\n", "self", ".", "params", "[", "\"dropout_output_keep_prob\"", "]", "=", "1.0", "\n", "self", ".", "params", "[", "\"reuse\"", "]", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.UnidirectionalRNNEncoder.encode": [[27, 44], ["rnn_encoder.get_rnn_cell", "tensorflow.contrib.rnn.static_rnn", "tensorflow.stack", "EncoderOutput"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.get_rnn_cell"], ["", "", "def", "encode", "(", "self", ",", "inputs", ",", "sequence_length", ",", "initial_state", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "# cell = get_rnn_cell(**self.params[\"rnn_cell\"])", "\n", "        ", "self", ".", "params", "[", "'reuse'", "]", "=", "reuse", "# KQ: temporary solution", "\n", "cell", "=", "get_rnn_cell", "(", "**", "self", ".", "params", ")", "\n", "outputs", ",", "state", "=", "tf", ".", "contrib", ".", "rnn", ".", "static_rnn", "(", "cell", "=", "cell", ",", "\n", "inputs", "=", "inputs", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "attention_values", "=", "tf", ".", "stack", "(", "outputs", ",", "axis", "=", "1", ")", "\n", "\n", "return", "EncoderOutput", "(", "\n", "outputs", "=", "outputs", ",", "\n", "final_state", "=", "state", ",", "\n", "attention_values", "=", "attention_values", ",", "\n", "attention_values_length", "=", "sequence_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.BidirectionalRNNEncoder.__init__": [[47, 53], ["copy.deepcopy", "utils.log_util.LogInfo.logs"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "mode", ")", ":", "\n", "        ", "self", ".", "params", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "# only keep dropout during training", "\n", "if", "mode", "!=", "tf", ".", "contrib", ".", "learn", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "            ", "self", ".", "params", "[", "'keep_prob'", "]", "=", "1.0", "\n", "", "LogInfo", ".", "logs", "(", "'Show Bi-RNN param: %s'", ",", "self", ".", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.BidirectionalRNNEncoder.encode": [[54, 71], ["rnn_encoder.get_rnn_cell", "rnn_encoder.get_rnn_cell", "tensorflow.contrib.rnn.static_bidirectional_rnn", "tensorflow.stack", "EncoderOutput"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.get_rnn_cell", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.get_rnn_cell"], ["", "def", "encode", "(", "self", ",", "inputs", ",", "sequence_length", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "self", ".", "params", "[", "'reuse'", "]", "=", "reuse", "# KQ: temporary solution", "\n", "cell_fw", "=", "get_rnn_cell", "(", "**", "self", ".", "params", ")", "\n", "cell_bw", "=", "get_rnn_cell", "(", "**", "self", ".", "params", ")", "\n", "\n", "outputs", ",", "output_state_fw", ",", "output_state_bw", "=", "tf", ".", "contrib", ".", "rnn", ".", "static_bidirectional_rnn", "(", "cell_fw", "=", "cell_fw", ",", "cell_bw", "=", "cell_bw", ",", "inputs", "=", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "attention_values", "=", "tf", ".", "stack", "(", "outputs", ",", "axis", "=", "1", ")", "\n", "\n", "return", "EncoderOutput", "(", "\n", "outputs", "=", "outputs", ",", "\n", "final_state", "=", "(", "output_state_fw", ",", "output_state_bw", ")", ",", "\n", "attention_values", "=", "attention_values", ",", "\n", "attention_values_length", "=", "sequence_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.get_rnn_cell": [[73, 107], ["range", "cells.append", "len", "tensorflow.contrib.rnn.core_rnn_cell.MultiRNNCell", "tensorflow.contrib.rnn.BasicRNNCell", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.contrib.rnn.GRUCell", "tensorflow.contrib.rnn.BasicLSTMCell"], "function", ["None"], ["", "", "def", "get_rnn_cell", "(", "cell_class", ",", "\n", "num_units", ",", "\n", "num_layers", "=", "1", ",", "\n", "keep_prob", "=", "1.0", ",", "\n", "dropout_input_keep_prob", "=", "None", ",", "\n", "dropout_output_keep_prob", "=", "None", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "if", "dropout_input_keep_prob", "is", "None", ":", "\n", "        ", "dropout_input_keep_prob", "=", "keep_prob", "\n", "", "if", "dropout_output_keep_prob", "is", "None", ":", "\n", "        ", "dropout_output_keep_prob", "=", "keep_prob", "\n", "\n", "", "cells", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "        ", "cell", "=", "None", "\n", "if", "cell_class", "==", "'RNN'", ":", "\n", "            ", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicRNNCell", "(", "num_units", "=", "num_units", ",", "reuse", "=", "reuse", ")", "\n", "", "elif", "cell_class", "==", "'GRU'", ":", "\n", "            ", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "GRUCell", "(", "num_units", "=", "num_units", ",", "reuse", "=", "reuse", ")", "\n", "", "elif", "cell_class", "==", "'LSTM'", ":", "\n", "            ", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "num_units", "=", "num_units", ",", "state_is_tuple", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "\n", "", "if", "keep_prob", "<", "1.0", ":", "\n", "            ", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "DropoutWrapper", "(", "cell", "=", "cell", ",", "\n", "input_keep_prob", "=", "dropout_input_keep_prob", ",", "\n", "output_keep_prob", "=", "dropout_output_keep_prob", ")", "\n", "", "cells", ".", "append", "(", "cell", ")", "\n", "\n", "", "if", "len", "(", "cells", ")", ">", "1", ":", "\n", "        ", "final_cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "core_rnn_cell", ".", "MultiRNNCell", "(", "cells", ",", "state_is_tuple", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "final_cell", "=", "cells", "[", "0", "]", "\n", "\n", "", "return", "final_cell", "\n", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.__init__": [[13, 79], ["utils.log_util.LogInfo.begin_track", "getattr", "kbqa_model.KbqaModel.input_tensor_definition", "utils.log_util.LogInfo.logs", "tensorflow.layers.Dropout", "utils.log_util.LogInfo.logs", "kbqa_model.KbqaModel.build_graph", "kbqa_model.KbqaModel.build_graph", "kbqa_model.KbqaModel.build_sent", "kbqa_model.KbqaModel.get_pair_loss", "tensorflow.reduce_mean", "kbqa_model.KbqaModel.build_update_summary", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.end_track", "tensorflow.variable_scope", "tensorflow.device", "utils.log_util.LogInfo.logs", "tensorflow.placeholder", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.get_variable"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.input_tensor_definition", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_graph", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_graph", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_sent", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.get_pair_loss", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_update_summary", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["    ", "def", "__init__", "(", "self", ",", "qw_max_len", ",", "pw_max_len", ",", "path_max_size", ",", "pseq_max_len", ",", "\n", "dim_emb", ",", "w_emb_fix", ",", "n_words", ",", "n_mids", ",", "n_paths", ",", "drop_rate", ",", "\n", "rnn_config", ",", "att_config", ",", "path_usage", ",", "sent_usage", ",", "seq_merge_mode", ",", "scoring_mode", ",", "\n", "final_func", ",", "loss_margin", ",", "optm_name", ",", "learning_rate", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Build KBQA Model:'", ")", "\n", "\n", "self", ".", "qw_max_len", "=", "qw_max_len", "\n", "self", ".", "pw_max_len", "=", "pw_max_len", "\n", "self", ".", "path_max_size", "=", "path_max_size", "\n", "self", ".", "pseq_max_len", "=", "pseq_max_len", "\n", "\n", "self", ".", "dim_emb", "=", "dim_emb", "\n", "self", ".", "path_usage", "=", "path_usage", "\n", "self", ".", "sent_usage", "=", "sent_usage", "\n", "self", ".", "seq_merge_mode", "=", "seq_merge_mode", "\n", "self", ".", "scoring_mode", "=", "scoring_mode", "\n", "self", ".", "final_func", "=", "final_func", "\n", "self", ".", "margin", "=", "loss_margin", "\n", "\n", "assert", "optm_name", "in", "(", "'Adam'", ",", "'Adadelta'", ",", "'Adagrad'", ",", "'GradientDescent'", ")", "\n", "self", ".", "optimizer", "=", "getattr", "(", "tf", ".", "train", ",", "optm_name", "+", "'Optimizer'", ")", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "\n", "if", "att_config", "[", "'att_func'", "]", "!=", "'noAtt'", ":", "\n", "            ", "self", ".", "att_config", "=", "att_config", "\n", "", "else", ":", "\n", "            ", "self", ".", "att_config", "=", "None", "\n", "\n", "", "self", ".", "rnn_config", "=", "rnn_config", "\n", "self", ".", "rnn_config", "[", "'reuse'", "]", "=", "tf", ".", "AUTO_REUSE", "\n", "self", ".", "dim_hidden", "=", "2", "*", "rnn_config", "[", "'num_units'", "]", "\n", "\n", "self", ".", "input_tensor_dict", "=", "self", ".", "input_tensor_definition", "(", "\n", "qw_max_len", "=", "self", ".", "qw_max_len", ",", "\n", "pw_max_len", "=", "self", ".", "pw_max_len", ",", "\n", "path_max_size", "=", "self", ".", "path_max_size", ",", "\n", "pseq_max_len", "=", "self", ".", "pseq_max_len", "\n", ")", "\n", "LogInfo", ".", "logs", "(", "'Global input tensors defined.'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'embedding_lookup'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "w_trainable", "=", "True", "if", "w_emb_fix", "==", "'Upd'", "else", "False", "\n", "LogInfo", ".", "logs", "(", "'Word embedding trainable: %s'", ",", "w_trainable", ")", "\n", "self", ".", "w_embedding_init", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "n_words", ",", "dim_emb", "]", ",", "'w_embedding_init'", ")", "\n", "self", ".", "w_embedding", "=", "tf", ".", "get_variable", "(", "name", "=", "'w_embedding'", ",", "initializer", "=", "self", ".", "w_embedding_init", ",", "\n", "trainable", "=", "w_trainable", ")", "\n", "self", ".", "m_embedding_init", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "n_mids", ",", "dim_emb", "]", ",", "'m_embedding_init'", ")", "\n", "self", ".", "m_embedding", "=", "tf", ".", "get_variable", "(", "name", "=", "'m_embedding'", ",", "initializer", "=", "self", ".", "m_embedding_init", ")", "\n", "self", ".", "p_embedding_init", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "n_paths", ",", "dim_emb", "]", ",", "'p_embedding_init'", ")", "\n", "self", ".", "p_embedding", "=", "tf", ".", "get_variable", "(", "name", "=", "'p_embedding'", ",", "initializer", "=", "self", ".", "p_embedding_init", ")", "\n", "", "", "self", ".", "dropout_layer", "=", "tf", ".", "layers", ".", "Dropout", "(", "drop_rate", ")", "\n", "LogInfo", ".", "logs", "(", "'Dropout: %.2f'", ",", "drop_rate", ")", "\n", "\n", "# Build the main graph for both optm and eval", "\n", "self", ".", "optm_tensor_dict", "=", "self", ".", "build_graph", "(", "mode_str", "=", "'optm'", ")", "\n", "self", ".", "eval_tensor_dict", "=", "self", ".", "build_graph", "(", "mode_str", "=", "'eval'", ")", "\n", "self", ".", "sent_tensor_dict", "=", "self", ".", "build_sent", "(", ")", "\n", "\n", "rm_weighted_loss", "=", "self", ".", "get_pair_loss", "(", "optm_score", "=", "self", ".", "optm_tensor_dict", "[", "'rm_score'", "]", ")", "\n", "self", ".", "rm_loss", "=", "tf", ".", "reduce_mean", "(", "rm_weighted_loss", ",", "name", "=", "'rm_loss'", ")", "\n", "self", ".", "rm_update", ",", "self", ".", "optm_rm_summary", "=", "self", ".", "build_update_summary", "(", ")", "\n", "LogInfo", ".", "logs", "(", "'Loss function: Hinge-%.1f'", ",", "self", ".", "margin", ")", "\n", "LogInfo", ".", "logs", "(", "'Loss & update defined.'", ")", "\n", "\n", "LogInfo", ".", "end_track", "(", "'End of Model'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.input_tensor_definition": [[80, 100], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "input_tensor_definition", "(", "qw_max_len", ",", "pw_max_len", ",", "path_max_size", ",", "pseq_max_len", ")", ":", "\n", "        ", "input_tensor_dict", "=", "{", "\n", "# Path input", "\n", "'path_size'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'path_size'", ")", ",", "\n", "'path_ids'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", "]", ",", "'path_ids'", ")", ",", "\n", "'pw_input'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", ",", "pw_max_len", "]", ",", "'pw_input'", ")", ",", "\n", "'pw_len'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", "]", ",", "'pw_len'", ")", ",", "\n", "'pseq_ids'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", ",", "pseq_max_len", "]", ",", "'pseq_ids'", ")", ",", "\n", "'pseq_len'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", "]", ",", "'pseq_len'", ")", ",", "\n", "\n", "# Sentential information", "\n", "'qw_input'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", ",", "qw_max_len", "]", ",", "'qw_input'", ")", ",", "\n", "'qw_len'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", "]", ",", "'qw_len'", ")", ",", "\n", "\n", "# Dependency information", "\n", "'dep_input'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", ",", "qw_max_len", "]", ",", "'dep_input'", ")", ",", "\n", "'dep_len'", ":", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", ",", "path_max_size", "]", ",", "'dep_len'", ")", "\n", "}", "\n", "return", "input_tensor_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_sent": [[101, 127], ["kbqa_model.KbqaModel.dropout_layer", "kbqa_model.KbqaModel.dropout_layer", "rnn_encoder.BidirectionalRNNEncoder.BidirectionalRNNEncoder", "tensorflow.device", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "kbqa_model.KbqaModel.build_question_repr", "kbqa_model.KbqaModel.build_question_repr", "kbqa_model.KbqaModel.build_sent_repr"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_question_repr", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_question_repr", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_sent_repr"], ["", "def", "build_sent", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "qw_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "w_embedding", ",", "\n", "ids", "=", "self", ".", "input_tensor_dict", "[", "'qw_input'", "]", ",", "\n", "name", "=", "'qw_emb'", ")", "# (ds, path_max_size, qw_max_len, dim_emb)", "\n", "dep_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "w_embedding", ",", "\n", "ids", "=", "self", ".", "input_tensor_dict", "[", "'dep_input'", "]", ",", "\n", "name", "=", "'dep_emb'", ")", "# (ds, path_max_size, qw_max_len, dim_emb)", "\n", "", "qw_len", "=", "self", ".", "input_tensor_dict", "[", "'qw_len'", "]", "\n", "dep_len", "=", "self", ".", "input_tensor_dict", "[", "'dep_len'", "]", "\n", "qw_emb", "=", "self", ".", "dropout_layer", "(", "qw_emb", ",", "training", "=", "False", ")", "\n", "dep_emb", "=", "self", ".", "dropout_layer", "(", "dep_emb", ",", "training", "=", "False", ")", "\n", "\n", "encoder_args", "=", "{", "'config'", ":", "self", ".", "rnn_config", ",", "'mode'", ":", "tf", ".", "contrib", ".", "learn", ".", "ModeKeys", ".", "INFER", "}", "\n", "rnn_encoder", "=", "BidirectionalRNNEncoder", "(", "**", "encoder_args", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'rm_task'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# Build question representation", "\n", "            ", "qw_repr", "=", "self", ".", "build_question_repr", "(", "seq_emb", "=", "qw_emb", ",", "seq_len", "=", "qw_len", ",", "path_repr", "=", "None", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "scope_name", "=", "'qw_repr'", ")", "\n", "dep_repr", "=", "self", ".", "build_question_repr", "(", "seq_emb", "=", "dep_emb", ",", "seq_len", "=", "dep_len", ",", "path_repr", "=", "None", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "scope_name", "=", "'dep_repr'", ")", "\n", "sent_repr", "=", "self", ".", "build_sent_repr", "(", "qw_repr", "=", "qw_repr", ",", "dep_repr", "=", "dep_repr", ")", "\n", "# Ready to return", "\n", "", "tensor_dict", "=", "{", "'sent_repr'", ":", "sent_repr", "}", "\n", "return", "tensor_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_graph": [[128, 187], ["utils.log_util.LogInfo.begin_track", "kbqa_model.KbqaModel.dropout_layer", "kbqa_model.KbqaModel.dropout_layer", "kbqa_model.KbqaModel.dropout_layer", "kbqa_model.KbqaModel.dropout_layer", "kbqa_model.KbqaModel.dropout_layer", "rnn_encoder.BidirectionalRNNEncoder.BidirectionalRNNEncoder", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.end_track", "tensorflow.device", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "kbqa_model.KbqaModel.build_path_repr", "kbqa_model.KbqaModel.build_question_repr", "kbqa_model.KbqaModel.build_question_repr", "kbqa_model.KbqaModel.build_sent_repr", "kbqa_model.KbqaModel.rm_forward", "len", "tensor_dict.keys"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_path_repr", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_question_repr", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_question_repr", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_sent_repr", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.rm_forward"], ["", "def", "build_graph", "(", "self", ",", "mode_str", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Build graph: [MT-%s]'", ",", "mode_str", ")", "\n", "mode", "=", "tf", ".", "contrib", ".", "learn", ".", "ModeKeys", ".", "INFER", "if", "mode_str", "==", "'eval'", "else", "tf", ".", "contrib", ".", "learn", ".", "ModeKeys", ".", "TRAIN", "\n", "training", "=", "False", "if", "mode_str", "==", "'eval'", "else", "True", "\n", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "qw_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "w_embedding", ",", "\n", "ids", "=", "self", ".", "input_tensor_dict", "[", "'qw_input'", "]", ",", "\n", "name", "=", "'qw_emb'", ")", "# (ds, path_max_size, qw_max_len, dim_emb)", "\n", "dep_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "w_embedding", ",", "\n", "ids", "=", "self", ".", "input_tensor_dict", "[", "'dep_input'", "]", ",", "\n", "name", "=", "'dep_emb'", ")", "# (ds, path_max_size, qw_max_len, dim_emb)", "\n", "pw_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "w_embedding", ",", "\n", "ids", "=", "self", ".", "input_tensor_dict", "[", "'pw_input'", "]", ",", "\n", "name", "=", "'pw_emb'", ")", "# (ds, path_max_size, pw_max_len, dim_emb)", "\n", "pseq_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "m_embedding", ",", "\n", "ids", "=", "self", ".", "input_tensor_dict", "[", "'pseq_ids'", "]", ",", "\n", "name", "=", "'pseq_emb'", ")", "# (ds, path_max_size, pseq_max_size, dim_emb)", "\n", "path_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "params", "=", "self", ".", "p_embedding", ",", "\n", "ids", "=", "self", ".", "input_tensor_dict", "[", "'path_ids'", "]", ",", "\n", "name", "=", "'path_emb'", ")", "# (ds, path_max_size, dim_emb)", "\n", "", "pw_len", "=", "self", ".", "input_tensor_dict", "[", "'pw_len'", "]", "\n", "pseq_len", "=", "self", ".", "input_tensor_dict", "[", "'pseq_len'", "]", "\n", "qw_len", "=", "self", ".", "input_tensor_dict", "[", "'qw_len'", "]", "\n", "dep_len", "=", "self", ".", "input_tensor_dict", "[", "'dep_len'", "]", "\n", "\n", "qw_emb", "=", "self", ".", "dropout_layer", "(", "qw_emb", ",", "training", "=", "training", ")", "\n", "dep_emb", "=", "self", ".", "dropout_layer", "(", "dep_emb", ",", "training", "=", "training", ")", "\n", "pw_emb", "=", "self", ".", "dropout_layer", "(", "pw_emb", ",", "training", "=", "training", ")", "\n", "pseq_emb", "=", "self", ".", "dropout_layer", "(", "pseq_emb", ",", "training", "=", "training", ")", "\n", "path_emb", "=", "self", ".", "dropout_layer", "(", "path_emb", ",", "training", "=", "training", ")", "\n", "\n", "encoder_args", "=", "{", "'config'", ":", "self", ".", "rnn_config", ",", "\n", "'mode'", ":", "mode", "}", "\n", "rnn_encoder", "=", "BidirectionalRNNEncoder", "(", "**", "encoder_args", ")", "\n", "\n", "# For RM kernel", "\n", "with", "tf", ".", "variable_scope", "(", "'rm_task'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# Build semantic component representation", "\n", "            ", "path_repr", "=", "self", ".", "build_path_repr", "(", "pw_emb", "=", "pw_emb", ",", "pw_len", "=", "pw_len", ",", "\n", "pseq_emb", "=", "pseq_emb", ",", "pseq_len", "=", "pseq_len", ",", "\n", "path_emb", "=", "path_emb", ",", "rnn_encoder", "=", "rnn_encoder", ")", "\n", "# Build question representation", "\n", "qw_repr", "=", "self", ".", "build_question_repr", "(", "seq_emb", "=", "qw_emb", ",", "seq_len", "=", "qw_len", ",", "path_repr", "=", "path_repr", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "scope_name", "=", "'qw_repr'", ")", "\n", "dep_repr", "=", "self", ".", "build_question_repr", "(", "seq_emb", "=", "dep_emb", ",", "seq_len", "=", "dep_len", ",", "path_repr", "=", "path_repr", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "scope_name", "=", "'dep_repr'", ")", "\n", "sent_repr", "=", "self", ".", "build_sent_repr", "(", "qw_repr", "=", "qw_repr", ",", "dep_repr", "=", "dep_repr", ")", "\n", "\n", "rm_final_feats", ",", "rm_score", "=", "self", ".", "rm_forward", "(", "path_repr", "=", "path_repr", ",", "sent_repr", "=", "sent_repr", ",", "\n", "path_size", "=", "self", ".", "input_tensor_dict", "[", "'path_size'", "]", ")", "\n", "\n", "# Ready to return", "\n", "", "tensor_dict", "=", "{", "'sent_repr'", ":", "sent_repr", ",", "\n", "'rm_score'", ":", "rm_score", ",", "\n", "'rm_final_feats'", ":", "rm_final_feats", "}", "\n", "LogInfo", ".", "logs", "(", "'%d tensors saved and return: %s'", ",", "len", "(", "tensor_dict", ")", ",", "tensor_dict", ".", "keys", "(", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "return", "tensor_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_path_repr": [[188, 218], ["utils.log_util.LogInfo.logs", "kbqa_model.KbqaModel._build_path_repr_pw_side", "kbqa_model.KbqaModel._build_path_repr_pseq_side", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel._build_path_repr_pw_side", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel._build_path_repr_pseq_side"], ["", "def", "build_path_repr", "(", "self", ",", "pw_emb", ",", "pw_len", ",", "path_emb", ",", "pseq_emb", ",", "pseq_len", ",", "rnn_encoder", ")", ":", "\n", "        ", "\"\"\"\n        :param pw_emb: (ds, path_max_size, pw_max_len, dim_emb)\n        :param pw_len: (ds, path_max_size)\n        :param path_emb: (ds, path_max_size, dim_emb)\n        :param pseq_emb: (ds, path_max_size, pseq_max_len, dim_emb)\n        :param pseq_len: (ds, path_max_size)\n        :param rnn_encoder:\n        \"\"\"", "\n", "LogInfo", ".", "logs", "(", "'build_path_repr: path_usage = [%s].'", ",", "self", ".", "path_usage", ")", "\n", "assert", "len", "(", "self", ".", "path_usage", ")", "==", "2", "\n", "# Word level representation", "\n", "pw_repr", "=", "self", ".", "_build_path_repr_pw_side", "(", "\n", "pw_emb", "=", "pw_emb", ",", "pw_len", "=", "pw_len", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "\n", "pw_usage", "=", "self", ".", "path_usage", "[", "0", "]", "\n", ")", "\n", "# Path level representation", "\n", "pseq_repr", "=", "self", ".", "_build_path_repr_pseq_side", "(", "\n", "path_emb", "=", "path_emb", ",", "pseq_emb", "=", "pseq_emb", ",", "pseq_len", "=", "pseq_len", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "pseq_usage", "=", "self", ".", "path_usage", "[", "1", "]", "\n", ")", "\n", "if", "pw_repr", "is", "None", ":", "\n", "            ", "assert", "pseq_repr", "is", "not", "None", "\n", "final_repr", "=", "pseq_repr", "\n", "", "elif", "pseq_repr", "is", "None", ":", "\n", "            ", "final_repr", "=", "pw_repr", "\n", "", "else", ":", "# summation", "\n", "            ", "final_repr", "=", "pw_repr", "+", "pseq_repr", "\n", "", "return", "final_repr", "# (ds, path_max_size, dim_emb or dim_hidden)", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel._build_path_repr_pw_side": [[219, 247], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.reshape", "kbqa_model.KbqaModel.show_tensor", "seq_helper.seq_hidden_averaging", "tensorflow.reshape", "seq_helper.seq_encoding_with_aggregation", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.show_tensor", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_averaging", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_encoding_with_aggregation"], ["", "def", "_build_path_repr_pw_side", "(", "self", ",", "pw_emb", ",", "pw_len", ",", "rnn_encoder", ",", "pw_usage", ")", ":", "\n", "        ", "\"\"\"\n        :param pw_emb: (ds, path_max_size, pw_max_len, dim_wd_emb)\n        :param pw_len: (ds, path_max_size)\n        :param rnn_encoder:\n        :param pw_usage: X,B,R (None / BOW / RNN)\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'pw_repr'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "pw_emb", "=", "tf", ".", "reshape", "(", "pw_emb", ",", "[", "-", "1", ",", "self", ".", "pw_max_len", ",", "self", ".", "dim_emb", "]", ")", "\n", "pw_len", "=", "tf", ".", "reshape", "(", "pw_len", ",", "[", "-", "1", "]", ")", "\n", "if", "pw_usage", "==", "'B'", ":", "\n", "                ", "pw_repr", "=", "seq_hidden_averaging", "(", "seq_hidden_input", "=", "pw_emb", ",", "len_input", "=", "pw_len", ")", "\n", "# (ds*path_max_size, dim_wd_emb), simply BOW", "\n", "pw_repr", "=", "tf", ".", "reshape", "(", "pw_repr", ",", "[", "-", "1", ",", "self", ".", "path_max_size", ",", "self", ".", "dim_emb", "]", ",", "'pw_repr'", ")", "\n", "", "elif", "pw_usage", "==", "'R'", ":", "\n", "                ", "pw_repr", "=", "seq_encoding_with_aggregation", "(", "\n", "emb_input", "=", "pw_emb", ",", "len_input", "=", "pw_len", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "\n", "seq_merge_mode", "=", "self", ".", "seq_merge_mode", "\n", ")", "# (ds*path_max_size, dim_hidden)", "\n", "pw_repr", "=", "tf", ".", "reshape", "(", "pw_repr", ",", "[", "-", "1", ",", "self", ".", "path_max_size", ",", "self", ".", "dim_hidden", "]", ",", "'pw_repr'", ")", "\n", "# (ds, path_max_size, dim_qw_hidden)", "\n", "", "else", ":", "\n", "                ", "assert", "pw_usage", "==", "'X'", "\n", "pw_repr", "=", "None", "\n", "", "", "if", "pw_repr", "is", "not", "None", ":", "\n", "            ", "self", ".", "show_tensor", "(", "pw_repr", ")", "\n", "", "return", "pw_repr", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel._build_path_repr_pseq_side": [[248, 279], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.reshape", "kbqa_model.KbqaModel.show_tensor", "seq_helper.seq_hidden_averaging", "tensorflow.reshape", "seq_helper.seq_encoding_with_aggregation", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.show_tensor", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_averaging", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_encoding_with_aggregation"], ["", "def", "_build_path_repr_pseq_side", "(", "self", ",", "path_emb", ",", "pseq_emb", ",", "pseq_len", ",", "rnn_encoder", ",", "pseq_usage", ")", ":", "\n", "        ", "\"\"\"\n        :param path_emb: (ds, path_max_size, dim_emb)\n        :param pseq_emb: (ds, path_max_size, pseq_max_len, dim_emb)\n        :param pseq_len: (ds, path_max_size)\n        :param rnn_encoder:\n        :param pseq_usage: X,B,R,H (None / BOW / RNN / wHole)\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'pseq_repr'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "pseq_emb", "=", "tf", ".", "reshape", "(", "pseq_emb", ",", "[", "-", "1", ",", "self", ".", "pseq_max_len", ",", "self", ".", "dim_emb", "]", ")", "\n", "pseq_len", "=", "tf", ".", "reshape", "(", "pseq_len", ",", "[", "-", "1", "]", ")", "\n", "if", "pseq_usage", "==", "'H'", ":", "\n", "                ", "pseq_repr", "=", "path_emb", "# (ds, path_max_size, dim_emb)", "\n", "", "elif", "pseq_usage", "==", "'B'", ":", "\n", "                ", "pseq_repr", "=", "seq_hidden_averaging", "(", "seq_hidden_input", "=", "pseq_emb", ",", "len_input", "=", "pseq_len", ")", "\n", "pseq_repr", "=", "tf", ".", "reshape", "(", "pseq_repr", ",", "[", "-", "1", ",", "self", ".", "path_max_size", ",", "self", ".", "dim_emb", "]", ",", "'pseq_repr'", ")", "\n", "# (ds, path_max_size, dim_wd_emb)", "\n", "", "elif", "pseq_usage", "==", "'R'", ":", "\n", "                ", "pseq_repr", "=", "seq_encoding_with_aggregation", "(", "\n", "emb_input", "=", "pseq_emb", ",", "len_input", "=", "pseq_len", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "\n", "seq_merge_mode", "=", "self", ".", "seq_merge_mode", "\n", ")", "# (ds*path_max_size, dim_hidden)", "\n", "pseq_repr", "=", "tf", ".", "reshape", "(", "pseq_repr", ",", "[", "-", "1", ",", "self", ".", "path_max_size", ",", "self", ".", "dim_hidden", "]", ",", "'pseq_repr'", ")", "\n", "# (ds, path_max_size, dim_hidden)", "\n", "", "else", ":", "\n", "                ", "assert", "pseq_usage", "==", "'X'", "\n", "pseq_repr", "=", "None", "\n", "", "", "if", "pseq_repr", "is", "not", "None", ":", "\n", "            ", "self", ".", "show_tensor", "(", "pseq_repr", ")", "\n", "", "return", "pseq_repr", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_question_repr": [[280, 319], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.reshape", "utils.log_util.LogInfo.logs", "seq_helper.seq_encoding", "tensorflow.sequence_mask", "attention.Attention", "attention.Attention.forward", "utils.log_util.LogInfo.logs", "seq_helper.seq_encoding_with_aggregation", "tensorflow.reshape.get_shape().as_list", "tensorflow.reshape.get_shape"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_encoding", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.Attention.forward", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_encoding_with_aggregation"], ["", "def", "build_question_repr", "(", "self", ",", "seq_emb", ",", "seq_len", ",", "path_repr", ",", "rnn_encoder", ",", "scope_name", ")", ":", "\n", "        ", "\"\"\"\n        :param seq_emb: (ds, path_max_size, qw_max_len, dim_wd_emb)\n        :param seq_len: (ds, path_max_size)\n        :param path_repr: (ds, path_max_size, dim_path_hidden)\n        :param rnn_encoder: RNN encoder (could be None)\n        :param scope_name: variable_scope name\n        \"\"\"", "\n", "seq_emb", "=", "tf", ".", "reshape", "(", "seq_emb", ",", "[", "-", "1", ",", "self", ".", "qw_max_len", ",", "self", ".", "dim_emb", "]", ")", "\n", "seq_len", "=", "tf", ".", "reshape", "(", "seq_len", ",", "[", "-", "1", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope_name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "if", "self", ".", "att_config", "is", "not", "None", ":", "\n", "                ", "dim_att_hidden", "=", "self", ".", "att_config", "[", "'dim_att_hidden'", "]", "\n", "att_func", "=", "self", ".", "att_config", "[", "'att_func'", "]", "\n", "dim_path_hidden", "=", "path_repr", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "path_repr", "=", "tf", ".", "reshape", "(", "path_repr", ",", "[", "-", "1", ",", "dim_path_hidden", "]", ")", "\n", "LogInfo", ".", "logs", "(", "'build_seq_repr: att_func = [%s].'", ",", "att_func", ")", "\n", "\n", "seq_hidden", "=", "seq_encoding", "(", "emb_input", "=", "seq_emb", ",", "len_input", "=", "seq_len", ",", "encoder", "=", "rnn_encoder", ")", "\n", "# (ds*path_max_size, qw_max_len, dim_hidden)", "\n", "seq_mask", "=", "tf", ".", "sequence_mask", "(", "lengths", "=", "seq_len", ",", "\n", "maxlen", "=", "self", ".", "qw_max_len", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "name", "=", "'seq_mask'", ")", "# (ds*path_max_size, qw_max_len)", "\n", "simple_att", "=", "Attention", "(", "lf_max_len", "=", "self", ".", "qw_max_len", ",", "\n", "dim_att_hidden", "=", "dim_att_hidden", ",", "\n", "att_func", "=", "att_func", ")", "\n", "seq_att_rep", ",", "att_mat", ",", "seq_weight", "=", "simple_att", ".", "forward", "(", "lf_input", "=", "seq_hidden", ",", "\n", "lf_mask", "=", "seq_mask", ",", "\n", "fix_rt_input", "=", "path_repr", ")", "\n", "seq_repr", "=", "seq_att_rep", "\n", "", "else", ":", "# no attention, similar with above", "\n", "                ", "LogInfo", ".", "logs", "(", "'build_seq_repr: att_func = [noAtt], seq_merge_mode = [%s].'", ",", "self", ".", "seq_merge_mode", ")", "\n", "seq_repr", "=", "seq_encoding_with_aggregation", "(", "emb_input", "=", "seq_emb", ",", "len_input", "=", "seq_len", ",", "\n", "rnn_encoder", "=", "rnn_encoder", ",", "\n", "seq_merge_mode", "=", "self", ".", "seq_merge_mode", ")", "\n", "", "seq_repr", "=", "tf", ".", "reshape", "(", "seq_repr", ",", "[", "-", "1", ",", "self", ".", "path_max_size", ",", "self", ".", "dim_hidden", "]", ",", "'seq_repr'", ")", "\n", "", "return", "seq_repr", "# (ds, path_max_size, dim_hidden)", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_sent_repr": [[320, 345], ["utils.log_util.LogInfo.logs", "tensorflow.add", "tensorflow.reduce_max", "tensorflow.concat", "tensorflow.contrib.layers.fully_connected", "tensorflow.stack"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "build_sent_repr", "(", "self", ",", "qw_repr", ",", "dep_repr", ")", ":", "\n", "        ", "\"\"\"\n        :param qw_repr:   (ds, path_max_len, dim_hidden)\n        :param dep_repr:  (ds, path_max_len, dim_hidden)\n        \"\"\"", "\n", "LogInfo", ".", "logs", "(", "'build_sent_repr: sent_usage = [%s].'", ",", "self", ".", "sent_usage", ")", "\n", "if", "self", ".", "sent_usage", "==", "'qwOnly'", ":", "\n", "            ", "sent_repr", "=", "qw_repr", "\n", "", "elif", "self", ".", "sent_usage", "==", "'depOnly'", ":", "\n", "            ", "sent_repr", "=", "dep_repr", "\n", "", "elif", "self", ".", "sent_usage", "==", "'mSum'", ":", "# merge by summation", "\n", "            ", "sent_repr", "=", "tf", ".", "add", "(", "qw_repr", ",", "dep_repr", ")", "\n", "", "elif", "self", ".", "sent_usage", "==", "'mMax'", ":", "# merge by max pooling", "\n", "            ", "sent_repr", "=", "tf", ".", "reduce_max", "(", "tf", ".", "stack", "(", "[", "qw_repr", ",", "dep_repr", "]", ",", "axis", "=", "0", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "concat_repr", "=", "tf", ".", "concat", "(", "[", "qw_repr", ",", "dep_repr", "]", ",", "axis", "=", "-", "1", ",", "name", "=", "'concat_repr'", ")", "\n", "# (ds, path_max_len, 2*dim_hidden)", "\n", "sent_repr", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "\n", "inputs", "=", "concat_repr", ",", "\n", "num_outputs", "=", "self", ".", "dim_hidden", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "scope", "=", "'mFC'", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "# (ds, path_max_len, dim_hidden)", "\n", "", "return", "sent_repr", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.rm_forward": [[346, 414], ["utils.log_util.LogInfo.logs", "tensorflow.variable_scope", "tensorflow.reshape.get_shape().as_list", "seq_helper.seq_hidden_max_pooling", "seq_helper.seq_hidden_max_pooling", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.expand_dims", "seq_helper.cosine_sim", "tensorflow.reshape.get_shape", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.reduce_sum", "kbqa_model.KbqaModel.final_func.startswith", "int", "tensorflow.concat", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected", "tensorflow.squeeze", "tensorflow.contrib.layers.xavier_initializer"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_max_pooling", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_max_pooling", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.cosine_sim"], ["", "def", "rm_forward", "(", "self", ",", "path_repr", ",", "sent_repr", ",", "path_size", ")", ":", "\n", "        ", "\"\"\"\n        Kernel part of rm_forward.\n        :param path_repr: (ds, path_max_len, dim_path_hidden)\n        :param sent_repr: (ds, path_max_len, dim_hidden)\n        :param path_size: (ds, )\n        \"\"\"", "\n", "LogInfo", ".", "logs", "(", "'rm_forward: scoring_mode = [%s], final_func = [%s].'", ",", "self", ".", "scoring_mode", ",", "self", ".", "final_func", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'rm_forward'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "dim_path_hidden", "=", "path_repr", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "assert", "self", ".", "scoring_mode", "in", "(", "'separated'", ",", "'compact'", ")", "\n", "if", "self", ".", "scoring_mode", "==", "'compact'", ":", "\n", "                ", "sent_repr", "=", "seq_hidden_max_pooling", "(", "seq_hidden_input", "=", "sent_repr", ",", "len_input", "=", "path_size", ")", "\n", "path_repr", "=", "seq_hidden_max_pooling", "(", "seq_hidden_input", "=", "path_repr", ",", "len_input", "=", "path_size", ")", "\n", "# (ds, dim_xx_hidden)", "\n", "", "else", ":", "\n", "                ", "sent_repr", "=", "tf", ".", "reshape", "(", "sent_repr", ",", "[", "-", "1", ",", "self", ".", "dim_hidden", "]", ")", "\n", "path_repr", "=", "tf", ".", "reshape", "(", "path_repr", ",", "[", "-", "1", ",", "dim_path_hidden", "]", ")", "\n", "# (ds*path_max_size, dim_xx_hidden)", "\n", "\n", "# Apply final scoring functions", "\n", "", "if", "self", ".", "final_func", "==", "'dot'", ":", "\n", "                ", "assert", "dim_path_hidden", "==", "self", ".", "dim_hidden", "\n", "merge_score", "=", "tf", ".", "reduce_sum", "(", "sent_repr", "*", "path_repr", ",", "axis", "=", "-", "1", ",", "name", "=", "'merge_score'", ")", "\n", "", "elif", "self", ".", "final_func", "==", "'cos'", ":", "\n", "                ", "assert", "dim_path_hidden", "==", "self", ".", "dim_hidden", "\n", "merge_score", "=", "cosine_sim", "(", "lf_input", "=", "sent_repr", ",", "rt_input", "=", "path_repr", ")", "\n", "", "elif", "self", ".", "final_func", "==", "'bilinear'", ":", "\n", "                ", "bilinear_mat", "=", "tf", ".", "get_variable", "(", "name", "=", "'bilinear_mat'", ",", "\n", "shape", "=", "[", "dim_path_hidden", ",", "self", ".", "dim_hidden", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ")", "\n", "proj_repr", "=", "tf", ".", "matmul", "(", "path_repr", ",", "bilinear_mat", ",", "name", "=", "'proj_repr'", ")", "\n", "merge_score", "=", "tf", ".", "reduce_sum", "(", "sent_repr", "*", "proj_repr", ",", "axis", "=", "-", "1", ",", "name", "=", "'merge_score'", ")", "\n", "", "else", ":", "\n", "                ", "assert", "self", ".", "final_func", ".", "startswith", "(", "'fc'", ")", "\n", "hidden_size", "=", "int", "(", "self", ".", "final_func", "[", "2", ":", "]", ")", "\n", "concat_repr", "=", "tf", ".", "concat", "(", "[", "sent_repr", ",", "path_repr", "]", ",", "axis", "=", "-", "1", ",", "name", "=", "'concat_repr'", ")", "\n", "concat_hidden", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "\n", "inputs", "=", "concat_repr", ",", "\n", "num_outputs", "=", "hidden_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "scope", "=", "'fc1'", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "# (ds / ds*path_max_len, 32)", "\n", "merge_score", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "\n", "inputs", "=", "concat_hidden", ",", "\n", "num_outputs", "=", "1", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'fc2'", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "# (ds / ds*path_max_len, 1)", "\n", "merge_score", "=", "tf", ".", "squeeze", "(", "merge_score", ",", "axis", "=", "-", "1", ",", "name", "=", "'merge_score'", ")", "\n", "\n", "", "if", "self", ".", "scoring_mode", "==", "'compact'", ":", "\n", "                ", "rm_score", "=", "merge_score", "\n", "rm_final_feats", "=", "tf", ".", "expand_dims", "(", "rm_score", ",", "-", "1", ",", "'rm_final_feats'", ")", "# (ds, 1)", "\n", "", "else", ":", "\n", "                ", "merge_score", "=", "tf", ".", "reshape", "(", "merge_score", ",", "[", "-", "1", ",", "self", ".", "path_max_size", "]", ")", "# (ds, path_max_size)", "\n", "path_mask", "=", "tf", ".", "sequence_mask", "(", "\n", "lengths", "=", "path_size", ",", "maxlen", "=", "self", ".", "path_max_size", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'path_mask'", "\n", ")", "# (ds, path_max_size) as mask", "\n", "rm_score", "=", "tf", ".", "reduce_sum", "(", "merge_score", "*", "path_mask", ",", "axis", "=", "-", "1", ",", "name", "=", "'rm_score'", ")", "# (ds, )", "\n", "rm_final_feats", "=", "tf", ".", "expand_dims", "(", "rm_score", ",", "-", "1", ",", "'rm_final_feats'", ")", "# (ds, 1)", "\n", "\n", "", "", "return", "rm_final_feats", ",", "rm_score", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.get_pair_loss": [[415, 423], ["tensorflow.unstack", "tensorflow.nn.relu", "tensorflow.reshape"], "methods", ["None"], ["", "def", "get_pair_loss", "(", "self", ",", "optm_score", ")", ":", "\n", "        ", "\"\"\"\n        :param optm_score:  (ds, )\n        in TRAIN mode, we put positive and negative cases together into one tensor\n        \"\"\"", "\n", "pos_score", ",", "neg_score", "=", "tf", ".", "unstack", "(", "tf", ".", "reshape", "(", "optm_score", ",", "shape", "=", "[", "-", "1", ",", "2", "]", ")", ",", "axis", "=", "1", ")", "\n", "margin_loss", "=", "tf", ".", "nn", ".", "relu", "(", "neg_score", "+", "self", ".", "margin", "-", "pos_score", ",", "name", "=", "'margin_loss'", ")", "\n", "return", "margin_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.build_update_summary": [[424, 435], ["getattr", "tensorflow.summary.scalar", "tensorflow.summary.merge_all", "getattr", "kbqa_model.KbqaModel.optimizer().minimize", "kbqa_model.KbqaModel.optimizer().minimize", "kbqa_model.KbqaModel.optimizer", "kbqa_model.KbqaModel.optimizer"], "methods", ["None"], ["", "def", "build_update_summary", "(", "self", ",", "spec_var_list", "=", "None", ")", ":", "\n", "        ", "collection_name", "=", "'optm_rm'", "\n", "loss_name", "=", "'rm_loss'", "\n", "task_loss", "=", "getattr", "(", "self", ",", "loss_name", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "loss_name", ",", "getattr", "(", "self", ",", "loss_name", ")", ",", "collections", "=", "[", "collection_name", "]", ")", "\n", "if", "spec_var_list", "is", "None", ":", "\n", "            ", "update_step", "=", "self", ".", "optimizer", "(", "self", ".", "learning_rate", ")", ".", "minimize", "(", "task_loss", ")", "\n", "", "else", ":", "\n", "            ", "update_step", "=", "self", ".", "optimizer", "(", "self", ".", "learning_rate", ")", ".", "minimize", "(", "task_loss", ",", "var_list", "=", "spec_var_list", ")", "\n", "", "optm_summary", "=", "tf", ".", "summary", ".", "merge_all", "(", "collection_name", ")", "\n", "return", "update_step", ",", "optm_summary", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.show_tensor": [[436, 439], ["utils.log_util.LogInfo.logs", "tensor.get_shape().as_list", "str", "tensor.get_shape"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "show_tensor", "(", "self", ",", "tensor", ",", "name", "=", "None", ")", ":", "\n", "        ", "show_name", "=", "name", "or", "tensor", ".", "name", "\n", "LogInfo", ".", "logs", "(", "'* %s --> %s | %s'", ",", "show_name", ",", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "str", "(", "tensor", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.train_batch": [[440, 456], ["sess.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "train_batch", "(", "self", ",", "sess", ",", "data", ")", ":", "\n", "        ", "input_feed", "=", "{", "\n", "self", ".", "input_tensor_dict", "[", "'path_size'", "]", ":", "data", "[", "'path_size'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'path_ids'", "]", ":", "data", "[", "'path_ids'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pw_input'", "]", ":", "data", "[", "'pw_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pw_len'", "]", ":", "data", "[", "'pw_len'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pseq_ids'", "]", ":", "data", "[", "'pseq_ids'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pseq_len'", "]", ":", "data", "[", "'pseq_len'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'qw_input'", "]", ":", "data", "[", "'qw_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'qw_len'", "]", ":", "data", "[", "'qw_len'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'dep_input'", "]", ":", "data", "[", "'dep_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'dep_len'", "]", ":", "data", "[", "'dep_len'", "]", "\n", "}", "\n", "output_feed", "=", "[", "self", ".", "rm_update", ",", "self", ".", "rm_loss", ",", "self", ".", "optm_rm_summary", "]", "\n", "outputs", "=", "sess", ".", "run", "(", "output_feed", ",", "feed_dict", "=", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", ",", "outputs", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.eval_batch": [[457, 474], ["sess.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "eval_batch", "(", "self", ",", "sess", ",", "data", ")", ":", "\n", "        ", "input_feed", "=", "{", "\n", "self", ".", "input_tensor_dict", "[", "'path_size'", "]", ":", "data", "[", "'path_size'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'path_ids'", "]", ":", "data", "[", "'path_ids'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pw_input'", "]", ":", "data", "[", "'pw_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pw_len'", "]", ":", "data", "[", "'pw_len'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pseq_ids'", "]", ":", "data", "[", "'pseq_ids'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'pseq_len'", "]", ":", "data", "[", "'pseq_len'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'qw_input'", "]", ":", "data", "[", "'qw_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'qw_len'", "]", ":", "data", "[", "'qw_len'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'dep_input'", "]", ":", "data", "[", "'dep_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'dep_len'", "]", ":", "data", "[", "'dep_len'", "]", "\n", "}", "\n", "output_feed", "=", "[", "self", ".", "eval_tensor_dict", "[", "'rm_score'", "]", ",", "\n", "self", ".", "eval_tensor_dict", "[", "'rm_final_feats'", "]", "]", "\n", "outputs", "=", "sess", ".", "run", "(", "output_feed", ",", "feed_dict", "=", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.kbqa_model.KbqaModel.transfer_encode": [[475, 485], ["sess.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "transfer_encode", "(", "self", ",", "sess", ",", "data", ")", ":", "\n", "        ", "input_feed", "=", "{", "\n", "self", ".", "input_tensor_dict", "[", "'qw_input'", "]", ":", "data", "[", "'qw_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'qw_len'", "]", ":", "data", "[", "'qw_len'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'dep_input'", "]", ":", "data", "[", "'dep_input'", "]", ",", "\n", "self", ".", "input_tensor_dict", "[", "'dep_len'", "]", ":", "data", "[", "'dep_len'", "]", "\n", "}", "\n", "output_feed", "=", "[", "self", ".", "sent_tensor_dict", "[", "'sent_repr'", "]", "]", "\n", "outputs", "=", "sess", ".", "run", "(", "output_feed", ",", "feed_dict", "=", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.Attention.__init__": [[11, 19], ["utils.log_util.LogInfo.logs"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["def", "__init__", "(", "self", ",", "lf_max_len", ",", "dim_att_hidden", ",", "att_func", ")", ":", "\n", "        ", "self", ".", "lf_max_len", "=", "lf_max_len", "\n", "self", ".", "dim_att_hidden", "=", "dim_att_hidden", "\n", "LogInfo", ".", "logs", "(", "'Attention: lf_max_len = %d, dim_att_hidden = %d, att_func = %s.'", ",", "\n", "lf_max_len", ",", "dim_att_hidden", ",", "att_func", ")", "\n", "\n", "assert", "att_func", "in", "(", "'dot'", ",", "'bilinear'", ",", "'bahdanau'", ",", "'bdot'", ")", "\n", "self", ".", "att_func", "=", "'attn_%s'", "%", "att_func", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.Attention.forward": [[20, 41], ["tensorflow.expand_dims", "tensorflow.variable_scope", "attention.Attention.att_func", "tensorflow.reshape", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.expand_dims"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "lf_input", ",", "lf_mask", ",", "fix_rt_input", ")", ":", "\n", "        ", "\"\"\"\n        :param lf_input:        (ds, lf_max_len, dim_hidden)\n        :param lf_mask:         (ds, lf_max_len) as float32\n        :param fix_rt_input:    (ds, dim_hidden), no timestamps\n        \"\"\"", "\n", "rt_input", "=", "tf", ".", "expand_dims", "(", "fix_rt_input", ",", "axis", "=", "1", ",", "name", "=", "'rt_input'", ")", "# (ds, 1, dim_hidden)", "\n", "with", "tf", ".", "variable_scope", "(", "'simple_att'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "raw_att_mat", "=", "self", ".", "att_func", "(", "lf_input", "=", "lf_input", ",", "rt_input", "=", "rt_input", ",", "\n", "lf_max_len", "=", "self", ".", "lf_max_len", ",", "rt_max_len", "=", "1", ",", "\n", "dim_att_hidden", "=", "self", ".", "dim_att_hidden", ")", "# (ds, lf_max_len, 1)", "\n", "raw_att_mat", "=", "tf", ".", "reshape", "(", "raw_att_mat", ",", "shape", "=", "[", "-", "1", ",", "self", ".", "lf_max_len", "]", ",", "name", "=", "'raw_att_mat'", ")", "\n", "# (ds, lf_max_len)", "\n", "\n", "masked_att_mat", "=", "raw_att_mat", "*", "lf_mask", "+", "tf", ".", "float32", ".", "min", "*", "(", "1.", "-", "lf_mask", ")", "\n", "lf_norm", "=", "tf", ".", "nn", ".", "softmax", "(", "masked_att_mat", ",", "name", "=", "'lf_norm'", ")", "# (ds, lf_max_len)", "\n", "lf_weighted", "=", "tf", ".", "expand_dims", "(", "lf_norm", ",", "axis", "=", "2", ")", "*", "lf_input", "# (ds, lf_max_len, dim_hidden)", "\n", "lf_weighted", "=", "tf", ".", "reduce_sum", "(", "lf_weighted", ",", "axis", "=", "1", ",", "\n", "name", "=", "'lf_weighted'", ")", "# (ds, dim_hidden)", "\n", "\n", "", "return", "lf_weighted", ",", "raw_att_mat", ",", "lf_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.expand_both_dims": [[43, 53], ["tensorflow.stack", "tensorflow.stack"], "function", ["None"], ["", "", "def", "expand_both_dims", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ")", ":", "\n", "    ", "\"\"\"\n    lf_input:   (ds, lf_max_len, dim_emb)\n    rt_input:   (ds, rt_max_len, dim_emb)\n    \"\"\"", "\n", "expand_lf_input", "=", "tf", ".", "stack", "(", "[", "lf_input", "]", "*", "rt_max_len", ",", "axis", "=", "2", ",", "\n", "name", "=", "'expand_lf_input'", ")", "# (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "expand_rt_input", "=", "tf", ".", "stack", "(", "[", "rt_input", "]", "*", "lf_max_len", ",", "axis", "=", "1", ",", "\n", "name", "=", "'expand_rt_input'", ")", "# (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "return", "expand_lf_input", ",", "expand_rt_input", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.attn_dot": [[55, 68], ["attention.expand_both_dims", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.expand_both_dims"], ["", "def", "attn_dot", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ",", "dim_att_hidden", ")", ":", "\n", "    ", "\"\"\"\n    bilinear: a = x_1 . x_2\n    dim_att_hidden is never used in the function.\n    \"\"\"", "\n", "assert", "dim_att_hidden", "is", "not", "None", "\n", "expand_lf_input", ",", "expand_rt_input", "=", "expand_both_dims", "(", "\n", "lf_input", "=", "lf_input", ",", "rt_input", "=", "rt_input", ",", "\n", "lf_max_len", "=", "lf_max_len", ",", "rt_max_len", "=", "rt_max_len", "\n", ")", "# both (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "att_mat", "=", "tf", ".", "reduce_sum", "(", "expand_lf_input", "*", "expand_rt_input", ",", "axis", "=", "-", "1", ",", "\n", "name", "=", "'att_mat'", ")", "# (ds, lf_max_len, rt_max_len)", "\n", "return", "att_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.attn_bilinear": [[70, 90], ["attention.expand_both_dims", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.expand_both_dims"], ["", "def", "attn_bilinear", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ",", "dim_att_hidden", ")", ":", "\n", "    ", "\"\"\"\n    bilinear: a = x_1 . W . x_2\n    dim_att_hidden should be equal with dim_hidden,\n    otherwise, matmul couldn't work properly\n    \"\"\"", "\n", "expand_lf_input", ",", "expand_rt_input", "=", "expand_both_dims", "(", "\n", "lf_input", "=", "lf_input", ",", "rt_input", "=", "rt_input", ",", "\n", "lf_max_len", "=", "lf_max_len", ",", "rt_max_len", "=", "rt_max_len", "\n", ")", "# both (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "with", "tf", ".", "variable_scope", "(", "'cross_att_bilinear'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "name", "=", "'w'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "dim_att_hidden", ",", "dim_att_hidden", "]", ")", "\n", "att_mat", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "multiply", "(", "\n", "x", "=", "tf", ".", "matmul", "(", "expand_lf_input", ",", "w", ")", ",", "\n", "y", "=", "expand_rt_input", "# both (ds, lf_max_len, rt_max_len, dim_att_hidden==dim_emb)", "\n", ")", ",", "axis", "=", "-", "1", ",", "name", "=", "'att_mat'", "\n", ")", "# (ds, lf_max_len, rt_max_len)", "\n", "", "return", "att_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.attn_bahdanau": [[92, 123], ["tensorflow.variable_scope", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected", "attention.expand_both_dims", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.expand_both_dims"], ["", "def", "attn_bahdanau", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ",", "dim_att_hidden", ")", ":", "\n", "    ", "\"\"\"\n    A = u . relu(W[x_1 : x_2] + b), or understand as:\n    A1 = W_1 . x_1\n    A2 = W_2 . x_2\n    A = u . relu(A1 + A2 + b)\n    :param lf_input: (ds, lf_max_len, dim_hidden)\n    :param rt_input: (ds, rt_max_len, dim_hidden)\n    :param lf_max_len: int value\n    :param rt_max_len: int value\n    :param dim_att_hidden: the hidden dimension in the attention operation\n    :return: (ds, lf_max_len, rt_max_len)\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'cross_att_bahdanau'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "lf_att", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "inputs", "=", "lf_input", ",", "\n", "num_outputs", "=", "dim_att_hidden", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'fc_lf'", ")", "# (ds, lf_max_len, dim_att_hidden)", "\n", "rt_att", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "inputs", "=", "rt_input", ",", "\n", "num_outputs", "=", "dim_att_hidden", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'fc_rt'", ")", "# (ds, rt_max_len, dim_att_hidden)", "\n", "expand_lf_att", ",", "expand_rt_att", "=", "expand_both_dims", "(", "\n", "lf_input", "=", "lf_att", ",", "rt_input", "=", "rt_att", ",", "\n", "lf_max_len", "=", "lf_max_len", ",", "rt_max_len", "=", "rt_max_len", "\n", ")", "# both (ds, lf_max_len, rt_max_len, dim_att_hidden)", "\n", "u", "=", "tf", ".", "get_variable", "(", "name", "=", "'u'", ",", "shape", "=", "[", "dim_att_hidden", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "name", "=", "'b'", ",", "shape", "=", "[", "dim_att_hidden", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "activate", "=", "tf", ".", "nn", ".", "relu", "(", "expand_lf_att", "+", "expand_rt_att", "+", "b", ")", "\n", "att_mat", "=", "tf", ".", "reduce_sum", "(", "activate", "*", "u", ",", "axis", "=", "-", "1", ",", "name", "=", "'att_mat'", ")", "# (ds, lf_max_len, rt_max_len)", "\n", "", "return", "att_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.attn_bdot": [[125, 146], ["attention.expand_both_dims", "tensorflow.reduce_sum", "tensorflow.variable_scope", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.expand_both_dims"], ["", "def", "attn_bdot", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ",", "dim_att_hidden", ")", ":", "\n", "    ", "\"\"\"\n    bahdanau-dot: t_i = relu(Wx_i + b), a = t_1 . t_2\n    Check AF-attention paper, formula (1)\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'cross_att_bahdanau_dot'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "lf_att", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "inputs", "=", "lf_input", ",", "\n", "num_outputs", "=", "dim_att_hidden", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "scope", "=", "'fc_lf'", ")", "# (ds, lf_max_len, dim_att_hidden)", "\n", "rt_att", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "inputs", "=", "rt_input", ",", "\n", "num_outputs", "=", "dim_att_hidden", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "scope", "=", "'fc_rt'", ")", "# (ds, rt_max_len, dim_att_hidden)", "\n", "", "expand_lf_att", ",", "expand_rt_att", "=", "expand_both_dims", "(", "\n", "lf_input", "=", "lf_att", ",", "rt_input", "=", "rt_att", ",", "\n", "lf_max_len", "=", "lf_max_len", ",", "rt_max_len", "=", "rt_max_len", "\n", ")", "# both (ds, lf_max_len, rt_max_len, dim_att_hidden)", "\n", "att_mat", "=", "tf", ".", "reduce_sum", "(", "expand_lf_att", "*", "expand_rt_att", ",", "axis", "=", "-", "1", ",", "\n", "name", "=", "'att_mat'", ")", "# (ds, lf_max_len, rt_max_len)", "\n", "return", "att_mat", "\n", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_encoding": [[8, 30], ["tensorflow.unstack", "encoder.encode", "tensorflow.stack", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.rnn_encoder.BidirectionalRNNEncoder.encode"], ["def", "seq_encoding", "(", "emb_input", ",", "len_input", ",", "encoder", ",", "fwbw", "=", "False", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "    ", "\"\"\"\n    Just a small wrapper: given the embedding input, length input and encoder, return the encoded result\n    :param emb_input: (data_size, stamps, dim_emb)\n    :param len_input: (data_size, ) as int32\n    :param encoder: the BidirectionalRNNEncoder instance\n    :param fwbw: only use the concat of last fw & bw state\n    :param reuse: reuse flag (used in generating RNN/GRU/LSTM- Cell)\n    :return: (data_size, stamps, dim_hidden)\n    \"\"\"", "\n", "if", "encoder", "is", "None", ":", "\n", "        ", "return", "emb_input", "# just use word embedding, without other operations", "\n", "", "rnn_input", "=", "tf", ".", "unstack", "(", "emb_input", ",", "axis", "=", "1", ",", "name", "=", "'emb_input'", ")", "# stamp * (data_size, dim_emb)", "\n", "encoder_output", "=", "encoder", ".", "encode", "(", "inputs", "=", "rnn_input", ",", "\n", "sequence_length", "=", "len_input", ",", "\n", "reuse", "=", "reuse", ")", "\n", "if", "not", "fwbw", ":", "\n", "        ", "out_hidden", "=", "tf", ".", "stack", "(", "encoder_output", ".", "outputs", ",", "axis", "=", "1", ",", "name", "=", "'out_hidden'", ")", "# (data_size, stamp, dim_hidden)", "\n", "return", "out_hidden", "\n", "", "else", ":", "\n", "        ", "out_hidden", "=", "tf", ".", "concat", "(", "encoder_output", ".", "final_state", ",", "axis", "=", "-", "1", ",", "name", "=", "'out_hidden'", ")", "# (data_size, dim_hidden)", "\n", "return", "out_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.schema_encoding": [[32, 55], ["seq_helper.seq_hidden_masking_before_pooling", "seq_helper.seq_hidden_masking_before_pooling", "tensorflow.concat", "tensorflow.reduce_max"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking_before_pooling", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking_before_pooling"], ["", "", "def", "schema_encoding", "(", "preds_hidden", ",", "preds_len", ",", "pwords_hidden", ",", "pwords_len", ")", ":", "\n", "    ", "\"\"\"\n    Given the pred-/pword- sequence embedding after Bidirectional RNN layer,\n    return the final representation of the schema.\n    The detail implementation is varied (max pooling, average ...), controlled by the detail config.\n    Currently we follow yu2017 and use max-pooling.\n    :param preds_hidden:    (data_size, pred_max_len, dim_hidden)\n    :param preds_len:       (data_size, )\n    :param pwords_hidden:   (data_size, pword_max_len, dim_hidden)\n    :param pwords_len:      (data_size, )\n    :return: (data_size, dim_hidden), the final representation of the schema\n    \"\"\"", "\n", "masked_preds_hidden", "=", "seq_hidden_masking_before_pooling", "(", "seq_hidden_input", "=", "preds_hidden", ",", "\n", "len_input", "=", "preds_len", ")", "\n", "masked_pwords_hidden", "=", "seq_hidden_masking_before_pooling", "(", "seq_hidden_input", "=", "pwords_hidden", ",", "\n", "len_input", "=", "pwords_len", ")", "\n", "masked_merge_hidden", "=", "tf", ".", "concat", "(", "\n", "[", "masked_preds_hidden", ",", "masked_pwords_hidden", "]", ",", "\n", "axis", "=", "1", ",", "name", "=", "'masked_merge_hidden'", "\n", ")", "# (data_size, pred_max_len + pword_max_len, dim_hidden)", "\n", "schema_hidden", "=", "tf", ".", "reduce_max", "(", "masked_merge_hidden", ",", "\n", "axis", "=", "1", ",", "name", "=", "'schema_hidden'", ")", "# (data_size, dim_hidden)", "\n", "return", "schema_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking": [[57, 72], ["tensorflow.sequence_mask", "tensorflow.expand_dims", "tensorflow.shape"], "function", ["None"], ["", "def", "seq_hidden_masking", "(", "seq_hidden_input", ",", "len_input", ",", "mask_value", ")", ":", "\n", "    ", "\"\"\"\n    According to the length of each data, set the padding hidden vector into some pre-defined mask value\n    Then we can perform max_pooling\n    :param seq_hidden_input:    (data_size, max_len, dim_hidden)\n    :param len_input:           (data_size, ) as int\n    :param mask_value: tf.float32.min or 0\n    :return: (data_size, stamps, dim_hidden) with masked.\n    \"\"\"", "\n", "max_len", "=", "tf", ".", "shape", "(", "seq_hidden_input", ")", "[", "1", "]", "# could be int or int-tensor", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "lengths", "=", "len_input", ",", "maxlen", "=", "max_len", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'mask'", ")", "# (data_size, max_len)", "\n", "exp_mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "axis", "=", "-", "1", ",", "name", "=", "'exp_mask'", ")", "# (data_size, max_len, 1)", "\n", "masked_hidden", "=", "exp_mask", "*", "seq_hidden_input", "+", "(", "1.0", "-", "exp_mask", ")", "*", "mask_value", "\n", "return", "masked_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking_before_pooling": [[74, 76], ["seq_helper.seq_hidden_masking"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking"], ["", "def", "seq_hidden_masking_before_pooling", "(", "seq_hidden_input", ",", "len_input", ")", ":", "\n", "    ", "return", "seq_hidden_masking", "(", "seq_hidden_input", ",", "len_input", ",", "mask_value", "=", "tf", ".", "float32", ".", "min", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking_before_averaging": [[78, 80], ["seq_helper.seq_hidden_masking"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking"], ["", "def", "seq_hidden_masking_before_averaging", "(", "seq_hidden_input", ",", "len_input", ")", ":", "\n", "    ", "return", "seq_hidden_masking", "(", "seq_hidden_input", ",", "len_input", ",", "mask_value", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_max_pooling": [[82, 93], ["seq_helper.seq_hidden_masking_before_pooling", "tensorflow.reduce_max"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking_before_pooling"], ["", "def", "seq_hidden_max_pooling", "(", "seq_hidden_input", ",", "len_input", ")", ":", "\n", "    ", "\"\"\"\n    Perform max pooling over the sequences.\n    Should perform masking before pooling, due to different length of sequences.\n    :param seq_hidden_input:    (data_size, max_len, dim_hidden)\n    :param len_input:           (data_size, ) as int\n    :return: (data_size, dim_hidden)\n    \"\"\"", "\n", "masked_hidden", "=", "seq_hidden_masking_before_pooling", "(", "seq_hidden_input", ",", "len_input", ")", "\n", "final_hidden", "=", "tf", ".", "reduce_max", "(", "masked_hidden", ",", "axis", "=", "1", ",", "name", "=", "'final_hidden'", ")", "# (-1, dim_hidden)", "\n", "return", "final_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_averaging": [[95, 117], ["seq_helper.seq_hidden_masking_before_averaging", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.div", "tensorflow.expand_dims", "tensorflow.maximum"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_masking_before_averaging"], ["", "def", "seq_hidden_averaging", "(", "seq_hidden_input", ",", "len_input", ")", ":", "\n", "    ", "\"\"\"\n    Average hidden vectors over all the stamps of the sequence.\n    For the padding position of each sequence, their vectors are always 0 (controlled by BidirectionalRNNEncoder)\n    For the padding sequences, their length is 0, we shall avoid dividing by 0.\n    :param seq_hidden_input:    (data_size, max_len, dim_hidden)\n    :param len_input:           (data_size, ) as int\n    :return: (data_size, dim_hidden) as the averaged vector repr.\n    \"\"\"", "\n", "masked_hidden", "=", "seq_hidden_masking_before_averaging", "(", "seq_hidden_input", ",", "len_input", ")", "\n", "sum_seq_hidden", "=", "tf", ".", "reduce_sum", "(", "\n", "masked_hidden", ",", "axis", "=", "1", ",", "name", "=", "'sum_seq_hidden'", "\n", ")", "# (-1, dim_hidden)", "\n", "seq_len_mat", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "expand_dims", "(", "\n", "tf", ".", "maximum", "(", "len_input", ",", "1", ")", ",", "# for padding sequence, their length=0, we avoid dividing by 0", "\n", "axis", "=", "1", "\n", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'seq_len_mat'", "\n", ")", "# (-1, 1) as float32", "\n", "seq_avg_hidden", "=", "tf", ".", "div", "(", "sum_seq_hidden", ",", "seq_len_mat", ",", "\n", "name", "=", "'seq_avg_hidden'", ")", "# (-1, dim_hidden)", "\n", "return", "seq_avg_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_encoding_with_aggregation": [[119, 143], ["seq_helper.seq_encoding", "seq_helper.seq_hidden_averaging", "seq_helper.seq_hidden_max_pooling"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_encoding", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_averaging", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.seq_hidden_max_pooling"], ["", "def", "seq_encoding_with_aggregation", "(", "emb_input", ",", "len_input", ",", "rnn_encoder", ",", "seq_merge_mode", ")", ":", "\n", "    ", "\"\"\"\n    Given sequence embedding, return the aggregated representation of the whole sequence.\n    Consider using or not using RNN\n    :param emb_input: (ds, max_len, dim_emb)\n    :param len_input: (ds, )\n    :param rnn_encoder: Xusheng's BidirectionalRNNEncoder\n    :param seq_merge_mode: fwbw / max / avg\n    :return: (ds, dim_hidden)\n    \"\"\"", "\n", "is_fwbw", "=", "seq_merge_mode", "==", "'fwbw'", "\n", "if", "rnn_encoder", "is", "not", "None", ":", "\n", "        ", "hidden_repr", "=", "seq_encoding", "(", "emb_input", "=", "emb_input", ",", "len_input", "=", "len_input", ",", "\n", "encoder", "=", "rnn_encoder", ",", "fwbw", "=", "is_fwbw", ")", "# (ds, dim_hidden)", "\n", "", "else", ":", "\n", "        ", "hidden_repr", "=", "emb_input", "# (ds, max_len, dim_emb)", "\n", "", "final_repr", "=", "None", "\n", "if", "seq_merge_mode", "==", "'fwbw'", ":", "\n", "        ", "final_repr", "=", "hidden_repr", "\n", "", "elif", "seq_merge_mode", "==", "'avg'", ":", "\n", "        ", "final_repr", "=", "seq_hidden_averaging", "(", "seq_hidden_input", "=", "hidden_repr", ",", "len_input", "=", "len_input", ")", "\n", "", "elif", "seq_merge_mode", "==", "'max'", ":", "\n", "        ", "final_repr", "=", "seq_hidden_max_pooling", "(", "seq_hidden_input", "=", "hidden_repr", ",", "len_input", "=", "len_input", ")", "\n", "", "return", "final_repr", "# (ds, dim_hidden)", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.cosine_sim": [[145, 169], ["tensorflow.sqrt", "tensorflow.div", "tensorflow.sqrt", "tensorflow.div", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "cosine_sim", "(", "lf_input", ",", "rt_input", ")", ":", "\n", "    ", "\"\"\"\n    This implementation is better\n    :param lf_input: (ANY_SHAPE, dim_hidden)\n    :param rt_input: (ANY_SHAPE, dim_hidden)\n    :return: (ANY_SHAPE, )\n    \"\"\"", "\n", "lf_norm", "=", "tf", ".", "sqrt", "(", "\n", "tf", ".", "reduce_sum", "(", "lf_input", "**", "2", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "+", "1e-6", ",", "\n", "name", "=", "'lf_norm'", "\n", ")", "# (ANY_SHAPE, 1)", "\n", "lf_norm_hidden", "=", "tf", ".", "div", "(", "lf_input", ",", "lf_norm", ",", "\n", "name", "=", "'lf_norm_hidden'", ")", "# (ANY_SHAPE, dim_hidden)", "\n", "rt_norm", "=", "tf", ".", "sqrt", "(", "\n", "tf", ".", "reduce_sum", "(", "rt_input", "**", "2", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "+", "1e-6", ",", "\n", "name", "=", "'rt_norm'", "\n", ")", "# (ANY_SHAPE, 1)", "\n", "rt_norm_hidden", "=", "tf", ".", "div", "(", "rt_input", ",", "rt_norm", ",", "\n", "name", "=", "'rt_norm_hidden'", ")", "# (ANY_SHAPE, dim_hidden)", "\n", "\n", "cosine_score", "=", "tf", ".", "reduce_sum", "(", "lf_norm_hidden", "*", "rt_norm_hidden", ",", "\n", "axis", "=", "-", "1", ",", "name", "=", "'cosine_score'", ")", "\n", "# (ANY_SHAPE, )", "\n", "return", "cosine_score", "\n", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_output_fn": [[35, 41], ["tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.contrib.layers.python.layers.layers.linear"], "function", ["None"], ["def", "create_output_fn", "(", "vocab_size", ")", ":", "\n", "    ", "with", "variable_scope", ".", "variable_scope", "(", "\"output_fn\"", ")", "as", "scope", ":", "\n", "        ", "def", "output_fn", "(", "x", ")", ":", "\n", "            ", "return", "layers", ".", "linear", "(", "x", ",", "vocab_size", ",", "scope", "=", "scope", ")", "\n", "\n", "", "return", "output_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_hidden_fn": [[43, 49], ["tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.contrib.layers.python.layers.layers.linear"], "function", ["None"], ["", "", "def", "create_hidden_fn", "(", "num_units", ")", ":", "\n", "    ", "with", "variable_scope", ".", "variable_scope", "(", "\"hidden_fn\"", ")", "as", "scope", ":", "\n", "        ", "def", "hidden_fn", "(", "x", ")", ":", "\n", "            ", "return", "layers", ".", "linear", "(", "x", ",", "num_units", ",", "scope", "=", "scope", ")", "\n", "\n", "", "return", "hidden_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_attention": [[51, 72], ["attention_decoder._create_attention_construct_fn", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.contrib.layers.python.layers.layers.linear", "attention_decoder._create_attention_score_fn"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._create_attention_construct_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._create_attention_score_fn"], ["", "", "def", "prepare_attention", "(", "attention_states", ",", "\n", "kd_states", ",", "\n", "attention_option", ",", "\n", "num_units", ",", "\n", "reuse", "=", "False", ")", ":", "\n", "# Prepare attention keys / values from attention_states", "\n", "    ", "with", "variable_scope", ".", "variable_scope", "(", "\"attn_keys\"", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "        ", "attention_keys", "=", "layers", ".", "linear", "(", "attention_states", ",", "num_units", ",", "\n", "biases_initializer", "=", "None", ",", "scope", "=", "scope", ")", "\n", "if", "kd_states", "is", "not", "None", ":", "\n", "            ", "attention_values", "=", "(", "attention_states", ",", "kd_states", ")", "\n", "", "else", ":", "\n", "            ", "attention_values", "=", "attention_states", "\n", "# Attention scoring function", "\n", "", "attention_score_fn", "=", "_create_attention_score_fn", "(", "\"attn_score\"", ",", "num_units", ",", "attention_option", ",", "reuse", ")", "\n", "\n", "# Attention construction function", "\n", "", "attention_construct_fn", "=", "_create_attention_construct_fn", "(", "\"attn_construct\"", ",", "\n", "num_units", ",", "attention_score_fn", ",", "reuse", ")", "\n", "\n", "return", "attention_keys", ",", "attention_values", ",", "attention_construct_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_multistep_attention": [[74, 111], ["attention_decoder._create_attention_construct_fn", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.contrib.layers.python.layers.layers.linear", "attention_decoder._create_attention_score_fn", "tensorflow.python.ops.variable_scope.variable_scope", "attention_decoder._create_attention_score_fn", "tensorflow.contrib.layers.python.layers.layers.linear"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._create_attention_construct_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._create_attention_score_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._create_attention_score_fn"], ["", "def", "prepare_multistep_attention", "(", "encoder_states", ",", "\n", "decoder_reprs", ",", "\n", "kd_states1", ",", "\n", "kd_states2", ",", "\n", "attention_option", ",", "\n", "num_units", ",", "\n", "reuse", "=", "False", ")", ":", "\n", "# Prepare attention keys / values from attention_states", "\n", "    ", "with", "variable_scope", ".", "variable_scope", "(", "\"attn_keys\"", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "        ", "attention_keys1", "=", "layers", ".", "linear", "(", "encoder_states", ",", "num_units", ",", "biases_initializer", "=", "None", ",", "scope", "=", "scope", ")", "\n", "attention_values1", "=", "encoder_states", "\n", "# Attention scoring function", "\n", "attention_score_fn1", "=", "_create_attention_score_fn", "(", "\"attn_score\"", ",", "num_units", ",", "\n", "attention_option", ",", "reuse", ")", "\n", "\n", "", "with", "variable_scope", ".", "variable_scope", "(", "\"attn_reprs\"", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "        ", "if", "decoder_reprs", "is", "not", "None", ":", "\n", "            ", "attention_keys2", "=", "layers", ".", "linear", "(", "decoder_reprs", ",", "num_units", ",", "biases_initializer", "=", "None", ",", "scope", "=", "scope", ")", "\n", "", "else", ":", "\n", "            ", "attention_keys2", "=", "None", "\n", "", "attention_values2", "=", "decoder_reprs", "\n", "# Attention scoring function", "\n", "attention_score_fn2", "=", "_create_attention_score_fn", "(", "\"attn_score\"", ",", "num_units", ",", "\n", "attention_option", ",", "reuse", ")", "\n", "\n", "", "attention_keys", "=", "(", "attention_keys1", ",", "attention_keys2", ")", "\n", "if", "kd_states1", "is", "not", "None", "and", "kd_states2", "is", "not", "None", ":", "\n", "        ", "attention_values", "=", "(", "attention_values1", ",", "attention_values2", ",", "kd_states1", ",", "kd_states2", ")", "\n", "", "else", ":", "\n", "        ", "attention_values", "=", "(", "attention_values1", ",", "attention_values2", ",", "None", ",", "None", ")", "\n", "", "attention_score_fn", "=", "(", "attention_score_fn1", ",", "attention_score_fn2", ")", "\n", "\n", "# Attention construction function", "\n", "attention_construct_fn", "=", "_create_attention_construct_fn", "(", "\"attn_construct_multi\"", ",", "\n", "num_units", ",", "attention_score_fn", ",", "reuse", ")", "\n", "\n", "return", "attention_keys", ",", "attention_values", ",", "attention_construct_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_train": [[113, 132], ["tensorflow.python.ops.array_ops.concat", "attention_decoder._init_attention", "attention_construct_fn"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._init_attention"], ["", "def", "attention_decoder_train", "(", "encoder_state", ",", "\n", "attention_keys", ",", "\n", "attention_values", ",", "\n", "attention_construct_fn", ")", ":", "\n", "    ", "def", "decoder_fn", "(", "time", ",", "cell_state", ",", "cell_input", ",", "cell_output", ",", "context_state", ")", ":", "\n", "        ", "if", "cell_state", "is", "None", ":", "# first call, return encoder_state", "\n", "            ", "cell_state", "=", "encoder_state", "\n", "# init attention", "\n", "attention", "=", "_init_attention", "(", "encoder_state", ")", "\n", "", "else", ":", "# construct attention", "\n", "            ", "attention", "=", "attention_construct_fn", "(", "cell_output", ",", "attention_keys", ",", "attention_values", ")", "\n", "cell_output", "=", "attention", "\n", "\n", "# combine cell_input and attention", "\n", "", "next_input", "=", "array_ops", ".", "concat", "(", "[", "cell_input", ",", "attention", "]", ",", "1", ")", "\n", "\n", "return", "(", "None", ",", "cell_state", ",", "next_input", ",", "cell_output", ",", "context_state", ")", "\n", "\n", "", "return", "decoder_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_inference": [[134, 201], ["tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.util.nest.flatten", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.control_flow_ops.cond", "encoder_info.get_shape", "tensorflow.python.ops.array_ops.shape", "ValueError", "tensorflow.python.ops.array_ops.zeros", "tensorflow.python.ops.array_ops.gather", "attention_decoder._init_attention", "attention_construct_fn", "tensorflow.python.ops.math_ops.equal", "tensorflow.python.ops.array_ops.gather", "tensorflow.python.ops.math_ops.greater", "tensorflow.python.ops.array_ops.ones", "tensorflow.python.ops.array_ops.zeros", "tensorflow.python.ops.array_ops.zeros", "attention_decoder.create_output_fn.output_fn", "tensorflow.python.ops.math_ops.cast", "attention_decoder.create_output_fn.output_fn", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.array_ops.ones", "tensorflow.python.ops.math_ops.argmax", "tensorflow.python.ops.math_ops.argmax"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._init_attention"], ["", "def", "attention_decoder_inference", "(", "num_units", ",", "\n", "num_decoder_symbols", ",", "\n", "output_fn", ",", "\n", "encoder_state", ",", "\n", "attention_keys", ",", "\n", "attention_values", ",", "\n", "attention_construct_fn", ",", "\n", "embeddings", ",", "\n", "start_of_sequence_id", ",", "\n", "end_of_sequence_id", ",", "\n", "maximum_length", ",", "\n", "dtype", "=", "dtypes", ".", "int32", ",", "\n", "is_pass1", "=", "False", ")", ":", "\n", "    ", "num_units", "=", "ops", ".", "convert_to_tensor", "(", "num_units", ",", "dtype", ")", "\n", "num_decoder_symbols", "=", "ops", ".", "convert_to_tensor", "(", "num_decoder_symbols", ",", "dtype", ")", "\n", "start_of_sequence_id", "=", "ops", ".", "convert_to_tensor", "(", "start_of_sequence_id", ",", "dtype", ")", "\n", "end_of_sequence_id", "=", "ops", ".", "convert_to_tensor", "(", "end_of_sequence_id", ",", "dtype", ")", "\n", "maximum_length", "=", "ops", ".", "convert_to_tensor", "(", "maximum_length", ",", "dtype", ")", "\n", "encoder_info", "=", "nest", ".", "flatten", "(", "encoder_state", ")", "[", "0", "]", "\n", "batch_size", "=", "encoder_info", ".", "get_shape", "(", ")", "[", "0", "]", ".", "value", "\n", "if", "batch_size", "is", "None", ":", "\n", "        ", "batch_size", "=", "array_ops", ".", "shape", "(", "encoder_info", ")", "[", "0", "]", "\n", "\n", "", "def", "decoder_fn", "(", "time", ",", "cell_state", ",", "cell_input", ",", "cell_output", ",", "context_state", ")", ":", "\n", "        ", "if", "cell_input", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Expected cell_input to be None, but saw: %s\"", "%", "cell_input", ")", "\n", "\n", "", "if", "cell_output", "is", "None", ":", "\n", "# invariant that this is time == 0", "\n", "            ", "next_input_id", "=", "array_ops", ".", "ones", "(", "[", "batch_size", ",", "]", ",", "dtype", "=", "dtype", ")", "*", "start_of_sequence_id", "\n", "done", "=", "array_ops", ".", "zeros", "(", "[", "batch_size", ",", "]", ",", "dtype", "=", "dtypes", ".", "bool", ")", "\n", "cell_state", "=", "encoder_state", "\n", "\n", "if", "is_pass1", ":", "\n", "                ", "cell_output", "=", "array_ops", ".", "zeros", "(", "[", "num_units", "]", ",", "dtype", "=", "dtypes", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "cell_output", "=", "array_ops", ".", "zeros", "(", "[", "num_decoder_symbols", "]", ",", "dtype", "=", "dtypes", ".", "float32", ")", "\n", "", "cell_input", "=", "array_ops", ".", "gather", "(", "embeddings", ",", "next_input_id", ")", "\n", "# init attention", "\n", "attention", "=", "_init_attention", "(", "encoder_state", ")", "\n", "", "else", ":", "\n", "# construct attention", "\n", "            ", "attention", "=", "attention_construct_fn", "(", "cell_output", ",", "attention_keys", ",", "attention_values", ")", "\n", "cell_output", "=", "attention", "\n", "\n", "if", "is_pass1", ":", "\n", "# argmax decoder", "\n", "                ", "cell_output_logits", "=", "output_fn", "(", "cell_output", ")", "# logits", "\n", "next_input_id", "=", "math_ops", ".", "cast", "(", "math_ops", ".", "argmax", "(", "cell_output_logits", ",", "1", ")", ",", "dtype", "=", "dtype", ")", "\n", "", "else", ":", "\n", "# argmax decoder", "\n", "                ", "cell_output", "=", "output_fn", "(", "cell_output", ")", "# output logits", "\n", "next_input_id", "=", "math_ops", ".", "cast", "(", "math_ops", ".", "argmax", "(", "cell_output", ",", "1", ")", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "done", "=", "math_ops", ".", "equal", "(", "next_input_id", ",", "end_of_sequence_id", ")", "\n", "cell_input", "=", "array_ops", ".", "gather", "(", "embeddings", ",", "next_input_id", ")", "\n", "\n", "# combine cell_input and attention", "\n", "", "next_input", "=", "array_ops", ".", "concat", "(", "[", "cell_input", ",", "attention", "]", ",", "1", ")", "\n", "\n", "# if time > maxlen, return all true vector", "\n", "done", "=", "control_flow_ops", ".", "cond", "(", "math_ops", ".", "greater", "(", "time", ",", "maximum_length", ")", ",", "\n", "lambda", ":", "array_ops", ".", "ones", "(", "[", "batch_size", ",", "]", ",", "dtype", "=", "dtypes", ".", "bool", ")", ",", "\n", "lambda", ":", "done", ")", "\n", "return", "(", "done", ",", "cell_state", ",", "next_input", ",", "cell_output", ",", "context_state", ")", "\n", "\n", "", "return", "decoder_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._init_attention": [[204, 225], ["isinstance", "isinstance", "tensorflow.python.ops.array_ops.zeros_like", "tensorflow.python.ops.array_ops.zeros_like"], "function", ["None"], ["", "def", "_init_attention", "(", "encoder_state", ")", ":", "\n", "    ", "\"\"\"Initialize attention. Handling both LSTM and GRU.\n    Args:\n        encoder_state: The encoded state to initialize the `dynamic_rnn_decoder`.\n    Returns:\n        attn: initial zero attention vector.\n    \"\"\"", "\n", "\n", "# Multi- vs single-layer", "\n", "if", "isinstance", "(", "encoder_state", ",", "tuple", ")", ":", "\n", "        ", "top_state", "=", "encoder_state", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "top_state", "=", "encoder_state", "\n", "\n", "# LSTM vs GRU", "\n", "", "if", "isinstance", "(", "top_state", ",", "rnn_cell_impl", ".", "LSTMStateTuple", ")", ":", "\n", "        ", "attn", "=", "array_ops", ".", "zeros_like", "(", "top_state", ".", "h", ")", "\n", "", "else", ":", "\n", "        ", "attn", "=", "array_ops", ".", "zeros_like", "(", "top_state", ")", "\n", "\n", "", "return", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._create_attention_construct_fn": [[227, 267], ["tensorflow.python.ops.variable_scope.variable_scope", "isinstance", "tensorflow.contrib.layers.python.layers.layers.linear", "attention_score_fn1", "isinstance", "attention_score_fn2", "tensorflow.python.ops.array_ops.concat", "attention_decoder._create_attention_score_fn.attention_score_fn", "tensorflow.python.ops.array_ops.concat", "attention_decoder._create_attention_score_fn.attention_score_fn", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.array_ops.concat", "attention_score_fn2", "tensorflow.python.ops.array_ops.concat"], "function", ["None"], ["", "def", "_create_attention_construct_fn", "(", "name", ",", "num_units", ",", "attention_score_fn", ",", "reuse", ")", ":", "\n", "    ", "\"\"\"Function to compute attention vectors.\n    Args:\n        name: to label variables.\n        num_units: hidden state dimension.\n        attention_score_fn: to compute similarity between key and target states.\n        reuse: whether to reuse variable scope.\n    Returns:\n        attention_construct_fn: to build attention states.\n    \"\"\"", "\n", "with", "variable_scope", ".", "variable_scope", "(", "name", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "\n", "        ", "def", "construct_fn", "(", "attention_query", ",", "attention_keys", ",", "attention_values", ")", ":", "\n", "            ", "if", "isinstance", "(", "attention_score_fn", ",", "tuple", ")", ":", "# multi-step decoding", "\n", "                ", "attention_score_fn1", ",", "attention_score_fn2", "=", "attention_score_fn", "\n", "attention_keys1", ",", "attention_keys2", "=", "attention_keys", "\n", "attention_values1", ",", "decoder_reprs", ",", "kd_states1", ",", "kd_states2", "=", "attention_values", "\n", "context1", "=", "attention_score_fn1", "(", "attention_query", ",", "attention_keys1", ",", "attention_values1", ")", "\n", "if", "kd_states1", "is", "None", "or", "kd_states2", "is", "None", ":", "\n", "                    ", "context2", "=", "attention_score_fn2", "(", "attention_query", ",", "attention_keys2", ",", "decoder_reprs", ")", "\n", "concat_input", "=", "array_ops", ".", "concat", "(", "[", "attention_query", ",", "context1", ",", "context2", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "if", "decoder_reprs", "is", "None", ":", "\n", "                        ", "concat_input", "=", "array_ops", ".", "concat", "(", "[", "attention_query", ",", "context1", ",", "kd_states1", ",", "kd_states2", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                        ", "context2", "=", "attention_score_fn2", "(", "attention_query", ",", "attention_keys2", ",", "decoder_reprs", ")", "\n", "concat_input", "=", "array_ops", ".", "concat", "(", "[", "attention_query", ",", "context1", ",", "context2", ",", "kd_states1", ",", "kd_states2", "]", ",", "1", ")", "\n", "", "", "", "else", ":", "# only one step decoding", "\n", "                ", "if", "isinstance", "(", "attention_values", ",", "tuple", ")", ":", "\n", "                    ", "attention_values1", ",", "kd_state", "=", "attention_values", "\n", "context1", "=", "attention_score_fn", "(", "attention_query", ",", "attention_keys", ",", "attention_values1", ")", "\n", "concat_input", "=", "array_ops", ".", "concat", "(", "[", "attention_query", ",", "context1", ",", "kd_state", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "context", "=", "attention_score_fn", "(", "attention_query", ",", "attention_keys", ",", "attention_values", ")", "\n", "concat_input", "=", "array_ops", ".", "concat", "(", "[", "attention_query", ",", "context", "]", ",", "1", ")", "\n", "\n", "", "", "attention", "=", "layers", ".", "linear", "(", "concat_input", ",", "num_units", ",", "biases_initializer", "=", "None", ",", "scope", "=", "scope", ")", "\n", "return", "attention", "\n", "\n", "", "return", "construct_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._create_attention_score_fn": [[269, 331], ["tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.nn_ops.softmax", "tensorflow.python.ops.array_ops.expand_dims", "tensorflow.python.ops.math_ops.reduce_sum", "math_ops.reduce_sum.set_shape", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.array_ops.reshape", "attention_decoder._attn_add_fun", "tensorflow.python.ops.array_ops.reshape", "attention_decoder._attn_mul_fun", "ValueError"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._attn_add_fun", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._attn_mul_fun"], ["", "", "def", "_create_attention_score_fn", "(", "name", ",", "num_units", ",", "attention_option", ",", "reuse", ",", "dtype", "=", "dtypes", ".", "float32", ")", ":", "\n", "    ", "\"\"\"Different ways to compute attention scores.\n    Args:\n        name: to label variables.\n        num_units: hidden state dimension.\n        attention_option: how to compute attention, either \"luong\" or \"bahdanau\".\n            \"bahdanau\": additive (Bahdanau et al., ICLR'2015)\n            \"luong\": multiplicative (Luong et al., EMNLP'2015)\n        reuse: whether to reuse variable scope.\n        dtype: (default: `dtypes.float32`) data type to use.\n    Returns:\n        attention_score_fn: to compute similarity between key and target states.\n    \"\"\"", "\n", "with", "variable_scope", ".", "variable_scope", "(", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "if", "attention_option", "==", "\"bahdanau\"", ":", "\n", "            ", "query_w", "=", "variable_scope", ".", "get_variable", "(", "\"attnW\"", ",", "[", "num_units", ",", "num_units", "]", ",", "dtype", "=", "dtype", ")", "\n", "score_v", "=", "variable_scope", ".", "get_variable", "(", "\"attnV\"", ",", "[", "num_units", "]", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "def", "attention_score_fn", "(", "query", ",", "keys", ",", "values", ")", ":", "\n", "            ", "\"\"\"Put attention masks on attention_values using attention_keys and query.\n            Args:\n                query: A Tensor of shape [batch_size, num_units].\n                keys: A Tensor of shape [batch_size, attention_length, num_units].\n                values: A Tensor of shape [batch_size, attention_length, num_units].\n            Returns:\n                context_vector: A Tensor of shape [batch_size, num_units].\n            Raises:\n                ValueError: if attention_option is neither \"luong\" or \"bahdanau\".\n            \"\"\"", "\n", "\n", "if", "attention_option", "==", "\"bahdanau\"", ":", "\n", "# transform query", "\n", "                ", "query", "=", "math_ops", ".", "matmul", "(", "query", ",", "query_w", ")", "\n", "\n", "# reshape query: [batch_size, 1, num_units]", "\n", "query", "=", "array_ops", ".", "reshape", "(", "query", ",", "[", "-", "1", ",", "1", ",", "num_units", "]", ")", "\n", "\n", "# attn_fun", "\n", "scores", "=", "_attn_add_fun", "(", "score_v", ",", "keys", ",", "query", ")", "\n", "", "elif", "attention_option", "==", "\"luong\"", ":", "\n", "# reshape query: [batch_size, 1, num_units]", "\n", "                ", "query", "=", "array_ops", ".", "reshape", "(", "query", ",", "[", "-", "1", ",", "1", ",", "num_units", "]", ")", "\n", "\n", "# attn_fun", "\n", "scores", "=", "_attn_mul_fun", "(", "keys", ",", "query", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown attention option %s!\"", "%", "attention_option", ")", "\n", "\n", "# Compute alignment weights", "\n", "#     scores: [batch_size, length]", "\n", "#     alignments: [batch_size, length]", "\n", "# TODO(thangluong): not normalize over padding positions.", "\n", "", "alignments", "=", "nn_ops", ".", "softmax", "(", "scores", ")", "\n", "\n", "# Now calculate the attention-weighted vector.", "\n", "alignments", "=", "array_ops", ".", "expand_dims", "(", "alignments", ",", "2", ")", "\n", "context_vector", "=", "math_ops", ".", "reduce_sum", "(", "alignments", "*", "values", ",", "[", "1", "]", ")", "\n", "context_vector", ".", "set_shape", "(", "[", "None", ",", "num_units", "]", ")", "\n", "\n", "return", "context_vector", "\n", "\n", "", "return", "attention_score_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._attn_add_fun": [[336, 339], ["tensorflow.python.framework.function.Defun", "tensorflow.python.ops.math_ops.reduce_sum", "tensorflow.python.ops.math_ops.tanh"], "function", ["None"], ["", "", "@", "function", ".", "Defun", "(", "func_name", "=", "\"attn_add_fun\"", ",", "noinline", "=", "True", ")", "\n", "def", "_attn_add_fun", "(", "v", ",", "keys", ",", "query", ")", ":", "\n", "    ", "return", "math_ops", ".", "reduce_sum", "(", "v", "*", "math_ops", ".", "tanh", "(", "keys", "+", "query", ")", ",", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder._attn_mul_fun": [[341, 344], ["tensorflow.python.framework.function.Defun", "tensorflow.python.ops.math_ops.reduce_sum"], "function", ["None"], ["", "@", "function", ".", "Defun", "(", "func_name", "=", "\"attn_mul_fun\"", ",", "noinline", "=", "True", ")", "\n", "def", "_attn_mul_fun", "(", "keys", ",", "query", ")", ":", "\n", "    ", "return", "math_ops", ".", "reduce_sum", "(", "keys", "*", "query", ",", "[", "2", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.dynamic_decoder.dynamic_rnn_decoder": [[33, 221], ["tensorflow.python.framework.ops.name_scope", "tensorflow.python.ops.rnn.raw_rnn", "outputs_ta.stack", "isinstance", "tensorflow.python.framework.ops.convert_to_tensor", "int", "tensorflow.python.ops.tensor_array_ops.TensorArray", "inputs_ta.unstack.unstack", "tensorflow.python.ops.array_ops.transpose", "ValueError", "tensorflow.python.ops.array_ops.transpose", "isinstance", "decoder_fn", "decoder_fn", "array_ops.transpose.get_shape", "array_ops.transpose.get_shape", "array_ops.transpose.get_shape", "tensorflow.python.ops.array_ops.shape", "ValueError", "ValueError", "inputs_ta.unstack.read", "tensorflow.python.ops.control_flow_ops.cond", "array_ops.transpose.get_shape", "array_ops.transpose.get_shape", "tensorflow.python.ops.math_ops.equal", "tensorflow.python.ops.array_ops.shape", "tensorflow.python.ops.array_ops.zeros", "inputs_ta.unstack.read"], "function", ["None"], ["def", "dynamic_rnn_decoder", "(", "cell", ",", "decoder_fn", ",", "inputs", "=", "None", ",", "sequence_length", "=", "None", ",", "\n", "parallel_iterations", "=", "None", ",", "swap_memory", "=", "False", ",", "\n", "time_major", "=", "False", ",", "scope", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Dynamic RNN decoder for a sequence-to-sequence model specified by\n    RNNCell and decoder function.\n\n    The `dynamic_rnn_decoder` is similar to the `tf.python.ops.rnn.dynamic_rnn`\n    as the decoder does not make any assumptions of sequence length and batch\n    size of the input.\n\n    The `dynamic_rnn_decoder` has two modes: training or inference and expects\n    the user to create seperate functions for each.\n\n    Under both training and inference, both `cell` and `decoder_fn` are expected,\n    where `cell` performs computation at every timestep using `raw_rnn`, and\n    `decoder_fn` allows modeling of early stopping, output, state, and next\n    input and context.\n\n    When training the user is expected to supply `inputs`. At every time step a\n    slice of the supplied input is fed to the `decoder_fn`, which modifies and\n    returns the input for the next time step.\n\n    `sequence_length` is needed at training time, i.e., when `inputs` is not\n    None, for dynamic unrolling. At test time, when `inputs` is None,\n    `sequence_length` is not needed.\n\n    Under inference `inputs` is expected to be `None` and the input is inferred\n    solely from the `decoder_fn`.\n\n    Args:\n        cell: An instance of RNNCell.\n        decoder_fn: A function that takes time, cell state, cell input,\n            cell output and context state. It returns a early stopping vector,\n            cell state, next input, cell output and context state.\n            Examples of decoder_fn can be found in the decoder_fn.py folder.\n        inputs: The inputs for decoding (embedded format).\n\n            If `time_major == False` (default), this must be a `Tensor` of shape:\n                `[batch_size, max_time, ...]`.\n\n            If `time_major == True`, this must be a `Tensor` of shape:\n                `[max_time, batch_size, ...]`.\n\n            The input to `cell` at each time step will be a `Tensor` with dimensions\n                `[batch_size, ...]`.\n\n        sequence_length: (optional) An int32/int64 vector sized `[batch_size]`.\n            if `inputs` is not None and `sequence_length` is None it is inferred\n            from the `inputs` as the maximal possible sequence length.\n        parallel_iterations: (Default: 32).    The number of iterations to run in\n            parallel.    Those operations which do not have any temporal dependency\n            and can be run in parallel, will be.    This parameter trades off\n            time for space.    Values >> 1 use more memory but take less time,\n            while smaller values use less memory but computations take longer.\n        swap_memory: Transparently swap the tensors produced in forward inference\n            but needed for back prop from GPU to CPU.    This allows training RNNs\n            which would typically not fit on a single GPU, with very minimal (or no)\n            performance penalty.\n        time_major: The shape format of the `inputs` and `outputs` Tensors.\n            If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n            If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n            Using `time_major = True` is a bit more efficient because it avoids\n            transposes at the beginning and end of the RNN calculation.    However,\n            most TensorFlow data is batch-major, so by default this function\n            accepts input and emits output in batch-major form.\n        scope: VariableScope for the `raw_rnn`;\n            defaults to None.\n        name: NameScope for the decoder;\n            defaults to \"dynamic_rnn_decoder\"\n\n    Returns:\n        A tuple (outputs, final_state, final_context_state) where:\n\n            outputs: the RNN output 'Tensor'.\n\n                If time_major == False (default), this will be a `Tensor` shaped:\n                    `[batch_size, max_time, cell.output_size]`.\n\n                If time_major == True, this will be a `Tensor` shaped:\n                    `[max_time, batch_size, cell.output_size]`.\n\n            final_state: The final state and will be shaped\n                `[batch_size, cell.state_size]`.\n\n            final_context_state: The context state returned by the final call\n                to decoder_fn. This is useful if the context state maintains internal\n                data which is required after the graph is run.\n                For example, one way to diversify the inference output is to use\n                a stochastic decoder_fn, in which case one would want to store the\n                decoded outputs, not just the RNN outputs. This can be done by\n                maintaining a TensorArray in context_state and storing the decoded\n                output of each iteration therein.\n\n    Raises:\n        ValueError: if inputs is not None and has less than three dimensions.\n    \"\"\"", "\n", "with", "ops", ".", "name_scope", "(", "name", ",", "\"dynamic_rnn_decoder\"", ",", "\n", "[", "cell", ",", "decoder_fn", ",", "inputs", ",", "sequence_length", ",", "\n", "parallel_iterations", ",", "swap_memory", ",", "time_major", ",", "scope", "]", ")", ":", "\n", "        ", "if", "inputs", "is", "not", "None", ":", "\n", "# Convert to tensor", "\n", "            ", "inputs", "=", "ops", ".", "convert_to_tensor", "(", "inputs", ")", "\n", "\n", "# Test input dimensions", "\n", "if", "inputs", ".", "get_shape", "(", ")", ".", "ndims", "is", "not", "None", "and", "(", "\n", "inputs", ".", "get_shape", "(", ")", ".", "ndims", "<", "2", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Inputs must have at least two dimensions\"", ")", "\n", "# Setup of RNN (dimensions, sizes, length, initial state, dtype)", "\n", "", "if", "not", "time_major", ":", "\n", "# [batch, seq, features] -> [seq, batch, features]", "\n", "                ", "inputs", "=", "array_ops", ".", "transpose", "(", "inputs", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "", "dtype", "=", "inputs", ".", "dtype", "\n", "# Get data input information", "\n", "input_depth", "=", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "2", "]", ")", "\n", "batch_depth", "=", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "max_time", "=", "inputs", ".", "get_shape", "(", ")", "[", "0", "]", ".", "value", "\n", "if", "max_time", "is", "None", ":", "\n", "                ", "max_time", "=", "array_ops", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "# Setup decoder inputs as TensorArray", "\n", "", "inputs_ta", "=", "tensor_array_ops", ".", "TensorArray", "(", "dtype", ",", "size", "=", "max_time", ")", "\n", "inputs_ta", "=", "inputs_ta", ".", "unstack", "(", "inputs", ")", "\n", "\n", "", "def", "loop_fn", "(", "time", ",", "cell_output", ",", "cell_state", ",", "loop_state", ")", ":", "\n", "            ", "if", "cell_state", "is", "None", ":", "# first call, before while loop (in raw_rnn)", "\n", "                ", "if", "cell_output", "is", "not", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Expected cell_output to be None when cell_state \"", "\n", "\"is None, but saw: %s\"", "%", "cell_output", ")", "\n", "", "if", "loop_state", "is", "not", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Expected loop_state to be None when cell_state \"", "\n", "\"is None, but saw: %s\"", "%", "loop_state", ")", "\n", "", "context_state", "=", "None", "\n", "", "else", ":", "# subsequent calls, inside while loop, after cell excution", "\n", "                ", "if", "isinstance", "(", "loop_state", ",", "tuple", ")", ":", "\n", "                    ", "(", "done", ",", "context_state", ")", "=", "loop_state", "\n", "", "else", ":", "\n", "                    ", "done", "=", "loop_state", "\n", "context_state", "=", "None", "\n", "\n", "# call decoder function", "\n", "", "", "if", "inputs", "is", "not", "None", ":", "# training", "\n", "# get next_cell_input", "\n", "                ", "if", "cell_state", "is", "None", ":", "\n", "                    ", "next_cell_input", "=", "inputs_ta", ".", "read", "(", "0", ")", "\n", "", "else", ":", "\n", "                    ", "if", "batch_depth", "is", "not", "None", ":", "\n", "                        ", "batch_size", "=", "batch_depth", "\n", "", "else", ":", "\n", "                        ", "batch_size", "=", "array_ops", ".", "shape", "(", "done", ")", "[", "0", "]", "\n", "", "next_cell_input", "=", "control_flow_ops", ".", "cond", "(", "\n", "math_ops", ".", "equal", "(", "time", ",", "max_time", ")", ",", "\n", "lambda", ":", "array_ops", ".", "zeros", "(", "[", "batch_size", ",", "input_depth", "]", ",", "dtype", "=", "dtype", ")", ",", "\n", "lambda", ":", "inputs_ta", ".", "read", "(", "time", ")", ")", "\n", "", "(", "next_done", ",", "next_cell_state", ",", "next_cell_input", ",", "emit_output", ",", "next_context_state", ")", "=", "decoder_fn", "(", "time", ",", "cell_state", ",", "next_cell_input", ",", "cell_output", ",", "context_state", ")", "\n", "", "else", ":", "# inference", "\n", "# next_cell_input is obtained through decoder_fn", "\n", "                ", "(", "next_done", ",", "next_cell_state", ",", "next_cell_input", ",", "emit_output", ",", "next_context_state", ")", "=", "decoder_fn", "(", "time", ",", "cell_state", ",", "None", ",", "cell_output", ",", "context_state", ")", "\n", "\n", "# check if we are done", "\n", "", "if", "next_done", "is", "None", ":", "# training", "\n", "                ", "next_done", "=", "time", ">=", "sequence_length", "\n", "\n", "# build next_loop_state", "\n", "", "if", "next_context_state", "is", "None", ":", "\n", "                ", "next_loop_state", "=", "next_done", "\n", "", "else", ":", "\n", "                ", "next_loop_state", "=", "(", "next_done", ",", "next_context_state", ")", "\n", "\n", "", "return", "(", "next_done", ",", "next_cell_input", ",", "next_cell_state", ",", "emit_output", ",", "next_loop_state", ")", "\n", "\n", "# Run raw_rnn function", "\n", "", "outputs_ta", ",", "final_state", ",", "final_loop_state", "=", "rnn", ".", "raw_rnn", "(", "cell", ",", "loop_fn", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "swap_memory", "=", "swap_memory", ",", "scope", "=", "scope", ")", "\n", "outputs", "=", "outputs_ta", ".", "stack", "(", ")", "\n", "if", "not", "time_major", ":", "\n", "# [seq, batch, features] -> [batch, seq, features]", "\n", "            ", "outputs", "=", "array_ops", ".", "transpose", "(", "outputs", ",", "perm", "=", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "# Get final context_state, if generated by user", "\n", "", "if", "isinstance", "(", "final_loop_state", ",", "tuple", ")", ":", "\n", "            ", "final_context_state", "=", "final_loop_state", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "final_context_state", "=", "None", "\n", "\n", "", "return", "outputs", ",", "final_state", ",", "final_context_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.__init__": [[12, 52], ["tensorflow.Variable", "model_multistep.TransDGModelMultistep._init_embed", "model_multistep.TransDGModelMultistep._init_placeholders", "model_multistep.TransDGModelMultistep._init_vocabs", "model_multistep.TransDGModelMultistep.build_model", "model_multistep.TransDGModelMultistep.build_model", "tensorflow.train.AdamOptimizer", "tensorflow.global_variables", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "model_multistep.TransDGModelMultistep._init_select_layer", "zip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_embed", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_placeholders", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_vocabs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_model", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_model", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_select_layer"], ["    ", "def", "__init__", "(", "self", ",", "word_embed", ",", "kd_embed", ",", "param_dict", ",", "use_trans_repr", "=", "True", ",", "use_trans_select", "=", "True", ",", "use_guiding", "=", "True", ",", "\n", "vocab_size", "=", "30000", ",", "dim_emb", "=", "300", ",", "dim_trans", "=", "100", ",", "cell_class", "=", "'GRU'", ",", "num_units", "=", "512", ",", "num_layers", "=", "2", ",", "\n", "max_length", "=", "60", ",", "lr_rate", "=", "0.0001", ",", "max_grad_norm", "=", "5.0", ",", "drop_rate", "=", "0.2", ",", "beam_size", "=", "1", ")", ":", "\n", "# initialize params", "\n", "        ", "self", ".", "use_trans_repr", "=", "use_trans_repr", "\n", "self", ".", "use_trans_select", "=", "use_trans_select", "\n", "self", ".", "use_guiding", "=", "use_guiding", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "dim_emb", "=", "dim_emb", "\n", "self", ".", "dim_trans", "=", "dim_trans", "\n", "self", ".", "cell_class", "=", "cell_class", "\n", "self", ".", "num_units", "=", "num_units", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "lr_rate", "=", "lr_rate", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "\n", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "self", ".", "_init_embed", "(", "word_embed", ",", "kd_embed", ")", "\n", "self", ".", "_init_placeholders", "(", ")", "\n", "self", ".", "_init_vocabs", "(", ")", "\n", "\n", "self", ".", "select_mode", "=", "None", "\n", "if", "self", ".", "use_trans_select", ":", "\n", "            ", "self", ".", "select_layer", "=", "self", ".", "_init_select_layer", "(", "param_dict", "=", "param_dict", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "select_layer", "=", "None", "\n", "\n", "# build model", "\n", "", "self", ".", "ppx_loss", ",", "self", ".", "loss", "=", "self", ".", "build_model", "(", "train_mode", "=", "True", ")", "\n", "self", ".", "generation", "=", "self", ".", "build_model", "(", "train_mode", "=", "False", ")", "\n", "\n", "# construct graphs for minimizing loss", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr_rate", ")", "\n", "self", ".", "params", "=", "tf", ".", "global_variables", "(", ")", "\n", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "loss", ",", "self", ".", "params", ")", "\n", "clipped_gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "self", ".", "max_grad_norm", ")", "\n", "self", ".", "update", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "clipped_gradients", ",", "self", ".", "params", ")", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep._init_vocabs": [[53, 66], ["tensorflow.contrib.lookup.MutableHashTable", "tensorflow.contrib.lookup.MutableHashTable", "tensorflow.contrib.lookup.MutableHashTable", "tensorflow.contrib.lookup.MutableHashTable"], "methods", ["None"], ["", "def", "_init_vocabs", "(", "self", ")", ":", "\n", "        ", "self", ".", "symbol2index", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "string", ",", "value_dtype", "=", "tf", ".", "int64", ",", "\n", "default_value", "=", "UNK_ID", ",", "shared_name", "=", "\"w2id_table\"", ",", "\n", "name", "=", "\"w2id_table\"", ",", "checkpoint", "=", "True", ")", "\n", "self", ".", "index2symbol", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "int64", ",", "value_dtype", "=", "tf", ".", "string", ",", "\n", "default_value", "=", "'_UNK'", ",", "shared_name", "=", "\"id2w_table\"", ",", "\n", "name", "=", "\"id2w_table\"", ",", "checkpoint", "=", "True", ")", "\n", "self", ".", "kd2index", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "string", ",", "value_dtype", "=", "tf", ".", "int64", ",", "\n", "default_value", "=", "NONE_ID", ",", "shared_name", "=", "\"kd2id_table\"", ",", "\n", "name", "=", "\"kd2id_table\"", ",", "checkpoint", "=", "True", ")", "\n", "self", ".", "index2kd", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "int64", ",", "value_dtype", "=", "tf", ".", "string", ",", "\n", "default_value", "=", "'_NONE'", ",", "shared_name", "=", "\"id2kd_table\"", ",", "\n", "name", "=", "\"id2kd_table\"", ",", "checkpoint", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep._init_placeholders": [[67, 76], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "_init_placeholders", "(", "self", ")", ":", "\n", "        ", "self", ".", "posts", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ")", ",", "'post'", ")", "# [batch, len]", "\n", "self", ".", "posts_length", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ")", ",", "'post_lens'", ")", "# batch", "\n", "self", ".", "responses", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ")", ",", "'resp'", ")", "# [batch, len]", "\n", "self", ".", "responses_length", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ")", ",", "'resp_lens'", ")", "# batch", "\n", "self", ".", "corr_responses", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ",", "None", ")", ",", "'corr_resps'", ")", "# [batch, topk, len]", "\n", "self", ".", "triples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ",", "None", ",", "3", ")", ",", "'triples'", ")", "\n", "self", ".", "entities", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ",", "None", ")", ",", "'entities'", ")", "\n", "self", ".", "trans_reprs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "None", ",", "self", ".", "num_units", ")", ",", "'trans_reprs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep._init_embed": [[77, 80], ["tensorflow.get_variable"], "methods", ["None"], ["", "def", "_init_embed", "(", "self", ",", "word_embed", ",", "kd_embed", "=", "None", ")", ":", "\n", "        ", "self", ".", "word_embed", "=", "tf", ".", "get_variable", "(", "'word_embed'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "word_embed", ",", "trainable", "=", "False", ")", "# [vocab_size, dim_emb]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep._init_select_layer": [[81, 113], ["param_dict.keys", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_init_select_layer", "(", "self", ",", "param_dict", ")", ":", "\n", "        ", "\"\"\"\n        :param param_dict: type dict\n        :return: Defined bilinear layer or mlp layer\n        \"\"\"", "\n", "if", "\"bilinear_mat\"", "in", "param_dict", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "select_mode", "=", "'bilinear'", "\n", "\n", "def", "bilinear_layer", "(", "inputs1", ",", "inputs2", ",", "trainable", "=", "False", ")", ":", "\n", "                ", "bilinear_mat", "=", "tf", ".", "get_variable", "(", "'bilinear_mat'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'bilinear_mat'", "]", ",", "trainable", "=", "trainable", ")", "\n", "proj_repr", "=", "tf", ".", "matmul", "(", "inputs2", ",", "bilinear_mat", ")", "\n", "scores", "=", "tf", ".", "reduce_sum", "(", "inputs1", "*", "proj_repr", ",", "axis", "=", "-", "1", ")", "\n", "return", "scores", "\n", "", "return", "bilinear_layer", "\n", "", "else", ":", "\n", "            ", "self", ".", "select_mode", "=", "'mlp'", "\n", "\n", "def", "fully_connected_layer", "(", "inputs", ",", "trainable", "=", "False", ")", ":", "\n", "                ", "fc1_weights", "=", "tf", ".", "get_variable", "(", "'fc1_weights'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc1_weights'", "]", ",", "trainable", "=", "trainable", ")", "\n", "fc1_biases", "=", "tf", ".", "get_variable", "(", "'fc1_biases'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc1_biases'", "]", ",", "trainable", "=", "trainable", ")", "\n", "hidden_outs", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "inputs", ",", "fc1_weights", ")", "+", "fc1_biases", ")", "\n", "\n", "fc2_weights", "=", "tf", ".", "get_variable", "(", "'fc2_weights'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc2_weights'", "]", ",", "trainable", "=", "trainable", ")", "\n", "fc2_biases", "=", "tf", ".", "get_variable", "(", "'fc2_biases'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc2_biases'", "]", ",", "trainable", "=", "trainable", ")", "\n", "scores", "=", "tf", ".", "matmul", "(", "hidden_outs", ",", "fc2_weights", ")", "+", "fc2_biases", "\n", "return", "scores", "\n", "", "return", "fully_connected_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.build_model": [[114, 183], ["model_multistep.TransDGModelMultistep.symbol2index.lookup", "tensorflow.nn.embedding_lookup", "model_multistep.TransDGModelMultistep.symbol2index.lookup", "tensorflow.nn.embedding_lookup", "model_multistep.TransDGModelMultistep.symbol2index.lookup", "tensorflow.nn.embedding_lookup", "tensorflow.reshape", "tensorflow.reduce_mean", "model_multistep.TransDGModelMultistep.build_encoder", "tensorflow.shape", "tensorflow.shape", "model_multistep.TransDGModelMultistep.symbol2index.lookup", "tensorflow.concat", "tensorflow.nn.embedding_lookup", "tensorflow.reshape", "tensorflow.unique", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.reshape", "tensorflow.stack", "tensorflow.floor", "model_multistep.TransDGModelMultistep.build_decoder", "seq_helper.sequence_loss", "seq_helper.sequence_loss", "seq_helper.sentence_ppx", "seq_helper.sentence_ppx", "tensorflow.identity", "tensorflow.identity", "model_multistep.TransDGModelMultistep.build_decoder", "tensorflow.argmax", "model_multistep.TransDGModelMultistep.index2symbol.lookup", "tensorflow.identity", "tensorflow.shape", "tensorflow.cumsum", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.one_hot", "tensorflow.size", "tensorflow.range", "tensorflow.gather_nd", "tensorflow.ones", "tensorflow.split"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_encoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sequence_loss", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sequence_loss", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sentence_ppx", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sentence_ppx", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_decoder"], ["", "", "def", "build_model", "(", "self", ",", "train_mode", "=", "True", ")", ":", "\n", "# build the vocab table (string to index)", "\n", "        ", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "0", "]", "\n", "post_word_id", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "posts", ")", "\n", "post_word_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "post_word_id", ")", "# [batch, len, unit]", "\n", "\n", "corr_responses_id", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "corr_responses", ")", "# [batch, topk, len]", "\n", "corr_responses_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "corr_responses_id", ")", "# [batch, topk, len, unit]", "\n", "\n", "triple_id", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "triples", ")", "\n", "triple_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "triple_id", ")", "\n", "triple_num", "=", "tf", ".", "shape", "(", "self", ".", "triples", ")", "[", "1", "]", "\n", "triple_input", "=", "tf", ".", "reshape", "(", "triple_input", ",", "[", "batch_size", ",", "triple_num", ",", "-", "1", ",", "3", "*", "self", ".", "dim_emb", "]", ")", "\n", "triple_input", "=", "tf", ".", "reduce_mean", "(", "triple_input", ",", "axis", "=", "2", ")", "# [batch, triple_num, 3*dim_emb]", "\n", "\n", "encoder_output", ",", "encoder_state", "=", "self", ".", "build_encoder", "(", "post_word_input", ",", "\n", "corr_responses_input", ",", "\n", "train_mode", "=", "train_mode", ")", "\n", "\n", "if", "train_mode", ":", "\n", "            ", "resp_target", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "responses", ")", "\n", "decoder_len", "=", "tf", ".", "shape", "(", "self", ".", "responses", ")", "[", "1", "]", "\n", "resp_word_id", "=", "tf", ".", "concat", "(", "[", "tf", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "*", "GO_ID", ",", "\n", "tf", ".", "split", "(", "resp_target", ",", "[", "decoder_len", "-", "1", ",", "1", "]", ",", "1", ")", "[", "0", "]", "]", ",", "1", ")", "# [batch,len]", "\n", "resp_word_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "resp_word_id", ")", "# [batch, len, unit]", "\n", "decoder_mask", "=", "tf", ".", "reshape", "(", "tf", ".", "cumsum", "(", "\n", "tf", ".", "one_hot", "(", "self", ".", "responses_length", "-", "1", ",", "decoder_len", ")", ",", "reverse", "=", "True", ",", "axis", "=", "1", ")", ",", "\n", "[", "-", "1", ",", "decoder_len", "]", ")", "\n", "\n", "\n", "uniq_ids", ",", "indices", "=", "tf", ".", "unique", "(", "tf", ".", "reshape", "(", "resp_word_id", ",", "[", "-", "1", "]", ")", ")", "\n", "\n", "# independent sample for each instance", "\n", "rand_mask", "=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "tf", ".", "size", "(", "uniq_ids", ")", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# prepare indices for tf.gather_nd", "\n", "batch_wise", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "axis", "=", "-", "1", ")", ",", "[", "1", ",", "decoder_len", "]", ")", "\n", "uniq_ids_wise", "=", "tf", ".", "reshape", "(", "indices", ",", "[", "batch_size", ",", "decoder_len", "]", ")", "\n", "\n", "# gather mask and convert it to binary mask", "\n", "mask_indices", "=", "tf", ".", "stack", "(", "[", "batch_wise", ",", "uniq_ids_wise", "]", ",", "axis", "=", "-", "1", ")", "\n", "binary_mask", "=", "tf", ".", "floor", "(", "tf", ".", "gather_nd", "(", "rand_mask", ",", "mask_indices", ")", "+", "0.5", ")", "\n", "\n", "# apply mask", "\n", "resp_word_dropped", "=", "resp_word_input", "*", "tf", ".", "expand_dims", "(", "binary_mask", ",", "axis", "=", "-", "1", ")", "\n", "\n", "\n", "output_logits1", ",", "output_logits2", "=", "self", ".", "build_decoder", "(", "encoder_output", ",", "encoder_state", ",", "\n", "triple_input", ",", "resp_word_input", ",", "resp_word_dropped", ",", "\n", "train_mode", "=", "train_mode", ")", "\n", "\n", "seq_loss1", "=", "sequence_loss", "(", "self", ".", "vocab_size", ",", "output_logits1", ",", "resp_target", ",", "decoder_mask", ")", "\n", "seq_loss2", "=", "sequence_loss", "(", "self", ".", "vocab_size", ",", "output_logits2", ",", "resp_target", ",", "decoder_mask", ")", "\n", "sent_ppx1", "=", "sentence_ppx", "(", "self", ".", "vocab_size", ",", "output_logits1", ",", "resp_target", ",", "decoder_mask", ")", "\n", "sent_ppx2", "=", "sentence_ppx", "(", "self", ".", "vocab_size", ",", "output_logits2", ",", "resp_target", ",", "decoder_mask", ")", "\n", "sent_ppx", "=", "(", "sent_ppx1", "+", "sent_ppx2", ")", "*", "0.5", "\n", "ppx_loss", "=", "tf", ".", "identity", "(", "sent_ppx", ",", "name", "=", "\"ppx_loss\"", ")", "\n", "seq_loss", "=", "seq_loss1", "+", "seq_loss2", "\n", "loss", "=", "tf", ".", "identity", "(", "seq_loss", ",", "name", "=", "\"loss\"", ")", "\n", "return", "ppx_loss", ",", "loss", "\n", "", "else", ":", "\n", "\n", "            ", "decoder_dist", "=", "self", ".", "build_decoder", "(", "encoder_output", ",", "encoder_state", ",", "\n", "triple_input", ",", "decoder_input", "=", "None", ",", "decoder_dropped", "=", "None", ",", "\n", "train_mode", "=", "False", ")", "\n", "generation_index", "=", "tf", ".", "argmax", "(", "decoder_dist", ",", "2", ")", "\n", "generation", "=", "self", ".", "index2symbol", ".", "lookup", "(", "generation_index", ")", "\n", "generation", "=", "tf", ".", "identity", "(", "generation", ",", "name", "=", "'generation'", ")", "\n", "return", "generation", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.build_encoder": [[184, 233], ["seq_helper.define_rnn_cell", "print", "tensorflow.variable_scope", "tensorflow.nn.dynamic_rnn", "tensorflow.reshape", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.get_variable", "tensorflow.reduce_sum", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.tanh", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.define_rnn_cell"], ["", "", "def", "build_encoder", "(", "self", ",", "post_word_input", ",", "corr_responses_input", ",", "train_mode", "=", "True", ")", ":", "\n", "        ", "if", "train_mode", ":", "\n", "            ", "keep_prob", "=", "1.0", "-", "self", ".", "drop_rate", "\n", "", "else", ":", "\n", "            ", "keep_prob", "=", "1.0", "\n", "", "encoder_cell", "=", "define_rnn_cell", "(", "cell_class", "=", "self", ".", "cell_class", ",", "num_units", "=", "self", ".", "num_units", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "keep_prob", "=", "keep_prob", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "            ", "encoder_output", ",", "encoder_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "encoder_cell", ",", "\n", "post_word_input", ",", "\n", "self", ".", "posts_length", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "scope", "=", "scope", ")", "\n", "", "if", "self", ".", "use_guiding", ":", "\n", "            ", "batch_size", ",", "encoder_len", "=", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "1", "]", "\n", "corr_response_input", "=", "tf", ".", "reshape", "(", "corr_responses_input", ",", "[", "batch_size", ",", "-", "1", ",", "self", ".", "dim_emb", "]", ")", "\n", "corr_cum_len", "=", "tf", ".", "shape", "(", "corr_response_input", ")", "[", "1", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'mutual_attention'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "encoder_out_trans", "=", "tf", ".", "layers", ".", "dense", "(", "encoder_output", ",", "self", ".", "num_units", ",", "\n", "name", "=", "'encoder_out_transform'", ")", "\n", "corr_response_trans", "=", "tf", ".", "layers", ".", "dense", "(", "corr_response_input", ",", "self", ".", "num_units", ",", "\n", "name", "=", "'corr_response_transform'", ")", "\n", "encoder_out_trans", "=", "tf", ".", "expand_dims", "(", "encoder_out_trans", ",", "axis", "=", "1", ")", "\n", "encoder_out_trans", "=", "tf", ".", "tile", "(", "encoder_out_trans", ",", "[", "1", ",", "corr_cum_len", ",", "1", ",", "1", "]", ")", "\n", "encoder_out_trans", "=", "tf", ".", "reshape", "(", "encoder_out_trans", ",", "[", "-", "1", ",", "encoder_len", ",", "self", ".", "num_units", "]", ")", "\n", "\n", "corr_response_trans", "=", "tf", ".", "reshape", "(", "corr_response_trans", ",", "[", "-", "1", ",", "self", ".", "num_units", "]", ")", "\n", "corr_response_trans", "=", "tf", ".", "expand_dims", "(", "corr_response_trans", ",", "axis", "=", "1", ")", "\n", "\n", "# TODO: try bilinear attention", "\n", "v", "=", "tf", ".", "get_variable", "(", "\"attention_v\"", ",", "[", "self", ".", "num_units", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "score", "=", "tf", ".", "reduce_sum", "(", "v", "*", "tf", ".", "tanh", "(", "encoder_out_trans", "+", "corr_response_trans", ")", ",", "axis", "=", "2", ")", "\n", "alignments", "=", "tf", ".", "nn", ".", "softmax", "(", "score", ")", "\n", "\n", "encoder_out_tiled", "=", "tf", ".", "expand_dims", "(", "encoder_output", ",", "axis", "=", "1", ")", "\n", "encoder_out_tiled", "=", "tf", ".", "tile", "(", "encoder_out_tiled", ",", "[", "1", ",", "corr_cum_len", ",", "1", ",", "1", "]", ")", "\n", "encoder_out_tiled", "=", "tf", ".", "reshape", "(", "encoder_out_tiled", ",", "[", "-", "1", ",", "encoder_len", ",", "self", ".", "num_units", "]", ")", "\n", "\n", "context_mutual", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "expand_dims", "(", "alignments", ",", "2", ")", "*", "encoder_out_tiled", ",", "axis", "=", "1", ")", "\n", "context_mutual", "=", "tf", ".", "reshape", "(", "context_mutual", ",", "[", "batch_size", ",", "-", "1", ",", "self", ".", "num_units", "]", ")", "\n", "context_mutual", "=", "tf", ".", "reduce_mean", "(", "context_mutual", ",", "axis", "=", "1", ")", "# [batch, num_units]", "\n", "", "encoder_output", "=", "tf", ".", "concat", "(", "[", "encoder_output", ",", "tf", ".", "expand_dims", "(", "context_mutual", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "trans_output", "=", "tf", ".", "layers", ".", "dense", "(", "self", ".", "trans_reprs", ",", "self", ".", "num_units", ",", "\n", "name", "=", "'trans_reprs_transform'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "encoder_output", "=", "tf", ".", "concat", "(", "[", "encoder_output", ",", "trans_output", "]", ",", "axis", "=", "1", ")", "\n", "", "print", "(", "\"encoder_output:\"", ",", "encoder_output", ".", "shape", ")", "\n", "return", "encoder_output", ",", "encoder_state", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.build_decoder": [[234, 340], ["seq_helper.define_rnn_cell", "seq_helper.define_rnn_cell", "tensorflow.variable_scope", "attention_decoder.prepare_attention", "attention_decoder.attention_decoder_train", "dynamic_decoder.dynamic_rnn_decoder", "attention_decoder.create_output_fn", "attention_decoder.create_output_fn.", "tensorflow.variable_scope", "attention_decoder.prepare_multistep_attention", "attention_decoder.attention_decoder_train", "dynamic_decoder.dynamic_rnn_decoder", "attention_decoder.create_output_fn", "attention_decoder.create_output_fn.", "tensorflow.variable_scope", "attention_decoder.prepare_attention", "attention_decoder.create_output_fn", "attention_decoder.attention_decoder_inference", "dynamic_decoder.dynamic_rnn_decoder", "tensorflow.variable_scope", "attention_decoder.prepare_multistep_attention", "attention_decoder.create_output_fn", "attention_decoder.attention_decoder_inference", "dynamic_decoder.dynamic_rnn_decoder", "model_multistep.TransDGModelMultistep.transfer_matching", "model_multistep.TransDGModelMultistep.transfer_matching", "model_multistep.TransDGModelMultistep.transfer_matching", "model_multistep.TransDGModelMultistep.transfer_matching"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.define_rnn_cell", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.define_rnn_cell", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_attention", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_train", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.dynamic_decoder.dynamic_rnn_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_output_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_multistep_attention", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_train", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.dynamic_decoder.dynamic_rnn_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_output_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_attention", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_output_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_inference", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.dynamic_decoder.dynamic_rnn_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_multistep_attention", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_output_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_inference", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.dynamic_decoder.dynamic_rnn_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.transfer_matching", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.transfer_matching", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.transfer_matching", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.transfer_matching"], ["", "def", "build_decoder", "(", "self", ",", "encoder_output", ",", "encoder_state", ",", "triple_input", ",", "decoder_input", ",", "decoder_dropped", ",", "train_mode", "=", "True", ")", ":", "\n", "        ", "if", "train_mode", ":", "\n", "            ", "keep_prob", "=", "1.0", "-", "self", ".", "drop_rate", "\n", "", "else", ":", "\n", "            ", "keep_prob", "=", "1.0", "\n", "", "decoder_cell_step1", "=", "define_rnn_cell", "(", "cell_class", "=", "self", ".", "cell_class", ",", "num_units", "=", "self", ".", "num_units", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "keep_prob", "=", "keep_prob", ")", "\n", "decoder_cell_step2", "=", "define_rnn_cell", "(", "cell_class", "=", "self", ".", "cell_class", ",", "num_units", "=", "self", ".", "num_units", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "keep_prob", "=", "keep_prob", ")", "\n", "\n", "if", "train_mode", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'decoder_step1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope1", ":", "\n", "                ", "if", "self", ".", "use_trans_select", ":", "\n", "                    ", "kd_context1", "=", "self", ".", "transfer_matching", "(", "encoder_output", ",", "triple_input", ")", "\n", "", "else", ":", "\n", "                    ", "kd_context1", "=", "None", "\n", "\n", "# prepare attention", "\n", "", "attention_keys1", ",", "attention_values1", ",", "attention_construct_fn1", "=", "prepare_attention", "(", "encoder_output", ",", "kd_context1", ",", "'luong'", ",", "self", ".", "num_units", ")", "\n", "\n", "decoder_fn_train1", "=", "attention_decoder_train", "(", "\n", "encoder_state", "=", "encoder_state", ",", "\n", "attention_keys", "=", "attention_keys1", ",", "\n", "attention_values", "=", "attention_values1", ",", "\n", "attention_construct_fn", "=", "attention_construct_fn1", ")", "\n", "\n", "# train decoder step1", "\n", "decoder_output1", ",", "_", ",", "_", "=", "dynamic_rnn_decoder", "(", "cell", "=", "decoder_cell_step1", ",", "\n", "decoder_fn", "=", "decoder_fn_train1", ",", "\n", "inputs", "=", "decoder_dropped", ",", "\n", "sequence_length", "=", "self", ".", "responses_length", ",", "\n", "scope", "=", "scope1", ")", "\n", "output_fn1", "=", "create_output_fn", "(", "vocab_size", "=", "self", ".", "vocab_size", ")", "\n", "output_logits1", "=", "output_fn1", "(", "decoder_output1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'decoder_step2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope2", ":", "\n", "                ", "if", "self", ".", "use_trans_select", ":", "\n", "                    ", "kd_context2", "=", "self", ".", "transfer_matching", "(", "decoder_output1", ",", "triple_input", ")", "\n", "", "else", ":", "\n", "                    ", "kd_context2", "=", "None", "\n", "", "attention_keys2", ",", "attention_values2", ",", "attention_construct_fn2", "=", "prepare_multistep_attention", "(", "encoder_output", ",", "decoder_output1", ",", "\n", "kd_context1", ",", "kd_context2", ",", "\n", "'luong'", ",", "self", ".", "num_units", ")", "\n", "decoder_fn_train2", "=", "attention_decoder_train", "(", "\n", "encoder_state", "=", "encoder_state", ",", "\n", "attention_keys", "=", "attention_keys2", ",", "\n", "attention_values", "=", "attention_values2", ",", "\n", "attention_construct_fn", "=", "attention_construct_fn2", ")", "\n", "# train decoder step2", "\n", "decoder_output2", ",", "_", ",", "_", "=", "dynamic_rnn_decoder", "(", "cell", "=", "decoder_cell_step2", ",", "\n", "decoder_fn", "=", "decoder_fn_train2", ",", "\n", "inputs", "=", "decoder_input", ",", "\n", "sequence_length", "=", "self", ".", "responses_length", ",", "\n", "scope", "=", "scope2", ")", "\n", "output_fn2", "=", "create_output_fn", "(", "vocab_size", "=", "self", ".", "vocab_size", ")", "\n", "output_logits2", "=", "output_fn2", "(", "decoder_output2", ")", "\n", "return", "output_logits1", ",", "output_logits2", "\n", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'decoder_step1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope1", ":", "\n", "                ", "if", "self", ".", "use_trans_select", ":", "\n", "                    ", "kd_context1", "=", "self", ".", "transfer_matching", "(", "encoder_output", ",", "triple_input", ")", "\n", "", "else", ":", "\n", "                    ", "kd_context1", "=", "None", "\n", "", "attention_keys1", ",", "attention_values1", ",", "attention_construct_fn1", "=", "prepare_attention", "(", "encoder_output", ",", "kd_context1", ",", "'luong'", ",", "self", ".", "num_units", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "output_fn1", "=", "create_output_fn", "(", "vocab_size", "=", "self", ".", "vocab_size", ")", "\n", "# inference decoder step 1", "\n", "decoder_hidden_inference1", "=", "attention_decoder_inference", "(", "\n", "num_units", "=", "self", ".", "num_units", ",", "num_decoder_symbols", "=", "self", ".", "vocab_size", ",", "\n", "output_fn", "=", "output_fn1", ",", "encoder_state", "=", "encoder_state", ",", "\n", "attention_keys", "=", "attention_keys1", ",", "attention_values", "=", "attention_values1", ",", "\n", "attention_construct_fn", "=", "attention_construct_fn1", ",", "embeddings", "=", "self", ".", "word_embed", ",", "\n", "start_of_sequence_id", "=", "GO_ID", ",", "end_of_sequence_id", "=", "EOS_ID", ",", "maximum_length", "=", "self", ".", "max_length", ",", "\n", "is_pass1", "=", "True", "\n", ")", "\n", "# get decoder hidden output", "\n", "decoder_hidden1", ",", "_", ",", "_", "=", "dynamic_rnn_decoder", "(", "cell", "=", "decoder_cell_step1", ",", "\n", "decoder_fn", "=", "decoder_hidden_inference1", ",", "\n", "scope", "=", "scope1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'decoder_step2'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope2", ":", "\n", "                ", "if", "self", ".", "use_trans_select", ":", "\n", "                    ", "kd_context2", "=", "self", ".", "transfer_matching", "(", "decoder_hidden1", ",", "triple_input", ")", "\n", "", "else", ":", "\n", "                    ", "kd_context2", "=", "None", "\n", "", "attention_keys2", ",", "attention_values2", ",", "attention_construct_fn2", "=", "prepare_multistep_attention", "(", "encoder_output", ",", "decoder_hidden1", ",", "\n", "kd_context1", ",", "kd_context2", ",", "\n", "'luong'", ",", "self", ".", "num_units", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "output_fn2", "=", "create_output_fn", "(", "vocab_size", "=", "self", ".", "vocab_size", ")", "\n", "# inference decoder", "\n", "decoder_fn_inference2", "=", "attention_decoder_inference", "(", "\n", "num_units", "=", "self", ".", "num_units", ",", "num_decoder_symbols", "=", "self", ".", "vocab_size", ",", "\n", "output_fn", "=", "output_fn2", ",", "encoder_state", "=", "encoder_state", ",", "\n", "attention_keys", "=", "attention_keys2", ",", "attention_values", "=", "attention_values2", ",", "\n", "attention_construct_fn", "=", "attention_construct_fn2", ",", "embeddings", "=", "self", ".", "word_embed", ",", "\n", "start_of_sequence_id", "=", "GO_ID", ",", "end_of_sequence_id", "=", "EOS_ID", ",", "maximum_length", "=", "self", ".", "max_length", "\n", ")", "\n", "# get decoder output", "\n", "decoder_distribution", ",", "_", ",", "_", "=", "dynamic_rnn_decoder", "(", "\n", "cell", "=", "decoder_cell_step2", ",", "decoder_fn", "=", "decoder_fn_inference2", ",", "scope", "=", "scope2", "\n", ")", "\n", "return", "decoder_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.transfer_matching": [[341, 363], ["tensorflow.reduce_mean", "tensorflow.tile", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.reshape", "model_multistep.TransDGModelMultistep.select_layer", "tensorflow.concat", "tensorflow.reshape", "model_multistep.TransDGModelMultistep.select_layer", "tensorflow.shape", "tensorflow.expand_dims"], "methods", ["None"], ["", "", "", "def", "transfer_matching", "(", "self", ",", "context_repr", ",", "knowledge_repr", ")", ":", "\n", "        ", "context", "=", "tf", ".", "reduce_mean", "(", "context_repr", ",", "axis", "=", "1", ")", "# [batch, num_units]", "\n", "kd_num", "=", "tf", ".", "shape", "(", "knowledge_repr", ")", "[", "1", "]", "\n", "context_tile", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "context", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "kd_num", ",", "1", "]", ")", "# [batch, kd_num, num_units]", "\n", "\n", "knowledge", "=", "tf", ".", "layers", ".", "dense", "(", "knowledge_repr", ",", "self", ".", "dim_emb", ",", "\n", "name", "=", "'knowledge_transform'", ")", "# [batch, kd_num, dim_emb]", "\n", "\n", "if", "self", ".", "select_mode", "==", "'bilinear'", ":", "\n", "            ", "context_reshaped", "=", "tf", ".", "reshape", "(", "context_tile", ",", "[", "-", "1", ",", "self", ".", "num_units", "]", ")", "\n", "knowledge_reshaped", "=", "tf", ".", "reshape", "(", "knowledge", ",", "[", "-", "1", ",", "self", ".", "dim_emb", "]", ")", "\n", "em_scores", "=", "self", ".", "select_layer", "(", "context_reshaped", ",", "knowledge_reshaped", ")", "\n", "", "else", ":", "\n", "            ", "concat_repr", "=", "tf", ".", "concat", "(", "[", "context_tile", ",", "knowledge", "]", ",", "axis", "=", "-", "1", ")", "# [batch, kd_num, num_units+dim_emb]", "\n", "concat_repr_reshaped", "=", "tf", ".", "reshape", "(", "concat_repr", ",", "[", "-", "1", ",", "self", ".", "num_units", "+", "self", ".", "dim_emb", "]", ")", "\n", "em_scores", "=", "self", ".", "select_layer", "(", "concat_repr_reshaped", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "0", "]", "\n", "em_scores", "=", "tf", ".", "reshape", "(", "em_scores", ",", "[", "batch_size", ",", "kd_num", "]", ")", "\n", "kd_context", "=", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "em_scores", ",", "axis", "=", "1", ")", ",", "knowledge", ")", "\n", "kd_context", "=", "tf", ".", "reshape", "(", "kd_context", ",", "[", "batch_size", ",", "self", ".", "dim_emb", "]", ")", "# [batch, dim_emb]", "\n", "return", "kd_context", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.set_vocabs": [[364, 377], ["model_multistep.TransDGModelMultistep.symbol2index.insert", "session.run", "model_multistep.TransDGModelMultistep.index2symbol.insert", "session.run", "model_multistep.TransDGModelMultistep.kd2index.insert", "session.run", "model_multistep.TransDGModelMultistep.index2kd.insert", "session.run", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "list", "list", "list", "list", "range", "range", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "set_vocabs", "(", "self", ",", "session", ",", "vocab", ",", "kd_vocab", ")", ":", "\n", "        ", "op_in", "=", "self", ".", "symbol2index", ".", "insert", "(", "tf", ".", "constant", "(", "vocab", ")", ",", "\n", "tf", ".", "constant", "(", "list", "(", "range", "(", "self", ".", "vocab_size", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "session", ".", "run", "(", "op_in", ")", "\n", "op_out", "=", "self", ".", "index2symbol", ".", "insert", "(", "tf", ".", "constant", "(", "list", "(", "range", "(", "self", ".", "vocab_size", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "tf", ".", "constant", "(", "vocab", ")", ")", "\n", "session", ".", "run", "(", "op_out", ")", "\n", "op_in", "=", "self", ".", "kd2index", ".", "insert", "(", "tf", ".", "constant", "(", "kd_vocab", ")", ",", "\n", "tf", ".", "constant", "(", "list", "(", "range", "(", "len", "(", "kd_vocab", ")", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "session", ".", "run", "(", "op_in", ")", "\n", "op_out", "=", "self", ".", "index2kd", ".", "insert", "(", "tf", ".", "constant", "(", "list", "(", "range", "(", "len", "(", "kd_vocab", ")", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "tf", ".", "constant", "(", "kd_vocab", ")", ")", "\n", "session", ".", "run", "(", "op_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.show_parameters": [[378, 381], ["print", "var.get_shape().as_list", "var.get_shape"], "methods", ["None"], ["", "def", "show_parameters", "(", "self", ")", ":", "\n", "        ", "for", "var", "in", "self", ".", "params", ":", "\n", "            ", "print", "(", "\"%s: %s\"", "%", "(", "var", ".", "name", ",", "var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.train_batch": [[382, 397], ["session.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "", "def", "train_batch", "(", "self", ",", "session", ",", "data", ",", "trans_reprs", ")", ":", "\n", "        ", "input_feed", "=", "{", "self", ".", "posts", ":", "data", "[", "'post'", "]", ",", "\n", "self", ".", "posts_length", ":", "data", "[", "'post_len'", "]", ",", "\n", "self", ".", "responses", ":", "data", "[", "'response'", "]", ",", "\n", "self", ".", "responses_length", ":", "data", "[", "'response_len'", "]", ",", "\n", "self", ".", "corr_responses", ":", "data", "[", "'corr_responses'", "]", ",", "\n", "self", ".", "triples", ":", "data", "[", "'all_triples'", "]", ",", "\n", "self", ".", "entities", ":", "data", "[", "'all_entities'", "]", "\n", "}", "\n", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "input_feed", "[", "self", ".", "trans_reprs", "]", "=", "trans_reprs", "\n", "\n", "", "output_feed", "=", "[", "self", ".", "ppx_loss", ",", "self", ".", "loss", ",", "self", ".", "update", "]", "\n", "outputs", "=", "session", ".", "run", "(", "output_feed", ",", "feed_dict", "=", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.eval_batch": [[398, 413], ["session.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "eval_batch", "(", "self", ",", "session", ",", "data", ",", "trans_reprs", ")", ":", "\n", "        ", "input_feed", "=", "{", "self", ".", "posts", ":", "data", "[", "'post'", "]", ",", "\n", "self", ".", "posts_length", ":", "data", "[", "'post_len'", "]", ",", "\n", "self", ".", "responses", ":", "data", "[", "'response'", "]", ",", "\n", "self", ".", "responses_length", ":", "data", "[", "'response_len'", "]", ",", "\n", "self", ".", "corr_responses", ":", "data", "[", "'corr_responses'", "]", ",", "\n", "self", ".", "triples", ":", "data", "[", "'all_triples'", "]", ",", "\n", "self", ".", "entities", ":", "data", "[", "'all_entities'", "]", "\n", "}", "\n", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "input_feed", "[", "self", ".", "trans_reprs", "]", "=", "trans_reprs", "\n", "\n", "", "output_feed", "=", "[", "self", ".", "ppx_loss", ",", "self", ".", "loss", "]", "\n", "outputs", "=", "session", ".", "run", "(", "output_feed", ",", "feed_dict", "=", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model_multistep.TransDGModelMultistep.decode_batch": [[414, 429], ["session.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "decode_batch", "(", "self", ",", "session", ",", "data", ",", "trans_reprs", ")", ":", "\n", "        ", "input_feed", "=", "{", "self", ".", "posts", ":", "data", "[", "'post'", "]", ",", "\n", "self", ".", "posts_length", ":", "data", "[", "'post_len'", "]", ",", "\n", "self", ".", "responses", ":", "data", "[", "'response'", "]", ",", "\n", "self", ".", "responses_length", ":", "data", "[", "'response_len'", "]", ",", "\n", "self", ".", "corr_responses", ":", "data", "[", "'corr_responses'", "]", ",", "\n", "self", ".", "triples", ":", "data", "[", "'all_triples'", "]", ",", "\n", "self", ".", "entities", ":", "data", "[", "'all_entities'", "]", "\n", "}", "\n", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "input_feed", "[", "self", ".", "trans_reprs", "]", "=", "trans_reprs", "\n", "\n", "", "output_feed", "=", "[", "self", ".", "generation", ",", "self", ".", "ppx_loss", ",", "self", ".", "loss", "]", "\n", "outputs", "=", "session", ".", "run", "(", "output_feed", ",", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", ",", "outputs", "[", "-", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.bahdanau_attention": [[5, 16], ["tensorflow.variable_scope", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tf.layers.Dense.", "tf.layers.Dense.", "attention._bahdanau_score", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention._bahdanau_score"], ["\n", "\n", "class", "Attention", ":", "\n", "    ", "\"\"\"\n    Implementation of different attentions\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "lf_max_len", ",", "dim_att_hidden", ",", "att_func", ")", ":", "\n", "        ", "self", ".", "lf_max_len", "=", "lf_max_len", "\n", "self", ".", "dim_att_hidden", "=", "dim_att_hidden", "\n", "LogInfo", ".", "logs", "(", "'Attention: lf_max_len = %d, dim_att_hidden = %d, att_func = %s.'", ",", "\n", "lf_max_len", ",", "dim_att_hidden", ",", "att_func", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention.luong_attention": [[18, 27], ["tensorflow.variable_scope", "tensorflow.layers.Dense", "tf.layers.Dense.", "attention._luong_score", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention._luong_score"], ["self", ".", "att_func", "=", "'attn_%s'", "%", "att_func", "\n", "\n", "", "def", "forward", "(", "self", ",", "lf_input", ",", "lf_mask", ",", "fix_rt_input", ")", ":", "\n", "        ", "\"\"\"\n        :param lf_input:        (ds, lf_max_len, dim_hidden)\n        :param lf_mask:         (ds, lf_max_len) as float32\n        :param fix_rt_input:    (ds, dim_hidden), no timestamps\n        \"\"\"", "\n", "rt_input", "=", "tf", ".", "expand_dims", "(", "fix_rt_input", ",", "axis", "=", "1", ",", "name", "=", "'rt_input'", ")", "# (ds, 1, dim_hidden)", "\n", "with", "tf", ".", "variable_scope", "(", "'simple_att'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention._bahdanau_score": [[29, 55], ["tensorflow.expand_dims", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.rsqrt", "tensorflow.sqrt", "tensorflow.zeros_initializer", "tensorflow.reduce_sum", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.square"], "function", ["None"], ["lf_max_len", "=", "self", ".", "lf_max_len", ",", "rt_max_len", "=", "1", ",", "\n", "dim_att_hidden", "=", "self", ".", "dim_att_hidden", ")", "# (ds, lf_max_len, 1)", "\n", "raw_att_mat", "=", "tf", ".", "reshape", "(", "raw_att_mat", ",", "shape", "=", "[", "-", "1", ",", "self", ".", "lf_max_len", "]", ",", "name", "=", "'raw_att_mat'", ")", "\n", "# (ds, lf_max_len)", "\n", "\n", "masked_att_mat", "=", "raw_att_mat", "*", "lf_mask", "+", "tf", ".", "float32", ".", "min", "*", "(", "1.", "-", "lf_mask", ")", "\n", "lf_norm", "=", "tf", ".", "nn", ".", "softmax", "(", "masked_att_mat", ",", "name", "=", "'lf_norm'", ")", "# (ds, lf_max_len)", "\n", "lf_weighted", "=", "tf", ".", "expand_dims", "(", "lf_norm", ",", "axis", "=", "2", ")", "*", "lf_input", "# (ds, lf_max_len, dim_hidden)", "\n", "lf_weighted", "=", "tf", ".", "reduce_sum", "(", "lf_weighted", ",", "axis", "=", "1", ",", "\n", "name", "=", "'lf_weighted'", ")", "# (ds, dim_hidden)", "\n", "\n", "", "return", "lf_weighted", ",", "raw_att_mat", ",", "lf_norm", "\n", "\n", "\n", "", "", "def", "expand_both_dims", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ")", ":", "\n", "    ", "\"\"\"\n    lf_input:   (ds, lf_max_len, dim_emb)\n    rt_input:   (ds, rt_max_len, dim_emb)\n    \"\"\"", "\n", "expand_lf_input", "=", "tf", ".", "stack", "(", "[", "lf_input", "]", "*", "rt_max_len", ",", "axis", "=", "2", ",", "\n", "name", "=", "'expand_lf_input'", ")", "# (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "expand_rt_input", "=", "tf", ".", "stack", "(", "[", "rt_input", "]", "*", "lf_max_len", ",", "axis", "=", "1", ",", "\n", "name", "=", "'expand_rt_input'", ")", "# (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "return", "expand_lf_input", ",", "expand_rt_input", "\n", "\n", "\n", "", "def", "attn_dot", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ",", "dim_att_hidden", ")", ":", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention._luong_score": [[57, 89], ["tensorflow.expand_dims", "tensorflow.matmul", "tensorflow.squeeze", "tensorflow.get_variable"], "function", ["None"], ["\n", "assert", "dim_att_hidden", "is", "not", "None", "\n", "expand_lf_input", ",", "expand_rt_input", "=", "expand_both_dims", "(", "\n", "lf_input", "=", "lf_input", ",", "rt_input", "=", "rt_input", ",", "\n", "lf_max_len", "=", "lf_max_len", ",", "rt_max_len", "=", "rt_max_len", "\n", ")", "# both (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "att_mat", "=", "tf", ".", "reduce_sum", "(", "expand_lf_input", "*", "expand_rt_input", ",", "axis", "=", "-", "1", ",", "\n", "name", "=", "'att_mat'", ")", "# (ds, lf_max_len, rt_max_len)", "\n", "return", "att_mat", "\n", "\n", "\n", "", "def", "attn_bilinear", "(", "lf_input", ",", "rt_input", ",", "lf_max_len", ",", "rt_max_len", ",", "dim_att_hidden", ")", ":", "\n", "    ", "\"\"\"\n    bilinear: a = x_1 . W . x_2\n    dim_att_hidden should be equal with dim_hidden,\n    otherwise, matmul couldn't work properly\n    \"\"\"", "\n", "expand_lf_input", ",", "expand_rt_input", "=", "expand_both_dims", "(", "\n", "lf_input", "=", "lf_input", ",", "rt_input", "=", "rt_input", ",", "\n", "lf_max_len", "=", "lf_max_len", ",", "rt_max_len", "=", "rt_max_len", "\n", ")", "# both (ds, lf_max_len, rt_max_len, dim_emb)", "\n", "with", "tf", ".", "variable_scope", "(", "'cross_att_bilinear'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "name", "=", "'w'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "dim_att_hidden", ",", "dim_att_hidden", "]", ")", "\n", "att_mat", "=", "tf", ".", "reduce_sum", "(", "\n", "input_tensor", "=", "tf", ".", "multiply", "(", "\n", "x", "=", "tf", ".", "matmul", "(", "expand_lf_input", ",", "w", ")", ",", "\n", "y", "=", "expand_rt_input", "# both (ds, lf_max_len, rt_max_len, dim_att_hidden==dim_emb)", "\n", ")", ",", "axis", "=", "-", "1", ",", "name", "=", "'att_mat'", "\n", ")", "# (ds, lf_max_len, rt_max_len)", "\n", "", "return", "att_mat", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.__init__": [[13, 52], ["tensorflow.Variable", "model.TransDGModel._init_embed", "model.TransDGModel._init_placeholders", "model.TransDGModel._init_vocabs", "model.TransDGModel.build_model", "model.TransDGModel.build_model", "tensorflow.train.AdamOptimizer", "tensorflow.global_variables", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "model.TransDGModel._init_select_layer", "zip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_embed", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_placeholders", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_vocabs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_model", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_model", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_select_layer"], ["    ", "def", "__init__", "(", "self", ",", "word_embed", ",", "kd_embed", ",", "param_dict", ",", "use_trans_repr", "=", "True", ",", "use_trans_select", "=", "True", ",", "\n", "vocab_size", "=", "30000", ",", "dim_emb", "=", "300", ",", "dim_trans", "=", "100", ",", "cell_class", "=", "'GRU'", ",", "num_units", "=", "512", ",", "num_layers", "=", "2", ",", "\n", "max_length", "=", "60", ",", "lr_rate", "=", "0.0001", ",", "max_grad_norm", "=", "5.0", ",", "drop_rate", "=", "0.2", ",", "beam_size", "=", "1", ")", ":", "\n", "# initialize params", "\n", "        ", "self", ".", "use_trans_repr", "=", "use_trans_repr", "\n", "self", ".", "use_trans_select", "=", "use_trans_select", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "dim_emb", "=", "dim_emb", "\n", "self", ".", "dim_trans", "=", "dim_trans", "\n", "self", ".", "cell_class", "=", "cell_class", "\n", "self", ".", "num_units", "=", "num_units", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "lr_rate", "=", "lr_rate", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "\n", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "self", ".", "_init_embed", "(", "word_embed", ",", "kd_embed", ")", "\n", "self", ".", "_init_placeholders", "(", ")", "\n", "self", ".", "_init_vocabs", "(", ")", "\n", "\n", "self", ".", "select_mode", "=", "None", "\n", "if", "self", ".", "use_trans_select", ":", "\n", "            ", "self", ".", "select_layer", "=", "self", ".", "_init_select_layer", "(", "param_dict", "=", "param_dict", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "select_layer", "=", "None", "\n", "\n", "# build model", "\n", "", "self", ".", "ppx_loss", ",", "self", ".", "loss", "=", "self", ".", "build_model", "(", "train_mode", "=", "True", ")", "\n", "self", ".", "generation", "=", "self", ".", "build_model", "(", "train_mode", "=", "False", ")", "\n", "\n", "# construct graphs for minimizing loss", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr_rate", ")", "\n", "self", ".", "params", "=", "tf", ".", "global_variables", "(", ")", "\n", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "loss", ",", "self", ".", "params", ")", "\n", "clipped_gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "self", ".", "max_grad_norm", ")", "\n", "self", ".", "update", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "clipped_gradients", ",", "self", ".", "params", ")", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_vocabs": [[53, 66], ["tensorflow.contrib.lookup.MutableHashTable", "tensorflow.contrib.lookup.MutableHashTable", "tensorflow.contrib.lookup.MutableHashTable", "tensorflow.contrib.lookup.MutableHashTable"], "methods", ["None"], ["", "def", "_init_vocabs", "(", "self", ")", ":", "\n", "        ", "self", ".", "symbol2index", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "string", ",", "value_dtype", "=", "tf", ".", "int64", ",", "\n", "default_value", "=", "UNK_ID", ",", "shared_name", "=", "\"w2id_table\"", ",", "\n", "name", "=", "\"w2id_table\"", ",", "checkpoint", "=", "True", ")", "\n", "self", ".", "index2symbol", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "int64", ",", "value_dtype", "=", "tf", ".", "string", ",", "\n", "default_value", "=", "'_UNK'", ",", "shared_name", "=", "\"id2w_table\"", ",", "\n", "name", "=", "\"id2w_table\"", ",", "checkpoint", "=", "True", ")", "\n", "self", ".", "kd2index", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "string", ",", "value_dtype", "=", "tf", ".", "int64", ",", "\n", "default_value", "=", "NONE_ID", ",", "shared_name", "=", "\"kd2id_table\"", ",", "\n", "name", "=", "\"kd2id_table\"", ",", "checkpoint", "=", "True", ")", "\n", "self", ".", "index2kd", "=", "MutableHashTable", "(", "key_dtype", "=", "tf", ".", "int64", ",", "value_dtype", "=", "tf", ".", "string", ",", "\n", "default_value", "=", "'_NONE'", ",", "shared_name", "=", "\"id2kd_table\"", ",", "\n", "name", "=", "\"id2kd_table\"", ",", "checkpoint", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_placeholders": [[67, 75], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "_init_placeholders", "(", "self", ")", ":", "\n", "        ", "self", ".", "posts", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ")", ",", "'post'", ")", "# [batch, len]", "\n", "self", ".", "posts_length", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ")", ",", "'post_lens'", ")", "# batch", "\n", "self", ".", "responses", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ")", ",", "'resp'", ")", "# [batch, len]", "\n", "self", ".", "responses_length", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", "None", ")", ",", "'resp_lens'", ")", "# batch", "\n", "self", ".", "corr_responses", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ",", "None", ")", ",", "'corr_resps'", ")", "# [batch, topk, len]", "\n", "self", ".", "triples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "(", "None", ",", "None", ",", "None", ",", "3", ")", ",", "'triples'", ")", "\n", "self", ".", "trans_reprs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "None", ",", "self", ".", "num_units", ")", ",", "'trans_reprs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_embed": [[76, 79], ["tensorflow.get_variable"], "methods", ["None"], ["", "def", "_init_embed", "(", "self", ",", "word_embed", ",", "kd_embed", "=", "None", ")", ":", "\n", "        ", "self", ".", "word_embed", "=", "tf", ".", "get_variable", "(", "'word_embed'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "word_embed", ",", "trainable", "=", "False", ")", "# [vocab_size, dim_emb]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel._init_select_layer": [[80, 112], ["param_dict.keys", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_init_select_layer", "(", "self", ",", "param_dict", ")", ":", "\n", "        ", "\"\"\"\n        :param param_dict: type dict\n        :return: Defined bilinear layer or mlp layer\n        \"\"\"", "\n", "if", "\"bilinear_mat\"", "in", "param_dict", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "select_mode", "=", "'bilinear'", "\n", "\n", "def", "bilinear_layer", "(", "inputs1", ",", "inputs2", ",", "trainable", "=", "False", ")", ":", "\n", "                ", "bilinear_mat", "=", "tf", ".", "get_variable", "(", "'bilinear_mat'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'bilinear_mat'", "]", ",", "trainable", "=", "trainable", ")", "\n", "proj_repr", "=", "tf", ".", "matmul", "(", "inputs2", ",", "bilinear_mat", ")", "\n", "scores", "=", "tf", ".", "reduce_sum", "(", "inputs1", "*", "proj_repr", ",", "axis", "=", "-", "1", ")", "\n", "return", "scores", "\n", "", "return", "bilinear_layer", "\n", "", "else", ":", "\n", "            ", "self", ".", "select_mode", "=", "'mlp'", "\n", "\n", "def", "fully_connected_layer", "(", "inputs", ",", "trainable", "=", "False", ")", ":", "\n", "                ", "fc1_weights", "=", "tf", ".", "get_variable", "(", "'fc1_weights'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc1_weights'", "]", ",", "trainable", "=", "trainable", ")", "\n", "fc1_biases", "=", "tf", ".", "get_variable", "(", "'fc1_biases'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc1_biases'", "]", ",", "trainable", "=", "trainable", ")", "\n", "hidden_outs", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "inputs", ",", "fc1_weights", ")", "+", "fc1_biases", ")", "\n", "\n", "fc2_weights", "=", "tf", ".", "get_variable", "(", "'fc2_weights'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc2_weights'", "]", ",", "trainable", "=", "trainable", ")", "\n", "fc2_biases", "=", "tf", ".", "get_variable", "(", "'fc2_biases'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "param_dict", "[", "'fc2_biases'", "]", ",", "trainable", "=", "trainable", ")", "\n", "scores", "=", "tf", ".", "matmul", "(", "hidden_outs", ",", "fc2_weights", ")", "+", "fc2_biases", "\n", "return", "scores", "\n", "", "return", "fully_connected_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_model": [[113, 157], ["model.TransDGModel.symbol2index.lookup", "tensorflow.nn.embedding_lookup", "model.TransDGModel.symbol2index.lookup", "tensorflow.nn.embedding_lookup", "model.TransDGModel.symbol2index.lookup", "tensorflow.nn.embedding_lookup", "tensorflow.reshape", "tensorflow.reduce_mean", "model.TransDGModel.symbol2index.lookup", "tensorflow.concat", "tensorflow.nn.embedding_lookup", "tensorflow.reshape", "model.TransDGModel.build_encoder", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.cumsum", "model.TransDGModel.build_decoder", "seq_helper.sentence_ppx", "seq_helper.sequence_loss", "tensorflow.identity", "tensorflow.identity", "model.TransDGModel.build_decoder", "tensorflow.argmax", "model.TransDGModel.index2symbol.lookup", "tensorflow.identity", "tensorflow.one_hot", "tensorflow.ones", "tensorflow.split"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_encoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sentence_ppx", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sequence_loss", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_decoder"], ["", "", "def", "build_model", "(", "self", ",", "train_mode", "=", "True", ")", ":", "\n", "# build the vocab table (string to index)", "\n", "        ", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "0", "]", "\n", "post_word_id", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "posts", ")", "\n", "post_word_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "post_word_id", ")", "# batch*len*unit", "\n", "\n", "corr_responses_id", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "corr_responses", ")", "# [batch, topk, len]", "\n", "corr_responses_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "corr_responses_id", ")", "# [batch, topk, len, unit]", "\n", "\n", "triple_id", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "triples", ")", "\n", "triple_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "triple_id", ")", "\n", "triple_num", "=", "tf", ".", "shape", "(", "self", ".", "triples", ")", "[", "1", "]", "\n", "triple_input", "=", "tf", ".", "reshape", "(", "triple_input", ",", "[", "batch_size", ",", "triple_num", ",", "-", "1", ",", "3", "*", "self", ".", "dim_emb", "]", ")", "\n", "triple_input", "=", "tf", ".", "reduce_mean", "(", "triple_input", ",", "axis", "=", "2", ")", "# [batch, triple_num, 3*dim_emb]", "\n", "\n", "resp_target", "=", "self", ".", "symbol2index", ".", "lookup", "(", "self", ".", "responses", ")", "\n", "decoder_len", "=", "tf", ".", "shape", "(", "self", ".", "responses", ")", "[", "1", "]", "\n", "resp_word_id", "=", "tf", ".", "concat", "(", "[", "tf", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "*", "GO_ID", ",", "\n", "tf", ".", "split", "(", "resp_target", ",", "[", "decoder_len", "-", "1", ",", "1", "]", ",", "1", ")", "[", "0", "]", "]", ",", "1", ")", "# [batch,len]", "\n", "resp_word_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "word_embed", ",", "resp_word_id", ")", "\n", "decoder_mask", "=", "tf", ".", "reshape", "(", "tf", ".", "cumsum", "(", "\n", "tf", ".", "one_hot", "(", "self", ".", "responses_length", "-", "1", ",", "decoder_len", ")", ",", "reverse", "=", "True", ",", "axis", "=", "1", ")", ",", "\n", "[", "-", "1", ",", "decoder_len", "]", ")", "\n", "\n", "encoder_output", ",", "encoder_state", "=", "self", ".", "build_encoder", "(", "post_word_input", ",", "\n", "corr_responses_input", ")", "\n", "\n", "if", "train_mode", ":", "\n", "            ", "output_logits", "=", "self", ".", "build_decoder", "(", "encoder_output", ",", "encoder_state", ",", "\n", "triple_input", ",", "resp_word_input", ",", "\n", "train_mode", "=", "train_mode", ")", "\n", "sent_ppx", "=", "sentence_ppx", "(", "self", ".", "vocab_size", ",", "output_logits", ",", "resp_target", ",", "decoder_mask", ")", "\n", "seq_loss", "=", "sequence_loss", "(", "self", ".", "vocab_size", ",", "output_logits", ",", "resp_target", ",", "decoder_mask", ")", "\n", "ppx_loss", "=", "tf", ".", "identity", "(", "sent_ppx", ",", "name", "=", "\"ppx_loss\"", ")", "\n", "loss", "=", "tf", ".", "identity", "(", "seq_loss", ",", "name", "=", "\"loss\"", ")", "\n", "return", "ppx_loss", ",", "loss", "\n", "", "else", ":", "\n", "            ", "decoder_dist", "=", "self", ".", "build_decoder", "(", "encoder_output", ",", "encoder_state", ",", "\n", "triple_input", ",", "decoder_input", "=", "None", ",", "\n", "train_mode", "=", "train_mode", ")", "\n", "generation_index", "=", "tf", ".", "argmax", "(", "decoder_dist", ",", "2", ")", "\n", "generation", "=", "self", ".", "index2symbol", ".", "lookup", "(", "generation_index", ")", "\n", "generation", "=", "tf", ".", "identity", "(", "generation", ",", "name", "=", "'generation'", ")", "\n", "return", "generation", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_encoder": [[158, 207], ["tensorflow.reshape", "tensorflow.concat", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.variable_scope", "tensorflow.nn.dynamic_rnn", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.get_variable", "tensorflow.reduce_sum", "tensorflow.nn.softmax", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.contrib.rnn.GRUCell", "tensorflow.tanh", "tensorflow.expand_dims", "range", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.RNNCell", "range", "range"], "methods", ["None"], ["", "", "def", "build_encoder", "(", "self", ",", "post_word_input", ",", "corr_responses_input", ")", ":", "\n", "        ", "if", "self", ".", "cell_class", "==", "'GRU'", ":", "\n", "            ", "encoder_cell", "=", "MultiRNNCell", "(", "[", "GRUCell", "(", "self", ".", "num_units", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "", "elif", "self", ".", "cell_class", "==", "'LSTM'", ":", "\n", "            ", "encoder_cell", "=", "MultiRNNCell", "(", "[", "LSTMCell", "(", "self", ".", "num_units", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "encoder_cell", "=", "MultiRNNCell", "(", "[", "RNNCell", "(", "self", ".", "num_units", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'encoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "            ", "encoder_output", ",", "encoder_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "encoder_cell", ",", "\n", "post_word_input", ",", "\n", "self", ".", "posts_length", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "scope", "=", "scope", ")", "\n", "", "batch_size", ",", "encoder_len", "=", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "1", "]", "\n", "corr_response_input", "=", "tf", ".", "reshape", "(", "corr_responses_input", ",", "[", "batch_size", ",", "-", "1", ",", "self", ".", "dim_emb", "]", ")", "\n", "corr_cum_len", "=", "tf", ".", "shape", "(", "corr_response_input", ")", "[", "1", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'mutual_attention'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "encoder_out_trans", "=", "tf", ".", "layers", ".", "dense", "(", "encoder_output", ",", "self", ".", "num_units", ",", "\n", "name", "=", "'encoder_out_transform'", ")", "\n", "corr_response_trans", "=", "tf", ".", "layers", ".", "dense", "(", "corr_response_input", ",", "self", ".", "num_units", ",", "\n", "name", "=", "'corr_response_transform'", ")", "\n", "encoder_out_trans", "=", "tf", ".", "expand_dims", "(", "encoder_out_trans", ",", "axis", "=", "1", ")", "\n", "encoder_out_trans", "=", "tf", ".", "tile", "(", "encoder_out_trans", ",", "[", "1", ",", "corr_cum_len", ",", "1", ",", "1", "]", ")", "\n", "encoder_out_trans", "=", "tf", ".", "reshape", "(", "encoder_out_trans", ",", "[", "-", "1", ",", "encoder_len", ",", "self", ".", "num_units", "]", ")", "\n", "\n", "corr_response_trans", "=", "tf", ".", "reshape", "(", "corr_response_trans", ",", "[", "-", "1", ",", "self", ".", "num_units", "]", ")", "\n", "corr_response_trans", "=", "tf", ".", "expand_dims", "(", "corr_response_trans", ",", "axis", "=", "1", ")", "\n", "\n", "# TODO: try bilinear attention", "\n", "v", "=", "tf", ".", "get_variable", "(", "\"attention_v\"", ",", "[", "self", ".", "num_units", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "score", "=", "tf", ".", "reduce_sum", "(", "v", "*", "tf", ".", "tanh", "(", "encoder_out_trans", "+", "corr_response_trans", ")", ",", "axis", "=", "2", ")", "\n", "alignments", "=", "tf", ".", "nn", ".", "softmax", "(", "score", ")", "\n", "\n", "encoder_out_tiled", "=", "tf", ".", "expand_dims", "(", "encoder_output", ",", "axis", "=", "1", ")", "\n", "encoder_out_tiled", "=", "tf", ".", "tile", "(", "encoder_out_tiled", ",", "[", "1", ",", "corr_cum_len", ",", "1", ",", "1", "]", ")", "\n", "encoder_out_tiled", "=", "tf", ".", "reshape", "(", "encoder_out_tiled", ",", "[", "-", "1", ",", "encoder_len", ",", "self", ".", "num_units", "]", ")", "\n", "\n", "context_mutual", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "expand_dims", "(", "alignments", ",", "2", ")", "*", "encoder_out_tiled", ",", "axis", "=", "1", ")", "\n", "context_mutual", "=", "tf", ".", "reshape", "(", "context_mutual", ",", "[", "batch_size", ",", "-", "1", ",", "self", ".", "num_units", "]", ")", "\n", "context_mutual", "=", "tf", ".", "reduce_mean", "(", "context_mutual", ",", "axis", "=", "1", ")", "\n", "\n", "", "encoder_output", "=", "tf", ".", "concat", "(", "[", "encoder_output", ",", "tf", ".", "expand_dims", "(", "context_mutual", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "trans_output", "=", "tf", ".", "layers", ".", "dense", "(", "self", ".", "trans_reprs", ",", "self", ".", "num_units", ",", "\n", "name", "=", "'trans_reprs_transform'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "encoder_output", "=", "tf", ".", "concat", "(", "[", "encoder_output", ",", "trans_output", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "return", "encoder_output", ",", "encoder_state", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.build_decoder": [[208, 261], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.variable_scope", "attention_decoder.prepare_attention", "attention_decoder.attention_decoder_train", "dynamic_decoder.dynamic_rnn_decoder", "attention_decoder.create_output_fn", "attention_decoder.create_output_fn.", "tensorflow.variable_scope", "attention_decoder.prepare_attention", "attention_decoder.create_output_fn", "attention_decoder.attention_decoder_inference", "dynamic_decoder.dynamic_rnn_decoder", "tensorflow.contrib.rnn.GRUCell", "model.TransDGModel.transfer_matching", "model.TransDGModel.transfer_matching", "range", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.RNNCell", "range", "range"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_attention", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_train", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.dynamic_decoder.dynamic_rnn_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_output_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.prepare_attention", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.create_output_fn", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.attention_decoder.attention_decoder_inference", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.dynamic_decoder.dynamic_rnn_decoder", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.transfer_matching", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.transfer_matching"], ["", "def", "build_decoder", "(", "self", ",", "encoder_output", ",", "encoder_state", ",", "triple_input", ",", "decoder_input", ",", "train_mode", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "cell_class", "==", "'GRU'", ":", "\n", "            ", "decoder_cell", "=", "MultiRNNCell", "(", "[", "GRUCell", "(", "self", ".", "num_units", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "", "elif", "self", ".", "cell_class", "==", "'LSTM'", ":", "\n", "            ", "decoder_cell", "=", "MultiRNNCell", "(", "[", "LSTMCell", "(", "self", ".", "num_units", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "decoder_cell", "=", "MultiRNNCell", "(", "[", "RNNCell", "(", "self", ".", "num_units", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "\n", "", "if", "train_mode", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'decoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "                ", "if", "self", ".", "use_trans_select", ":", "\n", "                    ", "kd_context", "=", "self", ".", "transfer_matching", "(", "encoder_output", ",", "triple_input", ")", "\n", "", "else", ":", "\n", "                    ", "kd_context", "=", "None", "\n", "# prepare attention", "\n", "", "attention_keys", ",", "attention_values", ",", "attention_construct_fn", "=", "prepare_attention", "(", "encoder_output", ",", "kd_context", ",", "'bahdanau'", ",", "self", ".", "num_units", ")", "\n", "decoder_fn_train", "=", "attention_decoder_train", "(", "\n", "encoder_state", "=", "encoder_state", ",", "\n", "attention_keys", "=", "attention_keys", ",", "\n", "attention_values", "=", "attention_values", ",", "\n", "attention_construct_fn", "=", "attention_construct_fn", ")", "\n", "# train decoder", "\n", "decoder_output", ",", "_", ",", "_", "=", "dynamic_rnn_decoder", "(", "cell", "=", "decoder_cell", ",", "\n", "decoder_fn", "=", "decoder_fn_train", ",", "\n", "inputs", "=", "decoder_input", ",", "\n", "sequence_length", "=", "self", ".", "responses_length", ",", "\n", "scope", "=", "scope", ")", "\n", "output_fn", "=", "create_output_fn", "(", "vocab_size", "=", "self", ".", "vocab_size", ")", "\n", "output_logits", "=", "output_fn", "(", "decoder_output", ")", "\n", "return", "output_logits", "\n", "", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'decoder'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "                ", "if", "self", ".", "use_trans_select", ":", "\n", "                    ", "kd_context", "=", "self", ".", "transfer_matching", "(", "encoder_output", ",", "triple_input", ")", "\n", "", "else", ":", "\n", "                    ", "kd_context", "=", "None", "\n", "", "attention_keys", ",", "attention_values", ",", "attention_construct_fn", "=", "prepare_attention", "(", "encoder_output", ",", "kd_context", ",", "'bahdanau'", ",", "self", ".", "num_units", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "output_fn", "=", "create_output_fn", "(", "vocab_size", "=", "self", ".", "vocab_size", ")", "\n", "# inference decoder", "\n", "decoder_fn_inference", "=", "attention_decoder_inference", "(", "\n", "num_units", "=", "self", ".", "num_units", ",", "num_decoder_symbols", "=", "self", ".", "vocab_size", ",", "\n", "output_fn", "=", "output_fn", ",", "encoder_state", "=", "encoder_state", ",", "\n", "attention_keys", "=", "attention_keys", ",", "attention_values", "=", "attention_values", ",", "\n", "attention_construct_fn", "=", "attention_construct_fn", ",", "embeddings", "=", "self", ".", "word_embed", ",", "\n", "start_of_sequence_id", "=", "GO_ID", ",", "end_of_sequence_id", "=", "EOS_ID", ",", "maximum_length", "=", "self", ".", "max_length", ")", "\n", "\n", "# get decoder output", "\n", "decoder_distribution", ",", "_", ",", "_", "=", "dynamic_rnn_decoder", "(", "cell", "=", "decoder_cell", ",", "\n", "decoder_fn", "=", "decoder_fn_inference", ",", "\n", "scope", "=", "scope", ")", "\n", "return", "decoder_distribution", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.transfer_matching": [[262, 284], ["tensorflow.reduce_mean", "tensorflow.tile", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.reshape", "model.TransDGModel.select_layer", "tensorflow.concat", "tensorflow.reshape", "model.TransDGModel.select_layer", "tensorflow.shape", "tensorflow.expand_dims"], "methods", ["None"], ["", "", "", "def", "transfer_matching", "(", "self", ",", "context_repr", ",", "knowledge_repr", ")", ":", "\n", "        ", "context", "=", "tf", ".", "reduce_mean", "(", "context_repr", ",", "axis", "=", "1", ")", "# [batch, num_units]", "\n", "triple_num", "=", "tf", ".", "shape", "(", "self", ".", "triples", ")", "[", "1", "]", "\n", "context_tile", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "context", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "triple_num", ",", "1", "]", ")", "# [batch, triple_num, num_units]", "\n", "knowledge", "=", "tf", ".", "layers", ".", "dense", "(", "knowledge_repr", ",", "self", ".", "dim_emb", ",", "\n", "name", "=", "'knowledge_transform'", ")", "# [batch, triple_num, dim_emb]", "\n", "\n", "if", "self", ".", "select_mode", "==", "'bilinear'", ":", "\n", "            ", "context_reshaped", "=", "tf", ".", "reshape", "(", "context_tile", ",", "[", "-", "1", ",", "self", ".", "num_units", "]", ")", "\n", "knowledge_reshaped", "=", "tf", ".", "reshape", "(", "knowledge", ",", "[", "-", "1", ",", "self", ".", "dim_emb", "]", ")", "\n", "em_scores", "=", "self", ".", "select_layer", "(", "context_reshaped", ",", "knowledge_reshaped", ")", "\n", "", "else", ":", "\n", "            ", "concat_repr", "=", "tf", ".", "concat", "(", "[", "context_tile", ",", "knowledge", "]", ",", "axis", "=", "-", "1", ")", "# [batch, triple_num, num_units+dim_emb]", "\n", "concat_repr_reshaped", "=", "tf", ".", "reshape", "(", "concat_repr", ",", "[", "-", "1", ",", "self", ".", "num_units", "+", "self", ".", "dim_emb", "]", ")", "# [batch*triple_num, num_units+dim_emb]", "\n", "em_scores", "=", "self", ".", "select_layer", "(", "concat_repr_reshaped", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "self", ".", "posts", ")", "[", "0", "]", "\n", "em_scores", "=", "tf", ".", "reshape", "(", "em_scores", ",", "[", "batch_size", ",", "triple_num", "]", ")", "\n", "kd_context", "=", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "em_scores", ",", "axis", "=", "1", ")", ",", "knowledge", ")", "\n", "kd_context", "=", "tf", ".", "reshape", "(", "kd_context", ",", "[", "batch_size", ",", "self", ".", "dim_emb", "]", ")", "\n", "\n", "return", "kd_context", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.set_vocabs": [[285, 298], ["model.TransDGModel.symbol2index.insert", "session.run", "model.TransDGModel.index2symbol.insert", "session.run", "model.TransDGModel.kd2index.insert", "session.run", "model.TransDGModel.index2kd.insert", "session.run", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "list", "list", "list", "list", "range", "range", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "set_vocabs", "(", "self", ",", "session", ",", "vocab", ",", "kd_vocab", ")", ":", "\n", "        ", "op_in", "=", "self", ".", "symbol2index", ".", "insert", "(", "tf", ".", "constant", "(", "vocab", ")", ",", "\n", "tf", ".", "constant", "(", "list", "(", "range", "(", "self", ".", "vocab_size", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "session", ".", "run", "(", "op_in", ")", "\n", "op_out", "=", "self", ".", "index2symbol", ".", "insert", "(", "tf", ".", "constant", "(", "list", "(", "range", "(", "self", ".", "vocab_size", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "tf", ".", "constant", "(", "vocab", ")", ")", "\n", "session", ".", "run", "(", "op_out", ")", "\n", "op_in", "=", "self", ".", "kd2index", ".", "insert", "(", "tf", ".", "constant", "(", "kd_vocab", ")", ",", "\n", "tf", ".", "constant", "(", "list", "(", "range", "(", "len", "(", "kd_vocab", ")", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "session", ".", "run", "(", "op_in", ")", "\n", "op_out", "=", "self", ".", "index2kd", ".", "insert", "(", "tf", ".", "constant", "(", "list", "(", "range", "(", "len", "(", "kd_vocab", ")", ")", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "tf", ".", "constant", "(", "kd_vocab", ")", ")", "\n", "session", ".", "run", "(", "op_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.show_parameters": [[299, 302], ["print", "var.get_shape().as_list", "var.get_shape"], "methods", ["None"], ["", "def", "show_parameters", "(", "self", ")", ":", "\n", "        ", "for", "var", "in", "self", ".", "params", ":", "\n", "            ", "print", "(", "\"%s: %s\"", "%", "(", "var", ".", "name", ",", "var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.train_batch": [[303, 317], ["session.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "", "def", "train_batch", "(", "self", ",", "session", ",", "data", ",", "trans_reprs", ")", ":", "\n", "        ", "input_feed", "=", "{", "self", ".", "posts", ":", "data", "[", "'post'", "]", ",", "\n", "self", ".", "posts_length", ":", "data", "[", "'post_len'", "]", ",", "\n", "self", ".", "responses", ":", "data", "[", "'response'", "]", ",", "\n", "self", ".", "responses_length", ":", "data", "[", "'response_len'", "]", ",", "\n", "self", ".", "corr_responses", ":", "data", "[", "'corr_responses'", "]", ",", "\n", "self", ".", "triples", ":", "data", "[", "'all_triples'", "]", "\n", "}", "\n", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "input_feed", "[", "self", ".", "trans_reprs", "]", "=", "trans_reprs", "\n", "\n", "", "output_feed", "=", "[", "self", ".", "ppx_loss", ",", "self", ".", "loss", ",", "self", ".", "update", "]", "\n", "outputs", "=", "session", ".", "run", "(", "output_feed", ",", "feed_dict", "=", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.eval_batch": [[318, 332], ["session.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "eval_batch", "(", "self", ",", "session", ",", "data", ",", "trans_reprs", ")", ":", "\n", "        ", "input_feed", "=", "{", "self", ".", "posts", ":", "data", "[", "'post'", "]", ",", "\n", "self", ".", "posts_length", ":", "data", "[", "'post_len'", "]", ",", "\n", "self", ".", "responses", ":", "data", "[", "'response'", "]", ",", "\n", "self", ".", "responses_length", ":", "data", "[", "'response_len'", "]", ",", "\n", "self", ".", "corr_responses", ":", "data", "[", "'corr_responses'", "]", ",", "\n", "self", ".", "triples", ":", "data", "[", "'all_triples'", "]", "\n", "}", "\n", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "input_feed", "[", "self", ".", "trans_reprs", "]", "=", "trans_reprs", "\n", "\n", "", "output_feed", "=", "[", "self", ".", "ppx_loss", ",", "self", ".", "loss", "]", "\n", "outputs", "=", "session", ".", "run", "(", "output_feed", ",", "feed_dict", "=", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.decode_batch": [[333, 347], ["session.run"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Ticker.run"], ["", "def", "decode_batch", "(", "self", ",", "session", ",", "data", ",", "trans_reprs", ")", ":", "\n", "        ", "input_feed", "=", "{", "self", ".", "posts", ":", "data", "[", "'post'", "]", ",", "\n", "self", ".", "posts_length", ":", "data", "[", "'post_len'", "]", ",", "\n", "self", ".", "responses", ":", "data", "[", "'response'", "]", ",", "\n", "self", ".", "responses_length", ":", "data", "[", "'response_len'", "]", ",", "\n", "self", ".", "corr_responses", ":", "data", "[", "'corr_responses'", "]", ",", "\n", "self", ".", "triples", ":", "data", "[", "'all_triples'", "]", "\n", "}", "\n", "if", "self", ".", "use_trans_repr", ":", "\n", "            ", "input_feed", "[", "self", ".", "trans_reprs", "]", "=", "trans_reprs", "\n", "\n", "", "output_feed", "=", "[", "self", ".", "generation", ",", "self", ".", "ppx_loss", ",", "self", ".", "loss", "]", "\n", "outputs", "=", "session", ".", "run", "(", "output_feed", ",", "input_feed", ")", "\n", "return", "outputs", "[", "0", "]", ",", "outputs", "[", "1", "]", ",", "outputs", "[", "-", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.define_rnn_cell": [[7, 33], ["range", "cells.append", "len", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.GRUCell", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.RNNCell"], "function", ["None"], ["\n", "def", "seq_encoding", "(", "emb_input", ",", "len_input", ",", "encoder", ",", "fwbw", "=", "False", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "    ", "\"\"\"\n    Just a small wrapper: given the embedding input, length input and encoder, return the encoded result\n    :param emb_input: (data_size, stamps, dim_emb)\n    :param len_input: (data_size, ) as int32\n    :param encoder: the BidirectionalRNNEncoder instance\n    :param fwbw: only use the concat of last fw & bw state\n    :param reuse: reuse flag (used in generating RNN/GRU/LSTM- Cell)\n    :return: (data_size, stamps, dim_hidden)\n    \"\"\"", "\n", "if", "encoder", "is", "None", ":", "\n", "        ", "return", "emb_input", "# just use word embedding, without other operations", "\n", "", "rnn_input", "=", "tf", ".", "unstack", "(", "emb_input", ",", "axis", "=", "1", ",", "name", "=", "'emb_input'", ")", "# stamp * (data_size, dim_emb)", "\n", "encoder_output", "=", "encoder", ".", "encode", "(", "inputs", "=", "rnn_input", ",", "\n", "sequence_length", "=", "len_input", ",", "\n", "reuse", "=", "reuse", ")", "\n", "if", "not", "fwbw", ":", "\n", "        ", "out_hidden", "=", "tf", ".", "stack", "(", "encoder_output", ".", "outputs", ",", "axis", "=", "1", ",", "name", "=", "'out_hidden'", ")", "# (data_size, stamp, dim_hidden)", "\n", "return", "out_hidden", "\n", "", "else", ":", "\n", "        ", "out_hidden", "=", "tf", ".", "concat", "(", "encoder_output", ".", "final_state", ",", "axis", "=", "-", "1", ",", "name", "=", "'out_hidden'", ")", "# (data_size, dim_hidden)", "\n", "return", "out_hidden", "\n", "\n", "\n", "", "", "def", "schema_encoding", "(", "preds_hidden", ",", "preds_len", ",", "pwords_hidden", ",", "pwords_len", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sequence_loss": [[35, 50], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["\n", "masked_preds_hidden", "=", "seq_hidden_masking_before_pooling", "(", "seq_hidden_input", "=", "preds_hidden", ",", "\n", "len_input", "=", "preds_len", ")", "\n", "masked_pwords_hidden", "=", "seq_hidden_masking_before_pooling", "(", "seq_hidden_input", "=", "pwords_hidden", ",", "\n", "len_input", "=", "pwords_len", ")", "\n", "masked_merge_hidden", "=", "tf", ".", "concat", "(", "\n", "[", "masked_preds_hidden", ",", "masked_pwords_hidden", "]", ",", "\n", "axis", "=", "1", ",", "name", "=", "'masked_merge_hidden'", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.ppx_loss": [[52, 63], ["tensorflow.reshape", "tensorflow.one_hot", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.log"], "function", ["None"], ["schema_hidden", "=", "tf", ".", "reduce_max", "(", "masked_merge_hidden", ",", "\n", "axis", "=", "1", ",", "name", "=", "'schema_hidden'", ")", "# (data_size, dim_hidden)", "\n", "return", "schema_hidden", "\n", "\n", "\n", "", "def", "seq_hidden_masking", "(", "seq_hidden_input", ",", "len_input", ",", "mask_value", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.seq_helper.sentence_ppx": [[65, 76], ["tensorflow.reshape", "tensorflow.one_hot", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.nn.log_softmax", "tensorflow.reshape"], "function", ["None"], ["\n", "max_len", "=", "tf", ".", "shape", "(", "seq_hidden_input", ")", "[", "1", "]", "# could be int or int-tensor", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "lengths", "=", "len_input", ",", "maxlen", "=", "max_len", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'mask'", ")", "# (data_size, max_len)", "\n", "exp_mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "axis", "=", "-", "1", ",", "name", "=", "'exp_mask'", ")", "# (data_size, max_len, 1)", "\n", "masked_hidden", "=", "exp_mask", "*", "seq_hidden_input", "+", "(", "1.0", "-", "exp_mask", ")", "*", "mask_value", "\n", "return", "masked_hidden", "\n", "\n", "\n", "", "def", "seq_hidden_masking_before_pooling", "(", "seq_hidden_input", ",", "len_input", ")", ":", "\n", "    ", "return", "seq_hidden_masking", "(", "seq_hidden_input", ",", "len_input", ",", "mask_value", "=", "tf", ".", "float32", ".", "min", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.reddit_candgen.RedditCandidateGenerator.__init__": [[17, 26], ["reddit_candgen.RedditCandidateGenerator._load_fb_subset", "reddit_candgen.RedditCandidateGenerator._load_linkings"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator._load_fb_subset", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator._load_linkings"], ["    ", "def", "__init__", "(", "self", ",", "freebase_fp", ",", "links_fp", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "self", ".", "subj_pred_dict", "=", "{", "}", "\n", "self", ".", "p_links_dict", "=", "{", "}", "# <p_idx, [LinkData]>", "\n", "# verbose = 0: show basic flow of the process", "\n", "# verbose = 1: show detail linking information", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "self", ".", "_load_fb_subset", "(", "freebase_fp", ")", "\n", "self", ".", "_load_linkings", "(", "links_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.reddit_candgen.RedditCandidateGenerator._load_fb_subset": [[27, 45], ["src.kbqa.utils.log_util.LogInfo.begin_track", "len", "src.kbqa.utils.log_util.LogInfo.logs", "enumerate", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.end_track", "codecs.open", "br.readlines", "len", "line.strip().split", "s[].replace", "p[].replace", "reddit_candgen.RedditCandidateGenerator.subj_pred_dict.setdefault().add", "len", "sum", "src.kbqa.utils.log_util.LogInfo.logs", "len", "line.strip", "reddit_candgen.RedditCandidateGenerator.subj_pred_dict.setdefault", "len", "set", "reddit_candgen.RedditCandidateGenerator.subj_pred_dict.values"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_fb_subset", "(", "self", ",", "fb_fp", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Loading freebase subset from [%s] ...'", ",", "fb_fp", ")", "\n", "prefix", "=", "'www.freebase.com/'", "\n", "pref_len", "=", "len", "(", "prefix", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "fb_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "lines", "=", "br", ".", "readlines", "(", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d lines loaded.'", ",", "len", "(", "lines", ")", ")", "\n", "for", "line_idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "line_idx", "%", "500000", "==", "0", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "'Current: %d / %d'", ",", "line_idx", ",", "len", "(", "lines", ")", ")", "\n", "", "s", ",", "p", ",", "_", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "s", "=", "s", "[", "pref_len", ":", "]", ".", "replace", "(", "'/'", ",", "'.'", ")", "\n", "p", "=", "p", "[", "pref_len", ":", "]", ".", "replace", "(", "'/'", ",", "'.'", ")", "\n", "self", ".", "subj_pred_dict", ".", "setdefault", "(", "s", ",", "set", "(", "[", "]", ")", ")", ".", "add", "(", "p", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d related entities and %d <S, P> pairs saved.'", ",", "\n", "len", "(", "self", ".", "subj_pred_dict", ")", ",", "sum", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "subj_pred_dict", ".", "values", "(", ")", "]", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.reddit_candgen.RedditCandidateGenerator._load_linkings": [[46, 67], ["src.kbqa.utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "line.startswith", "line.strip().split", "int", "int", "int", "json.loads", "src.kbqa.utils.link_data.LinkData", "reddit_candgen.RedditCandidateGenerator.p_links_dict.setdefault().append", "float", "line.strip", "reddit_candgen.RedditCandidateGenerator.p_links_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_linkings", "(", "self", ",", "links_fp", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "links_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "if", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                    ", "continue", "\n", "", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "q_idx", ",", "st", ",", "ed", ",", "mention", ",", "mid", ",", "wiki_name", ",", "feats", "=", "spt", "\n", "q_idx", "=", "int", "(", "q_idx", ")", "\n", "st", "=", "int", "(", "st", ")", "\n", "ed", "=", "int", "(", "ed", ")", "\n", "feat_dict", "=", "json", ".", "loads", "(", "feats", ")", "\n", "for", "k", "in", "feat_dict", ":", "\n", "                    ", "v", "=", "float", "(", "'%.6f'", "%", "feat_dict", "[", "k", "]", ")", "\n", "feat_dict", "[", "k", "]", "=", "v", "\n", "", "link_data", "=", "LinkData", "(", "category", "=", "'Entity'", ",", "\n", "start", "=", "st", ",", "end", "=", "ed", ",", "\n", "mention", "=", "mention", ",", "comp", "=", "'=='", ",", "\n", "value", "=", "mid", ",", "name", "=", "wiki_name", ",", "\n", "link_feat", "=", "feat_dict", ")", "\n", "self", ".", "p_links_dict", ".", "setdefault", "(", "q_idx", ",", "[", "]", ")", ".", "append", "(", "link_data", ")", "\n", "", "", "LogInfo", ".", "logs", "(", "'%d questions of link data loaded.'", ",", "len", "(", "self", ".", "p_links_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.reddit_candgen.RedditCandidateGenerator.single_post_candgen": [[68, 113], ["os.path.isfile", "shutil.move", "reddit_candgen.RedditCandidateGenerator.p_links_dict.get", "range", "os.path.isfile", "shutil.move", "reddit_candgen.RedditCandidateGenerator.subj_pred_dict.get", "len", "src.kbqa.utils.log_util.LogInfo.logs", "codecs.open", "codecs.open", "br.readlines", "len", "codecs.open", "set", "src.kbqa.dataset.schema.Schema", "sc_list.append", "bw.write", "json.loads", "reddit_candgen.RedditCandidateGenerator.append", "bw.write", "getattr", "opt_raw_paths.append", "line.strip", "src.kbqa.utils.link_data.LinkData", "json.dumps", "json.dumps", "gl.serialize"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.link_data.LinkData.serialize"], ["", "def", "single_post_candgen", "(", "self", ",", "p_idx", ",", "post", ",", "link_fp", ",", "schema_fp", ")", ":", "\n", "# =================== Linking first ==================== #", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "link_fp", ")", ":", "\n", "            ", "gather_linkings", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "link_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "                ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                    ", "tup_list", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "ld_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "tup_list", "}", "\n", "gather_linkings", ".", "append", "(", "LinkData", "(", "**", "ld_dict", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "gather_linkings", "=", "self", ".", "p_links_dict", ".", "get", "(", "p_idx", ",", "[", "]", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "gather_linkings", ")", ")", ":", "\n", "                ", "gather_linkings", "[", "idx", "]", ".", "gl_pos", "=", "idx", "\n", "# ==================== Save linking results ================ #", "\n", "", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "link_fp", ")", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "link_fp", "+", "'.tmp'", ",", "'w'", ",", "'utf-8'", ")", "as", "bw", ":", "\n", "                ", "for", "gl", "in", "gather_linkings", ":", "\n", "                    ", "bw", ".", "write", "(", "json", ".", "dumps", "(", "gl", ".", "serialize", "(", ")", ")", "+", "'\\n'", ")", "\n", "", "", "shutil", ".", "move", "(", "link_fp", "+", "'.tmp'", ",", "link_fp", ")", "\n", "# ===================== simple predicate finding ===================== #", "\n", "", "sc_list", "=", "[", "]", "\n", "for", "gl_data", "in", "gather_linkings", ":", "\n", "            ", "entity", "=", "gl_data", ".", "value", "\n", "pred_set", "=", "self", ".", "subj_pred_dict", ".", "get", "(", "entity", ",", "set", "(", "[", "]", ")", ")", "\n", "for", "pred", "in", "pred_set", ":", "\n", "                ", "sc", "=", "Schema", "(", ")", "\n", "sc", ".", "hops", "=", "1", "\n", "sc", ".", "main_pred_seq", "=", "[", "pred", "]", "\n", "sc", ".", "raw_paths", "=", "[", "(", "'Main'", ",", "gl_data", ",", "[", "pred", "]", ")", "]", "\n", "sc", ".", "ans_size", "=", "1", "\n", "sc_list", ".", "append", "(", "sc", ")", "\n", "", "", "if", "len", "(", "sc_list", ")", "==", "0", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "\"=============q_idx: %d sc_list=0======================\"", "%", "p_idx", ")", "\n", "# ==================== Save schema results ================ #", "\n", "# ans_size, hops, raw_paths", "\n", "# raw_paths: (category, gl_pos, gl_mid, pred_seq)", "\n", "", "with", "codecs", ".", "open", "(", "schema_fp", "+", "'.tmp'", ",", "'w'", ",", "'utf-8'", ")", "as", "bw", ":", "\n", "            ", "for", "sc", "in", "sc_list", ":", "\n", "                ", "sc_info_dict", "=", "{", "k", ":", "getattr", "(", "sc", ",", "k", ")", "for", "k", "in", "(", "'ans_size'", ",", "'hops'", ")", "}", "\n", "opt_raw_paths", "=", "[", "]", "\n", "for", "cate", ",", "gl", ",", "pred_seq", "in", "sc", ".", "raw_paths", ":", "\n", "                    ", "opt_raw_paths", ".", "append", "(", "(", "cate", ",", "gl", ".", "gl_pos", ",", "gl", ".", "value", ",", "pred_seq", ")", ")", "\n", "", "sc_info_dict", "[", "'raw_paths'", "]", "=", "opt_raw_paths", "\n", "bw", ".", "write", "(", "json", ".", "dumps", "(", "sc_info_dict", ")", "+", "'\\n'", ")", "\n", "", "", "shutil", ".", "move", "(", "schema_fp", "+", "'.tmp'", ",", "schema_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.reddit_candgen.main": [[115, 153], ["src.kbqa.utils.log_util.LogInfo.logs", "reddit_candgen.RedditCandidateGenerator", "enumerate", "open", "pickle.load", "src.kbqa.utils.log_util.LogInfo.begin_track", "all_lists.append", "os.path.isfile", "reddit_candgen.RedditCandidateGenerator.single_post_candgen", "src.kbqa.utils.log_util.LogInfo.end_track", "open", "enumerate", "len", "len", "int", "os.path.exists", "os.makedirs", "src.kbqa.utils.log_util.LogInfo.end_track", "fw.write", "fw.write", "len"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.reddit_candgen.RedditCandidateGenerator.single_post_candgen", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "data_path", "=", "\"%s/Reddit.%s.pkl\"", "%", "(", "args", ".", "data_dir", ",", "args", ".", "mode", ")", "\n", "freebase_path", "=", "\"%s/freebase-FB2M.txt\"", "%", "args", ".", "freebase_dir", "\n", "links_path", "=", "\"%s/Reddit.%s.links\"", "%", "(", "args", ".", "data_dir", ",", "args", ".", "mode", ")", "\n", "\n", "with", "open", "(", "data_path", ",", "'rb'", ")", "as", "br", ":", "\n", "        ", "dg_list", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d Reddit dialogs loaded.'", "%", "len", "(", "dg_list", ")", ")", "\n", "\n", "cand_gen", "=", "RedditCandidateGenerator", "(", "freebase_fp", "=", "freebase_path", ",", "links_fp", "=", "links_path", ",", "\n", "verbose", "=", "args", ".", "verbose", ")", "\n", "\n", "output_dir", "=", "args", ".", "output_prefix", "+", "\"_%s\"", "%", "args", ".", "mode", "\n", "all_list_fp", "=", "output_dir", "+", "'/all_list'", "\n", "all_lists", "=", "[", "]", "\n", "for", "p_idx", ",", "post", "in", "enumerate", "(", "dg_list", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Entering P %d / %d:'", ",", "p_idx", ",", "len", "(", "dg_list", ")", ")", "\n", "sub_idx", "=", "int", "(", "p_idx", "/", "10000", ")", "*", "10000", "\n", "index", "=", "'data/%d-%d/%d_schema'", "%", "(", "sub_idx", ",", "sub_idx", "+", "9999", ",", "p_idx", ")", "\n", "all_lists", ".", "append", "(", "index", ")", "\n", "sub_dir", "=", "'%s/data/%d-%d'", "%", "(", "output_dir", ",", "sub_idx", ",", "sub_idx", "+", "9999", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "sub_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "sub_dir", ")", "\n", "", "schema_fp", "=", "'%s/%d_schema'", "%", "(", "sub_dir", ",", "p_idx", ")", "\n", "link_fp", "=", "'%s/%d_links'", "%", "(", "sub_dir", ",", "p_idx", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "schema_fp", ")", ":", "\n", "            ", "LogInfo", ".", "end_track", "(", "'Skip this post, already saved.'", ")", "\n", "continue", "\n", "\n", "", "cand_gen", ".", "single_post_candgen", "(", "p_idx", "=", "p_idx", ",", "post", "=", "post", ",", "\n", "link_fp", "=", "link_fp", ",", "schema_fp", "=", "schema_fp", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "", "with", "open", "(", "all_list_fp", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "for", "i", ",", "idx_str", "in", "enumerate", "(", "all_lists", ")", ":", "\n", "            ", "if", "i", "==", "len", "(", "all_lists", ")", "-", "1", ":", "\n", "                ", "fw", ".", "write", "(", "idx_str", ")", "\n", "", "else", ":", "\n", "                ", "fw", ".", "write", "(", "idx_str", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.__init__": [[14, 29], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "candgen_dir", ",", "mode", "=", "'train'", ",", "file_list_name", "=", "'all_list'", ",", "full_constr", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "candgen_dir", "=", "candgen_dir", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "file_list_name", "=", "file_list_name", "\n", "self", ".", "full_constr", "=", "full_constr", "\n", "\n", "self", ".", "save_dir", "=", "'%s/%s'", "%", "(", "candgen_dir", ",", "file_list_name", ")", "\n", "\n", "self", ".", "qa_list", "=", "[", "]", "\n", "self", ".", "q_idx_list", "=", "[", "]", "# indicating all active questions", "\n", "self", ".", "smart_q_cand_dict", "=", "{", "}", "\n", "self", ".", "active_dicts", "=", "{", "'word'", ":", "{", "}", ",", "'mid'", ":", "{", "}", ",", "'path'", ":", "{", "}", "}", "\n", "self", ".", "active_uhashs", "=", "{", "'word'", ":", "[", "]", ",", "'mid'", ":", "[", "]", ",", "'path'", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.load_all_data": [[30, 52], ["gen_schema_dataset.DialogueSchemaDataset.load_reddit", "gen_schema_dataset.DialogueSchemaDataset.load_reddit_schemas_from_txt", "gen_schema_dataset.DialogueSchemaDataset.build_active_voc", "gen_schema_dataset.DialogueSchemaDataset.save_smart_cands", "print", "print", "print", "numpy.array", "print", "numpy.array", "print", "len", "len", "len", "len", "numpy.mean", "len", "len", "len", "gen_schema_dataset.DialogueSchemaDataset.smart_q_cand_dict.values", "numpy.sum", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.load_reddit", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.load_reddit_schemas_from_txt", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.build_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.save_smart_cands"], ["", "def", "load_all_data", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "smart_q_cand_dict", ")", ">", "0", ":", "# already loaded", "\n", "            ", "return", "\n", "\n", "", "self", ".", "load_reddit", "(", "mode", "=", "self", ".", "mode", ")", "\n", "\n", "self", ".", "load_reddit_schemas_from_txt", "(", ")", "\n", "\n", "self", ".", "build_active_voc", "(", ")", "\n", "\n", "self", ".", "save_smart_cands", "(", ")", "\n", "\n", "print", "(", "'Meta statistics:'", ")", "\n", "print", "(", "'Total posts = %d'", "%", "len", "(", "self", ".", "q_idx_list", ")", ")", "\n", "print", "(", "'Active Word / Mid / Path = %d / %d / %d (with PAD, START, UNK)'", "%", "(", "\n", "len", "(", "self", ".", "active_dicts", "[", "'word'", "]", ")", ",", "\n", "len", "(", "self", ".", "active_dicts", "[", "'mid'", "]", ")", ",", "\n", "len", "(", "self", ".", "active_dicts", "[", "'path'", "]", ")", ")", ")", "\n", "cand_size_dist", "=", "np", ".", "array", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "smart_q_cand_dict", ".", "values", "(", ")", "]", ")", "\n", "print", "(", "'Total schemas = %d, avg = %.3f'", "%", "(", "np", ".", "sum", "(", "cand_size_dist", ")", ",", "np", ".", "mean", "(", "cand_size_dist", ")", ")", ")", "\n", "qlen_dist", "=", "np", ".", "array", "(", "[", "len", "(", "qa", "[", "'tokens'", "]", ")", "for", "qa", "in", "self", ".", "qa_list", "]", ")", "\n", "print", "(", "'Avg post length = %.3f'", "%", "np", ".", "mean", "(", "qlen_dist", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.load_reddit": [[53, 59], ["print", "print", "open", "pickle.load", "len"], "methods", ["None"], ["", "def", "load_reddit", "(", "self", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "print", "(", "'Loading Reddit dialogs from pickle ...'", ")", "\n", "pickle_fp", "=", "'%s/Reddit.%s.pkl'", "%", "(", "self", ".", "data_dir", ",", "mode", ")", "\n", "with", "open", "(", "pickle_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "qa_list", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "print", "(", "'%d Reddit dialogs loaded.'", "%", "len", "(", "self", ".", "qa_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.save_smart_cands": [[60, 70], ["print", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump"], "methods", ["None"], ["", "def", "save_smart_cands", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Saving candidates into [%s] ...'", "%", "self", ".", "candgen_dir", ")", "\n", "with", "open", "(", "\"%s/q_idx.pkl\"", "%", "self", ".", "candgen_dir", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "q_idx_list", ",", "bw", ")", "\n", "", "with", "open", "(", "\"%s/q_cand.pkl\"", "%", "self", ".", "candgen_dir", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "smart_q_cand_dict", ",", "bw", ")", "\n", "", "with", "open", "(", "\"%s/active_dicts.pkl\"", "%", "self", ".", "candgen_dir", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "active_dicts", ",", "bw", ")", "\n", "", "with", "open", "(", "\"%s/active_uhashs.pkl\"", "%", "self", ".", "candgen_dir", ",", "'wb'", ")", "as", "bw", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "active_uhashs", ",", "bw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.load_reddit_schemas_from_txt": [[71, 110], ["print", "print", "enumerate", "len", "print", "print", "os.path.exists", "os.makedirs", "open", "list", "int", "gen_schema_dataset.DialogueSchemaDataset.q_idx_list.append", "gen_schema_dataset.DialogueSchemaDataset.load_schema_kq", "map", "print", "codecs.open", "br.readlines", "br.readlines", "len", "[].split", "json.loads", "gather_linkings.append", "schema_fp.rfind", "gl_line.strip", "src.kbqa.utils.link_data.LinkData", "len", "line.strip", "schema_fp.split"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.load_schema_kq"], ["", "", "def", "load_reddit_schemas_from_txt", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Loading Reddit schemas from [%s] ...'", "%", "self", ".", "candgen_dir", ")", "\n", "\n", "# Step 1: Load Auxiliary Information", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "save_dir", ")", "\n", "\n", "", "list_fp", "=", "'%s/%s'", "%", "(", "self", ".", "candgen_dir", ",", "self", ".", "file_list_name", ")", "\n", "with", "open", "(", "list_fp", ",", "'r'", ")", "as", "br", ":", "\n", "            ", "schema_fp_list", "=", "list", "(", "map", "(", "lambda", "line", ":", "'%s/%s'", "%", "(", "self", ".", "candgen_dir", ",", "line", ".", "strip", "(", ")", ")", ",", "br", ".", "readlines", "(", ")", ")", ")", "\n", "", "print", "(", "'%d schema files found in [%s].'", "%", "(", "len", "(", "schema_fp_list", ")", ",", "self", ".", "file_list_name", ")", ")", "\n", "\n", "# Step 2: Traverse & Make Statistics", "\n", "total_cand_size", "=", "0", "\n", "\n", "for", "scan_idx", ",", "schema_fp", "in", "enumerate", "(", "schema_fp_list", ")", ":", "\n", "            ", "if", "scan_idx", ">", "0", "and", "scan_idx", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "'%d / %d scanned.'", "%", "(", "scan_idx", ",", "len", "(", "schema_fp_list", ")", ")", ")", "\n", "", "link_fp", "=", "schema_fp", "[", "0", ":", "schema_fp", ".", "rfind", "(", "'_'", ")", "]", "+", "'_links'", "\n", "q_idx", "=", "int", "(", "schema_fp", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "self", ".", "q_idx_list", ".", "append", "(", "q_idx", ")", "\n", "\n", "gather_linkings", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "link_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "                ", "for", "gl_line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                    ", "tup_list", "=", "json", ".", "loads", "(", "gl_line", ".", "strip", "(", ")", ")", "\n", "ld_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "tup_list", "}", "\n", "gather_linkings", ".", "append", "(", "LinkData", "(", "**", "ld_dict", ")", ")", "\n", "\n", "", "", "candidate_list", ",", "total_lines", "=", "self", ".", "load_schema_kq", "(", "\n", "q_idx", "=", "q_idx", ",", "schema_fp", "=", "schema_fp", ",", "gather_linkings", "=", "gather_linkings", "\n", ")", "\n", "total_cand_size", "+=", "total_lines", "\n", "self", ".", "smart_q_cand_dict", "[", "q_idx", "]", "=", "candidate_list", "\n", "\n", "# Step 3: Show Statistics", "\n", "", "q_size", "=", "len", "(", "self", ".", "smart_q_cand_dict", ")", "\n", "print", "(", "'%d posts scanned:'", "%", "q_size", ")", "\n", "print", "(", "'Total schemas = %d'", "%", "total_cand_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.load_schema_kq": [[111, 127], ["codecs.open", "br.readlines", "enumerate", "len", "src.kbqa.dataset.schema.Schema", "src.kbqa.dataset.schema.Schema.read_schema_from_json", "candidate_list.append"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.schema.Schema.read_schema_from_json"], ["", "def", "load_schema_kq", "(", "self", ",", "q_idx", ",", "schema_fp", ",", "gather_linkings", ")", ":", "\n", "        ", "\"\"\"\n        Read the schema files generated by KQ.\n        \"\"\"", "\n", "candidate_list", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "schema_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "sc_lines", "=", "br", ".", "readlines", "(", ")", "\n", "for", "ori_idx", ",", "sc_line", "in", "enumerate", "(", "sc_lines", ")", ":", "\n", "                ", "schema", "=", "Schema", "(", ")", "\n", "# load schemas", "\n", "schema", ".", "read_schema_from_json", "(", "q_idx", "=", "q_idx", ",", "json_line", "=", "sc_line", ",", "gather_linkings", "=", "gather_linkings", ",", "\n", "ori_idx", "=", "ori_idx", ",", "full_constr", "=", "self", ".", "full_constr", ")", "\n", "\n", "candidate_list", ".", "append", "(", "schema", ")", "\n", "\n", "", "", "return", "candidate_list", ",", "len", "(", "sc_lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc": [[128, 132], ["len", "gen_schema_dataset.DialogueSchemaDataset.active_uhashs[].append"], "methods", ["None"], ["", "def", "add_item_into_active_voc", "(", "self", ",", "category", ",", "value", ")", ":", "\n", "        ", "if", "value", "not", "in", "self", ".", "active_dicts", "[", "category", "]", ":", "\n", "            ", "self", ".", "active_dicts", "[", "category", "]", "[", "value", "]", "=", "len", "(", "self", ".", "active_dicts", "[", "category", "]", ")", "\n", "self", ".", "active_uhashs", "[", "category", "]", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.build_active_voc": [[133, 151], ["print", "gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "print", "gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "tok.lower", "gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.DialogueSchemaDataset.add_item_into_active_voc"], ["", "", "def", "build_active_voc", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Building active word / mid / path vocabulary ... '", ")", "\n", "for", "category", "in", "(", "'word'", ",", "'mid'", ",", "'path'", ")", ":", "\n", "            ", "for", "mask", "in", "(", "'<PAD>'", ",", "'<START>'", ",", "'<UNK>'", ")", ":", "\n", "                ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "category", ",", "value", "=", "mask", ")", "\n", "", "", "for", "mask", "in", "(", "'<E>'", ",", "'<T>'", ",", "'<Tm>'", ",", "'<Ord>'", ")", ":", "\n", "            ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "mask", ")", "\n", "", "for", "q_idx", "in", "self", ".", "q_idx_list", ":", "\n", "            ", "qa", "=", "self", ".", "qa_list", "[", "q_idx", "]", "\n", "lower_tok_list", "=", "[", "tok", ".", "lower", "(", ")", "for", "tok", "in", "qa", "[", "'tokens'", "]", "]", "\n", "for", "tok", "in", "lower_tok_list", ":", "\n", "                ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "tok", ")", "\n", "", "for", "rel", ",", "head", ",", "dep", "in", "qa", "[", "'parse'", "]", ":", "\n", "                ", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "rel", ")", "\n", "self", ".", "add_item_into_active_voc", "(", "category", "=", "'word'", ",", "value", "=", "'!'", "+", "rel", ")", "\n", "\n", "", "", "for", "category", "in", "(", "'word'", ",", "'mid'", ",", "'path'", ")", ":", "\n", "            ", "print", "(", "'Active %s size = %d'", "%", "(", "category", ",", "len", "(", "self", ".", "active_dicts", "[", "category", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_schema_dataset.main": [[153, 156], ["gen_schema_dataset.DialogueSchemaDataset", "gen_schema_dataset.DialogueSchemaDataset.load_all_data"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_all_data"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "schema_dataset", "=", "DialogueSchemaDataset", "(", "args", ".", "data_dir", ",", "args", ".", "candgen_dir", ",", "mode", "=", "args", ".", "mode", ")", "\n", "schema_dataset", ".", "load_all_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinkTuple.__init__": [[23, 31], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "category", ",", "start", ",", "end", ",", "mention", ",", "mid", ",", "name", ",", "feat_dict", ")", ":", "\n", "        ", "self", ".", "category", "=", "category", "# category: this mid is an Entity or Type", "\n", "self", ".", "start", "=", "start", "# start: the starting token index of the mention", "\n", "self", ".", "end", "=", "end", "# end:  the end token index of the mention", "\n", "self", ".", "mention", "=", "mention", "# mention: the mention surface in the question", "\n", "self", ".", "mid", "=", "mid", "# mid: the linked entity mid", "\n", "self", ".", "name", "=", "name", "# name: corresponding type.object.name", "\n", "self", ".", "feat_dict", "=", "feat_dict", "# feat_dict: feature dict of linking", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker.__init__": [[34, 49], ["set", "set", "set", "gen_linkings.LukovLinker._load_fb_subset", "gen_linkings.LukovLinker._load_mid", "gen_linkings.LukovLinker._load_type", "gen_linkings.LukovLinker._load_pred", "gen_linkings.LukovLinker._load_pop_dict"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator._load_fb_subset", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_mid", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_type", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_pred", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_pop_dict"], ["    ", "def", "__init__", "(", "self", ",", "freebase_fp", ",", "mid_name_fp", ",", "type_name_fp", ",", "pred_name_fp", ",", "\n", "entity_pop_fp", ",", "type_pop_fp", ",", "allow_alias", "=", "False", ")", ":", "\n", "        ", "self", ".", "subj_pred_keys", "=", "set", "(", ")", "\n", "self", ".", "surface_mid_dict", "=", "{", "}", "# <surface, set([mid])>", "\n", "self", ".", "mid_name_dict", "=", "{", "}", "# <mid, type.object.name>", "\n", "self", ".", "type_set", "=", "set", "(", "[", "]", ")", "\n", "self", ".", "pred_set", "=", "set", "(", "[", "]", ")", "\n", "self", ".", "pop_dict", "=", "{", "}", "# <mid, popularity>", "\n", "self", ".", "skip_domain_set", "=", "{", "'common'", ",", "'type'", ",", "'user'", ",", "'base'", ",", "'freebase'", ",", "'g'", "}", "\n", "\n", "self", ".", "_load_fb_subset", "(", "freebase_fp", ")", "\n", "self", ".", "_load_mid", "(", "mid_name_fp", ",", "allow_alias", "=", "allow_alias", ")", "\n", "self", ".", "_load_type", "(", "type_name_fp", ")", "\n", "self", ".", "_load_pred", "(", "pred_name_fp", ")", "\n", "self", ".", "_load_pop_dict", "(", "entity_pop_fp", ",", "type_pop_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_fb_subset": [[50, 65], ["src.kbqa.utils.log_util.LogInfo.begin_track", "len", "src.kbqa.utils.log_util.LogInfo.logs", "enumerate", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.end_track", "codecs.open", "br.readlines", "len", "line.strip().split", "s[].replace", "gen_linkings.LukovLinker.subj_pred_keys.add", "len", "src.kbqa.utils.log_util.LogInfo.logs", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_fb_subset", "(", "self", ",", "freebase_fp", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Loading freebase subset from [%s] ...'", ",", "freebase_fp", ")", "\n", "prefix", "=", "'www.freebase.com/'", "\n", "pref_len", "=", "len", "(", "prefix", ")", "\n", "with", "codecs", ".", "open", "(", "freebase_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "lines", "=", "br", ".", "readlines", "(", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d lines loaded.'", ",", "len", "(", "lines", ")", ")", "\n", "for", "line_idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "line_idx", ">", "0", "and", "line_idx", "%", "500000", "==", "0", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "'Current: %d / %d'", ",", "line_idx", ",", "len", "(", "lines", ")", ")", "\n", "", "s", ",", "p", ",", "_", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "s", "=", "s", "[", "pref_len", ":", "]", ".", "replace", "(", "'/'", ",", "'.'", ")", "\n", "self", ".", "subj_pred_keys", ".", "add", "(", "s", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d related entities loaded.'", ",", "len", "(", "self", ".", "subj_pred_keys", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_mid": [[66, 100], ["src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.end_track", "codecs.open", "len", "len", "br.readline", "br.readline.strip().split", "name.lower", "mid.find", "len", "src.kbqa.utils.log_util.LogInfo.logs", "br.readline.strip", "gen_linkings.LukovLinker.surface_mid_dict.setdefault().add", "gen_linkings.LukovLinker.surface_mid_dict.setdefault", "set"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_mid", "(", "self", ",", "mid_name_fp", ",", "allow_alias", "=", "False", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Loading surface --> mid dictionary from [%s] ...'", ",", "mid_name_fp", ")", "\n", "with", "codecs", ".", "open", "(", "mid_name_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "scan", "=", "0", "\n", "while", "True", ":", "\n", "                ", "line", "=", "br", ".", "readline", "(", ")", "\n", "if", "line", "is", "None", "or", "line", "==", "''", ":", "\n", "                    ", "break", "\n", "", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "spt", ")", "<", "3", ":", "\n", "                    ", "continue", "\n", "", "mid", "=", "spt", "[", "0", "]", "\n", "name", "=", "spt", "[", "2", "]", "\n", "surface", "=", "name", ".", "lower", "(", ")", "# save lowercase as searching entrance", "\n", "skip", "=", "False", "# ignore some subjects at certain domain", "\n", "mid_prefix_pos", "=", "mid", ".", "find", "(", "'.'", ")", "\n", "if", "mid_prefix_pos", "==", "-", "1", ":", "\n", "                    ", "skip", "=", "True", "\n", "", "else", ":", "\n", "                    ", "mid_prefix", "=", "mid", "[", ":", "mid_prefix_pos", "]", "\n", "if", "mid_prefix", "in", "self", ".", "skip_domain_set", ":", "\n", "                        ", "skip", "=", "True", "\n", "", "", "if", "not", "skip", ":", "\n", "                    ", "if", "spt", "[", "1", "]", "==", "'type.object.name'", ":", "\n", "                        ", "self", ".", "mid_name_dict", "[", "mid", "]", "=", "name", "\n", "", "if", "spt", "[", "1", "]", "==", "'type.object.name'", "or", "allow_alias", ":", "\n", "                        ", "self", ".", "surface_mid_dict", ".", "setdefault", "(", "surface", ",", "set", "(", "[", "]", ")", ")", ".", "add", "(", "mid", ")", "\n", "", "", "scan", "+=", "1", "\n", "if", "scan", "%", "100000", "==", "0", ":", "\n", "                    ", "LogInfo", ".", "logs", "(", "'%d lines scanned.'", ",", "scan", ")", "\n", "", "", "", "LogInfo", ".", "logs", "(", "'%d lines scanned.'", ",", "scan", ")", "\n", "LogInfo", ".", "logs", "(", "'%d <surface, mid_set> loaded.'", ",", "len", "(", "self", ".", "surface_mid_dict", ")", ")", "\n", "LogInfo", ".", "logs", "(", "'%d <mid, name> loaded.'", ",", "len", "(", "self", ".", "mid_name_dict", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_type": [[101, 116], ["src.kbqa.utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "len", "line.strip().split", "type_name.lower().replace", "len", "gen_linkings.LukovLinker.surface_mid_dict.setdefault().add", "gen_linkings.LukovLinker.type_set.add", "line.strip", "type_name.lower", "type_mid.find", "gen_linkings.LukovLinker.surface_mid_dict.setdefault", "set"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_type", "(", "self", ",", "type_name_fp", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "type_name_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "spt", ")", "<", "2", ":", "\n", "                    ", "continue", "\n", "", "type_mid", ",", "type_name", "=", "spt", "[", "0", "]", ",", "spt", "[", "1", "]", "\n", "surface", "=", "type_name", ".", "lower", "(", ")", ".", "replace", "(", "'(s)'", ",", "''", ")", "\n", "type_prefix", "=", "type_mid", "[", ":", "type_mid", ".", "find", "(", "'.'", ")", "]", "\n", "if", "type_prefix", "not", "in", "self", ".", "skip_domain_set", ":", "\n", "                    ", "self", ".", "surface_mid_dict", ".", "setdefault", "(", "surface", ",", "set", "(", "[", "]", ")", ")", ".", "add", "(", "type_mid", ")", "\n", "self", ".", "mid_name_dict", "[", "type_mid", "]", "=", "type_name", "\n", "self", ".", "type_set", ".", "add", "(", "type_mid", ")", "\n", "", "", "", "LogInfo", ".", "logs", "(", "'After scanning %d types, %d <surface, mid_set> loaded.'", ",", "\n", "len", "(", "self", ".", "type_set", ")", ",", "len", "(", "self", ".", "surface_mid_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_pred": [[117, 125], ["src.kbqa.utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "line.strip().split", "gen_linkings.LukovLinker.pred_set.add", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_pred", "(", "self", ",", "pred_name_fp", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "pred_name_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "spt", ")", "<", "2", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "pred_set", ".", "add", "(", "spt", "[", "0", "]", ")", "\n", "", "", "LogInfo", ".", "logs", "(", "'%d predicates scanned.'", ",", "len", "(", "self", ".", "pred_set", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._load_pop_dict": [[126, 134], ["src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.logs", "len", "codecs.open", "br.readlines", "line.strip().split", "int", "line.strip"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_pop_dict", "(", "self", ",", "entity_pop_fp", ",", "type_pop_fp", ")", ":", "\n", "        ", "for", "pop_fp", "in", "[", "entity_pop_fp", ",", "type_pop_fp", "]", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'Reading popularity from %s ...'", ",", "pop_fp", ")", "\n", "with", "codecs", ".", "open", "(", "pop_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "                ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                    ", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "self", ".", "pop_dict", "[", "spt", "[", "0", "]", "]", "=", "int", "(", "spt", "[", "1", "]", ")", "\n", "", "", "", "LogInfo", ".", "logs", "(", "'%d <mid, popularity> loaded.'", ",", "len", "(", "self", ".", "pop_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._lowercased_surface": [[135, 157], ["range", "token_list[].lower"], "methods", ["None"], ["", "def", "_lowercased_surface", "(", "self", ",", "token_list", ",", "st", ",", "ed", ")", ":", "\n", "        ", "\"\"\"\n        Construct the surface form in [st, ed)\n        Be careful: Their may have or may not have a blank before the token starting with a punctuation\n                    For example, \"'s\" is a token starting with a punctuation.\n                    It's hard to say whether we shall directly connect two the last token, or adding a blank\n                    But we can enumerate each possibility.\n        Thus, the return value is a list of possible surfaces.\n        \"\"\"", "\n", "surface_list", "=", "[", "''", "]", "\n", "for", "idx", "in", "range", "(", "st", ",", "ed", ")", ":", "\n", "            ", "tok", "=", "token_list", "[", "idx", "]", ".", "lower", "(", ")", "\n", "if", "idx", "==", "st", ":", "# must not add blank", "\n", "                ", "new_surface_list", "=", "[", "x", "+", "tok", "for", "x", "in", "surface_list", "]", "\n", "", "elif", "idx", ">", "st", "and", "tok", "[", "0", "]", "not", "in", "punc_mask_str", ":", "# must add blank", "\n", "                ", "new_surface_list", "=", "[", "x", "+", "' '", "+", "tok", "for", "x", "in", "surface_list", "]", "\n", "", "else", ":", "# both add or not add are possible", "\n", "                ", "tmp1_list", "=", "[", "x", "+", "tok", "for", "x", "in", "surface_list", "]", "\n", "tmp2_list", "=", "[", "x", "+", "' '", "+", "tok", "for", "x", "in", "surface_list", "]", "\n", "new_surface_list", "=", "tmp1_list", "+", "tmp2_list", "\n", "", "surface_list", "=", "new_surface_list", "\n", "", "return", "surface_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker.link_single_question": [[158, 222], ["len", "range", "link_tups.sort", "range", "len", "print", "print", "gen_linkings.LukovLinkTuple", "link_tups.append", "gen_linkings.LukovLinkTuple", "gen_linkings.LukovLinker._lowercased_surface", "set", "re.match", "set.add", "gen_linkings.LukovLinker.surface_mid_dict.get", "re.match", "gen_linkings.LukovLinkTuple", "link_tups.append", "tok.lower", "set", "gen_linkings.LukovLinker.pop_dict.get"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker._lowercased_surface"], ["", "def", "link_single_question", "(", "self", ",", "q_tokens", ")", ":", "\n", "        ", "link_tups", "=", "[", "]", "\n", "token_list", "=", "q_tokens", "\n", "token_len", "=", "len", "(", "token_list", ")", "\n", "for", "i", "in", "range", "(", "token_len", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "token_len", ")", ":", "\n", "                ", "std_surface", "=", "' '", ".", "join", "(", "[", "tok", ".", "lower", "(", ")", "for", "tok", "in", "token_list", "[", "i", ":", "j", "]", "]", ")", "\n", "# LogInfo.begin_track('std_surface: %s', std_surface)", "\n", "lower_surface_list", "=", "self", ".", "_lowercased_surface", "(", "token_list", ",", "i", ",", "j", ")", "\n", "\n", "match_set", "=", "set", "(", "[", "]", ")", "\n", "if", "re", ".", "match", "(", "year_re", ",", "std_surface", ")", ":", "\n", "                    ", "match_set", ".", "add", "(", "std_surface", ")", "# time value", "\n", "", "for", "surf", "in", "lower_surface_list", ":", "\n", "                    ", "match_set", "|=", "self", ".", "surface_mid_dict", ".", "get", "(", "surf", ",", "set", "(", "[", "]", ")", ")", "\n", "", "for", "match_mid", "in", "match_set", ":", "\n", "                    ", "if", "match_mid", "in", "self", ".", "pred_set", ":", "\n", "                        ", "continue", "# won't match a mention into predicates", "\n", "", "if", "re", ".", "match", "(", "year_re", ",", "match_mid", ")", ":", "\n", "                        ", "mid_name", "=", "match_mid", "\n", "pop", "=", "1000", "# set to a rather high value", "\n", "category", "=", "'Time'", "\n", "", "else", ":", "\n", "                        ", "mid_name", "=", "self", ".", "mid_name_dict", "[", "match_mid", "]", "\n", "pop", "=", "self", ".", "pop_dict", ".", "get", "(", "match_mid", ",", "1", ")", "\n", "category", "=", "'Type'", "if", "match_mid", "in", "self", ".", "type_set", "else", "'Entity'", "\n", "# LogInfo.logs('match_mid: %s, name: %s', match_mid, mid_name)", "\n", "", "feat_dict", "=", "{", "'pop'", ":", "pop", "}", "\n", "tup", "=", "LukovLinkTuple", "(", "category", "=", "category", ",", "\n", "start", "=", "i", ",", "end", "=", "j", ",", "\n", "mention", "=", "std_surface", ",", "\n", "mid", "=", "match_mid", ",", "name", "=", "mid_name", ",", "\n", "feat_dict", "=", "feat_dict", ")", "\n", "link_tups", ".", "append", "(", "tup", ")", "\n", "# LogInfo.end_track()", "\n", "", "", "", "if", "len", "(", "link_tups", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"link_tups = 0\"", ")", "\n", "print", "(", "\"q:\"", ",", "q_tokens", ")", "\n", "feat_dict", "=", "{", "'pop'", ":", "1", "}", "\n", "tup", "=", "LukovLinkTuple", "(", "category", "=", "'Entity'", ",", "\n", "start", "=", "0", ",", "end", "=", "1", ",", "\n", "mention", "=", "'a'", ",", "\n", "mid", "=", "'m.02p6x0'", ",", "name", "=", "'A'", ",", "\n", "feat_dict", "=", "feat_dict", ")", "\n", "link_tups", ".", "append", "(", "tup", ")", "\n", "\n", "", "link_tups", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "feat_dict", "[", "'pop'", "]", ",", "reverse", "=", "True", ")", "\n", "final_tup", "=", "link_tups", "[", "0", "]", "\n", "is_in_fb", "=", "False", "\n", "for", "tup", "in", "link_tups", ":", "\n", "            ", "if", "tup", ".", "mid", "in", "self", ".", "subj_pred_keys", ":", "\n", "                ", "final_tup", "=", "tup", "\n", "is_in_fb", "=", "True", "\n", "break", "\n", "", "", "if", "not", "is_in_fb", ":", "\n", "            ", "feat_dict", "=", "{", "'pop'", ":", "1", "}", "\n", "tup", "=", "LukovLinkTuple", "(", "category", "=", "'Entity'", ",", "\n", "start", "=", "0", ",", "end", "=", "1", ",", "\n", "mention", "=", "'a'", ",", "\n", "mid", "=", "'m.02p6x0'", ",", "name", "=", "'A'", ",", "\n", "feat_dict", "=", "feat_dict", ")", "\n", "final_tup", "=", "tup", "\n", "\n", "", "return", "final_tup", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.load_simpq": [[224, 249], ["src.kbqa.utils.log_util.LogInfo.logs", "stanfordcorenlp.StanfordCoreNLP", "src.kbqa.utils.log_util.LogInfo.logs", "open", "pickle.dump", "codecs.open", "br.readlines", "len", "line.strip().split", "gen_linkings._remove_simpq_header", "gen_linkings._remove_simpq_header", "gen_linkings._remove_simpq_header", "stanfordcorenlp.StanfordCoreNLP.word_tokenize", "stanfordcorenlp.StanfordCoreNLP.dependency_parse", "qa_list.append", "src.kbqa.utils.log_util.LogInfo.logs", "line.strip", "len", "len"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings._remove_simpq_header", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings._remove_simpq_header", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings._remove_simpq_header", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "def", "load_simpq", "(", "data_dir", ")", ":", "\n", "    ", "LogInfo", ".", "logs", "(", "'SimpQ initializing ... '", ")", "\n", "qa_list", "=", "[", "]", "\n", "corenlp", "=", "StanfordCoreNLP", "(", "CORENLP_PATH", ")", "\n", "for", "Tvt", "in", "(", "'train'", ",", "'valid'", ",", "'test'", ")", ":", "\n", "        ", "fp", "=", "'%s/annotated_fb_data_%s.txt'", "%", "(", "data_dir", ",", "Tvt", ")", "\n", "with", "codecs", ".", "open", "(", "fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "qa", "=", "{", "}", "\n", "s", ",", "p", ",", "o", ",", "q", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "s", "=", "_remove_simpq_header", "(", "s", ")", "\n", "p", "=", "_remove_simpq_header", "(", "p", ")", "\n", "o", "=", "_remove_simpq_header", "(", "o", ")", "\n", "qa", "[", "'utterance'", "]", "=", "q", "\n", "qa", "[", "'targetValue'", "]", "=", "(", "s", ",", "p", ",", "o", ")", "# different from other datasets", "\n", "qa", "[", "'tokens'", "]", "=", "corenlp", ".", "word_tokenize", "(", "qa", "[", "'utterance'", "]", ")", "\n", "qa", "[", "'parse'", "]", "=", "corenlp", ".", "dependency_parse", "(", "qa", "[", "'utterance'", "]", ")", "\n", "qa_list", ".", "append", "(", "qa", ")", "\n", "if", "len", "(", "qa_list", ")", "%", "1000", "==", "0", ":", "\n", "                    ", "LogInfo", ".", "logs", "(", "'%d scanned.'", ",", "len", "(", "qa_list", ")", ")", "\n", "", "", "", "", "pickle_fp", "=", "'%s/simpQ.data.pkl'", "%", "data_dir", "\n", "with", "open", "(", "pickle_fp", ",", "'wb'", ")", "as", "bw", ":", "\n", "        ", "pickle", ".", "dump", "(", "qa_list", ",", "bw", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d SimpleQuestions loaded.'", "%", "len", "(", "qa_list", ")", ")", "\n", "return", "qa_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.load_reddit": [[251, 276], ["src.kbqa.utils.log_util.LogInfo.logs", "stanfordcorenlp.StanfordCoreNLP", "src.kbqa.utils.log_util.LogInfo.logs", "open", "open", "pickle.dump", "json.loads", "dg_list.append", "dg_line[].strip", "dg_line[].split", "stanfordcorenlp.StanfordCoreNLP.dependency_parse", "dg_line[].strip", "src.kbqa.utils.log_util.LogInfo.logs", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "load_reddit", "(", "data_dir", ",", "mode", "=", "'train'", ")", ":", "\n", "    ", "LogInfo", ".", "logs", "(", "'Reddit initializing ... '", ")", "\n", "dg_list", "=", "[", "]", "\n", "corenlp", "=", "StanfordCoreNLP", "(", "CORENLP_PATH", ")", "\n", "fp", "=", "'%s/%s.txt'", "%", "(", "data_dir", ",", "mode", ")", "\n", "with", "open", "(", "fp", ",", "'r'", ")", "as", "br", ":", "\n", "        ", "for", "line", "in", "br", ":", "\n", "            ", "dg_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "dialog", "=", "{", "'utterance'", ":", "dg_line", "[", "'post'", "]", ".", "strip", "(", ")", ",", "\n", "'tokens'", ":", "dg_line", "[", "'post'", "]", ".", "split", "(", ")", ",", "\n", "'parse'", ":", "corenlp", ".", "dependency_parse", "(", "dg_line", "[", "'post'", "]", ")", ",", "\n", "'response'", ":", "dg_line", "[", "'response'", "]", ".", "strip", "(", ")", ",", "\n", "'corr_responses'", ":", "dg_line", "[", "'corr_responses'", "]", ",", "\n", "'all_triples'", ":", "dg_line", "[", "'all_triples'", "]", ",", "\n", "'all_entities'", ":", "dg_line", "[", "'all_entities'", "]", "\n", "}", "\n", "\n", "dg_list", ".", "append", "(", "dialog", ")", "\n", "if", "len", "(", "dg_list", ")", "%", "10000", "==", "0", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "'%d scanned.'", ",", "len", "(", "dg_list", ")", ")", "\n", "", "", "", "pickle_fp", "=", "'%s/Reddit.%s.pkl'", "%", "(", "data_dir", ",", "mode", ")", "\n", "with", "open", "(", "pickle_fp", ",", "'wb'", ")", "as", "bw", ":", "\n", "        ", "pickle", ".", "dump", "(", "dg_list", ",", "bw", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d Reddit saved in [%s].'", "%", "(", "len", "(", "dg_list", ")", ",", "pickle_fp", ")", ")", "\n", "return", "dg_list", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings._remove_simpq_header": [[278, 282], ["mid.replace.replace"], "function", ["None"], ["", "def", "_remove_simpq_header", "(", "mid", ")", ":", "\n", "    ", "mid", "=", "mid", "[", "17", ":", "]", "# remove 'www.freebase.com/'", "\n", "mid", "=", "mid", ".", "replace", "(", "'/'", ",", "'.'", ")", "\n", "return", "mid", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.main": [[284, 312], ["gen_linkings.LukovLinker", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.utils.log_util.LogInfo.end_track", "gen_linkings.load_simpq", "gen_linkings.load_reddit", "codecs.open", "enumerate", "gen_linkings.LukovLinker.link_single_question", "bw.write", "src.kbqa.utils.log_util.LogInfo.logs", "json.dumps"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.load_simpq", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.load_reddit", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.gen_linkings.LukovLinker.link_single_question", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "data_name", "==", "\"SimpQ\"", ":", "\n", "        ", "qa_list", "=", "load_simpq", "(", "args", ".", "data_dir", ")", "\n", "output_file", "=", "\"%s/SimpQ.all.links\"", "%", "args", ".", "data_dir", "\n", "", "else", ":", "\n", "        ", "qa_list", "=", "load_reddit", "(", "args", ".", "data_dir", ",", "mode", "=", "args", ".", "mode", ")", "\n", "output_file", "=", "\"%s/Reddit.%s.links\"", "%", "(", "args", ".", "data_dir", ",", "args", ".", "mode", ")", "\n", "\n", "", "freebase_path", "=", "\"%s/freebase-FB2M.txt\"", "%", "args", ".", "fb_dir", "\n", "mid_name_path", "=", "\"%s/S-NAP-ENO-triple.txt\"", "%", "args", ".", "fb_meta_dir", "\n", "type_name_path", "=", "\"%s/TS-name.txt\"", "%", "args", ".", "fb_meta_dir", "\n", "pred_name_path", "=", "\"%s/PS-name.txt\"", "%", "args", ".", "fb_meta_dir", "\n", "entity_pop_path", "=", "\"%s/entity_pop_5m.txt\"", "%", "args", ".", "fb_meta_dir", "\n", "type_pop_path", "=", "\"%s/type_pop.txt\"", "%", "args", ".", "fb_meta_dir", "\n", "\n", "linker", "=", "LukovLinker", "(", "freebase_fp", "=", "freebase_path", ",", "mid_name_fp", "=", "mid_name_path", ",", "type_name_fp", "=", "type_name_path", ",", "\n", "pred_name_fp", "=", "pred_name_path", ",", "entity_pop_fp", "=", "entity_pop_path", ",", "type_pop_fp", "=", "type_pop_path", ")", "\n", "\n", "LogInfo", ".", "begin_track", "(", "'Linking data save to: %s'", "%", "output_file", ")", "\n", "with", "codecs", ".", "open", "(", "output_file", ",", "'w'", ",", "'utf-8'", ")", "as", "bw", ":", "\n", "        ", "for", "q_idx", ",", "qa", "in", "enumerate", "(", "qa_list", ")", ":", "\n", "            ", "q_tokens", "=", "qa", "[", "'tokens'", "]", "\n", "if", "q_idx", ">", "0", "and", "q_idx", "%", "10000", "==", "0", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "'Entering Q-%d'", ",", "q_idx", ")", "\n", "", "tup", "=", "linker", ".", "link_single_question", "(", "q_tokens", ")", "\n", "bw", ".", "write", "(", "'%04d\\t%d\\t%d\\t%s\\t%s\\t%s\\t%s\\n'", "%", "(", "\n", "q_idx", ",", "tup", ".", "start", ",", "tup", ".", "end", ",", "tup", ".", "mention", ",", "tup", ".", "mid", ",", "tup", ".", "name", ",", "json", ".", "dumps", "(", "tup", ".", "feat_dict", ")", ")", ")", "\n", "", "", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator.__init__": [[17, 26], ["simpq_candgen.SimpleQCandidateGenerator._load_fb_subset", "simpq_candgen.SimpleQCandidateGenerator._load_linkings"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator._load_fb_subset", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator._load_linkings"], ["    ", "def", "__init__", "(", "self", ",", "freebase_fp", ",", "links_fp", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "self", ".", "subj_pred_dict", "=", "{", "}", "\n", "self", ".", "q_links_dict", "=", "{", "}", "# <q_idx, [LinkData]>", "\n", "# verbose = 0: show basic flow of the process", "\n", "# verbose = 1: show detail linking information", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "self", ".", "_load_fb_subset", "(", "freebase_fp", ")", "\n", "self", ".", "_load_linkings", "(", "links_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator._load_fb_subset": [[27, 45], ["src.kbqa.utils.log_util.LogInfo.begin_track", "len", "src.kbqa.utils.log_util.LogInfo.logs", "enumerate", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.end_track", "codecs.open", "br.readlines", "len", "line.strip().split", "s[].replace", "p[].replace", "simpq_candgen.SimpleQCandidateGenerator.subj_pred_dict.setdefault().add", "len", "sum", "src.kbqa.utils.log_util.LogInfo.logs", "len", "line.strip", "simpq_candgen.SimpleQCandidateGenerator.subj_pred_dict.setdefault", "len", "set", "simpq_candgen.SimpleQCandidateGenerator.subj_pred_dict.values"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_fb_subset", "(", "self", ",", "fb_fp", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Loading freebase subset from [%s] ...'", ",", "fb_fp", ")", "\n", "prefix", "=", "'www.freebase.com/'", "\n", "pref_len", "=", "len", "(", "prefix", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "fb_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "lines", "=", "br", ".", "readlines", "(", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d lines loaded.'", ",", "len", "(", "lines", ")", ")", "\n", "for", "line_idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "line_idx", "%", "500000", "==", "0", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "'Current: %d / %d'", ",", "line_idx", ",", "len", "(", "lines", ")", ")", "\n", "", "s", ",", "p", ",", "_", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "s", "=", "s", "[", "pref_len", ":", "]", ".", "replace", "(", "'/'", ",", "'.'", ")", "\n", "p", "=", "p", "[", "pref_len", ":", "]", ".", "replace", "(", "'/'", ",", "'.'", ")", "\n", "self", ".", "subj_pred_dict", ".", "setdefault", "(", "s", ",", "set", "(", "[", "]", ")", ")", ".", "add", "(", "p", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d related entities and %d <S, P> pairs saved.'", ",", "\n", "len", "(", "self", ".", "subj_pred_dict", ")", ",", "sum", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "subj_pred_dict", ".", "values", "(", ")", "]", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator._load_linkings": [[46, 67], ["src.kbqa.utils.log_util.LogInfo.logs", "codecs.open", "br.readlines", "len", "line.startswith", "line.strip().split", "int", "int", "int", "json.loads", "src.kbqa.utils.link_data.LinkData", "simpq_candgen.SimpleQCandidateGenerator.q_links_dict.setdefault().append", "float", "line.strip", "simpq_candgen.SimpleQCandidateGenerator.q_links_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_load_linkings", "(", "self", ",", "links_fp", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "links_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "            ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                ", "if", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                    ", "continue", "\n", "", "spt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "q_idx", ",", "st", ",", "ed", ",", "mention", ",", "mid", ",", "wiki_name", ",", "feats", "=", "spt", "\n", "q_idx", "=", "int", "(", "q_idx", ")", "\n", "st", "=", "int", "(", "st", ")", "\n", "ed", "=", "int", "(", "ed", ")", "\n", "feat_dict", "=", "json", ".", "loads", "(", "feats", ")", "\n", "for", "k", "in", "feat_dict", ":", "\n", "                    ", "v", "=", "float", "(", "'%.6f'", "%", "feat_dict", "[", "k", "]", ")", "\n", "feat_dict", "[", "k", "]", "=", "v", "\n", "", "link_data", "=", "LinkData", "(", "category", "=", "'Entity'", ",", "\n", "start", "=", "st", ",", "end", "=", "ed", ",", "\n", "mention", "=", "mention", ",", "comp", "=", "'=='", ",", "\n", "value", "=", "mid", ",", "name", "=", "wiki_name", ",", "\n", "link_feat", "=", "feat_dict", ")", "\n", "self", ".", "q_links_dict", ".", "setdefault", "(", "q_idx", ",", "[", "]", ")", ".", "append", "(", "link_data", ")", "\n", "", "", "LogInfo", ".", "logs", "(", "'%d questions of link data loaded.'", ",", "len", "(", "self", ".", "q_links_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator.single_question_candgen": [[68, 128], ["os.path.isfile", "src.kbqa.utils.log_util.LogInfo.begin_track", "src.kbqa.utils.log_util.LogInfo.end_track", "shutil.move", "src.kbqa.utils.log_util.LogInfo.logs", "src.kbqa.utils.log_util.LogInfo.logs", "simpq_candgen.SimpleQCandidateGenerator.q_links_dict.get", "range", "len", "os.path.isfile", "shutil.move", "src.kbqa.utils.log_util.LogInfo.logs", "simpq_candgen.SimpleQCandidateGenerator.subj_pred_dict.get", "codecs.open", "len", "codecs.open", "br.readlines", "len", "len", "src.kbqa.utils.log_util.LogInfo.logs", "codecs.open", "len", "set", "src.kbqa.dataset.schema.Schema", "sc_list.append", "bw.write", "json.loads", "simpq_candgen.SimpleQCandidateGenerator.append", "gl.display", "bw.write", "getattr", "opt_raw_paths.append", "line.strip", "src.kbqa.utils.link_data.LinkData", "json.dumps", "json.dumps", "gl.serialize"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.link_data.LinkData.display", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.link_data.LinkData.serialize"], ["", "def", "single_question_candgen", "(", "self", ",", "q_idx", ",", "qa", ",", "link_fp", ",", "schema_fp", ")", ":", "\n", "# =================== Linking first ==================== #", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "link_fp", ")", ":", "\n", "            ", "gather_linkings", "=", "[", "]", "\n", "with", "codecs", ".", "open", "(", "link_fp", ",", "'r'", ",", "'utf-8'", ")", "as", "br", ":", "\n", "                ", "for", "line", "in", "br", ".", "readlines", "(", ")", ":", "\n", "                    ", "tup_list", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "ld_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "tup_list", "}", "\n", "gather_linkings", ".", "append", "(", "LinkData", "(", "**", "ld_dict", ")", ")", "\n", "", "", "LogInfo", ".", "logs", "(", "'Read %d links from file.'", ",", "len", "(", "gather_linkings", ")", ")", "\n", "", "else", ":", "\n", "            ", "gather_linkings", "=", "self", ".", "q_links_dict", ".", "get", "(", "q_idx", ",", "[", "]", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "gather_linkings", ")", ")", ":", "\n", "                ", "gather_linkings", "[", "idx", "]", ".", "gl_pos", "=", "idx", "\n", "\n", "", "", "LogInfo", ".", "begin_track", "(", "'Show %d E links :'", ",", "len", "(", "gather_linkings", ")", ")", "\n", "if", "self", ".", "verbose", ">=", "1", ":", "\n", "            ", "for", "gl", "in", "gather_linkings", ":", "\n", "                ", "LogInfo", ".", "logs", "(", "gl", ".", "display", "(", ")", ")", "\n", "", "", "LogInfo", ".", "end_track", "(", ")", "\n", "# ==================== Save linking results ================ #", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "link_fp", ")", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "link_fp", "+", "'.tmp'", ",", "'w'", ",", "'utf-8'", ")", "as", "bw", ":", "\n", "                ", "for", "gl", "in", "gather_linkings", ":", "\n", "                    ", "bw", ".", "write", "(", "json", ".", "dumps", "(", "gl", ".", "serialize", "(", ")", ")", "+", "'\\n'", ")", "\n", "", "", "shutil", ".", "move", "(", "link_fp", "+", "'.tmp'", ",", "link_fp", ")", "\n", "LogInfo", ".", "logs", "(", "'%d link data save to file.'", ",", "len", "(", "gather_linkings", ")", ")", "\n", "# ===================== simple predicate finding ===================== #", "\n", "", "gold_entity", ",", "gold_pred", ",", "_", "=", "qa", "[", "'targetValue'", "]", "\n", "sc_list", "=", "[", "]", "\n", "for", "gl_data", "in", "gather_linkings", ":", "\n", "            ", "entity", "=", "gl_data", ".", "value", "\n", "pred_set", "=", "self", ".", "subj_pred_dict", ".", "get", "(", "entity", ",", "set", "(", "[", "]", ")", ")", "\n", "for", "pred", "in", "pred_set", ":", "\n", "                ", "sc", "=", "Schema", "(", ")", "\n", "sc", ".", "hops", "=", "1", "\n", "sc", ".", "aggregate", "=", "False", "\n", "sc", ".", "main_pred_seq", "=", "[", "pred", "]", "\n", "sc", ".", "raw_paths", "=", "[", "(", "'Main'", ",", "gl_data", ",", "[", "pred", "]", ")", "]", "\n", "sc", ".", "ans_size", "=", "1", "\n", "if", "entity", "==", "gold_entity", "and", "pred", "==", "gold_pred", ":", "\n", "                    ", "sc", ".", "f1", "=", "sc", ".", "p", "=", "sc", ".", "r", "=", "1.", "\n", "", "else", ":", "\n", "                    ", "sc", ".", "f1", "=", "sc", ".", "p", "=", "sc", ".", "r", "=", "0.", "\n", "", "sc_list", ".", "append", "(", "sc", ")", "\n", "# ==================== Save schema results ================ #", "\n", "# p, r, f1, ans_size, hops, raw_paths, (agg)", "\n", "# raw_paths: (category, gl_pos, gl_mid, pred_seq)", "\n", "", "", "with", "codecs", ".", "open", "(", "schema_fp", "+", "'.tmp'", ",", "'w'", ",", "'utf-8'", ")", "as", "bw", ":", "\n", "            ", "for", "sc", "in", "sc_list", ":", "\n", "                ", "sc_info_dict", "=", "{", "k", ":", "getattr", "(", "sc", ",", "k", ")", "for", "k", "in", "(", "'p'", ",", "'r'", ",", "'f1'", ",", "'ans_size'", ",", "'hops'", ")", "}", "\n", "if", "sc", ".", "aggregate", "is", "not", "None", ":", "\n", "                    ", "sc_info_dict", "[", "'agg'", "]", "=", "sc", ".", "aggregate", "\n", "", "opt_raw_paths", "=", "[", "]", "\n", "for", "cate", ",", "gl", ",", "pred_seq", "in", "sc", ".", "raw_paths", ":", "\n", "                    ", "opt_raw_paths", ".", "append", "(", "(", "cate", ",", "gl", ".", "gl_pos", ",", "gl", ".", "value", ",", "pred_seq", ")", ")", "\n", "", "sc_info_dict", "[", "'raw_paths'", "]", "=", "opt_raw_paths", "\n", "bw", ".", "write", "(", "json", ".", "dumps", "(", "sc_info_dict", ")", "+", "'\\n'", ")", "\n", "", "", "shutil", ".", "move", "(", "schema_fp", "+", "'.tmp'", ",", "schema_fp", ")", "\n", "LogInfo", ".", "logs", "(", "'%d schemas successfully saved into [%s].'", ",", "len", "(", "sc_list", ")", ",", "schema_fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.main": [[130, 168], ["src.kbqa.utils.log_util.LogInfo.logs", "simpq_candgen.SimpleQCandidateGenerator", "enumerate", "open", "pickle.load", "src.kbqa.utils.log_util.LogInfo.begin_track", "all_lists.append", "os.path.isfile", "simpq_candgen.SimpleQCandidateGenerator.single_question_candgen", "src.kbqa.utils.log_util.LogInfo.end_track", "open", "enumerate", "len", "len", "int", "os.path.exists", "os.makedirs", "src.kbqa.utils.log_util.LogInfo.end_track", "fw.write", "fw.write", "len"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.simpq_candgen.SimpleQCandidateGenerator.single_question_candgen", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "data_path", "=", "\"%s/simpQ.data.pkl\"", "%", "args", ".", "data_dir", "\n", "freebase_path", "=", "\"%s/freebase-FB2M.txt\"", "%", "args", ".", "freebase_dir", "\n", "links_path", "=", "\"%s/SimpQ.all.links\"", "%", "args", ".", "data_dir", "\n", "\n", "with", "open", "(", "data_path", ",", "'rb'", ")", "as", "br", ":", "\n", "        ", "qa_list", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "LogInfo", ".", "logs", "(", "'%d SimpleQuestions loaded.'", "%", "len", "(", "qa_list", ")", ")", "\n", "\n", "cand_gen", "=", "SimpleQCandidateGenerator", "(", "freebase_fp", "=", "freebase_path", ",", "links_fp", "=", "links_path", ",", "\n", "verbose", "=", "args", ".", "verbose", ")", "\n", "\n", "all_list_fp", "=", "args", ".", "output_dir", "+", "'/all_list'", "\n", "all_lists", "=", "[", "]", "\n", "for", "q_idx", ",", "qa", "in", "enumerate", "(", "qa_list", ")", ":", "\n", "        ", "LogInfo", ".", "begin_track", "(", "'Entering Q %d / %d [%s]:'", ",", "\n", "q_idx", ",", "len", "(", "qa_list", ")", ",", "qa", "[", "'utterance'", "]", ")", "\n", "sub_idx", "=", "int", "(", "q_idx", "/", "1000", ")", "*", "1000", "\n", "index", "=", "'data/%d-%d/%d_schema'", "%", "(", "sub_idx", ",", "sub_idx", "+", "999", ",", "q_idx", ")", "\n", "all_lists", ".", "append", "(", "index", ")", "\n", "sub_dir", "=", "'%s/data/%d-%d'", "%", "(", "args", ".", "output_dir", ",", "sub_idx", ",", "sub_idx", "+", "999", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "sub_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "sub_dir", ")", "\n", "", "schema_fp", "=", "'%s/%d_schema'", "%", "(", "sub_dir", ",", "q_idx", ")", "\n", "link_fp", "=", "'%s/%d_links'", "%", "(", "sub_dir", ",", "q_idx", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "schema_fp", ")", ":", "\n", "            ", "LogInfo", ".", "end_track", "(", "'Skip this question, already saved.'", ")", "\n", "continue", "\n", "\n", "", "cand_gen", ".", "single_question_candgen", "(", "q_idx", "=", "q_idx", ",", "qa", "=", "qa", ",", "\n", "link_fp", "=", "link_fp", ",", "schema_fp", "=", "schema_fp", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "", "with", "open", "(", "all_list_fp", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "for", "i", ",", "idx_str", "in", "enumerate", "(", "all_lists", ")", ":", "\n", "            ", "if", "i", "==", "len", "(", "all_lists", ")", "-", "1", ":", "\n", "                ", "fw", ".", "write", "(", "idx_str", ")", "\n", "", "else", ":", "\n", "                ", "fw", ".", "write", "(", "idx_str", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.index_builder.load_raw_trainset": [[8, 16], ["open", "enumerate", "raw_train.append", "json.loads", "print"], "function", ["None"], ["def", "load_raw_trainset", "(", "data_dir", ")", ":", "\n", "    ", "raw_train", "=", "[", "]", "\n", "with", "open", "(", "'%s/trainset.txt'", "%", "data_dir", ")", "as", "f", ":", "\n", "        ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "raw_train", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "if", "idx", "%", "100000", "==", "0", "and", "idx", ">", "0", ":", "\n", "                ", "print", "(", "'read raw train line %d'", "%", "idx", ")", "\n", "", "", "", "return", "raw_train", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.index_builder.build_mapping": [[18, 41], ["range", "range", "print", "len", "keys.append", "values.append", "len", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str"], "function", ["None"], ["", "def", "build_mapping", "(", "data", ",", "index_dir", ")", ":", "\n", "    ", "posts", "=", "[", "item", "[", "\"post\"", "]", "for", "item", "in", "data", "]", "\n", "responses", "=", "[", "item", "[", "'response'", "]", "for", "item", "in", "data", "]", "\n", "keys", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "posts", ")", ")", ":", "\n", "        ", "keys", ".", "append", "(", "str", "(", "\" \"", ".", "join", "(", "posts", "[", "idx", "]", ")", ")", ")", "\n", "values", ".", "append", "(", "str", "(", "\" \"", ".", "join", "(", "responses", "[", "idx", "]", ")", ")", ")", "\n", "\n", "", "id2post", "=", "{", "}", "\n", "id2response", "=", "{", "}", "\n", "global_id", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "keys", ")", ")", ":", "\n", "        ", "id2post", "[", "str", "(", "global_id", ")", "]", "=", "keys", "[", "i", "]", "\n", "id2response", "[", "str", "(", "global_id", ")", "]", "=", "values", "[", "i", "]", "\n", "global_id", "+=", "1", "\n", "", "print", "(", "\"total id:\"", ",", "global_id", ")", "\n", "with", "open", "(", "\"%s/id2post.json\"", "%", "index_dir", ",", "\"w\"", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "id2post", ",", "fw", ")", "\n", "", "with", "open", "(", "\"%s/id2response.json\"", "%", "index_dir", ",", "\"w\"", ")", "as", "fw", ":", "\n", "        ", "json", ".", "dump", "(", "id2response", ",", "fw", ")", "\n", "\n", "", "return", "id2post", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.index_builder.main": [[43, 55], ["index_builder.load_raw_trainset", "index_builder.build_mapping", "src.utils.retriever.Indexer", "src.utils.retriever.Indexer.build_index", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.index_builder.load_raw_trainset", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.index_builder.build_mapping", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Indexer.build_index"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "index_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "index_dir", ")", "\n", "# load train data", "\n", "", "data_train", "=", "load_raw_trainset", "(", "args", ".", "data_dir", ")", "\n", "\n", "# build mappings: <id, post>, <id, response>", "\n", "id2post", "=", "build_mapping", "(", "data_train", ",", "args", ".", "index_dir", ")", "\n", "\n", "# build data index of posts", "\n", "indexer", "=", "Indexer", "(", "args", ".", "index_dir", ")", "\n", "indexer", ".", "build_index", "(", "id2post", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.response_candgen.data_gen": [[7, 75], ["print", "print", "src.utils.retriever.Queryer", "print", "open", "enumerate", "open", "json.load", "print", "open", "zip", "json.loads", "posts.append", "resps.append", "all_triples.append", "all_entities.append", "open", "enumerate", "response_candgen._validate", "src.utils.retriever.Queryer.run_query", "json.dumps", "fw.write", "print", "line.strip", "entity_lists.append", "response_k.append", "print", "ent_indexs.append"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.response_candgen._validate", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.retriever.Queryer.run_query"], ["def", "data_gen", "(", "data_dir", ",", "index_dir", ",", "top_k", "=", "3", ",", "mode", "=", "\"valid\"", ")", ":", "\n", "    ", "posts", ",", "resps", ",", "all_triples", ",", "all_entities", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "with", "open", "(", "\"%s/%sset.txt\"", "%", "(", "data_dir", ",", "mode", ")", ")", "as", "f", ":", "\n", "        ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "text_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "post", "=", "\" \"", ".", "join", "(", "text_line", "[", "'post'", "]", ")", "\n", "resp", "=", "\" \"", ".", "join", "(", "text_line", "[", "'response'", "]", ")", "\n", "triples", "=", "text_line", "[", "'all_triples'", "]", "\n", "entities", "=", "text_line", "[", "'all_entities'", "]", "\n", "posts", ".", "append", "(", "post", ")", "\n", "resps", ".", "append", "(", "resp", ")", "\n", "all_triples", ".", "append", "(", "triples", ")", "\n", "all_entities", ".", "append", "(", "entities", ")", "\n", "if", "idx", "%", "100000", "==", "0", "and", "idx", ">", "0", ":", "\n", "                ", "print", "(", "\"loading %d samples...\"", "%", "idx", ")", "\n", "", "", "", "print", "(", "\"load %s set done.\"", "%", "mode", ")", "\n", "\n", "with", "open", "(", "\"%s/id2response.json\"", "%", "index_dir", ",", "'r'", ")", "as", "fr", ":", "\n", "        ", "id2response", "=", "json", ".", "load", "(", "fr", ")", "\n", "", "print", "(", "\"load index id2response done.\"", ")", "\n", "\n", "entity_lists", "=", "[", "]", "\n", "if", "mode", "==", "\"test\"", ":", "\n", "        ", "with", "open", "(", "\"%s/csk_entity.txt\"", "%", "data_dir", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "e", "=", "line", ".", "strip", "(", ")", "\n", "entity_lists", ".", "append", "(", "e", ")", "\n", "", "", "print", "(", "\"load csk_entity done.\"", ")", "\n", "\n", "", "cnt", "=", "0", "\n", "queryer", "=", "Queryer", "(", "index_dir", ",", "top_k", "=", "top_k", ")", "\n", "with", "open", "(", "\"%s/%s.txt\"", "%", "(", "data_dir", ",", "mode", ")", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "for", "post", ",", "resp", ",", "all_triple", ",", "all_entity", "in", "zip", "(", "posts", ",", "resps", ",", "all_triples", ",", "all_entities", ")", ":", "\n", "# search corresponding responses of top-k posts", "\n", "            ", "query", "=", "_validate", "(", "post", ")", "\n", "result", "=", "queryer", ".", "run_query", "(", "query", ")", "\n", "result_ids", "=", "result", "[", "'ids'", "]", "\n", "response_k", "=", "[", "]", "\n", "for", "idx", "in", "result_ids", ":", "\n", "                ", "sent", "=", "id2response", "[", "idx", "]", "\n", "response_k", ".", "append", "(", "sent", ")", "\n", "", "if", "mode", "==", "\"test\"", ":", "\n", "                ", "ent_indexs", "=", "[", "]", "\n", "for", "ent_list", "in", "all_entity", ":", "\n", "                    ", "for", "idx", "in", "ent_list", ":", "\n", "                        ", "ent_indexs", ".", "append", "(", "idx", ")", "\n", "", "", "entities", "=", "[", "entity_lists", "[", "idx", "]", "for", "idx", "in", "ent_indexs", "]", "\n", "data", "=", "{", "'post'", ":", "post", ",", "\n", "'response'", ":", "resp", ",", "\n", "'corr_responses'", ":", "response_k", ",", "\n", "'all_triples'", ":", "all_triple", ",", "\n", "'all_entities'", ":", "all_entity", ",", "\n", "'entities'", ":", "entities", "\n", "}", "\n", "", "else", ":", "\n", "                ", "data", "=", "{", "'post'", ":", "post", ",", "\n", "'response'", ":", "resp", ",", "\n", "'corr_responses'", ":", "response_k", ",", "\n", "'all_triples'", ":", "all_triple", ",", "\n", "'all_entities'", ":", "all_entity", "\n", "}", "\n", "", "json_str", "=", "json", ".", "dumps", "(", "data", ")", "\n", "fw", ".", "write", "(", "json_str", "+", "'\\n'", ")", "\n", "cnt", "+=", "1", "\n", "if", "cnt", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "\"writing %d samples...\"", "%", "cnt", ")", "\n", "", "", "", "print", "(", "\"process %s done.\"", "%", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.response_candgen._validate": [[76, 84], ["str().strip", "str", "valid_query.replace.replace"], "function", ["None"], ["", "def", "_validate", "(", "query", ")", ":", "\n", "    ", "valid_query", "=", "str", "(", "query", ")", ".", "strip", "(", ")", "\n", "remove_str", "=", "[", "'*'", ",", "'?'", ",", "'!'", ",", "':'", ",", "'-'", ",", "'('", ",", "')'", ",", "'['", ",", "']'", ",", "'{'", ",", "'}'", "]", "\n", "for", "s", "in", "remove_str", ":", "\n", "        ", "if", "s", "in", "valid_query", ":", "\n", "            ", "valid_query", "=", "valid_query", ".", "replace", "(", "s", ",", "''", ")", "\n", "\n", "", "", "return", "valid_query", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.response_candgen.main": [[86, 88], ["response_candgen.data_gen"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.response_candgen.data_gen"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "data_gen", "(", "data_dir", "=", "args", ".", "data_dir", ",", "index_dir", "=", "args", ".", "index_dir", ",", "top_k", "=", "args", ".", "top_k", ",", "mode", "=", "args", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.__init__": [[14, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "candgen_dir", ",", "mode", "=", "'train'", ")", ":", "\n", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "candgen_dir", "=", "candgen_dir", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "self", ".", "q_idx_list", "=", "[", "]", "\n", "self", ".", "dialog_list", "=", "[", "]", "\n", "self", ".", "q_cand_dict", "=", "{", "}", "\n", "self", ".", "csk_triples", "=", "[", "]", "\n", "self", ".", "csk_entities", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_all_data": [[26, 38], ["preprocess_dataset.DialogueDataset.load_dialog_list", "preprocess_dataset.DialogueDataset.load_schemas", "preprocess_dataset.DialogueDataset.load_csk_triples", "preprocess_dataset.DialogueDataset.load_csk_entities", "print", "print", "numpy.array", "print", "numpy.array", "print", "len", "len", "len", "numpy.mean", "preprocess_dataset.DialogueDataset.q_cand_dict.values", "numpy.sum", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_dialog_list", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_schemas", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_csk_triples", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_csk_entities"], ["", "def", "load_all_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "load_dialog_list", "(", "mode", "=", "self", ".", "mode", ")", "\n", "self", ".", "load_schemas", "(", ")", "\n", "self", ".", "load_csk_triples", "(", ")", "\n", "self", ".", "load_csk_entities", "(", ")", "\n", "\n", "print", "(", "'Meta statistics:'", ")", "\n", "print", "(", "'Total posts = %d'", "%", "len", "(", "self", ".", "q_idx_list", ")", ")", "\n", "cand_size_dist", "=", "np", ".", "array", "(", "[", "len", "(", "v", ")", "for", "v", "in", "self", ".", "q_cand_dict", ".", "values", "(", ")", "]", ")", "\n", "print", "(", "'Total schemas = %d, avg = %.3f.'", "%", "(", "np", ".", "sum", "(", "cand_size_dist", ")", ",", "np", ".", "mean", "(", "cand_size_dist", ")", ")", ")", "\n", "qlen_dist", "=", "np", ".", "array", "(", "[", "len", "(", "qa", "[", "'tokens'", "]", ")", "for", "qa", "in", "self", ".", "dialog_list", "]", ")", "\n", "print", "(", "'Avg post length = %.3f.'", "%", "np", ".", "mean", "(", "qlen_dist", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_dialog_list": [[39, 45], ["print", "print", "open", "pickle.load", "len"], "methods", ["None"], ["", "def", "load_dialog_list", "(", "self", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "pickle_fp", "=", "'%s/Reddit.%s.pkl'", "%", "(", "self", ".", "data_dir", ",", "mode", ")", "\n", "print", "(", "'Loading Reddit dialogs from [%s] ...'", "%", "pickle_fp", ")", "\n", "with", "open", "(", "pickle_fp", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "dialog_list", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "print", "(", "'%d dialogs loaded.'", "%", "len", "(", "self", ".", "dialog_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_schemas": [[46, 52], ["print", "open", "pickle.load", "open", "pickle.load"], "methods", ["None"], ["", "def", "load_schemas", "(", "self", ")", ":", "\n", "        ", "print", "(", "'Loading schemas from [%s] ...'", "%", "self", ".", "candgen_dir", ")", "\n", "with", "open", "(", "\"%s/q_idx.pkl\"", "%", "self", ".", "candgen_dir", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "q_idx_list", "=", "pickle", ".", "load", "(", "br", ")", "\n", "", "with", "open", "(", "\"%s/q_cand.pkl\"", "%", "self", ".", "candgen_dir", ",", "'rb'", ")", "as", "br", ":", "\n", "            ", "self", ".", "q_cand_dict", "=", "pickle", ".", "load", "(", "br", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_csk_triples": [[53, 60], ["print", "print", "open", "enumerate", "preprocess_dataset.DialogueDataset.csk_triples.append", "len", "triple.strip"], "methods", ["None"], ["", "", "def", "load_csk_triples", "(", "self", ")", ":", "\n", "        ", "kb_triple_fp", "=", "\"%s/csk_triples.txt\"", "%", "self", ".", "data_dir", "\n", "print", "(", "'Loading commonsense triples from [%s]'", "%", "kb_triple_fp", ")", "\n", "with", "open", "(", "kb_triple_fp", ",", "'r'", ")", "as", "fr", ":", "\n", "            ", "for", "idx", ",", "triple", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "self", ".", "csk_triples", ".", "append", "(", "triple", ".", "strip", "(", ")", ")", "\n", "", "", "print", "(", "\"%d triples loaded\"", "%", "len", "(", "self", ".", "csk_triples", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_csk_entities": [[61, 68], ["print", "print", "open", "enumerate", "preprocess_dataset.DialogueDataset.csk_entities.append", "len", "entity.strip"], "methods", ["None"], ["", "def", "load_csk_entities", "(", "self", ")", ":", "\n", "        ", "kb_entity_fp", "=", "\"%s/csk_entities.txt\"", "%", "self", ".", "data_dir", "\n", "print", "(", "'Loading commonsense entities from [%s]'", "%", "kb_entity_fp", ")", "\n", "with", "open", "(", "kb_entity_fp", ",", "'r'", ")", "as", "fr", ":", "\n", "            ", "for", "idx", ",", "entity", "in", "enumerate", "(", "fr", ")", ":", "\n", "                ", "self", ".", "csk_entities", ".", "append", "(", "entity", ".", "strip", "(", ")", ")", "\n", "", "", "print", "(", "\"%d entities loaded\"", "%", "len", "(", "self", ".", "csk_entities", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder.__init__": [[72, 87], ["print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "schema_dataset", ",", "feature_helper", ",", "\n", "max_post_len", "=", "30", ",", "max_resp_len", "=", "30", ",", "max_triple_num", "=", "8", ",", "max_triple_len", "=", "20", ")", ":", "\n", "        ", "print", "(", "'SchemaBuilder initializing ...'", ")", "\n", "self", ".", "mode", "=", "schema_dataset", ".", "mode", "\n", "self", ".", "q_idx_list", "=", "schema_dataset", ".", "q_idx_list", "\n", "self", ".", "dialog_list", "=", "schema_dataset", ".", "dialog_list", "\n", "self", ".", "q_cand_dict", "=", "schema_dataset", ".", "q_cand_dict", "\n", "self", ".", "csk_triples", "=", "schema_dataset", ".", "csk_triples", "\n", "self", ".", "csk_entities", "=", "schema_dataset", ".", "csk_entities", "\n", "self", ".", "feat_gen_helper", "=", "feature_helper", "\n", "\n", "self", ".", "max_post_len", "=", "max_post_len", "\n", "self", ".", "max_resp_len", "=", "max_resp_len", "\n", "self", ".", "max_triple_num", "=", "max_triple_num", "\n", "self", ".", "max_triple_len", "=", "max_triple_len", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder.show_statistic": [[88, 125], ["max", "max", "max", "max", "max", "max", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "len", "len", "len", "len", "[].split", "[].split"], "methods", ["None"], ["", "def", "show_statistic", "(", "self", ")", ":", "\n", "        ", "posts", "=", "[", "len", "(", "self", ".", "dialog_list", "[", "idx", "]", "[", "'utterance'", "]", ".", "split", "(", ")", ")", "for", "idx", "in", "self", ".", "q_idx_list", "]", "\n", "resps", "=", "[", "len", "(", "self", ".", "dialog_list", "[", "idx", "]", "[", "'response'", "]", ".", "split", "(", ")", ")", "for", "idx", "in", "self", ".", "q_idx_list", "]", "\n", "triple_nums", "=", "[", "len", "(", "self", ".", "dialog_list", "[", "idx", "]", "[", "'all_triples'", "]", ")", "for", "idx", "in", "self", ".", "q_idx_list", "]", "\n", "triple_lens", "=", "[", "len", "(", "triple", ")", "for", "idx", "in", "self", ".", "q_idx_list", "for", "triple", "in", "self", ".", "dialog_list", "[", "idx", "]", "[", "'all_triples'", "]", "]", "\n", "entity_nums", "=", "[", "len", "(", "self", ".", "dialog_list", "[", "idx", "]", "[", "'all_entities'", "]", ")", "for", "idx", "in", "self", ".", "q_idx_list", "]", "\n", "entity_lens", "=", "[", "len", "(", "ent", ")", "for", "idx", "in", "self", ".", "q_idx_list", "for", "ent", "in", "self", ".", "dialog_list", "[", "idx", "]", "[", "'all_entities'", "]", "]", "\n", "\n", "max_post_len", "=", "max", "(", "posts", ")", "\n", "max_resp_len", "=", "max", "(", "resps", ")", "\n", "max_triple_num", "=", "max", "(", "triple_nums", ")", "\n", "max_triple_len", "=", "max", "(", "triple_lens", ")", "\n", "max_ent_num", "=", "max", "(", "entity_nums", ")", "\n", "max_ent_len", "=", "max", "(", "entity_lens", ")", "\n", "\n", "avg_post_len", "=", "np", ".", "mean", "(", "posts", ")", "\n", "avg_resp_len", "=", "np", ".", "mean", "(", "resps", ")", "\n", "avg_triple_num", "=", "np", ".", "mean", "(", "triple_nums", ")", "\n", "avg_triple_len", "=", "np", ".", "mean", "(", "triple_lens", ")", "\n", "avg_ent_num", "=", "np", ".", "mean", "(", "entity_nums", ")", "\n", "avg_ent_len", "=", "np", ".", "mean", "(", "entity_lens", ")", "\n", "\n", "print", "(", "\"Max post length = %d\"", "%", "max_post_len", ")", "# 64", "\n", "print", "(", "\"Max response length = %d\"", "%", "max_resp_len", ")", "# 60", "\n", "print", "(", "\"Max triple num = %d\"", "%", "max_triple_num", ")", "# 23", "\n", "print", "(", "\"Max triple length = %d\"", "%", "max_triple_len", ")", "# 25", "\n", "print", "(", "\"Max entity num = %d\"", "%", "max_ent_num", ")", "\n", "print", "(", "\"Max entity length = %d\"", "%", "max_ent_len", ")", "\n", "\n", "print", "(", "\"Avg post length = %.3f\"", "%", "avg_post_len", ")", "# 20", "\n", "print", "(", "\"Avg response length = %.3f\"", "%", "avg_resp_len", ")", "# 20", "\n", "print", "(", "\"Avg triple num = %.3f\"", "%", "avg_triple_num", ")", "# 5", "\n", "print", "(", "\"Avg triple length = %.3f\"", "%", "avg_triple_len", ")", "# 18", "\n", "print", "(", "\"Avg entity num = %.3f\"", "%", "avg_ent_num", ")", "\n", "print", "(", "\"Avg entity length = %.3f\"", "%", "avg_ent_len", ")", "\n", "\n", "return", "max_post_len", ",", "max_resp_len", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder.save_to_pickle": [[126, 191], ["os.path.exists", "os.mkdir", "enumerate", "chunk_list.append", "print", "print", "enumerate", "print", "print", "preprocess_dataset.DialogueBuilder._input_feat_gen", "open", "pickle.dump", "open", "preprocess_dataset.DialogueBuilder._input_feat_gen", "open", "pickle.dump", "print", "chunk_list.append", "print", "fw.write", "open", "pickle.dump", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._input_feat_gen", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._input_feat_gen"], ["", "def", "save_to_pickle", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "\n", "", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "q_dict", "=", "{", "}", "\n", "chunk_idx", "=", "0", "\n", "chunk_list", "=", "[", "]", "\n", "for", "scan_idx", ",", "q_idx", "in", "enumerate", "(", "self", ".", "q_idx_list", ")", ":", "\n", "                ", "cand_list", "=", "self", ".", "q_cand_dict", "[", "q_idx", "]", "\n", "schema", "=", "cand_list", "[", "0", "]", "# we just pick the first schema", "\n", "\n", "# Generate input features here", "\n", "input_np_dict", "=", "self", ".", "_input_feat_gen", "(", "schema", ",", "max_post_len", "=", "self", ".", "max_post_len", ",", "\n", "max_resp_len", "=", "self", ".", "max_resp_len", ",", "\n", "max_triple_num", "=", "self", ".", "max_triple_num", ",", "\n", "max_triple_len", "=", "self", ".", "max_triple_len", ")", "\n", "q_dict", "[", "q_idx", "]", "=", "input_np_dict", "\n", "if", "scan_idx", "+", "1", ">", "0", "and", "(", "scan_idx", "+", "1", ")", "%", "CHUNK_SIZE", "==", "0", ":", "\n", "                    ", "print", "(", "'scanned %d / %d questions.'", "%", "(", "scan_idx", "+", "1", ",", "len", "(", "self", ".", "q_idx_list", ")", ")", ")", "\n", "# save to chunk file", "\n", "chunk_idx", "+=", "1", "\n", "chunk_file", "=", "\"train.%03d.pkl\"", "%", "chunk_idx", "\n", "chunk_list", ".", "append", "(", "chunk_file", ")", "\n", "save_path", "=", "\"%s/%s\"", "%", "(", "save_dir", ",", "chunk_file", ")", "\n", "with", "open", "(", "save_path", ",", "'wb'", ")", "as", "bw", ":", "\n", "                        ", "pickle", ".", "dump", "(", "q_dict", ",", "bw", ")", "\n", "", "print", "(", "\"Saved data to pickle [%s]\"", "%", "save_path", ")", "\n", "q_dict", "=", "{", "}", "\n", "# remain data save to chunk file", "\n", "", "", "chunk_idx", "+=", "1", "\n", "chunk_file", "=", "\"train.%03d.pkl\"", "%", "chunk_idx", "\n", "chunk_list", ".", "append", "(", "chunk_file", ")", "\n", "save_path", "=", "\"%s/%s\"", "%", "(", "save_dir", ",", "chunk_file", ")", "\n", "with", "open", "(", "save_path", ",", "'wb'", ")", "as", "bw", ":", "\n", "                ", "pickle", ".", "dump", "(", "q_dict", ",", "bw", ")", "\n", "", "print", "(", "\"Saved data to pickle [%s]\"", "%", "save_path", ")", "\n", "\n", "# save index list", "\n", "index_save_path", "=", "\"%s/all_list\"", "%", "save_dir", "\n", "with", "open", "(", "index_save_path", ",", "'w'", ")", "as", "fw", ":", "\n", "                ", "for", "idx", "in", "chunk_list", ":", "\n", "                    ", "fw", ".", "write", "(", "idx", "+", "'\\n'", ")", "\n", "", "", "print", "(", "\"Index saved to [%s]\"", "%", "index_save_path", ")", "\n", "", "else", ":", "\n", "# TODO: use ground-truth length for valid/test data", "\n", "# max_post_len, max_resp_len = self.show_statistic()", "\n", "            ", "q_dict", "=", "{", "}", "\n", "total_size", "=", "0", "\n", "for", "scan_idx", ",", "q_idx", "in", "enumerate", "(", "self", ".", "q_idx_list", ")", ":", "\n", "                ", "cand_list", "=", "self", ".", "q_cand_dict", "[", "q_idx", "]", "\n", "schema", "=", "cand_list", "[", "0", "]", "# we just pick the first schema", "\n", "\n", "# Generate input features here", "\n", "input_np_dict", "=", "self", ".", "_input_feat_gen", "(", "schema", ",", "max_post_len", "=", "self", ".", "max_post_len", ",", "\n", "max_resp_len", "=", "self", ".", "max_resp_len", ",", "\n", "max_triple_num", "=", "self", ".", "max_triple_num", ",", "\n", "max_triple_len", "=", "self", ".", "max_triple_len", ")", "\n", "q_dict", "[", "q_idx", "]", "=", "input_np_dict", "\n", "total_size", "+=", "1", "\n", "", "print", "(", "'In total: data size = %d.'", "%", "total_size", ")", "\n", "save_path", "=", "\"%s/%s.pkl\"", "%", "(", "save_dir", ",", "self", ".", "mode", ")", "\n", "with", "open", "(", "save_path", ",", "'wb'", ")", "as", "bw", ":", "\n", "                ", "pickle", ".", "dump", "(", "q_dict", ",", "bw", ")", "\n", "", "print", "(", "\"Saved data to pickle [%s]\"", "%", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._input_feat_gen": [[192, 258], ["dialog[].split", "preprocess_dataset.DialogueBuilder._pad_sent", "dialog[].split", "preprocess_dataset.DialogueBuilder._pad_sent", "preprocess_dataset.DialogueBuilder._pad_triple", "preprocess_dataset.DialogueBuilder._pad_entity", "preprocess_dataset.DialogueBuilder.feat_gen_helper.generate_qw_feat", "preprocess_dataset.DialogueBuilder.feat_gen_helper.generate_dep_feat", "res.split", "preprocess_dataset.DialogueBuilder._pad_sent", "pad_corr_responses.append", "preprocess_dataset.DialogueBuilder.csk_triples[].split", "entities.append"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_sent", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_sent", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_triple", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_entity", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_qw_feat", "home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.feature_helper.FeatureHelper.generate_dep_feat", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_sent"], ["", "", "def", "_input_feat_gen", "(", "self", ",", "schema", ",", "max_post_len", ",", "max_resp_len", ",", "max_triple_num", ",", "max_triple_len", ")", ":", "\n", "        ", "q_idx", "=", "schema", ".", "q_idx", "\n", "dialog", "=", "self", ".", "dialog_list", "[", "q_idx", "]", "\n", "post_tokens", "=", "dialog", "[", "'utterance'", "]", ".", "split", "(", ")", "\n", "post_len", ",", "post", "=", "self", ".", "_pad_sent", "(", "post_tokens", ",", "max_post_len", ")", "\n", "\n", "response_tokens", "=", "dialog", "[", "'response'", "]", ".", "split", "(", ")", "\n", "response_len", ",", "response", "=", "self", ".", "_pad_sent", "(", "response_tokens", ",", "max_resp_len", ")", "\n", "\n", "corr_responses", "=", "dialog", "[", "'corr_responses'", "]", "\n", "pad_corr_responses", "=", "[", "]", "\n", "for", "res", "in", "corr_responses", ":", "\n", "            ", "tokens", "=", "res", ".", "split", "(", ")", "\n", "_", ",", "token_pad", "=", "self", ".", "_pad_sent", "(", "tokens", ",", "max_resp_len", ")", "\n", "pad_corr_responses", ".", "append", "(", "token_pad", ")", "\n", "\n", "", "all_triple_ids", "=", "dialog", "[", "'all_triples'", "]", "\n", "pad_all_triples", "=", "self", ".", "_pad_triple", "(", "\n", "[", "[", "self", ".", "csk_triples", "[", "x", "]", ".", "split", "(", "', '", ")", "for", "x", "in", "triple", "]", "for", "triple", "in", "all_triple_ids", "]", ",", "\n", "max_triple_num", ",", "max_triple_len", "\n", ")", "\n", "\n", "all_entity_ids", "=", "dialog", "[", "'all_entities'", "]", "\n", "pad_all_entities", "=", "self", ".", "_pad_entity", "(", "\n", "[", "[", "self", ".", "csk_entities", "[", "x", "]", "for", "x", "in", "entity", "]", "for", "entity", "in", "all_entity_ids", "]", ",", "\n", "max_triple_num", ",", "max_triple_len", "\n", ")", "\n", "\n", "qw_input", ",", "qw_len", "=", "self", ".", "feat_gen_helper", ".", "generate_qw_feat", "(", "sc", "=", "schema", ")", "\n", "dep_input", ",", "dep_len", "=", "self", ".", "feat_gen_helper", ".", "generate_dep_feat", "(", "sc", "=", "schema", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "entities", "=", "[", "]", "\n", "for", "ent_id_list", "in", "all_entity_ids", ":", "\n", "                ", "for", "ent_id", "in", "ent_id_list", ":", "\n", "                    ", "entities", ".", "append", "(", "self", ".", "csk_entities", "[", "ent_id", "]", ")", "\n", "\n", "", "", "input_np_dict", "=", "{", "\n", "'post'", ":", "post", ",", "\n", "'post_len'", ":", "post_len", ",", "\n", "'response'", ":", "response", ",", "\n", "'response_len'", ":", "response_len", ",", "\n", "'corr_responses'", ":", "pad_corr_responses", ",", "\n", "'all_triples'", ":", "pad_all_triples", ",", "\n", "'all_entities'", ":", "pad_all_entities", ",", "\n", "'entities'", ":", "entities", ",", "\n", "'qw_input'", ":", "qw_input", ",", "\n", "'qw_len'", ":", "qw_len", ",", "\n", "'dep_input'", ":", "dep_input", ",", "\n", "'dep_len'", ":", "dep_len", "\n", "}", "\n", "", "else", ":", "\n", "            ", "input_np_dict", "=", "{", "\n", "'post'", ":", "post", ",", "\n", "'post_len'", ":", "post_len", ",", "\n", "'response'", ":", "response", ",", "\n", "'response_len'", ":", "response_len", ",", "\n", "'corr_responses'", ":", "pad_corr_responses", ",", "\n", "'all_triples'", ":", "pad_all_triples", ",", "\n", "'all_entities'", ":", "pad_all_entities", ",", "\n", "'qw_input'", ":", "qw_input", ",", "\n", "'qw_len'", ":", "qw_len", ",", "\n", "'dep_input'", ":", "dep_input", ",", "\n", "'dep_len'", ":", "dep_len", "\n", "}", "\n", "", "return", "input_np_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_sent": [[259, 269], ["len", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_pad_sent", "(", "s", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "s", ")", ">=", "max_len", "-", "1", ":", "\n", "            ", "sentence", "=", "s", "[", ":", "max_len", "-", "1", "]", "+", "[", "'_EOS'", "]", "\n", "sent_len", "=", "max_len", "\n", "\n", "", "else", ":", "\n", "            ", "sentence", "=", "s", "+", "[", "'_EOS'", "]", "+", "[", "'_PAD'", "]", "*", "(", "max_len", "-", "len", "(", "s", ")", "-", "1", ")", "\n", "sent_len", "=", "len", "(", "s", ")", "+", "1", "\n", "", "return", "sent_len", ",", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_triple": [[270, 284], ["len", "len", "new_triple.append", "new_triple.append", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_pad_triple", "(", "triple", ",", "max_num", ",", "max_len", ")", ":", "\n", "        ", "new_triple", "=", "[", "]", "\n", "for", "tri", "in", "triple", ":", "\n", "            ", "if", "len", "(", "tri", ")", ">=", "max_len", ":", "\n", "                ", "new_triple", ".", "append", "(", "tri", "[", ":", "max_len", "]", ")", "\n", "", "else", ":", "\n", "                ", "new_triple", ".", "append", "(", "tri", "+", "[", "[", "'_PAD_H'", ",", "'_PAD_R'", ",", "'_PAD_T'", "]", "]", "*", "(", "max_len", "-", "len", "(", "tri", ")", ")", ")", "\n", "", "", "pad_triple", "=", "[", "[", "'_PAD_H'", ",", "'_PAD_R'", ",", "'_PAD_T'", "]", "]", "*", "max_len", "\n", "if", "len", "(", "new_triple", ")", ">=", "max_num", ":", "\n", "            ", "final_triple", "=", "new_triple", "[", ":", "max_num", "]", "\n", "", "else", ":", "\n", "            ", "final_triple", "=", "new_triple", "+", "[", "pad_triple", "]", "*", "(", "max_num", "-", "len", "(", "new_triple", ")", ")", "\n", "", "return", "final_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder._pad_entity": [[285, 300], ["len", "len", "new_ent.append", "new_ent.append", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_pad_entity", "(", "ents", ",", "max_num", ",", "max_len", ")", ":", "\n", "        ", "new_ent", "=", "[", "]", "\n", "for", "ent", "in", "ents", ":", "\n", "            ", "if", "len", "(", "ent", ")", ">=", "max_len", ":", "\n", "                ", "new_ent", ".", "append", "(", "ent", "[", ":", "max_len", "]", ")", "\n", "", "else", ":", "\n", "                ", "new_ent", ".", "append", "(", "ent", "+", "[", "'_PAD'", "]", "*", "(", "max_len", "-", "len", "(", "ent", ")", ")", ")", "\n", "\n", "", "", "pad_entity", "=", "[", "'_PAD'", "]", "*", "max_len", "\n", "if", "len", "(", "new_ent", ")", ">=", "max_num", ":", "\n", "            ", "final_entity", "=", "new_ent", "[", ":", "max_num", "]", "\n", "", "else", ":", "\n", "            ", "final_entity", "=", "new_ent", "+", "[", "pad_entity", "]", "*", "(", "max_num", "-", "len", "(", "new_ent", ")", ")", "\n", "", "return", "final_entity", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.main": [[302, 314], ["preprocess_dataset.DialogueDataset", "preprocess_dataset.DialogueDataset.load_all_data", "src.kbqa.dataset.feature_helper.FeatureHelper", "preprocess_dataset.DialogueBuilder", "preprocess_dataset.DialogueBuilder.save_to_pickle", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueDataset.load_all_data", "home.repos.pwc.inspect_result.siat-nlp_TransDG.scripts.preprocess_dataset.DialogueBuilder.save_to_pickle"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "dataset", "=", "DialogueDataset", "(", "args", ".", "data_dir", ",", "args", ".", "candgen_dir", ",", "mode", "=", "args", ".", "mode", ")", "\n", "dataset", ".", "load_all_data", "(", ")", "\n", "dialog_list", "=", "dataset", ".", "dialog_list", "\n", "with", "open", "(", "args", ".", "dict_path", ",", "'rb'", ")", "as", "br", ":", "\n", "        ", "active_dicts", "=", "pickle", ".", "load", "(", "br", ")", "\n", "\n", "", "feature_helper", "=", "FeatureHelper", "(", "active_dicts", ",", "dialog_list", ",", "freebase_helper", "=", "None", ",", "path_max_size", "=", "args", ".", "path_max_size", ",", "\n", "qw_max_len", "=", "args", ".", "qw_max_len", ",", "pw_max_len", "=", "args", ".", "pw_max_len", ",", "\n", "pseq_max_len", "=", "args", ".", "pseq_max_len", ")", "\n", "ds_builder", "=", "DialogueBuilder", "(", "dataset", ",", "feature_helper", ")", "\n", "ds_builder", ".", "save_to_pickle", "(", "save_dir", "=", "args", ".", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer.__init__": [[10, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "sess", ",", "ob_batch_num", "=", "100", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "ob_batch_num", "=", "ob_batch_num", "\n", "self", ".", "scan_data", "=", "0", "\n", "self", ".", "scan_batch", "=", "0", "\n", "self", ".", "ret_loss", "=", "0", "\n", "self", ".", "tb_point", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer._reset_optm_info": [[19, 22], ["None"], "methods", ["None"], ["", "def", "_reset_optm_info", "(", "self", ")", ":", "\n", "        ", "self", ".", "scan_data", "=", "self", ".", "scan_batch", "=", "0", "\n", "self", ".", "ret_loss", "=", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer._optimize": [[23, 41], ["optm_data_loader.get_batch", "optimizer.Optimizer.model.train_batch", "float", "utils.log_util.LogInfo.logs", "len"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.get_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.train_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_optimize", "(", "self", ",", "optm_data_loader", ",", "batch_idx", ")", ":", "\n", "        ", "local_data", ",", "local_size", "=", "optm_data_loader", ".", "get_batch", "(", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "_", ",", "local_loss", ",", "summary", "=", "self", ".", "model", ".", "train_batch", "(", "self", ".", "sess", ",", "local_data", ")", "\n", "local_loss", "=", "float", "(", "local_loss", ")", "\n", "self", ".", "ret_loss", "=", "1.0", "*", "(", "self", ".", "ret_loss", "*", "self", ".", "scan_data", "+", "local_loss", "*", "local_size", ")", "/", "(", "self", ".", "scan_data", "+", "local_size", ")", "\n", "self", ".", "scan_data", "+=", "local_size", "\n", "self", ".", "scan_batch", "+=", "1", "\n", "self", ".", "tb_point", "+=", "1", "\n", "if", "self", ".", "scan_batch", "%", "self", ".", "ob_batch_num", "==", "0", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'[optm-%s-%d/%d] cur_batch_loss = %.6f, avg_loss = %.6f, scanned = %d/%d'", ",", "\n", "optm_data_loader", ".", "mode", ",", "\n", "self", ".", "scan_batch", ",", "\n", "optm_data_loader", ".", "n_batch", ",", "\n", "local_loss", ",", "\n", "self", ".", "ret_loss", ",", "\n", "self", ".", "scan_data", ",", "\n", "len", "(", "optm_data_loader", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer.optimize_all": [[42, 46], ["optimizer.Optimizer._reset_optm_info", "range", "optimizer.Optimizer._optimize"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer._reset_optm_info", "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.optimizer.Optimizer._optimize"], ["", "", "def", "optimize_all", "(", "self", ",", "optm_data_loader", ")", ":", "\n", "        ", "self", ".", "_reset_optm_info", "(", ")", "\n", "for", "batch_idx", "in", "range", "(", "optm_data_loader", ".", "n_batch", ")", ":", "\n", "            ", "self", ".", "_optimize", "(", "optm_data_loader", "=", "optm_data_loader", ",", "batch_idx", "=", "batch_idx", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator.__init__": [[12, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "sess", ",", "ob_batch_num", "=", "100", ",", "show_detail", "=", "True", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "ob_batch_num", "=", "ob_batch_num", "\n", "self", ".", "show_detail", "=", "show_detail", "\n", "\n", "self", ".", "scan_data", "=", "0", "\n", "self", ".", "scan_batch", "=", "0", "\n", "self", ".", "tb_point", "=", "0", "\n", "self", ".", "eval_detail_dict", "=", "{", "}", "# store evaluation detail of each data", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator._reset_eval_info": [[23, 26], ["None"], "methods", ["None"], ["", "def", "_reset_eval_info", "(", "self", ")", ":", "\n", "        ", "self", ".", "scan_data", "=", "self", ".", "scan_batch", "=", "0", "\n", "self", ".", "eval_detail_dict", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator._evaluate": [[27, 49], ["eval_data_loader.get_batch", "evaluator.Evaluator.model.eval_batch", "local_eval_dict.items", "utils.log_util.LogInfo.logs", "evaluator.Evaluator.eval_detail_dict.setdefault().append", "len", "evaluator.Evaluator.eval_detail_dict.setdefault"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.dataset.data_loader.DataLoader.get_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.model.model.TransDGModel.eval_batch", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "def", "_evaluate", "(", "self", ",", "eval_data_loader", ",", "batch_idx", ")", ":", "\n", "        ", "local_data", ",", "local_size", "=", "eval_data_loader", ".", "get_batch", "(", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "rm_score", ",", "rm_final_feats", "=", "self", ".", "model", ".", "eval_batch", "(", "self", ".", "sess", ",", "local_data", ")", "\n", "local_eval_dict", "=", "{", "'rm_score'", ":", "rm_score", ",", "\n", "'rm_final_feats'", ":", "rm_final_feats", "}", "\n", "\n", "for", "tensor_name", ",", "batch_val", "in", "local_eval_dict", ".", "items", "(", ")", ":", "\n", "            ", "for", "val", "in", "batch_val", ":", "\n", "                ", "self", ".", "eval_detail_dict", ".", "setdefault", "(", "tensor_name", ",", "[", "]", ")", ".", "append", "(", "val", ")", "\n", "\n", "# collect all input / outputs of this batch, saving into eval_detail_dict (split by each data point)", "\n", "", "", "self", ".", "scan_data", "+=", "local_size", "\n", "self", ".", "scan_batch", "+=", "1", "\n", "self", ".", "tb_point", "+=", "1", "\n", "if", "self", ".", "scan_batch", "%", "self", ".", "ob_batch_num", "==", "0", ":", "\n", "            ", "LogInfo", ".", "logs", "(", "'[eval-%s-%d/%d] scanned = %d/%d'", ",", "\n", "eval_data_loader", ".", "mode", ",", "\n", "self", ".", "scan_batch", ",", "\n", "eval_data_loader", ".", "n_batch", ",", "\n", "self", ".", "scan_data", ",", "\n", "len", "(", "eval_data_loader", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator._post_process": [[50, 116], ["enumerate", "ret_q_score_dict.items", "utils.log_util.LogInfo.logs", "len", "ret_q_score_dict.setdefault().append", "score_list.sort", "len", "numpy.sum().astype", "open", "utils.log_util.LogInfo.redirect", "utils.log_util.LogInfo.logs", "sorted", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.stop_redirect", "open.close", "sorted", "len", "f1_list.append", "f1_list.append", "ret_q_score_dict.keys", "utils.log_util.LogInfo.begin_track", "numpy.max", "max", "enumerate", "utils.log_util.LogInfo.end_track", "ret_q_score_dict.keys", "open", "evaluator.Evaluator.eval_detail_dict.items", "ret_q_score_dict.setdefault", "getattr", "numpy.sum", "getattr", "open.write", "getattr", "utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.end_track", "len", "getattr", "evaluator.Evaluator.show_rm_info", "utils.log_util.LogInfo.logs"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.redirect", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.stop_redirect", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator.show_rm_info", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs"], ["", "", "def", "_post_process", "(", "self", ",", "eval_data_loader", ",", "detail_fp", ",", "result_fp", ")", ":", "\n", "        ", "\"\"\"\n        Given all the evaluation detail, calculate the final result.\n        \"\"\"", "\n", "assert", "len", "(", "self", ".", "eval_detail_dict", ")", ">", "0", "\n", "\n", "ret_q_score_dict", "=", "{", "}", "\n", "for", "scan_idx", ",", "(", "q_idx", ",", "cand", ")", "in", "enumerate", "(", "eval_data_loader", ".", "eval_sc_tup_list", ")", ":", "\n", "# put all output results into sc.run_info", "\n", "            ", "cand", ".", "run_info", "=", "{", "k", ":", "data_values", "[", "scan_idx", "]", "for", "k", ",", "data_values", "in", "self", ".", "eval_detail_dict", ".", "items", "(", ")", "}", "\n", "ret_q_score_dict", ".", "setdefault", "(", "q_idx", ",", "[", "]", ")", ".", "append", "(", "cand", ")", "\n", "\n", "", "score_key", "=", "'rm_score'", "\n", "f1_key", "=", "'rm_f1'", "\n", "f1_list", "=", "[", "]", "\n", "for", "q_idx", ",", "score_list", "in", "ret_q_score_dict", ".", "items", "(", ")", ":", "\n", "            ", "score_list", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "run_info", "[", "score_key", "]", ",", "reverse", "=", "True", ")", "# sort by score DESC", "\n", "if", "len", "(", "score_list", ")", "==", "0", ":", "\n", "                ", "f1_list", ".", "append", "(", "0.", ")", "\n", "", "else", ":", "\n", "                ", "f1_list", ".", "append", "(", "getattr", "(", "score_list", "[", "0", "]", ",", "f1_key", ")", ")", "\n", "\n", "", "", "LogInfo", ".", "logs", "(", "'Predict %d out of %d questions.'", ",", "len", "(", "f1_list", ")", ",", "eval_data_loader", ".", "total_questions", ")", "\n", "ret_metric", "=", "np", ".", "sum", "(", "f1_list", ")", ".", "astype", "(", "'float32'", ")", "/", "eval_data_loader", ".", "total_questions", "\n", "\n", "if", "detail_fp", "is", "not", "None", ":", "\n", "            ", "bw", "=", "open", "(", "detail_fp", ",", "'w'", ")", "\n", "LogInfo", ".", "redirect", "(", "bw", ")", "\n", "LogInfo", ".", "logs", "(", "'Avg_f1 = %.6f'", ",", "ret_metric", ")", "\n", "srt_q_idx_list", "=", "sorted", "(", "ret_q_score_dict", ".", "keys", "(", ")", ")", "\n", "for", "q_idx", "in", "srt_q_idx_list", ":", "\n", "                ", "LogInfo", ".", "begin_track", "(", "'Q-%04d:'", ",", "q_idx", ")", "\n", "srt_list", "=", "ret_q_score_dict", "[", "q_idx", "]", "# already sorted", "\n", "best_label_f1", "=", "np", ".", "max", "(", "[", "getattr", "(", "sc", ",", "f1_key", ")", "for", "sc", "in", "srt_list", "]", ")", "\n", "best_label_f1", "=", "max", "(", "best_label_f1", ",", "0.000001", ")", "\n", "for", "rank", ",", "sc", "in", "enumerate", "(", "srt_list", ")", ":", "\n", "                    ", "cur_f1", "=", "getattr", "(", "sc", ",", "f1_key", ")", "\n", "if", "rank", "<", "20", "or", "cur_f1", "==", "best_label_f1", ":", "\n", "                        ", "LogInfo", ".", "begin_track", "(", "'#-%04d [F1 = %.6f] [row_in_file = %d]'", ",", "rank", "+", "1", ",", "cur_f1", ",", "sc", ".", "ori_idx", ")", "\n", "LogInfo", ".", "logs", "(", "'%s: %.6f'", ",", "score_key", ",", "sc", ".", "run_info", "[", "score_key", "]", ")", "\n", "if", "self", ".", "show_detail", ":", "\n", "                            ", "self", ".", "show_rm_info", "(", "sc", ")", "\n", "", "else", ":", "\n", "                            ", "LogInfo", ".", "logs", "(", "'Current: not output detail.'", ")", "\n", "", "LogInfo", ".", "end_track", "(", ")", "\n", "", "", "LogInfo", ".", "end_track", "(", ")", "\n", "", "LogInfo", ".", "logs", "(", "'Avg_f1 = %.6f'", ",", "ret_metric", ")", "\n", "\n", "LogInfo", ".", "stop_redirect", "(", ")", "\n", "bw", ".", "close", "(", ")", "\n", "\n", "# Save detail information", "\n", "", "if", "result_fp", "is", "not", "None", ":", "\n", "            ", "srt_q_idx_list", "=", "sorted", "(", "ret_q_score_dict", ".", "keys", "(", ")", ")", "\n", "with", "open", "(", "result_fp", ",", "'w'", ")", "as", "bw", ":", "# write question --> selected schema", "\n", "                ", "for", "q_idx", "in", "srt_q_idx_list", ":", "\n", "                    ", "srt_list", "=", "ret_q_score_dict", "[", "q_idx", "]", "\n", "ori_idx", "=", "-", "1", "\n", "task_f1", "=", "0.", "\n", "if", "len", "(", "srt_list", ")", ">", "0", ":", "\n", "                        ", "best_sc", "=", "srt_list", "[", "0", "]", "\n", "ori_idx", "=", "best_sc", ".", "ori_idx", "\n", "task_f1", "=", "getattr", "(", "best_sc", ",", "f1_key", ")", "\n", "", "bw", ".", "write", "(", "'%d\\t%d\\t%.6f\\n'", "%", "(", "q_idx", ",", "ori_idx", ",", "task_f1", ")", ")", "\n", "\n", "", "", "", "return", "ret_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator.show_rm_info": [[117, 132], ["sc.run_info[].tolist", "utils.log_util.LogInfo.logs", "len", "range", "utils.log_util.LogInfo.begin_track", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.logs", "utils.log_util.LogInfo.end_track"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.begin_track", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.end_track"], ["", "@", "staticmethod", "\n", "def", "show_rm_info", "(", "sc", ")", ":", "\n", "        ", "rm_final_feats", "=", "sc", ".", "run_info", "[", "'rm_final_feats'", "]", ".", "tolist", "(", ")", "\n", "LogInfo", ".", "logs", "(", "'rm_final_feats = [%s]'", ",", "' '", ".", "join", "(", "[", "'%6.3f'", "%", "x", "for", "x", "in", "rm_final_feats", "]", ")", ")", "\n", "\n", "show_path_list", "=", "sc", ".", "path_list", "\n", "show_path_words_list", "=", "sc", ".", "path_words_list", "\n", "show_path_size", "=", "len", "(", "show_path_list", ")", "\n", "\n", "# show the detail of each path one by one", "\n", "for", "path_idx", "in", "range", "(", "show_path_size", ")", ":", "\n", "            ", "LogInfo", ".", "begin_track", "(", "'Showing path-%d / %d:'", ",", "path_idx", "+", "1", ",", "show_path_size", ")", "\n", "LogInfo", ".", "logs", "(", "'Path: [%s]'", ",", "'-->'", ".", "join", "(", "show_path_list", "[", "path_idx", "]", ")", ")", "\n", "LogInfo", ".", "logs", "(", "'Path-Word: [%s]'", ",", "' | '", ".", "join", "(", "show_path_words_list", "[", "path_idx", "]", ")", ")", "\n", "LogInfo", ".", "end_track", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator.evaluate_all": [[133, 141], ["evaluator.Evaluator._reset_eval_info", "range", "evaluator.Evaluator._post_process", "utils.log_util.LogInfo.logs", "evaluator.Evaluator._evaluate"], "methods", ["home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator._reset_eval_info", "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator._post_process", "home.repos.pwc.inspect_result.siat-nlp_TransDG.utils.log_util.LogInfo.logs", "home.repos.pwc.inspect_result.siat-nlp_TransDG.learner.evaluator.Evaluator._evaluate"], ["", "", "def", "evaluate_all", "(", "self", ",", "eval_data_loader", ",", "detail_fp", "=", "None", ",", "result_fp", "=", "None", ")", ":", "\n", "        ", "self", ".", "_reset_eval_info", "(", ")", "\n", "for", "batch_idx", "in", "range", "(", "eval_data_loader", ".", "n_batch", ")", ":", "\n", "            ", "self", ".", "_evaluate", "(", "eval_data_loader", "=", "eval_data_loader", ",", "batch_idx", "=", "batch_idx", ")", "\n", "\n", "", "ret_f1", "=", "self", ".", "_post_process", "(", "eval_data_loader", "=", "eval_data_loader", ",", "detail_fp", "=", "detail_fp", ",", "result_fp", "=", "result_fp", ")", "\n", "LogInfo", ".", "logs", "(", "'%s_F1 = %.6f'", ",", "eval_data_loader", ".", "mode", ",", "ret_f1", ")", "\n", "return", "ret_f1", "\n", "", "", ""]]}