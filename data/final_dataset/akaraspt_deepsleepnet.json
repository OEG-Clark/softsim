{"home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.summary.print_performance": [[15, 38], ["numpy.diagonal().astype", "numpy.sum().astype", "numpy.sum().astype", "numpy.mean", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.sum", "numpy.sum", "numpy.diagonal", "numpy.sum", "numpy.sum", "numpy.sum"], "function", ["None"], ["def", "print_performance", "(", "cm", ")", ":", "\n", "    ", "tp", "=", "np", ".", "diagonal", "(", "cm", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "tpfp", "=", "np", ".", "sum", "(", "cm", ",", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float", ")", "# sum of each col", "\n", "tpfn", "=", "np", ".", "sum", "(", "cm", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float", ")", "# sum of each row", "\n", "acc", "=", "np", ".", "sum", "(", "tp", ")", "/", "np", ".", "sum", "(", "cm", ")", "\n", "precision", "=", "tp", "/", "tpfp", "\n", "recall", "=", "tp", "/", "tpfn", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "mf1", "=", "np", ".", "mean", "(", "f1", ")", "\n", "\n", "print", "(", "\"Sample: {}\"", ".", "format", "(", "np", ".", "sum", "(", "cm", ")", ")", ")", "\n", "print", "(", "\"W: {}\"", ".", "format", "(", "tpfn", "[", "W", "]", ")", ")", "\n", "print", "(", "\"N1: {}\"", ".", "format", "(", "tpfn", "[", "N1", "]", ")", ")", "\n", "print", "(", "\"N2: {}\"", ".", "format", "(", "tpfn", "[", "N2", "]", ")", ")", "\n", "print", "(", "\"N3: {}\"", ".", "format", "(", "tpfn", "[", "N3", "]", ")", ")", "\n", "print", "(", "\"REM: {}\"", ".", "format", "(", "tpfn", "[", "REM", "]", ")", ")", "\n", "print", "(", "\"Confusion matrix:\"", ")", "\n", "print", "(", "cm", ")", "\n", "print", "(", "\"Precision: {}\"", ".", "format", "(", "precision", ")", ")", "\n", "print", "(", "\"Recall: {}\"", ".", "format", "(", "recall", ")", ")", "\n", "print", "(", "\"F1: {}\"", ".", "format", "(", "f1", ")", ")", "\n", "print", "(", "\"Overall accuracy: {}\"", ".", "format", "(", "acc", ")", ")", "\n", "print", "(", "\"Macro-F1 accuracy: {}\"", ".", "format", "(", "mf1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.summary.perf_overall": [[40, 84], ["os.listdir", "enumerate", "outputfiles.sort", "print", "numpy.asarray", "numpy.asarray", "sklearn.metrics.confusion_matrix", "numpy.mean", "sklearn.metrics.f1_score", "numpy.sum", "print", "summary.print_performance", "re.match", "outputfiles.append", "numpy.load", "print", "np.asarray.extend", "np.asarray.extend", "print", "sklearn.metrics.confusion_matrix", "summary.print_performance", "os.path.join", "len", "f[].flatten", "f[].flatten", "len", "numpy.hstack", "numpy.hstack"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten"], ["", "def", "perf_overall", "(", "data_dir", ")", ":", "\n", "# Remove non-output files, and perform ascending sort", "\n", "    ", "allfiles", "=", "os", ".", "listdir", "(", "data_dir", ")", "\n", "outputfiles", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "        ", "if", "re", ".", "match", "(", "\"^output_.+\\d+\\.npz\"", ",", "f", ")", ":", "\n", "            ", "outputfiles", ".", "append", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f", ")", ")", "\n", "", "", "outputfiles", ".", "sort", "(", ")", "\n", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "for", "fpath", "in", "outputfiles", ":", "\n", "        ", "with", "np", ".", "load", "(", "fpath", ",", "allow_pickle", "=", "True", ")", "as", "f", ":", "\n", "            ", "print", "(", "(", "f", "[", "\"y_true\"", "]", ".", "shape", ")", ")", "\n", "if", "len", "(", "f", "[", "\"y_true\"", "]", ".", "shape", ")", "==", "1", ":", "\n", "                ", "if", "len", "(", "f", "[", "\"y_true\"", "]", ")", "<", "10", ":", "\n", "                    ", "f_y_true", "=", "np", ".", "hstack", "(", "f", "[", "\"y_true\"", "]", ")", "\n", "f_y_pred", "=", "np", ".", "hstack", "(", "f", "[", "\"y_pred\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "f_y_true", "=", "f", "[", "\"y_true\"", "]", "\n", "f_y_pred", "=", "f", "[", "\"y_pred\"", "]", "\n", "", "", "else", ":", "\n", "                ", "f_y_true", "=", "f", "[", "\"y_true\"", "]", ".", "flatten", "(", ")", "\n", "f_y_pred", "=", "f", "[", "\"y_pred\"", "]", ".", "flatten", "(", ")", "\n", "\n", "", "y_true", ".", "extend", "(", "f_y_true", ")", "\n", "y_pred", ".", "extend", "(", "f_y_pred", ")", "\n", "\n", "print", "(", "\"File: {}\"", ".", "format", "(", "fpath", ")", ")", "\n", "cm", "=", "confusion_matrix", "(", "f_y_true", ",", "f_y_pred", ",", "labels", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ")", "\n", "print_performance", "(", "cm", ")", "\n", "", "", "print", "(", "\" \"", ")", "\n", "\n", "y_true", "=", "np", ".", "asarray", "(", "y_true", ")", "\n", "y_pred", "=", "np", ".", "asarray", "(", "y_pred", ")", "\n", "\n", "cm", "=", "confusion_matrix", "(", "y_true", ",", "y_pred", ")", "\n", "acc", "=", "np", ".", "mean", "(", "y_true", "==", "y_pred", ")", "\n", "mf1", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "\"macro\"", ")", "\n", "\n", "total", "=", "np", ".", "sum", "(", "cm", ",", "axis", "=", "1", ")", "\n", "\n", "print", "(", "\"DeepSleepNet (current)\"", ")", "\n", "print_performance", "(", "cm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.summary.main": [[86, 172], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "print", "print", "summary.print_performance", "print", "print", "summary.print_performance", "print", "print", "summary.print_performance", "print", "print", "summary.print_performance", "print", "print", "summary.print_performance", "print", "print", "summary.print_performance", "print", "print", "summary.print_performance", "summary.perf_overall"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.summary.perf_overall"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/home/akara/Workspace/deepsleep_output/results/outputs\"", ",", "\n", "help", "=", "\"Directory where to load prediction outputs\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "data_dir", "is", "not", "None", ":", "\n", "        ", "perf_overall", "(", "data_dir", "=", "args", ".", "data_dir", ")", "\n", "\n", "", "sharman2017", "=", "np", ".", "asarray", "(", "[", "\n", "[", "7944", ",", "11", ",", "12", ",", "6", ",", "30", "]", ",", "\n", "[", "183", ",", "113", ",", "123", ",", "4", ",", "181", "]", ",", "\n", "[", "48", ",", "4", ",", "3334", ",", "149", ",", "86", "]", ",", "\n", "[", "13", ",", "0", ",", "198", ",", "1088", ",", "0", "]", ",", "\n", "[", "52", ",", "11", ",", "207", ",", "0", ",", "1339", "]", "\n", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "hassan2017", "=", "np", ".", "asarray", "(", "[", "\n", "[", "3971", ",", "28", ",", "6", ",", "0", ",", "23", "]", ",", "\n", "[", "53", ",", "117", ",", "43", ",", "0", ",", "89", "]", ",", "\n", "[", "70", ",", "5", ",", "1641", ",", "54", ",", "41", "]", ",", "\n", "[", "33", ",", "0", ",", "104", ",", "513", ",", "0", "]", ",", "\n", "[", "41", ",", "24", ",", "84", ",", "1", ",", "655", "]", "\n", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "tsinalis2016", "=", "np", ".", "asarray", "(", "[", "\n", "[", "2744", ",", "441", ",", "34", ",", "23", ",", "138", "]", ",", "\n", "[", "472", ",", "1654", ",", "262", ",", "8", ",", "366", "]", ",", "\n", "[", "621", ",", "1270", ",", "13696", ",", "1231", ",", "760", "]", ",", "\n", "[", "143", ",", "7", ",", "469", ",", "4966", ",", "6", "]", ",", "\n", "[", "308", ",", "899", ",", "340", ",", "0", ",", "6164", "]", "\n", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "dong2016", "=", "np", ".", "asarray", "(", "[", "\n", "[", "5022", ",", "577", ",", "188", ",", "19", ",", "395", "]", ",", "\n", "[", "407", ",", "2468", ",", "989", ",", "4", ",", "965", "]", ",", "\n", "[", "130", ",", "630", ",", "27254", ",", "1021", ",", "763", "]", ",", "\n", "[", "13", ",", "0", ",", "1236", ",", "6399", ",", "5", "]", ",", "\n", "[", "103", ",", "258", ",", "609", ",", "0", ",", "9611", "]", "\n", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "hsu2013", "=", "np", ".", "asarray", "(", "[", "\n", "[", "34", ",", "2", ",", "7", ",", "2", ",", "3", "]", ",", "\n", "[", "0", ",", "20", ",", "23", ",", "3", ",", "9", "]", ",", "\n", "[", "3", ",", "4", ",", "574", ",", "8", ",", "1", "]", ",", "\n", "[", "0", ",", "0", ",", "3", ",", "26", ",", "0", "]", ",", "\n", "[", "3", ",", "5", ",", "13", ",", "4", ",", "213", "]", "\n", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "liang2012", "=", "np", ".", "asarray", "(", "[", "\n", "[", "195", ",", "24", ",", "4", ",", "0", ",", "3", "]", ",", "\n", "[", "61", ",", "72", ",", "48", ",", "3", ",", "69", "]", ",", "\n", "[", "12", ",", "103", ",", "4078", ",", "216", ",", "220", "]", ",", "\n", "[", "1", ",", "4", ",", "196", ",", "1309", ",", "0", "]", ",", "\n", "[", "8", ",", "8", ",", "22", ",", "6", ",", "1818", "]", "\n", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "fraiwan2012", "=", "np", ".", "asarray", "(", "[", "\n", "[", "2407", ",", "89", ",", "111", ",", "38", ",", "40", "]", ",", "\n", "[", "56", ",", "185", ",", "52", ",", "8", ",", "48", "]", ",", "\n", "[", "69", ",", "85", ",", "1897", ",", "174", ",", "131", "]", ",", "\n", "[", "14", ",", "9", ",", "86", ",", "482", ",", "3", "]", ",", "\n", "[", "33", ",", "60", ",", "92", ",", "3", ",", "719", "]", "\n", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Sharma (2017)\"", ")", "\n", "print_performance", "(", "sharman2017", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Hassan (2017)\"", ")", "\n", "print_performance", "(", "hassan2017", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Tsinalis (2016)\"", ")", "\n", "print_performance", "(", "tsinalis2016", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Dong (2016)\"", ")", "\n", "print_performance", "(", "dong2016", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Hsu (2013)\"", ")", "\n", "print_performance", "(", "hsu2013", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Liang (2012)\"", ")", "\n", "print_performance", "(", "liang2012", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Fraiwan (2012)\"", ")", "\n", "print_performance", "(", "fraiwan2012", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.submit_eAE.main": [[3, 27], ["eAE.eAE.eAE", "eAE.eAE.eAE.is_eae_alive", "eAE.eAE.eAE.submit_jobs", "print", "Exception", "range"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.is_eae_alive", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.submit_jobs"], ["def", "main", "(", ")", ":", "\n", "# Setting up the connection to interface", "\n", "    ", "ip", "=", "\"interfaceeae.doc.ic.ac.uk\"", "\n", "port", "=", "443", "\n", "eae", "=", "eAE", "(", "ip", ",", "port", ")", "\n", "\n", "# Testing if the interface is Alive", "\n", "is_alive", "=", "eae", ".", "is_eae_alive", "(", ")", "\n", "if", "is_alive", "!=", "200", ":", "\n", "        ", "raise", "Exception", "(", "\"!!!\"", ")", "\n", "\n", "# Initialize input argument for each node in the eAE cluster", "\n", "", "args", "=", "[", "'--data_dir data/eeg_fpz_cz --output_dir results --n_folds 20 --fold_idx {} --pretrain_epochs 100 --finetune_epochs 200'", ".", "format", "(", "fold_idx", ")", "for", "fold_idx", "in", "range", "(", "20", ")", "]", "\n", "\n", "# Submit a job", "\n", "parameters_set", "=", "\"\\n\"", ".", "join", "(", "args", ")", "\n", "cluster", "=", "\"gpu\"", "\n", "computation_type", "=", "\"GPU\"", "\n", "main_file", "=", "\"train.py\"", "\n", "data_files", "=", "[", "'deepsleep'", ",", "'tensorlayer'", ",", "'data/eeg_fpz_cz'", "]", "\n", "host_ip", "=", "\"host_ip_address\"", "# IP address of the machine to run this script", "\n", "ssh_port", "=", "\"ssh_port\"", "# Port for ssh", "\n", "job", "=", "eae", ".", "submit_jobs", "(", "parameters_set", ",", "cluster", ",", "computation_type", ",", "main_file", ",", "data_files", ",", "host_ip", ",", "ssh_port", ")", "\n", "print", "(", "job", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.CustomDeepSleepNet.__init__": [[337, 366], ["deepsleep.model.DeepSleepNet.__init__"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "batch_size", ",", "\n", "input_dims", ",", "\n", "n_classes", ",", "\n", "seq_length", ",", "\n", "n_rnn_layers", ",", "\n", "return_last", ",", "\n", "is_train", ",", "\n", "reuse_params", ",", "\n", "use_dropout_feature", ",", "\n", "use_dropout_sequence", ",", "\n", "name", "=", "\"deepsleepnet\"", "\n", ")", ":", "\n", "        ", "super", "(", "DeepSleepNet", ",", "self", ")", ".", "__init__", "(", "\n", "batch_size", "=", "batch_size", ",", "\n", "input_dims", "=", "input_dims", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "is_train", "=", "is_train", ",", "\n", "reuse_params", "=", "reuse_params", ",", "\n", "use_dropout", "=", "use_dropout_feature", ",", "\n", "name", "=", "name", "\n", ")", "\n", "\n", "self", ".", "seq_length", "=", "seq_length", "\n", "self", ".", "n_rnn_layers", "=", "n_rnn_layers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n", "self", ".", "use_dropout_sequence", "=", "use_dropout_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.CustomDeepSleepNet.build_model": [[367, 471], ["super().build_model", "predict.CustomDeepSleepNet.activations.append", "output_conns.append", "tensorflow.reshape", "predict.CustomDeepSleepNet.activations.append", "output_conns.append", "tensorflow.add_n", "predict.CustomDeepSleepNet.activations.append", "tensorflow.compat.v1.variable_scope", "deepsleep.nn.fc", "deepsleep.nn.batch_norm_new", "tensorflow.nn.relu", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.unstack", "predict.custom_bidirectional_rnn", "predict.CustomDeepSleepNet.activations.append", "predict.CustomDeepSleepNet.activations.append", "tensorflow.nn.dropout.get_shape", "tensorflow.compat.v1.nn.rnn_cell.LSTMCell", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.reshape.get_shape", "tensorflow.compat.v1.nn.rnn_cell.DropoutWrapper", "predict.CustomDeepSleepNet.build_model.lstm_cell"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.build_model", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.fc", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.batch_norm_new", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.custom_bidirectional_rnn"], ["", "def", "build_model", "(", "self", ",", "input_var", ")", ":", "\n", "# Create a network with superclass method", "\n", "        ", "network", "=", "super", "(", "DeepSleepNet", ",", "self", ")", ".", "build_model", "(", "\n", "input_var", "=", "self", ".", "input_var", "\n", ")", "\n", "\n", "# Residual (or shortcut) connection", "\n", "output_conns", "=", "[", "]", "\n", "\n", "# Fully-connected to select some part of the output to add with the output from bi-directional LSTM", "\n", "name", "=", "\"l{}_fc\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "            ", "output_tmp", "=", "fc", "(", "name", "=", "\"fc\"", ",", "input_var", "=", "network", ",", "n_hiddens", "=", "1024", ",", "bias", "=", "None", ",", "wd", "=", "0", ")", "\n", "output_tmp", "=", "batch_norm_new", "(", "name", "=", "\"bn\"", ",", "input_var", "=", "output_tmp", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "output_tmp", "=", "tf", ".", "nn", ".", "relu", "(", "output_tmp", ",", "name", "=", "\"relu\"", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "output_tmp", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "output_conns", ".", "append", "(", "output_tmp", ")", "\n", "\n", "######################################################################", "\n", "\n", "# Reshape the input from (batch_size * seq_length, input_dim) to", "\n", "# (batch_size, seq_length, input_dim)", "\n", "name", "=", "\"l{}_reshape_seq\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "input_dim", "=", "network", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "seq_input", "=", "tf", ".", "reshape", "(", "network", ",", "\n", "shape", "=", "[", "-", "1", ",", "self", ".", "seq_length", ",", "input_dim", "]", ",", "\n", "name", "=", "name", ")", "\n", "assert", "self", ".", "batch_size", "==", "seq_input", ".", "get_shape", "(", ")", "[", "0", "]", ".", "value", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "seq_input", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Bidirectional LSTM network", "\n", "name", "=", "\"l{}_bi_lstm\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "hidden_size", "=", "512", "# will output 1024 (512 forward, 512 backward)", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "\n", "            ", "def", "lstm_cell", "(", ")", ":", "\n", "                ", "cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "hidden_size", ",", "\n", "use_peepholes", "=", "True", ",", "\n", "state_is_tuple", "=", "True", ",", "\n", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ".", "reuse", ")", "\n", "if", "self", ".", "use_dropout_sequence", ":", "\n", "                    ", "keep_prob", "=", "0.5", "if", "self", ".", "is_train", "else", "1.0", "\n", "cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "output_keep_prob", "=", "keep_prob", "\n", ")", "\n", "\n", "", "return", "cell", "\n", "\n", "", "fw_cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "(", ")", "for", "_", "in", "range", "(", "self", ".", "n_rnn_layers", ")", "]", ",", "state_is_tuple", "=", "True", ")", "\n", "bw_cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "(", ")", "for", "_", "in", "range", "(", "self", ".", "n_rnn_layers", ")", "]", ",", "state_is_tuple", "=", "True", ")", "\n", "\n", "# Initial state of RNN", "\n", "self", ".", "fw_initial_state", "=", "fw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "tf", ".", "float32", ")", "\n", "self", ".", "bw_initial_state", "=", "bw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "tf", ".", "float32", ")", "\n", "\n", "# Feedforward to MultiRNNCell", "\n", "list_rnn_inputs", "=", "tf", ".", "unstack", "(", "seq_input", ",", "axis", "=", "1", ")", "\n", "outputs", ",", "fw_state", ",", "bw_state", ",", "fw_states", ",", "bw_states", "=", "custom_bidirectional_rnn", "(", "\n", "cell_fw", "=", "fw_cell", ",", "\n", "cell_bw", "=", "bw_cell", ",", "\n", "inputs", "=", "list_rnn_inputs", ",", "\n", "initial_state_fw", "=", "self", ".", "fw_initial_state", ",", "\n", "initial_state_bw", "=", "self", ".", "bw_initial_state", "\n", ")", "\n", "\n", "if", "self", ".", "return_last", ":", "\n", "                ", "network", "=", "outputs", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "network", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "hidden_size", "*", "2", "]", ",", "\n", "name", "=", "name", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "self", ".", "fw_final_state", "=", "fw_state", "\n", "self", ".", "bw_final_state", "=", "bw_state", "\n", "\n", "self", ".", "fw_states", "=", "fw_states", "\n", "self", ".", "bw_states", "=", "bw_states", "\n", "\n", "# Append output", "\n", "", "output_conns", ".", "append", "(", "network", ")", "\n", "\n", "######################################################################", "\n", "\n", "# Add", "\n", "name", "=", "\"l{}_add\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "tf", ".", "add_n", "(", "output_conns", ",", "name", "=", "name", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Dropout", "\n", "if", "self", ".", "use_dropout_sequence", ":", "\n", "            ", "name", "=", "\"l{}_dropout\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "if", "self", ".", "is_train", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "0.5", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "1.0", ",", "name", "=", "name", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.print_performance": [[38, 52], ["tensorflow.add_n", "sess.run", "print", "print", "print", "tensorflow.compat.v1.get_collection"], "function", ["None"], ["def", "print_performance", "(", "sess", ",", "network_name", ",", "n_examples", ",", "duration", ",", "loss", ",", "cm", ",", "acc", ",", "f1", ")", ":", "\n", "# Get regularization loss", "\n", "    ", "reg_loss", "=", "tf", ".", "add_n", "(", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "\"losses\"", ",", "scope", "=", "network_name", "+", "\"\\/\"", ")", ")", "\n", "reg_loss_value", "=", "sess", ".", "run", "(", "reg_loss", ")", "\n", "\n", "# Print performance", "\n", "print", "(", "(", "\n", "\"duration={:.3f} sec, n={}, loss={:.3f} ({:.3f}), acc={:.3f}, \"", "\n", "\"f1={:.3f}\"", ".", "format", "(", "\n", "duration", ",", "n_examples", ",", "loss", ",", "reg_loss_value", ",", "acc", ",", "f1", "\n", ")", "\n", ")", ")", "\n", "print", "(", "cm", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict._reverse_seq": [[54, 96], ["tuple", "zip", "list", "tensorflow.python.framework.tensor_shape.unknown_shape", "tensorflow.python.ops.array_ops.pack", "tensorflow.python.ops.array_ops.reverse_sequence", "tensorflow.python.ops.array_ops.unpack", "zip", "tensorflow.python.util.nest.pack_sequence_as", "reversed", "tensorflow.python.util.nest.flatten", "range", "tensor_shape.unknown_shape.merge_with", "input_.set_shape", "tensorflow.python.ops.math_ops.to_int64", "r.set_shape", "flat_result.append", "zip", "len", "input_.get_shape", "sequence[].get_shape"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten"], ["", "def", "_reverse_seq", "(", "input_seq", ",", "lengths", ")", ":", "\n", "    ", "\"\"\"Reverse a list of Tensors up to specified lengths.\n    Args:\n        input_seq: Sequence of seq_len tensors of dimension (batch_size, n_features)\n                   or nested tuples of tensors.\n        lengths:   A `Tensor` of dimension batch_size, containing lengths for each\n                   sequence in the batch. If \"None\" is specified, simply reverses\n                   the list.\n    Returns:\n        time-reversed sequence\n    \"\"\"", "\n", "if", "lengths", "is", "None", ":", "\n", "        ", "return", "list", "(", "reversed", "(", "input_seq", ")", ")", "\n", "\n", "", "flat_input_seq", "=", "tuple", "(", "nest", ".", "flatten", "(", "input_", ")", "for", "input_", "in", "input_seq", ")", "\n", "\n", "flat_results", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "input_seq", ")", ")", "]", "\n", "for", "sequence", "in", "zip", "(", "*", "flat_input_seq", ")", ":", "\n", "        ", "input_shape", "=", "tensor_shape", ".", "unknown_shape", "(", "\n", "ndims", "=", "sequence", "[", "0", "]", ".", "get_shape", "(", ")", ".", "ndims", ")", "\n", "for", "input_", "in", "sequence", ":", "\n", "            ", "input_shape", ".", "merge_with", "(", "input_", ".", "get_shape", "(", ")", ")", "\n", "input_", ".", "set_shape", "(", "input_shape", ")", "\n", "\n", "# Join into (time, batch_size, depth)", "\n", "", "s_joined", "=", "array_ops", ".", "pack", "(", "sequence", ")", "\n", "\n", "# TODO(schuster, ebrevdo): Remove cast when reverse_sequence takes int32", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "            ", "lengths", "=", "math_ops", ".", "to_int64", "(", "lengths", ")", "\n", "\n", "# Reverse along dimension 0", "\n", "", "s_reversed", "=", "array_ops", ".", "reverse_sequence", "(", "s_joined", ",", "lengths", ",", "0", ",", "1", ")", "\n", "# Split again into list", "\n", "result", "=", "array_ops", ".", "unpack", "(", "s_reversed", ")", "\n", "for", "r", ",", "flat_result", "in", "zip", "(", "result", ",", "flat_results", ")", ":", "\n", "            ", "r", ".", "set_shape", "(", "input_shape", ")", "\n", "flat_result", ".", "append", "(", "r", ")", "\n", "\n", "", "", "results", "=", "[", "nest", ".", "pack_sequence_as", "(", "structure", "=", "input_", ",", "flat_sequence", "=", "flat_result", ")", "\n", "for", "input_", ",", "flat_result", "in", "zip", "(", "input_seq", ",", "flat_results", ")", "]", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.custom_rnn": [[98, 252], ["isinstance", "TypeError", "tensorflow.python.util.nest.is_sequence", "TypeError", "ValueError", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.util.nest.is_sequence", "enumerate", "varscope.set_caching_device", "first_input.get_shape().with_rank_at_least", "tensorflow.python.util.nest.flatten", "cell.zero_state", "ops.convert_to_tensor", "tensorflow.python.util.nest.flatten", "tuple", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.ops.math_ops.to_int32", "tensorflow.python.ops.math_ops.reduce_min", "tensorflow.python.ops.math_ops.reduce_max", "outputs.append", "states.append", "first_input.get_shape", "flat_input.get_shape().with_rank_at_least", "fixed_batch_size.merge_with", "enumerate", "first_input.get_shape().with_rank_at_least", "tensorflow.python.ops.array_ops.shape", "ValueError", "ValueError", "_state_size_with_prefix", "tensorflow.python.ops.array_ops.zeros", "_state_size_with_prefix", "array_ops.zeros.set_shape", "varscope.reuse_variables", "cell", "_rnn_step", "call_cell", "first_input.get_shape", "math_ops.to_int32.get_shape", "tensorflow.python.ops.array_ops.pack", "_infer_state_dtype", "tensorflow.python.framework.tensor_shape.TensorShape", "predict.custom_rnn._create_zero_output"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten"], ["", "def", "custom_rnn", "(", "cell", ",", "inputs", ",", "initial_state", "=", "None", ",", "dtype", "=", "None", ",", "\n", "sequence_length", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a recurrent neural network specified by RNNCell `cell`.\n    The simplest form of RNN network generated is:\n    ```python\n        state = cell.zero_state(...)\n        outputs = []\n        for input_ in inputs:\n            output, state = cell(input_, state)\n            outputs.append(output)\n        return (outputs, state)\n    ```\n    However, a few other options are available:\n    An initial state can be provided.\n    If the sequence_length vector is provided, dynamic calculation is performed.\n    This method of calculation does not compute the RNN steps past the maximum\n    sequence length of the minibatch (thus saving computational time),\n    and properly propagates the state at an example's sequence length\n    to the final state output.\n    The dynamic calculation performed is, at time `t` for batch row `b`,\n    ```python\n        (output, state)(b, t) =\n            (t >= sequence_length(b))\n                ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))\n                : cell(input(b, t), state(b, t - 1))\n    ```\n    Args:\n        cell: An instance of RNNCell.\n        inputs: A length T list of inputs, each a `Tensor` of shape\n            `[batch_size, input_size]`, or a nested tuple of such elements.\n        initial_state: (optional) An initial state for the RNN.\n            If `cell.state_size` is an integer, this must be\n            a `Tensor` of appropriate type and shape `[batch_size, cell.state_size]`.\n            If `cell.state_size` is a tuple, this should be a tuple of\n            tensors having shapes `[batch_size, s] for s in cell.state_size`.\n        dtype: (optional) The data type for the initial state and expected output.\n            Required if initial_state is not provided or RNN state has a heterogeneous\n            dtype.\n        sequence_length: Specifies the length of each sequence in inputs.\n            An int32 or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`.\n        scope: VariableScope for the created subgraph; defaults to \"RNN\".\n    Returns:\n        A pair (outputs, state) where:\n        - outputs is a length T list of outputs (one for each input), or a nested\n            tuple of such elements.\n        - state is the final state\n    Raises:\n        TypeError: If `cell` is not an instance of RNNCell.\n        ValueError: If `inputs` is `None` or an empty list, or if the input depth\n            (column size) cannot be inferred from inputs via shape inference.\n    \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cell", ",", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"cell must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "nest", ".", "is_sequence", "(", "inputs", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"inputs must be a sequence\"", ")", "\n", "", "if", "not", "inputs", ":", "\n", "        ", "raise", "ValueError", "(", "\"inputs must not be empty\"", ")", "\n", "\n", "", "outputs", "=", "[", "]", "\n", "states", "=", "[", "]", "\n", "# Create a new scope in which the caching device is either", "\n", "# determined by the parent scope, or is set to place the cached", "\n", "# Variable using the same placement as for the rest of the RNN.", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "\"RNN\"", ")", "as", "varscope", ":", "\n", "        ", "if", "varscope", ".", "caching_device", "is", "None", ":", "\n", "            ", "varscope", ".", "set_caching_device", "(", "lambda", "op", ":", "op", ".", "device", ")", "\n", "\n", "# Obtain the first sequence of the input", "\n", "", "first_input", "=", "inputs", "\n", "while", "nest", ".", "is_sequence", "(", "first_input", ")", ":", "\n", "            ", "first_input", "=", "first_input", "[", "0", "]", "\n", "\n", "# Temporarily avoid EmbeddingWrapper and seq2seq badness", "\n", "# TODO(lukaszkaiser): remove EmbeddingWrapper", "\n", "", "if", "first_input", ".", "get_shape", "(", ")", ".", "ndims", "!=", "1", ":", "\n", "\n", "            ", "input_shape", "=", "first_input", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "2", ")", "\n", "fixed_batch_size", "=", "input_shape", "[", "0", "]", "\n", "\n", "flat_inputs", "=", "nest", ".", "flatten", "(", "inputs", ")", "\n", "for", "flat_input", "in", "flat_inputs", ":", "\n", "                ", "input_shape", "=", "flat_input", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "2", ")", "\n", "batch_size", ",", "input_size", "=", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", ":", "]", "\n", "fixed_batch_size", ".", "merge_with", "(", "batch_size", ")", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "input_size", ")", ":", "\n", "                    ", "if", "size", ".", "value", "is", "None", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "\"Input size (dimension %d of inputs) must be accessible via \"", "\n", "\"shape inference, but saw value None.\"", "%", "i", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "fixed_batch_size", "=", "first_input", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "1", ")", "[", "0", "]", "\n", "\n", "", "if", "fixed_batch_size", ".", "value", ":", "\n", "            ", "batch_size", "=", "fixed_batch_size", ".", "value", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "array_ops", ".", "shape", "(", "first_input", ")", "[", "0", "]", "\n", "", "if", "initial_state", "is", "not", "None", ":", "\n", "            ", "state", "=", "initial_state", "\n", "", "else", ":", "\n", "            ", "if", "not", "dtype", ":", "\n", "                ", "raise", "ValueError", "(", "\"If no initial_state is provided, \"", "\n", "\"dtype must be specified\"", ")", "\n", "", "state", "=", "cell", ".", "zero_state", "(", "batch_size", ",", "dtype", ")", "\n", "\n", "", "if", "sequence_length", "is", "not", "None", ":", "# Prepare variables", "\n", "            ", "sequence_length", "=", "ops", ".", "convert_to_tensor", "(", "\n", "sequence_length", ",", "name", "=", "\"sequence_length\"", ")", "\n", "if", "sequence_length", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "None", ",", "1", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"sequence_length must be a vector of length batch_size\"", ")", "\n", "", "def", "_create_zero_output", "(", "output_size", ")", ":", "\n", "# convert int to TensorShape if necessary", "\n", "                ", "size", "=", "_state_size_with_prefix", "(", "output_size", ",", "prefix", "=", "[", "batch_size", "]", ")", "\n", "output", "=", "array_ops", ".", "zeros", "(", "\n", "array_ops", ".", "pack", "(", "size", ")", ",", "_infer_state_dtype", "(", "dtype", ",", "state", ")", ")", "\n", "shape", "=", "_state_size_with_prefix", "(", "\n", "output_size", ",", "prefix", "=", "[", "fixed_batch_size", ".", "value", "]", ")", "\n", "output", ".", "set_shape", "(", "tensor_shape", ".", "TensorShape", "(", "shape", ")", ")", "\n", "return", "output", "\n", "\n", "", "output_size", "=", "cell", ".", "output_size", "\n", "flat_output_size", "=", "nest", ".", "flatten", "(", "output_size", ")", "\n", "flat_zero_output", "=", "tuple", "(", "\n", "_create_zero_output", "(", "size", ")", "for", "size", "in", "flat_output_size", ")", "\n", "zero_output", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "output_size", ",", "\n", "flat_sequence", "=", "flat_zero_output", ")", "\n", "\n", "sequence_length", "=", "math_ops", ".", "to_int32", "(", "sequence_length", ")", "\n", "min_sequence_length", "=", "math_ops", ".", "reduce_min", "(", "sequence_length", ")", "\n", "max_sequence_length", "=", "math_ops", ".", "reduce_max", "(", "sequence_length", ")", "\n", "\n", "", "for", "time", ",", "input_", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "if", "time", ">", "0", ":", "varscope", ".", "reuse_variables", "(", ")", "\n", "# pylint: disable=cell-var-from-loop", "\n", "call_cell", "=", "lambda", ":", "cell", "(", "input_", ",", "state", ")", "\n", "# pylint: enable=cell-var-from-loop", "\n", "if", "sequence_length", "is", "not", "None", ":", "\n", "                ", "(", "output", ",", "state", ")", "=", "_rnn_step", "(", "\n", "time", "=", "time", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "min_sequence_length", "=", "min_sequence_length", ",", "\n", "max_sequence_length", "=", "max_sequence_length", ",", "\n", "zero_output", "=", "zero_output", ",", "\n", "state", "=", "state", ",", "\n", "call_cell", "=", "call_cell", ",", "\n", "state_size", "=", "cell", ".", "state_size", ")", "\n", "", "else", ":", "\n", "                ", "(", "output", ",", "state", ")", "=", "call_cell", "(", ")", "\n", "\n", "", "outputs", ".", "append", "(", "output", ")", "\n", "states", ".", "append", "(", "state", ")", "\n", "\n", "", "return", "(", "outputs", ",", "state", ",", "states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.custom_bidirectional_rnn": [[254, 333], ["predict._reverse_seq", "predict._reverse_seq", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tuple", "tensorflow.python.util.nest.pack_sequence_as", "isinstance", "TypeError", "isinstance", "TypeError", "tensorflow.python.util.nest.is_sequence", "TypeError", "ValueError", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.variable_scope", "predict.custom_rnn", "tensorflow.python.ops.variable_scope.variable_scope", "predict._reverse_seq", "predict.custom_rnn", "tensorflow.python.ops.array_ops.concat", "zip"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict._reverse_seq", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict._reverse_seq", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.custom_rnn", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict._reverse_seq", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.custom_rnn"], ["", "", "def", "custom_bidirectional_rnn", "(", "cell_fw", ",", "cell_bw", ",", "inputs", ",", "\n", "initial_state_fw", "=", "None", ",", "initial_state_bw", "=", "None", ",", "\n", "dtype", "=", "None", ",", "sequence_length", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a bidirectional recurrent neural network.\n    Similar to the unidirectional case above (rnn) but takes input and builds\n    independent forward and backward RNNs with the final forward and backward\n    outputs depth-concatenated, such that the output will have the format\n    [time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of\n    forward and backward cell must match. The initial state for both directions\n    is zero by default (but can be set optionally) and no intermediate states are\n    ever returned -- the network is fully unrolled for the given (passed in)\n    length(s) of the sequence(s) or completely unrolled if length(s) is not given.\n    Args:\n        cell_fw: An instance of RNNCell, to be used for forward direction.\n        cell_bw: An instance of RNNCell, to be used for backward direction.\n        inputs: A length T list of inputs, each a tensor of shape\n            [batch_size, input_size], or a nested tuple of such elements.\n        initial_state_fw: (optional) An initial state for the forward RNN.\n            This must be a tensor of appropriate type and shape\n            `[batch_size, cell_fw.state_size]`.\n            If `cell_fw.state_size` is a tuple, this should be a tuple of\n            tensors having shapes `[batch_size, s] for s in cell_fw.state_size`.\n        initial_state_bw: (optional) Same as for `initial_state_fw`, but using\n            the corresponding properties of `cell_bw`.\n        dtype: (optional) The data type for the initial state.  Required if\n            either of the initial states are not provided.\n        sequence_length: (optional) An int32/int64 vector, size `[batch_size]`,\n            containing the actual lengths for each of the sequences.\n        scope: VariableScope for the created subgraph; defaults to \"BiRNN\"\n    Returns:\n        A tuple (outputs, output_state_fw, output_state_bw) where:\n            outputs is a length `T` list of outputs (one for each input), which\n                are depth-concatenated forward and backward outputs.\n            output_state_fw is the final state of the forward rnn.\n            output_state_bw is the final state of the backward rnn.\n    Raises:\n        TypeError: If `cell_fw` or `cell_bw` is not an instance of `RNNCell`.\n        ValueError: If inputs is None or an empty list.\n    \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cell_fw", ",", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"cell_fw must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "isinstance", "(", "cell_bw", ",", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"cell_bw must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "nest", ".", "is_sequence", "(", "inputs", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"inputs must be a sequence\"", ")", "\n", "", "if", "not", "inputs", ":", "\n", "        ", "raise", "ValueError", "(", "\"inputs must not be empty\"", ")", "\n", "\n", "", "with", "vs", ".", "variable_scope", "(", "scope", "or", "\"bidirectional_rnn\"", ")", ":", "\n", "# Forward direction", "\n", "        ", "with", "vs", ".", "variable_scope", "(", "\"fw\"", ")", "as", "fw_scope", ":", "\n", "            ", "output_fw", ",", "output_state_fw", ",", "fw_states", "=", "custom_rnn", "(", "\n", "cell_fw", ",", "inputs", ",", "initial_state_fw", ",", "dtype", ",", "\n", "sequence_length", ",", "scope", "=", "fw_scope", "\n", ")", "\n", "\n", "# Backward direction", "\n", "", "with", "vs", ".", "variable_scope", "(", "\"bw\"", ")", "as", "bw_scope", ":", "\n", "            ", "reversed_inputs", "=", "_reverse_seq", "(", "inputs", ",", "sequence_length", ")", "\n", "tmp", ",", "output_state_bw", ",", "tmp_states", "=", "custom_rnn", "(", "\n", "cell_bw", ",", "reversed_inputs", ",", "initial_state_bw", ",", "\n", "dtype", ",", "sequence_length", ",", "scope", "=", "bw_scope", "\n", ")", "\n", "\n", "", "", "output_bw", "=", "_reverse_seq", "(", "tmp", ",", "sequence_length", ")", "\n", "bw_states", "=", "_reverse_seq", "(", "tmp_states", ",", "sequence_length", ")", "\n", "\n", "# Concat each of the forward/backward outputs", "\n", "flat_output_fw", "=", "nest", ".", "flatten", "(", "output_fw", ")", "\n", "flat_output_bw", "=", "nest", ".", "flatten", "(", "output_bw", ")", "\n", "\n", "flat_outputs", "=", "tuple", "(", "array_ops", ".", "concat", "(", "values", "=", "[", "fw", ",", "bw", "]", ",", "axis", "=", "1", ")", "\n", "for", "fw", ",", "bw", "in", "zip", "(", "flat_output_fw", ",", "flat_output_bw", ")", ")", "\n", "\n", "outputs", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "output_fw", ",", "\n", "flat_sequence", "=", "flat_outputs", ")", "\n", "\n", "return", "(", "outputs", ",", "output_state_fw", ",", "output_state_bw", ",", "fw_states", ",", "bw_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.custom_run_epoch": [[473, 588], ["time.time", "enumerate", "os.path.join", "numpy.savez", "print", "numpy.hstack", "numpy.hstack", "zip", "sess.run", "sess.run", "len", "numpy.zeros", "numpy.zeros", "deepsleep.utils.iterate_batch_seq_minibatches", "all_fw_memory_cells.append", "all_bw_memory_cells.append", "y.append", "y_true.append", "time.time", "enumerate", "enumerate", "sess.run", "sess.run", "sess.run", "range", "each_y_true.extend", "each_y_pred.extend", "range", "numpy.isnan", "numpy.squeeze", "numpy.squeeze"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_batch_seq_minibatches"], ["", "", "def", "custom_run_epoch", "(", "\n", "sess", ",", "\n", "network", ",", "\n", "inputs", ",", "\n", "targets", ",", "\n", "train_op", ",", "\n", "is_train", ",", "\n", "output_dir", ",", "\n", "subject_idx", "\n", ")", ":", "\n", "    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "y", "=", "[", "]", "\n", "y_true", "=", "[", "]", "\n", "all_fw_memory_cells", "=", "[", "]", "\n", "all_bw_memory_cells", "=", "[", "]", "\n", "total_loss", ",", "n_batches", "=", "0.0", ",", "0", "\n", "for", "sub_f_idx", ",", "each_data", "in", "enumerate", "(", "zip", "(", "inputs", ",", "targets", ")", ")", ":", "\n", "        ", "each_x", ",", "each_y", "=", "each_data", "\n", "\n", "# # Initialize state of LSTM - Unidirectional LSTM", "\n", "# state = sess.run(network.initial_state)", "\n", "\n", "# Initialize state of LSTM - Bidirectional LSTM", "\n", "fw_state", "=", "sess", ".", "run", "(", "network", ".", "fw_initial_state", ")", "\n", "bw_state", "=", "sess", ".", "run", "(", "network", ".", "bw_initial_state", ")", "\n", "\n", "# Prepare storage for memory cells", "\n", "n_all_data", "=", "len", "(", "each_x", ")", "\n", "extra", "=", "n_all_data", "%", "network", ".", "seq_length", "\n", "n_data", "=", "n_all_data", "-", "extra", "\n", "cell_size", "=", "512", "\n", "fw_memory_cells", "=", "np", ".", "zeros", "(", "(", "n_data", ",", "network", ".", "n_rnn_layers", ",", "cell_size", ")", ")", "\n", "bw_memory_cells", "=", "np", ".", "zeros", "(", "(", "n_data", ",", "network", ".", "n_rnn_layers", ",", "cell_size", ")", ")", "\n", "seq_idx", "=", "0", "\n", "\n", "# Store prediction and actual stages of each patient", "\n", "each_y_true", "=", "[", "]", "\n", "each_y_pred", "=", "[", "]", "\n", "\n", "for", "x_batch", ",", "y_batch", "in", "iterate_batch_seq_minibatches", "(", "inputs", "=", "each_x", ",", "\n", "targets", "=", "each_y", ",", "\n", "batch_size", "=", "network", ".", "batch_size", ",", "\n", "seq_length", "=", "network", ".", "seq_length", ")", ":", "\n", "            ", "feed_dict", "=", "{", "\n", "network", ".", "input_var", ":", "x_batch", ",", "\n", "network", ".", "target_var", ":", "y_batch", "\n", "}", "\n", "\n", "# Unidirectional LSTM", "\n", "# for i, (c, h) in enumerate(network.initial_state):", "\n", "#     feed_dict[c] = state[i].c", "\n", "#     feed_dict[h] = state[i].h", "\n", "\n", "# _, loss_value, y_pred, state = sess.run(", "\n", "#     [train_op, network.loss_op, network.pred_op, network.final_state],", "\n", "#     feed_dict=feed_dict", "\n", "# )", "\n", "\n", "for", "i", ",", "(", "c", ",", "h", ")", "in", "enumerate", "(", "network", ".", "fw_initial_state", ")", ":", "\n", "                ", "feed_dict", "[", "c", "]", "=", "fw_state", "[", "i", "]", ".", "c", "\n", "feed_dict", "[", "h", "]", "=", "fw_state", "[", "i", "]", ".", "h", "\n", "\n", "", "for", "i", ",", "(", "c", ",", "h", ")", "in", "enumerate", "(", "network", ".", "bw_initial_state", ")", ":", "\n", "                ", "feed_dict", "[", "c", "]", "=", "bw_state", "[", "i", "]", ".", "c", "\n", "feed_dict", "[", "h", "]", "=", "bw_state", "[", "i", "]", ".", "h", "\n", "\n", "", "_", ",", "loss_value", ",", "y_pred", ",", "fw_state", ",", "bw_state", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "network", ".", "loss_op", ",", "network", ".", "pred_op", ",", "network", ".", "fw_final_state", ",", "network", ".", "bw_final_state", "]", ",", "\n", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "# Extract memory cells", "\n", "fw_states", "=", "sess", ".", "run", "(", "network", ".", "fw_states", ",", "feed_dict", "=", "feed_dict", ")", "\n", "bw_states", "=", "sess", ".", "run", "(", "network", ".", "bw_states", ",", "feed_dict", "=", "feed_dict", ")", "\n", "offset_idx", "=", "seq_idx", "*", "network", ".", "seq_length", "\n", "for", "s_idx", "in", "range", "(", "network", ".", "seq_length", ")", ":", "\n", "                ", "for", "r_idx", "in", "range", "(", "network", ".", "n_rnn_layers", ")", ":", "\n", "                    ", "fw_memory_cells", "[", "offset_idx", "+", "s_idx", "]", "[", "r_idx", "]", "=", "np", ".", "squeeze", "(", "fw_states", "[", "s_idx", "]", "[", "r_idx", "]", ".", "c", ")", "\n", "bw_memory_cells", "[", "offset_idx", "+", "s_idx", "]", "[", "r_idx", "]", "=", "np", ".", "squeeze", "(", "bw_states", "[", "s_idx", "]", "[", "r_idx", "]", ".", "c", ")", "\n", "", "", "seq_idx", "+=", "1", "\n", "each_y_true", ".", "extend", "(", "y_batch", ")", "\n", "each_y_pred", ".", "extend", "(", "y_pred", ")", "\n", "\n", "total_loss", "+=", "loss_value", "\n", "n_batches", "+=", "1", "\n", "\n", "# Check the loss value", "\n", "assert", "not", "np", ".", "isnan", "(", "loss_value", ")", ",", "\"Model diverged with loss = NaN\"", "\n", "\n", "", "all_fw_memory_cells", ".", "append", "(", "fw_memory_cells", ")", "\n", "all_bw_memory_cells", ".", "append", "(", "bw_memory_cells", ")", "\n", "y", ".", "append", "(", "each_y_pred", ")", "\n", "y_true", ".", "append", "(", "each_y_true", ")", "\n", "\n", "# Save memory cells and predictions", "\n", "", "save_dict", "=", "{", "\n", "\"fw_memory_cells\"", ":", "fw_memory_cells", ",", "\n", "\"bw_memory_cells\"", ":", "bw_memory_cells", ",", "\n", "\"y_true\"", ":", "y_true", ",", "\n", "\"y_pred\"", ":", "y", "\n", "}", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\n", "\"output_subject{}.npz\"", ".", "format", "(", "subject_idx", ")", "\n", ")", "\n", "np", ".", "savez", "(", "save_path", ",", "**", "save_dict", ")", "\n", "print", "(", "\"Saved outputs to {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_loss", "/=", "n_batches", "\n", "total_y_pred", "=", "np", ".", "hstack", "(", "y", ")", "\n", "total_y_true", "=", "np", ".", "hstack", "(", "y_true", ")", "\n", "\n", "return", "total_y_true", ",", "total_y_pred", ",", "total_loss", ",", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.predict": [[590, 682], ["print", "numpy.asarray", "numpy.asarray", "len", "sklearn.metrics.confusion_matrix", "numpy.mean", "sklearn.metrics.f1_score", "print", "print", "tensorflow.Graph().as_default", "tensorflow.compat.v1.Session", "predict.CustomDeepSleepNet", "CustomDeepSleepNet.init_ops", "range", "os.path.join", "tensorflow.compat.v1.train.Saver", "tf.compat.v1.train.Saver.restore", "print", "deepsleep.data_loader.SeqDataLoader.load_subject_data", "print", "predict.custom_run_epoch", "len", "sklearn.metrics.confusion_matrix", "numpy.mean", "sklearn.metrics.f1_score", "predict.print_performance", "np.asarray.extend", "np.asarray.extend", "datetime.datetime.now", "tensorflow.Graph", "tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "datetime.datetime.now", "tensorflow.no_op"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.init_ops", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader.load_subject_data", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.custom_run_epoch", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance"], ["", "def", "predict", "(", "\n", "data_dir", ",", "\n", "model_dir", ",", "\n", "output_dir", ",", "\n", "n_subjects", ",", "\n", "n_subjects_per_fold", "\n", ")", ":", "\n", "# Ground truth and predictions", "\n", "    ", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "\n", "# The model will be built into the default Graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "# Build the network", "\n", "        ", "valid_net", "=", "CustomDeepSleepNet", "(", "\n", "batch_size", "=", "1", ",", "\n", "input_dims", "=", "EPOCH_SEC_LEN", "*", "100", ",", "\n", "n_classes", "=", "NUM_CLASSES", ",", "\n", "seq_length", "=", "25", ",", "\n", "n_rnn_layers", "=", "2", ",", "\n", "return_last", "=", "False", ",", "\n", "is_train", "=", "False", ",", "\n", "reuse_params", "=", "False", ",", "\n", "use_dropout_feature", "=", "True", ",", "\n", "use_dropout_sequence", "=", "True", "\n", ")", "\n", "\n", "# Initialize parameters", "\n", "valid_net", ".", "init_ops", "(", ")", "\n", "\n", "for", "subject_idx", "in", "range", "(", "n_subjects", ")", ":", "\n", "            ", "fold_idx", "=", "subject_idx", "//", "n_subjects_per_fold", "\n", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "\n", "model_dir", ",", "\n", "\"fold{}\"", ".", "format", "(", "fold_idx", ")", ",", "\n", "\"deepsleepnet\"", "\n", ")", "\n", "\n", "# Restore the trained model", "\n", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_path", ")", ")", "\n", "print", "(", "\"Model restored from: {}\\n\"", ".", "format", "(", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_path", ")", ")", ")", "\n", "\n", "# Load testing data", "\n", "x", ",", "y", "=", "SeqDataLoader", ".", "load_subject_data", "(", "\n", "data_dir", "=", "data_dir", ",", "\n", "subject_idx", "=", "subject_idx", "\n", ")", "\n", "\n", "# Loop each epoch", "\n", "print", "(", "\"[{}] Predicting ...\\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "\n", "# Evaluate the model on the subject data", "\n", "y_true_", ",", "y_pred_", ",", "loss", ",", "duration", "=", "custom_run_epoch", "(", "\n", "sess", "=", "sess", ",", "network", "=", "valid_net", ",", "\n", "inputs", "=", "x", ",", "targets", "=", "y", ",", "\n", "train_op", "=", "tf", ".", "no_op", "(", ")", ",", "\n", "is_train", "=", "False", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "subject_idx", "=", "subject_idx", "\n", ")", "\n", "n_examples", "=", "len", "(", "y_true_", ")", "\n", "cm_", "=", "confusion_matrix", "(", "y_true_", ",", "y_pred_", ")", "\n", "acc_", "=", "np", ".", "mean", "(", "y_true_", "==", "y_pred_", ")", "\n", "mf1_", "=", "f1_score", "(", "y_true_", ",", "y_pred_", ",", "average", "=", "\"macro\"", ")", "\n", "\n", "# Report performance", "\n", "print_performance", "(", "\n", "sess", ",", "valid_net", ".", "name", ",", "\n", "n_examples", ",", "duration", ",", "loss", ",", "\n", "cm_", ",", "acc_", ",", "mf1_", "\n", ")", "\n", "\n", "y_true", ".", "extend", "(", "y_true_", ")", "\n", "y_pred", ".", "extend", "(", "y_pred_", ")", "\n", "\n", "# Overall performance", "\n", "", "", "print", "(", "\"[{}] Overall prediction performance\\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "y_true", "=", "np", ".", "asarray", "(", "y_true", ")", "\n", "y_pred", "=", "np", ".", "asarray", "(", "y_pred", ")", "\n", "n_examples", "=", "len", "(", "y_true", ")", "\n", "cm", "=", "confusion_matrix", "(", "y_true", ",", "y_pred", ")", "\n", "acc", "=", "np", ".", "mean", "(", "y_true", "==", "y_pred", ")", "\n", "mf1", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "\"macro\"", ")", "\n", "print", "(", "(", "\n", "\"n={}, acc={:.3f}, f1={:.3f}\"", ".", "format", "(", "\n", "n_examples", ",", "acc", ",", "mf1", "\n", ")", "\n", ")", ")", "\n", "print", "(", "cm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.predict.main": [[684, 701], ["predict.predict", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.predict"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "# # Makes the random numbers predictable", "\n", "# np.random.seed(0)", "\n", "# tf.set_random_seed(0)", "\n", "\n", "# Output dir", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "FLAGS", ".", "output_dir", ")", "\n", "\n", "", "n_subjects", "=", "20", "\n", "n_subjects_per_fold", "=", "1", "\n", "predict", "(", "\n", "data_dir", "=", "FLAGS", ".", "data_dir", ",", "\n", "model_dir", "=", "FLAGS", ".", "model_dir", ",", "\n", "output_dir", "=", "FLAGS", ".", "output_dir", ",", "\n", "n_subjects", "=", "n_subjects", ",", "\n", "n_subjects_per_fold", "=", "n_subjects_per_fold", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.train.pretrain": [[33, 51], ["deepsleep.trainer.DeepFeatureNetTrainer", "deepsleep.trainer.DeepFeatureNetTrainer.train"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepFeatureNetTrainer.train"], ["def", "pretrain", "(", "n_epochs", ")", ":", "\n", "    ", "trainer", "=", "DeepFeatureNetTrainer", "(", "\n", "data_dir", "=", "FLAGS", ".", "data_dir", ",", "\n", "output_dir", "=", "FLAGS", ".", "output_dir", ",", "\n", "n_folds", "=", "FLAGS", ".", "n_folds", ",", "\n", "fold_idx", "=", "FLAGS", ".", "fold_idx", ",", "\n", "batch_size", "=", "100", ",", "\n", "input_dims", "=", "EPOCH_SEC_LEN", "*", "100", ",", "\n", "n_classes", "=", "NUM_CLASSES", ",", "\n", "interval_plot_filter", "=", "50", ",", "\n", "interval_save_model", "=", "100", ",", "\n", "interval_print_cm", "=", "10", "\n", ")", "\n", "pretrained_model_path", "=", "trainer", ".", "train", "(", "\n", "n_epochs", "=", "n_epochs", ",", "\n", "resume", "=", "FLAGS", ".", "resume", "\n", ")", "\n", "return", "pretrained_model_path", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.train.finetune": [[53, 75], ["deepsleep.trainer.DeepSleepNetTrainer", "deepsleep.trainer.DeepSleepNetTrainer.finetune"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer.finetune"], ["", "def", "finetune", "(", "model_path", ",", "n_epochs", ")", ":", "\n", "    ", "trainer", "=", "DeepSleepNetTrainer", "(", "\n", "data_dir", "=", "FLAGS", ".", "data_dir", ",", "\n", "output_dir", "=", "FLAGS", ".", "output_dir", ",", "\n", "n_folds", "=", "FLAGS", ".", "n_folds", ",", "\n", "fold_idx", "=", "FLAGS", ".", "fold_idx", ",", "\n", "batch_size", "=", "10", ",", "\n", "input_dims", "=", "EPOCH_SEC_LEN", "*", "100", ",", "\n", "n_classes", "=", "NUM_CLASSES", ",", "\n", "seq_length", "=", "25", ",", "\n", "n_rnn_layers", "=", "2", ",", "\n", "return_last", "=", "False", ",", "\n", "interval_plot_filter", "=", "50", ",", "\n", "interval_save_model", "=", "100", ",", "\n", "interval_print_cm", "=", "10", "\n", ")", "\n", "finetuned_model_path", "=", "trainer", ".", "finetune", "(", "\n", "pretrained_model_path", "=", "model_path", ",", "\n", "n_epochs", "=", "n_epochs", ",", "\n", "resume", "=", "FLAGS", ".", "resume", "\n", ")", "\n", "return", "finetuned_model_path", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.train.main": [[77, 91], ["os.path.join", "train.pretrain", "train.finetune", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.DeleteRecursively"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.ReconLayer.pretrain", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer.finetune"], ["", "def", "main", "(", "argv", "=", "None", ")", ":", "\n", "# Output dir", "\n", "    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "\"fold{}\"", ".", "format", "(", "FLAGS", ".", "fold_idx", ")", ")", "\n", "if", "not", "FLAGS", ".", "resume", ":", "\n", "        ", "if", "tf", ".", "gfile", ".", "Exists", "(", "output_dir", ")", ":", "\n", "            ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "output_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "output_dir", ")", "\n", "\n", "", "pretrained_model_path", "=", "pretrain", "(", "\n", "n_epochs", "=", "FLAGS", ".", "pretrain_epochs", "\n", ")", "\n", "finetuned_model_path", "=", "finetune", "(", "\n", "model_path", "=", "pretrained_model_path", ",", "\n", "n_epochs", "=", "FLAGS", ".", "finetune_epochs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.__init__": [[87, 89], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "file", ")", ":", "\n", "    ", "self", ".", "file", "=", "file", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_header": [[91, 102], ["dhedfreader.edf_header", "numpy.all", "numpy.all"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.edf_header"], ["", "def", "read_header", "(", "self", ")", ":", "\n", "    ", "self", ".", "header", "=", "h", "=", "edf_header", "(", "self", ".", "file", ")", "\n", "\n", "# calculate ranges for rescaling", "\n", "self", ".", "dig_min", "=", "h", "[", "'digital_min'", "]", "\n", "self", ".", "phys_min", "=", "h", "[", "'physical_min'", "]", "\n", "phys_range", "=", "h", "[", "'physical_max'", "]", "-", "h", "[", "'physical_min'", "]", "\n", "dig_range", "=", "h", "[", "'digital_max'", "]", "-", "h", "[", "'digital_min'", "]", "\n", "assert", "np", ".", "all", "(", "phys_range", ">", "0", ")", "\n", "assert", "np", ".", "all", "(", "dig_range", ">", "0", ")", "\n", "self", ".", "gain", "=", "phys_range", "/", "dig_range", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_raw_record": [[104, 115], ["dhedfreader.BaseEDFReader.file.read", "result.append", "len"], "methods", ["None"], ["", "def", "read_raw_record", "(", "self", ")", ":", "\n", "    ", "'''Read a record with data and return a list containing arrays with raw\n    bytes.\n    '''", "\n", "result", "=", "[", "]", "\n", "for", "nsamp", "in", "self", ".", "header", "[", "'n_samples_per_record'", "]", ":", "\n", "      ", "samples", "=", "self", ".", "file", ".", "read", "(", "nsamp", "*", "2", ")", "\n", "if", "len", "(", "samples", ")", "!=", "nsamp", "*", "2", ":", "\n", "        ", "raise", "EDFEndOfData", "\n", "", "result", ".", "append", "(", "samples", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.convert_record": [[117, 140], ["float", "enumerate", "dhedfreader.tal", "events.extend", "numpy.fromstring().astype", "signals.append", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.tal"], ["", "def", "convert_record", "(", "self", ",", "raw_record", ")", ":", "\n", "    ", "'''Convert a raw record to a (time, signals, events) tuple based on\n    information in the header.\n    '''", "\n", "h", "=", "self", ".", "header", "\n", "dig_min", ",", "phys_min", ",", "gain", "=", "self", ".", "dig_min", ",", "self", ".", "phys_min", ",", "self", ".", "gain", "\n", "time", "=", "float", "(", "'nan'", ")", "\n", "signals", "=", "[", "]", "\n", "events", "=", "[", "]", "\n", "for", "(", "i", ",", "samples", ")", "in", "enumerate", "(", "raw_record", ")", ":", "\n", "      ", "if", "h", "[", "'label'", "]", "[", "i", "]", "==", "EVENT_CHANNEL", ":", "\n", "        ", "ann", "=", "tal", "(", "samples", ")", "\n", "time", "=", "ann", "[", "0", "]", "[", "0", "]", "\n", "events", ".", "extend", "(", "ann", "[", "1", ":", "]", ")", "\n", "# print(i, samples)", "\n", "# exit()", "\n", "", "else", ":", "\n", "# 2-byte little-endian integers", "\n", "        ", "dig", "=", "np", ".", "fromstring", "(", "samples", ",", "'<i2'", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "phys", "=", "(", "dig", "-", "dig_min", "[", "i", "]", ")", "*", "gain", "[", "i", "]", "+", "phys_min", "[", "i", "]", "\n", "signals", ".", "append", "(", "phys", ")", "\n", "\n", "", "", "return", "time", ",", "signals", ",", "events", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_record": [[142, 144], ["dhedfreader.BaseEDFReader.convert_record", "dhedfreader.BaseEDFReader.read_raw_record"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.convert_record", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_raw_record"], ["", "def", "read_record", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "convert_record", "(", "self", ".", "read_raw_record", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.records": [[146, 155], ["dhedfreader.BaseEDFReader.read_record"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_record"], ["", "def", "records", "(", "self", ")", ":", "\n", "    ", "'''\n    Record generator.\n    '''", "\n", "try", ":", "\n", "      ", "while", "True", ":", "\n", "        ", "yield", "self", ".", "read_record", "(", ")", "\n", "", "", "except", "EDFEndOfData", ":", "\n", "      ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.tal": [[23, 43], ["dhedfreader.tal.parse"], "function", ["None"], ["def", "tal", "(", "tal_str", ")", ":", "\n", "  ", "'''Return a list with (onset, duration, annotation) tuples for an EDF+ TAL\n  stream.\n  '''", "\n", "exp", "=", "'(?P<onset>[+\\-]\\d+(?:\\.\\d*)?)'", "+", "'(?:\\x15(?P<duration>\\d+(?:\\.\\d*)?))?'", "+", "'(\\x14(?P<annotation>[^\\x00]*))?'", "+", "'(?:\\x14\\x00)'", "\n", "\n", "def", "annotation_to_list", "(", "annotation", ")", ":", "\n", "#return str(annotation, 'utf-8').split('\\x14') if annotation else []", "\n", "    ", "return", "annotation", ".", "split", "(", "'\\x14'", ")", "if", "annotation", "else", "[", "]", "\n", "\n", "", "def", "parse", "(", "dic", ")", ":", "\n", "    ", "return", "(", "\n", "float", "(", "dic", "[", "'onset'", "]", ")", ",", "\n", "float", "(", "dic", "[", "'duration'", "]", ")", "if", "dic", "[", "'duration'", "]", "else", "0.", ",", "\n", "annotation_to_list", "(", "dic", "[", "'annotation'", "]", ")", ")", "\n", "\n", "", "return", "[", "parse", "(", "m", ".", "groupdict", "(", ")", ")", "for", "m", "in", "re", ".", "finditer", "(", "exp", ",", "tal_str", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.edf_header": [[45, 84], ["f.read().strip", "f.read().strip", "str", "int", "int", "float", "int", "list", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "f.read", "f.tell", "f.read", "int", "int", "datetime.datetime", "f.read", "f.read", "f.read", "f.read", "f.read", "range", "f.read().strip", "f.read().strip", "f.read().strip", "f.read().strip", "int", "f.tell", "f.read", "f.read", "re.findall", "re.findall", "float", "float", "float", "float", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read", "f.read"], "function", ["None"], ["", "def", "edf_header", "(", "f", ")", ":", "\n", "  ", "h", "=", "{", "}", "\n", "assert", "f", ".", "tell", "(", ")", "==", "0", "# check file position", "\n", "assert", "f", ".", "read", "(", "8", ")", "==", "'0       '", "\n", "\n", "# recording info)", "\n", "h", "[", "'local_subject_id'", "]", "=", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "\n", "h", "[", "'local_recording_id'", "]", "=", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "\n", "\n", "# parse timestamp", "\n", "(", "day", ",", "month", ",", "year", ")", "=", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "'(\\d+)'", ",", "f", ".", "read", "(", "8", ")", ")", "]", "\n", "(", "hour", ",", "minute", ",", "sec", ")", "=", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "'(\\d+)'", ",", "f", ".", "read", "(", "8", ")", ")", "]", "\n", "h", "[", "'date_time'", "]", "=", "str", "(", "datetime", ".", "datetime", "(", "year", "+", "2000", ",", "month", ",", "day", ",", "\n", "hour", ",", "minute", ",", "sec", ")", ")", "\n", "\n", "# misc", "\n", "header_nbytes", "=", "int", "(", "f", ".", "read", "(", "8", ")", ")", "\n", "subtype", "=", "f", ".", "read", "(", "44", ")", "[", ":", "5", "]", "\n", "h", "[", "'EDF+'", "]", "=", "subtype", "in", "[", "'EDF+C'", ",", "'EDF+D'", "]", "\n", "h", "[", "'contiguous'", "]", "=", "subtype", "!=", "'EDF+D'", "\n", "h", "[", "'n_records'", "]", "=", "int", "(", "f", ".", "read", "(", "8", ")", ")", "\n", "h", "[", "'record_length'", "]", "=", "float", "(", "f", ".", "read", "(", "8", ")", ")", "# in seconds", "\n", "nchannels", "=", "h", "[", "'n_channels'", "]", "=", "int", "(", "f", ".", "read", "(", "4", ")", ")", "\n", "\n", "# read channel info", "\n", "channels", "=", "list", "(", "range", "(", "h", "[", "'n_channels'", "]", ")", ")", "\n", "h", "[", "'label'", "]", "=", "[", "f", ".", "read", "(", "16", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'transducer_type'", "]", "=", "[", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'units'", "]", "=", "[", "f", ".", "read", "(", "8", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'physical_min'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'physical_max'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'digital_min'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'digital_max'", "]", "=", "np", ".", "asarray", "(", "[", "float", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", ")", "\n", "h", "[", "'prefiltering'", "]", "=", "[", "f", ".", "read", "(", "80", ")", ".", "strip", "(", ")", "for", "n", "in", "channels", "]", "\n", "h", "[", "'n_samples_per_record'", "]", "=", "[", "int", "(", "f", ".", "read", "(", "8", ")", ")", "for", "n", "in", "channels", "]", "\n", "f", ".", "read", "(", "32", "*", "nchannels", ")", "# reserved", "\n", "\n", "assert", "f", ".", "tell", "(", ")", "==", "header_nbytes", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.load_edf": [[157, 219], ["isinstance", "dhedfreader.BaseEDFReader", "dhedfreader.BaseEDFReader.read_header", "log.debug", "numpy.unique", "list", "numpy.hstack", "functools.reduce", "collections.namedtuple", "collections.namedtuple.", "float", "zip", "numpy.linspace", "numpy.hstack", "open", "dhedfreader.load_edf", "numpy.arange", "zip", "dhedfreader.BaseEDFReader.records"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_header", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.load_edf", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.records"], ["", "", "", "def", "load_edf", "(", "edffile", ")", ":", "\n", "  ", "'''Load an EDF+ file.\n  Very basic reader for EDF and EDF+ files. While BaseEDFReader does support\n  exotic features like non-homogeneous sample rates and loading only parts of\n  the stream, load_edf expects a single fixed sample rate for all channels and\n  tries to load the whole file.\n  Parameters\n  ----------\n  edffile : file-like object or string\n  Returns\n  -------\n  Named tuple with the fields:\n    X : NumPy array with shape p by n.\n      Raw recording of n samples in p dimensions.\n    sample_rate : float\n      The sample rate of the recording. Note that mixed sample-rates are not\n      supported.\n    sens_lab : list of length p with strings\n      The labels of the sensors used to record X.\n    time : NumPy array with length n\n      The time offset in the recording for each sample.\n    annotations : a list with tuples\n      EDF+ annotations are stored in (start, duration, description) tuples.\n      start : float\n        Indicates the start of the event in seconds.\n      duration : float\n        Indicates the duration of the event in seconds.\n      description : list with strings\n        Contains (multiple?) descriptions of the annotation event.\n  '''", "\n", "if", "isinstance", "(", "edffile", ",", "str", ")", ":", "\n", "    ", "with", "open", "(", "edffile", ",", "'rb'", ")", "as", "f", ":", "\n", "      ", "return", "load_edf", "(", "f", ")", "# convert filename to file", "\n", "\n", "", "", "reader", "=", "BaseEDFReader", "(", "edffile", ")", "\n", "reader", ".", "read_header", "(", ")", "\n", "\n", "h", "=", "reader", ".", "header", "\n", "log", ".", "debug", "(", "'EDF header: %s'", "%", "h", ")", "\n", "\n", "# get sample rate info", "\n", "nsamp", "=", "np", ".", "unique", "(", "\n", "[", "n", "for", "(", "l", ",", "n", ")", "in", "zip", "(", "h", "[", "'label'", "]", ",", "h", "[", "'n_samples_per_record'", "]", ")", "\n", "if", "l", "!=", "EVENT_CHANNEL", "]", ")", "\n", "assert", "nsamp", ".", "size", "==", "1", ",", "'Multiple sample rates not supported!'", "\n", "sample_rate", "=", "float", "(", "nsamp", "[", "0", "]", ")", "/", "h", "[", "'record_length'", "]", "\n", "\n", "rectime", ",", "X", ",", "annotations", "=", "list", "(", "zip", "(", "*", "reader", ".", "records", "(", ")", ")", ")", "\n", "X", "=", "np", ".", "hstack", "(", "X", ")", "\n", "annotations", "=", "reduce", "(", "operator", ".", "add", ",", "annotations", ")", "\n", "chan_lab", "=", "[", "lab", "for", "lab", "in", "reader", ".", "header", "[", "'label'", "]", "if", "lab", "!=", "EVENT_CHANNEL", "]", "\n", "\n", "# create timestamps", "\n", "if", "reader", ".", "header", "[", "'contiguous'", "]", ":", "\n", "    ", "time", "=", "np", ".", "arange", "(", "X", ".", "shape", "[", "1", "]", ")", "/", "sample_rate", "\n", "", "else", ":", "\n", "    ", "reclen", "=", "reader", ".", "header", "[", "'record_length'", "]", "\n", "within_rec_time", "=", "np", ".", "linspace", "(", "0", ",", "reclen", ",", "nsamp", ",", "endpoint", "=", "False", ")", "\n", "time", "=", "np", ".", "hstack", "(", "[", "t", "+", "within_rec_time", "for", "t", "in", "rectime", "]", ")", "\n", "\n", "", "tup", "=", "namedtuple", "(", "'EDF'", ",", "'X sample_rate chan_lab time annotations'", ")", "\n", "return", "tup", "(", "X", ",", "sample_rate", ",", "chan_lab", ",", "time", ",", "annotations", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.prepare_physionet.main": [[60, 213], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "glob.glob", "glob.glob", "np.asarray.sort", "np.asarray.sort", "numpy.asarray", "numpy.asarray", "range", "os.path.exists", "os.makedirs", "shutil.rmtree", "os.makedirs", "os.path.join", "os.path.join", "len", "mne.io.read_raw_edf", "raw_ch_df.to_frame.to_frame", "raw_ch_df.to_frame.set_index", "open", "dhedfreader.BaseEDFReader", "dhedfreader.BaseEDFReader.read_header", "open.close", "datetime.datetime.strptime", "open", "dhedfreader.BaseEDFReader", "dhedfreader.BaseEDFReader.read_header", "list", "open.close", "datetime.datetime.strptime", "numpy.hstack", "print", "print", "print", "numpy.hstack", "numpy.intersect1d", "print", "numpy.asarray().astype", "np.hstack.astype", "numpy.arange", "print", "print", "ntpath.basename().replace", "numpy.savez", "print", "mne.io.read_raw_edf.to_data_frame", "numpy.arange", "zip", "len", "numpy.hstack", "numpy.setdiff1d", "numpy.arange", "len", "len", "print", "numpy.setdiff1d", "numpy.all", "print", "Exception", "len", "len", "len", "numpy.where", "len", "os.path.join", "len", "int", "np.hstack.append", "np.hstack.append", "print", "np.hstack.append", "print", "numpy.arange", "len", "int", "len", "numpy.asarray", "len", "ntpath.basename", "dhedfreader.BaseEDFReader.records", "Exception", "numpy.ones", "int", "numpy.arange", "int", "numpy.arange", "numpy.arange", "len", "len", "int", "math.ceil", "numpy.split", "len"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_header", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.read_header", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.None.dhedfreader.BaseEDFReader.records"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/data/physionet_sleep\"", ",", "\n", "help", "=", "\"File path to the CSV or NPY file that contains walking data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"/data/physionet_sleep/eeg_fpz_cz\"", ",", "\n", "help", "=", "\"Directory where to save outputs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--select_ch\"", ",", "type", "=", "str", ",", "default", "=", "\"EEG Fpz-Cz\"", ",", "\n", "help", "=", "\"File path to the trained model used to estimate walking speeds.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Output dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "else", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "args", ".", "output_dir", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Select channel", "\n", "", "select_ch", "=", "args", ".", "select_ch", "\n", "\n", "# Read raw and annotation EDF files", "\n", "psg_fnames", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"*PSG.edf\"", ")", ")", "\n", "ann_fnames", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"*Hypnogram.edf\"", ")", ")", "\n", "psg_fnames", ".", "sort", "(", ")", "\n", "ann_fnames", ".", "sort", "(", ")", "\n", "psg_fnames", "=", "np", ".", "asarray", "(", "psg_fnames", ")", "\n", "ann_fnames", "=", "np", ".", "asarray", "(", "ann_fnames", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "psg_fnames", ")", ")", ":", "\n", "# if not \"ST7171J0-PSG.edf\" in psg_fnames[i]:", "\n", "#     continue", "\n", "\n", "        ", "raw", "=", "read_raw_edf", "(", "psg_fnames", "[", "i", "]", ",", "preload", "=", "True", ",", "stim_channel", "=", "None", ")", "\n", "sampling_rate", "=", "raw", ".", "info", "[", "'sfreq'", "]", "\n", "raw_ch_df", "=", "raw", ".", "to_data_frame", "(", "scaling_time", "=", "100.0", ")", "[", "select_ch", "]", "\n", "raw_ch_df", "=", "raw_ch_df", ".", "to_frame", "(", ")", "\n", "raw_ch_df", ".", "set_index", "(", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", ")", "\n", "\n", "# Get raw header", "\n", "f", "=", "open", "(", "psg_fnames", "[", "i", "]", ",", "'r'", ",", "encoding", "=", "'iso-8859-1'", ")", "\n", "reader_raw", "=", "dhedfreader", ".", "BaseEDFReader", "(", "f", ")", "\n", "reader_raw", ".", "read_header", "(", ")", "\n", "h_raw", "=", "reader_raw", ".", "header", "\n", "f", ".", "close", "(", ")", "\n", "raw_start_dt", "=", "datetime", ".", "strptime", "(", "h_raw", "[", "'date_time'", "]", ",", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "\n", "# Read annotation and its header", "\n", "f", "=", "open", "(", "ann_fnames", "[", "i", "]", ",", "'r'", ",", "encoding", "=", "'iso-8859-1'", ")", "\n", "reader_ann", "=", "dhedfreader", ".", "BaseEDFReader", "(", "f", ")", "\n", "reader_ann", ".", "read_header", "(", ")", "\n", "h_ann", "=", "reader_ann", ".", "header", "\n", "_", ",", "_", ",", "ann", "=", "list", "(", "zip", "(", "*", "reader_ann", ".", "records", "(", ")", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "ann_start_dt", "=", "datetime", ".", "strptime", "(", "h_ann", "[", "'date_time'", "]", ",", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "\n", "# Assert that raw and annotation files start at the same time", "\n", "assert", "raw_start_dt", "==", "ann_start_dt", "\n", "\n", "# Generate label and remove indices", "\n", "remove_idx", "=", "[", "]", "# indicies of the data that will be removed", "\n", "labels", "=", "[", "]", "# indicies of the data that have labels", "\n", "label_idx", "=", "[", "]", "\n", "for", "a", "in", "ann", "[", "0", "]", ":", "\n", "            ", "onset_sec", ",", "duration_sec", ",", "ann_char", "=", "a", "\n", "ann_str", "=", "\"\"", ".", "join", "(", "ann_char", ")", "\n", "label", "=", "ann2label", "[", "ann_str", "]", "\n", "if", "label", "!=", "UNKNOWN", ":", "\n", "                ", "if", "duration_sec", "%", "EPOCH_SEC_SIZE", "!=", "0", ":", "\n", "                    ", "raise", "Exception", "(", "\"Something wrong\"", ")", "\n", "", "duration_epoch", "=", "int", "(", "duration_sec", "/", "EPOCH_SEC_SIZE", ")", "\n", "label_epoch", "=", "np", ".", "ones", "(", "duration_epoch", ",", "dtype", "=", "np", ".", "int", ")", "*", "label", "\n", "labels", ".", "append", "(", "label_epoch", ")", "\n", "idx", "=", "int", "(", "onset_sec", "*", "sampling_rate", ")", "+", "np", ".", "arange", "(", "duration_sec", "*", "sampling_rate", ",", "dtype", "=", "np", ".", "int", ")", "\n", "label_idx", ".", "append", "(", "idx", ")", "\n", "\n", "print", "(", "\"Include onset:{}, duration:{}, label:{} ({})\"", ".", "format", "(", "\n", "onset_sec", ",", "duration_sec", ",", "label", ",", "ann_str", "\n", ")", ")", "\n", "", "else", ":", "\n", "                ", "idx", "=", "int", "(", "onset_sec", "*", "sampling_rate", ")", "+", "np", ".", "arange", "(", "duration_sec", "*", "sampling_rate", ",", "dtype", "=", "np", ".", "int", ")", "\n", "remove_idx", ".", "append", "(", "idx", ")", "\n", "\n", "print", "(", "\"Remove onset:{}, duration:{}, label:{} ({})\"", ".", "format", "(", "\n", "onset_sec", ",", "duration_sec", ",", "label", ",", "ann_str", "\n", ")", ")", "\n", "", "", "labels", "=", "np", ".", "hstack", "(", "labels", ")", "\n", "\n", "print", "(", "\"before remove unwanted: {}\"", ".", "format", "(", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", ".", "shape", ")", ")", "\n", "if", "len", "(", "remove_idx", ")", ">", "0", ":", "\n", "            ", "remove_idx", "=", "np", ".", "hstack", "(", "remove_idx", ")", "\n", "select_idx", "=", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", ",", "remove_idx", ")", "\n", "", "else", ":", "\n", "            ", "select_idx", "=", "np", ".", "arange", "(", "len", "(", "raw_ch_df", ")", ")", "\n", "", "print", "(", "\"after remove unwanted: {}\"", ".", "format", "(", "select_idx", ".", "shape", ")", ")", "\n", "\n", "# Select only the data with labels", "\n", "print", "(", "\"before intersect label: {}\"", ".", "format", "(", "select_idx", ".", "shape", ")", ")", "\n", "label_idx", "=", "np", ".", "hstack", "(", "label_idx", ")", "\n", "select_idx", "=", "np", ".", "intersect1d", "(", "select_idx", ",", "label_idx", ")", "\n", "print", "(", "\"after intersect label: {}\"", ".", "format", "(", "select_idx", ".", "shape", ")", ")", "\n", "\n", "# Remove extra index", "\n", "if", "len", "(", "label_idx", ")", ">", "len", "(", "select_idx", ")", ":", "\n", "            ", "print", "(", "\"before remove extra labels: {}, {}\"", ".", "format", "(", "select_idx", ".", "shape", ",", "labels", ".", "shape", ")", ")", "\n", "extra_idx", "=", "np", ".", "setdiff1d", "(", "label_idx", ",", "select_idx", ")", "\n", "# Trim the tail", "\n", "if", "np", ".", "all", "(", "extra_idx", ">", "select_idx", "[", "-", "1", "]", ")", ":", "\n", "                ", "n_trims", "=", "len", "(", "select_idx", ")", "%", "int", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", "\n", "n_label_trims", "=", "int", "(", "math", ".", "ceil", "(", "n_trims", "/", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", ")", ")", "\n", "select_idx", "=", "select_idx", "[", ":", "-", "n_trims", "]", "\n", "labels", "=", "labels", "[", ":", "-", "n_label_trims", "]", "\n", "", "print", "(", "\"after remove extra labels: {}, {}\"", ".", "format", "(", "select_idx", ".", "shape", ",", "labels", ".", "shape", ")", ")", "\n", "\n", "# Remove movement and unknown stages if any", "\n", "", "raw_ch", "=", "raw_ch_df", ".", "values", "[", "select_idx", "]", "\n", "\n", "# Verify that we can split into 30-s epochs", "\n", "if", "len", "(", "raw_ch", ")", "%", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Something wrong\"", ")", "\n", "", "n_epochs", "=", "len", "(", "raw_ch", ")", "/", "(", "EPOCH_SEC_SIZE", "*", "sampling_rate", ")", "\n", "\n", "# Get epochs and their corresponding labels", "\n", "x", "=", "np", ".", "asarray", "(", "np", ".", "split", "(", "raw_ch", ",", "n_epochs", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "y", "=", "labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "assert", "len", "(", "x", ")", "==", "len", "(", "y", ")", "\n", "\n", "# Select on sleep periods", "\n", "w_edge_mins", "=", "30", "\n", "nw_idx", "=", "np", ".", "where", "(", "y", "!=", "stage_dict", "[", "\"W\"", "]", ")", "[", "0", "]", "\n", "start_idx", "=", "nw_idx", "[", "0", "]", "-", "(", "w_edge_mins", "*", "2", ")", "\n", "end_idx", "=", "nw_idx", "[", "-", "1", "]", "+", "(", "w_edge_mins", "*", "2", ")", "\n", "if", "start_idx", "<", "0", ":", "start_idx", "=", "0", "\n", "if", "end_idx", ">=", "len", "(", "y", ")", ":", "end_idx", "=", "len", "(", "y", ")", "-", "1", "\n", "select_idx", "=", "np", ".", "arange", "(", "start_idx", ",", "end_idx", "+", "1", ")", "\n", "print", "(", "(", "\"Data before selection: {}, {}\"", ".", "format", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", ")", "\n", "x", "=", "x", "[", "select_idx", "]", "\n", "y", "=", "y", "[", "select_idx", "]", "\n", "print", "(", "(", "\"Data after selection: {}, {}\"", ".", "format", "(", "x", ".", "shape", ",", "y", ".", "shape", ")", ")", ")", "\n", "\n", "# Save", "\n", "filename", "=", "ntpath", ".", "basename", "(", "psg_fnames", "[", "i", "]", ")", ".", "replace", "(", "\"-PSG.edf\"", ",", "\".npz\"", ")", "\n", "save_dict", "=", "{", "\n", "\"x\"", ":", "x", ",", "\n", "\"y\"", ":", "y", ",", "\n", "\"fs\"", ":", "sampling_rate", ",", "\n", "\"ch_label\"", ":", "select_ch", ",", "\n", "\"header_raw\"", ":", "h_raw", ",", "\n", "\"header_annotation\"", ":", "h_ann", ",", "\n", "}", "\n", "np", ".", "savez", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "filename", ")", ",", "**", "save_dict", ")", "\n", "\n", "print", "(", "\"\\n=======================================\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.NonSeqDataLoader.__init__": [[13, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "n_folds", ",", "fold_idx", ")", ":", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "n_folds", "=", "n_folds", "\n", "self", ".", "fold_idx", "=", "fold_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.NonSeqDataLoader._load_npz_file": [[18, 25], ["numpy.load"], "methods", ["None"], ["", "def", "_load_npz_file", "(", "self", ",", "npz_file", ")", ":", "\n", "        ", "\"\"\"Load data and labels from a npz file.\"\"\"", "\n", "with", "np", ".", "load", "(", "npz_file", ")", "as", "f", ":", "\n", "            ", "data", "=", "f", "[", "\"x\"", "]", "\n", "labels", "=", "f", "[", "\"y\"", "]", "\n", "sampling_rate", "=", "f", "[", "\"fs\"", "]", "\n", "", "return", "data", ",", "labels", ",", "sampling_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.NonSeqDataLoader._load_npz_list_files": [[26, 43], ["numpy.vstack", "numpy.hstack", "print", "data_loader.NonSeqDataLoader._load_npz_file", "numpy.vstack.append", "numpy.hstack.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_file"], ["", "def", "_load_npz_list_files", "(", "self", ",", "npz_files", ")", ":", "\n", "        ", "\"\"\"Load data and labels from list of npz files.\"\"\"", "\n", "data", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "fs", "=", "None", "\n", "for", "npz_f", "in", "npz_files", ":", "\n", "            ", "print", "(", "\"Loading {} ...\"", ".", "format", "(", "npz_f", ")", ")", "\n", "tmp_data", ",", "tmp_labels", ",", "sampling_rate", "=", "self", ".", "_load_npz_file", "(", "npz_f", ")", "\n", "if", "fs", "is", "None", ":", "\n", "                ", "fs", "=", "sampling_rate", "\n", "", "elif", "fs", "!=", "sampling_rate", ":", "\n", "                ", "raise", "Exception", "(", "\"Found mismatch in sampling rate.\"", ")", "\n", "", "data", ".", "append", "(", "tmp_data", ")", "\n", "labels", ".", "append", "(", "tmp_labels", ")", "\n", "", "data", "=", "np", ".", "vstack", "(", "data", ")", "\n", "labels", "=", "np", ".", "hstack", "(", "labels", ")", "\n", "return", "data", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.NonSeqDataLoader._load_cv_data": [[44, 71], ["numpy.array_split", "numpy.setdiff1d", "print", "data_loader.NonSeqDataLoader._load_npz_list_files", "print", "print", "data_loader.NonSeqDataLoader._load_npz_list_files", "print", "numpy.squeeze", "numpy.squeeze", "data_train.astype.astype.astype", "label_train.astype.astype.astype", "data_val.astype.astype.astype", "label_val.astype.astype.astype"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files"], ["", "def", "_load_cv_data", "(", "self", ",", "list_files", ")", ":", "\n", "        ", "\"\"\"Load training and cross-validation sets.\"\"\"", "\n", "# Split files for training and validation sets", "\n", "val_files", "=", "np", ".", "array_split", "(", "list_files", ",", "self", ".", "n_folds", ")", "\n", "train_files", "=", "np", ".", "setdiff1d", "(", "list_files", ",", "val_files", "[", "self", ".", "fold_idx", "]", ")", "\n", "\n", "# Load a npz file", "\n", "print", "(", "\"Load training set:\"", ")", "\n", "data_train", ",", "label_train", "=", "self", ".", "_load_npz_list_files", "(", "train_files", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Load validation set:\"", ")", "\n", "data_val", ",", "label_val", "=", "self", ".", "_load_npz_list_files", "(", "val_files", "[", "self", ".", "fold_idx", "]", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "# Reshape the data to match the input of the model - conv2d", "\n", "data_train", "=", "np", ".", "squeeze", "(", "data_train", ")", "\n", "data_val", "=", "np", ".", "squeeze", "(", "data_val", ")", "\n", "data_train", "=", "data_train", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "\n", "data_val", "=", "data_val", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "\n", "\n", "# Casting", "\n", "data_train", "=", "data_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "label_train", "=", "label_train", ".", "astype", "(", "np", ".", "int32", ")", "\n", "data_val", "=", "data_val", ".", "astype", "(", "np", ".", "float32", ")", "\n", "label_val", "=", "label_val", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "return", "data_train", ",", "label_train", ",", "data_val", ",", "label_val", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.NonSeqDataLoader.load_train_data": [[72, 145], ["os.listdir", "enumerate", "npzfiles.sort", "enumerate", "list", "list.sort", "subject_files.sort", "print", "print", "data_loader.NonSeqDataLoader._load_npz_list_files", "print", "print", "data_loader.NonSeqDataLoader._load_npz_list_files", "print", "numpy.squeeze", "numpy.squeeze", "data_train.astype.astype.astype", "label_train.astype.astype.astype", "data_val.astype.astype.astype", "label_val.astype.astype.astype", "print", "deepsleep.sleep_stage.print_n_samples_each_class", "print", "print", "deepsleep.sleep_stage.print_n_samples_each_class", "print", "deepsleep.utils.get_balance_class_oversample", "print", "deepsleep.sleep_stage.print_n_samples_each_class", "print", "re.compile.match", "len", "enumerate", "npzfiles.append", "re.compile", "re.compile", "subject_files.append", "re.compile.match", "set", "set", "os.path.join", "os.path.join", "re.compile", "re.compile", "subject_files.append", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.sleep_stage.print_n_samples_each_class", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.sleep_stage.print_n_samples_each_class", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.get_balance_class_oversample", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.sleep_stage.print_n_samples_each_class"], ["", "def", "load_train_data", "(", "self", ",", "n_files", "=", "None", ")", ":", "\n", "# Remove non-mat files, and perform ascending sort", "\n", "        ", "allfiles", "=", "os", ".", "listdir", "(", "self", ".", "data_dir", ")", "\n", "npzfiles", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "\".npz\"", "in", "f", ":", "\n", "                ", "npzfiles", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "", "", "npzfiles", ".", "sort", "(", ")", "\n", "\n", "if", "n_files", "is", "not", "None", ":", "\n", "            ", "npzfiles", "=", "npzfiles", "[", ":", "n_files", "]", "\n", "\n", "", "subject_files", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "self", ".", "fold_idx", "<", "10", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*0{}[1-9]E0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "else", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*{}[1-9]E0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "if", "pattern", ".", "match", "(", "f", ")", ":", "\n", "                ", "subject_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "\n", "", "", "if", "len", "(", "subject_files", ")", "==", "0", ":", "\n", "            ", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "                ", "if", "self", ".", "fold_idx", "<", "10", ":", "\n", "                    ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*0{}[1-9]J0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "else", ":", "\n", "                    ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*{}[1-9]J0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "if", "pattern", ".", "match", "(", "f", ")", ":", "\n", "                    ", "subject_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "\n", "", "", "", "train_files", "=", "list", "(", "set", "(", "npzfiles", ")", "-", "set", "(", "subject_files", ")", ")", "\n", "train_files", ".", "sort", "(", ")", "\n", "subject_files", ".", "sort", "(", ")", "\n", "\n", "# Load training and validation sets", "\n", "print", "(", "\"\\n========== [Fold-{}] ==========\\n\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "print", "(", "\"Load training set:\"", ")", "\n", "data_train", ",", "label_train", "=", "self", ".", "_load_npz_list_files", "(", "npz_files", "=", "train_files", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Load validation set:\"", ")", "\n", "data_val", ",", "label_val", "=", "self", ".", "_load_npz_list_files", "(", "npz_files", "=", "subject_files", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "# Reshape the data to match the input of the model - conv2d", "\n", "data_train", "=", "np", ".", "squeeze", "(", "data_train", ")", "\n", "data_val", "=", "np", ".", "squeeze", "(", "data_val", ")", "\n", "data_train", "=", "data_train", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "\n", "data_val", "=", "data_val", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "\n", "\n", "# Casting", "\n", "data_train", "=", "data_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "label_train", "=", "label_train", ".", "astype", "(", "np", ".", "int32", ")", "\n", "data_val", "=", "data_val", ".", "astype", "(", "np", ".", "float32", ")", "\n", "label_val", "=", "label_val", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "print", "(", "\"Training set: {}, {}\"", ".", "format", "(", "data_train", ".", "shape", ",", "label_train", ".", "shape", ")", ")", "\n", "print_n_samples_each_class", "(", "label_train", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Validation set: {}, {}\"", ".", "format", "(", "data_val", ".", "shape", ",", "label_val", ".", "shape", ")", ")", "\n", "print_n_samples_each_class", "(", "label_val", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "# Use balanced-class, oversample training set", "\n", "x_train", ",", "y_train", "=", "get_balance_class_oversample", "(", "\n", "x", "=", "data_train", ",", "y", "=", "label_train", "\n", ")", "\n", "print", "(", "\"Oversampled training set: {}, {}\"", ".", "format", "(", "\n", "x_train", ".", "shape", ",", "y_train", ".", "shape", "\n", ")", ")", "\n", "print_n_samples_each_class", "(", "y_train", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "return", "x_train", ",", "y_train", ",", "data_val", ",", "label_val", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.NonSeqDataLoader.load_test_data": [[146, 179], ["os.listdir", "enumerate", "npzfiles.sort", "enumerate", "subject_files.sort", "print", "print", "data_loader.NonSeqDataLoader._load_npz_list_files", "numpy.squeeze", "data_val.astype.astype.astype", "label_val.astype.astype.astype", "re.compile.match", "npzfiles.append", "re.compile", "re.compile", "subject_files.append", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "# Remove non-mat files, and perform ascending sort", "\n", "        ", "allfiles", "=", "os", ".", "listdir", "(", "self", ".", "data_dir", ")", "\n", "npzfiles", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "\".npz\"", "in", "f", ":", "\n", "                ", "npzfiles", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "", "", "npzfiles", ".", "sort", "(", ")", "\n", "\n", "subject_files", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "self", ".", "fold_idx", "<", "10", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*0{}[1-9]E0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "else", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*{}[1-9]E0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "if", "pattern", ".", "match", "(", "f", ")", ":", "\n", "                ", "subject_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "", "", "subject_files", ".", "sort", "(", ")", "\n", "\n", "print", "(", "\"\\n========== [Fold-{}] ==========\\n\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "\n", "print", "(", "\"Load validation set:\"", ")", "\n", "data_val", ",", "label_val", "=", "self", ".", "_load_npz_list_files", "(", "subject_files", ")", "\n", "\n", "# Reshape the data to match the input of the model", "\n", "data_val", "=", "np", ".", "squeeze", "(", "data_val", ")", "\n", "data_val", "=", "data_val", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "\n", "\n", "# Casting", "\n", "data_val", "=", "data_val", ".", "astype", "(", "np", ".", "float32", ")", "\n", "label_val", "=", "label_val", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "return", "data_val", ",", "label_val", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader.__init__": [[183, 187], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "n_folds", ",", "fold_idx", ")", ":", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "n_folds", "=", "n_folds", "\n", "self", ".", "fold_idx", "=", "fold_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_file": [[188, 195], ["numpy.load"], "methods", ["None"], ["", "def", "_load_npz_file", "(", "self", ",", "npz_file", ")", ":", "\n", "        ", "\"\"\"Load data and labels from a npz file.\"\"\"", "\n", "with", "np", ".", "load", "(", "npz_file", ")", "as", "f", ":", "\n", "            ", "data", "=", "f", "[", "\"x\"", "]", "\n", "labels", "=", "f", "[", "\"y\"", "]", "\n", "sampling_rate", "=", "f", "[", "\"fs\"", "]", "\n", "", "return", "data", ",", "labels", ",", "sampling_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files": [[196, 224], ["print", "data_loader.SeqDataLoader._load_npz_file", "numpy.squeeze", "tmp_data.astype.astype.astype", "tmp_labels.astype.astype.astype", "data.append", "labels.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_file"], ["", "def", "_load_npz_list_files", "(", "self", ",", "npz_files", ")", ":", "\n", "        ", "\"\"\"Load data and labels from list of npz files.\"\"\"", "\n", "data", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "fs", "=", "None", "\n", "for", "npz_f", "in", "npz_files", ":", "\n", "            ", "print", "(", "\"Loading {} ...\"", ".", "format", "(", "npz_f", ")", ")", "\n", "tmp_data", ",", "tmp_labels", ",", "sampling_rate", "=", "self", ".", "_load_npz_file", "(", "npz_f", ")", "\n", "if", "fs", "is", "None", ":", "\n", "                ", "fs", "=", "sampling_rate", "\n", "", "elif", "fs", "!=", "sampling_rate", ":", "\n", "                ", "raise", "Exception", "(", "\"Found mismatch in sampling rate.\"", ")", "\n", "\n", "# Reshape the data to match the input of the model - conv2d", "\n", "", "tmp_data", "=", "np", ".", "squeeze", "(", "tmp_data", ")", "\n", "tmp_data", "=", "tmp_data", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "\n", "\n", "# # Reshape the data to match the input of the model - conv1d", "\n", "# tmp_data = tmp_data[:, :, np.newaxis]", "\n", "\n", "# Casting", "\n", "tmp_data", "=", "tmp_data", ".", "astype", "(", "np", ".", "float32", ")", "\n", "tmp_labels", "=", "tmp_labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "data", ".", "append", "(", "tmp_data", ")", "\n", "labels", ".", "append", "(", "tmp_labels", ")", "\n", "\n", "", "return", "data", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_cv_data": [[225, 240], ["numpy.array_split", "numpy.setdiff1d", "print", "data_loader.SeqDataLoader._load_npz_list_files", "print", "print", "data_loader.SeqDataLoader._load_npz_list_files", "print"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files"], ["", "def", "_load_cv_data", "(", "self", ",", "list_files", ")", ":", "\n", "        ", "\"\"\"Load sequence training and cross-validation sets.\"\"\"", "\n", "# Split files for training and validation sets", "\n", "val_files", "=", "np", ".", "array_split", "(", "list_files", ",", "self", ".", "n_folds", ")", "\n", "train_files", "=", "np", ".", "setdiff1d", "(", "list_files", ",", "val_files", "[", "self", ".", "fold_idx", "]", ")", "\n", "\n", "# Load a npz file", "\n", "print", "(", "\"Load training set:\"", ")", "\n", "data_train", ",", "label_train", "=", "self", ".", "_load_npz_list_files", "(", "train_files", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Load validation set:\"", ")", "\n", "data_val", ",", "label_val", "=", "self", ".", "_load_npz_list_files", "(", "val_files", "[", "self", ".", "fold_idx", "]", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "return", "data_train", ",", "label_train", ",", "data_val", ",", "label_val", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader.load_test_data": [[241, 260], ["os.listdir", "enumerate", "npzfiles.sort", "numpy.array_split", "print", "print", "data_loader.SeqDataLoader._load_npz_list_files", "npzfiles.append", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "# Remove non-mat files, and perform ascending sort", "\n", "        ", "allfiles", "=", "os", ".", "listdir", "(", "self", ".", "data_dir", ")", "\n", "npzfiles", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "\".npz\"", "in", "f", ":", "\n", "                ", "npzfiles", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "", "", "npzfiles", ".", "sort", "(", ")", "\n", "\n", "# Files for validation sets", "\n", "val_files", "=", "np", ".", "array_split", "(", "npzfiles", ",", "self", ".", "n_folds", ")", "\n", "val_files", "=", "val_files", "[", "self", ".", "fold_idx", "]", "\n", "\n", "print", "(", "\"\\n========== [Fold-{}] ==========\\n\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "\n", "print", "(", "\"Load validation set:\"", ")", "\n", "data_val", ",", "label_val", "=", "self", ".", "_load_npz_list_files", "(", "val_files", ")", "\n", "\n", "return", "data_val", ",", "label_val", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader.load_train_data": [[261, 313], ["os.listdir", "enumerate", "npzfiles.sort", "enumerate", "list", "list.sort", "subject_files.sort", "print", "print", "data_loader.SeqDataLoader._load_npz_list_files", "print", "print", "data_loader.SeqDataLoader._load_npz_list_files", "print", "print", "print", "deepsleep.sleep_stage.print_n_samples_each_class", "print", "print", "print", "deepsleep.sleep_stage.print_n_samples_each_class", "print", "re.compile.match", "print", "numpy.hstack", "print", "numpy.hstack", "npzfiles.append", "re.compile", "re.compile", "subject_files.append", "set", "set", "len", "len", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader._load_npz_list_files", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.sleep_stage.print_n_samples_each_class", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.sleep_stage.print_n_samples_each_class"], ["", "def", "load_train_data", "(", "self", ",", "n_files", "=", "None", ")", ":", "\n", "# Remove non-mat files, and perform ascending sort", "\n", "        ", "allfiles", "=", "os", ".", "listdir", "(", "self", ".", "data_dir", ")", "\n", "npzfiles", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "\".npz\"", "in", "f", ":", "\n", "                ", "npzfiles", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "", "", "npzfiles", ".", "sort", "(", ")", "\n", "\n", "if", "n_files", "is", "not", "None", ":", "\n", "            ", "npzfiles", "=", "npzfiles", "[", ":", "n_files", "]", "\n", "\n", "", "subject_files", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "self", ".", "fold_idx", "<", "10", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*0{}[1-9]E0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "else", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*{}[1-9]E0\\.npz$\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "if", "pattern", ".", "match", "(", "f", ")", ":", "\n", "                ", "subject_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "f", ")", ")", "\n", "\n", "", "", "train_files", "=", "list", "(", "set", "(", "npzfiles", ")", "-", "set", "(", "subject_files", ")", ")", "\n", "train_files", ".", "sort", "(", ")", "\n", "subject_files", ".", "sort", "(", ")", "\n", "\n", "# Load training and validation sets", "\n", "print", "(", "\"\\n========== [Fold-{}] ==========\\n\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "print", "(", "\"Load training set:\"", ")", "\n", "data_train", ",", "label_train", "=", "self", ".", "_load_npz_list_files", "(", "train_files", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Load validation set:\"", ")", "\n", "data_val", ",", "label_val", "=", "self", ".", "_load_npz_list_files", "(", "subject_files", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "print", "(", "\"Training set: n_subjects={}\"", ".", "format", "(", "len", "(", "data_train", ")", ")", ")", "\n", "n_train_examples", "=", "0", "\n", "for", "d", "in", "data_train", ":", "\n", "            ", "print", "(", "d", ".", "shape", ")", "\n", "n_train_examples", "+=", "d", ".", "shape", "[", "0", "]", "\n", "", "print", "(", "\"Number of examples = {}\"", ".", "format", "(", "n_train_examples", ")", ")", "\n", "print_n_samples_each_class", "(", "np", ".", "hstack", "(", "label_train", ")", ")", "\n", "print", "(", "\" \"", ")", "\n", "print", "(", "\"Validation set: n_subjects={}\"", ".", "format", "(", "len", "(", "data_val", ")", ")", ")", "\n", "n_valid_examples", "=", "0", "\n", "for", "d", "in", "data_val", ":", "\n", "            ", "print", "(", "d", ".", "shape", ")", "\n", "n_valid_examples", "+=", "d", ".", "shape", "[", "0", "]", "\n", "", "print", "(", "\"Number of examples = {}\"", ".", "format", "(", "n_valid_examples", ")", ")", "\n", "print_n_samples_each_class", "(", "np", ".", "hstack", "(", "label_val", ")", ")", "\n", "print", "(", "\" \"", ")", "\n", "\n", "return", "data_train", ",", "label_train", ",", "data_val", ",", "label_val", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader.load_subject_data": [[314, 372], ["os.listdir", "enumerate", "print", "data_loader.SeqDataLoader.load_subject_data.load_npz_list_files"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_subject_data", "(", "data_dir", ",", "subject_idx", ")", ":", "\n", "# Remove non-mat files, and perform ascending sort", "\n", "        ", "allfiles", "=", "os", ".", "listdir", "(", "data_dir", ")", "\n", "subject_files", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "allfiles", ")", ":", "\n", "            ", "if", "subject_idx", "<", "10", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*0{}[1-9]E0\\.npz$\"", ".", "format", "(", "subject_idx", ")", ")", "\n", "", "else", ":", "\n", "                ", "pattern", "=", "re", ".", "compile", "(", "\"[a-zA-Z0-9]*{}[1-9]E0\\.npz$\"", ".", "format", "(", "subject_idx", ")", ")", "\n", "", "if", "pattern", ".", "match", "(", "f", ")", ":", "\n", "                ", "subject_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f", ")", ")", "\n", "\n", "# Files for validation sets", "\n", "", "", "if", "len", "(", "subject_files", ")", "==", "0", "or", "len", "(", "subject_files", ")", ">", "2", ":", "\n", "            ", "raise", "Exception", "(", "\"Invalid file pattern\"", ")", "\n", "\n", "", "def", "load_npz_file", "(", "npz_file", ")", ":", "\n", "            ", "\"\"\"Load data and labels from a npz file.\"\"\"", "\n", "with", "np", ".", "load", "(", "npz_file", ")", "as", "f", ":", "\n", "                ", "data", "=", "f", "[", "\"x\"", "]", "\n", "labels", "=", "f", "[", "\"y\"", "]", "\n", "sampling_rate", "=", "f", "[", "\"fs\"", "]", "\n", "", "return", "data", ",", "labels", ",", "sampling_rate", "\n", "\n", "", "def", "load_npz_list_files", "(", "npz_files", ")", ":", "\n", "            ", "\"\"\"Load data and labels from list of npz files.\"\"\"", "\n", "data", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "fs", "=", "None", "\n", "for", "npz_f", "in", "npz_files", ":", "\n", "                ", "print", "(", "\"Loading {} ...\"", ".", "format", "(", "npz_f", ")", ")", "\n", "tmp_data", ",", "tmp_labels", ",", "sampling_rate", "=", "load_npz_file", "(", "npz_f", ")", "\n", "if", "fs", "is", "None", ":", "\n", "                    ", "fs", "=", "sampling_rate", "\n", "", "elif", "fs", "!=", "sampling_rate", ":", "\n", "                    ", "raise", "Exception", "(", "\"Found mismatch in sampling rate.\"", ")", "\n", "\n", "# Reshape the data to match the input of the model - conv2d", "\n", "", "tmp_data", "=", "np", ".", "squeeze", "(", "tmp_data", ")", "\n", "tmp_data", "=", "tmp_data", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "\n", "\n", "# # Reshape the data to match the input of the model - conv1d", "\n", "# tmp_data = tmp_data[:, :, np.newaxis]", "\n", "\n", "# Casting", "\n", "tmp_data", "=", "tmp_data", ".", "astype", "(", "np", ".", "float32", ")", "\n", "tmp_labels", "=", "tmp_labels", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "data", ".", "append", "(", "tmp_data", ")", "\n", "labels", ".", "append", "(", "tmp_labels", ")", "\n", "\n", "", "return", "data", ",", "labels", "\n", "\n", "", "print", "(", "\"Load data from: {}\"", ".", "format", "(", "subject_files", ")", ")", "\n", "data", ",", "labels", "=", "load_npz_list_files", "(", "subject_files", ")", "\n", "\n", "return", "data", ",", "labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.sleep_stage.print_n_samples_each_class": [[22, 28], ["np.unique", "len", "print", "np.where"], "function", ["None"], ["def", "print_n_samples_each_class", "(", "labels", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "unique_labels", "=", "np", ".", "unique", "(", "labels", ")", "\n", "for", "c", "in", "unique_labels", ":", "\n", "        ", "n_samples", "=", "len", "(", "np", ".", "where", "(", "labels", "==", "c", ")", "[", "0", "]", ")", "\n", "print", "(", "\"{}: {}\"", ".", "format", "(", "class_dict", "[", "c", "]", ",", "n_samples", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.__init__": [[29, 38], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "interval_plot_filter", "=", "50", ",", "\n", "interval_save_model", "=", "100", ",", "\n", "interval_print_cm", "=", "10", "\n", ")", ":", "\n", "        ", "self", ".", "interval_plot_filter", "=", "interval_plot_filter", "\n", "self", ".", "interval_save_model", "=", "interval_save_model", "\n", "self", ".", "interval_print_cm", "=", "interval_print_cm", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance": [[39, 88], ["tensorflow.add_n", "sess.run", "tensorflow.compat.v1.get_collection", "print", "print", "print", "print", "print", "print", "print", "print", "datetime.datetime.datetime.now"], "methods", ["None"], ["", "def", "print_performance", "(", "self", ",", "sess", ",", "output_dir", ",", "network_name", ",", "\n", "n_train_examples", ",", "n_valid_examples", ",", "\n", "train_cm", ",", "valid_cm", ",", "epoch", ",", "n_epochs", ",", "\n", "train_duration", ",", "train_loss", ",", "train_acc", ",", "train_f1", ",", "\n", "valid_duration", ",", "valid_loss", ",", "valid_acc", ",", "valid_f1", ")", ":", "\n", "# Get regularization loss", "\n", "        ", "train_reg_loss", "=", "tf", ".", "add_n", "(", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "\"losses\"", ",", "scope", "=", "network_name", "+", "\"\\/\"", ")", ")", "\n", "train_reg_loss_value", "=", "sess", ".", "run", "(", "train_reg_loss", ")", "\n", "valid_reg_loss_value", "=", "train_reg_loss_value", "\n", "\n", "# Print performance", "\n", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "interval_print_cm", "==", "0", ")", "or", "(", "(", "epoch", "+", "1", ")", "==", "n_epochs", ")", ":", "\n", "            ", "print", "(", "\" \"", ")", "\n", "print", "(", "\"[{}] epoch {}:\"", ".", "format", "(", "\n", "datetime", ".", "now", "(", ")", ",", "epoch", "+", "1", "\n", ")", ")", "\n", "print", "(", "(", "\n", "\"train ({:.3f} sec): n={}, loss={:.3f} ({:.3f}), acc={:.3f}, \"", "\n", "\"f1={:.3f}\"", ".", "format", "(", "\n", "train_duration", ",", "n_train_examples", ",", "\n", "train_loss", ",", "train_reg_loss_value", ",", "\n", "train_acc", ",", "train_f1", "\n", ")", "\n", ")", ")", "\n", "print", "(", "train_cm", ")", "\n", "print", "(", "(", "\n", "\"valid ({:.3f} sec): n={}, loss={:.3f} ({:.3f}), acc={:.3f}, \"", "\n", "\"f1={:.3f}\"", ".", "format", "(", "\n", "valid_duration", ",", "n_valid_examples", ",", "\n", "valid_loss", ",", "valid_reg_loss_value", ",", "\n", "valid_acc", ",", "valid_f1", "\n", ")", "\n", ")", ")", "\n", "print", "(", "valid_cm", ")", "\n", "print", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "(", "\n", "\"epoch {}: \"", "\n", "\"train ({:.2f} sec): n={}, loss={:.3f} ({:.3f}), \"", "\n", "\"acc={:.3f}, f1={:.3f} | \"", "\n", "\"valid ({:.2f} sec): n={}, loss={:.3f} ({:.3f}), \"", "\n", "\"acc={:.3f}, f1={:.3f}\"", ".", "format", "(", "\n", "epoch", "+", "1", ",", "\n", "train_duration", ",", "n_train_examples", ",", "\n", "train_loss", ",", "train_reg_loss_value", ",", "\n", "train_acc", ",", "train_f1", ",", "\n", "valid_duration", ",", "n_valid_examples", ",", "\n", "valid_loss", ",", "valid_reg_loss_value", ",", "\n", "valid_acc", ",", "valid_f1", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_network": [[91, 101], ["print", "print", "print", "print", "network.inputs.get_shape", "network.targets.get_shape", "act.get_shape"], "methods", ["None"], ["", "", "def", "print_network", "(", "self", ",", "network", ")", ":", "\n", "        ", "print", "(", "\"inputs ({}): {}\"", ".", "format", "(", "\n", "network", ".", "inputs", ".", "name", ",", "network", ".", "inputs", ".", "get_shape", "(", ")", "\n", ")", ")", "\n", "print", "(", "\"targets ({}): {}\"", ".", "format", "(", "\n", "network", ".", "targets", ".", "name", ",", "network", ".", "targets", ".", "get_shape", "(", ")", "\n", ")", ")", "\n", "for", "name", ",", "act", "in", "network", ".", "activations", ":", "\n", "            ", "print", "(", "\"{} ({}): {}\"", ".", "format", "(", "name", ",", "act", ".", "name", ",", "act", ".", "get_shape", "(", ")", ")", ")", "\n", "", "print", "(", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.plot_filters": [[102, 125], ["re.compile", "tensorflow.compat.v1.trainable_variables", "sess.run", "re.compile.match", "numpy.squeeze", "matplotlib.figure", "matplotlib.figure", "matplotlib.title", "matplotlib.title", "range", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.close", "matplotlib.close", "len", "matplotlib.subplot", "matplotlib.subplot", "matplotlib.plot", "matplotlib.plot", "matplotlib.axis", "matplotlib.axis", "os.path.join", "v.name.replace().replace", "v.name.replace"], "methods", ["None"], ["", "def", "plot_filters", "(", "self", ",", "sess", ",", "epoch", ",", "reg_exp", ",", "output_dir", ",", "n_viz_filters", ")", ":", "\n", "        ", "conv_weight", "=", "re", ".", "compile", "(", "reg_exp", ")", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "value", "=", "sess", ".", "run", "(", "v", ")", "\n", "if", "conv_weight", ".", "match", "(", "v", ".", "name", ")", ":", "\n", "                ", "weights", "=", "np", ".", "squeeze", "(", "value", ")", "\n", "# Only plot conv that has one channel", "\n", "if", "len", "(", "weights", ".", "shape", ")", ">", "2", ":", "\n", "                    ", "continue", "\n", "", "weights", "=", "weights", ".", "T", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "18", ",", "10", ")", ")", "\n", "plt", ".", "title", "(", "v", ".", "name", ")", "\n", "for", "w_idx", "in", "range", "(", "n_viz_filters", ")", ":", "\n", "                    ", "plt", ".", "subplot", "(", "4", ",", "4", ",", "w_idx", "+", "1", ")", "\n", "plt", ".", "plot", "(", "weights", "[", "w_idx", "]", ")", "\n", "plt", ".", "axis", "(", "\"tight\"", ")", "\n", "", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"{}_{}.png\"", ".", "format", "(", "\n", "v", ".", "name", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", ".", "replace", "(", "\":0\"", ",", "\"\"", ")", ",", "\n", "epoch", "+", "1", "\n", ")", "\n", ")", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepFeatureNetTrainer.__init__": [[129, 155], ["trainer.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_dir", ",", "\n", "output_dir", ",", "\n", "n_folds", ",", "\n", "fold_idx", ",", "\n", "batch_size", ",", "\n", "input_dims", ",", "\n", "n_classes", ",", "\n", "interval_plot_filter", "=", "50", ",", "\n", "interval_save_model", "=", "100", ",", "\n", "interval_print_cm", "=", "10", "\n", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "\n", "interval_plot_filter", "=", "interval_plot_filter", ",", "\n", "interval_save_model", "=", "interval_save_model", ",", "\n", "interval_print_cm", "=", "interval_print_cm", "\n", ")", "\n", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "output_dir", "=", "output_dir", "\n", "self", ".", "n_folds", "=", "n_folds", "\n", "self", ".", "fold_idx", "=", "fold_idx", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "input_dims", "=", "input_dims", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepFeatureNetTrainer._run_epoch": [[156, 215], ["time.time", "deepsleep.utils.iterate_minibatches", "numpy.hstack", "numpy.hstack", "sess.run", "y.append", "y_true.append", "time.time", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_minibatches"], ["", "def", "_run_epoch", "(", "self", ",", "sess", ",", "network", ",", "inputs", ",", "targets", ",", "train_op", ",", "is_train", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "y", "=", "[", "]", "\n", "y_true", "=", "[", "]", "\n", "total_loss", ",", "n_batches", "=", "0.0", ",", "0", "\n", "is_shuffle", "=", "True", "if", "is_train", "else", "False", "\n", "for", "x_batch", ",", "y_batch", "in", "iterate_minibatches", "(", "inputs", ",", "\n", "targets", ",", "\n", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "is_shuffle", ")", ":", "\n", "            ", "feed_dict", "=", "{", "\n", "network", ".", "input_var", ":", "x_batch", ",", "\n", "network", ".", "target_var", ":", "y_batch", "\n", "}", "\n", "\n", "# # MONITORING", "\n", "# if n_batches == 0:", "\n", "#     print \"BEFORE UPDATE [is_train={}]\".format(is_train)", "\n", "#     for n, v in network.monitor_vars[:2]:", "\n", "#         val = sess.run(v, feed_dict=feed_dict)", "\n", "#         val = np.transpose(val, axes=(3, 0, 1, 2)).reshape((64, -1))", "\n", "#         mean_val = np.mean(val, axis=1)", "\n", "#         var_val = np.var(val, axis=1)", "\n", "#         print \"{}: {}\\nmean_shape={}, mean_val={}\\nvar_shape={}, var_val={}\".format(", "\n", "#             n, val.shape, mean_val.shape, mean_val[:5], var_val.shape, var_val[:5]", "\n", "#         )", "\n", "\n", "_", ",", "loss_value", ",", "y_pred", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "network", ".", "loss_op", ",", "network", ".", "pred_op", "]", ",", "\n", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "# # MONITORING", "\n", "# if n_batches == 0:", "\n", "#     print \"AFTER UPDATE [is_train={}]\".format(is_train)", "\n", "#     for n, v in network.monitor_vars[:2]:", "\n", "#         val = sess.run(v, feed_dict=feed_dict)", "\n", "#         val = np.transpose(val, axes=(3, 0, 1, 2)).reshape((64, -1))", "\n", "#         mean_val = np.mean(val, axis=1)", "\n", "#         var_val = np.var(val, axis=1)", "\n", "#         print \"{}: {}\\nmean_shape={}, mean_val={}\\nvar_shape={}, var_val={}\".format(", "\n", "#             n, val.shape, mean_val.shape, mean_val[:5], var_val.shape, var_val[:5]", "\n", "#         )", "\n", "\n", "total_loss", "+=", "loss_value", "\n", "n_batches", "+=", "1", "\n", "y", ".", "append", "(", "y_pred", ")", "\n", "y_true", ".", "append", "(", "y_batch", ")", "\n", "\n", "# Check the loss value", "\n", "assert", "not", "np", ".", "isnan", "(", "loss_value", ")", ",", "\"Model diverged with loss = NaN\"", "\n", "\n", "", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_loss", "/=", "n_batches", "\n", "total_y_pred", "=", "np", ".", "hstack", "(", "y", ")", "\n", "total_y_true", "=", "np", ".", "hstack", "(", "y_true", ")", "\n", "\n", "return", "total_y_true", ",", "total_y_pred", ",", "total_loss", ",", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepFeatureNetTrainer.train": [[216, 443], ["print", "os.path.join", "tensorflow.Graph().as_default", "tensorflow.compat.v1.Session", "deepsleep.model.DeepFeatureNet", "deepsleep.model.DeepFeatureNet", "deepsleep.model.DeepFeatureNet.init_ops", "deepsleep.model.DeepFeatureNet.init_ops", "print", "print", "print", "print", "deepsleep.optimize.adam", "os.path.join", "tensorflow.compat.v1.train.Saver", "sess.run", "tensorflow.compat.v1.summary.FileWriter", "range", "print", "os.path.exists", "os.makedirs", "tensorflow.compat.v1.variable_scope", "tensorflow.Variable", "tensorflow.compat.v1.global_variables", "tensorflow.compat.v1.global_variables_initializer", "os.path.join", "os.path.exists", "print", "sess.run", "deepsleep.data_loader.NonSeqDataLoader", "deepsleep.data_loader.NonSeqDataLoader.load_train_data", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "sess.run", "trainer.DeepFeatureNetTrainer._run_epoch", "len", "sklearn.metrics.confusion_matrix", "numpy.mean", "sklearn.metrics.f1_score", "trainer.DeepFeatureNetTrainer._run_epoch", "len", "sklearn.metrics.confusion_matrix", "numpy.mean", "sklearn.metrics.f1_score", "trainer.DeepFeatureNetTrainer.print_performance", "numpy.savez", "sess.run", "tensorflow.Graph", "len", "deepsleep.model.DeepFeatureNet.input_var.get_shape", "deepsleep.model.DeepFeatureNet.target_var.get_shape", "tensorflow.compat.v1.trainable_variables", "os.path.isfile", "os.path.join", "trainer.DeepFeatureNetTrainer.plot_filters", "trainer.DeepFeatureNetTrainer.plot_filters", "tensorflow.compat.v1.assign", "time.time", "os.path.join", "tensorflow.compat.v1.train.Saver.save", "print", "time.time", "tensorflow.compat.v1.global_variables", "numpy.savez", "print", "act.get_shape", "os.path.join", "tensorflow.compat.v1.train.Saver.restore", "print", "print", "print", "datetime.datetime.datetime.now", "tensorflow.no_op", "numpy.asarray", "numpy.asarray", "time.time", "sess.run", "os.path.join", "time.time", "tensorflow.train.latest_checkpoint", "datetime.datetime.datetime.now", "datetime.datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.init_ops", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.init_ops", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.optimize.adam", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader.load_train_data", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer._run_epoch", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer._run_epoch", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.plot_filters", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.plot_filters"], ["", "def", "train", "(", "self", ",", "n_epochs", ",", "resume", ")", ":", "\n", "        ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "# Build training and validation networks", "\n", "            ", "train_net", "=", "DeepFeatureNet", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "input_dims", "=", "self", ".", "input_dims", ",", "\n", "n_classes", "=", "self", ".", "n_classes", ",", "\n", "is_train", "=", "True", ",", "\n", "reuse_params", "=", "False", ",", "\n", "use_dropout", "=", "True", "\n", ")", "\n", "valid_net", "=", "DeepFeatureNet", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "input_dims", "=", "self", ".", "input_dims", ",", "\n", "n_classes", "=", "self", ".", "n_classes", ",", "\n", "is_train", "=", "False", ",", "\n", "reuse_params", "=", "True", ",", "\n", "use_dropout", "=", "True", "\n", ")", "\n", "\n", "# Initialize parameters", "\n", "train_net", ".", "init_ops", "(", ")", "\n", "valid_net", ".", "init_ops", "(", ")", "\n", "\n", "print", "(", "\"Network (layers={})\"", ".", "format", "(", "len", "(", "train_net", ".", "activations", ")", ")", ")", "\n", "print", "(", "\"inputs ({}): {}\"", ".", "format", "(", "\n", "train_net", ".", "input_var", ".", "name", ",", "train_net", ".", "input_var", ".", "get_shape", "(", ")", "\n", ")", ")", "\n", "print", "(", "\"targets ({}): {}\"", ".", "format", "(", "\n", "train_net", ".", "target_var", ".", "name", ",", "train_net", ".", "target_var", ".", "get_shape", "(", ")", "\n", ")", ")", "\n", "for", "name", ",", "act", "in", "train_net", ".", "activations", ":", "\n", "                ", "print", "(", "\"{} ({}): {}\"", ".", "format", "(", "name", ",", "act", ".", "name", ",", "act", ".", "get_shape", "(", ")", ")", ")", "\n", "", "print", "(", "\" \"", ")", "\n", "\n", "# Define optimization operations", "\n", "train_op", ",", "grads_and_vars_op", "=", "adam", "(", "\n", "loss", "=", "train_net", ".", "loss_op", ",", "\n", "lr", "=", "1e-4", ",", "\n", "train_vars", "=", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", "\n", ")", "\n", "\n", "# Make subdirectory for pretraining", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "output_dir", ",", "\"fold{}\"", ".", "format", "(", "self", ".", "fold_idx", ")", ",", "train_net", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "# Global step for resume training", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "train_net", ".", "name", ")", "as", "scope", ":", "\n", "                ", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ")", "\n", "\n", "# print \"Trainable Variables:\"", "\n", "# for v in tf.compat.v1.trainable_variables():", "\n", "#     print v.name, v.get_shape()", "\n", "# print \" \"", "\n", "\n", "# print \"All Variables:\"", "\n", "# for v in tf.compat.v1.global_variables():", "\n", "#     print v.name, v.get_shape()", "\n", "# print \" \"", "\n", "\n", "# Create a saver", "\n", "", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", ",", "max_to_keep", "=", "0", ")", "\n", "\n", "# Initialize variables in the graph", "\n", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# Add the graph structure into the Tensorboard writer", "\n", "train_summary_wrt", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"train_summary\"", ")", ",", "\n", "sess", ".", "graph", "\n", ")", "\n", "\n", "# Resume the training if applicable", "\n", "if", "resume", ":", "\n", "                ", "if", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                    ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"checkpoint\"", ")", ")", ":", "\n", "# Restore the last checkpoint", "\n", "                        ", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "output_dir", ")", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "print", "(", "\"[{}] Resume pre-training ...\\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"[{}] Start pre-training ...\\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "print", "(", "\"[{}] Start pre-training ...\\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "\n", "# Load data", "\n", "", "if", "sess", ".", "run", "(", "global_step", ")", "<", "n_epochs", ":", "\n", "                ", "data_loader", "=", "NonSeqDataLoader", "(", "\n", "data_dir", "=", "self", ".", "data_dir", ",", "\n", "n_folds", "=", "self", ".", "n_folds", ",", "\n", "fold_idx", "=", "self", ".", "fold_idx", "\n", ")", "\n", "x_train", ",", "y_train", ",", "x_valid", ",", "y_valid", "=", "data_loader", ".", "load_train_data", "(", ")", "\n", "\n", "# Performance history", "\n", "all_train_loss", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_train_acc", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_train_f1", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_valid_loss", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_valid_acc", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_valid_f1", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "\n", "# Loop each epoch", "\n", "", "for", "epoch", "in", "range", "(", "sess", ".", "run", "(", "global_step", ")", ",", "n_epochs", ")", ":", "\n", "# # MONITORING", "\n", "# print \"BEFORE TRAINING\"", "\n", "# monitor_vars = [", "\n", "#     \"deepfeaturenet/l1_conv/bn/moving_mean:0\",", "\n", "#     \"deepfeaturenet/l1_conv/bn/moving_variance:0\"", "\n", "# ]", "\n", "# for n in monitor_vars:", "\n", "#     v = tf.compat.v1.get_default_graph().get_tensor_by_name(n)", "\n", "#     val = sess.run(v)", "\n", "#     print \"{}: {}, {}\".format(n, val.shape, val[:5])", "\n", "\n", "# Update parameters and compute loss of training set", "\n", "                ", "y_true_train", ",", "y_pred_train", ",", "train_loss", ",", "train_duration", "=", "self", ".", "_run_epoch", "(", "\n", "sess", "=", "sess", ",", "network", "=", "train_net", ",", "\n", "inputs", "=", "x_train", ",", "targets", "=", "y_train", ",", "\n", "train_op", "=", "train_op", ",", "\n", "is_train", "=", "True", "\n", ")", "\n", "n_train_examples", "=", "len", "(", "y_true_train", ")", "\n", "train_cm", "=", "confusion_matrix", "(", "y_true_train", ",", "y_pred_train", ")", "\n", "train_acc", "=", "np", ".", "mean", "(", "y_true_train", "==", "y_pred_train", ")", "\n", "train_f1", "=", "f1_score", "(", "y_true_train", ",", "y_pred_train", ",", "average", "=", "\"macro\"", ")", "\n", "\n", "# # MONITORING", "\n", "# print \"AFTER TRAINING and BEFORE VALID\"", "\n", "# for n in monitor_vars:", "\n", "#     v = tf.compat.v1.get_default_graph().get_tensor_by_name(n)", "\n", "#     val = sess.run(v)", "\n", "#     print \"{}: {}, {}\".format(n, val.shape, val[:5])", "\n", "\n", "# Evaluate the model on the validation set", "\n", "y_true_val", ",", "y_pred_val", ",", "valid_loss", ",", "valid_duration", "=", "self", ".", "_run_epoch", "(", "\n", "sess", "=", "sess", ",", "network", "=", "valid_net", ",", "\n", "inputs", "=", "x_valid", ",", "targets", "=", "y_valid", ",", "\n", "train_op", "=", "tf", ".", "no_op", "(", ")", ",", "\n", "is_train", "=", "False", "\n", ")", "\n", "n_valid_examples", "=", "len", "(", "y_true_val", ")", "\n", "valid_cm", "=", "confusion_matrix", "(", "y_true_val", ",", "y_pred_val", ")", "\n", "valid_acc", "=", "np", ".", "mean", "(", "y_true_val", "==", "y_pred_val", ")", "\n", "valid_f1", "=", "f1_score", "(", "y_true_val", ",", "y_pred_val", ",", "average", "=", "\"macro\"", ")", "\n", "\n", "# db.train_log(args={", "\n", "#     \"n_folds\": self.n_folds,", "\n", "#     \"fold_idx\": self.fold_idx,", "\n", "#     \"epoch\": epoch,", "\n", "#     \"train_step\": \"pretraining\",", "\n", "#     \"datetime\": datetime.utcnow(),", "\n", "#     \"model\": train_net.name,", "\n", "#     \"n_train_examples\": n_train_examples,", "\n", "#     \"n_valid_examples\": n_valid_examples,", "\n", "#     \"train_loss\": train_loss,", "\n", "#     \"train_acc\": train_acc,", "\n", "#     \"train_f1\": train_f1,", "\n", "#     \"train_duration\": train_duration,", "\n", "#     \"valid_loss\": valid_loss,", "\n", "#     \"valid_acc\": valid_acc,", "\n", "#     \"valid_f1\": valid_f1,", "\n", "#     \"valid_duration\": valid_duration,", "\n", "# })", "\n", "\n", "all_train_loss", "[", "epoch", "]", "=", "train_loss", "\n", "all_train_acc", "[", "epoch", "]", "=", "train_acc", "\n", "all_train_f1", "[", "epoch", "]", "=", "train_f1", "\n", "all_valid_loss", "[", "epoch", "]", "=", "valid_loss", "\n", "all_valid_acc", "[", "epoch", "]", "=", "valid_acc", "\n", "all_valid_f1", "[", "epoch", "]", "=", "valid_f1", "\n", "\n", "# Report performance", "\n", "self", ".", "print_performance", "(", "\n", "sess", ",", "output_dir", ",", "train_net", ".", "name", ",", "\n", "n_train_examples", ",", "n_valid_examples", ",", "\n", "train_cm", ",", "valid_cm", ",", "epoch", ",", "n_epochs", ",", "\n", "train_duration", ",", "train_loss", ",", "train_acc", ",", "train_f1", ",", "\n", "valid_duration", ",", "valid_loss", ",", "valid_acc", ",", "valid_f1", "\n", ")", "\n", "\n", "# Save performance history", "\n", "np", ".", "savez", "(", "\n", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"perf_fold{}.npz\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", ",", "\n", "train_loss", "=", "all_train_loss", ",", "valid_loss", "=", "all_valid_loss", ",", "\n", "train_acc", "=", "all_train_acc", ",", "valid_acc", "=", "all_valid_acc", ",", "\n", "train_f1", "=", "all_train_f1", ",", "valid_f1", "=", "all_valid_f1", ",", "\n", "y_true_val", "=", "np", ".", "asarray", "(", "y_true_val", ")", ",", "\n", "y_pred_val", "=", "np", ".", "asarray", "(", "y_pred_val", ")", "\n", ")", "\n", "\n", "# Visualize weights from convolutional layers", "\n", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "interval_plot_filter", "==", "0", ")", "or", "(", "(", "epoch", "+", "1", ")", "==", "n_epochs", ")", ":", "\n", "                    ", "self", ".", "plot_filters", "(", "sess", ",", "epoch", ",", "train_net", ".", "name", "+", "\"(_[0-9])?\\/l[0-9]+_conv\\/(weights)\"", ",", "output_dir", ",", "16", ")", "\n", "self", ".", "plot_filters", "(", "sess", ",", "epoch", ",", "train_net", ".", "name", "+", "\"(_[0-9])?/l[0-9]+_conv\\/conv1d\\/(weights)\"", ",", "output_dir", ",", "16", ")", "\n", "\n", "# Save checkpoint", "\n", "", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "assign", "(", "global_step", ",", "epoch", "+", "1", ")", ")", "\n", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "interval_save_model", "==", "0", ")", "or", "(", "(", "epoch", "+", "1", ")", "==", "n_epochs", ")", ":", "\n", "                    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"model_fold{}.ckpt\"", ".", "format", "(", "self", ".", "fold_idx", ")", "\n", ")", "\n", "saver", ".", "save", "(", "sess", ",", "save_path", ",", "global_step", "=", "global_step", ")", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "\"Saved model checkpoint ({:.3f} sec)\"", ".", "format", "(", "duration", ")", ")", "\n", "\n", "# Save paramaters", "\n", "", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "interval_save_model", "==", "0", ")", "or", "(", "(", "epoch", "+", "1", ")", "==", "n_epochs", ")", ":", "\n", "                    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "save_dict", "=", "{", "}", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", ":", "\n", "                        ", "save_dict", "[", "v", ".", "name", "]", "=", "sess", ".", "run", "(", "v", ")", "\n", "", "np", ".", "savez", "(", "\n", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\n", "\"params_fold{}.npz\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", ",", "\n", "**", "save_dict", "\n", ")", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "\"Saved trained parameters ({:.3f} sec)\"", ".", "format", "(", "duration", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"Finish pre-training\"", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"params_fold{}.npz\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer.__init__": [[447, 479], ["trainer.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_dir", ",", "\n", "output_dir", ",", "\n", "n_folds", ",", "\n", "fold_idx", ",", "\n", "batch_size", ",", "\n", "input_dims", ",", "\n", "n_classes", ",", "\n", "seq_length", ",", "\n", "n_rnn_layers", ",", "\n", "return_last", ",", "\n", "interval_plot_filter", "=", "50", ",", "\n", "interval_save_model", "=", "100", ",", "\n", "interval_print_cm", "=", "10", "\n", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "\n", "interval_plot_filter", "=", "interval_plot_filter", ",", "\n", "interval_save_model", "=", "interval_save_model", ",", "\n", "interval_print_cm", "=", "interval_print_cm", "\n", ")", "\n", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "output_dir", "=", "output_dir", "\n", "self", ".", "n_folds", "=", "n_folds", "\n", "self", ".", "fold_idx", "=", "fold_idx", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "input_dims", "=", "input_dims", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "seq_length", "=", "seq_length", "\n", "self", ".", "n_rnn_layers", "=", "n_rnn_layers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer._run_epoch": [[480, 542], ["time.time", "enumerate", "numpy.hstack", "numpy.hstack", "zip", "sess.run", "sess.run", "deepsleep.utils.iterate_batch_seq_minibatches", "time.time", "enumerate", "enumerate", "sess.run", "y.append", "y_true.append", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_batch_seq_minibatches"], ["", "def", "_run_epoch", "(", "self", ",", "sess", ",", "network", ",", "inputs", ",", "targets", ",", "train_op", ",", "is_train", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "y", "=", "[", "]", "\n", "y_true", "=", "[", "]", "\n", "total_loss", ",", "n_batches", "=", "0.0", ",", "0", "\n", "for", "sub_idx", ",", "each_data", "in", "enumerate", "(", "zip", "(", "inputs", ",", "targets", ")", ")", ":", "\n", "            ", "each_x", ",", "each_y", "=", "each_data", "\n", "\n", "# # Initialize state of LSTM - Unidirectional LSTM", "\n", "# state = sess.run(network.initial_state)", "\n", "\n", "# Initialize state of LSTM - Bidirectional LSTM", "\n", "fw_state", "=", "sess", ".", "run", "(", "network", ".", "fw_initial_state", ")", "\n", "bw_state", "=", "sess", ".", "run", "(", "network", ".", "bw_initial_state", ")", "\n", "\n", "for", "x_batch", ",", "y_batch", "in", "iterate_batch_seq_minibatches", "(", "inputs", "=", "each_x", ",", "\n", "targets", "=", "each_y", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "seq_length", "=", "self", ".", "seq_length", ")", ":", "\n", "                ", "feed_dict", "=", "{", "\n", "network", ".", "input_var", ":", "x_batch", ",", "\n", "network", ".", "target_var", ":", "y_batch", "\n", "}", "\n", "\n", "# Unidirectional LSTM", "\n", "# for i, (c, h) in enumerate(network.initial_state):", "\n", "#     feed_dict[c] = state[i].c", "\n", "#     feed_dict[h] = state[i].h", "\n", "\n", "# _, loss_value, y_pred, state = sess.run(", "\n", "#     [train_op, network.loss_op, network.pred_op, network.final_state],", "\n", "#     feed_dict=feed_dict", "\n", "# )", "\n", "\n", "for", "i", ",", "(", "c", ",", "h", ")", "in", "enumerate", "(", "network", ".", "fw_initial_state", ")", ":", "\n", "                    ", "feed_dict", "[", "c", "]", "=", "fw_state", "[", "i", "]", ".", "c", "\n", "feed_dict", "[", "h", "]", "=", "fw_state", "[", "i", "]", ".", "h", "\n", "\n", "", "for", "i", ",", "(", "c", ",", "h", ")", "in", "enumerate", "(", "network", ".", "bw_initial_state", ")", ":", "\n", "                    ", "feed_dict", "[", "c", "]", "=", "bw_state", "[", "i", "]", ".", "c", "\n", "feed_dict", "[", "h", "]", "=", "bw_state", "[", "i", "]", ".", "h", "\n", "\n", "", "_", ",", "loss_value", ",", "y_pred", ",", "fw_state", ",", "bw_state", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "network", ".", "loss_op", ",", "network", ".", "pred_op", ",", "network", ".", "fw_final_state", ",", "network", ".", "bw_final_state", "]", ",", "\n", "feed_dict", "=", "feed_dict", "\n", ")", "\n", "\n", "total_loss", "+=", "loss_value", "\n", "n_batches", "+=", "1", "\n", "y", ".", "append", "(", "y_pred", ")", "\n", "y_true", ".", "append", "(", "y_batch", ")", "\n", "\n", "# Check the loss value", "\n", "assert", "not", "np", ".", "isnan", "(", "loss_value", ")", ",", "\"Model diverged with loss = NaN\"", "\n", "\n", "", "", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_loss", "/=", "n_batches", "\n", "total_y_pred", "=", "np", ".", "hstack", "(", "y", ")", "\n", "total_y_true", "=", "np", ".", "hstack", "(", "y_true", ")", "\n", "\n", "return", "total_y_true", ",", "total_y_pred", ",", "total_loss", ",", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer.finetune": [[543, 810], ["print", "os.path.join", "tensorflow.Graph().as_default", "tensorflow.compat.v1.Session", "deepsleep.model.DeepSleepNet", "deepsleep.model.DeepSleepNet", "deepsleep.model.DeepSleepNet.init_ops", "deepsleep.model.DeepSleepNet.init_ops", "print", "print", "print", "print", "range", "list", "deepsleep.optimize.adam_clipping_list_lr", "os.path.join", "tensorflow.compat.v1.train.Saver", "sess.run", "tensorflow.compat.v1.summary.FileWriter", "range", "print", "numpy.load", "list", "len", "pretrain_params[].replace", "os.path.exists", "os.makedirs", "tensorflow.compat.v1.variable_scope", "tensorflow.Variable", "tensorflow.compat.v1.global_variables", "tensorflow.compat.v1.global_variables_initializer", "os.path.join", "os.path.exists", "print", "print", "print", "print", "sess.run", "deepsleep.data_loader.SeqDataLoader", "deepsleep.data_loader.SeqDataLoader.load_train_data", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "sess.run", "trainer.DeepSleepNetTrainer._run_epoch", "len", "sklearn.metrics.confusion_matrix", "numpy.mean", "sklearn.metrics.f1_score", "trainer.DeepSleepNetTrainer._run_epoch", "len", "sklearn.metrics.confusion_matrix", "numpy.mean", "sklearn.metrics.f1_score", "trainer.DeepSleepNetTrainer.print_performance", "numpy.savez", "sess.run", "tensorflow.Graph", "len", "deepsleep.model.DeepSleepNet.input_var.get_shape", "deepsleep.model.DeepSleepNet.target_var.get_shape", "f.keys", "tensorflow.compat.v1.trainable_variables", "set", "set", "os.path.isfile", "numpy.load", "f.items", "os.path.join", "trainer.DeepSleepNetTrainer.plot_filters", "trainer.DeepSleepNetTrainer.plot_filters", "tensorflow.compat.v1.assign", "time.time", "os.path.join", "tensorflow.compat.v1.train.Saver.save", "print", "time.time", "tensorflow.compat.v1.global_variables", "numpy.savez", "print", "act.get_shape", "v.name.replace", "tensorflow.compat.v1.trainable_variables", "os.path.join", "tensorflow.compat.v1.train.Saver.restore", "print", "print", "k.replace.replace.replace", "tensorflow.compat.v1.get_default_graph().get_tensor_by_name", "sess.run", "print", "datetime.datetime.datetime.now", "tensorflow.no_op", "numpy.asarray", "numpy.asarray", "time.time", "sess.run", "os.path.join", "time.time", "tensorflow.train.latest_checkpoint", "tensorflow.compat.v1.assign", "datetime.datetime.datetime.now", "tensorflow.compat.v1.get_default_graph", "tensorflow.compat.v1.get_default_graph().get_tensor_by_name.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.init_ops", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.init_ops", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.optimize.adam_clipping_list_lr", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.data_loader.SeqDataLoader.load_train_data", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer._run_epoch", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.DeepSleepNetTrainer._run_epoch", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.print_performance", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.plot_filters", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.trainer.Trainer.plot_filters"], ["", "def", "finetune", "(", "self", ",", "pretrained_model_path", ",", "n_epochs", ",", "resume", ")", ":", "\n", "        ", "pretrained_model_name", "=", "\"deepfeaturenet\"", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "as", "sess", ":", "\n", "# Build training and validation networks", "\n", "            ", "train_net", "=", "DeepSleepNet", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "input_dims", "=", "self", ".", "input_dims", ",", "\n", "n_classes", "=", "self", ".", "n_classes", ",", "\n", "seq_length", "=", "self", ".", "seq_length", ",", "\n", "n_rnn_layers", "=", "self", ".", "n_rnn_layers", ",", "\n", "return_last", "=", "self", ".", "return_last", ",", "\n", "is_train", "=", "True", ",", "\n", "reuse_params", "=", "False", ",", "\n", "use_dropout_feature", "=", "True", ",", "\n", "use_dropout_sequence", "=", "True", "\n", ")", "\n", "valid_net", "=", "DeepSleepNet", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "input_dims", "=", "self", ".", "input_dims", ",", "\n", "n_classes", "=", "self", ".", "n_classes", ",", "\n", "seq_length", "=", "self", ".", "seq_length", ",", "\n", "n_rnn_layers", "=", "self", ".", "n_rnn_layers", ",", "\n", "return_last", "=", "self", ".", "return_last", ",", "\n", "is_train", "=", "False", ",", "\n", "reuse_params", "=", "True", ",", "\n", "use_dropout_feature", "=", "True", ",", "\n", "use_dropout_sequence", "=", "True", "\n", ")", "\n", "\n", "# Initialize parameters", "\n", "train_net", ".", "init_ops", "(", ")", "\n", "valid_net", ".", "init_ops", "(", ")", "\n", "\n", "print", "(", "\"Network (layers={})\"", ".", "format", "(", "len", "(", "train_net", ".", "activations", ")", ")", ")", "\n", "print", "(", "\"inputs ({}): {}\"", ".", "format", "(", "\n", "train_net", ".", "input_var", ".", "name", ",", "train_net", ".", "input_var", ".", "get_shape", "(", ")", "\n", ")", ")", "\n", "print", "(", "\"targets ({}): {}\"", ".", "format", "(", "\n", "train_net", ".", "target_var", ".", "name", ",", "train_net", ".", "target_var", ".", "get_shape", "(", ")", "\n", ")", ")", "\n", "for", "name", ",", "act", "in", "train_net", ".", "activations", ":", "\n", "                ", "print", "(", "\"{} ({}): {}\"", ".", "format", "(", "name", ",", "act", ".", "name", ",", "act", ".", "get_shape", "(", ")", ")", ")", "\n", "", "print", "(", "\" \"", ")", "\n", "\n", "# Get list of all pretrained parameters", "\n", "with", "np", ".", "load", "(", "pretrained_model_path", ")", "as", "f", ":", "\n", "                ", "pretrain_params", "=", "list", "(", "f", ".", "keys", "(", ")", ")", "\n", "\n", "# Remove the network-name-prefix", "\n", "", "for", "i", "in", "range", "(", "len", "(", "pretrain_params", ")", ")", ":", "\n", "                ", "pretrain_params", "[", "i", "]", "=", "pretrain_params", "[", "i", "]", ".", "replace", "(", "pretrained_model_name", ",", "\"network\"", ")", "\n", "\n", "# Get trainable variables of the pretrained, and new ones", "\n", "", "train_vars1", "=", "[", "v", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", "\n", "if", "v", ".", "name", ".", "replace", "(", "train_net", ".", "name", ",", "\"network\"", ")", "in", "pretrain_params", "]", "\n", "train_vars2", "=", "list", "(", "set", "(", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ")", "-", "set", "(", "train_vars1", ")", ")", "\n", "\n", "# Optimizer that use different learning rates for each part of the network", "\n", "train_op", ",", "grads_and_vars_op", "=", "adam_clipping_list_lr", "(", "\n", "loss", "=", "train_net", ".", "loss_op", ",", "\n", "list_lrs", "=", "[", "1e-6", ",", "1e-4", "]", ",", "\n", "list_train_vars", "=", "[", "train_vars1", ",", "train_vars2", "]", ",", "\n", "clip_value", "=", "10.0", "\n", ")", "\n", "\n", "# Make subdirectory for pretraining", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "output_dir", ",", "\"fold{}\"", ".", "format", "(", "self", ".", "fold_idx", ")", ",", "train_net", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "# Global step for resume training", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "train_net", ".", "name", ")", "as", "scope", ":", "\n", "                ", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ")", "\n", "\n", "# print \"Pretrained parameters:\"", "\n", "# for v in train_vars1:", "\n", "#     print v.name", "\n", "# print \" \"", "\n", "\n", "# print \"Optimizing parameters:\"", "\n", "# for v in train_vars2:", "\n", "#     print v.name", "\n", "# print \" \"", "\n", "\n", "# print \"Trainable Variables:\"", "\n", "# for v in tf.compat.v1.trainable_variables():", "\n", "#     print v.name, v.get_shape()", "\n", "# print \" \"", "\n", "\n", "# print \"All Variables:\"", "\n", "# for v in tf.compat.v1.global_variables():", "\n", "#     print v.name, v.get_shape()", "\n", "# print \" \"", "\n", "\n", "# Create a saver", "\n", "", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", ",", "max_to_keep", "=", "0", ")", "\n", "\n", "# Initialize variables in the graph", "\n", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# Add the graph structure into the Tensorboard writer", "\n", "train_summary_wrt", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriter", "(", "\n", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"train_summary\"", ")", ",", "\n", "sess", ".", "graph", "\n", ")", "\n", "\n", "# Resume the training if applicable", "\n", "load_pretrain", "=", "False", "\n", "if", "resume", ":", "\n", "                ", "if", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                    ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"checkpoint\"", ")", ")", ":", "\n", "# Restore the last checkpoint", "\n", "                        ", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "output_dir", ")", ")", "\n", "print", "(", "\"Model restored\"", ")", "\n", "print", "(", "\"[{}] Resume fine-tuning ...\\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "                        ", "load_pretrain", "=", "True", "\n", "", "", "", "else", ":", "\n", "                ", "load_pretrain", "=", "True", "\n", "\n", "", "if", "load_pretrain", ":", "\n", "# Load pre-trained model", "\n", "                ", "print", "(", "\"Loading pre-trained parameters to the model ...\"", ")", "\n", "print", "(", "\" | --> {} from {}\"", ".", "format", "(", "pretrained_model_name", ",", "pretrained_model_path", ")", ")", "\n", "with", "np", ".", "load", "(", "pretrained_model_path", ")", "as", "f", ":", "\n", "                    ", "for", "k", ",", "v", "in", "f", ".", "items", "(", ")", ":", "\n", "                        ", "if", "\"Adam\"", "in", "k", "or", "\"softmax\"", "in", "k", "or", "\"power\"", "in", "k", "or", "\"global_step\"", "in", "k", ":", "\n", "                            ", "continue", "\n", "", "prev_k", "=", "k", "\n", "k", "=", "k", ".", "replace", "(", "pretrained_model_name", ",", "train_net", ".", "name", ")", "\n", "tmp_tensor", "=", "tf", ".", "compat", ".", "v1", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "k", ")", "\n", "sess", ".", "run", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "assign", "(", "\n", "tmp_tensor", ",", "\n", "v", "\n", ")", "\n", ")", "\n", "print", "(", "\"assigned {}: {} to {}: {}\"", ".", "format", "(", "\n", "prev_k", ",", "v", ".", "shape", ",", "k", ",", "tmp_tensor", ".", "get_shape", "(", ")", "\n", ")", ")", "\n", "", "", "print", "(", "\" \"", ")", "\n", "print", "(", "\"[{}] Start fine-tuning ...\\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "\n", "# Load data", "\n", "", "if", "sess", ".", "run", "(", "global_step", ")", "<", "n_epochs", ":", "\n", "                ", "data_loader", "=", "SeqDataLoader", "(", "\n", "data_dir", "=", "self", ".", "data_dir", ",", "\n", "n_folds", "=", "self", ".", "n_folds", ",", "\n", "fold_idx", "=", "self", ".", "fold_idx", "\n", ")", "\n", "x_train", ",", "y_train", ",", "x_valid", ",", "y_valid", "=", "data_loader", ".", "load_train_data", "(", ")", "\n", "\n", "# Performance history", "\n", "all_train_loss", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_train_acc", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_train_f1", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_valid_loss", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_valid_acc", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "all_valid_f1", "=", "np", ".", "zeros", "(", "n_epochs", ")", "\n", "\n", "# Loop each epoch", "\n", "", "for", "epoch", "in", "range", "(", "sess", ".", "run", "(", "global_step", ")", ",", "n_epochs", ")", ":", "\n", "# Update parameters and compute loss of training set", "\n", "                ", "y_true_train", ",", "y_pred_train", ",", "train_loss", ",", "train_duration", "=", "self", ".", "_run_epoch", "(", "\n", "sess", "=", "sess", ",", "network", "=", "train_net", ",", "\n", "inputs", "=", "x_train", ",", "targets", "=", "y_train", ",", "\n", "train_op", "=", "train_op", ",", "\n", "is_train", "=", "True", "\n", ")", "\n", "n_train_examples", "=", "len", "(", "y_true_train", ")", "\n", "train_cm", "=", "confusion_matrix", "(", "y_true_train", ",", "y_pred_train", ")", "\n", "train_acc", "=", "np", ".", "mean", "(", "y_true_train", "==", "y_pred_train", ")", "\n", "train_f1", "=", "f1_score", "(", "y_true_train", ",", "y_pred_train", ",", "average", "=", "\"macro\"", ")", "\n", "\n", "# Evaluate the model on the validation set", "\n", "y_true_val", ",", "y_pred_val", ",", "valid_loss", ",", "valid_duration", "=", "self", ".", "_run_epoch", "(", "\n", "sess", "=", "sess", ",", "network", "=", "valid_net", ",", "\n", "inputs", "=", "x_valid", ",", "targets", "=", "y_valid", ",", "\n", "train_op", "=", "tf", ".", "no_op", "(", ")", ",", "\n", "is_train", "=", "False", "\n", ")", "\n", "n_valid_examples", "=", "len", "(", "y_true_val", ")", "\n", "valid_cm", "=", "confusion_matrix", "(", "y_true_val", ",", "y_pred_val", ")", "\n", "valid_acc", "=", "np", ".", "mean", "(", "y_true_val", "==", "y_pred_val", ")", "\n", "valid_f1", "=", "f1_score", "(", "y_true_val", ",", "y_pred_val", ",", "average", "=", "\"macro\"", ")", "\n", "\n", "all_train_loss", "[", "epoch", "]", "=", "train_loss", "\n", "all_train_acc", "[", "epoch", "]", "=", "train_acc", "\n", "all_train_f1", "[", "epoch", "]", "=", "train_f1", "\n", "all_valid_loss", "[", "epoch", "]", "=", "valid_loss", "\n", "all_valid_acc", "[", "epoch", "]", "=", "valid_acc", "\n", "all_valid_f1", "[", "epoch", "]", "=", "valid_f1", "\n", "\n", "# db.train_log(args={", "\n", "#     \"n_folds\": self.n_folds,", "\n", "#     \"fold_idx\": self.fold_idx,", "\n", "#     \"epoch\": epoch,", "\n", "#     \"train_step\": \"finetuning\",", "\n", "#     \"datetime\": datetime.utcnow(),", "\n", "#     \"model\": train_net.name,", "\n", "#     \"n_train_examples\": n_train_examples,", "\n", "#     \"n_valid_examples\": n_valid_examples,", "\n", "#     \"train_loss\": train_loss,", "\n", "#     \"train_acc\": train_acc,", "\n", "#     \"train_f1\": train_f1,", "\n", "#     \"train_duration\": train_duration,", "\n", "#     \"valid_loss\": valid_loss,", "\n", "#     \"valid_acc\": valid_acc,", "\n", "#     \"valid_f1\": valid_f1,", "\n", "#     \"valid_duration\": valid_duration,", "\n", "# })", "\n", "\n", "# Report performance", "\n", "self", ".", "print_performance", "(", "\n", "sess", ",", "output_dir", ",", "train_net", ".", "name", ",", "\n", "n_train_examples", ",", "n_valid_examples", ",", "\n", "train_cm", ",", "valid_cm", ",", "epoch", ",", "n_epochs", ",", "\n", "train_duration", ",", "train_loss", ",", "train_acc", ",", "train_f1", ",", "\n", "valid_duration", ",", "valid_loss", ",", "valid_acc", ",", "valid_f1", "\n", ")", "\n", "\n", "# Save performance history", "\n", "np", ".", "savez", "(", "\n", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"perf_fold{}.npz\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", ",", "\n", "train_loss", "=", "all_train_loss", ",", "valid_loss", "=", "all_valid_loss", ",", "\n", "train_acc", "=", "all_train_acc", ",", "valid_acc", "=", "all_valid_acc", ",", "\n", "train_f1", "=", "all_train_f1", ",", "valid_f1", "=", "all_valid_f1", ",", "\n", "y_true_val", "=", "np", ".", "asarray", "(", "y_true_val", ")", ",", "\n", "y_pred_val", "=", "np", ".", "asarray", "(", "y_pred_val", ")", "\n", ")", "\n", "\n", "# Visualize weights from convolutional layers", "\n", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "interval_plot_filter", "==", "0", ")", "or", "(", "(", "epoch", "+", "1", ")", "==", "n_epochs", ")", ":", "\n", "                    ", "self", ".", "plot_filters", "(", "sess", ",", "epoch", ",", "train_net", ".", "name", "+", "\"(_[0-9])?\\/l[0-9]+_conv\\/(weights)\"", ",", "output_dir", ",", "16", ")", "\n", "self", ".", "plot_filters", "(", "sess", ",", "epoch", ",", "train_net", ".", "name", "+", "\"(_[0-9])?/l[0-9]+_conv\\/conv1d\\/(weights)\"", ",", "output_dir", ",", "16", ")", "\n", "\n", "# Save checkpoint", "\n", "", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "assign", "(", "global_step", ",", "epoch", "+", "1", ")", ")", "\n", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "interval_save_model", "==", "0", ")", "or", "(", "(", "epoch", "+", "1", ")", "==", "n_epochs", ")", ":", "\n", "                    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"model_fold{}.ckpt\"", ".", "format", "(", "self", ".", "fold_idx", ")", "\n", ")", "\n", "saver", ".", "save", "(", "sess", ",", "save_path", ",", "global_step", "=", "global_step", ")", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "\"Saved model checkpoint ({:.3f} sec)\"", ".", "format", "(", "duration", ")", ")", "\n", "\n", "# Save paramaters", "\n", "", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "interval_save_model", "==", "0", ")", "or", "(", "(", "epoch", "+", "1", ")", "==", "n_epochs", ")", ":", "\n", "                    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "save_dict", "=", "{", "}", "\n", "for", "v", "in", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", ":", "\n", "                        ", "save_dict", "[", "v", ".", "name", "]", "=", "sess", ".", "run", "(", "v", ")", "\n", "", "np", ".", "savez", "(", "\n", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\n", "\"params_fold{}.npz\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", ",", "\n", "**", "save_dict", "\n", ")", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "\"Saved trained parameters ({:.3f} sec)\"", ".", "format", "(", "duration", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"Finish fine-tuning\"", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"params_fold{}.npz\"", ".", "format", "(", "self", ".", "fold_idx", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.loss.softmax_cross_entrophy_loss": [[4, 12], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean"], "function", ["None"], ["def", "softmax_cross_entrophy_loss", "(", "logits", ",", "targets", ")", ":", "\n", "    ", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "targets", ",", "\n", "name", "=", "\"cross_entropy_per_example\"", "\n", ")", "\n", "cross_entropy_mean", "=", "tf", ".", "reduce_mean", "(", "cross_entropy", ",", "name", "=", "\"cross_entropy\"", ")", "\n", "return", "cross_entropy_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.loss.softmax_seq_loss_by_example": [[14, 21], ["tensorflow.nn.seq2seq.sequence_loss_by_example", "tensorflow.reduce_sum", "tensorflow.ones"], "function", ["None"], ["", "def", "softmax_seq_loss_by_example", "(", "logits", ",", "targets", ",", "batch_size", ",", "seq_length", ")", ":", "\n", "    ", "loss", "=", "tf", ".", "nn", ".", "seq2seq", ".", "sequence_loss_by_example", "(", "\n", "[", "logits", "]", ",", "\n", "[", "targets", "]", ",", "\n", "[", "tf", ".", "ones", "(", "[", "batch_size", "*", "seq_length", "]", ")", "]", ")", "\n", "seq_cross_entropy_mean", "=", "tf", ".", "reduce_sum", "(", "loss", ")", "/", "batch_size", "\n", "return", "seq_cross_entropy_mean", "\n", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn._create_variable": [[8, 11], ["tensorflow.compat.v1.get_variable"], "function", ["None"], ["def", "_create_variable", "(", "name", ",", "shape", ",", "initializer", ")", ":", "\n", "    ", "var", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", ",", "shape", ",", "initializer", "=", "initializer", ")", "\n", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.variable_with_weight_decay": [[13, 47], ["numpy.sqrt", "tensorflow.truncated_normal_initializer", "nn._create_variable", "len", "tensorflow.multiply", "tensorflow.compat.v1.add_to_collection", "len", "numpy.prod", "numpy.sqrt", "numpy.sqrt", "tensorflow.nn.l2_loss", "numpy.prod", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn._create_variable"], ["", "def", "variable_with_weight_decay", "(", "name", ",", "shape", ",", "wd", "=", "None", ")", ":", "\n", "# Get the number of input and output parameters", "\n", "    ", "if", "len", "(", "shape", ")", "==", "2", ":", "\n", "        ", "fan_in", "=", "shape", "[", "0", "]", "\n", "fan_out", "=", "shape", "[", "1", "]", "\n", "", "elif", "len", "(", "shape", ")", "==", "4", ":", "\n", "        ", "receptive_field_size", "=", "np", ".", "prod", "(", "shape", "[", ":", "2", "]", ")", "\n", "fan_in", "=", "shape", "[", "-", "2", "]", "*", "receptive_field_size", "\n", "fan_out", "=", "shape", "[", "-", "1", "]", "*", "receptive_field_size", "\n", "", "else", ":", "\n", "# no specific assumptions", "\n", "        ", "fan_in", "=", "np", ".", "sqrt", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "fan_out", "=", "np", ".", "sqrt", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "\n", "# He et al. 2015 - http://arxiv.org/abs/1502.01852", "\n", "", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "fan_in", ")", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "stddev", ")", "\n", "\n", "# # Xavier", "\n", "# initializer = tf.contrib.layers.xavier_initializer()", "\n", "\n", "# Create or get the existing variable", "\n", "var", "=", "_create_variable", "(", "\n", "name", ",", "\n", "shape", ",", "\n", "initializer", "\n", ")", "\n", "\n", "# L2 weight decay", "\n", "if", "wd", "is", "not", "None", ":", "\n", "        ", "weight_decay", "=", "tf", ".", "multiply", "(", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", ",", "wd", ",", "name", "=", "\"weight_loss\"", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "add_to_collection", "(", "\"losses\"", ",", "weight_decay", ")", "\n", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.conv_1d": [[49, 77], ["tensorflow.compat.v1.variable_scope", "nn.variable_with_weight_decay", "tensorflow.nn.conv2d", "nn._create_variable", "tensorflow.nn.bias_add", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.variable_with_weight_decay", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn._create_variable"], ["", "def", "conv_1d", "(", "name", ",", "input_var", ",", "filter_shape", ",", "stride", ",", "padding", "=", "\"SAME\"", ",", "\n", "bias", "=", "None", ",", "wd", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "# Trainable parameters", "\n", "        ", "kernel", "=", "variable_with_weight_decay", "(", "\n", "\"weights\"", ",", "\n", "shape", "=", "filter_shape", ",", "\n", "wd", "=", "wd", "\n", ")", "\n", "\n", "# Convolution", "\n", "output_var", "=", "tf", ".", "nn", ".", "conv2d", "(", "\n", "input_var", ",", "\n", "kernel", ",", "\n", "[", "1", ",", "stride", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "padding", "\n", ")", "\n", "\n", "# Bias", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "biases", "=", "_create_variable", "(", "\n", "\"biases\"", ",", "\n", "[", "filter_shape", "[", "-", "1", "]", "]", ",", "\n", "tf", ".", "constant_initializer", "(", "bias", ")", "\n", ")", "\n", "output_var", "=", "tf", ".", "nn", ".", "bias_add", "(", "output_var", ",", "biases", ")", "\n", "\n", "", "return", "output_var", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.max_pool_1d": [[79, 89], ["tensorflow.nn.max_pool2d"], "function", ["None"], ["", "", "def", "max_pool_1d", "(", "name", ",", "input_var", ",", "pool_size", ",", "stride", ",", "padding", "=", "\"SAME\"", ")", ":", "\n", "    ", "output_var", "=", "tf", ".", "nn", ".", "max_pool2d", "(", "\n", "input_var", ",", "\n", "ksize", "=", "[", "1", ",", "pool_size", ",", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "stride", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "padding", ",", "\n", "name", "=", "name", "\n", ")", "\n", "\n", "return", "output_var", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.avg_pool_1d": [[91, 101], ["tensorflow.nn.avg_pool"], "function", ["None"], ["", "def", "avg_pool_1d", "(", "name", ",", "input_var", ",", "pool_size", ",", "stride", ",", "padding", "=", "\"SAME\"", ")", ":", "\n", "    ", "output_var", "=", "tf", ".", "nn", ".", "avg_pool", "(", "\n", "input_var", ",", "\n", "ksize", "=", "[", "1", ",", "pool_size", ",", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "stride", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "padding", ",", "\n", "name", "=", "name", "\n", ")", "\n", "\n", "return", "output_var", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.fc": [[103, 128], ["tensorflow.compat.v1.variable_scope", "nn.variable_with_weight_decay", "tensorflow.matmul", "nn._create_variable", "tensorflow.add", "input_var.get_shape", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.variable_with_weight_decay", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn._create_variable"], ["", "def", "fc", "(", "name", ",", "input_var", ",", "n_hiddens", ",", "bias", "=", "None", ",", "wd", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "# Get input dimension", "\n", "        ", "input_dim", "=", "input_var", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "\n", "# Trainable parameters", "\n", "weights", "=", "variable_with_weight_decay", "(", "\n", "\"weights\"", ",", "\n", "shape", "=", "[", "input_dim", ",", "n_hiddens", "]", ",", "\n", "wd", "=", "wd", "\n", ")", "\n", "\n", "# Multiply weights", "\n", "output_var", "=", "tf", ".", "matmul", "(", "input_var", ",", "weights", ")", "\n", "\n", "# Bias", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "biases", "=", "_create_variable", "(", "\n", "\"biases\"", ",", "\n", "[", "n_hiddens", "]", ",", "\n", "tf", ".", "constant_initializer", "(", "bias", ")", "\n", ")", "\n", "output_var", "=", "tf", ".", "add", "(", "output_var", ",", "biases", ")", "\n", "\n", "", "return", "output_var", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.leaky_relu": [[130, 135], ["tensorflow.maximum"], "function", ["None"], ["", "", "def", "leaky_relu", "(", "name", ",", "input_var", ",", "alpha", "=", "0.01", ")", ":", "\n", "    ", "return", "tf", ".", "maximum", "(", "\n", "input_var", ",", "\n", "alpha", "*", "input_var", ",", "\n", "name", "=", "\"leaky_relu\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.batch_norm": [[138, 177], ["input_var.get_shape", "list", "range", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.nn.moments", "tensorflow.train.ExponentialMovingAverage", "tensorflow.cond", "tensorflow.nn.batch_normalization", "tf.train.ExponentialMovingAverage.apply", "len", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.identity", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.activation.identity", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.activation.identity"], ["", "def", "batch_norm", "(", "name", ",", "input_var", ",", "is_train", ",", "decay", "=", "0.999", ",", "epsilon", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"Batch normalization on fully-connected or convolutional maps.\n    Source: <http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow>\n    \"\"\"", "\n", "\n", "inputs_shape", "=", "input_var", ".", "get_shape", "(", ")", "\n", "axis", "=", "list", "(", "range", "(", "len", "(", "inputs_shape", ")", "-", "1", ")", ")", "\n", "params_shape", "=", "inputs_shape", "[", "-", "1", ":", "]", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "      ", "beta", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "\"beta\"", ",", "shape", "=", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "gamma", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "\"gamma\"", ",", "shape", "=", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ")", "\n", "batch_mean", ",", "batch_var", "=", "tf", ".", "nn", ".", "moments", "(", "input_var", ",", "\n", "axis", ",", "\n", "name", "=", "\"moments\"", ")", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "decay", ")", "\n", "\n", "def", "mean_var_with_update", "(", ")", ":", "\n", "          ", "ema_apply_op", "=", "ema", ".", "apply", "(", "[", "batch_mean", ",", "batch_var", "]", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "ema_apply_op", "]", ")", ":", "\n", "              ", "return", "tf", ".", "identity", "(", "batch_mean", ")", ",", "tf", ".", "identity", "(", "batch_var", ")", "\n", "\n", "", "", "mean", ",", "var", "=", "tf", ".", "cond", "(", "\n", "is_train", ",", "\n", "mean_var_with_update", ",", "\n", "lambda", ":", "(", "ema", ".", "average", "(", "batch_mean", ")", ",", "ema", ".", "average", "(", "batch_var", ")", ")", "\n", ")", "\n", "normed", "=", "tf", ".", "nn", ".", "batch_normalization", "(", "\n", "x", "=", "input_var", ",", "\n", "mean", "=", "mean", ",", "\n", "variance", "=", "var", ",", "\n", "offset", "=", "beta", ",", "\n", "scale", "=", "gamma", ",", "\n", "variance_epsilon", "=", "epsilon", ",", "\n", "name", "=", "\"tf_bn\"", "\n", ")", "\n", "", "return", "normed", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.batch_norm_new": [[179, 236], ["input_var.get_shape", "list", "range", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.nn.moments", "tensorflow.python.training.moving_averages.assign_moving_average", "tensorflow.python.training.moving_averages.assign_moving_average", "nn.batch_norm.mean_var_with_update"], "function", ["None"], ["", "def", "batch_norm_new", "(", "name", ",", "input_var", ",", "is_train", ",", "decay", "=", "0.999", ",", "epsilon", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"Batch normalization modified from BatchNormLayer in Tensorlayer.\n    Source: <https://github.com/zsdonghao/tensorlayer/blob/master/tensorlayer/layers.py#L2190>\n    \"\"\"", "\n", "\n", "inputs_shape", "=", "input_var", ".", "get_shape", "(", ")", "\n", "axis", "=", "list", "(", "range", "(", "len", "(", "inputs_shape", ")", "-", "1", ")", ")", "\n", "params_shape", "=", "inputs_shape", "[", "-", "1", ":", "]", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "# Trainable beta and gamma variables", "\n", "        ", "beta", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'beta'", ",", "\n", "shape", "=", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "gamma", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'gamma'", ",", "\n", "shape", "=", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "1.0", ",", "stddev", "=", "0.002", ")", ")", "\n", "\n", "# Moving mean and variance updated during training", "\n", "moving_mean", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'moving_mean'", ",", "\n", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "moving_variance", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'moving_variance'", ",", "\n", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "\n", "# Compute mean and variance along axis", "\n", "batch_mean", ",", "batch_variance", "=", "tf", ".", "nn", ".", "moments", "(", "input_var", ",", "axis", ",", "name", "=", "'moments'", ")", "\n", "\n", "# Define ops to update moving_mean and moving_variance", "\n", "update_moving_mean", "=", "moving_averages", ".", "assign_moving_average", "(", "moving_mean", ",", "batch_mean", ",", "decay", ",", "zero_debias", "=", "False", ")", "\n", "update_moving_variance", "=", "moving_averages", ".", "assign_moving_average", "(", "moving_variance", ",", "batch_variance", ",", "decay", ",", "zero_debias", "=", "False", ")", "\n", "\n", "# Define a function that :", "\n", "# 1. Update moving_mean & moving_variance with batch_mean & batch_variance", "\n", "# 2. Then return the batch_mean & batch_variance", "\n", "def", "mean_var_with_update", "(", ")", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "update_moving_mean", ",", "update_moving_variance", "]", ")", ":", "\n", "                ", "return", "tf", ".", "identity", "(", "batch_mean", ")", ",", "tf", ".", "identity", "(", "batch_variance", ")", "\n", "\n", "# Perform different ops for training and testing", "\n", "", "", "if", "is_train", ":", "\n", "            ", "mean", ",", "variance", "=", "mean_var_with_update", "(", ")", "\n", "normed", "=", "tf", ".", "nn", ".", "batch_normalization", "(", "input_var", ",", "mean", ",", "variance", ",", "beta", ",", "gamma", ",", "epsilon", ")", "\n", "\n", "", "else", ":", "\n", "            ", "normed", "=", "tf", ".", "nn", ".", "batch_normalization", "(", "input_var", ",", "moving_mean", ",", "moving_variance", ",", "beta", ",", "gamma", ",", "epsilon", ")", "\n", "# mean, variance = tf.cond(", "\n", "#     is_train,", "\n", "#     mean_var_with_update, # Training", "\n", "#     lambda: (moving_mean, moving_variance) # Testing - it will use the moving_mean and moving_variance (fixed during test) that are computed during training", "\n", "# )", "\n", "# normed = tf.nn.batch_normalization(input_var, mean, variance, beta, gamma, epsilon)", "\n", "\n", "", "return", "normed", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten": [[238, 247], ["[].as_list", "tensorflow.reshape", "input_var.get_shape"], "function", ["None"], ["", "", "def", "flatten", "(", "name", ",", "input_var", ")", ":", "\n", "    ", "dim", "=", "1", "\n", "for", "d", "in", "input_var", ".", "get_shape", "(", ")", "[", "1", ":", "]", ".", "as_list", "(", ")", ":", "\n", "        ", "dim", "*=", "d", "\n", "", "output_var", "=", "tf", ".", "reshape", "(", "input_var", ",", "\n", "shape", "=", "[", "-", "1", ",", "dim", "]", ",", "\n", "name", "=", "name", ")", "\n", "\n", "return", "output_var", "\n", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet.__init__": [[7, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "batch_size", ",", "\n", "input_dims", ",", "\n", "n_classes", ",", "\n", "is_train", ",", "\n", "reuse_params", ",", "\n", "use_dropout", ",", "\n", "name", "=", "\"deepfeaturenet\"", "\n", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "input_dims", "=", "input_dims", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "reuse_params", "=", "reuse_params", "\n", "self", ".", "use_dropout", "=", "use_dropout", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "activations", "=", "[", "]", "\n", "self", ".", "layer_idx", "=", "1", "\n", "self", ".", "monitor_vars", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._build_placeholder": [[29, 42], ["tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder"], "methods", ["None"], ["", "def", "_build_placeholder", "(", "self", ")", ":", "\n", "# Input", "\n", "        ", "name", "=", "\"x_train\"", "if", "self", ".", "is_train", "else", "\"x_valid\"", "\n", "self", ".", "input_var", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "self", ".", "batch_size", ",", "self", ".", "input_dims", ",", "1", ",", "1", "]", ",", "\n", "name", "=", "name", "+", "\"_inputs\"", "\n", ")", "\n", "# Target", "\n", "self", ".", "target_var", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "\n", "shape", "=", "[", "self", ".", "batch_size", ",", "]", ",", "\n", "name", "=", "name", "+", "\"_targets\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer": [[44, 66], ["input_var.get_shape", "model.DeepFeatureNet.activations.append", "tensorflow.compat.v1.variable_scope", "conv_1d", "batch_norm_new", "tensorflow.nn.relu"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.conv_1d", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.batch_norm_new"], ["", "def", "_conv1d_layer", "(", "self", ",", "input_var", ",", "filter_size", ",", "n_filters", ",", "stride", ",", "wd", "=", "0", ")", ":", "\n", "        ", "input_shape", "=", "input_var", ".", "get_shape", "(", ")", "\n", "n_batches", "=", "input_shape", "[", "0", "]", ".", "value", "\n", "input_dims", "=", "input_shape", "[", "1", "]", ".", "value", "\n", "n_in_filters", "=", "input_shape", "[", "3", "]", ".", "value", "\n", "name", "=", "\"l{}_conv\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "            ", "output", "=", "conv_1d", "(", "name", "=", "\"conv1d\"", ",", "input_var", "=", "input_var", ",", "filter_shape", "=", "[", "filter_size", ",", "1", ",", "n_in_filters", ",", "n_filters", "]", ",", "stride", "=", "stride", ",", "bias", "=", "None", ",", "wd", "=", "wd", ")", "\n", "\n", "# # MONITORING", "\n", "# self.monitor_vars.append((\"{}_before_bn\".format(name), output))", "\n", "\n", "output", "=", "batch_norm_new", "(", "name", "=", "\"bn\"", ",", "input_var", "=", "output", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "\n", "# # MONITORING", "\n", "# self.monitor_vars.append((\"{}_after_bn\".format(name), output))", "\n", "\n", "# output = leaky_relu(name=\"leaky_relu\", input_var=output)", "\n", "output", "=", "tf", ".", "nn", ".", "relu", "(", "output", ",", "name", "=", "\"relu\"", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "output", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet.build_model": [[67, 172], ["model.DeepFeatureNet._conv1d_layer", "max_pool_1d", "model.DeepFeatureNet.activations.append", "model.DeepFeatureNet._conv1d_layer", "model.DeepFeatureNet._conv1d_layer", "model.DeepFeatureNet._conv1d_layer", "max_pool_1d", "model.DeepFeatureNet.activations.append", "flatten", "model.DeepFeatureNet.activations.append", "output_conns.append", "model.DeepFeatureNet._conv1d_layer", "max_pool_1d", "model.DeepFeatureNet.activations.append", "model.DeepFeatureNet._conv1d_layer", "model.DeepFeatureNet._conv1d_layer", "model.DeepFeatureNet._conv1d_layer", "max_pool_1d", "model.DeepFeatureNet.activations.append", "flatten", "model.DeepFeatureNet.activations.append", "output_conns.append", "tensorflow.concat", "model.DeepFeatureNet.activations.append", "model.DeepFeatureNet.activations.append", "model.DeepFeatureNet.activations.append", "model.DeepFeatureNet.activations.append", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.max_pool_1d", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.max_pool_1d", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.max_pool_1d", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet._conv1d_layer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.max_pool_1d", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.flatten"], ["", "def", "build_model", "(", "self", ",", "input_var", ")", ":", "\n", "# List to store the output of each CNNs", "\n", "        ", "output_conns", "=", "[", "]", "\n", "\n", "######### CNNs with small filter size at the first layer #########", "\n", "\n", "# Convolution", "\n", "# network = self._conv1d_layer(input_var=input_var, filter_size=128, n_filters=64, stride=16, wd=1e-3)", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "input_var", ",", "filter_size", "=", "50", ",", "n_filters", "=", "64", ",", "stride", "=", "6", ",", "wd", "=", "1e-3", ")", "\n", "\n", "# Max pooling", "\n", "name", "=", "\"l{}_pool\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "max_pool_1d", "(", "name", "=", "name", ",", "input_var", "=", "network", ",", "pool_size", "=", "8", ",", "stride", "=", "8", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Dropout", "\n", "if", "self", ".", "use_dropout", ":", "\n", "            ", "name", "=", "\"l{}_dropout\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "if", "self", ".", "is_train", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "0.5", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "1.0", ",", "name", "=", "name", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Convolution", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "network", ",", "filter_size", "=", "8", ",", "n_filters", "=", "128", ",", "stride", "=", "1", ")", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "network", ",", "filter_size", "=", "8", ",", "n_filters", "=", "128", ",", "stride", "=", "1", ")", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "network", ",", "filter_size", "=", "8", ",", "n_filters", "=", "128", ",", "stride", "=", "1", ")", "\n", "\n", "# Max pooling", "\n", "name", "=", "\"l{}_pool\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "max_pool_1d", "(", "name", "=", "name", ",", "input_var", "=", "network", ",", "pool_size", "=", "4", ",", "stride", "=", "4", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Flatten", "\n", "name", "=", "\"l{}_flat\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "flatten", "(", "name", "=", "name", ",", "input_var", "=", "network", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "output_conns", ".", "append", "(", "network", ")", "\n", "\n", "######### CNNs with large filter size at the first layer #########", "\n", "\n", "# Convolution", "\n", "# network = self._conv1d_layer(input_var=input_var, filter_size=1024, n_filters=64, stride=128)", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "input_var", ",", "filter_size", "=", "400", ",", "n_filters", "=", "64", ",", "stride", "=", "50", ")", "\n", "\n", "# Max pooling", "\n", "name", "=", "\"l{}_pool\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "max_pool_1d", "(", "name", "=", "name", ",", "input_var", "=", "network", ",", "pool_size", "=", "4", ",", "stride", "=", "4", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Dropout", "\n", "if", "self", ".", "use_dropout", ":", "\n", "            ", "name", "=", "\"l{}_dropout\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "if", "self", ".", "is_train", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "0.5", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "1.0", ",", "name", "=", "name", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Convolution", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "network", ",", "filter_size", "=", "6", ",", "n_filters", "=", "128", ",", "stride", "=", "1", ")", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "network", ",", "filter_size", "=", "6", ",", "n_filters", "=", "128", ",", "stride", "=", "1", ")", "\n", "network", "=", "self", ".", "_conv1d_layer", "(", "input_var", "=", "network", ",", "filter_size", "=", "6", ",", "n_filters", "=", "128", ",", "stride", "=", "1", ")", "\n", "\n", "# Max pooling", "\n", "name", "=", "\"l{}_pool\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "max_pool_1d", "(", "name", "=", "name", ",", "input_var", "=", "network", ",", "pool_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Flatten", "\n", "name", "=", "\"l{}_flat\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "flatten", "(", "name", "=", "name", ",", "input_var", "=", "network", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "output_conns", ".", "append", "(", "network", ")", "\n", "\n", "######### Aggregate and link two CNNs #########", "\n", "\n", "# Concat", "\n", "name", "=", "\"l{}_concat\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "output_conns", ",", "name", "=", "name", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Dropout", "\n", "if", "self", ".", "use_dropout", ":", "\n", "            ", "name", "=", "\"l{}_dropout\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "if", "self", ".", "is_train", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "0.5", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "1.0", ",", "name", "=", "name", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepFeatureNet.init_ops": [[173, 222], ["model.DeepFeatureNet._build_placeholder", "tensorflow.compat.v1.variable_scope", "model.DeepFeatureNet.build_model", "fc", "model.DeepFeatureNet.activations.append", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.add_n", "tensorflow.add", "tensorflow.argmax", "scope.reuse_variables", "tensorflow.compat.v1.get_collection"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet._build_placeholder", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.build_model", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.fc"], ["", "def", "init_ops", "(", "self", ")", ":", "\n", "        ", "self", ".", "_build_placeholder", "(", ")", "\n", "\n", "# Get loss and prediction operations", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", "as", "scope", ":", "\n", "\n", "# Reuse variables for validation", "\n", "            ", "if", "self", ".", "reuse_params", ":", "\n", "                ", "scope", ".", "reuse_variables", "(", ")", "\n", "\n", "# Build model", "\n", "", "network", "=", "self", ".", "build_model", "(", "input_var", "=", "self", ".", "input_var", ")", "\n", "\n", "# Softmax linear", "\n", "name", "=", "\"l{}_softmax_linear\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "fc", "(", "name", "=", "name", ",", "input_var", "=", "network", ",", "n_hiddens", "=", "self", ".", "n_classes", ",", "bias", "=", "0.0", ",", "wd", "=", "0", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Outputs of softmax linear are logits", "\n", "self", ".", "logits", "=", "network", "\n", "\n", "######### Compute loss #########", "\n", "\n", "# Cross-entropy loss", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "self", ".", "logits", ",", "\n", "labels", "=", "self", ".", "target_var", ",", "\n", "name", "=", "\"sparse_softmax_cross_entropy_with_logits\"", "\n", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ",", "name", "=", "\"cross_entropy\"", ")", "\n", "\n", "# Regularization loss", "\n", "regular_loss", "=", "tf", ".", "add_n", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "\"losses\"", ",", "scope", "=", "scope", ".", "name", "+", "\"\\/\"", ")", ",", "\n", "name", "=", "\"regular_loss\"", "\n", ")", "\n", "\n", "# print \" \"", "\n", "# print \"Params to compute regularization loss:\"", "\n", "# for p in tf.compat.v1.get_collection(\"losses\", scope=scope.name + \"\\/\"):", "\n", "#     print p.name", "\n", "# print \" \"", "\n", "\n", "# Total loss", "\n", "self", ".", "loss_op", "=", "tf", ".", "add", "(", "loss", ",", "regular_loss", ")", "\n", "\n", "# Predictions", "\n", "self", ".", "pred_op", "=", "tf", ".", "argmax", "(", "self", ".", "logits", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.__init__": [[226, 255], ["model.DeepFeatureNet.__init__"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "batch_size", ",", "\n", "input_dims", ",", "\n", "n_classes", ",", "\n", "seq_length", ",", "\n", "n_rnn_layers", ",", "\n", "return_last", ",", "\n", "is_train", ",", "\n", "reuse_params", ",", "\n", "use_dropout_feature", ",", "\n", "use_dropout_sequence", ",", "\n", "name", "=", "\"deepsleepnet\"", "\n", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "\n", "batch_size", "=", "batch_size", ",", "\n", "input_dims", "=", "input_dims", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "is_train", "=", "is_train", ",", "\n", "reuse_params", "=", "reuse_params", ",", "\n", "use_dropout", "=", "use_dropout_feature", ",", "\n", "name", "=", "name", "\n", ")", "\n", "\n", "self", ".", "seq_length", "=", "seq_length", "\n", "self", ".", "n_rnn_layers", "=", "n_rnn_layers", "\n", "self", ".", "return_last", "=", "return_last", "\n", "\n", "self", ".", "use_dropout_sequence", "=", "use_dropout_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet._build_placeholder": [[256, 269], ["tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder"], "methods", ["None"], ["", "def", "_build_placeholder", "(", "self", ")", ":", "\n", "# Input", "\n", "        ", "name", "=", "\"x_train\"", "if", "self", ".", "is_train", "else", "\"x_valid\"", "\n", "self", ".", "input_var", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "self", ".", "batch_size", "*", "self", ".", "seq_length", ",", "self", ".", "input_dims", ",", "1", ",", "1", "]", ",", "\n", "name", "=", "name", "+", "\"_inputs\"", "\n", ")", "\n", "# Target", "\n", "self", ".", "target_var", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "\n", "tf", ".", "int32", ",", "\n", "shape", "=", "[", "self", ".", "batch_size", "*", "self", ".", "seq_length", ",", "]", ",", "\n", "name", "=", "name", "+", "\"_targets\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.build_model": [[271, 375], ["model.DeepFeatureNet.build_model", "model.DeepSleepNet.activations.append", "output_conns.append", "tensorflow.reshape", "model.DeepSleepNet.activations.append", "output_conns.append", "tensorflow.add_n", "model.DeepSleepNet.activations.append", "tensorflow.compat.v1.variable_scope", "fc", "batch_norm_new", "tensorflow.nn.relu", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell.zero_state", "tensorflow.unstack", "tensorflow.compat.v1.nn.static_bidirectional_rnn", "model.DeepSleepNet.activations.append", "model.DeepSleepNet.activations.append", "tensorflow.nn.dropout.get_shape", "tensorflow.compat.v1.nn.rnn_cell.LSTMCell", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.reshape.get_shape", "tensorflow.compat.v1.nn.rnn_cell.DropoutWrapper", "model.DeepSleepNet.build_model.lstm_cell"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.build_model", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.fc", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.batch_norm_new"], ["", "def", "build_model", "(", "self", ",", "input_var", ")", ":", "\n", "# Create a network with superclass method", "\n", "        ", "network", "=", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "build_model", "(", "\n", "input_var", "=", "self", ".", "input_var", "\n", ")", "\n", "\n", "# Residual (or shortcut) connection", "\n", "output_conns", "=", "[", "]", "\n", "\n", "# Fully-connected to select some part of the output to add with the output from bi-directional LSTM", "\n", "name", "=", "\"l{}_fc\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "            ", "output_tmp", "=", "fc", "(", "name", "=", "\"fc\"", ",", "input_var", "=", "network", ",", "n_hiddens", "=", "1024", ",", "bias", "=", "None", ",", "wd", "=", "0", ")", "\n", "output_tmp", "=", "batch_norm_new", "(", "name", "=", "\"bn\"", ",", "input_var", "=", "output_tmp", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "# output_tmp = leaky_relu(name=\"leaky_relu\", input_var=output_tmp)", "\n", "output_tmp", "=", "tf", ".", "nn", ".", "relu", "(", "output_tmp", ",", "name", "=", "\"relu\"", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "output_tmp", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "output_conns", ".", "append", "(", "output_tmp", ")", "\n", "\n", "######################################################################", "\n", "\n", "# Reshape the input from (batch_size * seq_length, input_dim) to", "\n", "# (batch_size, seq_length, input_dim)", "\n", "name", "=", "\"l{}_reshape_seq\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "input_dim", "=", "network", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "seq_input", "=", "tf", ".", "reshape", "(", "network", ",", "\n", "shape", "=", "[", "-", "1", ",", "self", ".", "seq_length", ",", "input_dim", "]", ",", "\n", "name", "=", "name", ")", "\n", "assert", "self", ".", "batch_size", "==", "seq_input", ".", "get_shape", "(", ")", "[", "0", "]", ".", "value", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "seq_input", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Bidirectional LSTM network", "\n", "name", "=", "\"l{}_bi_lstm\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "hidden_size", "=", "512", "# will output 1024 (512 forward, 512 backward)", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "scope", ":", "\n", "\n", "            ", "def", "lstm_cell", "(", ")", ":", "\n", "\n", "                ", "cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "LSTMCell", "(", "hidden_size", ",", "\n", "use_peepholes", "=", "True", ",", "\n", "state_is_tuple", "=", "True", ",", "\n", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ".", "reuse", ")", "\n", "if", "self", ".", "use_dropout_sequence", ":", "\n", "                    ", "keep_prob", "=", "0.5", "if", "self", ".", "is_train", "else", "1.0", "\n", "cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "output_keep_prob", "=", "keep_prob", "\n", ")", "\n", "\n", "", "return", "cell", "\n", "\n", "", "fw_cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "(", ")", "for", "_", "in", "range", "(", "self", ".", "n_rnn_layers", ")", "]", ",", "state_is_tuple", "=", "True", ")", "\n", "bw_cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "(", ")", "for", "_", "in", "range", "(", "self", ".", "n_rnn_layers", ")", "]", ",", "state_is_tuple", "=", "True", ")", "\n", "\n", "# Initial state of RNN", "\n", "self", ".", "fw_initial_state", "=", "fw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "tf", ".", "float32", ")", "\n", "self", ".", "bw_initial_state", "=", "bw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "tf", ".", "float32", ")", "\n", "\n", "# Feedforward to MultiRNNCell", "\n", "list_rnn_inputs", "=", "tf", ".", "unstack", "(", "seq_input", ",", "axis", "=", "1", ")", "\n", "#outputs, fw_state, bw_state = tf.nn.bidirectional_rnn(", "\n", "outputs", ",", "fw_state", ",", "bw_state", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "static_bidirectional_rnn", "(", "\n", "cell_fw", "=", "fw_cell", ",", "\n", "cell_bw", "=", "bw_cell", ",", "\n", "inputs", "=", "list_rnn_inputs", ",", "\n", "initial_state_fw", "=", "self", ".", "fw_initial_state", ",", "\n", "initial_state_bw", "=", "self", ".", "bw_initial_state", "\n", ")", "\n", "\n", "if", "self", ".", "return_last", ":", "\n", "                ", "network", "=", "outputs", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "network", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "hidden_size", "*", "2", "]", ",", "\n", "name", "=", "name", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "self", ".", "fw_final_state", "=", "fw_state", "\n", "self", ".", "bw_final_state", "=", "bw_state", "\n", "\n", "# Append output", "\n", "", "output_conns", ".", "append", "(", "network", ")", "\n", "\n", "######################################################################", "\n", "\n", "# Add", "\n", "name", "=", "\"l{}_add\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "tf", ".", "add_n", "(", "output_conns", ",", "name", "=", "name", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Dropout", "\n", "if", "self", ".", "use_dropout_sequence", ":", "\n", "            ", "name", "=", "\"l{}_dropout\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "if", "self", ".", "is_train", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "0.5", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "                ", "network", "=", "tf", ".", "nn", ".", "dropout", "(", "network", ",", "keep_prob", "=", "1.0", ",", "name", "=", "name", ")", "\n", "", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.init_ops": [[376, 426], ["model.DeepSleepNet._build_placeholder", "tensorflow.compat.v1.variable_scope", "model.DeepSleepNet.build_model", "fc", "model.DeepSleepNet.activations.append", "tensorflow.contrib.legacy_seq2seq.sequence_loss_by_example", "tensorflow.add_n", "tensorflow.add", "tensorflow.argmax", "scope.reuse_variables", "tensorflow.reduce_sum", "tensorflow.compat.v1.get_collection", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet._build_placeholder", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.model.DeepSleepNet.build_model", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.nn.fc"], ["", "def", "init_ops", "(", "self", ")", ":", "\n", "        ", "self", ".", "_build_placeholder", "(", ")", "\n", "\n", "# Get loss and prediction operations", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "self", ".", "name", ")", "as", "scope", ":", "\n", "\n", "# Reuse variables for validation", "\n", "            ", "if", "self", ".", "reuse_params", ":", "\n", "                ", "scope", ".", "reuse_variables", "(", ")", "\n", "\n", "# Build model", "\n", "", "network", "=", "self", ".", "build_model", "(", "input_var", "=", "self", ".", "input_var", ")", "\n", "\n", "# Softmax linear", "\n", "name", "=", "\"l{}_softmax_linear\"", ".", "format", "(", "self", ".", "layer_idx", ")", "\n", "network", "=", "fc", "(", "name", "=", "name", ",", "input_var", "=", "network", ",", "n_hiddens", "=", "self", ".", "n_classes", ",", "bias", "=", "0.0", ",", "wd", "=", "0", ")", "\n", "self", ".", "activations", ".", "append", "(", "(", "name", ",", "network", ")", ")", "\n", "self", ".", "layer_idx", "+=", "1", "\n", "\n", "# Outputs of softmax linear are logits", "\n", "self", ".", "logits", "=", "network", "\n", "\n", "######### Compute loss #########", "\n", "\n", "# Weighted cross-entropy loss for a sequence of logits (per example)", "\n", "loss", "=", "tf", ".", "contrib", ".", "legacy_seq2seq", ".", "sequence_loss_by_example", "(", "\n", "[", "self", ".", "logits", "]", ",", "\n", "[", "self", ".", "target_var", "]", ",", "\n", "[", "tf", ".", "ones", "(", "[", "self", ".", "batch_size", "*", "self", ".", "seq_length", "]", ")", "]", ",", "\n", "name", "=", "\"sequence_loss_by_example\"", "\n", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "loss", ")", "/", "self", ".", "batch_size", "\n", "\n", "# Regularization loss", "\n", "regular_loss", "=", "tf", ".", "add_n", "(", "\n", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "\"losses\"", ",", "scope", "=", "scope", ".", "name", "+", "\"\\/\"", ")", ",", "\n", "name", "=", "\"regular_loss\"", "\n", ")", "\n", "\n", "# print \" \"", "\n", "# print \"Params to compute regularization loss:\"", "\n", "# for p in tf.compat.v1.get_collection(\"losses\", scope=scope.name + \"\\/\"):", "\n", "#     print p.name", "\n", "# print \" \"", "\n", "\n", "# Total loss", "\n", "self", ".", "loss_op", "=", "tf", ".", "add", "(", "loss", ",", "regular_loss", ")", "\n", "\n", "# Predictions", "\n", "self", ".", "pred_op", "=", "tf", ".", "argmax", "(", "self", ".", "logits", ",", "1", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.optimize.adam": [[4, 15], ["tensorflow.compat.v1.train.AdamOptimizer", "tf.compat.v1.train.AdamOptimizer.compute_gradients", "tf.compat.v1.train.AdamOptimizer.apply_gradients"], "function", ["None"], ["def", "adam", "(", "loss", ",", "lr", ",", "train_vars", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-8", ")", ":", "\n", "    ", "opt", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "lr", ",", "\n", "beta1", "=", "beta1", ",", "\n", "beta2", "=", "beta2", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "name", "=", "\"Adam\"", "\n", ")", "\n", "grads_and_vars", "=", "opt", ".", "compute_gradients", "(", "loss", ",", "train_vars", ")", "\n", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "apply_gradient_op", ",", "grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.optimize.adam_clipping": [[17, 31], ["tensorflow.clip_by_global_norm", "list", "tensorflow.compat.v1.train.AdamOptimizer", "tf.compat.v1.train.AdamOptimizer.apply_gradients", "tensorflow.gradients", "zip"], "function", ["None"], ["", "def", "adam_clipping", "(", "loss", ",", "lr", ",", "train_vars", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "epsilon", "=", "1e-8", ",", "clip_value", "=", "5.0", ")", ":", "\n", "    ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "tf", ".", "gradients", "(", "loss", ",", "train_vars", ")", ",", "\n", "clip_value", ")", "\n", "capped_gvs", "=", "list", "(", "zip", "(", "grads", ",", "train_vars", ")", ")", "\n", "opt", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "lr", ",", "\n", "beta1", "=", "beta1", ",", "\n", "beta2", "=", "beta2", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "name", "=", "\"Adam\"", "\n", ")", "\n", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "capped_gvs", ")", "\n", "return", "apply_gradient_op", ",", "capped_gvs", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.optimize.adam_clipping_list_lr": [[33, 72], ["tensorflow.clip_by_global_norm", "enumerate", "tensorflow.group", "len", "len", "tensorflow.gradients", "tensorflow.compat.v1.train.AdamOptimizer", "list", "tf.compat.v1.train.AdamOptimizer.apply_gradients", "tf.group.append", "len", "len", "list", "list.extend", "zip", "len", "list", "list.extend", "len"], "function", ["None"], ["", "def", "adam_clipping_list_lr", "(", "loss", ",", "list_lrs", ",", "list_train_vars", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "epsilon", "=", "1e-8", ",", "clip_value", "=", "5.0", ")", ":", "\n", "    ", "assert", "len", "(", "list_lrs", ")", "==", "len", "(", "list_train_vars", ")", "\n", "\n", "train_vars", "=", "[", "]", "\n", "for", "v", "in", "list_train_vars", ":", "\n", "        ", "if", "len", "(", "train_vars", ")", "==", "0", ":", "\n", "            ", "train_vars", "=", "list", "(", "v", ")", "\n", "", "else", ":", "\n", "            ", "train_vars", ".", "extend", "(", "v", ")", "\n", "\n", "", "", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "tf", ".", "gradients", "(", "loss", ",", "train_vars", ")", ",", "\n", "clip_value", ")", "\n", "\n", "offset", "=", "0", "\n", "apply_gradient_ops", "=", "[", "]", "\n", "grads_and_vars", "=", "[", "]", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "list_train_vars", ")", ":", "\n", "        ", "g", "=", "grads", "[", "offset", ":", "offset", "+", "len", "(", "v", ")", "]", "\n", "opt", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", "=", "list_lrs", "[", "i", "]", ",", "\n", "beta1", "=", "beta1", ",", "\n", "beta2", "=", "beta2", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "name", "=", "\"Adam\"", "\n", ")", "\n", "gvs", "=", "list", "(", "zip", "(", "g", ",", "v", ")", ")", "\n", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "gvs", ")", "\n", "\n", "apply_gradient_ops", ".", "append", "(", "apply_gradient_op", ")", "\n", "if", "len", "(", "grads_and_vars", ")", "==", "0", ":", "\n", "            ", "grads_and_vars", "=", "list", "(", "gvs", ")", "\n", "", "else", ":", "\n", "            ", "grads_and_vars", ".", "extend", "(", "gvs", ")", "\n", "", "offset", "+=", "len", "(", "v", ")", "\n", "\n", "", "apply_gradient_ops", "=", "tf", ".", "group", "(", "*", "apply_gradient_ops", ")", "\n", "return", "apply_gradient_ops", ",", "grads_and_vars", "\n", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.get_balance_class_downsample": [[5, 32], ["numpy.unique", "numpy.vstack", "numpy.hstack", "len", "np.vstack.append", "np.hstack.append", "numpy.where", "numpy.random.permutation", "numpy.where"], "function", ["None"], ["def", "get_balance_class_downsample", "(", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\"\n    Balance the number of samples of all classes by (downsampling):\n        1. Find the class that has a smallest number of samples\n        2. Randomly select samples in each class equal to that smallest number\n    \"\"\"", "\n", "\n", "class_labels", "=", "np", ".", "unique", "(", "y", ")", "\n", "n_min_classes", "=", "-", "1", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "n_samples", "=", "len", "(", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", ")", "\n", "if", "n_min_classes", "==", "-", "1", ":", "\n", "            ", "n_min_classes", "=", "n_samples", "\n", "", "elif", "n_min_classes", ">", "n_samples", ":", "\n", "            ", "n_min_classes", "=", "n_samples", "\n", "\n", "", "", "balance_x", "=", "[", "]", "\n", "balance_y", "=", "[", "]", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "idx", "=", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", "\n", "idx", "=", "np", ".", "random", ".", "permutation", "(", "idx", ")", "[", ":", "n_min_classes", "]", "\n", "balance_x", ".", "append", "(", "x", "[", "idx", "]", ")", "\n", "balance_y", ".", "append", "(", "y", "[", "idx", "]", ")", "\n", "", "balance_x", "=", "np", ".", "vstack", "(", "balance_x", ")", "\n", "balance_y", "=", "np", ".", "hstack", "(", "balance_y", ")", "\n", "\n", "return", "balance_x", ",", "balance_y", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.get_balance_class_oversample": [[34, 66], ["numpy.unique", "numpy.vstack", "numpy.hstack", "len", "len", "int", "numpy.repeat", "numpy.repeat", "np.vstack.append", "np.hstack.append", "numpy.where", "len", "numpy.vstack", "numpy.hstack", "numpy.where", "numpy.random.permutation"], "function", ["None"], ["", "def", "get_balance_class_oversample", "(", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\"\n    Balance the number of samples of all classes by (oversampling):\n        1. Find the class that has the largest number of samples\n        2. Randomly select samples in each class equal to that largest number\n    \"\"\"", "\n", "class_labels", "=", "np", ".", "unique", "(", "y", ")", "\n", "n_max_classes", "=", "-", "1", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "n_samples", "=", "len", "(", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", ")", "\n", "if", "n_max_classes", "<", "n_samples", ":", "\n", "            ", "n_max_classes", "=", "n_samples", "\n", "\n", "", "", "balance_x", "=", "[", "]", "\n", "balance_y", "=", "[", "]", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "idx", "=", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", "\n", "n_samples", "=", "len", "(", "idx", ")", "\n", "n_repeats", "=", "int", "(", "n_max_classes", "/", "n_samples", ")", "\n", "tmp_x", "=", "np", ".", "repeat", "(", "x", "[", "idx", "]", ",", "n_repeats", ",", "axis", "=", "0", ")", "\n", "tmp_y", "=", "np", ".", "repeat", "(", "y", "[", "idx", "]", ",", "n_repeats", ",", "axis", "=", "0", ")", "\n", "n_remains", "=", "n_max_classes", "-", "len", "(", "tmp_x", ")", "\n", "if", "n_remains", ">", "0", ":", "\n", "            ", "sub_idx", "=", "np", ".", "random", ".", "permutation", "(", "idx", ")", "[", ":", "n_remains", "]", "\n", "tmp_x", "=", "np", ".", "vstack", "(", "[", "tmp_x", ",", "x", "[", "sub_idx", "]", "]", ")", "\n", "tmp_y", "=", "np", ".", "hstack", "(", "[", "tmp_y", ",", "y", "[", "sub_idx", "]", "]", ")", "\n", "", "balance_x", ".", "append", "(", "tmp_x", ")", "\n", "balance_y", ".", "append", "(", "tmp_y", ")", "\n", "", "balance_x", "=", "np", ".", "vstack", "(", "balance_x", ")", "\n", "balance_y", "=", "np", ".", "hstack", "(", "balance_y", ")", "\n", "\n", "return", "balance_x", ",", "balance_y", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_minibatches": [[68, 82], ["range", "len", "len", "numpy.arange", "numpy.random.shuffle", "len", "slice", "len"], "function", ["None"], ["", "def", "iterate_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Generate a generator that return a batch of inputs and targets.\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "if", "shuffle", ":", "\n", "        ", "indices", "=", "np", ".", "arange", "(", "len", "(", "inputs", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "inputs", ")", "-", "batch_size", "+", "1", ",", "batch_size", ")", ":", "\n", "        ", "if", "shuffle", ":", "\n", "            ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "            ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "inputs", "[", "excerpt", "]", ",", "targets", "[", "excerpt", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_seq_minibatches": [[84, 103], ["range", "len", "len", "numpy.zeros", "numpy.zeros", "range", "np.zeros.reshape", "np.zeros.reshape", "len"], "function", ["None"], ["", "", "def", "iterate_seq_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "seq_length", ",", "stride", ")", ":", "\n", "    ", "\"\"\"\n    Generate a generator that return a batch of sequence inputs and targets.\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "n_loads", "=", "(", "batch_size", "*", "stride", ")", "+", "(", "seq_length", "-", "stride", ")", "\n", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "inputs", ")", "-", "n_loads", "+", "1", ",", "(", "batch_size", "*", "stride", ")", ")", ":", "\n", "        ", "seq_inputs", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "seq_length", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "seq_targets", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "seq_length", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "targets", ".", "dtype", ")", "\n", "for", "b_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "start_seq_idx", "=", "start_idx", "+", "(", "b_idx", "*", "stride", ")", "\n", "end_seq_idx", "=", "start_seq_idx", "+", "seq_length", "\n", "seq_inputs", "[", "b_idx", "]", "=", "inputs", "[", "start_seq_idx", ":", "end_seq_idx", "]", "\n", "seq_targets", "[", "b_idx", "]", "=", "targets", "[", "start_seq_idx", ":", "end_seq_idx", "]", "\n", "", "flatten_inputs", "=", "seq_inputs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ")", "\n", "flatten_targets", "=", "seq_targets", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ")", "\n", "yield", "flatten_inputs", ",", "flatten_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_batch_seq_minibatches": [[105, 129], ["len", "numpy.zeros", "numpy.zeros", "range", "range", "len", "len", "ValueError", "x.reshape", "y.reshape"], "function", ["None"], ["", "", "def", "iterate_batch_seq_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "seq_length", ")", ":", "\n", "    ", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "n_inputs", "=", "len", "(", "inputs", ")", "\n", "batch_len", "=", "n_inputs", "//", "batch_size", "\n", "\n", "epoch_size", "=", "batch_len", "//", "seq_length", "\n", "if", "epoch_size", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"epoch_size == 0, decrease batch_size or seq_length\"", ")", "\n", "\n", "", "seq_inputs", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "batch_len", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "seq_targets", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "batch_len", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "targets", ".", "dtype", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "seq_inputs", "[", "i", "]", "=", "inputs", "[", "i", "*", "batch_len", ":", "(", "i", "+", "1", ")", "*", "batch_len", "]", "\n", "seq_targets", "[", "i", "]", "=", "targets", "[", "i", "*", "batch_len", ":", "(", "i", "+", "1", ")", "*", "batch_len", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "epoch_size", ")", ":", "\n", "        ", "x", "=", "seq_inputs", "[", ":", ",", "i", "*", "seq_length", ":", "(", "i", "+", "1", ")", "*", "seq_length", "]", "\n", "y", "=", "seq_targets", "[", ":", ",", "i", "*", "seq_length", ":", "(", "i", "+", "1", ")", "*", "seq_length", "]", "\n", "flatten_x", "=", "x", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ")", "\n", "flatten_y", "=", "y", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ")", "\n", "yield", "flatten_x", ",", "flatten_y", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_list_batch_seq_minibatches": [[131, 154], ["enumerate", "zip", "utils.iterate_seq_minibatches", "numpy.vstack", "seq_x.reshape.reshape", "numpy.hstack", "seq_y.reshape.reshape", "utils.iterate_batch_seq_minibatches", "seq_x.reshape.append", "seq_y.reshape.append", "x_batch.reshape.reshape", "y_batch.reshape.reshape"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_seq_minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.deepsleep.utils.iterate_batch_seq_minibatches"], ["", "", "def", "iterate_list_batch_seq_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "seq_length", ")", ":", "\n", "    ", "for", "idx", ",", "each_data", "in", "enumerate", "(", "zip", "(", "inputs", ",", "targets", ")", ")", ":", "\n", "        ", "each_x", ",", "each_y", "=", "each_data", "\n", "seq_x", ",", "seq_y", "=", "[", "]", ",", "[", "]", "\n", "for", "x_batch", ",", "y_batch", "in", "iterate_seq_minibatches", "(", "inputs", "=", "each_x", ",", "\n", "targets", "=", "each_y", ",", "\n", "batch_size", "=", "1", ",", "\n", "seq_length", "=", "seq_length", ",", "\n", "stride", "=", "1", ")", ":", "\n", "            ", "seq_x", ".", "append", "(", "x_batch", ")", "\n", "seq_y", ".", "append", "(", "y_batch", ")", "\n", "", "seq_x", "=", "np", ".", "vstack", "(", "seq_x", ")", "\n", "seq_x", "=", "seq_x", ".", "reshape", "(", "(", "-", "1", ",", "seq_length", ")", "+", "seq_x", ".", "shape", "[", "1", ":", "]", ")", "\n", "seq_y", "=", "np", ".", "hstack", "(", "seq_y", ")", "\n", "seq_y", "=", "seq_y", ".", "reshape", "(", "(", "-", "1", ",", "seq_length", ")", "+", "seq_y", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "for", "x_batch", ",", "y_batch", "in", "iterate_batch_seq_minibatches", "(", "inputs", "=", "seq_x", ",", "\n", "targets", "=", "seq_y", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "seq_length", "=", "1", ")", ":", "\n", "            ", "x_batch", "=", "x_batch", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "x_batch", ".", "shape", "[", "2", ":", "]", ")", "\n", "y_batch", "=", "y_batch", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "y_batch", ".", "shape", "[", "2", ":", "]", ")", "\n", "yield", "x_batch", ",", "y_batch", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.cross_entropy": [[13, 40], ["tensorflow.reduce_mean", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits"], "function", ["None"], ["def", "cross_entropy", "(", "output", ",", "target", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"It is a softmax cross-entropy operation, returns the TensorFlow expression of cross-entropy of two distributions, implement\n    softmax internally. See ``tf.nn.sparse_softmax_cross_entropy_with_logits``.\n\n    Parameters\n    ----------\n    output : Tensorflow variable\n        A distribution with shape: [batch_size, n_feature].\n    target : Tensorflow variable\n        A batch of index with shape: [batch_size, ].\n    name : string\n        Name of this loss.\n\n    Examples\n    --------\n    >>> ce = tl.cost.cross_entropy(y_logits, y_target_logits, 'my_loss')\n\n    References\n    -----------\n    - About cross-entropy: `wiki <https://en.wikipedia.org/wiki/Cross_entropy>`_.\\n\n    - The code is borrowed from: `here <https://en.wikipedia.org/wiki/Cross_entropy>`_.\n    \"\"\"", "\n", "try", ":", "# old", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "output", ",", "targets", "=", "target", ")", ")", "\n", "", "except", ":", "# TF 1.0", "\n", "        ", "assert", "name", "is", "not", "None", ",", "\"Please give a unique name to tl.cost.cross_entropy for TF1.0+\"", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "target", ",", "logits", "=", "output", ",", "name", "=", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.sigmoid_cross_entropy": [[41, 48], ["tensorflow.reduce_mean", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.nn.sigmoid_cross_entropy_with_logits"], "function", ["None"], ["", "", "def", "sigmoid_cross_entropy", "(", "output", ",", "target", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"It is a sigmoid cross-entropy operation, see ``tf.nn.sigmoid_cross_entropy_with_logits``.\n    \"\"\"", "\n", "try", ":", "# TF 1.0", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "target", ",", "logits", "=", "output", ",", "name", "=", "name", ")", ")", "\n", "", "except", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "output", ",", "targets", "=", "target", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.binary_cross_entropy": [[50, 77], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log"], "function", ["None"], ["", "", "def", "binary_cross_entropy", "(", "output", ",", "target", ",", "epsilon", "=", "1e-8", ",", "name", "=", "'bce_loss'", ")", ":", "\n", "    ", "\"\"\"Computes binary cross entropy given `output`.\n\n    For brevity, let `x = output`, `z = target`.  The binary cross entropy loss is\n\n        loss(x, z) = - sum_i (x[i] * log(z[i]) + (1 - x[i]) * log(1 - z[i]))\n\n    Parameters\n    ----------\n    output : tensor of type `float32` or `float64`.\n    target : tensor of the same type and shape as `output`.\n    epsilon : float\n        A small value to avoid output is zero.\n    name : string\n        An optional name to attach to this layer.\n\n    References\n    -----------\n    - `DRAW <https://github.com/ericjang/draw/blob/master/draw.py#L73>`_\n    \"\"\"", "\n", "#     from tensorflow.python.framework import ops", "\n", "#     with ops.op_scope([output, target], name, \"bce_loss\") as name:", "\n", "#         output = ops.convert_to_tensor(output, name=\"preds\")", "\n", "#         target = ops.convert_to_tensor(targets, name=\"target\")", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", ":", "\n", "        ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "-", "(", "target", "*", "tf", ".", "log", "(", "output", "+", "epsilon", ")", "+", "\n", "(", "1.", "-", "target", ")", "*", "tf", ".", "log", "(", "1.", "-", "output", "+", "epsilon", ")", ")", ",", "axis", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.mean_squared_error": [[79, 104], ["tensorflow.name_scope", "output.get_shape", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "output.get_shape", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.squared_difference", "tensorflow.squared_difference", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.squared_difference", "tensorflow.squared_difference"], "function", ["None"], ["", "", "def", "mean_squared_error", "(", "output", ",", "target", ",", "is_mean", "=", "False", ")", ":", "\n", "    ", "\"\"\"Return the TensorFlow expression of mean-squre-error of two distributions.\n\n    Parameters\n    ----------\n    output : 2D or 4D tensor.\n    target : 2D or 4D tensor.\n    is_mean : boolean, if True, use ``tf.reduce_mean`` to compute the loss of one data, otherwise, use ``tf.reduce_sum`` (default).\n\n    References\n    ------------\n    - `Wiki Mean Squared Error <https://en.wikipedia.org/wiki/Mean_squared_error>`_\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"mean_squared_error_loss\"", ")", ":", "\n", "        ", "if", "output", ".", "get_shape", "(", ")", ".", "ndims", "==", "2", ":", "# [batch_size, n_feature]", "\n", "            ", "if", "is_mean", ":", "\n", "                ", "mse", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "output", ",", "target", ")", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "mse", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "squared_difference", "(", "output", ",", "target", ")", ",", "1", ")", ")", "\n", "", "", "elif", "output", ".", "get_shape", "(", ")", ".", "ndims", "==", "4", ":", "# [batch_size, w, h, c]", "\n", "            ", "if", "is_mean", ":", "\n", "                ", "mse", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "squared_difference", "(", "output", ",", "target", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "mse", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "squared_difference", "(", "output", ",", "target", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "", "", "return", "mse", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.dice_coe": [[107, 141], ["tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.clip_by_value"], "function", ["None"], ["", "", "def", "dice_coe", "(", "output", ",", "target", ",", "epsilon", "=", "1e-10", ")", ":", "\n", "    ", "\"\"\"S\u00f8rensen\u2013Dice coefficient for comparing the similarity of two distributions,\n    usually be used for binary image segmentation i.e. labels are binary.\n    The coefficient = [0, 1], 1 if totally match.\n\n    Parameters\n    -----------\n    output : tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    target : tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    epsilon : float\n        An optional name to attach to this layer.\n\n    Examples\n    ---------\n    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\n    >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_, epsilon=1e-5)\n\n    References\n    -----------\n    - `wiki-dice <https://en.wikipedia.org/wiki/S\u00f8rensen\u2013Dice_coefficient>`_\n    \"\"\"", "\n", "# inse = tf.reduce_sum( tf.mul(output, target) )", "\n", "# l = tf.reduce_sum( tf.mul(output, output) )", "\n", "# r = tf.reduce_sum( tf.mul(target, target) )", "\n", "inse", "=", "tf", ".", "reduce_sum", "(", "output", "*", "target", ")", "\n", "l", "=", "tf", ".", "reduce_sum", "(", "output", "*", "output", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", "*", "target", ")", "\n", "dice", "=", "2", "*", "(", "inse", ")", "/", "(", "l", "+", "r", ")", "\n", "if", "epsilon", "==", "0", ":", "\n", "        ", "return", "dice", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "clip_by_value", "(", "dice", ",", "0", ",", "1.0", "-", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.dice_hard_coe": [[143, 176], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.clip_by_value"], "function", ["None"], ["", "", "def", "dice_hard_coe", "(", "output", ",", "target", ",", "epsilon", "=", "1e-10", ")", ":", "\n", "    ", "\"\"\"Non-differentiable S\u00f8rensen\u2013Dice coefficient for comparing the similarity of two distributions,\n    usually be used for binary image segmentation i.e. labels are binary.\n    The coefficient = [0, 1], 1 if totally match.\n\n    Parameters\n    -----------\n    output : tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    target : tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    epsilon : float\n        An optional name to attach to this layer.\n\n    Examples\n    ---------\n    >>> outputs = pixel_wise_softmax(network.outputs)\n    >>> dice_loss = 1 - dice_coe(outputs, y_, epsilon=1e-5)\n\n    References\n    -----------\n    - `wiki-dice <https://en.wikipedia.org/wiki/S\u00f8rensen\u2013Dice_coefficient>`_\n    \"\"\"", "\n", "output", "=", "tf", ".", "cast", "(", "output", ">", "0.5", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "target", "=", "tf", ".", "cast", "(", "target", ">", "0.5", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "inse", "=", "tf", ".", "reduce_sum", "(", "output", "*", "target", ")", "\n", "l", "=", "tf", ".", "reduce_sum", "(", "output", "*", "output", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", "*", "target", ")", "\n", "dice", "=", "2", "*", "(", "inse", ")", "/", "(", "l", "+", "r", ")", "\n", "if", "epsilon", "==", "0", ":", "\n", "        ", "return", "dice", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "clip_by_value", "(", "dice", ",", "0", ",", "1.0", "-", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.iou_coe": [[177, 206], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["", "", "def", "iou_coe", "(", "output", ",", "target", ",", "threshold", "=", "0.5", ",", "epsilon", "=", "1e-10", ")", ":", "\n", "    ", "\"\"\"Non-differentiable Intersection over Union, usually be used for evaluating binary image segmentation.\n    The coefficient = [0, 1], 1 means totally match.\n\n    Parameters\n    -----------\n    output : tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    target : tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    threshold : float\n        The threshold value to be true.\n    epsilon : float\n        A small value to avoid zero denominator when both output and target output nothing.\n\n    Examples\n    ---------\n    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\n    >>> iou = tl.cost.iou_coe(outputs[:,:,:,0], y_[:,:,:,0])\n\n    Notes\n    ------\n    - IOU cannot be used as training loss, people usually use dice coefficient for training, and IOU for evaluating.\n    \"\"\"", "\n", "pre", "=", "tf", ".", "cast", "(", "output", ">", "threshold", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "truth", "=", "tf", ".", "cast", "(", "target", ">", "threshold", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "intersection", "=", "tf", ".", "reduce_sum", "(", "pre", "*", "truth", ")", "\n", "union", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "(", "pre", "+", "truth", ")", ">", "threshold", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "intersection", ")", "/", "(", "tf", ".", "reduce_sum", "(", "union", ")", "+", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.cross_entropy_seq": [[208, 242], ["sequence_loss_by_example_fn", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.ones_like", "tensorflow.reshape"], "function", ["None"], ["", "def", "cross_entropy_seq", "(", "logits", ",", "target_seqs", ",", "batch_size", "=", "None", ")", ":", "#, batch_size=1, num_steps=None):", "\n", "    ", "\"\"\"Returns the expression of cross-entropy of two sequences, implement\n    softmax internally. Normally be used for Fixed Length RNN outputs.\n\n    Parameters\n    ----------\n    logits : Tensorflow variable\n        2D tensor, ``network.outputs``, [batch_size*n_steps (n_examples), number of output units]\n    target_seqs : Tensorflow variable\n        target : 2D tensor [batch_size, n_steps], if the number of step is dynamic, please use ``cross_entropy_seq_with_mask`` instead.\n    batch_size : None or int.\n        If not None, the return cost will be divided by batch_size.\n\n    Examples\n    --------\n    >>> see PTB tutorial for more details\n    >>> input_data = tf.compat.v1.placeholder(tf.int32, [batch_size, num_steps])\n    >>> targets = tf.compat.v1.placeholder(tf.int32, [batch_size, num_steps])\n    >>> cost = tl.cost.cross_entropy_seq(network.outputs, targets)\n    \"\"\"", "\n", "try", ":", "# TF 1.0", "\n", "        ", "sequence_loss_by_example_fn", "=", "tf", ".", "contrib", ".", "legacy_seq2seq", ".", "sequence_loss_by_example", "\n", "", "except", ":", "\n", "        ", "sequence_loss_by_example_fn", "=", "tf", ".", "nn", ".", "seq2seq", ".", "sequence_loss_by_example", "\n", "\n", "", "loss", "=", "sequence_loss_by_example_fn", "(", "\n", "[", "logits", "]", ",", "\n", "[", "tf", ".", "reshape", "(", "target_seqs", ",", "[", "-", "1", "]", ")", "]", ",", "\n", "[", "tf", ".", "ones_like", "(", "tf", ".", "reshape", "(", "target_seqs", ",", "[", "-", "1", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "]", ")", "\n", "# [tf.ones([batch_size * num_steps])])", "\n", "cost", "=", "tf", ".", "reduce_sum", "(", "loss", ")", "#/ batch_size", "\n", "if", "batch_size", "is", "not", "None", ":", "\n", "        ", "cost", "=", "cost", "/", "batch_size", "\n", "", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.cross_entropy_seq_with_mask": [[244, 281], ["tensorflow.reshape", "tensorflow.to_float", "tensorflow.reshape", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.divide", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.div", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "cross_entropy_seq_with_mask", "(", "logits", ",", "target_seqs", ",", "input_mask", ",", "return_details", "=", "False", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns the expression of cross-entropy of two sequences, implement\n    softmax internally. Normally be used for Dynamic RNN outputs.\n\n    Parameters\n    -----------\n    logits : network identity outputs\n        2D tensor, ``network.outputs``, [batch_size, number of output units].\n    target_seqs : int of tensor, like word ID.\n        [batch_size, ?]\n    input_mask : the mask to compute loss\n        The same size with target_seqs, normally 0 and 1.\n    return_details : boolean\n        - If False (default), only returns the loss.\n        - If True, returns the loss, losses, weights and targets (reshape to one vetcor).\n\n    Examples\n    --------\n    - see Image Captioning Example.\n    \"\"\"", "\n", "targets", "=", "tf", ".", "reshape", "(", "target_seqs", ",", "[", "-", "1", "]", ")", "# to one vector", "\n", "weights", "=", "tf", ".", "to_float", "(", "tf", ".", "reshape", "(", "input_mask", ",", "[", "-", "1", "]", ")", ")", "# to one vector like targets", "\n", "losses", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "labels", "=", "targets", ",", "name", "=", "name", ")", "*", "weights", "\n", "#losses = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets, name=name)) # for TF1.0 and others", "\n", "\n", "try", ":", "## TF1.0", "\n", "        ", "loss", "=", "tf", ".", "divide", "(", "tf", ".", "reduce_sum", "(", "losses", ")", ",", "# loss from mask. reduce_sum before element-wise mul with mask !!", "\n", "tf", ".", "reduce_sum", "(", "weights", ")", ",", "\n", "name", "=", "\"seq_loss_with_mask\"", ")", "\n", "", "except", ":", "## TF0.12", "\n", "        ", "loss", "=", "tf", ".", "div", "(", "tf", ".", "reduce_sum", "(", "losses", ")", ",", "# loss from mask. reduce_sum before element-wise mul with mask !!", "\n", "tf", ".", "reduce_sum", "(", "weights", ")", ",", "\n", "name", "=", "\"seq_loss_with_mask\"", ")", "\n", "", "if", "return_details", ":", "\n", "        ", "return", "loss", ",", "losses", ",", "weights", ",", "targets", "\n", "", "else", ":", "\n", "        ", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.cosine_similarity": [[283, 299], ["tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.multiply"], "function", ["None"], ["", "", "def", "cosine_similarity", "(", "v1", ",", "v2", ")", ":", "\n", "    ", "\"\"\"Cosine similarity [-1, 1], `wiki <https://en.wikipedia.org/wiki/Cosine_similarity>`_.\n\n    Parameters\n    -----------\n    v1, v2 : tensor of [batch_size, n_feature], with the same number of features.\n\n    Returns\n    -----------\n    a tensor of [batch_size, ]\n    \"\"\"", "\n", "try", ":", "## TF1.0", "\n", "        ", "cost", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "v1", ",", "v2", ")", ",", "1", ")", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "v1", ",", "v1", ")", ",", "1", ")", ")", "*", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "v2", ",", "v2", ")", ",", "1", ")", ")", ")", "\n", "", "except", ":", "## TF0.12", "\n", "        ", "cost", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "v1", ",", "v2", ")", ",", "axis", "=", "1", ")", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "v1", ",", "v1", ")", ",", "axis", "=", "1", ")", ")", "*", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "v2", ",", "v2", ")", ",", "axis", "=", "1", ")", ")", ")", "\n", "", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.li_regularizer": [[302, 354], ["isinstance", "isinstance", "ValueError", "ValueError", "ValueError", "logging.info", "tensorflow.name_scope", "tensorflow.python.framework.ops.convert_to_tensor", "standard_ops_fn", "tensorflow.python.ops.standard_ops.reduce_sum", "tensorflow.python.ops.standard_ops.sqrt", "tensorflow.python.ops.standard_ops.reduce_sum", "tensorflow.square"], "function", ["None"], ["", "def", "li_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"li regularization removes the neurons of previous layer, `i` represents `inputs`.\\n\n  Returns a function that can be used to apply group li regularization to weights.\\n\n  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\n\n  Parameters\n  ----------\n  scale : float\n    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\n  scope: An optional scope name for TF12+.\n\n  Returns\n  --------\n  A function with signature `li(weights, name=None)` that apply Li regularization.\n\n  Raises\n  ------\n  ValueError : if scale is outside of the range [0.0, 1.0] or if scale is not a float.\n  \"\"\"", "\n", "import", "numbers", "\n", "from", "tensorflow", ".", "python", ".", "framework", "import", "ops", "\n", "from", "tensorflow", ".", "python", ".", "ops", "import", "standard_ops", "\n", "# from tensorflow.python.platform import tf_logging as logging", "\n", "\n", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "    ", "if", "scale", "<", "0.", ":", "\n", "      ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "", "if", "scale", ">=", "1.", ":", "\n", "      ", "raise", "ValueError", "(", "'Setting a scale greater than 1 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "", "if", "scale", "==", "0.", ":", "\n", "      ", "logging", ".", "info", "(", "'Scale of 0 disables regularizer.'", ")", "\n", "return", "lambda", "_", ",", "name", "=", "None", ":", "None", "\n", "\n", "", "", "def", "li", "(", "weights", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Applies li regularization to weights.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'li_regularizer'", ")", "as", "scope", ":", "\n", "        ", "my_scale", "=", "ops", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "weights", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale'", ")", "\n", "if", "tf", ".", "__version__", "<=", "'0.12'", ":", "\n", "            ", "standard_ops_fn", "=", "standard_ops", ".", "mul", "\n", "", "else", ":", "\n", "            ", "standard_ops_fn", "=", "standard_ops", ".", "multiply", "\n", "return", "standard_ops_fn", "(", "\n", "my_scale", ",", "\n", "standard_ops", ".", "reduce_sum", "(", "standard_ops", ".", "sqrt", "(", "standard_ops", ".", "reduce_sum", "(", "tf", ".", "square", "(", "weights", ")", ",", "1", ")", ")", ")", ",", "\n", "name", "=", "scope", ")", "\n", "", "", "", "return", "li", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.lo_regularizer": [[357, 409], ["isinstance", "isinstance", "ValueError", "ValueError", "ValueError", "logging.info", "tensorflow.name_scope", "tensorflow.python.framework.ops.convert_to_tensor", "standard_ops_fn", "tensorflow.python.ops.standard_ops.reduce_sum", "tensorflow.python.ops.standard_ops.sqrt", "tensorflow.python.ops.standard_ops.reduce_sum", "tensorflow.square"], "function", ["None"], ["", "def", "lo_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"lo regularization removes the neurons of current layer, `o` represents `outputs`\\n\n  Returns a function that can be used to apply group lo regularization to weights.\\n\n  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\n\n  Parameters\n  ----------\n  scale : float\n    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\n  scope: An optional scope name for TF12+.\n\n  Returns\n  -------\n  A function with signature `lo(weights, name=None)` that apply Lo regularization.\n\n  Raises\n  ------\n  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\n  \"\"\"", "\n", "import", "numbers", "\n", "from", "tensorflow", ".", "python", ".", "framework", "import", "ops", "\n", "from", "tensorflow", ".", "python", ".", "ops", "import", "standard_ops", "\n", "# from tensorflow.python.platform import tf_logging as logging", "\n", "\n", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "    ", "if", "scale", "<", "0.", ":", "\n", "      ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "", "if", "scale", ">=", "1.", ":", "\n", "      ", "raise", "ValueError", "(", "'Setting a scale greater than 1 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "", "if", "scale", "==", "0.", ":", "\n", "      ", "logging", ".", "info", "(", "'Scale of 0 disables regularizer.'", ")", "\n", "return", "lambda", "_", ",", "name", "=", "None", ":", "None", "\n", "\n", "", "", "def", "lo", "(", "weights", ",", "name", "=", "'lo_regularizer'", ")", ":", "\n", "    ", "\"\"\"Applies group column regularization to weights.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "scope", ":", "\n", "        ", "my_scale", "=", "ops", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "weights", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale'", ")", "\n", "if", "tf", ".", "__version__", "<=", "'0.12'", ":", "\n", "            ", "standard_ops_fn", "=", "standard_ops", ".", "mul", "\n", "", "else", ":", "\n", "            ", "standard_ops_fn", "=", "standard_ops", ".", "multiply", "\n", "", "return", "standard_ops_fn", "(", "\n", "my_scale", ",", "\n", "standard_ops", ".", "reduce_sum", "(", "standard_ops", ".", "sqrt", "(", "standard_ops", ".", "reduce_sum", "(", "tf", ".", "square", "(", "weights", ")", ",", "0", ")", ")", ")", ",", "\n", "name", "=", "scope", ")", "\n", "", "", "return", "lo", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.maxnorm_regularizer": [[410, 459], ["isinstance", "isinstance", "ValueError", "ValueError", "logging.info", "tensorflow.name_scope", "tensorflow.python.framework.ops.convert_to_tensor", "standard_ops_fn", "tensorflow.python.ops.standard_ops.reduce_max", "tensorflow.python.ops.standard_ops.abs"], "function", ["None"], ["", "def", "maxnorm_regularizer", "(", "scale", "=", "1.0", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Max-norm regularization returns a function that can be used\n  to apply max-norm regularization to weights.\n  About max-norm: `wiki <https://en.wikipedia.org/wiki/Matrix_norm#Max_norm>`_.\\n\n  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\n\n  Parameters\n  ----------\n  scale : float\n    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\n  scope: An optional scope name.\n\n  Returns\n  ---------\n  A function with signature `mn(weights, name=None)` that apply Lo regularization.\n\n  Raises\n  --------\n  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\n  \"\"\"", "\n", "import", "numbers", "\n", "from", "tensorflow", ".", "python", ".", "framework", "import", "ops", "\n", "from", "tensorflow", ".", "python", ".", "ops", "import", "standard_ops", "\n", "\n", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "    ", "if", "scale", "<", "0.", ":", "\n", "      ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "# if scale >= 1.:", "\n", "#   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %", "\n", "#                    scale)", "\n", "", "if", "scale", "==", "0.", ":", "\n", "      ", "logging", ".", "info", "(", "'Scale of 0 disables regularizer.'", ")", "\n", "return", "lambda", "_", ",", "name", "=", "None", ":", "None", "\n", "\n", "", "", "def", "mn", "(", "weights", ",", "name", "=", "'max_regularizer'", ")", ":", "\n", "    ", "\"\"\"Applies max-norm regularization to weights.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "scope", ":", "\n", "          ", "my_scale", "=", "ops", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "weights", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale'", ")", "\n", "if", "tf", ".", "__version__", "<=", "'0.12'", ":", "\n", "              ", "standard_ops_fn", "=", "standard_ops", ".", "mul", "\n", "", "else", ":", "\n", "              ", "standard_ops_fn", "=", "standard_ops", ".", "multiply", "\n", "", "return", "standard_ops_fn", "(", "my_scale", ",", "standard_ops", ".", "reduce_max", "(", "standard_ops", ".", "abs", "(", "weights", ")", ")", ",", "name", "=", "scope", ")", "\n", "", "", "return", "mn", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.maxnorm_o_regularizer": [[460, 508], ["isinstance", "isinstance", "ValueError", "ValueError", "logging.info", "tensorflow.name_scope", "tensorflow.python.framework.ops.convert_to_tensor", "standard_ops_fn", "tensorflow.python.ops.standard_ops.reduce_sum", "tensorflow.python.ops.standard_ops.reduce_max", "tensorflow.python.ops.standard_ops.abs"], "function", ["None"], ["", "def", "maxnorm_o_regularizer", "(", "scale", ",", "scope", ")", ":", "\n", "  ", "\"\"\"Max-norm output regularization removes the neurons of current layer.\\n\n  Returns a function that can be used to apply max-norm regularization to each column of weight matrix.\\n\n  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\n\n  Parameters\n  ----------\n  scale : float\n    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\n  scope: An optional scope name.\n\n  Returns\n  ---------\n  A function with signature `mn_o(weights, name=None)` that apply Lo regularization.\n\n  Raises\n  ---------\n  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\n  \"\"\"", "\n", "import", "numbers", "\n", "from", "tensorflow", ".", "python", ".", "framework", "import", "ops", "\n", "from", "tensorflow", ".", "python", ".", "ops", "import", "standard_ops", "\n", "\n", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "    ", "if", "scale", "<", "0.", ":", "\n", "      ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "# if scale >= 1.:", "\n", "#   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %", "\n", "#                    scale)", "\n", "", "if", "scale", "==", "0.", ":", "\n", "      ", "logging", ".", "info", "(", "'Scale of 0 disables regularizer.'", ")", "\n", "return", "lambda", "_", ",", "name", "=", "None", ":", "None", "\n", "\n", "", "", "def", "mn_o", "(", "weights", ",", "name", "=", "'maxnorm_o_regularizer'", ")", ":", "\n", "     ", "\"\"\"Applies max-norm regularization to weights.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "scope", ":", "\n", "          ", "my_scale", "=", "ops", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "weights", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale'", ")", "\n", "if", "tf", ".", "__version__", "<=", "'0.12'", ":", "\n", "             ", "standard_ops_fn", "=", "standard_ops", ".", "mul", "\n", "", "else", ":", "\n", "             ", "standard_ops_fn", "=", "standard_ops", ".", "multiply", "\n", "", "return", "standard_ops_fn", "(", "my_scale", ",", "standard_ops", ".", "reduce_sum", "(", "standard_ops", ".", "reduce_max", "(", "standard_ops", ".", "abs", "(", "weights", ")", ",", "0", ")", ")", ",", "name", "=", "scope", ")", "\n", "", "", "return", "mn_o", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.maxnorm_i_regularizer": [[509, 557], ["isinstance", "isinstance", "ValueError", "ValueError", "logging.info", "tensorflow.name_scope", "tensorflow.python.framework.ops.convert_to_tensor", "standard_ops_fn", "tensorflow.python.ops.standard_ops.reduce_sum", "tensorflow.python.ops.standard_ops.reduce_max", "tensorflow.python.ops.standard_ops.abs"], "function", ["None"], ["", "def", "maxnorm_i_regularizer", "(", "scale", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Max-norm input regularization removes the neurons of previous layer.\\n\n  Returns a function that can be used to apply max-norm regularization to each row of weight matrix.\\n\n  The implementation follows `TensorFlow contrib <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/regularizers.py>`_.\n\n  Parameters\n  ----------\n  scale : float\n    A scalar multiplier `Tensor`. 0.0 disables the regularizer.\n  scope: An optional scope name.\n\n  Returns\n  ---------\n  A function with signature `mn_i(weights, name=None)` that apply Lo regularization.\n\n  Raises\n  ---------\n  ValueError : If scale is outside of the range [0.0, 1.0] or if scale is not a float.\n  \"\"\"", "\n", "import", "numbers", "\n", "from", "tensorflow", ".", "python", ".", "framework", "import", "ops", "\n", "from", "tensorflow", ".", "python", ".", "ops", "import", "standard_ops", "\n", "\n", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Integral", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'scale cannot be an integer: %s'", "%", "scale", ")", "\n", "", "if", "isinstance", "(", "scale", ",", "numbers", ".", "Real", ")", ":", "\n", "    ", "if", "scale", "<", "0.", ":", "\n", "      ", "raise", "ValueError", "(", "'Setting a scale less than 0 on a regularizer: %g'", "%", "\n", "scale", ")", "\n", "# if scale >= 1.:", "\n", "#   raise ValueError('Setting a scale greater than 1 on a regularizer: %g' %", "\n", "#                    scale)", "\n", "", "if", "scale", "==", "0.", ":", "\n", "      ", "logging", ".", "info", "(", "'Scale of 0 disables regularizer.'", ")", "\n", "return", "lambda", "_", ",", "name", "=", "None", ":", "None", "\n", "\n", "", "", "def", "mn_i", "(", "weights", ",", "name", "=", "'maxnorm_i_regularizer'", ")", ":", "\n", "     ", "\"\"\"Applies max-norm regularization to weights.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "scope", ":", "\n", "          ", "my_scale", "=", "ops", ".", "convert_to_tensor", "(", "scale", ",", "\n", "dtype", "=", "weights", ".", "dtype", ".", "base_dtype", ",", "\n", "name", "=", "'scale'", ")", "\n", "if", "tf", ".", "__version__", "<=", "'0.12'", ":", "\n", "             ", "standard_ops_fn", "=", "standard_ops", ".", "mul", "\n", "", "else", ":", "\n", "             ", "standard_ops_fn", "=", "standard_ops", ".", "multiply", "\n", "", "return", "standard_ops_fn", "(", "my_scale", ",", "standard_ops", ".", "reduce_sum", "(", "standard_ops", ".", "reduce_max", "(", "standard_ops", ".", "abs", "(", "weights", ")", ",", "1", ")", ")", ",", "name", "=", "scope", ")", "\n", "", "", "return", "mn_i", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.exit_tf": [[13, 38], ["sess.close", "exit", "print", "os.system", "os.system", "os.system", "print", "os.system", "print", "print"], "function", ["None"], ["def", "exit_tf", "(", "sess", "=", "None", ")", ":", "\n", "    ", "\"\"\"Close tensorboard and nvidia-process if available\n\n    Parameters\n    ----------\n    sess : a session instance of TensorFlow\n        TensorFlow session\n    \"\"\"", "\n", "text", "=", "\"[tl] Close tensorboard and nvidia-process if available\"", "\n", "sess", ".", "close", "(", ")", "\n", "# import time", "\n", "# time.sleep(2)", "\n", "if", "_platform", "==", "\"linux\"", "or", "_platform", "==", "\"linux2\"", ":", "\n", "        ", "print", "(", "(", "'linux: %s'", "%", "text", ")", ")", "\n", "os", ".", "system", "(", "'nvidia-smi'", ")", "\n", "os", ".", "system", "(", "'fuser 6006/tcp -k'", ")", "# kill tensorboard 6006", "\n", "os", ".", "system", "(", "\"nvidia-smi | grep python |awk '{print $3}'|xargs kill\"", ")", "# kill all nvidia-smi python process", "\n", "", "elif", "_platform", "==", "\"darwin\"", ":", "\n", "        ", "print", "(", "(", "'OS X: %s'", "%", "text", ")", ")", "\n", "os", ".", "system", "(", "\"lsof -i tcp:6006 | grep -v PID | awk '{print $2}' | xargs kill\"", ")", "# kill tensorboard 6006", "\n", "", "elif", "_platform", "==", "\"win32\"", ":", "\n", "        ", "print", "(", "(", "'Windows: %s'", "%", "text", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "_platform", ")", "\n", "", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.clear_all": [[39, 60], ["print", "globals().copy", "globals", "str", "str", "str", "print", "globals", "globals", "globals", "globals", "str", "globals"], "function", ["None"], ["", "def", "clear_all", "(", "printable", "=", "True", ")", ":", "\n", "    ", "\"\"\"Clears all the placeholder variables of keep prob,\n    including keeping probabilities of all dropout, denoising, dropconnect etc.\n\n    Parameters\n    ----------\n    printable : boolean\n        If True, print all deleted variables.\n    \"\"\"", "\n", "print", "(", "'clear all .....................................'", ")", "\n", "gl", "=", "globals", "(", ")", ".", "copy", "(", ")", "\n", "for", "var", "in", "gl", ":", "\n", "        ", "if", "var", "[", "0", "]", "==", "'_'", ":", "continue", "\n", "if", "'func'", "in", "str", "(", "globals", "(", ")", "[", "var", "]", ")", ":", "continue", "\n", "if", "'module'", "in", "str", "(", "globals", "(", ")", "[", "var", "]", ")", ":", "continue", "\n", "if", "'class'", "in", "str", "(", "globals", "(", ")", "[", "var", "]", ")", ":", "continue", "\n", "\n", "if", "printable", ":", "\n", "            ", "print", "(", "(", "\" clear_all ------- %s\"", "%", "str", "(", "globals", "(", ")", "[", "var", "]", ")", ")", ")", "\n", "\n", "", "del", "globals", "(", ")", "[", "var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.set_gpu_fraction": [[81, 99], ["print", "tensorflow.GPUOptions", "tensorflow.compat.v1.Session", "tensorflow.ConfigProto"], "function", ["None"], ["", "", "def", "set_gpu_fraction", "(", "sess", "=", "None", ",", "gpu_fraction", "=", "0.3", ")", ":", "\n", "    ", "\"\"\"Set the GPU memory fraction for the application.\n\n    Parameters\n    ----------\n    sess : a session instance of TensorFlow\n        TensorFlow session\n    gpu_fraction : a float\n        Fraction of GPU memory, (0 ~ 1]\n\n    References\n    ----------\n    - `TensorFlow using GPU <https://www.tensorflow.org/versions/r0.9/how_tos/using_gpu/index.html>`_\n    \"\"\"", "\n", "print", "(", "(", "\"  tensorlayer: GPU MEM Fraction %f\"", "%", "gpu_fraction", ")", ")", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "gpu_fraction", ")", "\n", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", ")", "\n", "return", "sess", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.disable_print": [[104, 118], ["None"], "function", ["None"], ["", "def", "disable_print", "(", ")", ":", "\n", "    ", "\"\"\"Disable console output, ``suppress_stdout`` is recommended.\n\n    Examples\n    ---------\n    >>> print(\"You can see me\")\n    >>> tl.ops.disable_print()\n    >>> print(\" You can't see me\")\n    >>> tl.ops.enable_print()\n    >>> print(\"You can see me\")\n    \"\"\"", "\n", "# sys.stdout = os.devnull   # this one kill the process", "\n", "sys", ".", "stdout", "=", "None", "\n", "sys", ".", "stderr", "=", "os", ".", "devnull", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.enable_print": [[119, 128], ["None"], "function", ["None"], ["", "def", "enable_print", "(", ")", ":", "\n", "    ", "\"\"\"Enable console output, ``suppress_stdout`` is recommended.\n\n    Examples\n    --------\n    - see tl.ops.disable_print()\n    \"\"\"", "\n", "sys", ".", "stdout", "=", "sys", ".", "__stdout__", "\n", "sys", ".", "stderr", "=", "sys", ".", "__stderr__", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.suppress_stdout": [[152, 174], ["open"], "function", ["None"], ["@", "contextmanager", "\n", "def", "suppress_stdout", "(", ")", ":", "\n", "    ", "\"\"\"Temporarily disable console output.\n\n    Examples\n    ---------\n    >>> print(\"You can see me\")\n    >>> with tl.ops.suppress_stdout():\n    >>>     print(\"You can't see me\")\n    >>> print(\"You can see me\")\n\n    References\n    -----------\n    - `stackoverflow <http://stackoverflow.com/questions/2125702/how-to-suppress-console-output-in-python>`_\n    \"\"\"", "\n", "with", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", "as", "devnull", ":", "\n", "        ", "old_stdout", "=", "sys", ".", "stdout", "\n", "sys", ".", "stdout", "=", "devnull", "\n", "try", ":", "\n", "            ", "yield", "\n", "", "finally", ":", "\n", "            ", "sys", ".", "stdout", "=", "old_stdout", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.get_site_packages_directory": [[177, 192], ["site.getsitepackages", "print", "print"], "function", ["None"], ["", "", "", "def", "get_site_packages_directory", "(", ")", ":", "\n", "    ", "\"\"\"Print and return the site-packages directory.\n\n    Examples\n    ---------\n    >>> loc = tl.ops.get_site_packages_directory()\n    \"\"\"", "\n", "import", "site", "\n", "try", ":", "\n", "        ", "loc", "=", "site", ".", "getsitepackages", "(", ")", "\n", "print", "(", "(", "\"  tl.ops : site-packages in \"", ",", "loc", ")", ")", "\n", "return", "loc", "\n", "", "except", ":", "\n", "        ", "print", "(", "\"  tl.ops : Cannot find package dir from virtual environment\"", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.empty_trash": [[195, 218], ["print", "os.system", "print", "os.system", "print", "print", "os.system", "os.system"], "function", ["None"], ["", "", "def", "empty_trash", "(", ")", ":", "\n", "    ", "\"\"\"Empty trash folder.\n\n    \"\"\"", "\n", "text", "=", "\"[tl] Empty the trash\"", "\n", "if", "_platform", "==", "\"linux\"", "or", "_platform", "==", "\"linux2\"", ":", "\n", "        ", "print", "(", "(", "'linux: %s'", "%", "text", ")", ")", "\n", "os", ".", "system", "(", "\"rm -rf ~/.local/share/Trash/*\"", ")", "\n", "", "elif", "_platform", "==", "\"darwin\"", ":", "\n", "        ", "print", "(", "(", "'OS X: %s'", "%", "text", ")", ")", "\n", "os", ".", "system", "(", "\"sudo rm -rf ~/.Trash/*\"", ")", "\n", "", "elif", "_platform", "==", "\"win32\"", ":", "\n", "        ", "print", "(", "(", "'Windows: %s'", "%", "text", ")", ")", "\n", "try", ":", "\n", "            ", "os", ".", "system", "(", "\"rd /s c:\\$Recycle.Bin\"", ")", "# Windows 7 or Server 2008", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "", "try", ":", "\n", "            ", "os", ".", "system", "(", "\"rd /s c:\\recycler\"", ")", "#  Windows XP, Vista, or Server 2003", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "_platform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.activation.identity": [[8, 22], ["None"], "function", ["None"], ["def", "identity", "(", "x", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"The identity activation function, Shortcut is ``linear``.\n\n    Parameters\n    ----------\n    x : a tensor input\n        input(s)\n\n\n    Returns\n    --------\n    A `Tensor` with the same type as `x`.\n    \"\"\"", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.activation.ramp": [[26, 46], ["tensorflow.clip_by_value"], "function", ["None"], ["def", "ramp", "(", "x", "=", "None", ",", "v_min", "=", "0", ",", "v_max", "=", "1", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"The ramp activation function.\n\n    Parameters\n    ----------\n    x : a tensor input\n        input(s)\n    v_min : float\n        if input(s) smaller than v_min, change inputs to v_min\n    v_max : float\n        if input(s) greater than v_max, change inputs to v_max\n    name : a string or None\n        An optional name to attach to this activation function.\n\n\n    Returns\n    --------\n    A `Tensor` with the same type as `x`.\n    \"\"\"", "\n", "return", "tf", ".", "clip_by_value", "(", "x", ",", "clip_value_min", "=", "v_min", ",", "clip_value_max", "=", "v_max", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.activation.leaky_relu": [[47, 76], ["tensorflow.name_scope", "tensorflow.maximum"], "function", ["None"], ["", "def", "leaky_relu", "(", "x", "=", "None", ",", "alpha", "=", "0.1", ",", "name", "=", "\"LeakyReLU\"", ")", ":", "\n", "    ", "\"\"\"The LeakyReLU, Shortcut is ``lrelu``.\n\n    Modified version of ReLU, introducing a nonzero gradient for negative\n    input.\n\n    Parameters\n    ----------\n    x : A `Tensor` with type `float`, `double`, `int32`, `int64`, `uint8`,\n        `int16`, or `int8`.\n    alpha : `float`. slope.\n    name : a string or None\n        An optional name to attach to this activation function.\n\n    Examples\n    ---------\n    >>> network = tl.layers.DenseLayer(network, n_units=100, name = 'dense_lrelu',\n    ...                 act= lambda x : tl.act.lrelu(x, 0.2))\n\n    References\n    ------------\n    - `Rectifier Nonlinearities Improve Neural Network Acoustic Models, Maas et al. (2013) <http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf>`_\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "scope", ":", "\n", "# x = tf.nn.relu(x)", "\n", "# m_x = tf.nn.relu(-x)", "\n", "# x -= alpha * m_x", "\n", "        ", "x", "=", "tf", ".", "maximum", "(", "x", ",", "alpha", "*", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.activation.pixel_wise_softmax": [[80, 101], ["tensorflow.name_scope", "tensorflow.nn.softmax"], "function", ["None"], ["def", "pixel_wise_softmax", "(", "output", ",", "name", "=", "'pixel_wise_softmax'", ")", ":", "\n", "    ", "\"\"\"Return the softmax outputs of images, every pixels have multiple label, the sum of a pixel is 1.\n    Usually be used for image segmentation.\n\n    Parameters\n    ------------\n    output : tensor\n        - For 2d image, 4D tensor [batch_size, height, weight, channel], channel >= 2.\n        - For 3d image, 5D tensor [batch_size, depth, height, weight, channel], channel >= 2.\n\n    Examples\n    ---------\n    >>> outputs = pixel_wise_softmax(network.outputs)\n    >>> dice_loss = 1 - dice_coe(outputs, y_, epsilon=1e-5)\n\n    References\n    -----------\n    - `tf.reverse <https://www.tensorflow.org/versions/master/api_docs/python/array_ops.html#reverse>`_\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "scope", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "softmax", "(", "output", ")", "\n", "## old implementation", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches": [[9, 55], ["range", "len", "len", "numpy.arange", "numpy.random.shuffle", "len", "slice", "len"], "function", ["None"], ["def", "minibatches", "(", "inputs", "=", "None", ",", "targets", "=", "None", ",", "batch_size", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\"Generate a generator that input a group of example in numpy.array and\n    their labels, return the examples and labels by the given batchsize.\n\n    Parameters\n    ----------\n    inputs : numpy.array\n        (X) The input features, every row is a example.\n    targets : numpy.array\n        (y) The labels of inputs, every row is a example.\n    batch_size : int\n        The batch size.\n    shuffle : boolean\n        Indicating whether to use a shuffling queue, shuffle the dataset before return.\n\n    Hints\n    -------\n    - If you have two inputs, e.g. X1 (1000, 100) and X2 (1000, 80), you can ``np.hstack((X1, X2))\n    into (1000, 180) and feed into ``inputs``, then you can split a batch of X1 and X2.\n\n    Examples\n    --------\n    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\n    >>> y = np.asarray([0,1,2,3,4,5])\n    >>> for batch in tl.iterate.minibatches(inputs=X, targets=y, batch_size=2, shuffle=False):\n    >>>     print(batch)\n    ... (array([['a', 'a'],\n    ...        ['b', 'b']],\n    ...         dtype='<U1'), array([0, 1]))\n    ... (array([['c', 'c'],\n    ...        ['d', 'd']],\n    ...         dtype='<U1'), array([2, 3]))\n    ... (array([['e', 'e'],\n    ...        ['f', 'f']],\n    ...         dtype='<U1'), array([4, 5]))\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "if", "shuffle", ":", "\n", "        ", "indices", "=", "np", ".", "arange", "(", "len", "(", "inputs", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "inputs", ")", "-", "batch_size", "+", "1", ",", "batch_size", ")", ":", "\n", "        ", "if", "shuffle", ":", "\n", "            ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "            ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "inputs", "[", "excerpt", "]", ",", "targets", "[", "excerpt", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.seq_minibatches": [[56, 115], ["range", "len", "len", "numpy.zeros", "numpy.zeros", "range", "np.zeros.reshape", "np.zeros.reshape", "len"], "function", ["None"], ["", "", "def", "seq_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "seq_length", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"Generate a generator that return a batch of sequence inputs and targets.\n    If ``batch_size = 100, seq_length = 5``, one return will have ``500`` rows (examples).\n\n    Examples\n    --------\n    - Synced sequence input and output.\n    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\n    >>> y = np.asarray([0, 1, 2, 3, 4, 5])\n    >>> for batch in tl.iterate.seq_minibatches(inputs=X, targets=y, batch_size=2, seq_length=2, stride=1):\n    >>>     print(batch)\n    ... (array([['a', 'a'],\n    ...        ['b', 'b'],\n    ...         ['b', 'b'],\n    ...         ['c', 'c']],\n    ...         dtype='<U1'), array([0, 1, 1, 2]))\n    ... (array([['c', 'c'],\n    ...         ['d', 'd'],\n    ...         ['d', 'd'],\n    ...         ['e', 'e']],\n    ...         dtype='<U1'), array([2, 3, 3, 4]))\n    ...\n    ...\n\n    - Many to One\n    >>> return_last = True\n    >>> num_steps = 2\n    >>> X = np.asarray([['a','a'], ['b','b'], ['c','c'], ['d','d'], ['e','e'], ['f','f']])\n    >>> Y = np.asarray([0,1,2,3,4,5])\n    >>> for batch in tl.iterate.seq_minibatches(inputs=X, targets=Y, batch_size=2, seq_length=num_steps, stride=1):\n    >>>     x, y = batch\n    >>>     if return_last:\n    >>>         tmp_y = y.reshape((-1, num_steps) + y.shape[1:])\n    >>>     y = tmp_y[:, -1]\n    >>>     print(x, y)\n    ... [['a' 'a']\n    ... ['b' 'b']\n    ... ['b' 'b']\n    ... ['c' 'c']] [1 2]\n    ... [['c' 'c']\n    ... ['d' 'd']\n    ... ['d' 'd']\n    ... ['e' 'e']] [3 4]\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "n_loads", "=", "(", "batch_size", "*", "stride", ")", "+", "(", "seq_length", "-", "stride", ")", "\n", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "inputs", ")", "-", "n_loads", "+", "1", ",", "(", "batch_size", "*", "stride", ")", ")", ":", "\n", "        ", "seq_inputs", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "seq_length", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "seq_targets", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "seq_length", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "targets", ".", "dtype", ")", "\n", "for", "b_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "start_seq_idx", "=", "start_idx", "+", "(", "b_idx", "*", "stride", ")", "\n", "end_seq_idx", "=", "start_seq_idx", "+", "seq_length", "\n", "seq_inputs", "[", "b_idx", "]", "=", "inputs", "[", "start_seq_idx", ":", "end_seq_idx", "]", "\n", "seq_targets", "[", "b_idx", "]", "=", "targets", "[", "start_seq_idx", ":", "end_seq_idx", "]", "\n", "", "flatten_inputs", "=", "seq_inputs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ")", "\n", "flatten_targets", "=", "seq_targets", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ")", "\n", "yield", "flatten_inputs", ",", "flatten_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.seq_minibatches2": [[116, 202], ["len", "numpy.zeros", "numpy.zeros", "range", "range", "len", "len", "ValueError"], "function", ["None"], ["", "", "def", "seq_minibatches2", "(", "inputs", ",", "targets", ",", "batch_size", ",", "num_steps", ")", ":", "\n", "    ", "\"\"\"Generate a generator that iterates on two list of words. Yields (Returns) the source contexts and\n    the target context by the given batch_size and num_steps (sequence_length),\n    see ``PTB tutorial``. In TensorFlow's tutorial, this generates the batch_size pointers into the raw\n    PTB data, and allows minibatch iteration along these pointers.\n\n    - Hint, if the input data are images, you can modify the code as follow.\n\n    .. code-block:: python\n\n        from\n        data = np.zeros([batch_size, batch_len)\n        to\n        data = np.zeros([batch_size, batch_len, inputs.shape[1], inputs.shape[2], inputs.shape[3]])\n\n    Parameters\n    ----------\n    inputs : a list\n            the context in list format; note that context usually be\n            represented by splitting by space, and then convert to unique\n            word IDs.\n    targets : a list\n            the context in list format; note that context usually be\n            represented by splitting by space, and then convert to unique\n            word IDs.\n    batch_size : int\n            the batch size.\n    num_steps : int\n            the number of unrolls. i.e. sequence_length\n\n    Yields\n    ------\n    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n\n    Raises\n    ------\n    ValueError : if batch_size or num_steps are too high.\n\n    Examples\n    --------\n    >>> X = [i for i in range(20)]\n    >>> Y = [i for i in range(20,40)]\n    >>> for batch in tl.iterate.seq_minibatches2(X, Y, batch_size=2, num_steps=3):\n    ...     x, y = batch\n    ...     print(x, y)\n    ...\n    ... [[  0.   1.   2.]\n    ... [ 10.  11.  12.]]\n    ... [[ 20.  21.  22.]\n    ... [ 30.  31.  32.]]\n    ...\n    ... [[  3.   4.   5.]\n    ... [ 13.  14.  15.]]\n    ... [[ 23.  24.  25.]\n    ... [ 33.  34.  35.]]\n    ...\n    ... [[  6.   7.   8.]\n    ... [ 16.  17.  18.]]\n    ... [[ 26.  27.  28.]\n    ... [ 36.  37.  38.]]\n\n    Code References\n    ---------------\n    - ``tensorflow/models/rnn/ptb/reader.py``\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "data_len", "=", "len", "(", "inputs", ")", "\n", "batch_len", "=", "data_len", "//", "batch_size", "\n", "# data = np.zeros([batch_size, batch_len])", "\n", "data", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "batch_len", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "data2", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "batch_len", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "data", "[", "i", "]", "=", "inputs", "[", "batch_len", "*", "i", ":", "batch_len", "*", "(", "i", "+", "1", ")", "]", "\n", "data2", "[", "i", "]", "=", "targets", "[", "batch_len", "*", "i", ":", "batch_len", "*", "(", "i", "+", "1", ")", "]", "\n", "\n", "", "epoch_size", "=", "(", "batch_len", "-", "1", ")", "//", "num_steps", "\n", "\n", "if", "epoch_size", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"epoch_size == 0, decrease batch_size or num_steps\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "epoch_size", ")", ":", "\n", "        ", "x", "=", "data", "[", ":", ",", "i", "*", "num_steps", ":", "(", "i", "+", "1", ")", "*", "num_steps", "]", "\n", "x2", "=", "data2", "[", ":", ",", "i", "*", "num_steps", ":", "(", "i", "+", "1", ")", "*", "num_steps", "]", "\n", "yield", "(", "x", ",", "x2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.ptb_iterator": [[204, 279], ["numpy.array", "len", "numpy.zeros", "range", "range", "ValueError"], "function", ["None"], ["", "", "def", "ptb_iterator", "(", "raw_data", ",", "batch_size", ",", "num_steps", ")", ":", "\n", "    ", "\"\"\"\n    Generate a generator that iterates on a list of words, see PTB tutorial. Yields (Returns) the source contexts and\n    the target context by the given batch_size and num_steps (sequence_length).\\n\n    see ``PTB tutorial``.\n\n    e.g. x = [0, 1, 2]  y = [1, 2, 3] , when batch_size = 1, num_steps = 3,\n    raw_data = [i for i in range(100)]\n\n    In TensorFlow's tutorial, this generates batch_size pointers into the raw\n    PTB data, and allows minibatch iteration along these pointers.\n\n    Parameters\n    ----------\n    raw_data : a list\n            the context in list format; note that context usually be\n            represented by splitting by space, and then convert to unique\n            word IDs.\n    batch_size : int\n            the batch size.\n    num_steps : int\n            the number of unrolls. i.e. sequence_length\n\n    Yields\n    ------\n    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n    The second element of the tuple is the same data time-shifted to the\n    right by one.\n\n    Raises\n    ------\n    ValueError : if batch_size or num_steps are too high.\n\n    Examples\n    --------\n    >>> train_data = [i for i in range(20)]\n    >>> for batch in tl.iterate.ptb_iterator(train_data, batch_size=2, num_steps=3):\n    >>>     x, y = batch\n    >>>     print(x, y)\n    ... [[ 0  1  2] <---x                       1st subset/ iteration\n    ...  [10 11 12]]\n    ... [[ 1  2  3] <---y\n    ...  [11 12 13]]\n    ...\n    ... [[ 3  4  5]  <--- 1st batch input       2nd subset/ iteration\n    ...  [13 14 15]] <--- 2nd batch input\n    ... [[ 4  5  6]  <--- 1st batch target\n    ...  [14 15 16]] <--- 2nd batch target\n    ...\n    ... [[ 6  7  8]                             3rd subset/ iteration\n    ...  [16 17 18]]\n    ... [[ 7  8  9]\n    ...  [17 18 19]]\n\n    Code References\n    ----------------\n    - ``tensorflow/models/rnn/ptb/reader.py``\n    \"\"\"", "\n", "raw_data", "=", "np", ".", "array", "(", "raw_data", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "data_len", "=", "len", "(", "raw_data", ")", "\n", "batch_len", "=", "data_len", "//", "batch_size", "\n", "data", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "batch_len", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "data", "[", "i", "]", "=", "raw_data", "[", "batch_len", "*", "i", ":", "batch_len", "*", "(", "i", "+", "1", ")", "]", "\n", "\n", "", "epoch_size", "=", "(", "batch_len", "-", "1", ")", "//", "num_steps", "\n", "\n", "if", "epoch_size", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"epoch_size == 0, decrease batch_size or num_steps\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "epoch_size", ")", ":", "\n", "        ", "x", "=", "data", "[", ":", ",", "i", "*", "num_steps", ":", "(", "i", "+", "1", ")", "*", "num_steps", "]", "\n", "y", "=", "data", "[", ":", ",", "i", "*", "num_steps", "+", "1", ":", "(", "i", "+", "1", ")", "*", "num_steps", "+", "1", "]", "\n", "yield", "(", "x", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.threading_data": [[37, 106], ["six.moves.range", "numpy.asarray", "fn", "len", "len", "threading.Thread", "threading.Thread.start", "threads.append", "threading.Thread.join"], "function", ["None"], ["def", "threading_data", "(", "data", "=", "None", ",", "fn", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Return a batch of result by given data.\n    Usually be used for data augmentation.\n\n    Parameters\n    -----------\n    data : numpy array or zip of numpy array, see Examples below.\n    fn : the function for data processing.\n    more args : the args for fn, see Examples below.\n\n    Examples\n    --------\n    - Single array\n    >>> X --> [batch_size, row, col, 1] greyscale\n    >>> results = threading_data(X, zoom, zoom_range=[0.5, 1], is_random=True)\n    ... results --> [batch_size, row, col, channel]\n    >>> tl.visualize.images2d(images=np.asarray(results), second=0.01, saveable=True, name='after', dtype=None)\n    >>> tl.visualize.images2d(images=np.asarray(X), second=0.01, saveable=True, name='before', dtype=None)\n\n    - List of array (e.g. functions with ``multi``)\n    >>> X, Y --> [batch_size, row, col, 1]  greyscale\n    >>> data = threading_data([_ for _ in zip(X, Y)], zoom_multi, zoom_range=[0.5, 1], is_random=True)\n    ... data --> [batch_size, 2, row, col, 1]\n    >>> X_, Y_ = data.transpose((1,0,2,3,4))\n    ... X_, Y_ --> [batch_size, row, col, 1]\n    >>> tl.visualize.images2d(images=np.asarray(X_), second=0.01, saveable=True, name='after', dtype=None)\n    >>> tl.visualize.images2d(images=np.asarray(Y_), second=0.01, saveable=True, name='before', dtype=None)\n\n    - Customized function for image segmentation\n    >>> def distort_img(data):\n    ...     x, y = data\n    ...     x, y = flip_axis_multi([x, y], axis=0, is_random=True)\n    ...     x, y = flip_axis_multi([x, y], axis=1, is_random=True)\n    ...     x, y = crop_multi([x, y], 100, 100, is_random=True)\n    ...     return x, y\n    >>> X, Y --> [batch_size, row, col, channel]\n    >>> data = threading_data([_ for _ in zip(X, Y)], distort_img)\n    >>> X_, Y_ = data.transpose((1,0,2,3,4))\n\n    References\n    ----------\n    - `python queue <https://pymotw.com/2/Queue/index.html#module-Queue>`_\n    - `run with limited queue <http://effbot.org/librarybook/queue.htm>`_\n    \"\"\"", "\n", "## plot function info", "\n", "# for name, value in kwargs.items():", "\n", "#     print('{0} = {1}'.format(name, value))", "\n", "# exit()", "\n", "# define function for threading", "\n", "def", "apply_fn", "(", "results", ",", "i", ",", "data", ",", "kwargs", ")", ":", "\n", "        ", "results", "[", "i", "]", "=", "fn", "(", "data", ",", "**", "kwargs", ")", "\n", "\n", "## start multi-threaded reading.", "\n", "", "results", "=", "[", "None", "]", "*", "len", "(", "data", ")", "## preallocate result list", "\n", "threads", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "        ", "t", "=", "threading", ".", "Thread", "(", "\n", "name", "=", "'threading_and_return'", ",", "\n", "target", "=", "apply_fn", ",", "\n", "args", "=", "(", "results", ",", "i", ",", "data", "[", "i", "]", ",", "kwargs", ")", "\n", ")", "\n", "t", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "t", ")", "\n", "\n", "## <Milo> wait for all threads to complete", "\n", "", "for", "t", "in", "threads", ":", "\n", "        ", "t", ".", "join", "(", ")", "\n", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.rotation": [[140, 181], ["numpy.array", "prepro.transform_matrix_offset_center", "prepro.apply_transform", "numpy.random.uniform", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.transform_matrix_offset_center", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "def", "rotation", "(", "x", ",", "rg", "=", "20", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "\n", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Rotate an image randomly or non-randomly.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    rg : int or float\n        Degree to rotate, usually 0 ~ 180.\n    is_random : boolean, default False\n        If True, randomly rotate.\n    row_index, col_index, channel_index : int\n        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\n    fill_mode : string\n        Method to fill missing pixel, default \u2018nearest\u2019, more options \u2018constant\u2019, \u2018reflect\u2019 or \u2018wrap\u2019\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    cval : scalar, optional\n        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n\n    Examples\n    ---------\n    >>> x --> [row, col, 1] greyscale\n    >>> x = rotation(x, rg=40, is_random=False)\n    >>> tl.visualize.frame(x[:,:,0], second=0.01, saveable=True, name='temp',cmap='gray')\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "theta", "=", "np", ".", "pi", "/", "180", "*", "np", ".", "random", ".", "uniform", "(", "-", "rg", ",", "rg", ")", "\n", "", "else", ":", "\n", "        ", "theta", "=", "np", ".", "pi", "/", "180", "*", "rg", "\n", "", "rotation_matrix", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "theta", ")", ",", "-", "np", ".", "sin", "(", "theta", ")", ",", "0", "]", ",", "\n", "[", "np", ".", "sin", "(", "theta", ")", ",", "np", ".", "cos", "(", "theta", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "row_index", "]", ",", "x", ".", "shape", "[", "col_index", "]", "\n", "transform_matrix", "=", "transform_matrix_offset_center", "(", "rotation_matrix", ",", "h", ",", "w", ")", "\n", "x", "=", "apply_transform", "(", "x", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.rotation_multi": [[182, 214], ["numpy.array", "prepro.transform_matrix_offset_center", "numpy.asarray", "results.append", "numpy.random.uniform", "prepro.apply_transform", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.transform_matrix_offset_center", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "def", "rotation_multi", "(", "x", ",", "rg", "=", "20", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "\n", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Rotate multiple images with the same arguments, randomly or non-randomly.\n    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``rotation``.\n\n    Examples\n    --------\n    >>> x, y --> [row, col, 1]  greyscale\n    >>> x, y = rotation_multi([x, y], rg=90, is_random=False)\n    >>> tl.visualize.frame(x[:,:,0], second=0.01, saveable=True, name='x',cmap='gray')\n    >>> tl.visualize.frame(y[:,:,0], second=0.01, saveable=True, name='y',cmap='gray')\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "theta", "=", "np", ".", "pi", "/", "180", "*", "np", ".", "random", ".", "uniform", "(", "-", "rg", ",", "rg", ")", "\n", "", "else", ":", "\n", "        ", "theta", "=", "np", ".", "pi", "/", "180", "*", "rg", "\n", "", "rotation_matrix", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "theta", ")", ",", "-", "np", ".", "sin", "(", "theta", ")", ",", "0", "]", ",", "\n", "[", "np", ".", "sin", "(", "theta", ")", ",", "np", ".", "cos", "(", "theta", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "h", ",", "w", "=", "x", "[", "0", "]", ".", "shape", "[", "row_index", "]", ",", "x", "[", "0", "]", ".", "shape", "[", "col_index", "]", "\n", "transform_matrix", "=", "transform_matrix_offset_center", "(", "rotation_matrix", ",", "h", ",", "w", ")", "\n", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "results", ".", "append", "(", "apply_transform", "(", "data", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.crop": [[216, 245], ["int", "int", "int", "int", "numpy.floor", "numpy.floor", "numpy.random.uniform", "numpy.random.uniform"], "function", ["None"], ["", "def", "crop", "(", "x", ",", "wrg", ",", "hrg", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ")", ":", "\n", "    ", "\"\"\"Randomly or centrally crop an image.\n\n    Parameters\n    ----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    wrg : float\n        Size of weight.\n    hrg : float\n        Size of height.\n    is_random : boolean, default False\n        If True, randomly crop, else central crop.\n    row_index, col_index, channel_index : int\n        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\n    \"\"\"", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "row_index", "]", ",", "x", ".", "shape", "[", "col_index", "]", "\n", "assert", "(", "h", ">", "hrg", ")", "and", "(", "w", ">", "wrg", ")", ",", "\"The size of cropping should smaller than the original image\"", "\n", "if", "is_random", ":", "\n", "        ", "h_offset", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "h", "-", "hrg", ")", "-", "1", ")", "\n", "w_offset", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "w", "-", "wrg", ")", "-", "1", ")", "\n", "# print(h_offset, w_offset, x[h_offset: hrg+h_offset ,w_offset: wrg+w_offset].shape)", "\n", "return", "x", "[", "h_offset", ":", "hrg", "+", "h_offset", ",", "w_offset", ":", "wrg", "+", "w_offset", "]", "\n", "", "else", ":", "# central crop", "\n", "        ", "h_offset", "=", "int", "(", "np", ".", "floor", "(", "(", "h", "-", "hrg", ")", "/", "2.", ")", ")", "\n", "w_offset", "=", "int", "(", "np", ".", "floor", "(", "(", "w", "-", "wrg", ")", "/", "2.", ")", ")", "\n", "h_end", "=", "h_offset", "+", "hrg", "\n", "w_end", "=", "w_offset", "+", "wrg", "\n", "return", "x", "[", "h_offset", ":", "h_end", ",", "w_offset", ":", "w_end", "]", "\n", "# old implementation", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.crop_multi": [[253, 279], ["int", "int", "numpy.asarray", "numpy.asarray", "results.append", "results.append", "numpy.random.uniform", "numpy.random.uniform"], "function", ["None"], ["", "", "def", "crop_multi", "(", "x", ",", "wrg", ",", "hrg", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ")", ":", "\n", "    ", "\"\"\"Randomly or centrally crop multiple images.\n\n    Parameters\n    ----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``crop``.\n    \"\"\"", "\n", "h", ",", "w", "=", "x", "[", "0", "]", ".", "shape", "[", "row_index", "]", ",", "x", "[", "0", "]", ".", "shape", "[", "col_index", "]", "\n", "assert", "(", "h", ">", "hrg", ")", "and", "(", "w", ">", "wrg", ")", ",", "\"The size of cropping should smaller than the original image\"", "\n", "if", "is_random", ":", "\n", "        ", "h_offset", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "h", "-", "hrg", ")", "-", "1", ")", "\n", "w_offset", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "w", "-", "wrg", ")", "-", "1", ")", "\n", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "            ", "results", ".", "append", "(", "data", "[", "h_offset", ":", "hrg", "+", "h_offset", ",", "w_offset", ":", "wrg", "+", "w_offset", "]", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "", "else", ":", "\n", "# central crop", "\n", "        ", "h_offset", "=", "(", "h", "-", "hrg", ")", "/", "2", "\n", "w_offset", "=", "(", "w", "-", "wrg", ")", "/", "2", "\n", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "            ", "results", ".", "append", "(", "data", "[", "h_offset", ":", "h", "-", "h_offset", ",", "w_offset", ":", "w", "-", "w_offset", "]", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.flip_axis": [[281, 309], ["numpy.random.uniform", "numpy.asarray().swapaxes", "x.swapaxes.swapaxes", "numpy.asarray().swapaxes", "x.swapaxes.swapaxes", "numpy.asarray", "numpy.asarray"], "function", ["None"], ["", "", "def", "flip_axis", "(", "x", ",", "axis", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Flip the axis of an image, such as flip left and right, up and down, randomly or non-randomly,\n\n    Parameters\n    ----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    axis : int\n        - 0, flip up and down\n        - 1, flip left and right\n        - 2, flip channel\n    is_random : boolean, default False\n        If True, randomly flip.\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "factor", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ")", "\n", "if", "factor", ">", "0", ":", "\n", "            ", "x", "=", "np", ".", "asarray", "(", "x", ")", ".", "swapaxes", "(", "axis", ",", "0", ")", "\n", "x", "=", "x", "[", ":", ":", "-", "1", ",", "...", "]", "\n", "x", "=", "x", ".", "swapaxes", "(", "0", ",", "axis", ")", "\n", "return", "x", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "", "", "else", ":", "\n", "        ", "x", "=", "np", ".", "asarray", "(", "x", ")", ".", "swapaxes", "(", "axis", ",", "0", ")", "\n", "x", "=", "x", "[", ":", ":", "-", "1", ",", "...", "]", "\n", "x", "=", "x", ".", "swapaxes", "(", "0", ",", "axis", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.flip_axis_multi": [[310, 347], ["numpy.random.uniform", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray().swapaxes", "data.swapaxes.swapaxes", "results.append", "numpy.asarray().swapaxes", "data.swapaxes.swapaxes", "results.append", "numpy.asarray", "numpy.asarray"], "function", ["None"], ["", "", "def", "flip_axis_multi", "(", "x", ",", "axis", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Flip the axises of multiple images together, such as flip left and right, up and down, randomly or non-randomly,\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``flip_axis``.\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "factor", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ")", "\n", "if", "factor", ">", "0", ":", "\n", "# x = np.asarray(x).swapaxes(axis, 0)", "\n", "# x = x[::-1, ...]", "\n", "# x = x.swapaxes(0, axis)", "\n", "# return x", "\n", "            ", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "                ", "data", "=", "np", ".", "asarray", "(", "data", ")", ".", "swapaxes", "(", "axis", ",", "0", ")", "\n", "data", "=", "data", "[", ":", ":", "-", "1", ",", "...", "]", "\n", "data", "=", "data", ".", "swapaxes", "(", "0", ",", "axis", ")", "\n", "results", ".", "append", "(", "data", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "asarray", "(", "x", ")", "\n", "", "", "else", ":", "\n", "# x = np.asarray(x).swapaxes(axis, 0)", "\n", "# x = x[::-1, ...]", "\n", "# x = x.swapaxes(0, axis)", "\n", "# return x", "\n", "        ", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "            ", "data", "=", "np", ".", "asarray", "(", "data", ")", ".", "swapaxes", "(", "axis", ",", "0", ")", "\n", "data", "=", "data", "[", ":", ":", "-", "1", ",", "...", "]", "\n", "data", "=", "data", ".", "swapaxes", "(", "0", ",", "axis", ")", "\n", "results", ".", "append", "(", "data", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.shift": [[349, 387], ["numpy.array", "prepro.apply_transform", "numpy.random.uniform", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "", "def", "shift", "(", "x", ",", "wrg", "=", "0.1", ",", "hrg", "=", "0.1", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "\n", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Shift an image randomly or non-randomly.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    wrg : float\n        Percentage of shift in axis x, usually -0.25 ~ 0.25.\n    hrg : float\n        Percentage of shift in axis y, usually -0.25 ~ 0.25.\n    is_random : boolean, default False\n        If True, randomly shift.\n    row_index, col_index, channel_index : int\n        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\n    fill_mode : string\n        Method to fill missing pixel, default \u2018nearest\u2019, more options \u2018constant\u2019, \u2018reflect\u2019 or \u2018wrap\u2019.\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    cval : scalar, optional\n        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    \"\"\"", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "row_index", "]", ",", "x", ".", "shape", "[", "col_index", "]", "\n", "if", "is_random", ":", "\n", "        ", "tx", "=", "np", ".", "random", ".", "uniform", "(", "-", "hrg", ",", "hrg", ")", "*", "h", "\n", "ty", "=", "np", ".", "random", ".", "uniform", "(", "-", "wrg", ",", "wrg", ")", "*", "w", "\n", "", "else", ":", "\n", "        ", "tx", ",", "ty", "=", "hrg", "*", "h", ",", "wrg", "*", "w", "\n", "", "translation_matrix", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "tx", "]", ",", "\n", "[", "0", ",", "1", ",", "ty", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "transform_matrix", "=", "translation_matrix", "# no need to do offset", "\n", "x", "=", "apply_transform", "(", "x", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.shift_multi": [[388, 414], ["numpy.array", "numpy.asarray", "results.append", "numpy.random.uniform", "numpy.random.uniform", "prepro.apply_transform"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "def", "shift_multi", "(", "x", ",", "wrg", "=", "0.1", ",", "hrg", "=", "0.1", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "\n", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Shift images with the same arguments, randomly or non-randomly.\n    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``shift``.\n    \"\"\"", "\n", "h", ",", "w", "=", "x", "[", "0", "]", ".", "shape", "[", "row_index", "]", ",", "x", "[", "0", "]", ".", "shape", "[", "col_index", "]", "\n", "if", "is_random", ":", "\n", "        ", "tx", "=", "np", ".", "random", ".", "uniform", "(", "-", "hrg", ",", "hrg", ")", "*", "h", "\n", "ty", "=", "np", ".", "random", ".", "uniform", "(", "-", "wrg", ",", "wrg", ")", "*", "w", "\n", "", "else", ":", "\n", "        ", "tx", ",", "ty", "=", "hrg", "*", "h", ",", "wrg", "*", "w", "\n", "", "translation_matrix", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "tx", "]", ",", "\n", "[", "0", ",", "1", ",", "ty", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "transform_matrix", "=", "translation_matrix", "# no need to do offset", "\n", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "results", ".", "append", "(", "apply_transform", "(", "data", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.shear": [[416, 452], ["numpy.array", "prepro.transform_matrix_offset_center", "prepro.apply_transform", "numpy.random.uniform", "numpy.cos", "numpy.sin"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.transform_matrix_offset_center", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "def", "shear", "(", "x", ",", "intensity", "=", "0.1", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "\n", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Shear an image randomly or non-randomly.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    intensity : float\n        Percentage of shear, usually -0.5 ~ 0.5 (is_random==True), 0 ~ 0.5 (is_random==False),\n        you can have a quick try by shear(X, 1).\n    is_random : boolean, default False\n        If True, randomly shear.\n    row_index, col_index, channel_index : int\n        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\n    fill_mode : string\n        Method to fill missing pixel, default \u2018nearest\u2019, more options \u2018constant\u2019, \u2018reflect\u2019 or \u2018wrap\u2019.\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    cval : scalar, optional\n        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "shear", "=", "np", ".", "random", ".", "uniform", "(", "-", "intensity", ",", "intensity", ")", "\n", "", "else", ":", "\n", "        ", "shear", "=", "intensity", "\n", "", "shear_matrix", "=", "np", ".", "array", "(", "[", "[", "1", ",", "-", "np", ".", "sin", "(", "shear", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "np", ".", "cos", "(", "shear", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "row_index", "]", ",", "x", ".", "shape", "[", "col_index", "]", "\n", "transform_matrix", "=", "transform_matrix_offset_center", "(", "shear_matrix", ",", "h", ",", "w", ")", "\n", "x", "=", "apply_transform", "(", "x", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.shear_multi": [[453, 478], ["numpy.array", "prepro.transform_matrix_offset_center", "numpy.asarray", "numpy.random.uniform", "results.append", "prepro.apply_transform", "numpy.cos", "numpy.sin"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.transform_matrix_offset_center", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "def", "shear_multi", "(", "x", ",", "intensity", "=", "0.1", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "\n", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Shear images with the same arguments, randomly or non-randomly.\n    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``shear``.\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "shear", "=", "np", ".", "random", ".", "uniform", "(", "-", "intensity", ",", "intensity", ")", "\n", "", "else", ":", "\n", "        ", "shear", "=", "intensity", "\n", "", "shear_matrix", "=", "np", ".", "array", "(", "[", "[", "1", ",", "-", "np", ".", "sin", "(", "shear", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "np", ".", "cos", "(", "shear", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "h", ",", "w", "=", "x", "[", "0", "]", ".", "shape", "[", "row_index", "]", ",", "x", "[", "0", "]", ".", "shape", "[", "col_index", "]", "\n", "transform_matrix", "=", "transform_matrix_offset_center", "(", "shear_matrix", ",", "h", ",", "w", ")", "\n", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "results", ".", "append", "(", "apply_transform", "(", "data", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.swirl": [[480, 538], ["Exception", "numpy.max", "skimage.transform.swirl", "int", "int", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.swirl"], ["", "def", "swirl", "(", "x", ",", "center", "=", "None", ",", "strength", "=", "1", ",", "radius", "=", "100", ",", "rotation", "=", "0", ",", "output_shape", "=", "None", ",", "order", "=", "1", ",", "mode", "=", "'constant'", ",", "cval", "=", "0", ",", "clip", "=", "True", ",", "preserve_range", "=", "False", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Swirl an image randomly or non-randomly, see `scikit-image swirl API <http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.swirl>`_\n    and `example <http://scikit-image.org/docs/dev/auto_examples/plot_swirl.html>`_.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    center : (row, column) tuple or (2,) ndarray, optional\n        Center coordinate of transformation.\n    strength : float, optional\n        The amount of swirling applied.\n    radius : float, optional\n        The extent of the swirl in pixels. The effect dies out rapidly beyond radius.\n    rotation : float, (degree) optional\n        Additional rotation applied to the image, usually [0, 360], relates to center.\n    output_shape : tuple (rows, cols), optional\n        Shape of the output image generated. By default the shape of the input image is preserved.\n    order : int, optional\n        The order of the spline interpolation, default is 1. The order has to be in the range 0-5. See skimage.transform.warp for detail.\n    mode : {\u2018constant\u2019, \u2018edge\u2019, \u2018symmetric\u2019, \u2018reflect\u2019, \u2018wrap\u2019}, optional\n        Points outside the boundaries of the input are filled according to the given mode, with \u2018constant\u2019 used as the default. Modes match the behaviour of numpy.pad.\n    cval : float, optional\n        Used in conjunction with mode \u2018constant\u2019, the value outside the image boundaries.\n    clip : bool, optional\n        Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.\n    preserve_range : bool, optional\n        Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of img_as_float.\n    is_random : boolean, default False\n        If True, random swirl.\n            - random center = [(0 ~ x.shape[0]), (0 ~ x.shape[1])]\n            - random strength = [0, strength]\n            - random radius = [1e-10, radius]\n            - random rotation = [-rotation, rotation]\n\n    Examples\n    ---------\n    >>> x --> [row, col, 1] greyscale\n    >>> x = swirl(x, strength=4, radius=100)\n    \"\"\"", "\n", "assert", "radius", "!=", "0", ",", "Exception", "(", "\"Invalid radius value\"", ")", "\n", "rotation", "=", "np", ".", "pi", "/", "180", "*", "rotation", "\n", "if", "is_random", ":", "\n", "        ", "center_h", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "x", ".", "shape", "[", "0", "]", ")", ")", "\n", "center_w", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "x", ".", "shape", "[", "1", "]", ")", ")", "\n", "center", "=", "(", "center_h", ",", "center_w", ")", "\n", "strength", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "strength", ")", "\n", "radius", "=", "np", ".", "random", ".", "uniform", "(", "1e-10", ",", "radius", ")", "\n", "rotation", "=", "np", ".", "random", ".", "uniform", "(", "-", "rotation", ",", "rotation", ")", "\n", "\n", "", "max_v", "=", "np", ".", "max", "(", "x", ")", "\n", "if", "max_v", ">", "1", ":", "# Note: the input of this fn should be [-1, 1], rescale is required.", "\n", "        ", "x", "=", "x", "/", "max_v", "\n", "", "swirled", "=", "skimage", ".", "transform", ".", "swirl", "(", "x", ",", "center", "=", "center", ",", "strength", "=", "strength", ",", "radius", "=", "radius", ",", "rotation", "=", "rotation", ",", "\n", "output_shape", "=", "output_shape", ",", "order", "=", "order", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ",", "clip", "=", "clip", ",", "preserve_range", "=", "preserve_range", ")", "\n", "if", "max_v", ">", "1", ":", "\n", "        ", "swirled", "=", "swirled", "*", "max_v", "\n", "", "return", "swirled", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.swirl_multi": [[539, 570], ["Exception", "numpy.asarray", "int", "int", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.max", "skimage.transform.swirl", "results.append", "numpy.random.uniform", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.swirl"], ["", "def", "swirl_multi", "(", "x", ",", "center", "=", "None", ",", "strength", "=", "1", ",", "radius", "=", "100", ",", "rotation", "=", "0", ",", "output_shape", "=", "None", ",", "order", "=", "1", ",", "mode", "=", "'constant'", ",", "cval", "=", "0", ",", "clip", "=", "True", ",", "preserve_range", "=", "False", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Swirl multiple images with the same arguments, randomly or non-randomly.\n    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``swirl``.\n    \"\"\"", "\n", "assert", "radius", "!=", "0", ",", "Exception", "(", "\"Invalid radius value\"", ")", "\n", "rotation", "=", "np", ".", "pi", "/", "180", "*", "rotation", "\n", "if", "is_random", ":", "\n", "        ", "center_h", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ")", "\n", "center_w", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "x", "[", "0", "]", ".", "shape", "[", "1", "]", ")", ")", "\n", "center", "=", "(", "center_h", ",", "center_w", ")", "\n", "strength", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "strength", ")", "\n", "radius", "=", "np", ".", "random", ".", "uniform", "(", "1e-10", ",", "radius", ")", "\n", "rotation", "=", "np", ".", "random", ".", "uniform", "(", "-", "rotation", ",", "rotation", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "max_v", "=", "np", ".", "max", "(", "data", ")", "\n", "if", "max_v", ">", "1", ":", "# Note: the input of this fn should be [-1, 1], rescale is required.", "\n", "            ", "data", "=", "data", "/", "max_v", "\n", "", "swirled", "=", "skimage", ".", "transform", ".", "swirl", "(", "data", ",", "center", "=", "center", ",", "strength", "=", "strength", ",", "radius", "=", "radius", ",", "rotation", "=", "rotation", ",", "\n", "output_shape", "=", "output_shape", ",", "order", "=", "order", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ",", "clip", "=", "clip", ",", "preserve_range", "=", "preserve_range", ")", "\n", "if", "max_v", ">", "1", ":", "\n", "            ", "swirled", "=", "swirled", "*", "max_v", "\n", "", "results", ".", "append", "(", "swirled", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.elastic_transform": [[575, 621], ["numpy.meshgrid", "numpy.random.RandomState", "numpy.random.RandomState", "len", "scipy.ndimage.filters.gaussian_filter", "scipy.ndimage.filters.gaussian_filter", "numpy.arange", "numpy.arange", "numpy.reshape", "numpy.reshape", "scipy.ndimage.interpolation.map_coordinates().reshape", "scipy.ndimage.interpolation.map_coordinates().reshape", "int", "len", "Exception", "time.time", "len", "scipy.ndimage.interpolation.map_coordinates", "scipy.ndimage.interpolation.map_coordinates", "np.random.RandomState.rand", "np.random.RandomState.rand"], "function", ["None"], ["def", "elastic_transform", "(", "x", ",", "alpha", ",", "sigma", ",", "mode", "=", "\"constant\"", ",", "cval", "=", "0", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Elastic deformation of images as described in `[Simard2003] <http://deeplearning.cs.cmu.edu/pdfs/Simard.pdf>`_ .\n\n    Parameters\n    -----------\n    x : numpy array, a greyscale image.\n    alpha : scalar factor.\n    sigma : scalar or sequence of scalars, the smaller the sigma, the more transformation.\n        Standard deviation for Gaussian kernel. The standard deviations of the Gaussian filter are given for each axis as a sequence, or as a single number, in which case it is equal for all axes.\n    mode : default constant, see `scipy.ndimage.filters.gaussian_filter <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.filters.gaussian_filter.html>`_.\n    cval : float, optional. Used in conjunction with mode \u2018constant\u2019, the value outside the image boundaries.\n    is_random : boolean, default False\n\n    Examples\n    ---------\n    >>> x = elastic_transform(x, alpha = x.shape[1] * 3, sigma = x.shape[1] * 0.07)\n\n    References\n    ------------\n    - `Github <https://gist.github.com/chsasank/4d8f68caf01f041a6453e67fb30f8f5a>`_.\n    - `Kaggle <https://www.kaggle.com/pscion/ultrasound-nerve-segmentation/elastic-transform-for-data-augmentation-0878921a>`_\n    \"\"\"", "\n", "if", "is_random", "is", "False", ":", "\n", "        ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "None", ")", "\n", "", "else", ":", "\n", "        ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "#", "\n", "", "is_3d", "=", "False", "\n", "if", "len", "(", "x", ".", "shape", ")", "==", "3", "and", "x", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "        ", "x", "=", "x", "[", ":", ",", ":", ",", "0", "]", "\n", "is_3d", "=", "True", "\n", "", "elif", "len", "(", "x", ".", "shape", ")", "==", "3", "and", "x", ".", "shape", "[", "-", "1", "]", "!=", "1", ":", "\n", "        ", "raise", "Exception", "(", "\"Only support greyscale image\"", ")", "\n", "", "assert", "len", "(", "x", ".", "shape", ")", "==", "2", "\n", "\n", "shape", "=", "x", ".", "shape", "\n", "\n", "dx", "=", "gaussian_filter", "(", "(", "random_state", ".", "rand", "(", "*", "shape", ")", "*", "2", "-", "1", ")", ",", "sigma", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ")", "*", "alpha", "\n", "dy", "=", "gaussian_filter", "(", "(", "random_state", ".", "rand", "(", "*", "shape", ")", "*", "2", "-", "1", ")", ",", "sigma", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ")", "*", "alpha", "\n", "\n", "x_", ",", "y_", "=", "np", ".", "meshgrid", "(", "np", ".", "arange", "(", "shape", "[", "0", "]", ")", ",", "np", ".", "arange", "(", "shape", "[", "1", "]", ")", ",", "indexing", "=", "'ij'", ")", "\n", "indices", "=", "np", ".", "reshape", "(", "x_", "+", "dx", ",", "(", "-", "1", ",", "1", ")", ")", ",", "np", ".", "reshape", "(", "y_", "+", "dy", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "if", "is_3d", ":", "\n", "        ", "return", "map_coordinates", "(", "x", ",", "indices", ",", "order", "=", "1", ")", ".", "reshape", "(", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "map_coordinates", "(", "x", ",", "indices", ",", "order", "=", "1", ")", ".", "reshape", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.elastic_transform_multi": [[622, 661], ["np.random.RandomState.rand", "numpy.asarray", "numpy.random.RandomState", "numpy.random.RandomState", "len", "numpy.meshgrid", "int", "len", "scipy.ndimage.filters.gaussian_filter", "scipy.ndimage.filters.gaussian_filter", "numpy.arange", "numpy.arange", "numpy.reshape", "numpy.reshape", "results.append", "results.append", "time.time", "len", "Exception", "scipy.ndimage.interpolation.map_coordinates().reshape", "scipy.ndimage.interpolation.map_coordinates().reshape", "len", "scipy.ndimage.interpolation.map_coordinates", "scipy.ndimage.interpolation.map_coordinates"], "function", ["None"], ["", "", "def", "elastic_transform_multi", "(", "x", ",", "alpha", ",", "sigma", ",", "mode", "=", "\"constant\"", ",", "cval", "=", "0", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Elastic deformation of images as described in `[Simard2003] <http://deeplearning.cs.cmu.edu/pdfs/Simard.pdf>`_.\n\n    Parameters\n    -----------\n    x : list of numpy array\n    others : see ``elastic_transform``.\n    \"\"\"", "\n", "if", "is_random", "is", "False", ":", "\n", "        ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "None", ")", "\n", "", "else", ":", "\n", "        ", "random_state", "=", "np", ".", "random", ".", "RandomState", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "\n", "", "shape", "=", "x", "[", "0", "]", ".", "shape", "\n", "if", "len", "(", "shape", ")", "==", "3", ":", "\n", "        ", "shape", "=", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "", "new_shape", "=", "random_state", ".", "rand", "(", "*", "shape", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "is_3d", "=", "False", "\n", "if", "len", "(", "data", ".", "shape", ")", "==", "3", "and", "data", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "            ", "data", "=", "data", "[", ":", ",", ":", ",", "0", "]", "\n", "is_3d", "=", "True", "\n", "", "elif", "len", "(", "data", ".", "shape", ")", "==", "3", "and", "data", ".", "shape", "[", "-", "1", "]", "!=", "1", ":", "\n", "            ", "raise", "Exception", "(", "\"Only support greyscale image\"", ")", "\n", "", "assert", "len", "(", "data", ".", "shape", ")", "==", "2", "\n", "\n", "dx", "=", "gaussian_filter", "(", "(", "new_shape", "*", "2", "-", "1", ")", ",", "sigma", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ")", "*", "alpha", "\n", "dy", "=", "gaussian_filter", "(", "(", "new_shape", "*", "2", "-", "1", ")", ",", "sigma", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ")", "*", "alpha", "\n", "\n", "x_", ",", "y_", "=", "np", ".", "meshgrid", "(", "np", ".", "arange", "(", "shape", "[", "0", "]", ")", ",", "np", ".", "arange", "(", "shape", "[", "1", "]", ")", ",", "indexing", "=", "'ij'", ")", "\n", "indices", "=", "np", ".", "reshape", "(", "x_", "+", "dx", ",", "(", "-", "1", ",", "1", ")", ")", ",", "np", ".", "reshape", "(", "y_", "+", "dy", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "# print(data.shape)", "\n", "if", "is_3d", ":", "\n", "            ", "results", ".", "append", "(", "map_coordinates", "(", "data", ",", "indices", ",", "order", "=", "1", ")", ".", "reshape", "(", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "results", ".", "append", "(", "map_coordinates", "(", "data", ",", "indices", ",", "order", "=", "1", ")", ".", "reshape", "(", "shape", ")", ")", "\n", "", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.zoom": [[663, 708], ["numpy.array", "prepro.transform_matrix_offset_center", "prepro.apply_transform", "len", "Exception", "print", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.transform_matrix_offset_center", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "def", "zoom", "(", "x", ",", "zoom_range", "=", "(", "0.9", ",", "1.1", ")", ",", "is_random", "=", "False", ",", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "\n", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Zoom in and out of a single image, randomly or non-randomly.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    zoom_range : list or tuple\n        - If is_random=False, (h, w) are the fixed zoom factor for row and column axies, factor small than one is zoom in.\n        - If is_random=True, (min zoom out, max zoom out) for x and y with different random zoom in/out factor.\n        e.g (0.5, 1) zoom in 1~2 times.\n    is_random : boolean, default False\n        If True, randomly zoom.\n    row_index, col_index, channel_index : int\n        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\n    fill_mode : string\n        Method to fill missing pixel, default \u2018nearest\u2019, more options \u2018constant\u2019, \u2018reflect\u2019 or \u2018wrap\u2019.\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    cval : scalar, optional\n        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0.\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    \"\"\"", "\n", "if", "len", "(", "zoom_range", ")", "!=", "2", ":", "\n", "        ", "raise", "Exception", "(", "'zoom_range should be a tuple or list of two floats. '", "\n", "'Received arg: '", ",", "zoom_range", ")", "\n", "", "if", "is_random", ":", "\n", "        ", "if", "zoom_range", "[", "0", "]", "==", "1", "and", "zoom_range", "[", "1", "]", "==", "1", ":", "\n", "            ", "zx", ",", "zy", "=", "1", ",", "1", "\n", "print", "(", "\" random_zoom : not zoom in/out\"", ")", "\n", "", "else", ":", "\n", "            ", "zx", ",", "zy", "=", "np", ".", "random", ".", "uniform", "(", "zoom_range", "[", "0", "]", ",", "zoom_range", "[", "1", "]", ",", "2", ")", "\n", "", "", "else", ":", "\n", "        ", "zx", ",", "zy", "=", "zoom_range", "\n", "# print(zx, zy)", "\n", "", "zoom_matrix", "=", "np", ".", "array", "(", "[", "[", "zx", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "zy", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "row_index", "]", ",", "x", ".", "shape", "[", "col_index", "]", "\n", "transform_matrix", "=", "transform_matrix_offset_center", "(", "zoom_matrix", ",", "h", ",", "w", ")", "\n", "x", "=", "apply_transform", "(", "x", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.zoom_multi": [[709, 745], ["numpy.array", "prepro.transform_matrix_offset_center", "numpy.asarray", "len", "Exception", "results.append", "print", "numpy.random.uniform", "prepro.apply_transform"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.transform_matrix_offset_center", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform"], ["", "def", "zoom_multi", "(", "x", ",", "zoom_range", "=", "(", "0.9", ",", "1.1", ")", ",", "is_random", "=", "False", ",", "\n", "row_index", "=", "0", ",", "col_index", "=", "1", ",", "channel_index", "=", "2", ",", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Zoom in and out of images with the same arguments, randomly or non-randomly.\n    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``zoom``.\n    \"\"\"", "\n", "if", "len", "(", "zoom_range", ")", "!=", "2", ":", "\n", "        ", "raise", "Exception", "(", "'zoom_range should be a tuple or list of two floats. '", "\n", "'Received arg: '", ",", "zoom_range", ")", "\n", "\n", "", "if", "is_random", ":", "\n", "        ", "if", "zoom_range", "[", "0", "]", "==", "1", "and", "zoom_range", "[", "1", "]", "==", "1", ":", "\n", "            ", "zx", ",", "zy", "=", "1", ",", "1", "\n", "print", "(", "\" random_zoom : not zoom in/out\"", ")", "\n", "", "else", ":", "\n", "            ", "zx", ",", "zy", "=", "np", ".", "random", ".", "uniform", "(", "zoom_range", "[", "0", "]", ",", "zoom_range", "[", "1", "]", ",", "2", ")", "\n", "", "", "else", ":", "\n", "        ", "zx", ",", "zy", "=", "zoom_range", "\n", "\n", "", "zoom_matrix", "=", "np", ".", "array", "(", "[", "[", "zx", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "zy", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "\n", "h", ",", "w", "=", "x", "[", "0", "]", ".", "shape", "[", "row_index", "]", ",", "x", "[", "0", "]", ".", "shape", "[", "col_index", "]", "\n", "transform_matrix", "=", "transform_matrix_offset_center", "(", "zoom_matrix", ",", "h", ",", "w", ")", "\n", "# x = apply_transform(x, transform_matrix, channel_index, fill_mode, cval)", "\n", "# return x", "\n", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "results", ".", "append", "(", "apply_transform", "(", "data", ",", "transform_matrix", ",", "channel_index", ",", "fill_mode", ",", "cval", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.brightness": [[752, 777], ["skimage.exposure.adjust_gamma", "numpy.random.uniform"], "function", ["None"], ["", "def", "brightness", "(", "x", ",", "gamma", "=", "1", ",", "gain", "=", "1", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Change the brightness of a single image, randomly or non-randomly.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    gamma : float, small than 1 means brighter.\n        Non negative real number. Default value is 1.\n\n        - If is_random is True, gamma in a range of (1-gamma, 1+gamma).\n    gain : float\n        The constant multiplier. Default value is 1.\n    is_random : boolean, default False\n        - If True, randomly change brightness.\n\n    References\n    -----------\n    - `skimage.exposure.adjust_gamma <http://scikit-image.org/docs/dev/api/skimage.exposure.html>`_\n    - `chinese blog <http://www.cnblogs.com/denny402/p/5124402.html>`_\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "gamma", "=", "np", ".", "random", ".", "uniform", "(", "1", "-", "gamma", ",", "1", "+", "gamma", ")", "\n", "", "x", "=", "exposure", ".", "adjust_gamma", "(", "x", ",", "gamma", ",", "gain", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.brightness_multi": [[778, 795], ["numpy.asarray", "numpy.random.uniform", "results.append", "skimage.exposure.adjust_gamma"], "function", ["None"], ["", "def", "brightness_multi", "(", "x", ",", "gamma", "=", "1", ",", "gain", "=", "1", ",", "is_random", "=", "False", ")", ":", "\n", "    ", "\"\"\"Change the brightness of multiply images, randomly or non-randomly.\n    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``brightness``.\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "gamma", "=", "np", ".", "random", ".", "uniform", "(", "1", "-", "gamma", ",", "1", "+", "gamma", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "results", ".", "append", "(", "exposure", ".", "adjust_gamma", "(", "data", ",", "gamma", ",", "gain", ")", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.constant": [[798, 802], ["skimage.exposure.adjust_sigmoid"], "function", ["None"], ["", "def", "constant", "(", "x", ",", "cutoff", "=", "0.5", ",", "gain", "=", "10", ",", "inv", "=", "False", ",", "is_random", "=", "False", ")", ":", "\n", "# TODO", "\n", "    ", "x", "=", "exposure", ".", "adjust_sigmoid", "(", "x", ",", "cutoff", "=", "cutoff", ",", "gain", "=", "gain", ",", "inv", "=", "inv", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.constant_multi": [[803, 806], ["None"], "function", ["None"], ["", "def", "constant_multi", "(", ")", ":", "\n", "#TODO", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.imresize": [[808, 843], ["scipy.misc.imresize", "scipy.misc.imresize", "scipy.misc.imresize", "scipy.misc.imresize", "Exception"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.imresize", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.imresize", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.imresize", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.imresize"], ["", "def", "imresize", "(", "x", ",", "size", "=", "[", "100", ",", "100", "]", ",", "interp", "=", "'bilinear'", ",", "mode", "=", "None", ")", ":", "\n", "    ", "\"\"\"Resize an image by given output size and method. Warning, this function\n    will rescale the value to [0, 255].\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    size : int, float or tuple (h, w)\n        - int, Percentage of current size.\n        - float, Fraction of current size.\n        - tuple, Size of the output image.\n    interp : str, optional\n        Interpolation to use for re-sizing (\u2018nearest\u2019, \u2018lanczos\u2019, \u2018bilinear\u2019, \u2018bicubic\u2019 or \u2018cubic\u2019).\n    mode : str, optional\n        The PIL image mode (\u2018P\u2019, \u2018L\u2019, etc.) to convert arr before resizing.\n\n    Returns\n    --------\n    imresize : ndarray\n    The resized array of image.\n\n    References\n    ------------\n    - `scipy.misc.imresize <https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.imresize.html>`_\n    \"\"\"", "\n", "if", "x", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "# greyscale", "\n", "        ", "x", "=", "scipy", ".", "misc", ".", "imresize", "(", "x", "[", ":", ",", ":", ",", "0", "]", ",", "size", ",", "interp", "=", "interp", ",", "mode", "=", "mode", ")", "\n", "return", "x", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "", "elif", "x", ".", "shape", "[", "-", "1", "]", "==", "3", ":", "\n", "# rgb, bgr ..", "\n", "        ", "return", "scipy", ".", "misc", ".", "imresize", "(", "x", ",", "size", ",", "interp", "=", "interp", ",", "mode", "=", "mode", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unsupported channel %d\"", "%", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.samplewise_norm": [[845, 891], ["Exception", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std"], "function", ["None"], ["", "", "def", "samplewise_norm", "(", "x", ",", "rescale", "=", "None", ",", "samplewise_center", "=", "False", ",", "samplewise_std_normalization", "=", "False", ",", "\n", "channel_index", "=", "2", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Normalize an image by rescale, samplewise centering and samplewise centering in order.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    rescale : rescaling factor.\n            If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (before applying any other transformation)\n    samplewise_center : set each sample mean to 0.\n    samplewise_std_normalization : divide each input by its std.\n    epsilon : small position value for dividing standard deviation.\n\n    Examples\n    --------\n    >>> x = samplewise_norm(x, samplewise_center=True, samplewise_std_normalization=True)\n    >>> print(x.shape, np.mean(x), np.std(x))\n    ... (160, 176, 1), 0.0, 1.0\n\n    Notes\n    ------\n    When samplewise_center and samplewise_std_normalization are True.\n\n    - For greyscale image, every pixels are subtracted and divided by the mean and std of whole image.\n    - For RGB image, every pixels are subtracted and divided by the mean and std of this pixel i.e. the mean and std of a pixel is 0 and 1.\n    \"\"\"", "\n", "if", "rescale", ":", "\n", "        ", "x", "*=", "rescale", "\n", "\n", "", "if", "x", ".", "shape", "[", "channel_index", "]", "==", "1", ":", "\n", "# greyscale", "\n", "        ", "if", "samplewise_center", ":", "\n", "            ", "x", "=", "x", "-", "np", ".", "mean", "(", "x", ")", "\n", "", "if", "samplewise_std_normalization", ":", "\n", "            ", "x", "=", "x", "/", "np", ".", "std", "(", "x", ")", "\n", "", "return", "x", "\n", "", "elif", "x", ".", "shape", "[", "channel_index", "]", "==", "3", ":", "\n", "# rgb", "\n", "        ", "if", "samplewise_center", ":", "\n", "            ", "x", "=", "x", "-", "np", ".", "mean", "(", "x", ",", "axis", "=", "channel_index", ",", "keepdims", "=", "True", ")", "\n", "", "if", "samplewise_std_normalization", ":", "\n", "            ", "x", "=", "x", "/", "(", "np", ".", "std", "(", "x", ",", "axis", "=", "channel_index", ",", "keepdims", "=", "True", ")", "+", "epsilon", ")", "\n", "", "return", "x", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unsupported channels %d\"", "%", "x", ".", "shape", "[", "channel_index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.featurewise_norm": [[892, 909], ["None"], "function", ["None"], ["", "", "def", "featurewise_norm", "(", "x", ",", "mean", "=", "None", ",", "std", "=", "None", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Normalize every pixels by the same given mean and std, which are usually\n    compute from all examples.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    mean : value for subtraction.\n    std : value for division.\n    epsilon : small position value for dividing standard deviation.\n    \"\"\"", "\n", "if", "mean", ":", "\n", "        ", "x", "=", "x", "-", "mean", "\n", "", "if", "std", ":", "\n", "        ", "x", "=", "x", "/", "(", "std", "+", "epsilon", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.get_zca_whitening_principal_components_img": [[911, 927], ["numpy.reshape", "print", "print", "scipy.linalg.svd", "print", "numpy.dot", "numpy.dot", "numpy.dot", "numpy.diag", "numpy.sqrt"], "function", ["None"], ["", "def", "get_zca_whitening_principal_components_img", "(", "X", ")", ":", "\n", "    ", "\"\"\"Return the ZCA whitening principal components matrix.\n\n    Parameters\n    -----------\n    x : numpy array\n        Batch of image with dimension of [n_example, row, col, channel] (default).\n    \"\"\"", "\n", "flatX", "=", "np", ".", "reshape", "(", "X", ",", "(", "X", ".", "shape", "[", "0", "]", ",", "X", ".", "shape", "[", "1", "]", "*", "X", ".", "shape", "[", "2", "]", "*", "X", ".", "shape", "[", "3", "]", ")", ")", "\n", "print", "(", "\"zca : computing sigma ..\"", ")", "\n", "sigma", "=", "np", ".", "dot", "(", "flatX", ".", "T", ",", "flatX", ")", "/", "flatX", ".", "shape", "[", "0", "]", "\n", "print", "(", "\"zca : computing U, S and V ..\"", ")", "\n", "U", ",", "S", ",", "V", "=", "linalg", ".", "svd", "(", "sigma", ")", "\n", "print", "(", "\"zca : computing principal components ..\"", ")", "\n", "principal_components", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "U", ",", "np", ".", "diag", "(", "1.", "/", "np", ".", "sqrt", "(", "S", "+", "10e-7", ")", ")", ")", ",", "U", ".", "T", ")", "\n", "return", "principal_components", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.zca_whitening": [[928, 945], ["print", "print", "numpy.dot", "numpy.reshape"], "function", ["None"], ["", "def", "zca_whitening", "(", "x", ",", "principal_components", ")", ":", "\n", "    ", "\"\"\"Apply ZCA whitening on an image by given principal components matrix.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    principal_components : matrix from ``get_zca_whitening_principal_components_img``.\n    \"\"\"", "\n", "# flatx = np.reshape(x, (x.size))", "\n", "print", "(", "(", "principal_components", ".", "shape", ",", "x", ".", "shape", ")", ")", "# ((28160, 28160), (160, 176, 1))", "\n", "# flatx = np.reshape(x, (x.shape))", "\n", "# flatx = np.reshape(x, (x.shape[0], ))", "\n", "print", "(", "(", "flatx", ".", "shape", ")", ")", "# (160, 176, 1)", "\n", "whitex", "=", "np", ".", "dot", "(", "flatx", ",", "principal_components", ")", "\n", "x", "=", "np", ".", "reshape", "(", "whitex", ",", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.channel_shift": [[958, 983], ["numpy.rollaxis", "numpy.stack", "numpy.rollaxis", "numpy.random.uniform", "numpy.min", "numpy.max", "numpy.clip"], "function", ["None"], ["", "def", "channel_shift", "(", "x", ",", "intensity", ",", "is_random", "=", "False", ",", "channel_index", "=", "2", ")", ":", "\n", "    ", "\"\"\"Shift the channels of an image, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`_.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    intensity : float\n        Intensity of shifting.\n    is_random : boolean, default False\n        If True, randomly shift.\n    channel_index : int\n        Index of channel, default 2.\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "factor", "=", "np", ".", "random", ".", "uniform", "(", "-", "intensity", ",", "intensity", ")", "\n", "", "else", ":", "\n", "        ", "factor", "=", "intensity", "\n", "", "x", "=", "np", ".", "rollaxis", "(", "x", ",", "channel_index", ",", "0", ")", "\n", "min_x", ",", "max_x", "=", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", "\n", "channel_images", "=", "[", "np", ".", "clip", "(", "x_channel", "+", "factor", ",", "min_x", ",", "max_x", ")", "\n", "for", "x_channel", "in", "x", "]", "\n", "x", "=", "np", ".", "stack", "(", "channel_images", ",", "axis", "=", "0", ")", "\n", "x", "=", "np", ".", "rollaxis", "(", "x", ",", "0", ",", "channel_index", "+", "1", ")", "\n", "return", "x", "\n", "# x = np.rollaxis(x, channel_index, 0)", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.channel_shift_multi": [[991, 1016], ["numpy.asarray", "numpy.random.uniform", "numpy.rollaxis", "numpy.stack", "numpy.rollaxis", "results.append", "numpy.min", "numpy.max", "numpy.clip"], "function", ["None"], ["", "def", "channel_shift_multi", "(", "x", ",", "intensity", ",", "channel_index", "=", "2", ")", ":", "\n", "    ", "\"\"\"Shift the channels of images with the same arguments, randomly or non-randomly, see `numpy.rollaxis <https://docs.scipy.org/doc/numpy/reference/generated/numpy.rollaxis.html>`_ .\n    Usually be used for image segmentation which x=[X, Y], X and Y should be matched.\n\n    Parameters\n    -----------\n    x : list of numpy array\n        List of images with dimension of [n_images, row, col, channel] (default).\n    others : see ``channel_shift``.\n    \"\"\"", "\n", "if", "is_random", ":", "\n", "        ", "factor", "=", "np", ".", "random", ".", "uniform", "(", "-", "intensity", ",", "intensity", ")", "\n", "", "else", ":", "\n", "        ", "factor", "=", "intensity", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "data", "in", "x", ":", "\n", "        ", "data", "=", "np", ".", "rollaxis", "(", "data", ",", "channel_index", ",", "0", ")", "\n", "min_x", ",", "max_x", "=", "np", ".", "min", "(", "data", ")", ",", "np", ".", "max", "(", "data", ")", "\n", "channel_images", "=", "[", "np", ".", "clip", "(", "x_channel", "+", "factor", ",", "min_x", ",", "max_x", ")", "\n", "for", "x_channel", "in", "x", "]", "\n", "data", "=", "np", ".", "stack", "(", "channel_images", ",", "axis", "=", "0", ")", "\n", "data", "=", "np", ".", "rollaxis", "(", "x", ",", "0", ",", "channel_index", "+", "1", ")", "\n", "results", ".", "append", "(", "data", ")", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.drop": [[1018, 1045], ["len", "numpy.random.binomial", "six.moves.range", "numpy.multiply", "Exception", "numpy.multiply", "numpy.multiply", "Exception", "len", "numpy.random.binomial", "numpy.random.binomial"], "function", ["None"], ["", "def", "drop", "(", "x", ",", "keep", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"Randomly set some pixels to zero by a given keeping probability.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] or [row, col].\n    keep : float (0, 1)\n        The keeping probability, the lower more values will be set to zero.\n    \"\"\"", "\n", "if", "len", "(", "x", ".", "shape", ")", "==", "3", ":", "\n", "        ", "if", "x", ".", "shape", "[", "-", "1", "]", "==", "3", ":", "# color", "\n", "            ", "img_size", "=", "x", ".", "shape", "\n", "mask", "=", "np", ".", "random", ".", "binomial", "(", "n", "=", "1", ",", "p", "=", "keep", ",", "size", "=", "x", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                ", "x", "[", ":", ",", ":", ",", "i", "]", "=", "np", ".", "multiply", "(", "x", "[", ":", ",", ":", ",", "i", "]", ",", "mask", ")", "\n", "", "", "elif", "x", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "# greyscale image", "\n", "            ", "img_size", "=", "x", ".", "shape", "\n", "x", "=", "np", ".", "multiply", "(", "x", ",", "np", ".", "random", ".", "binomial", "(", "n", "=", "1", ",", "p", "=", "keep", ",", "size", "=", "img_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Unsupported shape {}\"", ".", "format", "(", "x", ".", "shape", ")", ")", "\n", "", "", "elif", "len", "(", "x", ".", "shape", ")", "==", "2", "or", "1", ":", "# greyscale matrix (image) or vector", "\n", "        ", "img_size", "=", "x", ".", "shape", "\n", "x", "=", "np", ".", "multiply", "(", "x", ",", "np", ".", "random", ".", "binomial", "(", "n", "=", "1", ",", "p", "=", "keep", ",", "size", "=", "img_size", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unsupported shape {}\"", ".", "format", "(", "x", ".", "shape", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.transform_matrix_offset_center": [[1057, 1077], ["numpy.array", "numpy.array", "numpy.dot", "numpy.dot", "float", "float"], "function", ["None"], ["", "def", "transform_matrix_offset_center", "(", "matrix", ",", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\"Return transform matrix offset center.\n\n    Parameters\n    ----------\n    matrix : numpy array\n        Transform matrix\n    x, y : int\n        Size of image.\n\n    Examples\n    --------\n    - See ``rotation``, ``shear``, ``zoom``.\n    \"\"\"", "\n", "o_x", "=", "float", "(", "x", ")", "/", "2", "+", "0.5", "\n", "o_y", "=", "float", "(", "y", ")", "/", "2", "+", "0.5", "\n", "offset_matrix", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "o_x", "]", ",", "[", "0", ",", "1", ",", "o_y", "]", ",", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "reset_matrix", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "-", "o_x", "]", ",", "[", "0", ",", "1", ",", "-", "o_y", "]", ",", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "transform_matrix", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "offset_matrix", ",", "matrix", ")", ",", "reset_matrix", ")", "\n", "return", "transform_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.apply_transform": [[1079, 1111], ["numpy.rollaxis", "numpy.stack", "numpy.rollaxis", "scipy.interpolation.affine_transform"], "function", ["None"], ["", "def", "apply_transform", "(", "x", ",", "transform_matrix", ",", "channel_index", "=", "2", ",", "fill_mode", "=", "'nearest'", ",", "cval", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Return transformed images by given transform_matrix from ``transform_matrix_offset_center``.\n\n    Parameters\n    ----------\n    x : numpy array\n        Batch of images with dimension of 3, [batch_size, row, col, channel].\n    transform_matrix : numpy array\n        Transform matrix (offset center), can be generated by ``transform_matrix_offset_center``\n    channel_index : int\n        Index of channel, default 2.\n    fill_mode : string\n        Method to fill missing pixel, default \u2018nearest\u2019, more options \u2018constant\u2019, \u2018reflect\u2019 or \u2018wrap\u2019\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n    cval : scalar, optional\n        Value used for points outside the boundaries of the input if mode='constant'. Default is 0.0\n\n        - `scipy ndimage affine_transform <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.interpolation.affine_transform.html>`_\n\n    Examples\n    --------\n    - See ``rotation``, ``shift``, ``shear``, ``zoom``.\n    \"\"\"", "\n", "x", "=", "np", ".", "rollaxis", "(", "x", ",", "channel_index", ",", "0", ")", "\n", "final_affine_matrix", "=", "transform_matrix", "[", ":", "2", ",", ":", "2", "]", "\n", "final_offset", "=", "transform_matrix", "[", ":", "2", ",", "2", "]", "\n", "channel_images", "=", "[", "ndi", ".", "interpolation", ".", "affine_transform", "(", "x_channel", ",", "final_affine_matrix", ",", "\n", "final_offset", ",", "order", "=", "0", ",", "mode", "=", "fill_mode", ",", "cval", "=", "cval", ")", "for", "x_channel", "in", "x", "]", "\n", "x", "=", "np", ".", "stack", "(", "channel_images", ",", "axis", "=", "0", ")", "\n", "x", "=", "np", ".", "rollaxis", "(", "x", ",", "0", ",", "channel_index", "+", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.projective_transform_by_points": [[1113, 1169], ["skimage.transform.ProjectiveTransform", "transform.ProjectiveTransform.estimate", "skimage.transform.warp", "type", "numpy.array", "type", "numpy.array", "numpy.max"], "function", ["None"], ["", "def", "projective_transform_by_points", "(", "x", ",", "src", ",", "dst", ",", "map_args", "=", "{", "}", ",", "output_shape", "=", "None", ",", "order", "=", "1", ",", "mode", "=", "'constant'", ",", "cval", "=", "0.0", ",", "clip", "=", "True", ",", "preserve_range", "=", "False", ")", ":", "\n", "    ", "\"\"\"Projective transform by given coordinates, usually 4 coordinates. see `scikit-image <http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html>`_.\n\n    Parameters\n    -----------\n    x : numpy array\n        An image with dimension of [row, col, channel] (default).\n    src : list or numpy\n        The original coordinates, usually 4 coordinates of (x, y).\n    dst : list or numpy\n        The coordinates after transformation, the number of coordinates is the same with src.\n    map_args : dict, optional\n        Keyword arguments passed to inverse_map.\n    output_shape : tuple (rows, cols), optional\n        Shape of the output image generated. By default the shape of the input image is preserved. Note that, even for multi-band images, only rows and columns need to be specified.\n    order : int, optional\n        The order of interpolation. The order has to be in the range 0-5:\n\n        - 0 Nearest-neighbor\n        - 1 Bi-linear (default)\n        - 2 Bi-quadratic\n        - 3 Bi-cubic\n        - 4 Bi-quartic\n        - 5 Bi-quintic\n    mode : {\u2018constant\u2019, \u2018edge\u2019, \u2018symmetric\u2019, \u2018reflect\u2019, \u2018wrap\u2019}, optional\n        Points outside the boundaries of the input are filled according to the given mode. Modes match the behaviour of numpy.pad.\n    cval : float, optional\n        Used in conjunction with mode \u2018constant\u2019, the value outside the image boundaries.\n    clip : bool, optional\n        Whether to clip the output to the range of values of the input image. This is enabled by default, since higher order interpolation may produce values outside the given input range.\n    preserve_range : bool, optional\n        Whether to keep the original range of values. Otherwise, the input image is converted according to the conventions of img_as_float.\n\n    Examples\n    --------\n    >>> Assume X is an image from CIFAR 10, i.e. shape == (32, 32, 3)\n    >>> src = [[0,0],[0,32],[32,0],[32,32]]\n    >>> dst = [[10,10],[0,32],[32,0],[32,32]]\n    >>> x = projective_transform_by_points(X, src, dst)\n\n    References\n    -----------\n    - `scikit-image : geometric transformations <http://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html>`_\n    - `scikit-image : examples <http://scikit-image.org/docs/dev/auto_examples/index.html>`_\n    \"\"\"", "\n", "if", "type", "(", "src", ")", "is", "list", ":", "# convert to numpy", "\n", "        ", "src", "=", "np", ".", "array", "(", "src", ")", "\n", "", "if", "type", "(", "dst", ")", "is", "list", ":", "\n", "        ", "dst", "=", "np", ".", "array", "(", "dst", ")", "\n", "", "if", "np", ".", "max", "(", "x", ")", ">", "1", ":", "# convert to [0, 1]", "\n", "        ", "x", "=", "x", "/", "255", "\n", "\n", "", "m", "=", "transform", ".", "ProjectiveTransform", "(", ")", "\n", "m", ".", "estimate", "(", "dst", ",", "src", ")", "\n", "warped", "=", "transform", ".", "warp", "(", "x", ",", "m", ",", "map_args", "=", "map_args", ",", "output_shape", "=", "output_shape", ",", "order", "=", "order", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ",", "clip", "=", "clip", ",", "preserve_range", "=", "preserve_range", ")", "\n", "return", "warped", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.array_to_img": [[1171, 1209], ["x.transpose.transpose", "max", "numpy.max", "Image.fromarray", "x.transpose.astype", "Image.fromarray", "Exception", "numpy.min", "x[].astype"], "function", ["None"], ["", "def", "array_to_img", "(", "x", ",", "dim_ordering", "=", "(", "0", ",", "1", ",", "2", ")", ",", "scale", "=", "True", ")", ":", "\n", "    ", "\"\"\"Converts a numpy array to PIL image object (uint8 format).\n\n    Parameters\n    ----------\n    x : numpy array\n        A image with dimension of 3 and channels of 1 or 3.\n    dim_ordering : list or tuple of 3 int\n        Index of row, col and channel, default (0, 1, 2), for theano (1, 2, 0).\n    scale : boolean, default is True\n        If True, converts image to [0, 255] from any range of value like [-1, 2].\n\n    References\n    -----------\n    - `PIL Image.fromarray <http://pillow.readthedocs.io/en/3.1.x/reference/Image.html?highlight=fromarray>`_\n    \"\"\"", "\n", "from", "PIL", "import", "Image", "\n", "# if dim_ordering == 'default':", "\n", "#     dim_ordering = K.image_dim_ordering()", "\n", "# if dim_ordering == 'th':  # theano", "\n", "#     x = x.transpose(1, 2, 0)", "\n", "x", "=", "x", ".", "transpose", "(", "dim_ordering", ")", "\n", "if", "scale", ":", "\n", "        ", "x", "+=", "max", "(", "-", "np", ".", "min", "(", "x", ")", ",", "0", ")", "\n", "x_max", "=", "np", ".", "max", "(", "x", ")", "\n", "if", "x_max", "!=", "0", ":", "\n", "# print(x_max)", "\n", "# x /= x_max", "\n", "            ", "x", "=", "x", "/", "x_max", "\n", "", "x", "*=", "255", "\n", "", "if", "x", ".", "shape", "[", "2", "]", "==", "3", ":", "\n", "# RGB", "\n", "        ", "return", "Image", ".", "fromarray", "(", "x", ".", "astype", "(", "'uint8'", ")", ",", "'RGB'", ")", "\n", "", "elif", "x", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "# grayscale", "\n", "        ", "return", "Image", ".", "fromarray", "(", "x", "[", ":", ",", ":", ",", "0", "]", ".", "astype", "(", "'uint8'", ")", ",", "'L'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Unsupported channel number: '", ",", "x", ".", "shape", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.pad_sequences": [[1212, 1282], ["len", "tuple", "enumerate", "len", "numpy.max", "numpy.asarray", "len", "len", "ValueError", "numpy.ones", "ValueError", "ValueError", "numpy.asarray", "len", "len"], "function", ["None"], ["", "", "def", "pad_sequences", "(", "sequences", ",", "maxlen", "=", "None", ",", "dtype", "=", "'int32'", ",", "padding", "=", "'post'", ",", "truncating", "=", "'pre'", ",", "value", "=", "0.", ")", ":", "\n", "    ", "\"\"\"Pads each sequence to the same length:\n    the length of the longest sequence.\n    If maxlen is provided, any sequence longer\n    than maxlen is truncated to maxlen.\n    Truncation happens off either the beginning (default) or\n    the end of the sequence.\n    Supports post-padding and pre-padding (default).\n\n    Parameters\n    ----------\n    sequences : list of lists where each element is a sequence\n    maxlen : int, maximum length\n    dtype : type to cast the resulting sequence.\n    padding : 'pre' or 'post', pad either before or after each sequence.\n    truncating : 'pre' or 'post', remove values from sequences larger than\n        maxlen either in the beginning or in the end of the sequence\n    value : float, value to pad the sequences to the desired value.\n\n    Returns\n    ----------\n    x : numpy array with dimensions (number_of_sequences, maxlen)\n\n    Examples\n    ----------\n    >>> sequences = [[1,1,1,1,1],[2,2,2],[3,3]]\n    >>> sequences = pad_sequences(sequences, maxlen=None, dtype='int32',\n    ...                  padding='post', truncating='pre', value=0.)\n    ... [[1 1 1 1 1]\n    ...  [2 2 2 0 0]\n    ...  [3 3 0 0 0]]\n    \"\"\"", "\n", "lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "sequences", "]", "\n", "\n", "nb_samples", "=", "len", "(", "sequences", ")", "\n", "if", "maxlen", "is", "None", ":", "\n", "        ", "maxlen", "=", "np", ".", "max", "(", "lengths", ")", "\n", "\n", "# take the sample shape from the first non empty sequence", "\n", "# checking for consistency in the main loop below.", "\n", "", "sample_shape", "=", "tuple", "(", ")", "\n", "for", "s", "in", "sequences", ":", "\n", "        ", "if", "len", "(", "s", ")", ">", "0", ":", "\n", "            ", "sample_shape", "=", "np", ".", "asarray", "(", "s", ")", ".", "shape", "[", "1", ":", "]", "\n", "break", "\n", "\n", "", "", "x", "=", "(", "np", ".", "ones", "(", "(", "nb_samples", ",", "maxlen", ")", "+", "sample_shape", ")", "*", "value", ")", ".", "astype", "(", "dtype", ")", "\n", "for", "idx", ",", "s", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "if", "len", "(", "s", ")", "==", "0", ":", "\n", "            ", "continue", "# empty list was found", "\n", "", "if", "truncating", "==", "'pre'", ":", "\n", "            ", "trunc", "=", "s", "[", "-", "maxlen", ":", "]", "\n", "", "elif", "truncating", "==", "'post'", ":", "\n", "            ", "trunc", "=", "s", "[", ":", "maxlen", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Truncating type \"%s\" not understood'", "%", "truncating", ")", "\n", "\n", "# check `trunc` has expected shape", "\n", "", "trunc", "=", "np", ".", "asarray", "(", "trunc", ",", "dtype", "=", "dtype", ")", "\n", "if", "trunc", ".", "shape", "[", "1", ":", "]", "!=", "sample_shape", ":", "\n", "            ", "raise", "ValueError", "(", "'Shape of sample %s of sequence at position %s is different from expected shape %s'", "%", "\n", "(", "trunc", ".", "shape", "[", "1", ":", "]", ",", "idx", ",", "sample_shape", ")", ")", "\n", "\n", "", "if", "padding", "==", "'post'", ":", "\n", "            ", "x", "[", "idx", ",", ":", "len", "(", "trunc", ")", "]", "=", "trunc", "\n", "", "elif", "padding", "==", "'pre'", ":", "\n", "            ", "x", "[", "idx", ",", "-", "len", "(", "trunc", ")", ":", "]", "=", "trunc", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Padding type \"%s\" not understood'", "%", "padding", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.process_sequences": [[1283, 1323], ["enumerate", "enumerate", "enumerate"], "function", ["None"], ["", "def", "process_sequences", "(", "sequences", ",", "end_id", "=", "0", ",", "pad_val", "=", "0", ",", "is_shorten", "=", "True", ",", "remain_end_id", "=", "False", ")", ":", "\n", "    ", "\"\"\"Set all tokens(ids) after END token to the padding value, and then shorten (option) it to the maximum sequence length in this batch.\n\n    Parameters\n    -----------\n    sequences : numpy array or list of list with token IDs.\n        e.g. [[4,3,5,3,2,2,2,2], [5,3,9,4,9,2,2,3]]\n    end_id : int, the special token for END.\n    pad_val : int, replace the end_id and the ids after end_id to this value.\n    is_shorten : boolean, default True.\n        Shorten the sequences.\n    remain_end_id : boolean, default False.\n        Keep an end_id in the end.\n\n    Examples\n    ---------\n    >>> sentences_ids = [[4, 3, 5, 3, 2, 2, 2, 2],  <-- end_id is 2\n    ...                  [5, 3, 9, 4, 9, 2, 2, 3]]  <-- end_id is 2\n    >>> sentences_ids = precess_sequences(sentences_ids, end_id=vocab.end_id, pad_val=0, is_shorten=True)\n    ... [[4, 3, 5, 3, 0], [5, 3, 9, 4, 9]]\n    \"\"\"", "\n", "max_length", "=", "0", "\n", "for", "i_s", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "is_end", "=", "False", "\n", "for", "i_w", ",", "n", "in", "enumerate", "(", "seq", ")", ":", "\n", "            ", "if", "n", "==", "end_id", "and", "is_end", "==", "False", ":", "# 1st time to see end_id", "\n", "                ", "is_end", "=", "True", "\n", "if", "max_length", "<", "i_w", ":", "\n", "                    ", "max_length", "=", "i_w", "\n", "", "if", "remain_end_id", "is", "False", ":", "\n", "                    ", "seq", "[", "i_w", "]", "=", "pad_val", "# set end_id to pad_val", "\n", "", "", "elif", "is_end", "==", "True", ":", "\n", "                ", "seq", "[", "i_w", "]", "=", "pad_val", "\n", "\n", "", "", "", "if", "remain_end_id", "is", "True", ":", "\n", "        ", "max_length", "+=", "1", "\n", "", "if", "is_shorten", ":", "\n", "        ", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "            ", "sequences", "[", "i", "]", "=", "seq", "[", ":", "max_length", "]", "\n", "", "", "return", "sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.sequences_add_start_id": [[1324, 1347], ["six.moves.range", "len", "six.moves.range", "len"], "function", ["None"], ["", "def", "sequences_add_start_id", "(", "sequences", ",", "start_id", "=", "0", ",", "remove_last", "=", "False", ")", ":", "\n", "    ", "\"\"\"Add special start token(id) in the beginning of each sequence.\n\n    Examples\n    ---------\n    >>> sentences_ids = [[4,3,5,3,2,2,2,2], [5,3,9,4,9,2,2,3]]\n    >>> sentences_ids = sequences_add_start_id(sentences_ids, start_id=2)\n    ... [[2, 4, 3, 5, 3, 2, 2, 2, 2], [2, 5, 3, 9, 4, 9, 2, 2, 3]]\n    >>> sentences_ids = sequences_add_start_id(sentences_ids, start_id=2, remove_last=True)\n    ... [[2, 4, 3, 5, 3, 2, 2, 2], [2, 5, 3, 9, 4, 9, 2, 2]]\n\n    - For Seq2seq\n    >>> input = [a, b, c]\n    >>> target = [x, y, z]\n    >>> decode_seq = [start_id, a, b] <-- sequences_add_start_id(input, start_id, True)\n    \"\"\"", "\n", "sequences_out", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "sequences", ")", ")", "]", "#[[]] * len(sequences)", "\n", "for", "i", "in", "range", "(", "len", "(", "sequences", ")", ")", ":", "\n", "        ", "if", "remove_last", ":", "\n", "            ", "sequences_out", "[", "i", "]", "=", "[", "start_id", "]", "+", "sequences", "[", "i", "]", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "sequences_out", "[", "i", "]", "=", "[", "start_id", "]", "+", "sequences", "[", "i", "]", "\n", "", "", "return", "sequences_out", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.sequences_get_mask": [[1348, 1367], ["numpy.ones_like", "enumerate", "reversed", "list", "six.moves.range", "len"], "function", ["None"], ["", "def", "sequences_get_mask", "(", "sequences", ",", "pad_val", "=", "0", ")", ":", "\n", "    ", "\"\"\"Return mask for sequences.\n\n    Examples\n    ---------\n    >>> sentences_ids = [[4, 0, 5, 3, 0, 0],\n    ...                  [5, 3, 9, 4, 9, 0]]\n    >>> mask = sequences_get_mask(sentences_ids, pad_val=0)\n    ... [[1 1 1 1 0 0]\n    ...  [1 1 1 1 1 0]]\n    \"\"\"", "\n", "mask", "=", "np", ".", "ones_like", "(", "sequences", ")", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "for", "i_w", "in", "reversed", "(", "list", "(", "range", "(", "len", "(", "seq", ")", ")", ")", ")", ":", "\n", "            ", "if", "seq", "[", "i_w", "]", "==", "pad_val", ":", "\n", "                ", "mask", "[", "i", ",", "i_w", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "break", "# <-- exit the for loop, prepcess next sequence", "\n", "", "", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.distorted_images": [[1374, 1459], ["print", "exit", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.while_loop", "int", "tensorflow.constant", "tensorflow.constant", "tensorflow.less", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.per_image_standardization", "tensorflow.expand_dims", "Exception", "tensorflow.gather", "tensorflow.concat", "tensorflow.add"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.constant", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.constant"], ["", "def", "distorted_images", "(", "images", "=", "None", ",", "height", "=", "24", ",", "width", "=", "24", ")", ":", "\n", "    ", "\"\"\"Distort images for generating more training data.\n\n    Features\n    ---------\n    They are cropped to height * width pixels randomly.\n\n    They are approximately whitened to make the model insensitive to dynamic range.\n\n    Randomly flip the image from left to right.\n\n    Randomly distort the image brightness.\n\n    Randomly distort the image contrast.\n\n    Whiten (Normalize) the images.\n\n    Parameters\n    ----------\n    images : 4D Tensor\n        The tensor or placeholder of images\n    height : int\n        The height for random crop.\n    width : int\n        The width for random crop.\n\n    Returns\n    -------\n    result : tuple of Tensor\n        (Tensor for distorted images, Tensor for while loop index)\n\n    Examples\n    --------\n    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)\n    >>> sess = tf.InteractiveSession()\n    >>> batch_size = 128\n    >>> x = tf.compat.v1.placeholder(tf.float32, shape=[batch_size, 32, 32, 3])\n    >>> distorted_images_op = tl.preprocess.distorted_images(images=x, height=24, width=24)\n    >>> sess.run(tf.initialize_all_variables())\n    >>> feed_dict={x: X_train[0:batch_size,:,:,:]}\n    >>> distorted_images, idx = sess.run(distorted_images_op, feed_dict=feed_dict)\n    >>> tl.visualize.images2d(X_train[0:9,:,:,:], second=2, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)\n    >>> tl.visualize.images2d(distorted_images[1:10,:,:,:], second=10, saveable=False, name='distorted_images', dtype=None, fig_idx=23012)\n\n    Notes\n    ------\n    - The first image in 'distorted_images' should be removed.\n\n    References\n    -----------\n    - `tensorflow.models.image.cifar10.cifar10_input <https://github.com/tensorflow/tensorflow/blob/r0.9/tensorflow/models/image/cifar10/cifar10_input.py>`_\n    \"\"\"", "\n", "print", "(", "\"This function is deprecated, please use tf.map_fn instead, e.g:\\n   \\\n            t_image = tf.map_fn(lambda img: tf.image.random_brightness(img, max_delta=32. / 255.), t_image)\\n \\\n            t_image = tf.map_fn(lambda img: tf.image.random_contrast(img, lower=0.5, upper=1.5), t_image)\\n \\\n            t_image = tf.map_fn(lambda img: tf.image.random_saturation(img, lower=0.5, upper=1.5), t_image)\\n \\\n            t_image = tf.map_fn(lambda img: tf.image.random_hue(img, max_delta=0.032), t_image)\"", ")", "\n", "exit", "(", ")", "\n", "# print(\" [Warning] distorted_images will be deprecated due to speed, see TFRecord tutorial for more info...\")", "\n", "try", ":", "\n", "        ", "batch_size", "=", "int", "(", "images", ".", "_shape", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "        ", "raise", "Exception", "(", "'unknow batch_size of images'", ")", "\n", "", "distorted_x", "=", "tf", ".", "Variable", "(", "tf", ".", "constant", "(", "0.1", ",", "shape", "=", "[", "1", ",", "height", ",", "width", ",", "3", "]", ")", ")", "\n", "i", "=", "tf", ".", "Variable", "(", "tf", ".", "constant", "(", "0", ")", ")", "\n", "\n", "c", "=", "lambda", "distorted_x", ",", "i", ":", "tf", ".", "less", "(", "i", ",", "batch_size", ")", "\n", "\n", "def", "body", "(", "distorted_x", ",", "i", ")", ":", "\n", "# 1. Randomly crop a [height, width] section of the image.", "\n", "        ", "image", "=", "tf", ".", "random_crop", "(", "tf", ".", "gather", "(", "images", ",", "i", ")", ",", "[", "height", ",", "width", ",", "3", "]", ")", "\n", "# 2. Randomly flip the image horizontally.", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "# 3. Randomly change brightness.", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "63", ")", "\n", "# 4. Randomly change contrast.", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "# 5. Subtract off the mean and divide by the variance of the pixels.", "\n", "image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", "\n", "# 6. Append the image to a batch.", "\n", "image", "=", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "return", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "[", "distorted_x", ",", "image", "]", ")", ",", "tf", ".", "add", "(", "i", ",", "1", ")", "\n", "\n", "", "result", "=", "tf", ".", "while_loop", "(", "cond", "=", "c", ",", "body", "=", "body", ",", "loop_vars", "=", "(", "distorted_x", ",", "i", ")", ",", "parallel_iterations", "=", "16", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.crop_central_whiten_images": [[1461, 1530], ["print", "exit", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.while_loop", "int", "tensorflow.constant", "tensorflow.constant", "tensorflow.less", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.image.per_image_standardization", "tensorflow.expand_dims", "Exception", "tensorflow.gather", "tensorflow.concat", "tensorflow.add"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.constant", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.prepro.constant"], ["", "def", "crop_central_whiten_images", "(", "images", "=", "None", ",", "height", "=", "24", ",", "width", "=", "24", ")", ":", "\n", "    ", "\"\"\"Crop the central of image, and normailize it for test data.\n\n    They are cropped to central of height * width pixels.\n\n    Whiten (Normalize) the images.\n\n    Parameters\n    ----------\n    images : 4D Tensor\n        The tensor or placeholder of images\n    height : int\n        The height for central crop.\n    width : int\n        The width for central crop.\n\n    Returns\n    -------\n    result : tuple Tensor\n        (Tensor for distorted images, Tensor for while loop index)\n\n    Examples\n    --------\n    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)\n    >>> sess = tf.InteractiveSession()\n    >>> batch_size = 128\n    >>> x = tf.compat.v1.placeholder(tf.float32, shape=[batch_size, 32, 32, 3])\n    >>> central_images_op = tl.preprocess.crop_central_whiten_images(images=x, height=24, width=24)\n    >>> sess.run(tf.initialize_all_variables())\n    >>> feed_dict={x: X_train[0:batch_size,:,:,:]}\n    >>> central_images, idx = sess.run(central_images_op, feed_dict=feed_dict)\n    >>> tl.visualize.images2d(X_train[0:9,:,:,:], second=2, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)\n    >>> tl.visualize.images2d(central_images[1:10,:,:,:], second=10, saveable=False, name='central_images', dtype=None, fig_idx=23012)\n\n    Notes\n    ------\n    The first image in 'central_images' should be removed.\n\n    Code References\n    ----------------\n    - ``tensorflow.models.image.cifar10.cifar10_input``\n    \"\"\"", "\n", "print", "(", "\"This function is deprecated, please use tf.map_fn instead, e.g:\\n   \\\n            t_image = tf.map_fn(lambda img: tf.image.random_brightness(img, max_delta=32. / 255.), t_image)\\n \\\n            t_image = tf.map_fn(lambda img: tf.image.random_contrast(img, lower=0.5, upper=1.5), t_image)\\n \\\n            t_image = tf.map_fn(lambda img: tf.image.random_saturation(img, lower=0.5, upper=1.5), t_image)\\n \\\n            t_image = tf.map_fn(lambda img: tf.image.random_hue(img, max_delta=0.032), t_image)\"", ")", "\n", "exit", "(", ")", "\n", "# print(\" [Warning] crop_central_whiten_images will be deprecated due to speed, see TFRecord tutorial for more info...\")", "\n", "try", ":", "\n", "        ", "batch_size", "=", "int", "(", "images", ".", "_shape", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "        ", "raise", "Exception", "(", "'unknow batch_size of images'", ")", "\n", "", "central_x", "=", "tf", ".", "Variable", "(", "tf", ".", "constant", "(", "0.1", ",", "shape", "=", "[", "1", ",", "height", ",", "width", ",", "3", "]", ")", ")", "\n", "i", "=", "tf", ".", "Variable", "(", "tf", ".", "constant", "(", "0", ")", ")", "\n", "\n", "c", "=", "lambda", "central_x", ",", "i", ":", "tf", ".", "less", "(", "i", ",", "batch_size", ")", "\n", "\n", "def", "body", "(", "central_x", ",", "i", ")", ":", "\n", "# 1. Crop the central [height, width] of the image.", "\n", "        ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "tf", ".", "gather", "(", "images", ",", "i", ")", ",", "height", ",", "width", ")", "\n", "# 2. Subtract off the mean and divide by the variance of the pixels.", "\n", "image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", "\n", "# 5. Append the image to a batch.", "\n", "image", "=", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "return", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "[", "central_x", ",", "image", "]", ")", ",", "tf", ".", "add", "(", "i", ",", "1", ")", "\n", "\n", "", "result", "=", "tf", ".", "while_loop", "(", "cond", "=", "c", ",", "body", "=", "body", ",", "loop_vars", "=", "(", "central_x", ",", "i", ")", ",", "parallel_iterations", "=", "16", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.SimpleVocabulary.__init__": [[179, 185], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_id", ")", ":", "\n", "    ", "\"\"\"Initializes the vocabulary.\"\"\"", "\n", "\n", "\n", "self", ".", "_vocab", "=", "vocab", "\n", "self", ".", "_unk_id", "=", "unk_id", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.SimpleVocabulary.word_to_id": [[186, 192], ["None"], "methods", ["None"], ["", "def", "word_to_id", "(", "self", ",", "word", ")", ":", "\n", "    ", "\"\"\"Returns the integer id of a word string.\"\"\"", "\n", "if", "word", "in", "self", ".", "_vocab", ":", "\n", "      ", "return", "self", ".", "_vocab", "[", "word", "]", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "_unk_id", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.Vocabulary.__init__": [[231, 266], ["tensorflow.logging.info", "dict", "print", "print", "print", "print", "print", "print", "tensorflow.gfile.Exists", "tensorflow.logging.fatal", "tensorflow.gfile.GFile", "list", "list.append", "f.readlines", "line.split", "len", "enumerate"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_file", ",", "\n", "start_word", "=", "\"<S>\"", ",", "\n", "end_word", "=", "\"</S>\"", ",", "\n", "unk_word", "=", "\"<UNK>\"", ",", "\n", "pad_word", "=", "\"<PAD>\"", ")", ":", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "vocab_file", ")", ":", "\n", "      ", "tf", ".", "logging", ".", "fatal", "(", "\"Vocab file %s not found.\"", ",", "vocab_file", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Initializing vocabulary from file: %s\"", ",", "vocab_file", ")", "\n", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "vocab_file", ",", "mode", "=", "\"r\"", ")", "as", "f", ":", "\n", "      ", "reverse_vocab", "=", "list", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "reverse_vocab", "=", "[", "line", ".", "split", "(", ")", "[", "0", "]", "for", "line", "in", "reverse_vocab", "]", "\n", "assert", "start_word", "in", "reverse_vocab", "\n", "assert", "end_word", "in", "reverse_vocab", "\n", "if", "unk_word", "not", "in", "reverse_vocab", ":", "\n", "      ", "reverse_vocab", ".", "append", "(", "unk_word", ")", "\n", "", "vocab", "=", "dict", "(", "[", "(", "x", ",", "y", ")", "for", "(", "y", ",", "x", ")", "in", "enumerate", "(", "reverse_vocab", ")", "]", ")", "\n", "\n", "print", "(", "(", "\"  [TL] Vocabulary from %s : %s %s %s\"", "%", "(", "vocab_file", ",", "start_word", ",", "end_word", ",", "unk_word", ")", ")", ")", "\n", "print", "(", "(", "\"    vocabulary with %d words (includes start_word, end_word, unk_word)\"", "%", "len", "(", "vocab", ")", ")", ")", "\n", "# tf.logging.info(\"     vocabulary with %d words\" % len(vocab))", "\n", "\n", "self", ".", "vocab", "=", "vocab", "# vocab[word] = id", "\n", "self", ".", "reverse_vocab", "=", "reverse_vocab", "# reverse_vocab[id] = word", "\n", "\n", "# Save special word ids.", "\n", "self", ".", "start_id", "=", "vocab", "[", "start_word", "]", "\n", "self", ".", "end_id", "=", "vocab", "[", "end_word", "]", "\n", "self", ".", "unk_id", "=", "vocab", "[", "unk_word", "]", "\n", "self", ".", "pad_id", "=", "vocab", "[", "pad_word", "]", "\n", "print", "(", "(", "\"      start_id: %d\"", "%", "self", ".", "start_id", ")", ")", "\n", "print", "(", "(", "\"      end_id: %d\"", "%", "self", ".", "end_id", ")", ")", "\n", "print", "(", "(", "\"      unk_id: %d\"", "%", "self", ".", "unk_id", ")", ")", "\n", "print", "(", "(", "\"      pad_id: %d\"", "%", "self", ".", "pad_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.Vocabulary.word_to_id": [[267, 273], ["None"], "methods", ["None"], ["", "def", "word_to_id", "(", "self", ",", "word", ")", ":", "\n", "    ", "\"\"\"Returns the integer word id of a word string.\"\"\"", "\n", "if", "word", "in", "self", ".", "vocab", ":", "\n", "      ", "return", "self", ".", "vocab", "[", "word", "]", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "unk_id", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.Vocabulary.id_to_word": [[274, 280], ["len"], "methods", ["None"], ["", "", "def", "id_to_word", "(", "self", ",", "word_id", ")", ":", "\n", "    ", "\"\"\"Returns the word string of an integer word id.\"\"\"", "\n", "if", "word_id", ">=", "len", "(", "self", ".", "reverse_vocab", ")", ":", "\n", "      ", "return", "self", ".", "reverse_vocab", "[", "self", ".", "unk_id", "]", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "reverse_vocab", "[", "word_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.generate_skip_gram_batch": [[19, 92], ["numpy.ndarray", "numpy.ndarray", "collections.deque", "range", "range", "collections.deque.append", "range", "collections.deque.append", "len", "targets_to_avoid.append", "len", "random.randint"], "function", ["None"], ["def", "generate_skip_gram_batch", "(", "data", ",", "batch_size", ",", "num_skips", ",", "skip_window", ",", "data_index", "=", "0", ")", ":", "\n", "    ", "\"\"\"Generate a training batch for the Skip-Gram model.\n\n    Parameters\n    ----------\n    data : a list\n        To present context.\n    batch_size : an int\n        Batch size to return.\n    num_skips : an int\n        How many times to reuse an input to generate a label.\n    skip_window : an int\n        How many words to consider left and right.\n    data_index : an int\n        Index of the context location.\n        without using yield, this code use data_index to instead.\n\n    Returns\n    --------\n    batch : a list\n        Inputs\n    labels : a list\n        Labels\n    data_index : an int\n        Index of the context location.\n\n    Examples\n    --------\n    >>> Setting num_skips=2, skip_window=1, use the right and left words.\n    >>> In the same way, num_skips=4, skip_window=2 means use the nearby 4 words.\n\n    >>> data = [1,2,3,4,5,6,7,8,9,10,11]\n    >>> batch, labels, data_index = tl.nlp.generate_skip_gram_batch(data=data, batch_size=8, num_skips=2, skip_window=1, data_index=0)\n    >>> print(batch)\n    ... [2 2 3 3 4 4 5 5]\n    >>> print(labels)\n    ... [[3]\n    ... [1]\n    ... [4]\n    ... [2]\n    ... [5]\n    ... [3]\n    ... [4]\n    ... [6]]\n\n    References\n    -----------\n    - `TensorFlow word2vec tutorial <https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html#vector-representations-of-words>`_\n    \"\"\"", "\n", "# global data_index   # you can put data_index outside the function, then", "\n", "#       modify the global data_index in the function without return it.", "\n", "# note: without using yield, this code use data_index to instead.", "\n", "assert", "batch_size", "%", "num_skips", "==", "0", "\n", "assert", "num_skips", "<=", "2", "*", "skip_window", "\n", "batch", "=", "np", ".", "ndarray", "(", "shape", "=", "(", "batch_size", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "labels", "=", "np", ".", "ndarray", "(", "shape", "=", "(", "batch_size", ",", "1", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "span", "=", "2", "*", "skip_window", "+", "1", "# [ skip_window target skip_window ]", "\n", "buffer", "=", "collections", ".", "deque", "(", "maxlen", "=", "span", ")", "\n", "for", "_", "in", "range", "(", "span", ")", ":", "\n", "        ", "buffer", ".", "append", "(", "data", "[", "data_index", "]", ")", "\n", "data_index", "=", "(", "data_index", "+", "1", ")", "%", "len", "(", "data", ")", "\n", "", "for", "i", "in", "range", "(", "batch_size", "//", "num_skips", ")", ":", "\n", "        ", "target", "=", "skip_window", "# target label at the center of the buffer", "\n", "targets_to_avoid", "=", "[", "skip_window", "]", "\n", "for", "j", "in", "range", "(", "num_skips", ")", ":", "\n", "            ", "while", "target", "in", "targets_to_avoid", ":", "\n", "                ", "target", "=", "random", ".", "randint", "(", "0", ",", "span", "-", "1", ")", "\n", "", "targets_to_avoid", ".", "append", "(", "target", ")", "\n", "batch", "[", "i", "*", "num_skips", "+", "j", "]", "=", "buffer", "[", "skip_window", "]", "\n", "labels", "[", "i", "*", "num_skips", "+", "j", ",", "0", "]", "=", "buffer", "[", "target", "]", "\n", "", "buffer", ".", "append", "(", "data", "[", "data_index", "]", ")", "\n", "data_index", "=", "(", "data_index", "+", "1", ")", "%", "len", "(", "data", ")", "\n", "", "return", "batch", ",", "labels", ",", "data_index", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.sample": [[95, 140], ["numpy.copy", "numpy.argmax", "numpy.argmax", "numpy.argmax", "warnings.warn", "numpy.argmax", "numpy.random.multinomial", "numpy.log", "numpy.exp", "numpy.sum", "numpy.random.multinomial", "numpy.random.multinomial", "numpy.exp"], "function", ["None"], ["", "def", "sample", "(", "a", "=", "[", "]", ",", "temperature", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Sample an index from a probability array.\n\n    Parameters\n    ----------\n    a : a list\n        List of probabilities.\n    temperature : float or None\n        The higher the more uniform.\\n\n        When a = [0.1, 0.2, 0.7],\\n\n            temperature = 0.7, the distribution will be sharpen [ 0.05048273  0.13588945  0.81362782]\\n\n            temperature = 1.0, the distribution will be the same [0.1    0.2    0.7]\\n\n            temperature = 1.5, the distribution will be filtered [ 0.16008435  0.25411807  0.58579758]\\n\n        If None, it will be ``np.argmax(a)``\n\n    Notes\n    ------\n    No matter what is the temperature and input list, the sum of all probabilities will be one.\n    Even if input list = [1, 100, 200], the sum of all probabilities will still be one.\n\n    For large vocabulary_size, choice a higher temperature to avoid error.\n    \"\"\"", "\n", "b", "=", "np", ".", "copy", "(", "a", ")", "\n", "try", ":", "\n", "        ", "if", "temperature", "==", "1", ":", "\n", "            ", "return", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "1", ",", "a", ",", "1", ")", ")", "\n", "", "if", "temperature", "is", "None", ":", "\n", "            ", "return", "np", ".", "argmax", "(", "a", ")", "\n", "", "else", ":", "\n", "            ", "a", "=", "np", ".", "log", "(", "a", ")", "/", "temperature", "\n", "a", "=", "np", ".", "exp", "(", "a", ")", "/", "np", ".", "sum", "(", "np", ".", "exp", "(", "a", ")", ")", "\n", "return", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "1", ",", "a", ",", "1", ")", ")", "\n", "", "", "except", ":", "\n", "# np.set_printoptions(threshold=np.nan)", "\n", "# print(a)", "\n", "# print(np.sum(a))", "\n", "# print(np.max(a))", "\n", "# print(np.min(a))", "\n", "# exit()", "\n", "        ", "message", "=", "\"For large vocabulary_size, choice a higher temperature\\\n         to avoid log error. Hint : use ``sample_top``. \"", "\n", "warnings", ".", "warn", "(", "message", ",", "Warning", ")", "\n", "# print(a)", "\n", "# print(b)", "\n", "return", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "1", ",", "b", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.sample_top": [[141, 157], ["numpy.random.choice", "numpy.argpartition", "numpy.sum"], "function", ["None"], ["", "", "def", "sample_top", "(", "a", "=", "[", "]", ",", "top_k", "=", "10", ")", ":", "\n", "    ", "\"\"\"Sample from ``top_k`` probabilities.\n\n    Parameters\n    ----------\n    a : a list\n        List of probabilities.\n    top_k : int\n        Number of candidates to be considered.\n    \"\"\"", "\n", "idx", "=", "np", ".", "argpartition", "(", "a", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "probs", "=", "a", "[", "idx", "]", "\n", "# print(\"new\", probs)", "\n", "probs", "=", "probs", "/", "np", ".", "sum", "(", "probs", ")", "\n", "choice", "=", "np", ".", "random", ".", "choice", "(", "idx", ",", "p", "=", "probs", ")", "\n", "return", "choice", "\n", "## old implementation", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.process_sentence": [[281, 314], ["process_sentence.extend", "nltk.tokenize.word_tokenize", "process_sentence.append", "Exception", "sentence.lower"], "function", ["None"], ["", "", "", "def", "process_sentence", "(", "sentence", ",", "start_word", "=", "\"<S>\"", ",", "end_word", "=", "\"</S>\"", ")", ":", "\n", "    ", "\"\"\"Converts a sentence string into a list of string words, add start_word and end_word,\n    see ``create_vocab()`` and ``tutorial_tfrecord3.py``.\n\n    Parameter\n    ---------\n    sentence : a sentence in string.\n    start_word : a string or None, if None, non start word will be appended.\n    end_word : a string or None, if None, non end word will be appended.\n\n    Returns\n    ---------\n    A list of strings; the processed caption.\n\n    Examples\n    -----------\n    >>> c = \"how are you?\"\n    >>> c = tl.nlp.process_sentence(c)\n    >>> print(c)\n    ... ['<S>', 'how', 'are', 'you', '?', '</S>']\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "nltk", "\n", "", "except", ":", "\n", "        ", "raise", "Exception", "(", "\"Hint : NLTK is required.\"", ")", "\n", "", "if", "start_word", "is", "not", "None", ":", "\n", "        ", "process_sentence", "=", "[", "start_word", "]", "\n", "", "else", ":", "\n", "        ", "process_sentence", "=", "[", "]", "\n", "", "process_sentence", ".", "extend", "(", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "sentence", ".", "lower", "(", ")", ")", ")", "\n", "if", "end_word", "is", "not", "None", ":", "\n", "        ", "process_sentence", ".", "append", "(", "end_word", ")", "\n", "", "return", "process_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.create_vocab": [[315, 388], ["print", "Counter", "print", "word_counts.sort", "print", "print", "len", "dict", "nlp.SimpleVocabulary", "Counter.update", "tensorflow.gfile.FastGFile", "f.write", "len", "list", "len", "Counter.items", "enumerate"], "function", ["None"], ["", "def", "create_vocab", "(", "sentences", ",", "word_counts_output_file", ",", "min_word_count", "=", "1", ")", ":", "\n", "    ", "\"\"\"Creates the vocabulary of word to word_id, see create_vocab() and ``tutorial_tfrecord3.py``.\n\n    The vocabulary is saved to disk in a text file of word counts. The id of each\n    word in the file is its corresponding 0-based line number.\n\n    Parameters\n    ------------\n    sentences : a list of lists of strings.\n    word_counts_output_file : A string\n        The file name.\n    min_word_count : a int\n        Minimum number of occurrences for a word.\n\n    Returns\n    --------\n    - tl.nlp.SimpleVocabulary object.\n\n    Mores\n    -----\n    - ``tl.nlp.build_vocab()``\n\n    Examples\n    --------\n    >>> captions = [\"one two , three\", \"four five five\"]\n    >>> processed_capts = []\n    >>> for c in captions:\n    >>>     c = tl.nlp.process_sentence(c, start_word=\"<S>\", end_word=\"</S>\")\n    >>>     processed_capts.append(c)\n    >>> print(processed_capts)\n    ...[['<S>', 'one', 'two', ',', 'three', '</S>'], ['<S>', 'four', 'five', 'five', '</S>']]\n\n    >>> tl.nlp.create_vocab(processed_capts, word_counts_output_file='vocab.txt', min_word_count=1)\n    ...   [TL] Creating vocabulary.\n    ...   Total words: 8\n    ...   Words in vocabulary: 8\n    ...   Wrote vocabulary file: vocab.txt\n    >>> vocab = tl.nlp.Vocabulary('vocab.txt', start_word=\"<S>\", end_word=\"</S>\", unk_word=\"<UNK>\")\n    ... INFO:tensorflow:Initializing vocabulary from file: vocab.txt\n    ... [TL] Vocabulary from vocab.txt : <S> </S> <UNK>\n    ... vocabulary with 10 words (includes start_word, end_word, unk_word)\n    ...     start_id: 2\n    ...     end_id: 3\n    ...     unk_id: 9\n    ...     pad_id: 0\n    \"\"\"", "\n", "from", "collections", "import", "Counter", "\n", "print", "(", "\"  [TL] Creating vocabulary.\"", ")", "\n", "counter", "=", "Counter", "(", ")", "\n", "for", "c", "in", "sentences", ":", "\n", "        ", "counter", ".", "update", "(", "c", ")", "\n", "# print('c',c)", "\n", "", "print", "(", "(", "\"    Total words: %d\"", "%", "len", "(", "counter", ")", ")", ")", "\n", "\n", "# Filter uncommon words and sort by descending count.", "\n", "word_counts", "=", "[", "x", "for", "x", "in", "list", "(", "counter", ".", "items", "(", ")", ")", "if", "x", "[", "1", "]", ">=", "min_word_count", "]", "\n", "word_counts", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "word_counts", "=", "[", "(", "\"<PAD>\"", ",", "0", ")", "]", "+", "word_counts", "# 1st id should be reserved for padding", "\n", "# print(word_counts)", "\n", "print", "(", "(", "\"    Words in vocabulary: %d\"", "%", "len", "(", "word_counts", ")", ")", ")", "\n", "\n", "# Write out the word counts file.", "\n", "with", "tf", ".", "gfile", ".", "FastGFile", "(", "word_counts_output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "[", "\"%s %d\"", "%", "(", "w", ",", "c", ")", "for", "w", ",", "c", "in", "word_counts", "]", ")", ")", "\n", "", "print", "(", "(", "\"    Wrote vocabulary file: %s\"", "%", "word_counts_output_file", ")", ")", "\n", "\n", "# Create the vocabulary dictionary.", "\n", "reverse_vocab", "=", "[", "x", "[", "0", "]", "for", "x", "in", "word_counts", "]", "\n", "unk_id", "=", "len", "(", "reverse_vocab", ")", "\n", "vocab_dict", "=", "dict", "(", "[", "(", "x", ",", "y", ")", "for", "(", "y", ",", "x", ")", "in", "enumerate", "(", "reverse_vocab", ")", "]", ")", "\n", "vocab", "=", "SimpleVocabulary", "(", "vocab_dict", ",", "unk_id", ")", "\n", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.simple_read_words": [[391, 406], ["open", "f.read"], "function", ["None"], ["", "def", "simple_read_words", "(", "filename", "=", "\"nietzsche.txt\"", ")", ":", "\n", "    ", "\"\"\"Read context from file without any preprocessing.\n\n    Parameters\n    ----------\n    filename : a string\n        A file path (like .txt file)\n\n    Returns\n    --------\n    The context in a string\n    \"\"\"", "\n", "with", "open", "(", "\"nietzsche.txt\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "words", "=", "f", ".", "read", "(", ")", "\n", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.read_words": [[407, 435], ["tensorflow.gfile.GFile", "f.read().replace().split", "f.seek", "f.read().replace().split", "f.read().replace", "x.encode", "f.read().replace", "f.read", "f.read"], "function", ["None"], ["", "", "def", "read_words", "(", "filename", "=", "\"nietzsche.txt\"", ",", "replace", "=", "[", "'\\n'", ",", "'<eos>'", "]", ")", ":", "\n", "    ", "\"\"\"File to list format context. Note that, this script can not handle punctuations.\n    For customized read_words method, see ``tutorial_generate_text.py``.\n\n    Parameters\n    ----------\n    filename : a string\n        A file path (like .txt file),\n    replace : a list\n        [original string, target string], to disable replace use ['', '']\n\n    Returns\n    --------\n    The context in a list, split by space by default, and use ``'<eos>'`` to represent ``'\\n'``,\n    e.g. ``[... 'how', 'useful', 'it', \"'s\" ... ]``.\n\n    Code References\n    ---------------\n    - `tensorflow.models.rnn.ptb.reader <https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/ptb>`_\n    \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "try", ":", "# python 3.4 or older", "\n", "            ", "context_list", "=", "f", ".", "read", "(", ")", ".", "replace", "(", "*", "replace", ")", ".", "split", "(", ")", "\n", "", "except", ":", "# python 3.5", "\n", "            ", "f", ".", "seek", "(", "0", ")", "\n", "replace", "=", "[", "x", ".", "encode", "(", "'utf-8'", ")", "for", "x", "in", "replace", "]", "\n", "context_list", "=", "f", ".", "read", "(", ")", ".", "replace", "(", "*", "replace", ")", ".", "split", "(", ")", "\n", "", "return", "context_list", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.read_analogies_file": [[436, 498], ["print", "print", "print", "numpy.array", "open", "line.startswith", "line.strip().lower().split", "len", "word2id.get", "questions.append", "line.strip().lower", "w.strip", "len", "numpy.array", "line.strip"], "function", ["None"], ["", "", "def", "read_analogies_file", "(", "eval_file", "=", "'questions-words.txt'", ",", "word2id", "=", "{", "}", ")", ":", "\n", "    ", "\"\"\"Reads through an analogy question file, return its id format.\n\n    Parameters\n    ----------\n    eval_data : a string\n        The file name.\n    word2id : a dictionary\n        Mapping words to unique IDs.\n\n    Returns\n    --------\n    analogy_questions : a [n, 4] numpy array containing the analogy question's\n             word ids.\n             questions_skipped: questions skipped due to unknown words.\n\n    Examples\n    ---------\n    >>> eval_file should be in this format :\n    >>> : capital-common-countries\n    >>> Athens Greece Baghdad Iraq\n    >>> Athens Greece Bangkok Thailand\n    >>> Athens Greece Beijing China\n    >>> Athens Greece Berlin Germany\n    >>> Athens Greece Bern Switzerland\n    >>> Athens Greece Cairo Egypt\n    >>> Athens Greece Canberra Australia\n    >>> Athens Greece Hanoi Vietnam\n    >>> Athens Greece Havana Cuba\n    ...\n\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\n    >>> data, count, dictionary, reverse_dictionary = \\\n                tl.nlp.build_words_dataset(words, vocabulary_size, True)\n    >>> analogy_questions = tl.nlp.read_analogies_file( \\\n                eval_file='questions-words.txt', word2id=dictionary)\n    >>> print(analogy_questions)\n    ... [[ 3068  1248  7161  1581]\n    ... [ 3068  1248 28683  5642]\n    ... [ 3068  1248  3878   486]\n    ... ...,\n    ... [ 1216  4309 19982 25506]\n    ... [ 1216  4309  3194  8650]\n    ... [ 1216  4309   140   312]]\n    \"\"\"", "\n", "questions", "=", "[", "]", "\n", "questions_skipped", "=", "0", "\n", "with", "open", "(", "eval_file", ",", "\"rb\"", ")", "as", "analogy_f", ":", "\n", "      ", "for", "line", "in", "analogy_f", ":", "\n", "          ", "if", "line", ".", "startswith", "(", "b\":\"", ")", ":", "# Skip comments.", "\n", "                ", "continue", "\n", "", "words", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", ".", "split", "(", "b\" \"", ")", "# lowercase", "\n", "ids", "=", "[", "word2id", ".", "get", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "words", "]", "\n", "if", "None", "in", "ids", "or", "len", "(", "ids", ")", "!=", "4", ":", "\n", "              ", "questions_skipped", "+=", "1", "\n", "", "else", ":", "\n", "              ", "questions", ".", "append", "(", "np", ".", "array", "(", "ids", ")", ")", "\n", "", "", "", "print", "(", "(", "\"Eval analogy file: \"", ",", "eval_file", ")", ")", "\n", "print", "(", "(", "\"Questions: \"", ",", "len", "(", "questions", ")", ")", ")", "\n", "print", "(", "(", "\"Skipped: \"", ",", "questions_skipped", ")", ")", "\n", "analogy_questions", "=", "np", ".", "array", "(", "questions", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "return", "analogy_questions", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.build_vocab": [[499, 535], ["collections.Counter", "sorted", "list", "dict", "list", "zip", "list", "collections.Counter.items", "zip", "list", "range", "len"], "function", ["None"], ["", "def", "build_vocab", "(", "data", ")", ":", "\n", "    ", "\"\"\"Build vocabulary.\n    Given the context in list format.\n    Return the vocabulary, which is a dictionary for word to id.\n    e.g. {'campbell': 2587, 'atlantic': 2247, 'aoun': 6746 .... }\n\n    Parameters\n    ----------\n    data : a list of string\n        the context in list format\n\n    Returns\n    --------\n    word_to_id : a dictionary\n        mapping words to unique IDs. e.g. {'campbell': 2587, 'atlantic': 2247, 'aoun': 6746 .... }\n\n    Code References\n    ---------------\n    - `tensorflow.models.rnn.ptb.reader <https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/ptb>`_\n\n    Examples\n    --------\n    >>> data_path = os.getcwd() + '/simple-examples/data'\n    >>> train_path = os.path.join(data_path, \"ptb.train.txt\")\n    >>> word_to_id = build_vocab(read_txt_words(train_path))\n    \"\"\"", "\n", "# data = _read_words(filename)", "\n", "counter", "=", "collections", ".", "Counter", "(", "data", ")", "\n", "# print('counter', counter)   # dictionary for the occurrence number of each word, e.g. 'banknote': 1, 'photography': 1, 'kia': 1", "\n", "count_pairs", "=", "sorted", "(", "list", "(", "counter", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "# print('count_pairs',count_pairs)  # convert dictionary to list of tuple, e.g. ('ssangyong', 1), ('swapo', 1), ('wachter', 1)", "\n", "words", ",", "_", "=", "list", "(", "zip", "(", "*", "count_pairs", ")", ")", "\n", "word_to_id", "=", "dict", "(", "list", "(", "zip", "(", "words", ",", "list", "(", "range", "(", "len", "(", "words", ")", ")", ")", ")", ")", ")", "\n", "# print(words)    # list of words", "\n", "# print(word_to_id) # dictionary for word to id, e.g. 'campbell': 2587, 'atlantic': 2247, 'aoun': 6746", "\n", "return", "word_to_id", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.build_reverse_dictionary": [[536, 552], ["dict", "list", "zip", "list", "list", "word_to_id.values", "word_to_id.keys"], "function", ["None"], ["", "def", "build_reverse_dictionary", "(", "word_to_id", ")", ":", "\n", "    ", "\"\"\"Given a dictionary for converting word to integer id.\n    Returns a reverse dictionary for converting a id to word.\n\n    Parameters\n    ----------\n    word_to_id : dictionary\n        mapping words to unique ids\n\n    Returns\n    --------\n    reverse_dictionary : a dictionary\n        mapping ids to words\n    \"\"\"", "\n", "reverse_dictionary", "=", "dict", "(", "list", "(", "zip", "(", "list", "(", "word_to_id", ".", "values", "(", ")", ")", ",", "list", "(", "word_to_id", ".", "keys", "(", ")", ")", ")", ")", ")", "\n", "return", "reverse_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.build_words_dataset": [[553, 616], ["count.extend", "dict", "list", "dict", "collections.Counter().most_common", "len", "list.append", "list", "print", "print", "len", "zip", "list", "collections.Counter", "list", "list", "len", "collections.Counter().keys", "dict.values", "dict.keys", "list", "collections.Counter().keys", "collections.Counter", "collections.Counter"], "function", ["None"], ["", "def", "build_words_dataset", "(", "words", "=", "[", "]", ",", "vocabulary_size", "=", "50000", ",", "printable", "=", "True", ",", "unk_key", "=", "'UNK'", ")", ":", "\n", "    ", "\"\"\"Build the words dictionary and replace rare words with 'UNK' token.\n    The most common word has the smallest integer id.\n\n    Parameters\n    ----------\n    words : a list of string or byte\n        The context in list format. You may need to do preprocessing on the words,\n        such as lower case, remove marks etc.\n    vocabulary_size : an int\n        The maximum vocabulary size, limiting the vocabulary size.\n        Then the script replaces rare words with 'UNK' token.\n    printable : boolean\n        Whether to print the read vocabulary size of the given words.\n    unk_key : a string\n        Unknown words = unk_key\n\n    Returns\n    --------\n    data : a list of integer\n        The context in a list of ids\n    count : a list of tuple and list\n        count[0] is a list : the number of rare words\\n\n        count[1:] are tuples : the number of occurrence of each word\\n\n        e.g. [['UNK', 418391], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764)]\n    dictionary : a dictionary\n        word_to_id, mapping words to unique IDs.\n    reverse_dictionary : a dictionary\n        id_to_word, mapping id to unique word.\n\n    Examples\n    --------\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\n    >>> vocabulary_size = 50000\n    >>> data, count, dictionary, reverse_dictionary = tl.nlp.build_words_dataset(words, vocabulary_size)\n\n    Code References\n    -----------------\n    - `tensorflow/examples/tutorials/word2vec/word2vec_basic.py <https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/word2vec/word2vec_basic.py>`_\n    \"\"\"", "\n", "import", "collections", "\n", "count", "=", "[", "[", "unk_key", ",", "-", "1", "]", "]", "\n", "count", ".", "extend", "(", "collections", ".", "Counter", "(", "words", ")", ".", "most_common", "(", "vocabulary_size", "-", "1", ")", ")", "\n", "dictionary", "=", "dict", "(", ")", "\n", "for", "word", ",", "_", "in", "count", ":", "\n", "        ", "dictionary", "[", "word", "]", "=", "len", "(", "dictionary", ")", "\n", "", "data", "=", "list", "(", ")", "\n", "unk_count", "=", "0", "\n", "for", "word", "in", "words", ":", "\n", "        ", "if", "word", "in", "dictionary", ":", "\n", "            ", "index", "=", "dictionary", "[", "word", "]", "\n", "", "else", ":", "\n", "            ", "index", "=", "0", "# dictionary['UNK']", "\n", "unk_count", "+=", "1", "\n", "", "data", ".", "append", "(", "index", ")", "\n", "", "count", "[", "0", "]", "[", "1", "]", "=", "unk_count", "\n", "reverse_dictionary", "=", "dict", "(", "list", "(", "zip", "(", "list", "(", "dictionary", ".", "values", "(", ")", ")", ",", "list", "(", "dictionary", ".", "keys", "(", ")", ")", ")", ")", ")", "\n", "if", "printable", ":", "\n", "        ", "print", "(", "(", "'Real vocabulary size    %d'", "%", "len", "(", "list", "(", "collections", ".", "Counter", "(", "words", ")", ".", "keys", "(", ")", ")", ")", ")", ")", "\n", "print", "(", "(", "'Limited vocabulary size {}'", ".", "format", "(", "vocabulary_size", ")", ")", ")", "\n", "", "assert", "len", "(", "list", "(", "collections", ".", "Counter", "(", "words", ")", ".", "keys", "(", ")", ")", ")", ">=", "vocabulary_size", ",", "\"the limited vocabulary_size must be less than or equal to the read vocabulary_size\"", "\n", "return", "data", ",", "count", ",", "dictionary", ",", "reverse_dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.words_to_word_ids": [[617, 667], ["word_to_id.get", "word_ids.append", "word_ids.append"], "function", ["None"], ["", "def", "words_to_word_ids", "(", "data", "=", "[", "]", ",", "word_to_id", "=", "{", "}", ",", "unk_key", "=", "'UNK'", ")", ":", "\n", "    ", "\"\"\"Given a context (words) in list format and the vocabulary,\n    Returns a list of IDs to represent the context.\n\n    Parameters\n    ----------\n    data : a list of string or byte\n        the context in list format\n    word_to_id : a dictionary\n        mapping words to unique IDs.\n    unk_key : a string\n        Unknown words = unk_key\n\n    Returns\n    --------\n    A list of IDs to represent the context.\n\n    Examples\n    --------\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\n    >>> vocabulary_size = 50000\n    >>> data, count, dictionary, reverse_dictionary = \\\n    ...         tl.nlp.build_words_dataset(words, vocabulary_size, True)\n    >>> context = [b'hello', b'how', b'are', b'you']\n    >>> ids = tl.nlp.words_to_word_ids(words, dictionary)\n    >>> context = tl.nlp.word_ids_to_words(ids, reverse_dictionary)\n    >>> print(ids)\n    ... [6434, 311, 26, 207]\n    >>> print(context)\n    ... [b'hello', b'how', b'are', b'you']\n\n    Code References\n    ---------------\n    - `tensorflow.models.rnn.ptb.reader <https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn/ptb>`_\n    \"\"\"", "\n", "# if isinstance(data[0], six.string_types):", "\n", "#     print(type(data[0]))", "\n", "#     # exit()", "\n", "#     print(data[0])", "\n", "#     print(word_to_id)", "\n", "#     return [word_to_id[str(word)] for word in data]", "\n", "# else:", "\n", "\n", "word_ids", "=", "[", "]", "\n", "for", "word", "in", "data", ":", "\n", "        ", "if", "word_to_id", ".", "get", "(", "word", ")", "is", "not", "None", ":", "\n", "            ", "word_ids", ".", "append", "(", "word_to_id", "[", "word", "]", ")", "\n", "", "else", ":", "\n", "            ", "word_ids", ".", "append", "(", "word_to_id", "[", "unk_key", "]", ")", "\n", "", "", "return", "word_ids", "\n", "# return [word_to_id[word] for word in data]    # this one", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.word_ids_to_words": [[677, 697], ["None"], "function", ["None"], ["", "def", "word_ids_to_words", "(", "data", ",", "id_to_word", ")", ":", "\n", "    ", "\"\"\"Given a context (ids) in list format and the vocabulary,\n    Returns a list of words to represent the context.\n\n    Parameters\n    ----------\n    data : a list of integer\n        the context in list format\n    id_to_word : a dictionary\n        mapping id to unique word.\n\n    Returns\n    --------\n    A list of string or byte to represent the context.\n\n    Examples\n    ---------\n    >>> see words_to_word_ids\n    \"\"\"", "\n", "return", "[", "id_to_word", "[", "i", "]", "for", "i", "in", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.save_vocab": [[698, 731], ["os.getcwd", "len", "print", "open", "range", "os.path.join", "f.write", "tensorflow.compat.as_text"], "function", ["None"], ["", "def", "save_vocab", "(", "count", "=", "[", "]", ",", "name", "=", "'vocab.txt'", ")", ":", "\n", "    ", "\"\"\"Save the vocabulary to a file so the model can be reloaded.\n\n    Parameters\n    ----------\n    count : a list of tuple and list\n        count[0] is a list : the number of rare words\\n\n        count[1:] are tuples : the number of occurrence of each word\\n\n        e.g. [['UNK', 418391], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764)]\n\n    Examples\n    ---------\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\n    >>> vocabulary_size = 50000\n    >>> data, count, dictionary, reverse_dictionary = \\\n    ...     tl.nlp.build_words_dataset(words, vocabulary_size, True)\n    >>> tl.nlp.save_vocab(count, name='vocab_text8.txt')\n    >>> vocab_text8.txt\n    ... UNK 418391\n    ... the 1061396\n    ... of 593677\n    ... and 416629\n    ... one 411764\n    ... in 372201\n    ... a 325873\n    ... to 316376\n    \"\"\"", "\n", "pwd", "=", "os", ".", "getcwd", "(", ")", "\n", "vocabulary_size", "=", "len", "(", "count", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "pwd", ",", "name", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "vocabulary_size", ")", ":", "\n", "            ", "f", ".", "write", "(", "\"%s %d\\n\"", "%", "(", "tf", ".", "compat", ".", "as_text", "(", "count", "[", "i", "]", "[", "0", "]", ")", ",", "count", "[", "i", "]", "[", "1", "]", ")", ")", "\n", "", "", "print", "(", "(", "\"%d vocab saved to %s in %s\"", "%", "(", "vocabulary_size", ",", "name", ",", "pwd", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.basic_tokenizer": [[733, 767], ["re.compile", "tensorflow.compat.as_bytes", "tf.compat.as_bytes.strip().split", "words.extend", "tf.compat.as_bytes.strip", "re.split"], "function", ["None"], ["", "def", "basic_tokenizer", "(", "sentence", ",", "_WORD_SPLIT", "=", "re", ".", "compile", "(", "b\"([.,!?\\\"':;)(])\"", ")", ")", ":", "\n", "  ", "\"\"\"Very basic tokenizer: split the sentence into a list of tokens.\n\n  Parameters\n  -----------\n  sentence : tensorflow.python.platform.gfile.GFile Object\n  _WORD_SPLIT : regular expression for word spliting.\n\n\n  Examples\n  --------\n  >>> see create_vocabulary\n  >>> from tensorflow.python.platform import gfile\n  >>> train_path = \"wmt/giga-fren.release2\"\n  >>> with gfile.GFile(train_path + \".en\", mode=\"rb\") as f:\n  >>>    for line in f:\n  >>>       tokens = tl.nlp.basic_tokenizer(line)\n  >>>       print(tokens)\n  >>>       exit()\n  ... [b'Changing', b'Lives', b'|', b'Changing', b'Society', b'|', b'How',\n  ...   b'It', b'Works', b'|', b'Technology', b'Drives', b'Change', b'Home',\n  ...   b'|', b'Concepts', b'|', b'Teachers', b'|', b'Search', b'|', b'Overview',\n  ...   b'|', b'Credits', b'|', b'HHCC', b'Web', b'|', b'Reference', b'|',\n  ...   b'Feedback', b'Virtual', b'Museum', b'of', b'Canada', b'Home', b'Page']\n\n  References\n  ----------\n  - Code from ``/tensorflow/models/rnn/translation/data_utils.py``\n  \"\"\"", "\n", "words", "=", "[", "]", "\n", "sentence", "=", "tf", ".", "compat", ".", "as_bytes", "(", "sentence", ")", "\n", "for", "space_separated_fragment", "in", "sentence", ".", "strip", "(", ")", ".", "split", "(", ")", ":", "\n", "    ", "words", ".", "extend", "(", "re", ".", "split", "(", "_WORD_SPLIT", ",", "space_separated_fragment", ")", ")", "\n", "", "return", "[", "w", "for", "w", "in", "words", "if", "w", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.create_vocabulary": [[768, 818], ["re.compile", "tensorflow.python.platform.gfile.Exists", "print", "print", "tensorflow.python.platform.gfile.GFile", "sorted", "len", "tensorflow.python.platform.gfile.GFile", "print", "tokenizer", "nlp.basic_tokenizer", "vocab_file.write", "re.sub"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.basic_tokenizer"], ["", "def", "create_vocabulary", "(", "vocabulary_path", ",", "data_path", ",", "max_vocabulary_size", ",", "\n", "tokenizer", "=", "None", ",", "normalize_digits", "=", "True", ",", "\n", "_DIGIT_RE", "=", "re", ".", "compile", "(", "br\"\\d\"", ")", ",", "\n", "_START_VOCAB", "=", "[", "b\"_PAD\"", ",", "b\"_GO\"", ",", "b\"_EOS\"", ",", "b\"_UNK\"", "]", ")", ":", "\n", "  ", "\"\"\"Create vocabulary file (if it does not exist yet) from data file.\n\n  Data file is assumed to contain one sentence per line. Each sentence is\n  tokenized and digits are normalized (if normalize_digits is set).\n  Vocabulary contains the most-frequent tokens up to max_vocabulary_size.\n  We write it to vocabulary_path in a one-token-per-line format, so that later\n  token in the first line gets id=0, second line gets id=1, and so on.\n\n  Parameters\n  -----------\n  vocabulary_path : path where the vocabulary will be created.\n  data_path : data file that will be used to create vocabulary.\n  max_vocabulary_size : limit on the size of the created vocabulary.\n  tokenizer : a function to use to tokenize each data sentence.\n        if None, basic_tokenizer will be used.\n  normalize_digits : Boolean\n        if true, all digits are replaced by 0s.\n\n  References\n  ----------\n  - Code from ``/tensorflow/models/rnn/translation/data_utils.py``\n  \"\"\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "vocabulary_path", ")", ":", "\n", "    ", "print", "(", "(", "\"Creating vocabulary %s from data %s\"", "%", "(", "vocabulary_path", ",", "data_path", ")", ")", ")", "\n", "vocab", "=", "{", "}", "\n", "with", "gfile", ".", "GFile", "(", "data_path", ",", "mode", "=", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "counter", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "        ", "counter", "+=", "1", "\n", "if", "counter", "%", "100000", "==", "0", ":", "\n", "          ", "print", "(", "(", "\"  processing line %d\"", "%", "counter", ")", ")", "\n", "", "tokens", "=", "tokenizer", "(", "line", ")", "if", "tokenizer", "else", "basic_tokenizer", "(", "line", ")", "\n", "for", "w", "in", "tokens", ":", "\n", "          ", "word", "=", "re", ".", "sub", "(", "_DIGIT_RE", ",", "b\"0\"", ",", "w", ")", "if", "normalize_digits", "else", "w", "\n", "if", "word", "in", "vocab", ":", "\n", "            ", "vocab", "[", "word", "]", "+=", "1", "\n", "", "else", ":", "\n", "            ", "vocab", "[", "word", "]", "=", "1", "\n", "", "", "", "vocab_list", "=", "_START_VOCAB", "+", "sorted", "(", "vocab", ",", "key", "=", "vocab", ".", "get", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "vocab_list", ")", ">", "max_vocabulary_size", ":", "\n", "        ", "vocab_list", "=", "vocab_list", "[", ":", "max_vocabulary_size", "]", "\n", "", "with", "gfile", ".", "GFile", "(", "vocabulary_path", ",", "mode", "=", "\"wb\"", ")", "as", "vocab_file", ":", "\n", "        ", "for", "w", "in", "vocab_list", ":", "\n", "          ", "vocab_file", ".", "write", "(", "w", "+", "b\"\\n\"", ")", "\n", "", "", "", "", "else", ":", "\n", "    ", "print", "(", "(", "\"Vocabulary %s from data %s exists\"", "%", "(", "vocabulary_path", ",", "data_path", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.initialize_vocabulary": [[819, 865], ["tensorflow.python.platform.gfile.Exists", "dict", "ValueError", "tensorflow.python.platform.gfile.GFile", "rev_vocab.extend", "tensorflow.compat.as_bytes", "f.readlines", "line.strip", "enumerate"], "function", ["None"], ["", "", "def", "initialize_vocabulary", "(", "vocabulary_path", ")", ":", "\n", "  ", "\"\"\"Initialize vocabulary from file, return the word_to_id (dictionary)\n  and id_to_word (list).\n\n  We assume the vocabulary is stored one-item-per-line, so a file:\\n\n    dog\\n\n    cat\\n\n  will result in a vocabulary {\"dog\": 0, \"cat\": 1}, and this function will\n  also return the reversed-vocabulary [\"dog\", \"cat\"].\n\n  Parameters\n  -----------\n  vocabulary_path : path to the file containing the vocabulary.\n\n  Returns\n  --------\n  vocab : a dictionary\n        Word to id. A dictionary mapping string to integers.\n  rev_vocab : a list\n        Id to word. The reversed vocabulary (a list, which reverses the vocabulary mapping).\n\n  Examples\n  ---------\n  >>> Assume 'test' contains\n  ... dog\n  ... cat\n  ... bird\n  >>> vocab, rev_vocab = tl.nlp.initialize_vocabulary(\"test\")\n  >>> print(vocab)\n  >>> {b'cat': 1, b'dog': 0, b'bird': 2}\n  >>> print(rev_vocab)\n  >>> [b'dog', b'cat', b'bird']\n\n  Raises\n  -------\n  ValueError : if the provided vocabulary_path does not exist.\n  \"\"\"", "\n", "if", "gfile", ".", "Exists", "(", "vocabulary_path", ")", ":", "\n", "    ", "rev_vocab", "=", "[", "]", "\n", "with", "gfile", ".", "GFile", "(", "vocabulary_path", ",", "mode", "=", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "rev_vocab", ".", "extend", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "rev_vocab", "=", "[", "tf", ".", "compat", ".", "as_bytes", "(", "line", ".", "strip", "(", ")", ")", "for", "line", "in", "rev_vocab", "]", "\n", "vocab", "=", "dict", "(", "[", "(", "x", ",", "y", ")", "for", "(", "y", ",", "x", ")", "in", "enumerate", "(", "rev_vocab", ")", "]", ")", "\n", "return", "vocab", ",", "rev_vocab", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Vocabulary file %s not found.\"", ",", "vocabulary_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.sentence_to_token_ids": [[866, 899], ["re.compile", "tokenizer", "nlp.basic_tokenizer", "vocabulary.get", "vocabulary.get", "re.sub"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.basic_tokenizer"], ["", "", "def", "sentence_to_token_ids", "(", "sentence", ",", "vocabulary", ",", "\n", "tokenizer", "=", "None", ",", "normalize_digits", "=", "True", ",", "\n", "UNK_ID", "=", "3", ",", "_DIGIT_RE", "=", "re", ".", "compile", "(", "br\"\\d\"", ")", ")", ":", "\n", "  ", "\"\"\"Convert a string to list of integers representing token-ids.\n\n  For example, a sentence \"I have a dog\" may become tokenized into\n  [\"I\", \"have\", \"a\", \"dog\"] and with vocabulary {\"I\": 1, \"have\": 2,\n  \"a\": 4, \"dog\": 7\"} this function will return [1, 2, 4, 7].\n\n  Parameters\n  -----------\n  sentence :  tensorflow.python.platform.gfile.GFile Object\n        The sentence in bytes format to convert to token-ids.\\n\n        see basic_tokenizer(), data_to_token_ids()\n  vocabulary : a dictionary mapping tokens to integers.\n  tokenizer : a function to use to tokenize each sentence;\n        If None, basic_tokenizer will be used.\n  normalize_digits : Boolean\n        If true, all digits are replaced by 0s.\n\n  Returns\n  --------\n  A list of integers, the token-ids for the sentence.\n  \"\"\"", "\n", "\n", "if", "tokenizer", ":", "\n", "    ", "words", "=", "tokenizer", "(", "sentence", ")", "\n", "", "else", ":", "\n", "    ", "words", "=", "basic_tokenizer", "(", "sentence", ")", "\n", "", "if", "not", "normalize_digits", ":", "\n", "    ", "return", "[", "vocabulary", ".", "get", "(", "w", ",", "UNK_ID", ")", "for", "w", "in", "words", "]", "\n", "# Normalize digits by 0 before looking words up in the vocabulary.", "\n", "", "return", "[", "vocabulary", ".", "get", "(", "re", ".", "sub", "(", "_DIGIT_RE", ",", "b\"0\"", ",", "w", ")", ",", "UNK_ID", ")", "for", "w", "in", "words", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.data_to_token_ids": [[900, 938], ["re.compile", "tensorflow.python.platform.gfile.Exists", "print", "nlp.initialize_vocabulary", "print", "tensorflow.python.platform.gfile.GFile", "tensorflow.python.platform.gfile.GFile", "nlp.sentence_to_token_ids", "tokens_file.write", "print", "str"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.initialize_vocabulary", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.sentence_to_token_ids"], ["", "def", "data_to_token_ids", "(", "data_path", ",", "target_path", ",", "vocabulary_path", ",", "\n", "tokenizer", "=", "None", ",", "normalize_digits", "=", "True", ",", "\n", "UNK_ID", "=", "3", ",", "_DIGIT_RE", "=", "re", ".", "compile", "(", "br\"\\d\"", ")", ")", ":", "\n", "  ", "\"\"\"Tokenize data file and turn into token-ids using given vocabulary file.\n\n  This function loads data line-by-line from data_path, calls the above\n  sentence_to_token_ids, and saves the result to target_path. See comment\n  for sentence_to_token_ids on the details of token-ids format.\n\n  Parameters\n  -----------\n  data_path : path to the data file in one-sentence-per-line format.\n  target_path : path where the file with token-ids will be created.\n  vocabulary_path : path to the vocabulary file.\n  tokenizer : a function to use to tokenize each sentence;\n      if None, basic_tokenizer will be used.\n  normalize_digits : Boolean; if true, all digits are replaced by 0s.\n\n  References\n  ----------\n  - Code from ``/tensorflow/models/rnn/translation/data_utils.py``\n  \"\"\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "target_path", ")", ":", "\n", "    ", "print", "(", "(", "\"Tokenizing data in %s\"", "%", "data_path", ")", ")", "\n", "vocab", ",", "_", "=", "initialize_vocabulary", "(", "vocabulary_path", ")", "\n", "with", "gfile", ".", "GFile", "(", "data_path", ",", "mode", "=", "\"rb\"", ")", "as", "data_file", ":", "\n", "      ", "with", "gfile", ".", "GFile", "(", "target_path", ",", "mode", "=", "\"w\"", ")", "as", "tokens_file", ":", "\n", "        ", "counter", "=", "0", "\n", "for", "line", "in", "data_file", ":", "\n", "          ", "counter", "+=", "1", "\n", "if", "counter", "%", "100000", "==", "0", ":", "\n", "            ", "print", "(", "(", "\"  tokenizing line %d\"", "%", "counter", ")", ")", "\n", "", "token_ids", "=", "sentence_to_token_ids", "(", "line", ",", "vocab", ",", "tokenizer", ",", "\n", "normalize_digits", ",", "UNK_ID", "=", "UNK_ID", ",", "\n", "_DIGIT_RE", "=", "_DIGIT_RE", ")", "\n", "tokens_file", ".", "write", "(", "\" \"", ".", "join", "(", "[", "str", "(", "tok", ")", "for", "tok", "in", "token_ids", "]", ")", "+", "\"\\n\"", ")", "\n", "", "", "", "", "else", ":", "\n", "    ", "print", "(", "(", "\"Target path %s exists\"", "%", "target_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Layer.__init__": [[256, 272], ["tensorflow.compat.v1.get_variable_scope", "Exception", "set_keep[].append"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "inputs", "=", "None", ",", "\n", "name", "=", "'layer'", "\n", ")", ":", "\n", "        ", "self", ".", "inputs", "=", "inputs", "\n", "scope_name", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "if", "scope_name", ":", "\n", "            ", "name", "=", "scope_name", "+", "'/'", "+", "name", "\n", "", "if", "(", "name", "in", "set_keep", "[", "'_layers_name_list'", "]", ")", "and", "name_reuse", "==", "False", ":", "\n", "            ", "raise", "Exception", "(", "\"Layer '%s' already exists, please choice other 'name' or reuse this layer\\\n            \\nHint : Use different name for different 'Layer' (The name is used to control parameter sharing)\"", "%", "name", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "name", "=", "name", "\n", "if", "name", "not", "in", "[", "''", ",", "None", ",", "False", "]", ":", "\n", "                ", "set_keep", "[", "'_layers_name_list'", "]", ".", "append", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Layer.print_params": [[274, 286], ["enumerate", "print", "print", "layers.Layer.count_params", "print", "print", "Exception", "str", "str", "p.eval().mean", "numpy.median", "p.eval().std", "str", "p.get_shape", "p.eval", "p.eval", "p.eval", "p.eval"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Layer.count_params"], ["", "", "", "def", "print_params", "(", "self", ",", "details", "=", "True", ")", ":", "\n", "        ", "''' Print all info of parameters in the network'''", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "self", ".", "all_params", ")", ":", "\n", "            ", "if", "details", ":", "\n", "                ", "try", ":", "\n", "                    ", "print", "(", "(", "\"  param {:3}: {:15} (mean: {:<18}, median: {:<18}, std: {:<18})   {}\"", ".", "format", "(", "i", ",", "str", "(", "p", ".", "eval", "(", ")", ".", "shape", ")", ",", "p", ".", "eval", "(", ")", ".", "mean", "(", ")", ",", "np", ".", "median", "(", "p", ".", "eval", "(", ")", ")", ",", "p", ".", "eval", "(", ")", ".", "std", "(", ")", ",", "p", ".", "name", ")", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "(", "str", "(", "e", ")", ")", ")", "\n", "raise", "Exception", "(", "\"Hint: print params details after tl.layers.initialize_global_variables(sess) or use network.print_params(False).\"", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "(", "\"  param {:3}: {:15}    {}\"", ".", "format", "(", "i", ",", "str", "(", "p", ".", "get_shape", "(", ")", ")", ",", "p", ".", "name", ")", ")", ")", "\n", "", "", "print", "(", "(", "\"  num of params: %d\"", "%", "self", ".", "count_params", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Layer.print_layers": [[287, 291], ["enumerate", "print", "str"], "methods", ["None"], ["", "def", "print_layers", "(", "self", ")", ":", "\n", "        ", "''' Print all info of layers in the network '''", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "self", ".", "all_layers", ")", ":", "\n", "            ", "print", "(", "(", "\"  layer %d: %s\"", "%", "(", "i", ",", "str", "(", "p", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Layer.count_params": [[292, 307], ["enumerate", "p.get_shape", "int"], "methods", ["None"], ["", "", "def", "count_params", "(", "self", ")", ":", "\n", "        ", "''' Return the number of parameters in the network '''", "\n", "n_params", "=", "0", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "self", ".", "all_params", ")", ":", "\n", "            ", "n", "=", "1", "\n", "# for s in p.eval().shape:", "\n", "for", "s", "in", "p", ".", "get_shape", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "s", "=", "int", "(", "s", ")", "\n", "", "except", ":", "\n", "                    ", "s", "=", "1", "\n", "", "if", "s", ":", "\n", "                    ", "n", "=", "n", "*", "s", "\n", "", "", "n_params", "=", "n_params", "+", "n", "\n", "", "return", "n_params", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Layer.__str__": [[308, 313], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "# print(\"\\nIt is a Layer class\")", "\n", "# self.print_params(False)", "\n", "# self.print_layers()", "\n", "        ", "return", "\"  Last layer is: %s\"", "%", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.InputLayer.__init__": [[326, 337], ["layers.Layer.__init__", "print", "inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "inputs", "=", "None", ",", "\n", "name", "=", "'input_layer'", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "inputs", "=", "inputs", ",", "name", "=", "name", ")", "\n", "print", "(", "(", "\"  [TL] InputLayer  %s: %s\"", "%", "(", "self", ".", "name", ",", "inputs", ".", "get_shape", "(", ")", ")", ")", ")", "\n", "self", ".", "outputs", "=", "inputs", "\n", "self", ".", "all_layers", "=", "[", "]", "\n", "self", ".", "all_params", "=", "[", "]", "\n", "self", ".", "all_drop", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.OneHotInputLayer.__init__": [[357, 374], ["layers.Layer.__init__", "print", "tensorflow.one_hot", "inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "inputs", "=", "None", ",", "\n", "depth", "=", "None", ",", "\n", "on_value", "=", "None", ",", "\n", "off_value", "=", "None", ",", "\n", "axis", "=", "None", ",", "\n", "dtype", "=", "None", ",", "\n", "name", "=", "'input_layer'", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "inputs", "=", "inputs", ",", "name", "=", "name", ")", "\n", "assert", "depth", "!=", "None", ",", "\"depth is not given\"", "\n", "print", "(", "(", "\"  [TL]:Instantiate OneHotInputLayer  %s: %s\"", "%", "(", "self", ".", "name", ",", "inputs", ".", "get_shape", "(", ")", ")", ")", ")", "\n", "self", ".", "outputs", "=", "tf", ".", "one_hot", "(", "inputs", ",", "depth", ",", "on_value", "=", "on_value", ",", "off_value", "=", "off_value", ",", "axis", "=", "axis", ",", "dtype", "=", "dtype", ")", "\n", "self", ".", "all_layers", "=", "[", "]", "\n", "self", ".", "all_params", "=", "[", "]", "\n", "self", ".", "all_drop", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Word2vecEmbeddingInputlayer.__init__": [[459, 516], ["tensorflow.random_uniform_initializer", "tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "print", "tensorflow.reduce_mean", "tensorflow.nn.l2_normalize", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.nn.nce_loss"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "inputs", "=", "None", ",", "\n", "train_labels", "=", "None", ",", "\n", "vocabulary_size", "=", "80000", ",", "\n", "embedding_size", "=", "200", ",", "\n", "num_sampled", "=", "64", ",", "\n", "nce_loss_args", "=", "{", "}", ",", "\n", "E_init", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "1.0", ",", "maxval", "=", "1.0", ")", ",", "\n", "E_init_args", "=", "{", "}", ",", "\n", "nce_W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.03", ")", ",", "\n", "nce_W_init_args", "=", "{", "}", ",", "\n", "nce_b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "nce_b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'word2vec_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "inputs", "\n", "print", "(", "(", "\"  [TL] Word2vecEmbeddingInputlayer %s: (%d, %d)\"", "%", "(", "self", ".", "name", ",", "vocabulary_size", ",", "embedding_size", ")", ")", ")", "\n", "# Look up embeddings for inputs.", "\n", "# Note: a row of 'embeddings' is the vector representation of a word.", "\n", "# for the sake of speed, it is better to slice the embedding matrix", "\n", "# instead of transfering a word id to one-hot-format vector and then", "\n", "# multiply by the embedding matrix.", "\n", "# embed is the outputs of the hidden layer (embedding layer), it is a", "\n", "# row vector with 'embedding_size' values.", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "embeddings", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'embeddings'", ",", "\n", "shape", "=", "(", "vocabulary_size", ",", "embedding_size", ")", ",", "\n", "initializer", "=", "E_init", ",", "\n", "**", "E_init_args", ")", "\n", "embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeddings", ",", "self", ".", "inputs", ")", "\n", "# Construct the variables for the NCE loss (i.e. negative sampling)", "\n", "nce_weights", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'nce_weights'", ",", "\n", "shape", "=", "(", "vocabulary_size", ",", "embedding_size", ")", ",", "\n", "initializer", "=", "nce_W_init", ",", "\n", "**", "nce_W_init_args", ")", "\n", "nce_biases", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'nce_biases'", ",", "\n", "shape", "=", "(", "vocabulary_size", ")", ",", "\n", "initializer", "=", "nce_b_init", ",", "\n", "**", "nce_b_init_args", ")", "\n", "\n", "# Compute the average NCE loss for the batch.", "\n", "# tf.nce_loss automatically draws a new sample of the negative labels", "\n", "# each time we evaluate the loss.", "\n", "", "self", ".", "nce_cost", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "nn", ".", "nce_loss", "(", "weights", "=", "nce_weights", ",", "biases", "=", "nce_biases", ",", "\n", "inputs", "=", "embed", ",", "labels", "=", "train_labels", ",", "\n", "num_sampled", "=", "num_sampled", ",", "num_classes", "=", "vocabulary_size", ",", "\n", "**", "nce_loss_args", ")", ")", "\n", "\n", "self", ".", "outputs", "=", "embed", "\n", "self", ".", "normalized_embeddings", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "embeddings", ",", "1", ")", "\n", "\n", "self", ".", "all_layers", "=", "[", "self", ".", "outputs", "]", "\n", "self", ".", "all_params", "=", "[", "embeddings", ",", "nce_weights", ",", "nce_biases", "]", "\n", "self", ".", "all_drop", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.EmbeddingInputlayer.__init__": [[595, 620], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.nn.embedding_lookup"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "inputs", "=", "None", ",", "\n", "vocabulary_size", "=", "80000", ",", "\n", "embedding_size", "=", "200", ",", "\n", "E_init", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "E_init_args", "=", "{", "}", ",", "\n", "name", "=", "'embedding_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "inputs", "\n", "print", "(", "(", "\"  [TL] EmbeddingInputlayer %s: (%d, %d)\"", "%", "(", "self", ".", "name", ",", "vocabulary_size", ",", "embedding_size", ")", ")", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "embeddings", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'embeddings'", ",", "\n", "shape", "=", "(", "vocabulary_size", ",", "embedding_size", ")", ",", "\n", "initializer", "=", "E_init", ",", "\n", "**", "E_init_args", ")", "\n", "embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeddings", ",", "self", ".", "inputs", ")", "\n", "\n", "", "self", ".", "outputs", "=", "embed", "\n", "\n", "self", ".", "all_layers", "=", "[", "self", ".", "outputs", "]", "\n", "self", ".", "all_params", "=", "[", "embeddings", "]", "\n", "self", ".", "all_drop", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DenseLayer.__init__": [[667, 704], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "int", "print", "list", "list", "dict", "layers.DenseLayer.all_layers.extend", "Exception", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "layers.DenseLayer.all_params.extend", "layers.DenseLayer.all_params.extend", "layers.DenseLayer.inputs.get_shape", "layers.DenseLayer.inputs.get_shape", "tensorflow.compat.v1.get_variable", "act", "act", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "n_units", "=", "100", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'dense_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "if", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "ndims", "!=", "2", ":", "\n", "            ", "raise", "Exception", "(", "\"The input dimension must be rank 2, please reshape or flatten it\"", ")", "\n", "\n", "", "n_in", "=", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "self", ".", "n_units", "=", "n_units", "\n", "print", "(", "(", "\"  [TL] DenseLayer  %s: %d %s\"", "%", "(", "self", ".", "name", ",", "self", ".", "n_units", ",", "act", ".", "__name__", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'W'", ",", "shape", "=", "(", "n_in", ",", "n_units", ")", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "if", "b_init", ":", "\n", "                ", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b'", ",", "shape", "=", "(", "n_units", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "matmul", "(", "self", ".", "inputs", ",", "W", ")", "+", "b", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "outputs", "=", "act", "(", "tf", ".", "matmul", "(", "self", ".", "inputs", ",", "W", ")", ")", "\n", "\n", "# Hint : list(), dict() is pass by value (shallow), without them, it is", "\n", "# pass by reference.", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "if", "b_init", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.ReconLayer.__init__": [[749, 835], ["layers.DenseLayer.__init__", "print", "print", "print", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.compat.v1.train.AdamOptimizer().minimize", "tensorflow.squared_difference", "cost.lo_regularizer", "cost.li_regularizer", "tensorflow.reduce_mean", "print", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.reduce_sum", "print", "Exception", "tensorflow.compat.v1.train.AdamOptimizer", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log", "tensorflow.divide", "tensorflow.log", "tensorflow.log", "tensorflow.subtract", "tensorflow.div", "float", "tensorflow.subtract", "float"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.lo_regularizer", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.cost.li_regularizer"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "x_recon", "=", "None", ",", "\n", "name", "=", "'recon_layer'", ",", "\n", "n_units", "=", "784", ",", "\n", "act", "=", "tf", ".", "nn", ".", "softplus", ",", "\n", ")", ":", "\n", "        ", "DenseLayer", ".", "__init__", "(", "self", ",", "layer", "=", "layer", ",", "n_units", "=", "n_units", ",", "act", "=", "act", ",", "name", "=", "name", ")", "\n", "print", "(", "(", "\"     [TL] %s is a ReconLayer\"", "%", "self", ".", "name", ")", ")", "\n", "\n", "# y : reconstruction outputs; train_params : parameters to train", "\n", "# Note that: train_params = [W_encoder, b_encoder, W_decoder, b_encoder]", "\n", "y", "=", "self", ".", "outputs", "\n", "self", ".", "train_params", "=", "self", ".", "all_params", "[", "-", "4", ":", "]", "\n", "\n", "# =====================================================================", "\n", "#", "\n", "# You need to modify the below cost function and optimizer so as to", "\n", "# implement your own pre-train method.", "\n", "#", "\n", "# =====================================================================", "\n", "lambda_l2_w", "=", "0.004", "\n", "learning_rate", "=", "0.0001", "\n", "print", "(", "(", "\"     lambda_l2_w: %f\"", "%", "lambda_l2_w", ")", ")", "\n", "print", "(", "(", "\"     learning_rate: %f\"", "%", "learning_rate", ")", ")", "\n", "\n", "# Mean-squre-error i.e. quadratic-cost", "\n", "mse", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "squared_difference", "(", "y", ",", "x_recon", ")", ",", "1", ")", "\n", "mse", "=", "tf", ".", "reduce_mean", "(", "mse", ")", "# in theano: mse = ((y - x) ** 2 ).sum(axis=1).mean()", "\n", "# mse = tf.reduce_mean(tf.reduce_sum(tf.square(tf.sub(y, x_recon)),  1))", "\n", "# mse = tf.reduce_mean(tf.squared_difference(y, x_recon)) # <haodong>: Error", "\n", "# mse = tf.sqrt(tf.reduce_mean(tf.square(y - x_recon)))   # <haodong>: Error", "\n", "# Cross-entropy", "\n", "# ce = cost.cross_entropy(y, x_recon)                                               # <haodong>: list , list , Error (only be used for softmax output)", "\n", "# ce = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, x_recon))          # <haodong>: list , list , Error (only be used for softmax output)", "\n", "# ce = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y, x_recon))   # <haodong>: list , index , Error (only be used for softmax output)", "\n", "L2_w", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "lambda_l2_w", ")", "(", "self", ".", "train_params", "[", "0", "]", ")", "+", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "lambda_l2_w", ")", "(", "self", ".", "train_params", "[", "2", "]", ")", "# faster than the code below", "\n", "# L2_w = lambda_l2_w * tf.reduce_mean(tf.square(self.train_params[0])) + lambda_l2_w * tf.reduce_mean( tf.square(self.train_params[2]))", "\n", "# DropNeuro", "\n", "P_o", "=", "cost", ".", "lo_regularizer", "(", "0.03", ")", "(", "self", ".", "train_params", "[", "0", "]", ")", "# + cost.lo_regularizer(0.5)(self.train_params[2])    # <haodong>: if add lo on decoder, no neuron will be broken", "\n", "P_i", "=", "cost", ".", "li_regularizer", "(", "0.03", ")", "(", "self", ".", "train_params", "[", "0", "]", ")", "# + cost.li_regularizer(0.001)(self.train_params[2])", "\n", "\n", "# L1 of activation outputs", "\n", "activation_out", "=", "self", ".", "all_layers", "[", "-", "2", "]", "\n", "L1_a", "=", "0.001", "*", "tf", ".", "reduce_mean", "(", "activation_out", ")", "# <haodong>:  theano: T.mean( self.a[i] )         # some neuron are broken, white and black", "\n", "# L1_a = 0.001 * tf.reduce_mean( tf.reduce_sum(activation_out, 0) )         # <haodong>: some neuron are broken, white and black", "\n", "# L1_a = 0.001 * 100 * tf.reduce_mean( tf.reduce_sum(activation_out, 1) )   # <haodong>: some neuron are broken, white and black", "\n", "# KL Divergence", "\n", "beta", "=", "4", "\n", "rho", "=", "0.15", "\n", "p_hat", "=", "tf", ".", "reduce_mean", "(", "activation_out", ",", "0", ")", "# theano: p_hat = T.mean( self.a[i], axis=0 )", "\n", "try", ":", "## TF1.0", "\n", "            ", "KLD", "=", "beta", "*", "tf", ".", "reduce_sum", "(", "rho", "*", "tf", ".", "log", "(", "tf", ".", "divide", "(", "rho", ",", "p_hat", ")", ")", "+", "(", "1", "-", "rho", ")", "*", "tf", ".", "log", "(", "(", "1", "-", "rho", ")", "/", "(", "tf", ".", "subtract", "(", "float", "(", "1", ")", ",", "p_hat", ")", ")", ")", ")", "\n", "", "except", ":", "## TF0.12", "\n", "            ", "KLD", "=", "beta", "*", "tf", ".", "reduce_sum", "(", "rho", "*", "tf", ".", "log", "(", "tf", ".", "div", "(", "rho", ",", "p_hat", ")", ")", "+", "(", "1", "-", "rho", ")", "*", "tf", ".", "log", "(", "(", "1", "-", "rho", ")", "/", "(", "tf", ".", "subtract", "(", "float", "(", "1", ")", ",", "p_hat", ")", ")", ")", ")", "\n", "# KLD = beta * tf.reduce_sum( rho * tf.log(rho/ p_hat) + (1- rho) * tf.log((1- rho)/(1- p_hat)) )", "\n", "# theano: L1_a = l1_a[i] * T.sum( rho[i] * T.log(rho[i]/ p_hat) + (1- rho[i]) * T.log((1- rho[i])/(1- p_hat)) )", "\n", "# Total cost", "\n", "", "if", "act", "==", "tf", ".", "nn", ".", "softplus", ":", "\n", "            ", "print", "(", "'     use: mse, L2_w, L1_a'", ")", "\n", "self", ".", "cost", "=", "mse", "+", "L1_a", "+", "L2_w", "\n", "", "elif", "act", "==", "tf", ".", "nn", ".", "sigmoid", ":", "\n", "# ----------------------------------------------------", "\n", "# Cross-entropy was used in Denoising AE", "\n", "# print('     use: ce, L2_w, KLD')", "\n", "# self.cost = ce + L2_w + KLD", "\n", "# ----------------------------------------------------", "\n", "# Mean-squared-error was used in Vanilla AE", "\n", "            ", "print", "(", "'     use: mse, L2_w, KLD'", ")", "\n", "self", ".", "cost", "=", "mse", "+", "L2_w", "+", "KLD", "\n", "# ----------------------------------------------------", "\n", "# Add DropNeuro penalty (P_o) can remove neurons of AE", "\n", "# print('     use: mse, L2_w, KLD, P_o')", "\n", "# self.cost = mse + L2_w + KLD + P_o", "\n", "# ----------------------------------------------------", "\n", "# Add DropNeuro penalty (P_i) can remove neurons of previous layer", "\n", "#   If previous layer is InputLayer, it means remove useless features", "\n", "# print('     use: mse, L2_w, KLD, P_i')", "\n", "# self.cost = mse + L2_w + KLD + P_i", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Don't support the given reconstruct activation function\"", ")", "\n", "\n", "", "self", ".", "train_op", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "epsilon", "=", "1e-08", ",", "use_locking", "=", "False", ")", ".", "minimize", "(", "self", ".", "cost", ",", "var_list", "=", "self", ".", "train_params", ")", "\n", "# self.train_op = tf.train.GradientDescentOptimizer(1.0).minimize(self.cost, var_list=self.train_params)", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.ReconLayer.pretrain": [[837, 889], ["print", "print", "range", "print", "print", "time.time", "iterate.minibatches", "utils.dict_to_one", "feed_dict.update", "sess.run", "print", "iterate.minibatches", "print", "iterate.minibatches", "print", "utils.dict_to_one", "feed_dict.update", "sess.run", "utils.dict_to_one", "feed_dict.update", "sess.run", "visualize.W", "files.save_npz", "layers.ReconLayer.train_params[].eval", "Exception", "time.time", "str", "str"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.W", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.save_npz"], ["", "def", "pretrain", "(", "self", ",", "sess", ",", "x", ",", "X_train", ",", "X_val", ",", "denoise_name", "=", "None", ",", "n_epoch", "=", "100", ",", "batch_size", "=", "128", ",", "print_freq", "=", "10", ",", "\n", "save", "=", "True", ",", "save_name", "=", "'w1pre_'", ")", ":", "\n", "# ====================================================", "\n", "#", "\n", "# You need to modify the cost function in __init__() so as to", "\n", "# get your own pre-train method.", "\n", "#", "\n", "# ====================================================", "\n", "        ", "print", "(", "(", "\"     [*] %s start pretrain\"", "%", "self", ".", "name", ")", ")", "\n", "print", "(", "(", "\"     batch_size: %d\"", "%", "batch_size", ")", ")", "\n", "if", "denoise_name", ":", "\n", "            ", "print", "(", "(", "\"     denoising layer keep: %f\"", "%", "self", ".", "all_drop", "[", "set_keep", "[", "denoise_name", "]", "]", ")", ")", "\n", "dp_denoise", "=", "self", ".", "all_drop", "[", "set_keep", "[", "denoise_name", "]", "]", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"     no denoising layer\"", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "n_epoch", ")", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "X_train_a", ",", "_", "in", "iterate", ".", "minibatches", "(", "X_train", ",", "X_train", ",", "batch_size", ",", "shuffle", "=", "True", ")", ":", "\n", "                ", "dp_dict", "=", "utils", ".", "dict_to_one", "(", "self", ".", "all_drop", ")", "\n", "if", "denoise_name", ":", "\n", "                    ", "dp_dict", "[", "set_keep", "[", "denoise_name", "]", "]", "=", "dp_denoise", "\n", "", "feed_dict", "=", "{", "x", ":", "X_train_a", "}", "\n", "feed_dict", ".", "update", "(", "dp_dict", ")", "\n", "sess", ".", "run", "(", "self", ".", "train_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "", "if", "epoch", "+", "1", "==", "1", "or", "(", "epoch", "+", "1", ")", "%", "print_freq", "==", "0", ":", "\n", "                ", "print", "(", "(", "\"Epoch %d of %d took %fs\"", "%", "(", "epoch", "+", "1", ",", "n_epoch", ",", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", ")", "\n", "train_loss", ",", "n_batch", "=", "0", ",", "0", "\n", "for", "X_train_a", ",", "_", "in", "iterate", ".", "minibatches", "(", "X_train", ",", "X_train", ",", "batch_size", ",", "shuffle", "=", "True", ")", ":", "\n", "                    ", "dp_dict", "=", "utils", ".", "dict_to_one", "(", "self", ".", "all_drop", ")", "\n", "feed_dict", "=", "{", "x", ":", "X_train_a", "}", "\n", "feed_dict", ".", "update", "(", "dp_dict", ")", "\n", "err", "=", "sess", ".", "run", "(", "self", ".", "cost", ",", "feed_dict", "=", "feed_dict", ")", "\n", "train_loss", "+=", "err", "\n", "n_batch", "+=", "1", "\n", "", "print", "(", "(", "\"   train loss: %f\"", "%", "(", "train_loss", "/", "n_batch", ")", ")", ")", "\n", "val_loss", ",", "n_batch", "=", "0", ",", "0", "\n", "for", "X_val_a", ",", "_", "in", "iterate", ".", "minibatches", "(", "X_val", ",", "X_val", ",", "batch_size", ",", "shuffle", "=", "True", ")", ":", "\n", "                    ", "dp_dict", "=", "utils", ".", "dict_to_one", "(", "self", ".", "all_drop", ")", "\n", "feed_dict", "=", "{", "x", ":", "X_val_a", "}", "\n", "feed_dict", ".", "update", "(", "dp_dict", ")", "\n", "err", "=", "sess", ".", "run", "(", "self", ".", "cost", ",", "feed_dict", "=", "feed_dict", ")", "\n", "val_loss", "+=", "err", "\n", "n_batch", "+=", "1", "\n", "", "print", "(", "(", "\"   val loss: %f\"", "%", "(", "val_loss", "/", "n_batch", ")", ")", ")", "\n", "if", "save", ":", "\n", "                    ", "try", ":", "\n", "                        ", "visualize", ".", "W", "(", "self", ".", "train_params", "[", "0", "]", ".", "eval", "(", ")", ",", "second", "=", "10", ",", "saveable", "=", "True", ",", "shape", "=", "[", "28", ",", "28", "]", ",", "name", "=", "save_name", "+", "str", "(", "epoch", "+", "1", ")", ",", "fig_idx", "=", "2012", ")", "\n", "files", ".", "save_npz", "(", "[", "self", ".", "all_params", "[", "0", "]", "]", ",", "name", "=", "save_name", "+", "str", "(", "epoch", "+", "1", ")", "+", "'.npz'", ")", "\n", "", "except", ":", "\n", "                        ", "raise", "Exception", "(", "\"You should change the visualize.W() in ReconLayer.pretrain(), if you want to save the feature images for different dataset\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DropoutLayer.__init__": [[938, 972], ["layers.Layer.__init__", "print", "list", "list", "dict", "print", "list", "list", "dict", "layers.DropoutLayer.all_layers.extend", "tensorflow.nn.dropout", "tensorflow.compat.v1.placeholder", "tensorflow.nn.dropout", "layers.DropoutLayer.all_drop.update"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "keep", "=", "0.5", ",", "\n", "is_fix", "=", "False", ",", "\n", "is_train", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "name", "=", "'dropout_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "is_train", "is", "False", ":", "\n", "            ", "print", "(", "\"  [TL] skip DropoutLayer\"", ")", "\n", "self", ".", "outputs", "=", "layer", ".", "outputs", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] DropoutLayer %s: keep:%f is_fix:%s\"", "%", "(", "self", ".", "name", ",", "keep", ",", "is_fix", ")", ")", ")", "\n", "\n", "# The name of placeholder for keep_prob is the same with the name", "\n", "# of the Layer.", "\n", "if", "is_fix", ":", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "inputs", ",", "keep", ",", "seed", "=", "seed", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "                ", "set_keep", "[", "name", "]", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "outputs", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "inputs", ",", "set_keep", "[", "name", "]", ",", "seed", "=", "seed", ",", "name", "=", "name", ")", "# 1.2", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "if", "is_fix", "is", "False", ":", "\n", "                ", "self", ".", "all_drop", ".", "update", "(", "{", "set_keep", "[", "name", "]", ":", "keep", "}", ")", "\n", "", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.GaussianNoiseLayer.__init__": [[1008, 1034], ["layers.Layer.__init__", "print", "list", "list", "dict", "print", "list", "list", "dict", "tensorflow.compat.v1.variable_scope", "tensorflow.random_normal", "layers.GaussianNoiseLayer.inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "mean", "=", "0.0", ",", "\n", "stddev", "=", "1.0", ",", "\n", "is_train", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "name", "=", "'gaussian_noise_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "is_train", "is", "False", ":", "\n", "            ", "print", "(", "\"  [TL] skip GaussianNoiseLayer\"", ")", "\n", "self", ".", "outputs", "=", "layer", ".", "outputs", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] GaussianNoiseLayer %s: mean:%f stddev:%f\"", "%", "(", "self", ".", "name", ",", "mean", ",", "stddev", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "# noise = np.random.normal(0.0 , sigma , tf.to_int64(self.inputs).get_shape())", "\n", "                ", "noise", "=", "tf", ".", "random_normal", "(", "shape", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", ",", "mean", "=", "mean", ",", "stddev", "=", "stddev", ",", "seed", "=", "seed", ")", "\n", "self", ".", "outputs", "=", "self", ".", "inputs", "+", "noise", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DropconnectDenseLayer.__init__": [[1076, 1111], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "int", "print", "tensorflow.compat.v1.placeholder", "tensorflow.nn.dropout", "act", "list", "list", "dict", "layers.DropconnectDenseLayer.all_drop.update", "layers.DropconnectDenseLayer.all_layers.extend", "layers.DropconnectDenseLayer.all_params.extend", "Exception", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "act", "layers.DropconnectDenseLayer.inputs.get_shape", "layers.DropconnectDenseLayer.inputs.get_shape", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "keep", "=", "0.5", ",", "\n", "n_units", "=", "100", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'dropconnect_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "if", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "ndims", "!=", "2", ":", "\n", "            ", "raise", "Exception", "(", "\"The input dimension must be rank 2\"", ")", "\n", "", "n_in", "=", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "self", ".", "n_units", "=", "n_units", "\n", "print", "(", "(", "\"  [TL] DropconnectDenseLayer %s: %d %s\"", "%", "(", "self", ".", "name", ",", "self", ".", "n_units", ",", "act", ".", "__name__", ")", ")", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'W'", ",", "shape", "=", "(", "n_in", ",", "n_units", ")", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b'", ",", "shape", "=", "(", "n_units", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "matmul", "(", "self", ".", "inputs", ",", "W", ")", "+", "b", ")", "#, name=name)    # 1.2", "\n", "\n", "", "set_keep", "[", "name", "]", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "W_dropcon", "=", "tf", ".", "nn", ".", "dropout", "(", "W", ",", "set_keep", "[", "name", "]", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "matmul", "(", "self", ".", "inputs", ",", "W_dropcon", ")", "+", "b", ")", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_drop", ".", "update", "(", "{", "set_keep", "[", "name", "]", ":", "keep", "}", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Conv1dLayer.__init__": [[1142, 1181], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.Conv1dLayer.all_layers.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "layers.Conv1dLayer.all_params.extend", "layers.Conv1dLayer.all_params.extend", "tensorflow.compat.v1.get_variable", "act", "act", "str", "str", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "shape", "=", "[", "5", ",", "1", ",", "5", "]", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "use_cudnn_on_gpu", "=", "None", ",", "\n", "data_format", "=", "None", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'cnn_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] Conv1dLayer %s: shape:%s stride:%s pad:%s act:%s\"", "%", "\n", "(", "self", ".", "name", ",", "str", "(", "shape", ")", ",", "str", "(", "stride", ")", ",", "padding", ",", "act", ".", "__name__", ")", ")", ")", "\n", "if", "act", "is", "None", ":", "\n", "            ", "act", "=", "tf", ".", "identity", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'W_conv1d'", ",", "shape", "=", "shape", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "if", "b_init", ":", "\n", "                ", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b_conv1d'", ",", "shape", "=", "(", "shape", "[", "-", "1", "]", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv1d", "(", "self", ".", "inputs", ",", "W", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "\n", "use_cudnn_on_gpu", "=", "use_cudnn_on_gpu", ",", "data_format", "=", "data_format", ")", "+", "b", ")", "#1.2", "\n", "", "else", ":", "\n", "                ", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv1d", "(", "self", ".", "inputs", ",", "W", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "\n", "use_cudnn_on_gpu", "=", "use_cudnn_on_gpu", ",", "data_format", "=", "data_format", ")", ")", "\n", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "if", "b_init", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Conv2dLayer.__init__": [[1245, 1281], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.Conv2dLayer.all_layers.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "layers.Conv2dLayer.all_params.extend", "layers.Conv2dLayer.all_params.extend", "tensorflow.compat.v1.get_variable", "act", "act", "str", "str", "tensorflow.nn.conv2d", "tensorflow.nn.conv2d"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "shape", "=", "[", "5", ",", "5", ",", "1", ",", "100", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "use_cudnn_on_gpu", "=", "None", ",", "\n", "data_format", "=", "None", ",", "\n", "name", "=", "'cnn_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] Conv2dLayer %s: shape:%s strides:%s pad:%s act:%s\"", "%", "\n", "(", "self", ".", "name", ",", "str", "(", "shape", ")", ",", "str", "(", "strides", ")", ",", "padding", ",", "act", ".", "__name__", ")", ")", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'W_conv2d'", ",", "shape", "=", "shape", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "if", "b_init", ":", "\n", "                ", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b_conv2d'", ",", "shape", "=", "(", "shape", "[", "-", "1", "]", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv2d", "(", "self", ".", "inputs", ",", "W", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "use_cudnn_on_gpu", "=", "use_cudnn_on_gpu", ",", "data_format", "=", "data_format", ")", "+", "b", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv2d", "(", "self", ".", "inputs", ",", "W", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "use_cudnn_on_gpu", "=", "use_cudnn_on_gpu", ",", "data_format", "=", "data_format", ")", ")", "\n", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "if", "b_init", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DeConv2dLayer.__init__": [[1352, 1387], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.DeConv2dLayer.all_layers.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "layers.DeConv2dLayer.all_params.extend", "layers.DeConv2dLayer.all_params.extend", "tensorflow.compat.v1.get_variable", "act", "act", "str", "str", "str", "tensorflow.nn.conv2d_transpose", "tensorflow.nn.conv2d_transpose"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "shape", "=", "[", "3", ",", "3", ",", "128", ",", "256", "]", ",", "\n", "output_shape", "=", "[", "1", ",", "256", ",", "256", ",", "128", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'decnn2d_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] DeConv2dLayer %s: shape:%s out_shape:%s strides:%s pad:%s act:%s\"", "%", "\n", "(", "self", ".", "name", ",", "str", "(", "shape", ")", ",", "str", "(", "output_shape", ")", ",", "str", "(", "strides", ")", ",", "padding", ",", "act", ".", "__name__", ")", ")", ")", "\n", "# print(\"  DeConv2dLayer: Untested\")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'W_deconv2d'", ",", "shape", "=", "shape", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "if", "b_init", ":", "\n", "                ", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b_deconv2d'", ",", "shape", "=", "(", "shape", "[", "-", "2", "]", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv2d_transpose", "(", "self", ".", "inputs", ",", "W", ",", "output_shape", "=", "output_shape", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", "+", "b", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv2d_transpose", "(", "self", ".", "inputs", ",", "W", ",", "output_shape", "=", "output_shape", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", ")", "\n", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "if", "b_init", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "W", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Conv3dLayer.__init__": [[1415, 1446], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.Conv3dLayer.all_layers.extend", "layers.Conv3dLayer.all_params.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "act", "str", "str", "tensorflow.nn.conv3d"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "shape", "=", "[", "2", ",", "2", ",", "2", ",", "64", ",", "128", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'cnn3d_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] Conv3dLayer %s: shape:%s strides:%s pad:%s act:%s\"", "%", "(", "self", ".", "name", ",", "str", "(", "shape", ")", ",", "str", "(", "strides", ")", ",", "padding", ",", "act", ".", "__name__", ")", ")", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "# W = tf.Variable(W_init(shape=shape, **W_init_args), name='W_conv')", "\n", "# b = tf.Variable(b_init(shape=[shape[-1]], **b_init_args), name='b_conv')", "\n", "            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'W_conv3d'", ",", "shape", "=", "shape", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b_conv3d'", ",", "shape", "=", "(", "shape", "[", "-", "1", "]", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv3d", "(", "self", ".", "inputs", ",", "W", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "None", ")", "+", "b", ")", "\n", "\n", "# self.outputs = act( tf.nn.conv3d(self.inputs, W, strides=strides, padding=padding, name=None) + b )", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DeConv3dLayer.__init__": [[1475, 1505], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.DeConv3dLayer.all_layers.extend", "layers.DeConv3dLayer.all_params.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "act", "str", "str", "str", "tensorflow.nn.conv3d_transpose"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "shape", "=", "[", "2", ",", "2", ",", "2", ",", "128", ",", "256", "]", ",", "\n", "output_shape", "=", "[", "1", ",", "12", ",", "32", ",", "32", ",", "128", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'decnn3d_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] DeConv3dLayer %s: shape:%s out_shape:%s strides:%s pad:%s act:%s\"", "%", "\n", "(", "self", ".", "name", ",", "str", "(", "shape", ")", ",", "str", "(", "output_shape", ")", ",", "str", "(", "strides", ")", ",", "padding", ",", "act", ".", "__name__", ")", ")", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "W", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'W_deconv3d'", ",", "shape", "=", "shape", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b_deconv3d'", ",", "shape", "=", "(", "shape", "[", "-", "2", "]", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "conv3d_transpose", "(", "self", ".", "inputs", ",", "W", ",", "output_shape", "=", "output_shape", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", "+", "b", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.UpSampling2dLayer.__init__": [[1524, 1559], ["layers.Layer.__init__", "print", "list", "list", "dict", "layers.UpSampling2dLayer.all_layers.extend", "len", "tensorflow.compat.v1.variable_scope", "layers.UpSampling2dLayer.inputs.get_shape", "len", "Exception", "tensorflow.image.resize_images", "int", "int", "layers.UpSampling2dLayer.inputs.get_shape", "tensorflow.image.resize_images", "int", "int", "layers.UpSampling2dLayer.inputs.get_shape", "layers.UpSampling2dLayer.inputs.get_shape", "layers.UpSampling2dLayer.inputs.get_shape", "layers.UpSampling2dLayer.inputs.get_shape", "layers.UpSampling2dLayer.inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "size", "=", "[", "]", ",", "\n", "is_scale", "=", "True", ",", "\n", "method", "=", "0", ",", "\n", "align_corners", "=", "False", ",", "\n", "name", "=", "'upsample2d_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "if", "len", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", ")", "==", "3", ":", "\n", "            ", "if", "is_scale", ":", "\n", "                ", "size_h", "=", "size", "[", "0", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "size_w", "=", "size", "[", "1", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "size", "=", "[", "size_h", ",", "size_w", "]", "\n", "", "", "elif", "len", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", ")", "==", "4", ":", "\n", "            ", "if", "is_scale", ":", "\n", "                ", "size_h", "=", "size", "[", "0", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "size_w", "=", "size", "[", "1", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "2", "]", ")", "\n", "size", "=", "[", "size_h", ",", "size_w", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Donot support shape %s\"", "%", "self", ".", "inputs", ".", "get_shape", "(", ")", ")", "\n", "", "print", "(", "(", "\"  [TL] UpSampling2dLayer %s: is_scale:%s size:%s method:%d align_corners:%s\"", "%", "\n", "(", "name", ",", "is_scale", ",", "size", ",", "method", ",", "align_corners", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "image", ".", "resize_images", "(", "self", ".", "inputs", ",", "size", "=", "size", ",", "method", "=", "method", ",", "align_corners", "=", "align_corners", ")", "\n", "", "except", ":", "# for TF 0.10", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "image", ".", "resize_images", "(", "self", ".", "inputs", ",", "new_height", "=", "size", "[", "0", "]", ",", "new_width", "=", "size", "[", "1", "]", ",", "method", "=", "method", ",", "align_corners", "=", "align_corners", ")", "\n", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DownSampling2dLayer.__init__": [[1578, 1613], ["layers.Layer.__init__", "print", "list", "list", "dict", "layers.DownSampling2dLayer.all_layers.extend", "len", "tensorflow.compat.v1.variable_scope", "layers.DownSampling2dLayer.inputs.get_shape", "len", "Exception", "tensorflow.image.resize_images", "int", "int", "layers.DownSampling2dLayer.inputs.get_shape", "tensorflow.image.resize_images", "int", "int", "layers.DownSampling2dLayer.inputs.get_shape", "layers.DownSampling2dLayer.inputs.get_shape", "layers.DownSampling2dLayer.inputs.get_shape", "layers.DownSampling2dLayer.inputs.get_shape", "layers.DownSampling2dLayer.inputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "size", "=", "[", "]", ",", "\n", "is_scale", "=", "True", ",", "\n", "method", "=", "0", ",", "\n", "align_corners", "=", "False", ",", "\n", "name", "=", "'downsample2d_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "if", "len", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", ")", "==", "3", ":", "\n", "            ", "if", "is_scale", ":", "\n", "                ", "size_h", "=", "size", "[", "0", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "size_w", "=", "size", "[", "1", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "size", "=", "[", "size_h", ",", "size_w", "]", "\n", "", "", "elif", "len", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", ")", "==", "4", ":", "\n", "            ", "if", "is_scale", ":", "\n", "                ", "size_h", "=", "size", "[", "0", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "size_w", "=", "size", "[", "1", "]", "*", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "2", "]", ")", "\n", "size", "=", "[", "size_h", ",", "size_w", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Donot support shape %s\"", "%", "self", ".", "inputs", ".", "get_shape", "(", ")", ")", "\n", "", "print", "(", "(", "\"  [TL] DownSampling2dLayer %s: is_scale:%s size:%s method:%d, align_corners:%s\"", "%", "\n", "(", "name", ",", "is_scale", ",", "size", ",", "method", ",", "align_corners", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "image", ".", "resize_images", "(", "self", ".", "inputs", ",", "size", "=", "size", ",", "method", "=", "method", ",", "align_corners", "=", "align_corners", ")", "\n", "", "except", ":", "# for TF 0.10", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "image", ".", "resize_images", "(", "self", ".", "inputs", ",", "new_height", "=", "size", "[", "0", "]", ",", "new_width", "=", "size", "[", "1", "]", ",", "method", "=", "method", ",", "align_corners", "=", "align_corners", ")", "\n", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.AtrousConv2dLayer.__init__": [[1632, 1669], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.AtrousConv2dLayer.all_layers.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "layers.AtrousConv2dLayer.all_params.extend", "layers.AtrousConv2dLayer.all_params.extend", "int", "tensorflow.compat.v1.get_variable", "act", "act", "tensorflow.nn.atrous_conv2d", "layers.AtrousConv2dLayer.inputs.get_shape", "tensorflow.nn.atrous_conv2d"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "n_filter", "=", "32", ",", "\n", "filter_size", "=", "(", "3", ",", "3", ")", ",", "\n", "rate", "=", "2", ",", "\n", "act", "=", "None", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "\n", "b_init_args", "=", "{", "}", ",", "\n", "name", "=", "'atrou2d'", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] AtrousConv2dLayer %s: n_filter:%d filter_size:%s rate:%d pad:%s act:%s\"", "%", "\n", "(", "self", ".", "name", ",", "n_filter", ",", "filter_size", ",", "rate", ",", "padding", ",", "act", ".", "__name__", ")", ")", ")", "\n", "if", "act", "is", "None", ":", "\n", "            ", "act", "=", "tf", ".", "identity", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "shape", "=", "[", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", ",", "n_filter", "]", "\n", "filters", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'filter'", ",", "shape", "=", "shape", ",", "initializer", "=", "W_init", ",", "**", "W_init_args", ")", "\n", "if", "b_init", ":", "\n", "                ", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'b'", ",", "shape", "=", "(", "n_filter", ")", ",", "initializer", "=", "b_init", ",", "**", "b_init_args", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "atrous_conv2d", "(", "self", ".", "inputs", ",", "filters", ",", "rate", ",", "padding", ")", "+", "b", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "atrous_conv2d", "(", "self", ".", "inputs", ",", "filters", ",", "rate", ",", "padding", ")", ")", "\n", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "if", "b_init", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "filters", ",", "b", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "all_params", ".", "extend", "(", "[", "filters", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.SeparableConv2dLayer.__init__": [[1694, 1743], ["tensorflow.zeros_initializer", "layers.Layer.__init__", "bias_initializer.", "print", "list", "list", "dict", "layers.SeparableConv2dLayer.all_layers.extend", "layers.SeparableConv2dLayer.all_params.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.layers.separable_conv2d", "tensorflow.compat.v1.get_collection", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "filters", "=", "None", ",", "\n", "kernel_size", "=", "5", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'valid'", ",", "\n", "data_format", "=", "'channels_last'", ",", "\n", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "\n", "depth_multiplier", "=", "1", ",", "\n", "act", "=", "None", ",", "\n", "use_bias", "=", "True", ",", "\n", "depthwise_initializer", "=", "None", ",", "\n", "pointwise_initializer", "=", "None", ",", "\n", "bias_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "depthwise_regularizer", "=", "None", ",", "\n", "pointwise_regularizer", "=", "None", ",", "\n", "bias_regularizer", "=", "None", ",", "\n", "activity_regularizer", "=", "None", ",", "\n", "name", "=", "'atrou2d'", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "assert", "filters", "is", "not", "None", "\n", "assert", "tf", ".", "__version__", ">", "\"0.12.1\"", ",", "\"This layer only supports for TF 1.0+\"", "\n", "if", "act", "is", "None", ":", "\n", "            ", "act", "=", "tf", ".", "identity", "\n", "\n", "", "bias_initializer", "=", "bias_initializer", "(", ")", "\n", "\n", "print", "(", "(", "\"  [TL] SeparableConv2dLayer %s: filters:%s kernel_size:%s strides:%s padding:%s dilation_rate:%s depth_multiplier:%s act:%s\"", "%", "\n", "(", "self", ".", "name", ",", "str", "(", "filters", ")", ",", "str", "(", "kernel_size", ")", ",", "str", "(", "strides", ")", ",", "padding", ",", "str", "(", "dilation_rate", ")", ",", "str", "(", "depth_multiplier", ")", ",", "act", ".", "__name__", ")", ")", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "self", ".", "outputs", "=", "tf", ".", "layers", ".", "separable_conv2d", "(", "self", ".", "inputs", ",", "filters", ",", "kernel_size", ",", "\n", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "data_format", "=", "data_format", ",", "\n", "dilation_rate", "=", "dilation_rate", ",", "depth_multiplier", "=", "depth_multiplier", ",", "activation", "=", "act", ",", "\n", "use_bias", "=", "use_bias", ",", "depthwise_initializer", "=", "depthwise_initializer", ",", "pointwise_initializer", "=", "pointwise_initializer", ",", "\n", "bias_initializer", "=", "bias_initializer", ",", "depthwise_regularizer", "=", "depthwise_regularizer", ",", "\n", "pointwise_regularizer", "=", "pointwise_regularizer", ",", "bias_regularizer", "=", "bias_regularizer", ",", "activity_regularizer", "=", "activity_regularizer", ",", ")", "\n", "#trainable=True, name=None, reuse=None)", "\n", "\n", "variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.LocalResponseNormLayer.__init__": [[2169, 2189], ["layers.Layer.__init__", "print", "list", "list", "dict", "layers.LocalResponseNormLayer.all_layers.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.nn.lrn"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "depth_radius", "=", "None", ",", "\n", "bias", "=", "None", ",", "\n", "alpha", "=", "None", ",", "\n", "beta", "=", "None", ",", "\n", "name", "=", "'lrn_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] LocalResponseNormLayer %s: depth_radius: %d, bias: %f, alpha: %f, beta: %f\"", "%", "\n", "(", "self", ".", "name", ",", "depth_radius", ",", "bias", ",", "alpha", ",", "beta", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "self", ".", "outputs", "=", "tf", ".", "nn", ".", "lrn", "(", "self", ".", "inputs", ",", "depth_radius", "=", "depth_radius", ",", "bias", "=", "bias", ",", "alpha", "=", "alpha", ",", "beta", "=", "beta", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.BatchNormLayer.__init__": [[2219, 2306], ["tensorflow.zeros_initializer", "tensorflow.random_normal_initializer", "layers.Layer.__init__", "print", "layers.BatchNormLayer.inputs.get_shape", "list", "list", "dict", "layers.BatchNormLayer.all_layers.extend", "layers.BatchNormLayer.all_params.extend", "tensorflow.compat.v1.variable_scope", "list", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.compat.v1.get_variable", "tensorflow.nn.moments", "range", "beta_init.", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "moving_averages.assign_moving_average", "moving_averages.assign_moving_average", "layers.BatchNormLayer.__init__.mean_var_with_update"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "decay", "=", "0.9", ",", "\n", "epsilon", "=", "0.00001", ",", "\n", "act", "=", "tf", ".", "identity", ",", "\n", "is_train", "=", "False", ",", "\n", "beta_init", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "gamma_init", "=", "tf", ".", "random_normal_initializer", "(", "mean", "=", "1.0", ",", "stddev", "=", "0.002", ")", ",", "# tf.ones_initializer,", "\n", "name", "=", "'batchnorm_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] BatchNormLayer %s: decay:%f epsilon:%f act:%s is_train:%s\"", "%", "\n", "(", "self", ".", "name", ",", "decay", ",", "epsilon", ",", "act", ".", "__name__", ",", "is_train", ")", ")", ")", "\n", "x_shape", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", "\n", "params_shape", "=", "x_shape", "[", "-", "1", ":", "]", "\n", "\n", "from", "tensorflow", ".", "python", ".", "training", "import", "moving_averages", "\n", "from", "tensorflow", ".", "python", ".", "ops", "import", "control_flow_ops", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "axis", "=", "list", "(", "range", "(", "len", "(", "x_shape", ")", "-", "1", ")", ")", "\n", "\n", "## 1. beta, gamma", "\n", "if", "tf", ".", "__version__", ">", "'0.12.1'", "and", "beta_init", "==", "tf", ".", "zeros_initializer", "(", ")", ":", "\n", "                ", "beta_init", "=", "beta_init", "(", ")", "\n", "", "beta", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'beta'", ",", "shape", "=", "params_shape", ",", "\n", "initializer", "=", "beta_init", ",", "\n", "trainable", "=", "is_train", ")", "#, restore=restore)", "\n", "\n", "gamma", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'gamma'", ",", "shape", "=", "params_shape", ",", "\n", "initializer", "=", "gamma_init", ",", "trainable", "=", "is_train", ",", "\n", ")", "#restore=restore)", "\n", "\n", "## 2.", "\n", "if", "tf", ".", "__version__", ">", "'0.12.1'", ":", "\n", "                ", "moving_mean_init", "=", "tf", ".", "zeros_initializer", "(", ")", "\n", "", "else", ":", "\n", "                ", "moving_mean_init", "=", "tf", ".", "zeros_initializer", "(", ")", "\n", "", "moving_mean", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'moving_mean'", ",", "\n", "params_shape", ",", "\n", "initializer", "=", "moving_mean_init", ",", "\n", "trainable", "=", "False", ",", ")", "#   restore=restore)", "\n", "moving_variance", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "'moving_variance'", ",", "\n", "params_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.", ")", ",", "\n", "trainable", "=", "False", ",", ")", "#   restore=restore)", "\n", "\n", "## 3.", "\n", "# These ops will only be preformed when training.", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "self", ".", "inputs", ",", "axis", ")", "\n", "try", ":", "# TF12", "\n", "                ", "update_moving_mean", "=", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_mean", ",", "mean", ",", "decay", ",", "zero_debias", "=", "False", ")", "# if zero_debias=True, has bias", "\n", "update_moving_variance", "=", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_variance", ",", "variance", ",", "decay", ",", "zero_debias", "=", "False", ")", "# if zero_debias=True, has bias", "\n", "# print(\"TF12 moving\")", "\n", "", "except", "Exception", "as", "e", ":", "# TF11", "\n", "                ", "update_moving_mean", "=", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_mean", ",", "mean", ",", "decay", ")", "\n", "update_moving_variance", "=", "moving_averages", ".", "assign_moving_average", "(", "\n", "moving_variance", ",", "variance", ",", "decay", ")", "\n", "# print(\"TF11 moving\")", "\n", "\n", "", "def", "mean_var_with_update", "(", ")", ":", "\n", "                ", "with", "tf", ".", "control_dependencies", "(", "[", "update_moving_mean", ",", "update_moving_variance", "]", ")", ":", "\n", "                    ", "return", "tf", ".", "identity", "(", "mean", ")", ",", "tf", ".", "identity", "(", "variance", ")", "\n", "\n", "", "", "if", "is_train", ":", "\n", "                ", "mean", ",", "var", "=", "mean_var_with_update", "(", ")", "\n", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "batch_normalization", "(", "self", ".", "inputs", ",", "mean", ",", "var", ",", "beta", ",", "gamma", ",", "epsilon", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "outputs", "=", "act", "(", "tf", ".", "nn", ".", "batch_normalization", "(", "self", ".", "inputs", ",", "moving_mean", ",", "moving_variance", ",", "beta", ",", "gamma", ",", "epsilon", ")", ")", "\n", "\n", "", "variables", "=", "[", "beta", ",", "gamma", ",", "moving_mean", ",", "moving_variance", "]", "\n", "\n", "# print(len(variables))", "\n", "# for idx, v in enumerate(variables):", "\n", "#     print(\"  var {:3}: {:15}   {}\".format(idx, str(v.get_shape()), v))", "\n", "# exit()", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.PoolLayer.__init__": [[3052, 3072], ["layers.Layer.__init__", "print", "pool", "list", "list", "dict", "layers.PoolLayer.all_layers.extend", "str", "str"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "ksize", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "pool", "=", "tf", ".", "nn", ".", "max_pool2d", ",", "\n", "name", "=", "'pool_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] PoolLayer   %s: ksize:%s strides:%s padding:%s pool:%s\"", "%", "\n", "(", "self", ".", "name", ",", "str", "(", "ksize", ")", ",", "str", "(", "strides", ")", ",", "padding", ",", "pool", ".", "__name__", ")", ")", ")", "\n", "\n", "self", ".", "outputs", "=", "pool", "(", "self", ".", "inputs", ",", "ksize", "=", "ksize", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "name", ")", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.PadLayer.__init__": [[3088, 3107], ["layers.Layer.__init__", "print", "tensorflow.pad", "list", "list", "dict", "layers.PadLayer.all_layers.extend", "list", "paddings.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "paddings", "=", "None", ",", "\n", "mode", "=", "'CONSTANT'", ",", "\n", "name", "=", "'pad_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "assert", "paddings", "is", "not", "None", ",", "\"paddings should be a Tensor of type int32. see https://www.tensorflow.org/api_docs/python/tf/pad\"", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] PadLayer   %s: paddings:%s mode:%s\"", "%", "\n", "(", "self", ".", "name", ",", "list", "(", "paddings", ".", "get_shape", "(", ")", ")", ",", "mode", ")", ")", ")", "\n", "\n", "self", ".", "outputs", "=", "tf", ".", "pad", "(", "self", ".", "inputs", ",", "paddings", "=", "paddings", ",", "mode", "=", "mode", ",", "name", "=", "name", ")", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.TimeDistributedLayer.__init__": [[3142, 3181], ["layers.Layer.__init__", "print", "isinstance", "layers.TimeDistributedLayer.inputs.get_shape", "tensorflow.unstack", "tensorflow.stack", "list", "list", "dict", "layers.TimeDistributedLayer.all_layers.extend", "layers.TimeDistributedLayer.all_params.extend", "dict", "isinstance", "tensorflow.transpose", "ops.suppress_stdout", "range", "tensorflow.stack", "tensorflow.compat.v1.variable_scope", "layers.set_name_reuse", "layer_class", "tensorflow.compat.v1.get_collection", "layers.InputLayer", "str"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.ops.suppress_stdout", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.set_name_reuse"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "layer_class", "=", "None", ",", "\n", "args", "=", "{", "}", ",", "\n", "name", "=", "'time_distributed'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] TimeDistributedLayer %s: layer_class:%s args:%s\"", "%", "\n", "(", "self", ".", "name", ",", "layer_class", ".", "__name__", ",", "args", ")", ")", ")", "\n", "\n", "if", "not", "args", ":", "args", "=", "dict", "(", ")", "\n", "assert", "isinstance", "(", "args", ",", "dict", ")", ",", "\"'args' must be a dict.\"", "\n", "\n", "if", "not", "isinstance", "(", "self", ".", "inputs", ",", "tf", ".", "Tensor", ")", ":", "\n", "            ", "self", ".", "inputs", "=", "tf", ".", "transpose", "(", "tf", ".", "stack", "(", "self", ".", "inputs", ")", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "", "input_shape", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", "\n", "\n", "timestep", "=", "input_shape", "[", "1", "]", "\n", "x", "=", "tf", ".", "unstack", "(", "self", ".", "inputs", ",", "axis", "=", "1", ")", "\n", "\n", "with", "ops", ".", "suppress_stdout", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "timestep", ")", ":", "\n", "                ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "reuse", "=", "(", "False", "if", "i", "==", "0", "else", "True", ")", ")", "as", "vs", ":", "\n", "                    ", "set_name_reuse", "(", "(", "False", "if", "i", "==", "0", "else", "True", ")", ")", "\n", "net", "=", "layer_class", "(", "InputLayer", "(", "x", "[", "i", "]", ",", "name", "=", "args", "[", "'name'", "]", "+", "str", "(", "i", ")", ")", ",", "**", "args", ")", "\n", "# net = layer_class(InputLayer(x[i], name=\"input_\"+args['name']), **args)", "\n", "x", "[", "i", "]", "=", "net", ".", "outputs", "\n", "variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "", "", "", "self", ".", "outputs", "=", "tf", ".", "stack", "(", "x", ",", "axis", "=", "1", ",", "name", "=", "name", ")", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.RNNLayer.__init__": [[3332, 3449], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "print", "list", "list", "dict", "layers.RNNLayer.all_layers.extend", "layers.RNNLayer.all_params.extend", "Exception", "layers.RNNLayer.inputs.get_shape().with_rank", "layers.RNNLayer.inputs.get_shape().with_rank_at_least", "print", "print", "cell_fn", "cell_fn", "cell_fn.zero_state", "tensorflow.compat.v1.variable_scope", "range", "tensorflow.compat.v1.get_collection", "cell_init_args.pop", "Exception", "array_ops.shape", "inspect.getargspec", "cell_fn.", "outputs.append", "len", "layers.RNNLayer.inputs.get_shape", "layers.RNNLayer.inputs.get_shape", "layers.RNNLayer.inputs.get_shape", "tensorflow.compat.v1.get_variable_scope().reuse_variables", "tensorflow.reshape", "tensorflow.reshape", "layers.RNNLayer.inputs.get_shape", "tensorflow.compat.v1.get_variable_scope", "tensorflow.concat", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "tensorflow.compat.v1.get_variable_scope", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "cell_fn", "=", "None", ",", "#tf.nn.rnn_cell.BasicRNNCell,", "\n", "cell_init_args", "=", "{", "}", ",", "\n", "n_hidden", "=", "100", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "n_steps", "=", "5", ",", "\n", "initial_state", "=", "None", ",", "\n", "return_last", "=", "False", ",", "\n", "# is_reshape = True,", "\n", "return_seq_2d", "=", "False", ",", "\n", "name", "=", "'rnn_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "cell_fn", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Please put in cell_fn\"", ")", "\n", "", "if", "'GRU'", "in", "cell_fn", ".", "__name__", ":", "\n", "            ", "try", ":", "\n", "                ", "cell_init_args", ".", "pop", "(", "'state_is_tuple'", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "\n", "print", "(", "(", "\"  [TL] RNNLayer %s: n_hidden:%d n_steps:%d in_dim:%d in_shape:%s cell_fn:%s \"", "%", "(", "self", ".", "name", ",", "n_hidden", ",", "\n", "n_steps", ",", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "ndims", ",", "self", ".", "inputs", ".", "get_shape", "(", ")", ",", "cell_fn", ".", "__name__", ")", ")", ")", "\n", "# You can get the dimension by .get_shape() or ._shape, and check the", "\n", "# dimension by .with_rank() as follow.", "\n", "# self.inputs.get_shape().with_rank(2)", "\n", "# self.inputs.get_shape().with_rank(3)", "\n", "\n", "# Input dimension should be rank 3 [batch_size, n_steps(max), n_features]", "\n", "try", ":", "\n", "            ", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank", "(", "3", ")", "\n", "", "except", ":", "\n", "            ", "raise", "Exception", "(", "\"RNN : Input dimension should be rank 3 : [batch_size, n_steps, n_features]\"", ")", "\n", "\n", "\n", "# is_reshape : boolean (deprecate)", "\n", "#     Reshape the inputs to 3 dimension tensor.\\n", "\n", "#     If input is\uff3bbatch_size, n_steps, n_features], we do not need to reshape it.\\n", "\n", "#     If input is [batch_size * n_steps, n_features], we need to reshape it.", "\n", "# if is_reshape:", "\n", "#     self.inputs = tf.reshape(self.inputs, shape=[-1, n_steps, int(self.inputs._shape[-1])])", "\n", "\n", "", "fixed_batch_size", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "1", ")", "[", "0", "]", "\n", "\n", "if", "fixed_batch_size", ".", "value", ":", "\n", "            ", "batch_size", "=", "fixed_batch_size", ".", "value", "\n", "print", "(", "(", "\"       RNN batch_size (concurrent processes): %d\"", "%", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "from", "tensorflow", ".", "python", ".", "ops", "import", "array_ops", "\n", "batch_size", "=", "array_ops", ".", "shape", "(", "self", ".", "inputs", ")", "[", "0", "]", "\n", "print", "(", "\"       non specified batch_size, uses a tensor instead.\"", ")", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "# Simplified version of tensorflow.models.rnn.rnn.py's rnn().", "\n", "# This builds an unrolled LSTM for tutorial purposes only.", "\n", "# In general, use the rnn() or state_saving_rnn() from rnn.py.", "\n", "#", "\n", "# The alternative version of the code below is:", "\n", "#", "\n", "# from tensorflow.models.rnn import rnn", "\n", "# inputs = [tf.squeeze(input_, [1])", "\n", "#           for input_ in tf.split(1, num_steps, inputs)]", "\n", "# outputs, state = rnn.rnn(cell, inputs, initial_state=self._initial_state)", "\n", "outputs", "=", "[", "]", "\n", "if", "'reuse'", "in", "inspect", ".", "getargspec", "(", "cell_fn", ".", "__init__", ")", ".", "args", ":", "\n", "            ", "self", ".", "cell", "=", "cell", "=", "cell_fn", "(", "num_units", "=", "n_hidden", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ".", "reuse", ",", "**", "cell_init_args", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "cell", "=", "cell", "=", "cell_fn", "(", "num_units", "=", "n_hidden", ",", "**", "cell_init_args", ")", "\n", "", "if", "initial_state", "is", "None", ":", "\n", "            ", "self", ".", "initial_state", "=", "cell", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "# 1.2.3", "\n", "", "state", "=", "self", ".", "initial_state", "\n", "# with tf.compat.v1.variable_scope(\"model\", reuse=None, initializer=initializer):", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "initializer", "=", "initializer", ")", "as", "vs", ":", "\n", "            ", "for", "time_step", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "if", "time_step", ">", "0", ":", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "(", "cell_output", ",", "state", ")", "=", "cell", "(", "self", ".", "inputs", "[", ":", ",", "time_step", ",", ":", "]", ",", "state", ")", "\n", "outputs", ".", "append", "(", "cell_output", ")", "\n", "\n", "# Retrieve just the RNN variables.", "\n", "# rnn_variables = [v for v in tf.all_variables() if v.name.startswith(vs.name)]", "\n", "", "rnn_variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "", "print", "(", "(", "\"     n_params : %d\"", "%", "(", "len", "(", "rnn_variables", ")", ")", ")", ")", "\n", "\n", "if", "return_last", ":", "\n", "# 2D Tensor [batch_size, n_hidden]", "\n", "            ", "self", ".", "outputs", "=", "outputs", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "if", "return_seq_2d", ":", "\n", "# PTB tutorial: stack dense layer after that, or compute the cost from the output", "\n", "# 2D Tensor [n_example, n_hidden]", "\n", "                ", "try", ":", "# TF1.0", "\n", "                    ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "-", "1", ",", "n_hidden", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                    ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "n_hidden", "]", ")", "\n", "\n", "\n", "", "", "else", ":", "\n", "# <akara>: stack more RNN layer after that", "\n", "# 3D Tensor [n_example/n_steps, n_steps, n_hidden]", "\n", "                ", "try", ":", "# TF1.0", "\n", "                    ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "-", "1", ",", "n_steps", ",", "n_hidden", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                    ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "n_steps", ",", "n_hidden", "]", ")", "\n", "\n", "", "", "", "self", ".", "final_state", "=", "state", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "# print(type(self.outputs))", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "rnn_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.BiRNNLayer.__init__": [[3519, 3662], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "print", "list", "list", "dict", "layers.BiRNNLayer.all_layers.extend", "layers.BiRNNLayer.all_params.extend", "Exception", "layers.BiRNNLayer.inputs.get_shape().with_rank_at_least", "print", "print", "layers.BiRNNLayer.inputs.get_shape().with_rank", "tensorflow.compat.v1.variable_scope", "cell_creator", "cell_creator", "bidirectional_rnn_fn", "tensorflow.compat.v1.get_collection", "cell_init_args.pop", "array_ops.shape", "Exception", "cell_fn", "layers.BiRNNLayer.fw_cell.zero_state", "layers.BiRNNLayer.bw_cell.zero_state", "tensorflow.unstack", "len", "layers.BiRNNLayer.inputs.get_shape", "layers.BiRNNLayer.inputs.get_shape", "layers.BiRNNLayer.inputs.get_shape", "type", "isinstance", "DropoutWrapper_fn", "MultiRNNCell_fn", "MultiRNNCell_fn", "tensorflow.unstack", "layers.BiRNNLayer.inputs.get_shape", "Exception", "rnn_creator", "MultiRNNCell_fn", "MultiRNNCell_fn", "tensorflow.reshape", "tensorflow.reshape", "cell_creator", "cell_creator", "tensorflow.concat", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "range", "range", "cell_creator", "cell_creator", "tensorflow.concat", "tensorflow.concat", "range", "range"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "cell_fn", "=", "None", ",", "#tf.nn.rnn_cell.LSTMCell,", "\n", "cell_init_args", "=", "{", "'use_peepholes'", ":", "True", ",", "'state_is_tuple'", ":", "True", "}", ",", "\n", "n_hidden", "=", "100", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "n_steps", "=", "5", ",", "\n", "fw_initial_state", "=", "None", ",", "\n", "bw_initial_state", "=", "None", ",", "\n", "dropout", "=", "None", ",", "\n", "n_layer", "=", "1", ",", "\n", "return_last", "=", "False", ",", "\n", "return_seq_2d", "=", "False", ",", "\n", "name", "=", "'birnn_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "cell_fn", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Please put in cell_fn\"", ")", "\n", "", "if", "'GRU'", "in", "cell_fn", ".", "__name__", ":", "\n", "            ", "try", ":", "\n", "                ", "cell_init_args", ".", "pop", "(", "'state_is_tuple'", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "\n", "print", "(", "(", "\"  [TL] BiRNNLayer %s: n_hidden:%d n_steps:%d in_dim:%d in_shape:%s cell_fn:%s dropout:%s n_layer:%d \"", "%", "(", "self", ".", "name", ",", "n_hidden", ",", "\n", "n_steps", ",", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "ndims", ",", "self", ".", "inputs", ".", "get_shape", "(", ")", ",", "cell_fn", ".", "__name__", ",", "dropout", ",", "n_layer", ")", ")", ")", "\n", "\n", "fixed_batch_size", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "1", ")", "[", "0", "]", "\n", "\n", "if", "fixed_batch_size", ".", "value", ":", "\n", "            ", "self", ".", "batch_size", "=", "fixed_batch_size", ".", "value", "\n", "print", "(", "(", "\"       RNN batch_size (concurrent processes): %d\"", "%", "self", ".", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "from", "tensorflow", ".", "python", ".", "ops", "import", "array_ops", "\n", "self", ".", "batch_size", "=", "array_ops", ".", "shape", "(", "self", ".", "inputs", ")", "[", "0", "]", "\n", "print", "(", "\"       non specified batch_size, uses a tensor instead.\"", ")", "\n", "\n", "# Input dimension should be rank 3 [batch_size, n_steps(max), n_features]", "\n", "", "try", ":", "\n", "            ", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank", "(", "3", ")", "\n", "", "except", ":", "\n", "            ", "raise", "Exception", "(", "\"RNN : Input dimension should be rank 3 : [batch_size, n_steps, n_features]\"", ")", "\n", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "initializer", "=", "initializer", ")", "as", "vs", ":", "\n", "            ", "rnn_creator", "=", "lambda", ":", "cell_fn", "(", "num_units", "=", "n_hidden", ",", "**", "cell_init_args", ")", "\n", "# Apply dropout", "\n", "if", "dropout", ":", "\n", "                ", "if", "type", "(", "dropout", ")", "in", "[", "tuple", ",", "list", "]", ":", "\n", "                    ", "in_keep_prob", "=", "dropout", "[", "0", "]", "\n", "out_keep_prob", "=", "dropout", "[", "1", "]", "\n", "", "elif", "isinstance", "(", "dropout", ",", "float", ")", ":", "\n", "                    ", "in_keep_prob", ",", "out_keep_prob", "=", "dropout", ",", "dropout", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "\"Invalid dropout type (must be a 2-D tuple of \"", "\n", "\"float)\"", ")", "\n", "", "try", ":", "# TF 1.0", "\n", "                    ", "DropoutWrapper_fn", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "\n", "", "except", ":", "\n", "                    ", "DropoutWrapper_fn", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "\n", "", "cell_creator", "=", "lambda", ":", "DropoutWrapper_fn", "(", "rnn_creator", "(", ")", ",", "\n", "input_keep_prob", "=", "in_keep_prob", ",", "\n", "output_keep_prob", "=", "1.0", ")", "# out_keep_prob)", "\n", "", "else", ":", "\n", "                ", "cell_creator", "=", "rnn_creator", "\n", "", "self", ".", "fw_cell", "=", "cell_creator", "(", ")", "\n", "self", ".", "bw_cell", "=", "cell_creator", "(", ")", "\n", "\n", "# Apply multiple layers", "\n", "if", "n_layer", ">", "1", ":", "\n", "                ", "try", ":", "# TF1.0", "\n", "                    ", "MultiRNNCell_fn", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "\n", "", "except", ":", "\n", "                    ", "MultiRNNCell_fn", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "\n", "\n", "", "try", ":", "\n", "                    ", "self", ".", "fw_cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ",", "state_is_tuple", "=", "True", ")", "\n", "self", ".", "bw_cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ",", "state_is_tuple", "=", "True", ")", "\n", "", "except", ":", "\n", "                    ", "self", ".", "fw_cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ")", "\n", "self", ".", "bw_cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ")", "\n", "\n", "# Initial state of RNN", "\n", "", "", "if", "fw_initial_state", "is", "None", ":", "\n", "                ", "self", ".", "fw_initial_state", "=", "self", ".", "fw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "fw_initial_state", "=", "fw_initial_state", "\n", "", "if", "bw_initial_state", "is", "None", ":", "\n", "                ", "self", ".", "bw_initial_state", "=", "self", ".", "bw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "bw_initial_state", "=", "bw_initial_state", "\n", "# exit()", "\n", "# Feedforward to MultiRNNCell", "\n", "", "try", ":", "## TF1.0", "\n", "                ", "list_rnn_inputs", "=", "tf", ".", "unstack", "(", "self", ".", "inputs", ",", "axis", "=", "1", ")", "\n", "", "except", ":", "## TF0.12", "\n", "                ", "list_rnn_inputs", "=", "tf", ".", "unstack", "(", "self", ".", "inputs", ",", "axis", "=", "1", ")", "\n", "\n", "", "try", ":", "# TF1.0", "\n", "                ", "bidirectional_rnn_fn", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "static_bidirectional_rnn", "\n", "", "except", ":", "\n", "                ", "bidirectional_rnn_fn", "=", "tf", ".", "nn", ".", "bidirectional_rnn", "\n", "", "outputs", ",", "fw_state", ",", "bw_state", "=", "bidirectional_rnn_fn", "(", "# outputs, fw_state, bw_state = tf.contrib.rnn.static_bidirectional_rnn(", "\n", "cell_fw", "=", "self", ".", "fw_cell", ",", "\n", "cell_bw", "=", "self", ".", "bw_cell", ",", "\n", "inputs", "=", "list_rnn_inputs", ",", "\n", "initial_state_fw", "=", "self", ".", "fw_initial_state", ",", "\n", "initial_state_bw", "=", "self", ".", "bw_initial_state", "\n", ")", "\n", "\n", "if", "return_last", ":", "\n", "                ", "self", ".", "outputs", "=", "outputs", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "outputs", "=", "outputs", "\n", "if", "return_seq_2d", ":", "\n", "# 2D Tensor [n_example, n_hidden]", "\n", "                    ", "try", ":", "# TF1.0", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "-", "1", ",", "n_hidden", "*", "2", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "n_hidden", "*", "2", "]", ")", "\n", "", "", "else", ":", "\n", "# <akara>: stack more RNN layer after that", "\n", "# 3D Tensor [n_example/n_steps, n_steps, n_hidden]", "\n", "\n", "                    ", "try", ":", "# TF1.0", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "-", "1", ",", "n_steps", ",", "n_hidden", "*", "2", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "n_steps", ",", "n_hidden", "*", "2", "]", ")", "\n", "", "", "", "self", ".", "fw_final_state", "=", "fw_state", "\n", "self", ".", "bw_final_state", "=", "bw_state", "\n", "\n", "# Retrieve just the RNN variables.", "\n", "rnn_variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "", "print", "(", "(", "\"     n_params : %d\"", "%", "(", "len", "(", "rnn_variables", ")", ")", ")", ")", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "rnn_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DynamicRNNLayer.__init__": [[3893, 4058], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "cell_creator", "list", "list", "dict", "layers.DynamicRNNLayer.all_layers.extend", "layers.DynamicRNNLayer.all_params.extend", "Exception", "layers.DynamicRNNLayer.inputs.get_shape().with_rank", "layers.DynamicRNNLayer.inputs.get_shape().with_rank_at_least", "print", "print", "cell_fn", "DropoutWrapper_fn", "layers.DynamicRNNLayer.cell.zero_state", "tensorflow.compat.v1.variable_scope", "tensorflow.nn.dynamic_rnn", "tensorflow.compat.v1.get_collection", "cell_init_args.pop", "Exception", "array_ops.shape", "type", "isinstance", "DropoutWrapper_fn", "MultiRNNCell_fn", "layers.retrieve_seq_length_op", "layers.advanced_indexing_op", "layers.DynamicRNNLayer.inputs.get_shape", "layers.DynamicRNNLayer.inputs.get_shape", "layers.DynamicRNNLayer.inputs.get_shape", "Exception", "rnn_creator", "MultiRNNCell_fn", "layers.retrieve_seq_length_op", "layers.DynamicRNNLayer.inputs.get_shape", "cell_creator", "isinstance", "tensorflow.stack", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.reshape", "range", "cell_creator", "isinstance", "tensorflow.stack", "tensorflow.concat", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "range", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.retrieve_seq_length_op", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.advanced_indexing_op", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.retrieve_seq_length_op"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "cell_fn", "=", "None", ",", "#tf.nn.rnn_cell.LSTMCell,", "\n", "cell_init_args", "=", "{", "'state_is_tuple'", ":", "True", "}", ",", "\n", "n_hidden", "=", "256", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "sequence_length", "=", "None", ",", "\n", "initial_state", "=", "None", ",", "\n", "dropout", "=", "None", ",", "\n", "n_layer", "=", "1", ",", "\n", "return_last", "=", "False", ",", "\n", "return_seq_2d", "=", "False", ",", "\n", "dynamic_rnn_init_args", "=", "{", "}", ",", "\n", "name", "=", "'dyrnn_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "cell_fn", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Please put in cell_fn\"", ")", "\n", "", "if", "'GRU'", "in", "cell_fn", ".", "__name__", ":", "\n", "            ", "try", ":", "\n", "                ", "cell_init_args", ".", "pop", "(", "'state_is_tuple'", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "\n", "print", "(", "(", "\"  [TL] DynamicRNNLayer %s: n_hidden:%d, in_dim:%d in_shape:%s cell_fn:%s dropout:%s n_layer:%d\"", "%", "(", "self", ".", "name", ",", "n_hidden", ",", "\n", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "ndims", ",", "self", ".", "inputs", ".", "get_shape", "(", ")", ",", "cell_fn", ".", "__name__", ",", "dropout", ",", "n_layer", ")", ")", ")", "\n", "\n", "# Input dimension should be rank 3 [batch_size, n_steps(max), n_features]", "\n", "try", ":", "\n", "            ", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank", "(", "3", ")", "\n", "", "except", ":", "\n", "            ", "raise", "Exception", "(", "\"RNN : Input dimension should be rank 3 : [batch_size, n_steps(max), n_features]\"", ")", "\n", "\n", "# Get the batch_size", "\n", "", "fixed_batch_size", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "1", ")", "[", "0", "]", "\n", "if", "fixed_batch_size", ".", "value", ":", "\n", "            ", "batch_size", "=", "fixed_batch_size", ".", "value", "\n", "print", "(", "(", "\"       batch_size (concurrent processes): %d\"", "%", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "from", "tensorflow", ".", "python", ".", "ops", "import", "array_ops", "\n", "batch_size", "=", "array_ops", ".", "shape", "(", "self", ".", "inputs", ")", "[", "0", "]", "\n", "print", "(", "\"       non specified batch_size, uses a tensor instead.\"", ")", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "# Creats the cell function", "\n", "# cell_instance_fn=lambda: cell_fn(num_units=n_hidden, **cell_init_args) # HanSheng", "\n", "rnn_creator", "=", "lambda", ":", "cell_fn", "(", "num_units", "=", "n_hidden", ",", "**", "cell_init_args", ")", "\n", "\n", "# Apply dropout", "\n", "if", "dropout", ":", "\n", "            ", "if", "type", "(", "dropout", ")", "in", "[", "tuple", ",", "list", "]", ":", "\n", "                ", "in_keep_prob", "=", "dropout", "[", "0", "]", "\n", "out_keep_prob", "=", "dropout", "[", "1", "]", "\n", "", "elif", "isinstance", "(", "dropout", ",", "float", ")", ":", "\n", "                ", "in_keep_prob", ",", "out_keep_prob", "=", "dropout", ",", "dropout", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Invalid dropout type (must be a 2-D tuple of \"", "\n", "\"float)\"", ")", "\n", "", "try", ":", "# TF1.0", "\n", "                ", "DropoutWrapper_fn", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "\n", "", "except", ":", "\n", "                ", "DropoutWrapper_fn", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "\n", "\n", "# cell_instance_fn1=cell_instance_fn        # HanSheng", "\n", "# cell_instance_fn=DropoutWrapper_fn(", "\n", "#                     cell_instance_fn1(),", "\n", "#                     input_keep_prob=in_keep_prob,", "\n", "#                     output_keep_prob=out_keep_prob)", "\n", "", "cell_creator", "=", "lambda", ":", "DropoutWrapper_fn", "(", "rnn_creator", "(", ")", ",", "\n", "input_keep_prob", "=", "in_keep_prob", ",", "output_keep_prob", "=", "1.0", ")", "#out_keep_prob)", "\n", "", "else", ":", "\n", "            ", "cell_creator", "=", "rnn_creator", "\n", "", "self", ".", "cell", "=", "cell_creator", "(", ")", "\n", "# Apply multiple layers", "\n", "if", "n_layer", ">", "1", ":", "\n", "            ", "try", ":", "\n", "                ", "MultiRNNCell_fn", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "\n", "", "except", ":", "\n", "                ", "MultiRNNCell_fn", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "\n", "\n", "# cell_instance_fn2=cell_instance_fn # HanSheng", "\n", "", "try", ":", "\n", "# cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)], state_is_tuple=True) # HanSheng", "\n", "                ", "self", ".", "cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ",", "state_is_tuple", "=", "True", ")", "\n", "", "except", ":", "# when GRU", "\n", "# cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)]) # HanSheng", "\n", "                ", "self", ".", "cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ")", "\n", "\n", "", "", "if", "dropout", ":", "\n", "            ", "self", ".", "cell", "=", "DropoutWrapper_fn", "(", "self", ".", "cell", ",", "\n", "input_keep_prob", "=", "1.0", ",", "output_keep_prob", "=", "out_keep_prob", ")", "\n", "\n", "# self.cell=cell_instance_fn() # HanSheng", "\n", "\n", "# Initialize initial_state", "\n", "", "if", "initial_state", "is", "None", ":", "\n", "            ", "self", ".", "initial_state", "=", "self", ".", "cell", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "initial_state", "=", "initial_state", "\n", "\n", "# Computes sequence_length", "\n", "", "if", "sequence_length", "is", "None", ":", "\n", "            ", "try", ":", "## TF1.0", "\n", "                ", "sequence_length", "=", "retrieve_seq_length_op", "(", "\n", "self", ".", "inputs", "if", "isinstance", "(", "self", ".", "inputs", ",", "tf", ".", "Tensor", ")", "else", "tf", ".", "stack", "(", "self", ".", "inputs", ")", ")", "\n", "", "except", ":", "## TF0.12", "\n", "                ", "sequence_length", "=", "retrieve_seq_length_op", "(", "\n", "self", ".", "inputs", "if", "isinstance", "(", "self", ".", "inputs", ",", "tf", ".", "Tensor", ")", "else", "tf", ".", "stack", "(", "self", ".", "inputs", ")", ")", "\n", "\n", "# Main - Computes outputs and last_states", "\n", "", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "initializer", "=", "initializer", ")", "as", "vs", ":", "\n", "            ", "outputs", ",", "last_states", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "self", ".", "cell", ",", "\n", "# inputs=X", "\n", "inputs", "=", "self", ".", "inputs", ",", "\n", "# dtype=tf.float64,", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state", "=", "self", ".", "initial_state", ",", "\n", "**", "dynamic_rnn_init_args", "\n", ")", "\n", "rnn_variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "# print(\"     n_params : %d\" % (len(rnn_variables)))", "\n", "# Manage the outputs", "\n", "if", "return_last", ":", "\n", "# [batch_size, n_hidden]", "\n", "# outputs = tf.transpose(tf.pack(outputs), [1, 0, 2]) # TF1.0 tf.pack --> tf.stack", "\n", "                ", "self", ".", "outputs", "=", "advanced_indexing_op", "(", "outputs", ",", "sequence_length", ")", "\n", "", "else", ":", "\n", "# [batch_size, n_step(max), n_hidden]", "\n", "# self.outputs = result[0][\"outputs\"]", "\n", "# self.outputs = outputs    # it is 3d, but it is a list", "\n", "                ", "if", "return_seq_2d", ":", "\n", "# PTB tutorial:", "\n", "# 2D Tensor [n_example, n_hidden]", "\n", "                    ", "try", ":", "# TF1.0", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "-", "1", ",", "n_hidden", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "n_hidden", "]", ")", "\n", "", "", "else", ":", "\n", "# <akara>:", "\n", "# 3D Tensor [batch_size, n_steps(max), n_hidden]", "\n", "                    ", "max_length", "=", "tf", ".", "shape", "(", "outputs", ")", "[", "1", "]", "\n", "batch_size", "=", "tf", ".", "shape", "(", "outputs", ")", "[", "0", "]", "\n", "\n", "\n", "try", ":", "# TF1.0", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "batch_size", ",", "max_length", ",", "n_hidden", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "batch_size", ",", "max_length", ",", "n_hidden", "]", ")", "\n", "# self.outputs = tf.reshape(tf.concat(1, outputs), [-1, max_length, n_hidden])", "\n", "\n", "# Final state", "\n", "", "", "", "", "self", ".", "final_state", "=", "last_states", "\n", "\n", "self", ".", "sequence_length", "=", "sequence_length", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "rnn_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.BiDynamicRNNLayer.__init__": [[4134, 4296], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.BiDynamicRNNLayer.all_layers.extend", "layers.BiDynamicRNNLayer.all_params.extend", "Exception", "layers.BiDynamicRNNLayer.inputs.get_shape().with_rank", "layers.BiDynamicRNNLayer.inputs.get_shape().with_rank_at_least", "print", "print", "tensorflow.compat.v1.variable_scope", "cell_creator", "cell_creator", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.compat.v1.get_collection", "print", "cell_init_args.pop", "Exception", "array_ops.shape", "cell_fn", "MultiRNNCell_fn", "MultiRNNCell_fn", "layers.BiDynamicRNNLayer.fw_cell.zero_state", "layers.BiDynamicRNNLayer.bw_cell.zero_state", "tensorflow.concat", "layers.advanced_indexing_op", "layers.BiDynamicRNNLayer.inputs.get_shape", "layers.BiDynamicRNNLayer.inputs.get_shape", "layers.BiDynamicRNNLayer.inputs.get_shape", "type", "isinstance", "DropoutWrapper_fn", "layers.retrieve_seq_length_op", "len", "tensorflow.concat", "layers.BiDynamicRNNLayer.inputs.get_shape", "Exception", "rnn_creator", "cell_creator", "cell_creator", "layers.retrieve_seq_length_op", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.reshape", "range", "range", "isinstance", "tensorflow.stack", "tensorflow.concat", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "isinstance", "tensorflow.stack", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.advanced_indexing_op", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.retrieve_seq_length_op", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.retrieve_seq_length_op"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "cell_fn", "=", "None", ",", "#tf.nn.rnn_cell.LSTMCell,", "\n", "cell_init_args", "=", "{", "'state_is_tuple'", ":", "True", "}", ",", "\n", "n_hidden", "=", "256", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "sequence_length", "=", "None", ",", "\n", "fw_initial_state", "=", "None", ",", "\n", "bw_initial_state", "=", "None", ",", "\n", "dropout", "=", "None", ",", "\n", "n_layer", "=", "1", ",", "\n", "return_last", "=", "False", ",", "\n", "return_seq_2d", "=", "False", ",", "\n", "dynamic_rnn_init_args", "=", "{", "}", ",", "\n", "name", "=", "'bi_dyrnn_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "cell_fn", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Please put in cell_fn\"", ")", "\n", "", "if", "'GRU'", "in", "cell_fn", ".", "__name__", ":", "\n", "            ", "try", ":", "\n", "                ", "cell_init_args", ".", "pop", "(", "'state_is_tuple'", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "\n", "print", "(", "(", "\"  [TL] BiDynamicRNNLayer %s: n_hidden:%d in_dim:%d in_shape:%s cell_fn:%s dropout:%s n_layer:%d\"", "%", "\n", "(", "self", ".", "name", ",", "n_hidden", ",", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "ndims", ",", "self", ".", "inputs", ".", "get_shape", "(", ")", ",", "cell_fn", ".", "__name__", ",", "dropout", ",", "n_layer", ")", ")", ")", "\n", "\n", "# Input dimension should be rank 3 [batch_size, n_steps(max), n_features]", "\n", "try", ":", "\n", "            ", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank", "(", "3", ")", "\n", "", "except", ":", "\n", "            ", "raise", "Exception", "(", "\"RNN : Input dimension should be rank 3 : [batch_size, n_steps(max), n_features]\"", ")", "\n", "\n", "# Get the batch_size", "\n", "", "fixed_batch_size", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "1", ")", "[", "0", "]", "\n", "if", "fixed_batch_size", ".", "value", ":", "\n", "            ", "batch_size", "=", "fixed_batch_size", ".", "value", "\n", "print", "(", "(", "\"       batch_size (concurrent processes): %d\"", "%", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "from", "tensorflow", ".", "python", ".", "ops", "import", "array_ops", "\n", "batch_size", "=", "array_ops", ".", "shape", "(", "self", ".", "inputs", ")", "[", "0", "]", "\n", "print", "(", "\"       non specified batch_size, uses a tensor instead.\"", ")", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ",", "initializer", "=", "initializer", ")", "as", "vs", ":", "\n", "# Creats the cell function", "\n", "# cell_instance_fn=lambda: cell_fn(num_units=n_hidden, **cell_init_args) # HanSheng", "\n", "            ", "rnn_creator", "=", "lambda", ":", "cell_fn", "(", "num_units", "=", "n_hidden", ",", "**", "cell_init_args", ")", "\n", "\n", "# Apply dropout", "\n", "if", "dropout", ":", "\n", "                ", "if", "type", "(", "dropout", ")", "in", "[", "tuple", ",", "list", "]", ":", "\n", "                    ", "in_keep_prob", "=", "dropout", "[", "0", "]", "\n", "out_keep_prob", "=", "dropout", "[", "1", "]", "\n", "", "elif", "isinstance", "(", "dropout", ",", "float", ")", ":", "\n", "                    ", "in_keep_prob", ",", "out_keep_prob", "=", "dropout", ",", "dropout", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "\"Invalid dropout type (must be a 2-D tuple of \"", "\n", "\"float)\"", ")", "\n", "", "try", ":", "\n", "                    ", "DropoutWrapper_fn", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "\n", "", "except", ":", "\n", "                    ", "DropoutWrapper_fn", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "DropoutWrapper", "\n", "\n", "# cell_instance_fn1=cell_instance_fn            # HanSheng", "\n", "# cell_instance_fn=lambda: DropoutWrapper_fn(", "\n", "#                     cell_instance_fn1(),", "\n", "#                     input_keep_prob=in_keep_prob,", "\n", "#                     output_keep_prob=out_keep_prob)", "\n", "", "cell_creator", "=", "lambda", ":", "DropoutWrapper_fn", "(", "rnn_creator", "(", ")", ",", "\n", "input_keep_prob", "=", "in_keep_prob", ",", "\n", "output_keep_prob", "=", "1.0", ")", "# out_keep_prob)", "\n", "", "else", ":", "\n", "                ", "cell_creator", "=", "rnn_creator", "\n", "", "self", ".", "fw_cell", "=", "cell_creator", "(", ")", "\n", "self", ".", "bw_cell", "=", "cell_creator", "(", ")", "\n", "# Apply multiple layers", "\n", "if", "n_layer", ">", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "MultiRNNCell_fn", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "\n", "", "except", ":", "\n", "                    ", "MultiRNNCell_fn", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "\n", "\n", "# cell_instance_fn2=cell_instance_fn            # HanSheng", "\n", "# cell_instance_fn=lambda: MultiRNNCell_fn([cell_instance_fn2() for _ in range(n_layer)])", "\n", "", "self", ".", "fw_cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ")", "\n", "self", ".", "bw_cell", "=", "MultiRNNCell_fn", "(", "[", "cell_creator", "(", ")", "for", "_", "in", "range", "(", "n_layer", ")", "]", ")", "\n", "# self.fw_cell=cell_instance_fn()", "\n", "# self.bw_cell=cell_instance_fn()", "\n", "# Initial state of RNN", "\n", "", "if", "fw_initial_state", "is", "None", ":", "\n", "                ", "self", ".", "fw_initial_state", "=", "self", ".", "fw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "fw_initial_state", "=", "fw_initial_state", "\n", "", "if", "bw_initial_state", "is", "None", ":", "\n", "                ", "self", ".", "bw_initial_state", "=", "self", ".", "bw_cell", ".", "zero_state", "(", "self", ".", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "bw_initial_state", "=", "bw_initial_state", "\n", "# Computes sequence_length", "\n", "", "if", "sequence_length", "is", "None", ":", "\n", "                ", "try", ":", "## TF1.0", "\n", "                    ", "sequence_length", "=", "retrieve_seq_length_op", "(", "\n", "self", ".", "inputs", "if", "isinstance", "(", "self", ".", "inputs", ",", "tf", ".", "Tensor", ")", "else", "tf", ".", "stack", "(", "self", ".", "inputs", ")", ")", "\n", "", "except", ":", "## TF0.12", "\n", "                    ", "sequence_length", "=", "retrieve_seq_length_op", "(", "\n", "self", ".", "inputs", "if", "isinstance", "(", "self", ".", "inputs", ",", "tf", ".", "Tensor", ")", "else", "tf", ".", "stack", "(", "self", ".", "inputs", ")", ")", "\n", "\n", "", "", "outputs", ",", "(", "states_fw", ",", "states_bw", ")", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", "=", "self", ".", "fw_cell", ",", "\n", "cell_bw", "=", "self", ".", "bw_cell", ",", "\n", "inputs", "=", "self", ".", "inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state_fw", "=", "self", ".", "fw_initial_state", ",", "\n", "initial_state_bw", "=", "self", ".", "bw_initial_state", ",", "\n", "**", "dynamic_rnn_init_args", "\n", ")", "\n", "rnn_variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "print", "(", "(", "\"     n_params : %d\"", "%", "(", "len", "(", "rnn_variables", ")", ")", ")", ")", "\n", "# Manage the outputs", "\n", "try", ":", "# TF1.0", "\n", "                ", "outputs", "=", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "2", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                ", "outputs", "=", "tf", ".", "concat", "(", "axis", "=", "2", ",", "values", "=", "outputs", ")", "\n", "", "if", "return_last", ":", "\n", "# [batch_size, 2 * n_hidden]", "\n", "                ", "self", ".", "outputs", "=", "advanced_indexing_op", "(", "outputs", ",", "sequence_length", ")", "\n", "", "else", ":", "\n", "# [batch_size, n_step(max), 2 * n_hidden]", "\n", "                ", "if", "return_seq_2d", ":", "\n", "# PTB tutorial:", "\n", "# 2D Tensor [n_example, 2 * n_hidden]", "\n", "                    ", "try", ":", "# TF1.0", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "-", "1", ",", "2", "*", "n_hidden", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "-", "1", ",", "2", "*", "n_hidden", "]", ")", "\n", "", "", "else", ":", "\n", "# <akara>:", "\n", "# 3D Tensor [batch_size, n_steps(max), 2 * n_hidden]", "\n", "                    ", "max_length", "=", "tf", ".", "shape", "(", "outputs", ")", "[", "1", "]", "\n", "batch_size", "=", "tf", ".", "shape", "(", "outputs", ")", "[", "0", "]", "\n", "try", ":", "# TF1.0", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "outputs", ",", "values", "=", "1", ")", ",", "[", "batch_size", ",", "max_length", ",", "2", "*", "n_hidden", "]", ")", "\n", "", "except", ":", "# TF0.12", "\n", "                        ", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "outputs", ")", ",", "[", "batch_size", ",", "max_length", ",", "2", "*", "n_hidden", "]", ")", "\n", "# self.outputs = tf.reshape(tf.concat(1, outputs), [-1, max_length, 2 * n_hidden])", "\n", "\n", "# Final state", "\n", "", "", "", "", "self", ".", "fw_final_states", "=", "states_fw", "\n", "self", ".", "bw_final_states", "=", "states_bw", "\n", "\n", "self", ".", "sequence_length", "=", "sequence_length", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "rnn_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Seq2Seq.__init__": [[4391, 4464], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.Seq2Seq.all_layers.extend", "layers.Seq2Seq.all_params.extend", "layers.list_remove_repeat", "layers.list_remove_repeat", "Exception", "tensorflow.compat.v1.variable_scope", "layers.DynamicRNNLayer", "layers.DynamicRNNLayer", "tensorflow.compat.v1.get_collection", "cell_init_args.pop"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat"], ["def", "__init__", "(", "\n", "self", ",", "\n", "net_encode_in", "=", "None", ",", "\n", "net_decode_in", "=", "None", ",", "\n", "cell_fn", "=", "None", ",", "#tf.nn.rnn_cell.LSTMCell,", "\n", "cell_init_args", "=", "{", "'state_is_tuple'", ":", "True", "}", ",", "\n", "n_hidden", "=", "256", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "encode_sequence_length", "=", "None", ",", "\n", "decode_sequence_length", "=", "None", ",", "\n", "initial_state", "=", "None", ",", "\n", "dropout", "=", "None", ",", "\n", "n_layer", "=", "1", ",", "\n", "# return_last = False,", "\n", "return_seq_2d", "=", "False", ",", "\n", "name", "=", "'seq2seq'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "cell_fn", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Please put in cell_fn\"", ")", "\n", "", "if", "'GRU'", "in", "cell_fn", ".", "__name__", ":", "\n", "            ", "try", ":", "\n", "                ", "cell_init_args", ".", "pop", "(", "'state_is_tuple'", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "# self.inputs = layer.outputs", "\n", "", "", "print", "(", "(", "\"  [**] Seq2Seq %s: n_hidden:%d cell_fn:%s dropout:%s n_layer:%d\"", "%", "\n", "(", "self", ".", "name", ",", "n_hidden", ",", "cell_fn", ".", "__name__", ",", "dropout", ",", "n_layer", ")", ")", ")", "\n", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "#, reuse=reuse):", "\n", "# tl.layers.set_name_reuse(reuse)", "\n", "# network = InputLayer(self.inputs, name=name+'/input')", "\n", "            ", "network_encode", "=", "DynamicRNNLayer", "(", "net_encode_in", ",", "\n", "cell_fn", "=", "cell_fn", ",", "\n", "cell_init_args", "=", "cell_init_args", ",", "\n", "n_hidden", "=", "n_hidden", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "dropout", "=", "dropout", ",", "\n", "n_layer", "=", "n_layer", ",", "\n", "sequence_length", "=", "encode_sequence_length", ",", "\n", "return_last", "=", "False", ",", "\n", "return_seq_2d", "=", "True", ",", "\n", "name", "=", "name", "+", "'_encode'", ")", "\n", "# vs.reuse_variables()", "\n", "# tl.layers.set_name_reuse(True)", "\n", "network_decode", "=", "DynamicRNNLayer", "(", "net_decode_in", ",", "\n", "cell_fn", "=", "cell_fn", ",", "\n", "cell_init_args", "=", "cell_init_args", ",", "\n", "n_hidden", "=", "n_hidden", ",", "\n", "initial_state", "=", "network_encode", ".", "final_state", ",", "\n", "dropout", "=", "dropout", ",", "\n", "n_layer", "=", "n_layer", ",", "\n", "sequence_length", "=", "decode_sequence_length", ",", "\n", "return_last", "=", "False", ",", "\n", "return_seq_2d", "=", "return_seq_2d", ",", "\n", "name", "=", "name", "+", "'_decode'", ")", "\n", "self", ".", "outputs", "=", "network_decode", ".", "outputs", "\n", "\n", "rnn_variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "# Final state", "\n", "", "self", ".", "final_state", "=", "network_decode", ".", "final_state", "\n", "\n", "# self.sequence_length = sequence_length", "\n", "self", ".", "all_layers", "=", "list", "(", "network_decode", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "network_decode", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "network_decode", ".", "all_drop", ")", "\n", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "rnn_variables", ")", "\n", "\n", "self", ".", "all_layers", "=", "list_remove_repeat", "(", "self", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list_remove_repeat", "(", "self", ".", "all_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.PeekySeq2Seq.__init__": [[4471, 4494], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "Exception"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "net_encode_in", "=", "None", ",", "\n", "net_decode_in", "=", "None", ",", "\n", "cell_fn", "=", "None", ",", "#tf.nn.rnn_cell.LSTMCell,", "\n", "cell_init_args", "=", "{", "'state_is_tuple'", ":", "True", "}", ",", "\n", "n_hidden", "=", "256", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "in_sequence_length", "=", "None", ",", "\n", "out_sequence_length", "=", "None", ",", "\n", "initial_state", "=", "None", ",", "\n", "dropout", "=", "None", ",", "\n", "n_layer", "=", "1", ",", "\n", "# return_last = False,", "\n", "return_seq_2d", "=", "False", ",", "\n", "name", "=", "'peeky_seq2seq'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "cell_fn", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Please put in cell_fn\"", ")", "\n", "# self.inputs = layer.outputs", "\n", "", "print", "(", "(", "\"  [TL] PeekySeq2seq %s: n_hidden:%d cell_fn:%s dropout:%s n_layer:%d\"", "%", "\n", "(", "self", ".", "name", ",", "n_hidden", ",", "cell_fn", ".", "__name__", ",", "dropout", ",", "n_layer", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.AttentionSeq2Seq.__init__": [[4501, 4524], ["tensorflow.random_uniform_initializer", "layers.Layer.__init__", "print", "Exception"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "net_encode_in", "=", "None", ",", "\n", "net_decode_in", "=", "None", ",", "\n", "cell_fn", "=", "None", ",", "#tf.nn.rnn_cell.LSTMCell,", "\n", "cell_init_args", "=", "{", "'state_is_tuple'", ":", "True", "}", ",", "\n", "n_hidden", "=", "256", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "0.1", ",", "0.1", ")", ",", "\n", "in_sequence_length", "=", "None", ",", "\n", "out_sequence_length", "=", "None", ",", "\n", "initial_state", "=", "None", ",", "\n", "dropout", "=", "None", ",", "\n", "n_layer", "=", "1", ",", "\n", "# return_last = False,", "\n", "return_seq_2d", "=", "False", ",", "\n", "name", "=", "'attention_seq2seq'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "if", "cell_fn", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"Please put in cell_fn\"", ")", "\n", "# self.inputs = layer.outputs", "\n", "", "print", "(", "(", "\"  [TL] PeekySeq2seq %s: n_hidden:%d cell_fn:%s dropout:%s n_layer:%d\"", "%", "\n", "(", "self", ".", "name", ",", "n_hidden", ",", "cell_fn", ".", "__name__", ",", "dropout", ",", "n_layer", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.FlattenLayer.__init__": [[4559, 4573], ["layers.Layer.__init__", "layers.flatten_reshape", "int", "print", "list", "list", "dict", "layers.FlattenLayer.all_layers.extend", "layers.FlattenLayer.outputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.flatten_reshape"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "name", "=", "'flatten_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "self", ".", "outputs", "=", "flatten_reshape", "(", "self", ".", "inputs", ",", "name", "=", "name", ")", "\n", "self", ".", "n_units", "=", "int", "(", "self", ".", "outputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "print", "(", "(", "\"  [TL] FlattenLayer %s: %d\"", "%", "(", "self", ".", "name", ",", "self", ".", "n_units", ")", ")", ")", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.ReshapeLayer.__init__": [[4602, 4616], ["layers.Layer.__init__", "tensorflow.reshape", "print", "list", "list", "dict", "layers.ReshapeLayer.all_layers.extend", "layers.ReshapeLayer.outputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "shape", "=", "[", "]", ",", "\n", "name", "=", "'reshape_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "self", ".", "outputs", "=", "tf", ".", "reshape", "(", "self", ".", "inputs", ",", "shape", "=", "shape", ",", "name", "=", "name", ")", "\n", "print", "(", "(", "\"  [TL] ReshapeLayer %s: %s\"", "%", "(", "self", ".", "name", ",", "self", ".", "outputs", ".", "get_shape", "(", ")", ")", ")", ")", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.LambdaLayer.__init__": [[4642, 4663], ["layers.Layer.__init__", "print", "list", "list", "dict", "layers.LambdaLayer.all_layers.extend", "layers.LambdaLayer.all_params.extend", "tensorflow.compat.v1.variable_scope", "fn", "tensorflow.compat.v1.get_collection"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "fn", "=", "None", ",", "\n", "fn_args", "=", "{", "}", ",", "\n", "name", "=", "'lambda_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "assert", "layer", "is", "not", "None", "\n", "assert", "fn", "is", "not", "None", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] LambdaLayer  %s\"", "%", "self", ".", "name", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "self", ".", "outputs", "=", "fn", "(", "self", ".", "inputs", ",", "**", "fn_args", ")", "\n", "variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.ConcatLayer.__init__": [[4704, 4732], ["layers.Layer.__init__", "int", "print", "list", "list", "dict", "range", "layers.list_remove_repeat", "layers.list_remove_repeat", "layers.ConcatLayer.inputs.append", "tensorflow.concat", "len", "layers.ConcatLayer.all_layers.extend", "layers.ConcatLayer.all_params.extend", "layers.ConcatLayer.all_drop.update", "tensorflow.concat", "layers.ConcatLayer.outputs.get_shape", "list", "list", "dict"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "[", "]", ",", "\n", "concat_dim", "=", "1", ",", "\n", "name", "=", "'concat_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "[", "]", "\n", "for", "l", "in", "layer", ":", "\n", "            ", "self", ".", "inputs", ".", "append", "(", "l", ".", "outputs", ")", "\n", "", "try", ":", "# TF1.0", "\n", "            ", "self", ".", "outputs", "=", "tf", ".", "concat", "(", "axis", "=", "self", ".", "inputs", ",", "values", "=", "concat_dim", ",", "name", "=", "name", ")", "\n", "", "except", ":", "# TF0.12", "\n", "            ", "self", ".", "outputs", "=", "tf", ".", "concat", "(", "axis", "=", "concat_dim", ",", "values", "=", "self", ".", "inputs", ",", "name", "=", "name", ")", "\n", "", "self", ".", "n_units", "=", "int", "(", "self", ".", "outputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "print", "(", "(", "\"  [TL] ConcatLayer %s: %d\"", "%", "(", "self", ".", "name", ",", "self", ".", "n_units", ")", ")", ")", "\n", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", "[", "0", "]", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", "[", "0", "]", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", "[", "0", "]", ".", "all_drop", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "layer", ")", ")", ":", "\n", "            ", "self", ".", "all_layers", ".", "extend", "(", "list", "(", "layer", "[", "i", "]", ".", "all_layers", ")", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "list", "(", "layer", "[", "i", "]", ".", "all_params", ")", ")", "\n", "self", ".", "all_drop", ".", "update", "(", "dict", "(", "layer", "[", "i", "]", ".", "all_drop", ")", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list_remove_repeat", "(", "self", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list_remove_repeat", "(", "self", ".", "all_params", ")", "\n", "#self.all_drop = list_remove_repeat(self.all_drop) # it is a dict", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.ElementwiseLayer.__init__": [[4759, 4786], ["layers.Layer.__init__", "print", "list", "list", "dict", "range", "layers.list_remove_repeat", "layers.list_remove_repeat", "combine_fn", "len", "layers.ElementwiseLayer.all_layers.extend", "layers.ElementwiseLayer.all_params.extend", "layers.ElementwiseLayer.all_drop.update", "str", "str", "list", "list", "dict", "layer[].outputs.get_shape", "layers.ElementwiseLayer.outputs.get_shape", "l.outputs.get_shape", "layers.ElementwiseLayer.outputs.get_shape", "str", "l.outputs.get_shape"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "[", "]", ",", "\n", "combine_fn", "=", "tf", ".", "minimum", ",", "\n", "name", "=", "'elementwise_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "\n", "print", "(", "(", "\"  [TL] ElementwiseLayer %s: size:%s fn:%s\"", "%", "(", "self", ".", "name", ",", "layer", "[", "0", "]", ".", "outputs", ".", "get_shape", "(", ")", ",", "combine_fn", ".", "__name__", ")", ")", ")", "\n", "\n", "self", ".", "outputs", "=", "layer", "[", "0", "]", ".", "outputs", "\n", "# print(self.outputs._shape, type(self.outputs._shape))", "\n", "for", "l", "in", "layer", "[", "1", ":", "]", ":", "\n", "            ", "assert", "str", "(", "self", ".", "outputs", ".", "get_shape", "(", ")", ")", "==", "str", "(", "l", ".", "outputs", ".", "get_shape", "(", ")", ")", ",", "\"Hint: the input shapes should be the same. %s != %s\"", "%", "(", "self", ".", "outputs", ".", "get_shape", "(", ")", ",", "str", "(", "l", ".", "outputs", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "outputs", "=", "combine_fn", "(", "self", ".", "outputs", ",", "l", ".", "outputs", ",", "name", "=", "name", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", "[", "0", "]", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", "[", "0", "]", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", "[", "0", "]", ".", "all_drop", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "layer", ")", ")", ":", "\n", "            ", "self", ".", "all_layers", ".", "extend", "(", "list", "(", "layer", "[", "i", "]", ".", "all_layers", ")", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "list", "(", "layer", "[", "i", "]", ".", "all_params", ")", ")", "\n", "self", ".", "all_drop", ".", "update", "(", "dict", "(", "layer", "[", "i", "]", ".", "all_drop", ")", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list_remove_repeat", "(", "self", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list_remove_repeat", "(", "self", ".", "all_params", ")", "\n", "# self.all_drop = list_remove_repeat(self.all_drop)", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.ExpandDimsLayer.__init__": [[4803, 4822], ["layers.Layer.__init__", "print", "list", "list", "dict", "layers.ExpandDimsLayer.all_layers.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "axis", "=", "None", ",", "\n", "name", "=", "'expand_dims'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "\n", "print", "(", "(", "\"  [TL] ExpandDimsLayer  %s: axis:%d\"", "%", "(", "self", ".", "name", ",", "axis", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "try", ":", "# TF12 TF1.0", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "expand_dims", "(", "self", ".", "inputs", ",", "axis", "=", "axis", ")", "\n", "", "except", ":", "# TF11", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "expand_dims", "(", "self", ".", "inputs", ",", "axis", "=", "axis", ")", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "# self.all_params.extend( variables )", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.TileLayer.__init__": [[4838, 4854], ["layers.Layer.__init__", "print", "list", "list", "dict", "layers.TileLayer.all_layers.extend", "tensorflow.compat.v1.variable_scope", "tensorflow.tile"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "multiples", "=", "None", ",", "\n", "name", "=", "'tile'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "\n", "print", "(", "(", "\"  [TL] TileLayer  %s: multiples:%s\"", "%", "(", "self", ".", "name", ",", "multiples", ")", ")", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "self", ".", "outputs", "=", "tf", ".", "tile", "(", "self", ".", "inputs", ",", "multiples", "=", "multiples", ")", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "# self.all_params.extend( variables )", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.SlimNetsLayer.__init__": [[4883, 4920], ["layers.Layer.__init__", "print", "slim_layer", "tensorflow.compat.v1.get_collection", "list", "list", "list", "dict", "layers.SlimNetsLayer.all_layers.extend", "layers.SlimNetsLayer.all_params.extend", "print", "end_points.values", "slim_layers.append"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "slim_layer", "=", "None", ",", "\n", "slim_args", "=", "{", "}", ",", "\n", "name", "=", "'tfslim_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "assert", "slim_layer", "is", "not", "None", "\n", "assert", "slim_args", "is", "not", "None", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] SlimNetsLayer %s: %s\"", "%", "(", "self", ".", "name", ",", "slim_layer", ".", "__name__", ")", ")", ")", "\n", "\n", "# with tf.compat.v1.variable_scope(name) as vs:", "\n", "#     net, end_points = slim_layer(self.inputs, **slim_args)", "\n", "#     slim_variables = tf.compat.v1.get_collection(TF_GRAPHKEYS_VARIABLES, scope=vs.name)", "\n", "\n", "net", ",", "end_points", "=", "slim_layer", "(", "self", ".", "inputs", ",", "**", "slim_args", ")", "\n", "\n", "slim_variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "name", ")", "\n", "if", "slim_variables", "==", "[", "]", ":", "\n", "            ", "print", "(", "(", "\"No variables found under %s : the name of SlimNetsLayer should be matched with the begining of the ckpt file, see tutorial_inceptionV3_tfslim.py for more details\"", "%", "name", ")", ")", "\n", "\n", "\n", "", "self", ".", "outputs", "=", "net", "\n", "\n", "slim_layers", "=", "[", "]", "\n", "for", "v", "in", "list", "(", "end_points", ".", "values", "(", ")", ")", ":", "\n", "# tf.contrib.layers.summaries.summarize_activation(v)", "\n", "            ", "slim_layers", ".", "append", "(", "v", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "\n", "self", ".", "all_layers", ".", "extend", "(", "slim_layers", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "slim_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.KerasLayer.__init__": [[4937, 4958], ["layers.Layer.__init__", "print", "print", "list", "list", "dict", "layers.KerasLayer.all_layers.extend", "layers.KerasLayer.all_params.extend", "tensorflow.compat.v1.variable_scope", "keras_layer", "tensorflow.compat.v1.get_collection"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "keras_layer", "=", "None", ",", "\n", "keras_args", "=", "{", "}", ",", "\n", "name", "=", "'keras_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "assert", "layer", "is", "not", "None", "\n", "assert", "keras_layer", "is", "not", "None", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] KerasLayer %s: %s\"", "%", "(", "self", ".", "name", ",", "keras_layer", ")", ")", ")", "\n", "print", "(", "\"       This API will be removed, please use LambdaLayer instead.\"", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "self", ".", "outputs", "=", "keras_layer", "(", "self", ".", "inputs", ",", "**", "keras_args", ")", "\n", "variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.EstimatorLayer.__init__": [[4975, 4996], ["layers.Layer.__init__", "print", "print", "list", "list", "dict", "layers.EstimatorLayer.all_layers.extend", "layers.EstimatorLayer.all_params.extend", "tensorflow.compat.v1.variable_scope", "model_fn", "tensorflow.compat.v1.get_collection"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "model_fn", "=", "None", ",", "\n", "args", "=", "{", "}", ",", "\n", "name", "=", "'estimator_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "assert", "layer", "is", "not", "None", "\n", "assert", "model_fn", "is", "not", "None", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] EstimatorLayer %s: %s\"", "%", "(", "self", ".", "name", ",", "model_fn", ")", ")", ")", "\n", "print", "(", "\"       This API will be removed, please use LambdaLayer instead.\"", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "self", ".", "outputs", "=", "model_fn", "(", "self", ".", "inputs", ",", "**", "args", ")", "\n", "variables", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.PReluLayer.__init__": [[5017, 5049], ["tensorflow.constant_initializer", "layers.Layer.__init__", "print", "list", "list", "dict", "layers.PReluLayer.all_layers.extend", "layers.PReluLayer.all_params.extend", "int", "tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.get_variable", "layers.PReluLayer.inputs.get_shape", "tensorflow.nn.relu", "tensorflow.multiply", "tensorflow.nn.relu", "tensorflow.multiply", "tensorflow.abs", "tensorflow.abs"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "channel_shared", "=", "False", ",", "\n", "a_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "a_init_args", "=", "{", "}", ",", "\n", "# restore = True,", "\n", "name", "=", "\"prelu_layer\"", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "print", "(", "(", "\"  [TL] PReluLayer %s: channel_shared:%s\"", "%", "(", "self", ".", "name", ",", "channel_shared", ")", ")", ")", "\n", "if", "channel_shared", ":", "\n", "            ", "w_shape", "=", "(", "1", ",", ")", "\n", "", "else", ":", "\n", "            ", "w_shape", "=", "int", "(", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "\n", "# with tf.name_scope(name) as scope:", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "alphas", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "name", "=", "'alphas'", ",", "shape", "=", "w_shape", ",", "initializer", "=", "a_init", ",", "**", "a_init_args", ")", "\n", "try", ":", "## TF 1.0", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "nn", ".", "relu", "(", "self", ".", "inputs", ")", "+", "tf", ".", "multiply", "(", "alphas", ",", "(", "self", ".", "inputs", "-", "tf", ".", "abs", "(", "self", ".", "inputs", ")", ")", ")", "*", "0.5", "\n", "", "except", ":", "## TF 0.12", "\n", "                ", "self", ".", "outputs", "=", "tf", ".", "nn", ".", "relu", "(", "self", ".", "inputs", ")", "+", "tf", ".", "multiply", "(", "alphas", ",", "(", "self", ".", "inputs", "-", "tf", ".", "abs", "(", "self", ".", "inputs", ")", ")", ")", "*", "0.5", "\n", "\n", "\n", "", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "[", "alphas", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MultiplexerLayer.__init__": [[5103, 5137], ["layers.Layer.__init__", "len", "print", "tensorflow.compat.v1.placeholder", "tensorflow.gather", "list", "list", "dict", "range", "layers.list_remove_repeat", "layers.list_remove_repeat", "layers.MultiplexerLayer.inputs.append", "tensorflow.stack", "len", "layers.MultiplexerLayer.all_layers.extend", "layers.MultiplexerLayer.all_params.extend", "layers.MultiplexerLayer.all_drop.update", "tensorflow.stack", "list", "list", "dict"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat"], ["def", "__init__", "(", "self", ",", "\n", "layer", "=", "[", "]", ",", "\n", "name", "=", "'mux_layer'", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "n_inputs", "=", "len", "(", "layer", ")", "\n", "\n", "self", ".", "inputs", "=", "[", "]", "\n", "for", "l", "in", "layer", ":", "\n", "            ", "self", ".", "inputs", ".", "append", "(", "l", ".", "outputs", ")", "\n", "", "try", ":", "## TF1.0", "\n", "            ", "all_inputs", "=", "tf", ".", "stack", "(", "self", ".", "inputs", ",", "name", "=", "name", ")", "# pack means concat a list of tensor in a new dim  # 1.2", "\n", "", "except", ":", "\n", "            ", "all_inputs", "=", "tf", ".", "stack", "(", "self", ".", "inputs", ",", "name", "=", "name", ")", "# pack means concat a list of tensor in a new dim  # 1.2", "\n", "\n", "", "print", "(", "(", "\"  [TL] MultiplexerLayer %s: n_inputs:%d\"", "%", "(", "self", ".", "name", ",", "self", ".", "n_inputs", ")", ")", ")", "\n", "\n", "self", ".", "sel", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ")", "\n", "self", ".", "outputs", "=", "tf", ".", "gather", "(", "all_inputs", ",", "self", ".", "sel", ",", "name", "=", "name", ")", "# [sel, :, : ...] # 1.2", "\n", "\n", "# print(self.outputs, vars(self.outputs))", "\n", "#         # tf.reshape(self.outputs, shape=)", "\n", "# exit()", "\n", "# the same with ConcatLayer", "\n", "self", ".", "all_layers", "=", "list", "(", "layer", "[", "0", "]", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", "[", "0", "]", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", "[", "0", "]", ".", "all_drop", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "layer", ")", ")", ":", "\n", "            ", "self", ".", "all_layers", ".", "extend", "(", "list", "(", "layer", "[", "i", "]", ".", "all_layers", ")", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "list", "(", "layer", "[", "i", "]", ".", "all_params", ")", ")", "\n", "self", ".", "all_drop", ".", "update", "(", "dict", "(", "layer", "[", "i", "]", ".", "all_drop", ")", ")", "\n", "\n", "", "self", ".", "all_layers", "=", "list_remove_repeat", "(", "self", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list_remove_repeat", "(", "self", ".", "all_params", ")", "\n", "# self.all_drop = list_remove_repeat(self.all_drop)", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.EmbeddingAttentionSeq2seqWrapper.__init__": [[5209, 5345], ["layers.Layer.__init__", "tensorflow.Variable", "layers.EmbeddingAttentionSeq2seqWrapper.learning_rate.assign", "tensorflow.Variable", "tensorflow.compat.v1.train.Saver", "float", "Exception", "tensorflow.compat.v1.variable_scope", "cell_creator", "range", "range", "tensorflow.compat.v1.trainable_variables", "tensorflow.compat.v1.get_collection", "tensorflow.compat.v1.global_variables", "tensorflow.compat.v1.get_variable", "tensorflow.transpose", "tensorflow.compat.v1.get_variable", "tensorflow.nn.seq2seq.embedding_attention_seq2seq", "layers.EmbeddingAttentionSeq2seqWrapper.encoder_inputs.append", "layers.EmbeddingAttentionSeq2seqWrapper.decoder_inputs.append", "layers.EmbeddingAttentionSeq2seqWrapper.target_weights.append", "tensorflow.nn.seq2seq.model_with_buckets", "tensorflow.nn.seq2seq.model_with_buckets", "tensorflow.train.GradientDescentOptimizer", "range", "tensorflow.reshape", "tensorflow.nn.sampled_softmax_loss", "tensorflow.compat.v1.nn.rnn_cell.GRUCell", "tensorflow.compat.v1.nn.rnn_cell.MultiRNNCell", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.placeholder", "range", "range", "len", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "layers.EmbeddingAttentionSeq2seqWrapper.gradient_norms.append", "layers.EmbeddingAttentionSeq2seqWrapper.updates.append", "tensorflow.nn.rnn_cell.GRUCell", "tensorflow.compat.v1.nn.rnn_cell.BasicLSTMCell", "tensorflow.nn.rnn_cell.MultiRNNCell", "layers.EmbeddingAttentionSeq2seqWrapper.__init__.seq2seq_f"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "self", ",", "\n", "source_vocab_size", ",", "\n", "target_vocab_size", ",", "\n", "buckets", ",", "\n", "size", ",", "\n", "num_layers", ",", "\n", "max_gradient_norm", ",", "\n", "batch_size", ",", "\n", "learning_rate", ",", "\n", "learning_rate_decay_factor", ",", "\n", "use_lstm", "=", "False", ",", "\n", "num_samples", "=", "512", ",", "\n", "forward_only", "=", "False", ",", "\n", "name", "=", "'wrapper'", ")", ":", "\n", "    ", "Layer", ".", "__init__", "(", "self", ")", "#, name=name)", "\n", "\n", "self", ".", "source_vocab_size", "=", "source_vocab_size", "\n", "self", ".", "target_vocab_size", "=", "target_vocab_size", "\n", "self", ".", "buckets", "=", "buckets", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "tf", ".", "Variable", "(", "float", "(", "learning_rate", ")", ",", "trainable", "=", "False", ",", "name", "=", "'learning_rate'", ")", "\n", "self", ".", "learning_rate_decay_op", "=", "self", ".", "learning_rate", ".", "assign", "(", "\n", "self", ".", "learning_rate", "*", "learning_rate_decay_factor", ")", "\n", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "'global_step'", ")", "\n", "\n", "if", "tf", ".", "__version__", ">=", "\"0.12\"", ":", "\n", "        ", "raise", "Exception", "(", "\"Deprecated after TF0.12 : use other seq2seq layers instead.\"", ")", "\n", "\n", "# =========== Fake output Layer for compute cost ======", "\n", "# If we use sampled softmax, we need an output projection.", "\n", "", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "        ", "output_projection", "=", "None", "\n", "softmax_loss_function", "=", "None", "\n", "# Sampled softmax only makes sense if we sample less than vocabulary size.", "\n", "if", "num_samples", ">", "0", "and", "num_samples", "<", "self", ".", "target_vocab_size", ":", "\n", "          ", "w", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\"proj_w\"", ",", "[", "size", ",", "self", ".", "target_vocab_size", "]", ")", "\n", "w_t", "=", "tf", ".", "transpose", "(", "w", ")", "\n", "b", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable", "(", "\"proj_b\"", ",", "[", "self", ".", "target_vocab_size", "]", ")", "\n", "output_projection", "=", "(", "w", ",", "b", ")", "\n", "\n", "def", "sampled_loss", "(", "inputs", ",", "labels", ")", ":", "\n", "            ", "labels", "=", "tf", ".", "reshape", "(", "labels", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "return", "tf", ".", "nn", ".", "sampled_softmax_loss", "(", "w_t", ",", "b", ",", "inputs", ",", "labels", ",", "num_samples", ",", "\n", "self", ".", "target_vocab_size", ")", "\n", "", "softmax_loss_function", "=", "sampled_loss", "\n", "\n", "# ============ Seq Encode Layer =============", "\n", "# Create the internal multi-layer cell for our RNN.", "\n", "", "try", ":", "# TF1.0", "\n", "          ", "cell_creator", "=", "lambda", ":", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "size", ")", "\n", "", "except", ":", "\n", "          ", "cell_creator", "=", "lambda", ":", "tf", ".", "nn", ".", "rnn_cell", ".", "GRUCell", "(", "size", ")", "\n", "\n", "", "if", "use_lstm", ":", "\n", "          ", "try", ":", "# TF1.0", "\n", "            ", "cell_creator", "=", "lambda", ":", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "BasicLSTMCell", "(", "size", ")", "\n", "", "except", ":", "\n", "            ", "cell_creator", "=", "lambda", ":", "tf", ".", "nn", ".", "rnn_cell", ".", "BasicLSTMCell", "(", "size", ")", "\n", "\n", "", "", "cell", "=", "cell_creator", "(", ")", "\n", "if", "num_layers", ">", "1", ":", "\n", "          ", "try", ":", "# TF1.0", "\n", "            ", "cell", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "single_cell", "]", "*", "num_layers", ")", "\n", "", "except", ":", "\n", "            ", "cell", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "MultiRNNCell", "(", "[", "single_cell", "]", "*", "num_layers", ")", "\n", "\n", "# ============== Seq Decode Layer ============", "\n", "# The seq2seq function: we use embedding for the input and attention.", "\n", "", "", "def", "seq2seq_f", "(", "encoder_inputs", ",", "decoder_inputs", ",", "do_decode", ")", ":", "\n", "          ", "return", "tf", ".", "nn", ".", "seq2seq", ".", "embedding_attention_seq2seq", "(", "\n", "encoder_inputs", ",", "decoder_inputs", ",", "cell", ",", "\n", "num_encoder_symbols", "=", "source_vocab_size", ",", "\n", "num_decoder_symbols", "=", "target_vocab_size", ",", "\n", "embedding_size", "=", "size", ",", "\n", "output_projection", "=", "output_projection", ",", "\n", "feed_previous", "=", "do_decode", ")", "\n", "\n", "#=============================================================", "\n", "# Feeds for inputs.", "\n", "", "self", ".", "encoder_inputs", "=", "[", "]", "\n", "self", ".", "decoder_inputs", "=", "[", "]", "\n", "self", ".", "target_weights", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "buckets", "[", "-", "1", "]", "[", "0", "]", ")", ":", "# Last bucket is the biggest one.", "\n", "          ", "self", ".", "encoder_inputs", ".", "append", "(", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "\n", "name", "=", "\"encoder{0}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "", "for", "i", "in", "range", "(", "buckets", "[", "-", "1", "]", "[", "1", "]", "+", "1", ")", ":", "\n", "          ", "self", ".", "decoder_inputs", ".", "append", "(", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "\n", "name", "=", "\"decoder{0}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "self", ".", "target_weights", ".", "append", "(", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "\n", "name", "=", "\"weight{0}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "\n", "# Our targets are decoder inputs shifted by one.", "\n", "", "targets", "=", "[", "self", ".", "decoder_inputs", "[", "i", "+", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "decoder_inputs", ")", "-", "1", ")", "]", "\n", "self", ".", "targets", "=", "targets", "# DH add for debug", "\n", "\n", "\n", "# Training outputs and losses.", "\n", "if", "forward_only", ":", "\n", "          ", "self", ".", "outputs", ",", "self", ".", "losses", "=", "tf", ".", "nn", ".", "seq2seq", ".", "model_with_buckets", "(", "\n", "self", ".", "encoder_inputs", ",", "self", ".", "decoder_inputs", ",", "targets", ",", "\n", "self", ".", "target_weights", ",", "buckets", ",", "lambda", "x", ",", "y", ":", "seq2seq_f", "(", "x", ",", "y", ",", "True", ")", ",", "\n", "softmax_loss_function", "=", "softmax_loss_function", ")", "\n", "# If we use output projection, we need to project outputs for decoding.", "\n", "if", "output_projection", "is", "not", "None", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "buckets", ")", ")", ":", "\n", "              ", "self", ".", "outputs", "[", "b", "]", "=", "[", "\n", "tf", ".", "matmul", "(", "output", ",", "output_projection", "[", "0", "]", ")", "+", "output_projection", "[", "1", "]", "\n", "for", "output", "in", "self", ".", "outputs", "[", "b", "]", "\n", "]", "\n", "", "", "", "else", ":", "\n", "          ", "self", ".", "outputs", ",", "self", ".", "losses", "=", "tf", ".", "nn", ".", "seq2seq", ".", "model_with_buckets", "(", "\n", "self", ".", "encoder_inputs", ",", "self", ".", "decoder_inputs", ",", "targets", ",", "\n", "self", ".", "target_weights", ",", "buckets", ",", "\n", "lambda", "x", ",", "y", ":", "seq2seq_f", "(", "x", ",", "y", ",", "False", ")", ",", "\n", "softmax_loss_function", "=", "softmax_loss_function", ")", "\n", "\n", "# Gradients and SGD update operation for training the model.", "\n", "", "params", "=", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", "\n", "if", "not", "forward_only", ":", "\n", "          ", "self", ".", "gradient_norms", "=", "[", "]", "\n", "self", ".", "updates", "=", "[", "]", "\n", "opt", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "self", ".", "learning_rate", ")", "\n", "for", "b", "in", "range", "(", "len", "(", "buckets", ")", ")", ":", "\n", "            ", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "losses", "[", "b", "]", ",", "params", ")", "\n", "clipped_gradients", ",", "norm", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "\n", "max_gradient_norm", ")", "\n", "self", ".", "gradient_norms", ".", "append", "(", "norm", ")", "\n", "self", ".", "updates", ".", "append", "(", "opt", ".", "apply_gradients", "(", "\n", "list", "(", "zip", "(", "clipped_gradients", ",", "params", ")", ")", ",", "global_step", "=", "self", ".", "global_step", ")", ")", "\n", "\n", "# if save into npz", "\n", "", "", "self", ".", "all_params", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "TF_GRAPHKEYS_VARIABLES", ",", "scope", "=", "vs", ".", "name", ")", "\n", "\n", "# if save into ckpt", "\n", "", "self", ".", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.EmbeddingAttentionSeq2seqWrapper.step": [[5346, 5414], ["range", "range", "numpy.zeros", "session.run", "len", "ValueError", "len", "ValueError", "len", "ValueError", "range", "output_feed.append", "len", "len", "len"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "session", ",", "encoder_inputs", ",", "decoder_inputs", ",", "target_weights", ",", "\n", "bucket_id", ",", "forward_only", ")", ":", "\n", "    ", "\"\"\"Run a step of the model feeding the given inputs.\n\n    Parameters\n    ----------\n    session : tensorflow session to use.\n    encoder_inputs : list of numpy int vectors to feed as encoder inputs.\n    decoder_inputs : list of numpy int vectors to feed as decoder inputs.\n    target_weights : list of numpy float vectors to feed as target weights.\n    bucket_id : which bucket of the model to use.\n    forward_only : whether to do the backward step or only forward.\n\n    Returns\n    --------\n    A triple consisting of gradient norm (or None if we did not do backward),\n    average perplexity, and the outputs.\n\n    Raises\n    --------\n    ValueError : if length of encoder_inputs, decoder_inputs, or\n        target_weights disagrees with bucket size for the specified bucket_id.\n    \"\"\"", "\n", "# Check if the sizes match.", "\n", "encoder_size", ",", "decoder_size", "=", "self", ".", "buckets", "[", "bucket_id", "]", "\n", "if", "len", "(", "encoder_inputs", ")", "!=", "encoder_size", ":", "\n", "      ", "raise", "ValueError", "(", "\"Encoder length must be equal to the one in bucket,\"", "\n", "\" %d != %d.\"", "%", "(", "len", "(", "encoder_inputs", ")", ",", "encoder_size", ")", ")", "\n", "", "if", "len", "(", "decoder_inputs", ")", "!=", "decoder_size", ":", "\n", "      ", "raise", "ValueError", "(", "\"Decoder length must be equal to the one in bucket,\"", "\n", "\" %d != %d.\"", "%", "(", "len", "(", "decoder_inputs", ")", ",", "decoder_size", ")", ")", "\n", "", "if", "len", "(", "target_weights", ")", "!=", "decoder_size", ":", "\n", "      ", "raise", "ValueError", "(", "\"Weights length must be equal to the one in bucket,\"", "\n", "\" %d != %d.\"", "%", "(", "len", "(", "target_weights", ")", ",", "decoder_size", ")", ")", "\n", "# print('in model.step()')", "\n", "# print('a',bucket_id, encoder_size, decoder_size)", "\n", "\n", "# Input feed: encoder inputs, decoder inputs, target_weights, as provided.", "\n", "", "input_feed", "=", "{", "}", "\n", "for", "l", "in", "range", "(", "encoder_size", ")", ":", "\n", "      ", "input_feed", "[", "self", ".", "encoder_inputs", "[", "l", "]", ".", "name", "]", "=", "encoder_inputs", "[", "l", "]", "\n", "", "for", "l", "in", "range", "(", "decoder_size", ")", ":", "\n", "      ", "input_feed", "[", "self", ".", "decoder_inputs", "[", "l", "]", ".", "name", "]", "=", "decoder_inputs", "[", "l", "]", "\n", "input_feed", "[", "self", ".", "target_weights", "[", "l", "]", ".", "name", "]", "=", "target_weights", "[", "l", "]", "\n", "# print(self.encoder_inputs[l].name)", "\n", "# print(self.decoder_inputs[l].name)", "\n", "# print(self.target_weights[l].name)", "\n", "\n", "# Since our targets are decoder inputs shifted by one, we need one more.", "\n", "", "last_target", "=", "self", ".", "decoder_inputs", "[", "decoder_size", "]", ".", "name", "\n", "input_feed", "[", "last_target", "]", "=", "np", ".", "zeros", "(", "[", "self", ".", "batch_size", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# print('last_target', last_target)", "\n", "\n", "# Output feed: depends on whether we do a backward step or not.", "\n", "if", "not", "forward_only", ":", "\n", "      ", "output_feed", "=", "[", "self", ".", "updates", "[", "bucket_id", "]", ",", "# Update Op that does SGD.", "\n", "self", ".", "gradient_norms", "[", "bucket_id", "]", ",", "# Gradient norm.", "\n", "self", ".", "losses", "[", "bucket_id", "]", "]", "# Loss for this batch.", "\n", "", "else", ":", "\n", "      ", "output_feed", "=", "[", "self", ".", "losses", "[", "bucket_id", "]", "]", "# Loss for this batch.", "\n", "for", "l", "in", "range", "(", "decoder_size", ")", ":", "# Output logits.", "\n", "        ", "output_feed", ".", "append", "(", "self", ".", "outputs", "[", "bucket_id", "]", "[", "l", "]", ")", "\n", "\n", "", "", "outputs", "=", "session", ".", "run", "(", "output_feed", ",", "input_feed", ")", "\n", "if", "not", "forward_only", ":", "\n", "      ", "return", "outputs", "[", "1", "]", ",", "outputs", "[", "2", "]", ",", "None", "# Gradient norm, loss, no outputs.", "\n", "", "else", ":", "\n", "      ", "return", "None", ",", "outputs", "[", "0", "]", ",", "outputs", "[", "1", ":", "]", "# No gradient norm, loss, outputs.", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.EmbeddingAttentionSeq2seqWrapper.get_batch": [[5415, 5484], ["range", "range", "range", "random.choice", "encoder_inputs.append", "decoder_inputs.append", "batch_encoder_inputs.append", "batch_decoder_inputs.append", "numpy.ones", "range", "batch_weights.append", "list", "numpy.array", "numpy.array", "len", "reversed", "len", "range", "range"], "methods", ["None"], ["", "", "def", "get_batch", "(", "self", ",", "data", ",", "bucket_id", ",", "PAD_ID", "=", "0", ",", "GO_ID", "=", "1", ",", "EOS_ID", "=", "2", ",", "UNK_ID", "=", "3", ")", ":", "\n", "    ", "\"\"\" Get a random batch of data from the specified bucket, prepare for step.\n\n    To feed data in step(..) it must be a list of batch-major vectors, while\n    data here contains single length-major cases. So the main logic of this\n    function is to re-index data cases to be in the proper format for feeding.\n\n    Parameters\n    ----------\n    data : a tuple of size len(self.buckets) in which each element contains\n        lists of pairs of input and output data that we use to create a batch.\n    bucket_id : integer, which bucket to get the batch for.\n    PAD_ID : int\n        Index of Padding in vocabulary\n    GO_ID : int\n        Index of GO in vocabulary\n    EOS_ID : int\n        Index of End of sentence in vocabulary\n    UNK_ID : int\n        Index of Unknown word in vocabulary\n\n    Returns\n    -------\n    The triple (encoder_inputs, decoder_inputs, target_weights) for\n    the constructed batch that has the proper format to call step(...) later.\n    \"\"\"", "\n", "encoder_size", ",", "decoder_size", "=", "self", ".", "buckets", "[", "bucket_id", "]", "\n", "encoder_inputs", ",", "decoder_inputs", "=", "[", "]", ",", "[", "]", "\n", "\n", "# Get a random batch of encoder and decoder inputs from data,", "\n", "# pad them if needed, reverse encoder inputs and add GO to decoder.", "\n", "for", "_", "in", "range", "(", "self", ".", "batch_size", ")", ":", "\n", "      ", "encoder_input", ",", "decoder_input", "=", "random", ".", "choice", "(", "data", "[", "bucket_id", "]", ")", "\n", "\n", "# Encoder inputs are padded and then reversed.", "\n", "encoder_pad", "=", "[", "PAD_ID", "]", "*", "(", "encoder_size", "-", "len", "(", "encoder_input", ")", ")", "\n", "encoder_inputs", ".", "append", "(", "list", "(", "reversed", "(", "encoder_input", "+", "encoder_pad", ")", ")", ")", "\n", "\n", "# Decoder inputs get an extra \"GO\" symbol, and are padded then.", "\n", "decoder_pad_size", "=", "decoder_size", "-", "len", "(", "decoder_input", ")", "-", "1", "\n", "decoder_inputs", ".", "append", "(", "[", "GO_ID", "]", "+", "decoder_input", "+", "\n", "[", "PAD_ID", "]", "*", "decoder_pad_size", ")", "\n", "\n", "# Now we create batch-major vectors from the data selected above.", "\n", "", "batch_encoder_inputs", ",", "batch_decoder_inputs", ",", "batch_weights", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "# Batch encoder inputs are just re-indexed encoder_inputs.", "\n", "for", "length_idx", "in", "range", "(", "encoder_size", ")", ":", "\n", "      ", "batch_encoder_inputs", ".", "append", "(", "\n", "np", ".", "array", "(", "[", "encoder_inputs", "[", "batch_idx", "]", "[", "length_idx", "]", "\n", "for", "batch_idx", "in", "range", "(", "self", ".", "batch_size", ")", "]", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n", "# Batch decoder inputs are re-indexed decoder_inputs, we create weights.", "\n", "", "for", "length_idx", "in", "range", "(", "decoder_size", ")", ":", "\n", "      ", "batch_decoder_inputs", ".", "append", "(", "\n", "np", ".", "array", "(", "[", "decoder_inputs", "[", "batch_idx", "]", "[", "length_idx", "]", "\n", "for", "batch_idx", "in", "range", "(", "self", ".", "batch_size", ")", "]", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n", "# Create target_weights to be 0 for targets that are padding.", "\n", "batch_weight", "=", "np", ".", "ones", "(", "self", ".", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "batch_idx", "in", "range", "(", "self", ".", "batch_size", ")", ":", "\n", "# We set weight to 0 if the corresponding target is a PAD symbol.", "\n", "# The corresponding target is decoder_input shifted by 1 forward.", "\n", "        ", "if", "length_idx", "<", "decoder_size", "-", "1", ":", "\n", "          ", "target", "=", "decoder_inputs", "[", "batch_idx", "]", "[", "length_idx", "+", "1", "]", "\n", "", "if", "length_idx", "==", "decoder_size", "-", "1", "or", "target", "==", "PAD_ID", ":", "\n", "          ", "batch_weight", "[", "batch_idx", "]", "=", "0.0", "\n", "", "", "batch_weights", ".", "append", "(", "batch_weight", ")", "\n", "", "return", "batch_encoder_inputs", ",", "batch_decoder_inputs", ",", "batch_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MaxoutLayer.__init__": [[5496, 5522], ["layers.Layer.__init__", "print", "print", "list", "list", "dict", "layers.MaxoutLayer.all_layers.extend", "layers.MaxoutLayer.all_params.extend", "tensorflow.compat.v1.variable_scope"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layer", "=", "None", ",", "\n", "n_units", "=", "100", ",", "\n", "name", "=", "'maxout_layer'", ",", "\n", ")", ":", "\n", "        ", "Layer", ".", "__init__", "(", "self", ",", "name", "=", "name", ")", "\n", "self", ".", "inputs", "=", "layer", ".", "outputs", "\n", "\n", "print", "(", "(", "\"  [TL] MaxoutLayer %s: %d\"", "%", "(", "self", ".", "name", ",", "self", ".", "n_units", ")", ")", ")", "\n", "print", "(", "\"    Waiting for contribution\"", ")", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "            ", "pass", "\n", "# W = tf.Variable(init.xavier_init(n_inputs=n_in, n_outputs=n_units, uniform=True), name='W')", "\n", "# b = tf.Variable(tf.zeros([n_units]), name='b')", "\n", "\n", "# self.outputs = act(tf.matmul(self.inputs, W) + b)", "\n", "# https://www.tensorflow.org/versions/r0.9/api_docs/python/array_ops.html#pack", "\n", "# http://stackoverflow.com/questions/34362193/how-to-explicitly-broadcast-a-tensor-to-match-anothers-shape-in-tensorflow", "\n", "# tf.concat tf.pack  tf.tile", "\n", "\n", "", "self", ".", "all_layers", "=", "list", "(", "layer", ".", "all_layers", ")", "\n", "self", ".", "all_params", "=", "list", "(", "layer", ".", "all_params", ")", "\n", "self", ".", "all_drop", "=", "dict", "(", "layer", ".", "all_drop", ")", "\n", "self", ".", "all_layers", ".", "extend", "(", "[", "self", ".", "outputs", "]", ")", "\n", "self", ".", "all_params", ".", "extend", "(", "[", "W", ",", "b", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.flatten_reshape": [[36, 65], ["[].as_list", "tensorflow.reshape", "variable.get_shape"], "function", ["None"], ["", "def", "flatten_reshape", "(", "variable", ",", "name", "=", "''", ")", ":", "\n", "    ", "\"\"\"Reshapes high-dimension input to a vector.\n    [batch_size, mask_row, mask_col, n_mask] ---> [batch_size, mask_row * mask_col * n_mask]\n\n    Parameters\n    ----------\n    variable : a tensorflow variable\n    name : a string or None\n        An optional name to attach to this layer.\n\n    Examples\n    --------\n    >>> W_conv2 = weight_variable([5, 5, 100, 32])   # 64 features for each 5x5 patch\n    >>> b_conv2 = bias_variable([32])\n    >>> W_fc1 = weight_variable([7 * 7 * 32, 256])\n\n    >>> h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n    >>> h_pool2 = max_pool_2x2(h_conv2)\n    >>> h_pool2.get_shape()[:].as_list() = [batch_size, 7, 7, 32]\n    ...         [batch_size, mask_row, mask_col, n_mask]\n    >>> h_pool2_flat = tl.layers.flatten_reshape(h_pool2)\n    ...         [batch_size, mask_row * mask_col * n_mask]\n    >>> h_pool2_flat_drop = tf.nn.dropout(h_pool2_flat, keep_prob)\n    ...\n    \"\"\"", "\n", "dim", "=", "1", "\n", "for", "d", "in", "variable", ".", "get_shape", "(", ")", "[", "1", ":", "]", ".", "as_list", "(", ")", ":", "\n", "        ", "dim", "*=", "d", "\n", "", "return", "tf", ".", "reshape", "(", "variable", ",", "shape", "=", "[", "-", "1", ",", "dim", "]", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.clear_layers_name": [[66, 81], ["None"], "function", ["None"], ["", "def", "clear_layers_name", "(", ")", ":", "\n", "    ", "\"\"\"Clear all layer names in set_keep['_layers_name_list'],\n    enable layer name reuse.\n\n    Examples\n    ---------\n    >>> network = tl.layers.InputLayer(x, name='input_layer')\n    >>> network = tl.layers.DenseLayer(network, n_units=800, name='relu1')\n    ...\n    >>> tl.layers.clear_layers_name()\n    >>> network2 = tl.layers.InputLayer(x, name='input_layer')\n    >>> network2 = tl.layers.DenseLayer(network2, n_units=800, name='relu1')\n    ...\n    \"\"\"", "\n", "set_keep", "[", "'_layers_name_list'", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.set_name_reuse": [[82, 118], ["None"], "function", ["None"], ["", "def", "set_name_reuse", "(", "enable", "=", "True", ")", ":", "\n", "    ", "\"\"\"Enable or disable reuse layer name. By default, each layer must has unique\n    name. When you want two or more input placeholder (inference) share the same\n    model parameters, you need to enable layer name reuse, then allow the\n    parameters have same name scope.\n\n    Parameters\n    ------------\n    enable : boolean, enable name reuse.\n\n    Examples\n    ------------\n    >>> def embed_seq(input_seqs, is_train, reuse):\n    >>>    with tf.compat.v1.variable_scope(\"model\", reuse=reuse):\n    >>>         tl.layers.set_name_reuse(reuse)\n    >>>         network = tl.layers.EmbeddingInputlayer(\n    ...                     inputs = input_seqs,\n    ...                     vocabulary_size = vocab_size,\n    ...                     embedding_size = embedding_size,\n    ...                     name = 'e_embedding')\n    >>>        network = tl.layers.DynamicRNNLayer(network,\n    ...                     cell_fn = tf.nn.rnn_cell.BasicLSTMCell,\n    ...                     n_hidden = embedding_size,\n    ...                     dropout = (0.7 if is_train else None),\n    ...                     initializer = w_init,\n    ...                     sequence_length = tl.layers.retrieve_seq_length_op2(input_seqs),\n    ...                     return_last = True,\n    ...                     name = 'e_dynamicrnn',)\n    >>>    return network\n    >>>\n    >>> net_train = embed_seq(t_caption, is_train=True, reuse=False)\n    >>> net_test = embed_seq(t_caption, is_train=False, reuse=True)\n\n    - see ``tutorial_ptb_lstm.py`` for example.\n    \"\"\"", "\n", "set_keep", "[", "'name_reuse'", "]", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.initialize_rnn_state": [[119, 139], ["isinstance", "state.c.eval", "state.h.eval", "state.eval"], "function", ["None"], ["", "def", "initialize_rnn_state", "(", "state", ")", ":", "\n", "    ", "\"\"\"Return the initialized RNN state.\n    The input is LSTMStateTuple or State of RNNCells.\n\n    Parameters\n    -----------\n    state : a RNN state.\n    \"\"\"", "\n", "try", ":", "# TF1.0", "\n", "        ", "LSTMStateTuple", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "rnn_cell", ".", "LSTMStateTuple", "\n", "", "except", ":", "\n", "        ", "LSTMStateTuple", "=", "tf", ".", "nn", ".", "rnn_cell", ".", "LSTMStateTuple", "\n", "\n", "", "if", "isinstance", "(", "state", ",", "LSTMStateTuple", ")", ":", "\n", "        ", "c", "=", "state", ".", "c", ".", "eval", "(", ")", "\n", "h", "=", "state", ".", "h", ".", "eval", "(", ")", "\n", "return", "(", "c", ",", "h", ")", "\n", "", "else", ":", "\n", "        ", "new_state", "=", "state", ".", "eval", "(", ")", "\n", "return", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.print_all_variables": [[140, 161], ["enumerate", "tensorflow.compat.v1.trainable_variables", "print", "print", "print", "tensorflow.compat.v1.global_variables", "tensorflow.compat.v1.global_variables", "str", "v.get_shape"], "function", ["None"], ["", "", "def", "print_all_variables", "(", "train_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"Print all trainable and non-trainable variables\n    without tl.layers.initialize_global_variables(sess)\n\n    Parameters\n    ----------\n    train_only : boolean\n        If True, only print the trainable variables, otherwise, print all variables.\n    \"\"\"", "\n", "# tvar = tf.compat.v1.trainable_variables() if train_only else tf.all_variables()", "\n", "if", "train_only", ":", "\n", "        ", "t_vars", "=", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", "\n", "print", "(", "\"  [*] printing trainable variables\"", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "# TF1.0", "\n", "            ", "t_vars", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", "\n", "", "except", ":", "# TF0.12", "\n", "            ", "t_vars", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", "\n", "", "print", "(", "\"  [*] printing global variables\"", ")", "\n", "", "for", "idx", ",", "v", "in", "enumerate", "(", "t_vars", ")", ":", "\n", "        ", "print", "(", "(", "\"  var {:3}: {:15}   {}\"", ".", "format", "(", "idx", ",", "str", "(", "v", ".", "get_shape", "(", ")", ")", ",", "v", ".", "name", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.get_variables_with_name": [[162, 184], ["print", "tensorflow.compat.v1.trainable_variables", "enumerate", "tensorflow.compat.v1.global_variables", "print", "tensorflow.compat.v1.global_variables", "str", "v.get_shape"], "function", ["None"], ["", "", "def", "get_variables_with_name", "(", "name", ",", "train_only", "=", "True", ",", "printable", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get variable list by a given name scope.\n\n    Examples\n    ---------\n    >>> dense_vars = tl.layers.get_variable_with_name('dense', True, True)\n    \"\"\"", "\n", "print", "(", "(", "\"  [*] geting variables with %s\"", "%", "name", ")", ")", "\n", "# tvar = tf.compat.v1.trainable_variables() if train_only else tf.all_variables()", "\n", "if", "train_only", ":", "\n", "        ", "t_vars", "=", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "# TF1.0", "\n", "            ", "t_vars", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", "\n", "", "except", ":", "# TF0.12", "\n", "            ", "t_vars", "=", "tf", ".", "compat", ".", "v1", ".", "global_variables", "(", ")", "\n", "\n", "", "", "d_vars", "=", "[", "var", "for", "var", "in", "t_vars", "if", "name", "in", "var", ".", "name", "]", "\n", "if", "printable", ":", "\n", "        ", "for", "idx", ",", "v", "in", "enumerate", "(", "d_vars", ")", ":", "\n", "            ", "print", "(", "(", "\"  got {:3}: {:15}   {}\"", ".", "format", "(", "idx", ",", "v", ".", "name", ",", "str", "(", "v", ".", "get_shape", "(", ")", ")", ")", ")", ")", "\n", "", "", "return", "d_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.get_layers_with_name": [[185, 206], ["print", "layers.append", "print", "str", "layer.get_shape"], "function", ["None"], ["", "def", "get_layers_with_name", "(", "network", "=", "None", ",", "name", "=", "\"\"", ",", "printable", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get layer list in a network by a given name scope.\n\n    Examples\n    ---------\n    >>> layers = tl.layers.get_layers_with_name(network, \"CNN\", True)\n    \"\"\"", "\n", "assert", "network", "is", "not", "None", "\n", "print", "(", "(", "\"  [*] geting layers with %s\"", "%", "name", ")", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "i", "=", "0", "\n", "for", "layer", "in", "network", ".", "all_layers", ":", "\n", "# print(type(layer.name))", "\n", "        ", "if", "name", "in", "layer", ".", "name", ":", "\n", "            ", "layers", ".", "append", "(", "layer", ")", "\n", "if", "printable", ":", "\n", "# print(layer.name)", "\n", "                ", "print", "(", "(", "\"  got {:3}: {:15}   {}\"", ".", "format", "(", "i", ",", "layer", ".", "name", ",", "str", "(", "layer", ".", "get_shape", "(", ")", ")", ")", ")", ")", "\n", "i", "=", "i", "+", "1", "\n", "", "", "", "return", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.list_remove_repeat": [[207, 224], ["l2.append"], "function", ["None"], ["", "def", "list_remove_repeat", "(", "l", "=", "None", ")", ":", "\n", "    ", "\"\"\"Remove the repeated items in a list, and return the processed list.\n    You may need it to create merged layer like Concat, Elementwise and etc.\n\n    Parameters\n    ----------\n    l : a list\n\n    Examples\n    ---------\n    >>> l = [2, 3, 4, 2, 3]\n    >>> l = list_remove_repeat(l)\n    ... [2, 3, 4]\n    \"\"\"", "\n", "l2", "=", "[", "]", "\n", "[", "l2", ".", "append", "(", "i", ")", "for", "i", "in", "l", "if", "not", "i", "in", "l2", "]", "\n", "return", "l2", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.initialize_global_variables": [[225, 238], ["sess.run", "tensorflow.compat.v1.global_variables_initializer", "sess.run", "tensorflow.compat.v1.global_variables_initializer"], "function", ["None"], ["", "def", "initialize_global_variables", "(", "sess", "=", "None", ")", ":", "\n", "    ", "\"\"\"Excute ``sess.run(tf.compat.v1.global_variables_initializer())`` for TF12+ or\n    sess.run(tf.initialize_all_variables()) for TF11.\n\n    Parameters\n    ----------\n    sess : a Session\n    \"\"\"", "\n", "assert", "sess", "is", "not", "None", "\n", "try", ":", "# TF12", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", ")", "\n", "", "except", ":", "# TF11", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.deconv2d_bilinear_upsampling_initializer": [[1745, 1805], ["numpy.zeros", "range", "numpy.zeros", "range", "tensorflow.constant_initializer", "Exception", "Exception", "range", "abs", "abs"], "function", ["None"], ["", "", "def", "deconv2d_bilinear_upsampling_initializer", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Returns initializer that can be passed to DeConv2dLayer to initalize the\n    weights to correspond to channel wise bilinear upsampling.\n    Used in some segmantic segmentation approches such as [FCN](https://arxiv.org/abs/1605.06211)\n\n    Parameters\n    ----------\n        shape : list of shape\n            shape of the filters, [height, width, output_channels, in_channels], must match that passed to DeConv2dLayer\n\n    Returns\n    ----------\n        tf.constant_initializer\n            with weights set to correspond to per channel bilinear upsampling when passed as W_int in DeConv2dLayer\n\n    Examples\n    --------\n    >>> rescale_factor = 2 #upsampling by a factor of 2, ie e.g 100->200\n    >>> filter_size = (2 * rescale_factor - rescale_factor % 2) #Corresponding bilinear filter size\n    >>> num_in_channels = 3\n    >>> num_out_channels = 3\n    >>> deconv_filter_shape = [filter_size, filter_size, num_out_channels, num_in_channels]\n    >>> x = tf.compat.v1.placeholder(tf.float32, [1, imsize, imsize, num_channels])\n    >>> network = tl.layers.InputLayer(x, name='input_layer')\n    >>> bilinear_init = deconv2d_bilinear_upsampling_initializer(shape=filter_shape)\n    >>> network = tl.layers.DeConv2dLayer(network,\n                            shape = filter_shape,\n                            output_shape = [1, imsize*rescale_factor, imsize*rescale_factor, num_out_channels],\n                            strides=[1, rescale_factor, rescale_factor, 1],\n                            W_init=bilinear_init,\n                            padding='SAME',\n                            act=tf.identity, name='g/h1/decon2d')\n    \"\"\"", "\n", "if", "shape", "[", "0", "]", "!=", "shape", "[", "1", "]", ":", "\n", "        ", "raise", "Exception", "(", "'deconv2d_bilinear_upsampling_initializer only supports symmetrical filter sizes'", ")", "\n", "", "if", "shape", "[", "3", "]", "<", "shape", "[", "2", "]", ":", "\n", "        ", "raise", "Exception", "(", "'deconv2d_bilinear_upsampling_initializer behaviour is not defined for num_in_channels < num_out_channels '", ")", "\n", "\n", "", "filter_size", "=", "shape", "[", "0", "]", "\n", "num_out_channels", "=", "shape", "[", "2", "]", "\n", "num_in_channels", "=", "shape", "[", "3", "]", "\n", "\n", "#Create bilinear filter kernel as numpy array", "\n", "bilinear_kernel", "=", "np", ".", "zeros", "(", "[", "filter_size", ",", "filter_size", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "scale_factor", "=", "(", "filter_size", "+", "1", ")", "//", "2", "\n", "if", "filter_size", "%", "2", "==", "1", ":", "\n", "        ", "center", "=", "scale_factor", "-", "1", "\n", "", "else", ":", "\n", "        ", "center", "=", "scale_factor", "-", "0.5", "\n", "", "for", "x", "in", "range", "(", "filter_size", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "filter_size", ")", ":", "\n", "            ", "bilinear_kernel", "[", "x", ",", "y", "]", "=", "(", "1", "-", "abs", "(", "x", "-", "center", ")", "/", "scale_factor", ")", "*", "(", "1", "-", "abs", "(", "y", "-", "center", ")", "/", "scale_factor", ")", "\n", "", "", "weights", "=", "np", ".", "zeros", "(", "(", "filter_size", ",", "filter_size", ",", "num_out_channels", ",", "num_in_channels", ")", ")", "\n", "for", "i", "in", "range", "(", "num_out_channels", ")", ":", "\n", "        ", "weights", "[", ":", ",", ":", ",", "i", ",", "i", "]", "=", "bilinear_kernel", "\n", "\n", "#assign numpy array to constant_initalizer and pass to get_variable", "\n", "", "bilinear_weights_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "weights", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "bilinear_weights_init", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Conv1d": [[1807, 1839], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Conv1dLayer", "int", "Conv1dLayer.outputs.get_shape"], "function", ["None"], ["", "def", "Conv1d", "(", "net", ",", "n_filter", "=", "32", ",", "filter_size", "=", "5", ",", "stride", "=", "1", ",", "act", "=", "None", ",", "\n", "padding", "=", "'SAME'", ",", "use_cudnn_on_gpu", "=", "None", ",", "data_format", "=", "None", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "\n", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "b_init_args", "=", "{", "}", ",", "name", "=", "'conv1d'", ",", ")", ":", "\n", "    ", "\"\"\"Wrapper for :class:`Conv1dLayer`, if you don't understand how to use :class:`Conv1dLayer`, this function may be easier.\n\n    Parameters\n    ----------\n    net : TensorLayer layer.\n    n_filter : number of filter.\n    filter_size : an int.\n    stride : an int.\n    act : None or activation function.\n    others : see :class:`Conv1dLayer`.\n    \"\"\"", "\n", "if", "act", "is", "None", ":", "\n", "        ", "act", "=", "tf", ".", "identity", "\n", "", "net", "=", "Conv1dLayer", "(", "layer", "=", "net", ",", "\n", "act", "=", "act", ",", "\n", "shape", "=", "[", "filter_size", ",", "int", "(", "net", ".", "outputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", ",", "n_filter", "]", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "use_cudnn_on_gpu", "=", "use_cudnn_on_gpu", ",", "\n", "data_format", "=", "data_format", ",", "\n", "W_init", "=", "W_init", ",", "\n", "b_init", "=", "b_init", ",", "\n", "W_init_args", "=", "W_init_args", ",", "\n", "b_init_args", "=", "b_init_args", ",", "\n", "name", "=", "name", ",", "\n", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.Conv2d": [[1840, 1882], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.Conv2dLayer", "len", "int", "Conv2dLayer.outputs.get_shape"], "function", ["None"], ["", "def", "Conv2d", "(", "net", ",", "n_filter", "=", "32", ",", "filter_size", "=", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "act", "=", "None", ",", "\n", "padding", "=", "'SAME'", ",", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "b_init_args", "=", "{", "}", ",", "use_cudnn_on_gpu", "=", "None", ",", "data_format", "=", "None", ",", "name", "=", "'conv2d'", ",", ")", ":", "\n", "    ", "\"\"\"Wrapper for :class:`Conv2dLayer`, if you don't understand how to use :class:`Conv2dLayer`, this function may be easier.\n\n    Parameters\n    ----------\n    net : TensorLayer layer.\n    n_filter : number of filter.\n    filter_size : tuple (height, width) for filter size.\n    strides : tuple (height, width) for strides.\n    act : None or activation function.\n    others : see :class:`Conv2dLayer`.\n\n    Examples\n    --------\n    >>> w_init = tf.truncated_normal_initializer(stddev=0.01)\n    >>> b_init = tf.constant_initializer(value=0.0)\n    >>> inputs = InputLayer(x, name='inputs')\n    >>> conv1 = Conv2d(inputs, 64, (3, 3), act=tf.nn.relu, padding='SAME', W_init=w_init, b_init=b_init, name='conv1_1')\n    >>> conv1 = Conv2d(conv1, 64, (3, 3), act=tf.nn.relu, padding='SAME', W_init=w_init, b_init=b_init, name='conv1_2')\n    >>> pool1 = MaxPool2d(conv1, (2, 2), padding='SAME', name='pool1')\n    >>> conv2 = Conv2d(pool1, 128, (3, 3), act=tf.nn.relu, padding='SAME', W_init=w_init, b_init=b_init, name='conv2_1')\n    >>> conv2 = Conv2d(conv2, 128, (3, 3), act=tf.nn.relu, padding='SAME', W_init=w_init, b_init=b_init, name='conv2_2')\n    >>> pool2 = MaxPool2d(conv2, (2, 2), padding='SAME', name='pool2')\n    \"\"\"", "\n", "assert", "len", "(", "strides", ")", "==", "2", ",", "\"len(strides) should be 2, Conv2d and Conv2dLayer are different.\"", "\n", "if", "act", "is", "None", ":", "\n", "        ", "act", "=", "tf", ".", "identity", "\n", "", "net", "=", "Conv2dLayer", "(", "net", ",", "\n", "act", "=", "act", ",", "\n", "shape", "=", "[", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "int", "(", "net", ".", "outputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", ",", "n_filter", "]", ",", "# 32 features for each 5x5 patch", "\n", "strides", "=", "[", "1", ",", "strides", "[", "0", "]", ",", "strides", "[", "1", "]", ",", "1", "]", ",", "\n", "padding", "=", "padding", ",", "\n", "W_init", "=", "W_init", ",", "\n", "W_init_args", "=", "W_init_args", ",", "\n", "b_init", "=", "b_init", ",", "\n", "b_init_args", "=", "b_init_args", ",", "\n", "use_cudnn_on_gpu", "=", "use_cudnn_on_gpu", ",", "\n", "data_format", "=", "data_format", ",", "\n", "name", "=", "name", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.DeConv2d": [[1883, 1917], ["tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "layers.DeConv2dLayer", "len", "tensorflow.shape", "int", "int", "int", "DeConv2dLayer.outputs.get_shape"], "function", ["None"], ["", "def", "DeConv2d", "(", "net", ",", "n_out_channel", "=", "32", ",", "filter_size", "=", "(", "3", ",", "3", ")", ",", "\n", "out_size", "=", "(", "30", ",", "30", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'SAME'", ",", "batch_size", "=", "None", ",", "act", "=", "None", ",", "\n", "W_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.02", ")", ",", "b_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.0", ")", ",", "\n", "W_init_args", "=", "{", "}", ",", "b_init_args", "=", "{", "}", ",", "name", "=", "'decnn2d'", ")", ":", "\n", "    ", "\"\"\"Wrapper for :class:`DeConv2dLayer`, if you don't understand how to use :class:`DeConv2dLayer`, this function may be easier.\n\n    Parameters\n    ----------\n    net : TensorLayer layer.\n    n_out_channel : int, number of output channel.\n    filter_size : tuple of (height, width) for filter size.\n    out_size :  tuple of (height, width) of output.\n    batch_size : int or None, batch_size. If None, try to find the batch_size from the first dim of net.outputs (you should tell the batch_size when define the input placeholder).\n    strides : tuple of (height, width) for strides.\n    act : None or activation function.\n    others : see :class:`DeConv2dLayer`.\n    \"\"\"", "\n", "assert", "len", "(", "strides", ")", "==", "2", ",", "\"len(strides) should be 2, DeConv2d and DeConv2dLayer are different.\"", "\n", "if", "act", "is", "None", ":", "\n", "        ", "act", "=", "tf", ".", "identity", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "        ", "batch_size", "=", "tf", ".", "shape", "(", "net", ".", "outputs", ")", "[", "0", "]", "\n", "", "net", "=", "DeConv2dLayer", "(", "layer", "=", "net", ",", "\n", "act", "=", "act", ",", "\n", "shape", "=", "[", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "n_out_channel", ",", "int", "(", "net", ".", "outputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "]", ",", "\n", "output_shape", "=", "[", "batch_size", ",", "int", "(", "out_size", "[", "0", "]", ")", ",", "int", "(", "out_size", "[", "1", "]", ")", ",", "n_out_channel", "]", ",", "\n", "strides", "=", "[", "1", ",", "strides", "[", "0", "]", ",", "strides", "[", "1", "]", ",", "1", "]", ",", "\n", "padding", "=", "padding", ",", "\n", "W_init", "=", "W_init", ",", "\n", "b_init", "=", "b_init", ",", "\n", "W_init_args", "=", "W_init_args", ",", "\n", "b_init_args", "=", "b_init_args", ",", "\n", "name", "=", "name", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MaxPool1d": [[1918, 1942], ["print", "tensorflow.layers.max_pooling1d", "copy.copy", "copy.copy.all_layers.extend", "str", "str", "str"], "function", ["None"], ["", "def", "MaxPool1d", "(", "net", ",", "filter_size", ",", "strides", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", ":", "#Untested", "\n", "    ", "\"\"\"Wrapper for `tf.layers.max_pooling1d <https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling1d>`_ .\n\n    Parameters\n    ------------\n    net : TensorLayer layer, the tensor over which to pool. Must have rank 3.\n    filter_size (pool_size) : An integer or tuple/list of a single integer, representing the size of the pooling window.\n    strides : An integer or tuple/list of a single integer, specifying the strides of the pooling operation.\n    padding : A string. The padding method, either 'valid' or 'same'. Case-insensitive.\n    data_format : A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, length, channels) while channels_first corresponds to inputs with shape (batch, channels, length).\n    name : A string, the name of the layer.\n\n    Returns\n    --------\n    - A :class:`Layer` which the output tensor, of rank 3.\n    \"\"\"", "\n", "print", "(", "(", "\"  [TL] MaxPool1d %s: filter_size:%s strides:%s padding:%s\"", "%", "\n", "(", "name", ",", "str", "(", "filter_size", ")", ",", "str", "(", "strides", ")", ",", "str", "(", "padding", ")", ")", ")", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "max_pooling1d", "(", "net", ".", "outputs", ",", "filter_size", ",", "strides", ",", "padding", "=", "padding", ",", "data_format", "=", "data_format", ",", "name", "=", "name", ")", "\n", "\n", "net_new", "=", "copy", ".", "copy", "(", "net", ")", "\n", "net_new", ".", "outputs", "=", "outputs", "\n", "net_new", ".", "all_layers", ".", "extend", "(", "[", "outputs", "]", ")", "\n", "return", "net_new", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MeanPool1d": [[1943, 1967], ["print", "tensorflow.layers.average_pooling1d", "copy.copy", "copy.copy.all_layers.extend", "str", "str", "str"], "function", ["None"], ["", "def", "MeanPool1d", "(", "net", ",", "filter_size", ",", "strides", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", ":", "#Untested", "\n", "    ", "\"\"\"Wrapper for `tf.layers.average_pooling1d <https://www.tensorflow.org/api_docs/python/tf/layers/average_pooling1d>`_ .\n\n    Parameters\n    ------------\n    net : TensorLayer layer, the tensor over which to pool. Must have rank 3.\n    filter_size (pool_size) : An integer or tuple/list of a single integer, representing the size of the pooling window.\n    strides : An integer or tuple/list of a single integer, specifying the strides of the pooling operation.\n    padding : A string. The padding method, either 'valid' or 'same'. Case-insensitive.\n    data_format : A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last corresponds to inputs with shape (batch, length, channels) while channels_first corresponds to inputs with shape (batch, channels, length).\n    name : A string, the name of the layer.\n\n    Returns\n    --------\n    - A :class:`Layer` which the output tensor, of rank 3.\n    \"\"\"", "\n", "print", "(", "(", "\"  [TL] MeanPool1d %s: filter_size:%s strides:%s padding:%s\"", "%", "\n", "(", "name", ",", "str", "(", "filter_size", ")", ",", "str", "(", "strides", ")", ",", "str", "(", "padding", ")", ")", ")", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "average_pooling1d", "(", "net", ".", "outputs", ",", "filter_size", ",", "strides", ",", "padding", "=", "padding", ",", "data_format", "=", "data_format", ",", "name", "=", "name", ")", "\n", "\n", "net_new", "=", "copy", ".", "copy", "(", "net", ")", "\n", "net_new", ".", "outputs", "=", "outputs", "\n", "net_new", ".", "all_layers", ".", "extend", "(", "[", "outputs", "]", ")", "\n", "return", "net_new", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MaxPool2d": [[1968, 1987], ["layers.PoolLayer", "len"], "function", ["None"], ["", "def", "MaxPool2d", "(", "net", ",", "filter_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "None", ",", "padding", "=", "'SAME'", ",", "name", "=", "'maxpool'", ")", ":", "\n", "    ", "\"\"\"Wrapper for :class:`PoolLayer`.\n\n    Parameters\n    -----------\n    net : TensorLayer layer.\n    filter_size : tuple of (height, width) for filter size.\n    strides : tuple of (height, width). Default is the same with filter_size.\n    others : see :class:`PoolLayer`.\n    \"\"\"", "\n", "if", "strides", "is", "None", ":", "\n", "        ", "strides", "=", "filter_size", "\n", "", "assert", "len", "(", "strides", ")", "==", "2", ",", "\"len(strides) should be 2, MaxPool2d and PoolLayer are different.\"", "\n", "net", "=", "PoolLayer", "(", "net", ",", "ksize", "=", "[", "1", ",", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "strides", "[", "0", "]", ",", "strides", "[", "1", "]", ",", "1", "]", ",", "\n", "padding", "=", "padding", ",", "\n", "pool", "=", "tf", ".", "nn", ".", "max_pool2d", ",", "\n", "name", "=", "name", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MeanPool2d": [[1988, 2007], ["layers.PoolLayer", "len"], "function", ["None"], ["", "def", "MeanPool2d", "(", "net", ",", "filter_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "None", ",", "padding", "=", "'SAME'", ",", "name", "=", "'meanpool'", ")", ":", "\n", "    ", "\"\"\"Wrapper for :class:`PoolLayer`.\n\n    Parameters\n    -----------\n    net : TensorLayer layer.\n    filter_size : tuple of (height, width) for filter size.\n    strides : tuple of (height, width). Default is the same with filter_size.\n    others : see :class:`PoolLayer`.\n    \"\"\"", "\n", "if", "strides", "is", "None", ":", "\n", "        ", "strides", "=", "filter_size", "\n", "", "assert", "len", "(", "strides", ")", "==", "2", ",", "\"len(strides) should be 2, MeanPool2d and PoolLayer are different.\"", "\n", "net", "=", "PoolLayer", "(", "net", ",", "ksize", "=", "[", "1", ",", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "strides", "[", "0", "]", ",", "strides", "[", "1", "]", ",", "1", "]", ",", "\n", "padding", "=", "padding", ",", "\n", "pool", "=", "tf", ".", "nn", ".", "avg_pool", ",", "\n", "name", "=", "name", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MaxPool3d": [[2008, 2028], ["print", "tensorflow.layers.max_pooling3d", "copy.copy", "copy.copy.all_layers.extend", "str", "str", "str"], "function", ["None"], ["", "def", "MaxPool3d", "(", "net", ",", "filter_size", ",", "strides", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", ":", "#Untested", "\n", "    ", "\"\"\"Wrapper for `tf.layers.max_pooling3d <https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling3d>`_ .\n\n    Parameters\n    ------------\n    net : TensorLayer layer, the tensor over which to pool. Must have rank 5.\n    filter_size (pool_size) : An integer or tuple/list of 3 integers: (pool_depth, pool_height, pool_width) specifying the size of the pooling window. Can be a single integer to specify the same value for all spatial dimensions.\n    strides : An integer or tuple/list of 3 integers, specifying the strides of the pooling operation. Can be a single integer to specify the same value for all spatial dimensions.\n    padding : A string. The padding method, either 'valid' or 'same'. Case-insensitive.\n    data_format : A string. The ordering of the dimensions in the inputs. channels_last (default) and channels_first are supported. channels_last corresponds to inputs with shape (batch, depth, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, depth, height, width).\n    name : A string, the name of the layer.\n    \"\"\"", "\n", "print", "(", "(", "\"  [TL] MaxPool3d %s: filter_size:%s strides:%s padding:%s\"", "%", "\n", "(", "name", ",", "str", "(", "filter_size", ")", ",", "str", "(", "strides", ")", ",", "str", "(", "padding", ")", ")", ")", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "max_pooling3d", "(", "net", ".", "outputs", ",", "filter_size", ",", "strides", ",", "padding", "=", "padding", ",", "data_format", "=", "data_format", ",", "name", "=", "name", ")", "\n", "\n", "net_new", "=", "copy", ".", "copy", "(", "net", ")", "\n", "net_new", ".", "outputs", "=", "outputs", "\n", "net_new", ".", "all_layers", ".", "extend", "(", "[", "outputs", "]", ")", "\n", "return", "net_new", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.MeanPool3d": [[2029, 2049], ["print", "tensorflow.layers.average_pooling3d", "copy.copy", "copy.copy.all_layers.extend", "str", "str", "str"], "function", ["None"], ["", "def", "MeanPool3d", "(", "net", ",", "filter_size", ",", "strides", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", ":", "#Untested", "\n", "    ", "\"\"\"Wrapper for `tf.layers.average_pooling3d <https://www.tensorflow.org/api_docs/python/tf/layers/average_pooling3d>`_\n\n    Parameters\n    ------------\n    net : TensorLayer layer, the tensor over which to pool. Must have rank 5.\n    filter_size (pool_size) : An integer or tuple/list of 3 integers: (pool_depth, pool_height, pool_width) specifying the size of the pooling window. Can be a single integer to specify the same value for all spatial dimensions.\n    strides : An integer or tuple/list of 3 integers, specifying the strides of the pooling operation. Can be a single integer to specify the same value for all spatial dimensions.\n    padding : A string. The padding method, either 'valid' or 'same'. Case-insensitive.\n    data_format : A string. The ordering of the dimensions in the inputs. channels_last (default) and channels_first are supported. channels_last corresponds to inputs with shape (batch, depth, height, width, channels) while channels_first corresponds to inputs with shape (batch, channels, depth, height, width).\n    name : A string, the name of the layer.\n    \"\"\"", "\n", "print", "(", "(", "\"  [TL] MeanPool3d %s: filter_size:%s strides:%s padding:%s\"", "%", "\n", "(", "name", ",", "str", "(", "filter_size", ")", ",", "str", "(", "strides", ")", ",", "str", "(", "padding", ")", ")", ")", ")", "\n", "outputs", "=", "tf", ".", "layers", ".", "average_pooling3d", "(", "net", ".", "outputs", ",", "filter_size", ",", "strides", ",", "padding", "=", "padding", ",", "data_format", "=", "data_format", ",", "name", "=", "name", ")", "\n", "\n", "net_new", "=", "copy", ".", "copy", "(", "net", ")", "\n", "net_new", ".", "outputs", "=", "outputs", "\n", "net_new", ".", "all_layers", ".", "extend", "(", "[", "outputs", "]", ")", "\n", "return", "net_new", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.SubpixelConv2d": [[2051, 2152], ["print", "layers.Layer", "list", "list", "dict", "Layer.all_layers.extend", "tensorflow.compat.v1.get_variable_scope", "I.get_shape().as_list", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.split", "tensorflow.concat", "tensorflow.split", "tensorflow.concat", "tensorflow.reshape", "int", "tensorflow.compat.v1.variable_scope", "act", "Exception", "tensorflow.shape", "tensorflow.split", "tensorflow.concat", "layers.SubpixelConv2d._PS"], "function", ["None"], ["", "def", "SubpixelConv2d", "(", "net", ",", "scale", "=", "2", ",", "n_out_channel", "=", "None", ",", "act", "=", "tf", ".", "identity", ",", "name", "=", "'subpixel_conv2d'", ")", ":", "\n", "    ", "\"\"\"The :class:`SubpixelConv2d` class is a sub-pixel 2d convolutional ayer, usually be used\n    for super-resolution application.\n\n    Parameters\n    ------------\n    net : TensorLayer layer.\n    scale : int, upscaling ratio, a wrong setting will lead to Dimension size error.\n    n_out_channel : int or None, the number of output channels.\n        Note that, the number of input channels == (scale x scale) x The number of output channels.\n        If None, automatically set n_out_channel == the number of input channels / (scale x scale).\n    act : activation function.\n    name : string.\n        An optional name to attach to this layer.\n\n    Examples\n    ---------\n    >>> # examples here just want to tell you how to set the n_out_channel.\n    >>> x = np.random.rand(2, 16, 16, 4)\n    >>> X = tf.compat.v1.placeholder(\"float32\", shape=(2, 16, 16, 4), name=\"X\")\n    >>> net = InputLayer(X, name='input')\n    >>> net = SubpixelConv2d(net, scale=2, n_out_channel=1, name='subpixel_conv2d')\n    >>> y = sess.run(net.outputs, feed_dict={X: x})\n    >>> print(x.shape, y.shape)\n    ... (2, 16, 16, 4) (2, 32, 32, 1)\n    >>>\n    >>> x = np.random.rand(2, 16, 16, 4*10)\n    >>> X = tf.compat.v1.placeholder(\"float32\", shape=(2, 16, 16, 4*10), name=\"X\")\n    >>> net = InputLayer(X, name='input2')\n    >>> net = SubpixelConv2d(net, scale=2, n_out_channel=10, name='subpixel_conv2d2')\n    >>> y = sess.run(net.outputs, feed_dict={X: x})\n    >>> print(x.shape, y.shape)\n    ... (2, 16, 16, 40) (2, 32, 32, 10)\n    >>>\n    >>> x = np.random.rand(2, 16, 16, 25*10)\n    >>> X = tf.compat.v1.placeholder(\"float32\", shape=(2, 16, 16, 25*10), name=\"X\")\n    >>> net = InputLayer(X, name='input3')\n    >>> net = SubpixelConv2d(net, scale=5, n_out_channel=None, name='subpixel_conv2d3')\n    >>> y = sess.run(net.outputs, feed_dict={X: x})\n    >>> print(x.shape, y.shape)\n    ... (2, 16, 16, 250) (2, 80, 80, 10)\n\n    References\n    ------------\n    - `Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network <https://arxiv.org/pdf/1609.05158.pdf>`_\n    \"\"\"", "\n", "# github/Tetrachrome/subpixel  https://github.com/Tetrachrome/subpixel/blob/master/subpixel.py", "\n", "\n", "_err_log", "=", "\"SubpixelConv2d: The number of input channels == (scale x scale) x The number of output channels\"", "\n", "\n", "scope_name", "=", "tf", ".", "compat", ".", "v1", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "if", "scope_name", ":", "\n", "        ", "name", "=", "scope_name", "+", "'/'", "+", "name", "\n", "\n", "", "def", "_phase_shift", "(", "I", ",", "r", ")", ":", "\n", "        ", "if", "tf", ".", "__version__", "<", "'1.0'", ":", "\n", "            ", "raise", "Exception", "(", "\"Only support TF1.0+\"", ")", "\n", "", "bsize", ",", "a", ",", "b", ",", "c", "=", "I", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "bsize", "=", "tf", ".", "shape", "(", "I", ")", "[", "0", "]", "# Handling Dimension(None) type for undefined batch dim", "\n", "X", "=", "tf", ".", "reshape", "(", "I", ",", "(", "bsize", ",", "a", ",", "b", ",", "r", ",", "r", ")", ")", "\n", "X", "=", "tf", ".", "transpose", "(", "X", ",", "(", "0", ",", "1", ",", "2", ",", "4", ",", "3", ")", ")", "# bsize, a, b, 1, 1 # tf 0.12", "\n", "# X = tf.split(1, a, X)  # a, [bsize, b, r, r] # tf 0.12", "\n", "X", "=", "tf", ".", "split", "(", "axis", "=", "X", ",", "num_or_size_splits", "=", "a", ",", "value", "=", "1", ")", "\n", "# X = tf.concat(2, [tf.squeeze(x, axis=1) for x in X])  # bsize, b, a*r, r # tf 0.12", "\n", "X", "=", "tf", ".", "concat", "(", "axis", "=", "[", "tf", ".", "squeeze", "(", "x", ",", "axis", "=", "1", ")", "for", "x", "in", "X", "]", ",", "values", "=", "2", ")", "\n", "# X = tf.split(1, b, X)  # b, [bsize, a*r, r] # tf 0.12", "\n", "X", "=", "tf", ".", "split", "(", "axis", "=", "X", ",", "num_or_size_splits", "=", "b", ",", "value", "=", "1", ")", "\n", "# X = tf.concat(2, [tf.squeeze(x, axis=1) for x in X])  # bsize, a*r, b*r # tf 0.12", "\n", "X", "=", "tf", ".", "concat", "(", "axis", "=", "[", "tf", ".", "squeeze", "(", "x", ",", "axis", "=", "1", ")", "for", "x", "in", "X", "]", ",", "values", "=", "2", ")", "\n", "return", "tf", ".", "reshape", "(", "X", ",", "(", "bsize", ",", "a", "*", "r", ",", "b", "*", "r", ",", "1", ")", ")", "\n", "\n", "", "def", "_PS", "(", "X", ",", "r", ",", "n_out_channel", ")", ":", "\n", "        ", "if", "n_out_channel", ">", "1", ":", "\n", "            ", "assert", "int", "(", "X", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "==", "(", "r", "**", "2", ")", "*", "n_out_channel", ",", "_err_log", "\n", "Xc", "=", "tf", ".", "split", "(", "axis", "=", "X", ",", "num_or_size_splits", "=", "n_out_channel", ",", "value", "=", "3", ")", "\n", "X", "=", "tf", ".", "concat", "(", "axis", "=", "[", "_phase_shift", "(", "x", ",", "r", ")", "for", "x", "in", "Xc", "]", ",", "values", "=", "3", ")", "\n", "", "elif", "n_out_channel", "==", "1", ":", "\n", "            ", "assert", "int", "(", "X", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "==", "(", "r", "**", "2", ")", ",", "_err_log", "\n", "X", "=", "_phase_shift", "(", "X", ",", "r", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "_err_log", ")", "\n", "", "return", "X", "\n", "\n", "", "inputs", "=", "net", ".", "outputs", "\n", "\n", "if", "n_out_channel", "is", "None", ":", "\n", "        ", "assert", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "/", "(", "scale", "**", "2", ")", "%", "1", "==", "0", ",", "_err_log", "\n", "n_out_channel", "=", "int", "(", "int", "(", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "/", "(", "scale", "**", "2", ")", ")", "\n", "\n", "", "print", "(", "(", "\"  [TL] SubpixelConv2d  %s: scale: %d n_out_channel: %s act: %s\"", "%", "(", "name", ",", "scale", ",", "n_out_channel", ",", "act", ".", "__name__", ")", ")", ")", "\n", "\n", "net_new", "=", "Layer", "(", "inputs", ",", "name", "=", "name", ")", "\n", "# with tf.name_scope(name):", "\n", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "name", ")", "as", "vs", ":", "\n", "        ", "net_new", ".", "outputs", "=", "act", "(", "_PS", "(", "inputs", ",", "r", "=", "scale", ",", "n_out_channel", "=", "n_out_channel", ")", ")", "\n", "\n", "", "net_new", ".", "all_layers", "=", "list", "(", "net", ".", "all_layers", ")", "\n", "net_new", ".", "all_params", "=", "list", "(", "net", ".", "all_params", ")", "\n", "net_new", ".", "all_drop", "=", "dict", "(", "net", ".", "all_drop", ")", "\n", "net_new", ".", "all_layers", ".", "extend", "(", "[", "net_new", ".", "outputs", "]", ")", "\n", "return", "net_new", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.advanced_indexing_op": [[3664, 3709], ["int", "tensorflow.reshape", "tensorflow.gather", "tensorflow.shape", "tensorflow.shape", "input.get_shape", "tensorflow.range"], "function", ["None"], ["", "", "def", "advanced_indexing_op", "(", "input", ",", "index", ")", ":", "\n", "    ", "\"\"\"Advanced Indexing for Sequences, returns the outputs by given sequence lengths.\n    When return the last output :class:`DynamicRNNLayer` uses it to get the last outputs with the sequence lengths.\n\n    Parameters\n    -----------\n    input : tensor for data\n        [batch_size, n_step(max), n_features]\n    index : tensor for indexing, i.e. sequence_length in Dynamic RNN.\n        [batch_size]\n\n    Examples\n    ---------\n    >>> batch_size, max_length, n_features = 3, 5, 2\n    >>> z = np.random.uniform(low=-1, high=1, size=[batch_size, max_length, n_features]).astype(np.float32)\n    >>> b_z = tf.constant(z)\n    >>> sl = tf.compat.v1.placeholder(dtype=tf.int32, shape=[batch_size])\n    >>> o = advanced_indexing_op(b_z, sl)\n    >>>\n    >>> sess = tf.InteractiveSession()\n    >>> tl.layers.initialize_global_variables(sess)\n    >>>\n    >>> order = np.asarray([1,1,2])\n    >>> print(\"real\",z[0][order[0]-1], z[1][order[1]-1], z[2][order[2]-1])\n    >>> y = sess.run([o], feed_dict={sl:order})\n    >>> print(\"given\",order)\n    >>> print(\"out\", y)\n    ... real [-0.93021595  0.53820813] [-0.92548317 -0.77135968] [ 0.89952248  0.19149846]\n    ... given [1 1 2]\n    ... out [array([[-0.93021595,  0.53820813],\n    ...             [-0.92548317, -0.77135968],\n    ...             [ 0.89952248,  0.19149846]], dtype=float32)]\n\n    References\n    -----------\n    - Modified from TFlearn (the original code is used for fixed length rnn), `references <https://github.com/tflearn/tflearn/blob/master/tflearn/layers/recurrent.py>`_.\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "input", ")", "[", "0", "]", "\n", "# max_length = int(input.get_shape()[1])    # for fixed length rnn, length is given", "\n", "max_length", "=", "tf", ".", "shape", "(", "input", ")", "[", "1", "]", "# for dynamic_rnn, length is unknown", "\n", "dim_size", "=", "int", "(", "input", ".", "get_shape", "(", ")", "[", "2", "]", ")", "\n", "index", "=", "tf", ".", "range", "(", "0", ",", "batch_size", ")", "*", "max_length", "+", "(", "index", "-", "1", ")", "\n", "flat", "=", "tf", ".", "reshape", "(", "input", ",", "[", "-", "1", ",", "dim_size", "]", ")", "\n", "relevant", "=", "tf", ".", "gather", "(", "flat", ",", "index", ")", "\n", "return", "relevant", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.retrieve_seq_length_op": [[3710, 3754], ["tensorflow.name_scope", "tensorflow.sign", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.reduce_max", "tensorflow.abs"], "function", ["None"], ["", "def", "retrieve_seq_length_op", "(", "data", ")", ":", "\n", "    ", "\"\"\"An op to compute the length of a sequence from input shape of [batch_size, n_step(max), n_features],\n    it can be used when the features of padding (on right hand side) are all zeros.\n\n    Parameters\n    -----------\n    data : tensor\n        [batch_size, n_step(max), n_features] with zero padding on right hand side.\n\n    Examples\n    ---------\n    >>> data = [[[1],[2],[0],[0],[0]],\n    ...         [[1],[2],[3],[0],[0]],\n    ...         [[1],[2],[6],[1],[0]]]\n    >>> data = np.asarray(data)\n    >>> print(data.shape)\n    ... (3, 5, 1)\n    >>> data = tf.constant(data)\n    >>> sl = retrieve_seq_length_op(data)\n    >>> sess = tf.InteractiveSession()\n    >>> tl.layers.initialize_global_variables(sess)\n    >>> y = sl.eval()\n    ... [2 3 4]\n\n    - Multiple features\n    >>> data = [[[1,2],[2,2],[1,2],[1,2],[0,0]],\n    ...         [[2,3],[2,4],[3,2],[0,0],[0,0]],\n    ...         [[3,3],[2,2],[5,3],[1,2],[0,0]]]\n    >>> sl\n    ... [4 3 4]\n\n    References\n    ------------\n    - Borrow from `TFlearn <https://github.com/tflearn/tflearn/blob/master/tflearn/layers/recurrent.py>`_.\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'GetLength'", ")", ":", "\n", "## TF 1.0 change reduction_indices to axis", "\n", "        ", "used", "=", "tf", ".", "sign", "(", "tf", ".", "reduce_max", "(", "tf", ".", "abs", "(", "data", ")", ",", "2", ")", ")", "\n", "length", "=", "tf", ".", "reduce_sum", "(", "used", ",", "1", ")", "\n", "## TF < 1.0", "\n", "# used = tf.sign(tf.reduce_max(tf.abs(data), reduction_indices=2))", "\n", "# length = tf.reduce_sum(used, reduction_indices=1)", "\n", "length", "=", "tf", ".", "cast", "(", "length", ",", "tf", ".", "int32", ")", "\n", "", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.retrieve_seq_length_op2": [[3755, 3776], ["tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.greater", "tensorflow.zeros_like"], "function", ["None"], ["", "def", "retrieve_seq_length_op2", "(", "data", ")", ":", "\n", "    ", "\"\"\"An op to compute the length of a sequence, from input shape of [batch_size, n_step(max)],\n    it can be used when the features of padding (on right hand side) are all zeros.\n\n    Parameters\n    -----------\n    data : tensor\n        [batch_size, n_step(max)] with zero padding on right hand side.\n\n    Examples\n    --------\n    >>> data = [[1,2,0,0,0],\n    ...         [1,2,3,0,0],\n    ...         [1,2,6,1,0]]\n    >>> o = retrieve_seq_length_op2(data)\n    >>> sess = tf.InteractiveSession()\n    >>> tl.layers.initialize_global_variables(sess)\n    >>> print(o.eval())\n    ... [2 3 4]\n    \"\"\"", "\n", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "data", ",", "tf", ".", "zeros_like", "(", "data", ")", ")", ",", "tf", ".", "int32", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.retrieve_seq_length_op3": [[3778, 3788], ["data.get_shape", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.reduce_any", "tensorflow.cast", "ValueError", "ValueError", "tensorflow.not_equal", "tensorflow.not_equal"], "function", ["None"], ["", "def", "retrieve_seq_length_op3", "(", "data", ",", "pad_val", "=", "0", ")", ":", "# HangSheng: return tensor for sequence length, if input is tf.string", "\n", "    ", "data_shape_size", "=", "data", ".", "get_shape", "(", ")", ".", "ndims", "\n", "if", "data_shape_size", "==", "3", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "tf", ".", "reduce_any", "(", "tf", ".", "not_equal", "(", "data", ",", "pad_val", ")", ",", "axis", "=", "2", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "1", ")", "\n", "", "elif", "data_shape_size", "==", "2", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "data", ",", "pad_val", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "1", ")", "\n", "", "elif", "data_shape_size", "==", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"retrieve_seq_length_op3: data has wrong shape!\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"retrieve_seq_length_op3: handling data_shape_size %s hasn't been implemented!\"", "%", "(", "data_shape_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.target_mask_op": [[3790, 3800], ["data.get_shape", "tensorflow.cast", "tensorflow.reduce_any", "tensorflow.cast", "tensorflow.not_equal", "tensorflow.not_equal", "ValueError", "ValueError"], "function", ["None"], ["", "", "def", "target_mask_op", "(", "data", ",", "pad_val", "=", "0", ")", ":", "# HangSheng: return tensor for mask,if input is tf.string", "\n", "    ", "data_shape_size", "=", "data", ".", "get_shape", "(", ")", ".", "ndims", "\n", "if", "data_shape_size", "==", "3", ":", "\n", "        ", "return", "tf", ".", "cast", "(", "tf", ".", "reduce_any", "(", "tf", ".", "not_equal", "(", "data", ",", "pad_val", ")", ",", "axis", "=", "2", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "", "elif", "data_shape_size", "==", "2", ":", "\n", "        ", "return", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "data", ",", "pad_val", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "", "elif", "data_shape_size", "==", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"target_mask_op: data has wrong shape!\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"target_mask_op: handling data_shape_size %s hasn't been implemented!\"", "%", "(", "data_shape_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.rein.discount_episode_rewards": [[10, 46], ["numpy.zeros_like", "reversed", "range"], "function", ["None"], ["def", "discount_episode_rewards", "(", "rewards", "=", "[", "]", ",", "gamma", "=", "0.99", ",", "mode", "=", "0", ")", ":", "\n", "    ", "\"\"\" Take 1D float array of rewards and compute discounted rewards for an\n    episode. When encount a non-zero value, consider as the end a of an episode.\n\n    Parameters\n    ----------\n    rewards : numpy list\n        a list of rewards\n    gamma : float\n        discounted factor\n    mode : int\n        if mode == 0, reset the discount process when encount a non-zero reward (Ping-pong game).\n        if mode == 1, would not reset the discount process.\n\n    Examples\n    ----------\n    >>> rewards = np.asarray([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1])\n    >>> gamma = 0.9\n    >>> discount_rewards = tl.rein.discount_episode_rewards(rewards, gamma)\n    >>> print(discount_rewards)\n    ... [ 0.72899997  0.81        0.89999998  1.          0.72899997  0.81\n    ... 0.89999998  1.          0.72899997  0.81        0.89999998  1.        ]\n    >>> discount_rewards = tl.rein.discount_episode_rewards(rewards, gamma, mode=1)\n    >>> print(discount_rewards)\n    ... [ 1.52110755  1.69011939  1.87791049  2.08656716  1.20729685  1.34144104\n    ... 1.49048996  1.65610003  0.72899997  0.81        0.89999998  1.        ]\n    \"\"\"", "\n", "discounted_r", "=", "np", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "running_add", "=", "0", "\n", "for", "t", "in", "reversed", "(", "range", "(", "0", ",", "rewards", ".", "size", ")", ")", ":", "\n", "        ", "if", "mode", "==", "0", ":", "\n", "            ", "if", "rewards", "[", "t", "]", "!=", "0", ":", "running_add", "=", "0", "\n", "\n", "", "running_add", "=", "running_add", "*", "gamma", "+", "rewards", "[", "t", "]", "\n", "discounted_r", "[", "t", "]", "=", "running_add", "\n", "", "return", "discounted_r", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.rein.cross_entropy_reward_loss": [[48, 86], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_sum", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.multiply"], "function", ["None"], ["", "def", "cross_entropy_reward_loss", "(", "logits", ",", "actions", ",", "rewards", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Calculate the loss for Policy Gradient Network.\n\n    Parameters\n    ----------\n    logits : tensor\n        The network outputs without softmax. This function implements softmax\n        inside.\n    actions : tensor/ placeholder\n        The agent actions.\n    rewards : tensor/ placeholder\n        The rewards.\n\n    Examples\n    ----------\n    >>> states_batch_pl = tf.compat.v1.placeholder(tf.float32, shape=[None, D])   # observation for training\n    >>> network = tl.layers.InputLayer(states_batch_pl, name='input_layer')\n    >>> network = tl.layers.DenseLayer(network, n_units=H, act = tf.nn.relu, name='relu1')\n    >>> network = tl.layers.DenseLayer(network, n_units=3, act = tl.activation.identity, name='output_layer')\n    >>> probs = network.outputs\n    >>> sampling_prob = tf.nn.softmax(probs)\n    >>> actions_batch_pl = tf.compat.v1.placeholder(tf.int32, shape=[None])\n    >>> discount_rewards_batch_pl = tf.compat.v1.placeholder(tf.float32, shape=[None])\n    >>> loss = cross_entropy_reward_loss(probs, actions_batch_pl, discount_rewards_batch_pl)\n    >>> train_op = tf.train.RMSPropOptimizer(learning_rate, decay_rate).minimize(loss)\n    \"\"\"", "\n", "\n", "try", ":", "# TF 1.0", "\n", "        ", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "actions", ",", "logits", "=", "logits", ",", "name", "=", "name", ")", "\n", "", "except", ":", "\n", "        ", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "targets", "=", "actions", ")", "\n", "# cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, actions)", "\n", "\n", "", "try", ":", "## TF1.0", "\n", "        ", "loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "cross_entropy", ",", "rewards", ")", ")", "\n", "", "except", ":", "## TF0.12", "\n", "        ", "loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "cross_entropy", ",", "rewards", ")", ")", "# element-wise mul", "\n", "", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_mnist_dataset": [[23, 85], ["print", "files.load_mnist_dataset.load_mnist_images"], "function", ["None"], ["def", "load_mnist_dataset", "(", "shape", "=", "(", "-", "1", ",", "784", ")", ",", "path", "=", "\"data/mnist/\"", ")", ":", "\n", "    ", "\"\"\"Automatically download MNIST dataset\n    and return the training, validation and test set with 50000, 10000 and 10000\n    digit images respectively.\n\n    Parameters\n    ----------\n    shape : tuple\n        The shape of digit images, defaults to (-1,784)\n    path : string\n        Path to download data to, defaults to data/mnist/\n\n    Examples\n    --------\n    >>> X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1,784))\n    >>> X_train, y_train, X_val, y_val, X_test, y_test = tl.files.load_mnist_dataset(shape=(-1, 28, 28, 1))\n    \"\"\"", "\n", "# We first define functions for loading MNIST images and labels.", "\n", "# For convenience, they also download the requested files if needed.", "\n", "def", "load_mnist_images", "(", "path", ",", "filename", ")", ":", "\n", "        ", "filepath", "=", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "'http://yann.lecun.com/exdb/mnist/'", ")", "\n", "\n", "print", "(", "filepath", ")", "\n", "# Read the inputs in Yann LeCun's binary format.", "\n", "with", "gzip", ".", "open", "(", "filepath", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "16", ")", "\n", "# The inputs are vectors now, we reshape them to monochrome 2D images,", "\n", "# following the shape convention: (examples, channels, rows, columns)", "\n", "", "data", "=", "data", ".", "reshape", "(", "shape", ")", "\n", "# The inputs come as bytes, we convert them to float32 in range [0,1].", "\n", "# (Actually to range [0, 255/256], for compatibility to the version", "\n", "# provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)", "\n", "return", "data", "/", "np", ".", "float32", "(", "256", ")", "\n", "\n", "", "def", "load_mnist_labels", "(", "path", ",", "filename", ")", ":", "\n", "        ", "filepath", "=", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "'http://yann.lecun.com/exdb/mnist/'", ")", "\n", "# Read the labels in Yann LeCun's binary format.", "\n", "with", "gzip", ".", "open", "(", "filepath", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "8", ")", "\n", "# The labels are vectors of integers now, that's exactly what we want.", "\n", "", "return", "data", "\n", "\n", "# Download and read the training and test set images and labels.", "\n", "", "print", "(", "(", "\"Load or Download MNIST > {}\"", ".", "format", "(", "path", ")", ")", ")", "\n", "X_train", "=", "load_mnist_images", "(", "path", ",", "'train-images-idx3-ubyte.gz'", ")", "\n", "y_train", "=", "load_mnist_labels", "(", "path", ",", "'train-labels-idx1-ubyte.gz'", ")", "\n", "X_test", "=", "load_mnist_images", "(", "path", ",", "'t10k-images-idx3-ubyte.gz'", ")", "\n", "y_test", "=", "load_mnist_labels", "(", "path", ",", "'t10k-labels-idx1-ubyte.gz'", ")", "\n", "\n", "# We reserve the last 10000 training examples for validation.", "\n", "X_train", ",", "X_val", "=", "X_train", "[", ":", "-", "10000", "]", ",", "X_train", "[", "-", "10000", ":", "]", "\n", "y_train", ",", "y_val", "=", "y_train", "[", ":", "-", "10000", "]", ",", "y_train", "[", "-", "10000", ":", "]", "\n", "\n", "# We just return all the arrays in order, as expected in main().", "\n", "# (It doesn't matter how we do this as long as we can read them again.)", "\n", "X_train", "=", "np", ".", "asarray", "(", "X_train", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "y_train", "=", "np", ".", "asarray", "(", "y_train", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "X_val", "=", "np", ".", "asarray", "(", "X_val", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "y_val", "=", "np", ".", "asarray", "(", "y_val", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "X_test", "=", "np", ".", "asarray", "(", "X_test", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "y_test", "=", "np", ".", "asarray", "(", "y_test", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "return", "X_train", ",", "y_train", ",", "X_val", ",", "y_val", ",", "X_test", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_cifar10_dataset": [[87, 220], ["print", "files.maybe_download_and_extract", "range", "files.load_cifar10_dataset.unpickle"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.maybe_download_and_extract"], ["", "def", "load_cifar10_dataset", "(", "shape", "=", "(", "-", "1", ",", "32", ",", "32", ",", "3", ")", ",", "path", "=", "'data/cifar10/'", ",", "plotable", "=", "False", ",", "second", "=", "3", ")", ":", "\n", "    ", "\"\"\"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with\n    6000 images per class. There are 50000 training images and 10000 test images.\n\n    The dataset is divided into five training batches and one test batch, each with\n    10000 images. The test batch contains exactly 1000 randomly-selected images from\n    each class. The training batches contain the remaining images in random order,\n    but some training batches may contain more images from one class than another.\n    Between them, the training batches contain exactly 5000 images from each class.\n\n    Parameters\n    ----------\n    shape : tupe\n        The shape of digit images: e.g. (-1, 3, 32, 32) , (-1, 32, 32, 3) , (-1, 32*32*3)\n    plotable : True, False\n        Whether to plot some image examples.\n    second : int\n        If ``plotable`` is True, ``second`` is the display time.\n    path : string\n        Path to download data to, defaults to data/cifar10/\n\n    Examples\n    --------\n    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=True)\n\n    Notes\n    ------\n    CIFAR-10 images can only be display without color change under uint8.\n    >>> X_train = np.asarray(X_train, dtype=np.uint8)\n    >>> plt.ion()\n    >>> fig = plt.figure(1232)\n    >>> count = 1\n    >>> for row in range(10):\n    >>>     for col in range(10):\n    >>>         a = fig.add_subplot(10, 10, count)\n    >>>         plt.imshow(X_train[count-1], interpolation='nearest')\n    >>>         plt.gca().xaxis.set_major_locator(plt.NullLocator())    # \u4e0d\u663e\u793a\u523b\u5ea6(tick)\n    >>>         plt.gca().yaxis.set_major_locator(plt.NullLocator())\n    >>>         count = count + 1\n    >>> plt.draw()\n    >>> plt.pause(3)\n\n    References\n    ----------\n    - `CIFAR website <https://www.cs.toronto.edu/~kriz/cifar.html>`_\n    - `Data download link <https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz>`_\n    - `Code references <https://teratail.com/questions/28932>`_\n    \"\"\"", "\n", "\n", "print", "(", "(", "\"Load or Download cifar10 > {}\"", ".", "format", "(", "path", ")", ")", ")", "\n", "\n", "#Helper function to unpickle the data", "\n", "def", "unpickle", "(", "file", ")", ":", "\n", "        ", "fp", "=", "open", "(", "file", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", ".", "major", "==", "2", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "elif", "sys", ".", "version_info", ".", "major", "==", "3", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "fp", ",", "encoding", "=", "'latin-1'", ")", "\n", "", "fp", ".", "close", "(", ")", "\n", "return", "data", "\n", "\n", "", "filename", "=", "'cifar-10-python.tar.gz'", "\n", "url", "=", "'https://www.cs.toronto.edu/~kriz/'", "\n", "#Download and uncompress file", "\n", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "url", ",", "extract", "=", "True", ")", "\n", "\n", "#Unpickle file and fill in data", "\n", "X_train", "=", "None", "\n", "y_train", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "6", ")", ":", "\n", "        ", "data_dic", "=", "unpickle", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'cifar-10-batches-py/'", ",", "\"data_batch_{}\"", ".", "format", "(", "i", ")", ")", ")", "\n", "if", "i", "==", "1", ":", "\n", "            ", "X_train", "=", "data_dic", "[", "'data'", "]", "\n", "", "else", ":", "\n", "            ", "X_train", "=", "np", ".", "vstack", "(", "(", "X_train", ",", "data_dic", "[", "'data'", "]", ")", ")", "\n", "", "y_train", "+=", "data_dic", "[", "'labels'", "]", "\n", "\n", "", "test_data_dic", "=", "unpickle", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'cifar-10-batches-py/'", ",", "\"test_batch\"", ")", ")", "\n", "X_test", "=", "test_data_dic", "[", "'data'", "]", "\n", "y_test", "=", "np", ".", "array", "(", "test_data_dic", "[", "'labels'", "]", ")", "\n", "\n", "if", "shape", "==", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", ":", "\n", "        ", "X_test", "=", "X_test", ".", "reshape", "(", "shape", ")", "\n", "X_train", "=", "X_train", ".", "reshape", "(", "shape", ")", "\n", "", "elif", "shape", "==", "(", "-", "1", ",", "32", ",", "32", ",", "3", ")", ":", "\n", "        ", "X_test", "=", "X_test", ".", "reshape", "(", "shape", ",", "order", "=", "'F'", ")", "\n", "X_train", "=", "X_train", ".", "reshape", "(", "shape", ",", "order", "=", "'F'", ")", "\n", "X_test", "=", "np", ".", "transpose", "(", "X_test", ",", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "X_train", "=", "np", ".", "transpose", "(", "X_train", ",", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "", "else", ":", "\n", "        ", "X_test", "=", "X_test", ".", "reshape", "(", "shape", ")", "\n", "X_train", "=", "X_train", ".", "reshape", "(", "shape", ")", "\n", "\n", "", "y_train", "=", "np", ".", "array", "(", "y_train", ")", "\n", "\n", "if", "plotable", "==", "True", ":", "\n", "        ", "print", "(", "'\\nCIFAR-10'", ")", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "fig", "=", "plt", ".", "figure", "(", "1", ")", "\n", "\n", "print", "(", "(", "'Shape of a training image: X_train[0]'", ",", "X_train", "[", "0", "]", ".", "shape", ")", ")", "\n", "\n", "plt", ".", "ion", "(", ")", "# interactive mode", "\n", "count", "=", "1", "\n", "for", "row", "in", "range", "(", "10", ")", ":", "\n", "            ", "for", "col", "in", "range", "(", "10", ")", ":", "\n", "                ", "a", "=", "fig", ".", "add_subplot", "(", "10", ",", "10", ",", "count", ")", "\n", "if", "shape", "==", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", ":", "\n", "# plt.imshow(X_train[count-1], interpolation='nearest')", "\n", "                    ", "plt", ".", "imshow", "(", "np", ".", "transpose", "(", "X_train", "[", "count", "-", "1", "]", ",", "(", "1", ",", "2", ",", "0", ")", ")", ",", "interpolation", "=", "'nearest'", ")", "\n", "# plt.imshow(np.transpose(X_train[count-1], (2, 1, 0)), interpolation='nearest')", "\n", "", "elif", "shape", "==", "(", "-", "1", ",", "32", ",", "32", ",", "3", ")", ":", "\n", "                    ", "plt", ".", "imshow", "(", "X_train", "[", "count", "-", "1", "]", ",", "interpolation", "=", "'nearest'", ")", "\n", "# plt.imshow(np.transpose(X_train[count-1], (1, 0, 2)), interpolation='nearest')", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "\"Do not support the given 'shape' to plot the image examples\"", ")", "\n", "", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "# \u4e0d\u663e\u793a\u523b\u5ea6(tick)", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "", "plt", ".", "draw", "(", ")", "# interactive mode", "\n", "plt", ".", "pause", "(", "3", ")", "# interactive mode", "\n", "\n", "print", "(", "(", "\"X_train:\"", ",", "X_train", ".", "shape", ")", ")", "\n", "print", "(", "(", "\"y_train:\"", ",", "y_train", ".", "shape", ")", ")", "\n", "print", "(", "(", "\"X_test:\"", ",", "X_test", ".", "shape", ")", ")", "\n", "print", "(", "(", "\"y_test:\"", ",", "y_test", ".", "shape", ")", ")", "\n", "\n", "", "X_train", "=", "np", ".", "asarray", "(", "X_train", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "X_test", "=", "np", ".", "asarray", "(", "X_test", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "y_train", "=", "np", ".", "asarray", "(", "y_train", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "y_test", "=", "np", ".", "asarray", "(", "y_test", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_ptb_dataset": [[222, 297], ["print", "files.maybe_download_and_extract", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "nlp.build_vocab", "nlp.words_to_word_ids", "nlp.words_to_word_ids", "nlp.words_to_word_ids", "len", "nlp.read_words", "nlp.read_words", "nlp.read_words", "nlp.read_words"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.maybe_download_and_extract", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.build_vocab", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.words_to_word_ids", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.words_to_word_ids", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.words_to_word_ids", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.read_words", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.read_words", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.read_words", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.nlp.read_words"], ["", "def", "load_ptb_dataset", "(", "path", "=", "'data/ptb/'", ")", ":", "\n", "    ", "\"\"\"Penn TreeBank (PTB) dataset is used in many LANGUAGE MODELING papers,\n    including \"Empirical Evaluation and Combination of Advanced Language\n    Modeling Techniques\", \"Recurrent Neural Network Regularization\".\n\n    It consists of 929k training words, 73k validation words, and 82k test\n    words. It has 10k words in its vocabulary.\n\n    In \"Recurrent Neural Network Regularization\", they trained regularized LSTMs\n    of two sizes; these are denoted the medium LSTM and large LSTM. Both LSTMs\n    have two layers and are unrolled for 35 steps. They initialize the hidden\n    states to zero. They then use the final hidden states of the current\n    minibatch as the initial hidden state of the subsequent minibatch\n    (successive minibatches sequentially traverse the training set).\n    The size of each minibatch is 20.\n\n    The medium LSTM has 650 units per layer and its parameters are initialized\n    uniformly in [\u22120.05, 0.05]. They apply 50% dropout on the non-recurrent\n    connections. They train the LSTM for 39 epochs with a learning rate of 1,\n    and after 6 epochs they decrease it by a factor of 1.2 after each epoch.\n    They clip the norm of the gradients (normalized by minibatch size) at 5.\n\n    The large LSTM has 1500 units per layer and its parameters are initialized\n    uniformly in [\u22120.04, 0.04]. We apply 65% dropout on the non-recurrent\n    connections. They train the model for 55 epochs with a learning rate of 1;\n    after 14 epochs they start to reduce the learning rate by a factor of 1.15\n    after each epoch. They clip the norm of the gradients (normalized by\n    minibatch size) at 10.\n\n    Parameters\n    ----------\n    path : : string\n        Path to download data to, defaults to data/ptb/\n\n    Returns\n    --------\n    train_data, valid_data, test_data, vocabulary size\n\n    Examples\n    --------\n    >>> train_data, valid_data, test_data, vocab_size = tl.files.load_ptb_dataset()\n\n    Code References\n    ---------------\n    - ``tensorflow.models.rnn.ptb import reader``\n\n    Download Links\n    ---------------\n    - `Manual download <http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz>`_\n    \"\"\"", "\n", "print", "(", "(", "\"Load or Download Penn TreeBank (PTB) dataset > {}\"", ".", "format", "(", "path", ")", ")", ")", "\n", "\n", "#Maybe dowload and uncompress tar, or load exsisting files", "\n", "filename", "=", "'simple-examples.tgz'", "\n", "url", "=", "'http://www.fit.vutbr.cz/~imikolov/rnnlm/'", "\n", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "url", ",", "extract", "=", "True", ")", "\n", "\n", "data_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'simple-examples'", ",", "'data'", ")", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"ptb.train.txt\"", ")", "\n", "valid_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"ptb.valid.txt\"", ")", "\n", "test_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"ptb.test.txt\"", ")", "\n", "\n", "word_to_id", "=", "nlp", ".", "build_vocab", "(", "nlp", ".", "read_words", "(", "train_path", ")", ")", "\n", "\n", "train_data", "=", "nlp", ".", "words_to_word_ids", "(", "nlp", ".", "read_words", "(", "train_path", ")", ",", "word_to_id", ")", "\n", "valid_data", "=", "nlp", ".", "words_to_word_ids", "(", "nlp", ".", "read_words", "(", "valid_path", ")", ",", "word_to_id", ")", "\n", "test_data", "=", "nlp", ".", "words_to_word_ids", "(", "nlp", ".", "read_words", "(", "test_path", ")", ",", "word_to_id", ")", "\n", "vocabulary", "=", "len", "(", "word_to_id", ")", "\n", "\n", "# print(nlp.read_words(train_path))     # ... 'according', 'to', 'mr.', '<unk>', '<eos>']", "\n", "# print(train_data)                 # ...  214,         5,    23,    1,       2]", "\n", "# print(word_to_id)                 # ... 'beyond': 1295, 'anti-nuclear': 9599, 'trouble': 1520, '<eos>': 2 ... }", "\n", "# print(vocabulary)                 # 10000", "\n", "# exit()", "\n", "return", "train_data", ",", "valid_data", ",", "test_data", ",", "vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_matt_mahoney_text8_dataset": [[299, 332], ["print", "files.maybe_download_and_extract", "zipfile.ZipFile", "f.read().split", "os.path.join", "f.read", "f.namelist"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.maybe_download_and_extract"], ["", "def", "load_matt_mahoney_text8_dataset", "(", "path", "=", "'data/mm_test8/'", ")", ":", "\n", "    ", "\"\"\"Download a text file from Matt Mahoney's website\n    if not present, and make sure it's the right size.\n    Extract the first file enclosed in a zip file as a list of words.\n    This dataset can be used for Word Embedding.\n\n    Parameters\n    ----------\n    path : : string\n        Path to download data to, defaults to data/mm_test8/\n\n    Returns\n    --------\n    word_list : a list\n        a list of string (word).\\n\n        e.g. [.... 'their', 'families', 'who', 'were', 'expelled', 'from', 'jerusalem', ...]\n\n    Examples\n    --------\n    >>> words = tl.files.load_matt_mahoney_text8_dataset()\n    >>> print('Data size', len(words))\n    \"\"\"", "\n", "\n", "print", "(", "(", "\"Load or Download matt_mahoney_text8 Dataset> {}\"", ".", "format", "(", "path", ")", ")", ")", "\n", "\n", "filename", "=", "'text8.zip'", "\n", "url", "=", "'http://mattmahoney.net/dc/'", "\n", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "url", ",", "expected_bytes", "=", "31344016", ")", "\n", "\n", "with", "zipfile", ".", "ZipFile", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ")", "as", "f", ":", "\n", "        ", "word_list", "=", "f", ".", "read", "(", "f", ".", "namelist", "(", ")", "[", "0", "]", ")", ".", "split", "(", ")", "\n", "\n", "", "return", "word_list", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_imdb_dataset": [[334, 417], ["files.maybe_download_and_extract", "filename.endswith", "six.moves.cPickle.load", "open.close", "numpy.random.seed", "numpy.random.shuffle", "numpy.random.seed", "numpy.random.shuffle", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "gzip.open", "open", "six.moves.zip", "Exception", "max", "os.path.join", "os.path.join", "nX.append", "len", "new_X.append", "new_labels.append", "max", "int", "int", "int", "int", "str", "nx.append", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.maybe_download_and_extract"], ["", "def", "load_imdb_dataset", "(", "path", "=", "'data/imdb/'", ",", "nb_words", "=", "None", ",", "skip_top", "=", "0", ",", "\n", "maxlen", "=", "None", ",", "test_split", "=", "0.2", ",", "seed", "=", "113", ",", "\n", "start_char", "=", "1", ",", "oov_char", "=", "2", ",", "index_from", "=", "3", ")", ":", "\n", "    ", "\"\"\"Load IMDB dataset\n\n    Parameters\n    ----------\n    path : : string\n        Path to download data to, defaults to data/imdb/\n\n    Examples\n    --------\n    >>> X_train, y_train, X_test, y_test = tl.files.load_imbd_dataset(\n    ...                                 nb_words=20000, test_split=0.2)\n    >>> print('X_train.shape', X_train.shape)\n    ... (20000,)  [[1, 62, 74, ... 1033, 507, 27],[1, 60, 33, ... 13, 1053, 7]..]\n    >>> print('y_train.shape', y_train.shape)\n    ... (20000,)  [1 0 0 ..., 1 0 1]\n\n    References\n    -----------\n    - `Modified from keras. <https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py>`_\n    \"\"\"", "\n", "\n", "filename", "=", "\"imdb.pkl\"", "\n", "url", "=", "'https://s3.amazonaws.com/text-datasets/'", "\n", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "url", ")", "\n", "\n", "if", "filename", ".", "endswith", "(", "\".gz\"", ")", ":", "\n", "        ", "f", "=", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ",", "'rb'", ")", "\n", "", "else", ":", "\n", "        ", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "filename", ")", ",", "'rb'", ")", "\n", "\n", "", "X", ",", "labels", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "X", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "labels", ")", "\n", "\n", "if", "start_char", "is", "not", "None", ":", "\n", "        ", "X", "=", "[", "[", "start_char", "]", "+", "[", "w", "+", "index_from", "for", "w", "in", "x", "]", "for", "x", "in", "X", "]", "\n", "", "elif", "index_from", ":", "\n", "        ", "X", "=", "[", "[", "w", "+", "index_from", "for", "w", "in", "x", "]", "for", "x", "in", "X", "]", "\n", "\n", "", "if", "maxlen", ":", "\n", "        ", "new_X", "=", "[", "]", "\n", "new_labels", "=", "[", "]", "\n", "for", "x", ",", "y", "in", "zip", "(", "X", ",", "labels", ")", ":", "\n", "            ", "if", "len", "(", "x", ")", "<", "maxlen", ":", "\n", "                ", "new_X", ".", "append", "(", "x", ")", "\n", "new_labels", ".", "append", "(", "y", ")", "\n", "", "", "X", "=", "new_X", "\n", "labels", "=", "new_labels", "\n", "", "if", "not", "X", ":", "\n", "        ", "raise", "Exception", "(", "'After filtering for sequences shorter than maxlen='", "+", "\n", "str", "(", "maxlen", ")", "+", "', no sequence was kept. '", "\n", "'Increase maxlen.'", ")", "\n", "", "if", "not", "nb_words", ":", "\n", "        ", "nb_words", "=", "max", "(", "[", "max", "(", "x", ")", "for", "x", "in", "X", "]", ")", "\n", "\n", "# by convention, use 2 as OOV word", "\n", "# reserve 'index_from' (=3 by default) characters: 0 (padding), 1 (start), 2 (OOV)", "\n", "", "if", "oov_char", "is", "not", "None", ":", "\n", "        ", "X", "=", "[", "[", "oov_char", "if", "(", "w", ">=", "nb_words", "or", "w", "<", "skip_top", ")", "else", "w", "for", "w", "in", "x", "]", "for", "x", "in", "X", "]", "\n", "", "else", ":", "\n", "        ", "nX", "=", "[", "]", "\n", "for", "x", "in", "X", ":", "\n", "            ", "nx", "=", "[", "]", "\n", "for", "w", "in", "x", ":", "\n", "                ", "if", "(", "w", ">=", "nb_words", "or", "w", "<", "skip_top", ")", ":", "\n", "                    ", "nx", ".", "append", "(", "w", ")", "\n", "", "", "nX", ".", "append", "(", "nx", ")", "\n", "", "X", "=", "nX", "\n", "\n", "", "X_train", "=", "np", ".", "array", "(", "X", "[", ":", "int", "(", "len", "(", "X", ")", "*", "(", "1", "-", "test_split", ")", ")", "]", ")", "\n", "y_train", "=", "np", ".", "array", "(", "labels", "[", ":", "int", "(", "len", "(", "X", ")", "*", "(", "1", "-", "test_split", ")", ")", "]", ")", "\n", "\n", "X_test", "=", "np", ".", "array", "(", "X", "[", "int", "(", "len", "(", "X", ")", "*", "(", "1", "-", "test_split", ")", ")", ":", "]", ")", "\n", "y_test", "=", "np", ".", "array", "(", "labels", "[", "int", "(", "len", "(", "X", ")", "*", "(", "1", "-", "test_split", ")", ")", ":", "]", ")", "\n", "\n", "return", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_nietzsche_dataset": [[418, 443], ["print", "files.maybe_download_and_extract", "open", "f.read"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.maybe_download_and_extract"], ["", "def", "load_nietzsche_dataset", "(", "path", "=", "'data/nietzsche/'", ")", ":", "\n", "    ", "\"\"\"Load Nietzsche dataset.\n    Returns a string.\n\n    Parameters\n    ----------\n    path : string\n        Path to download data to, defaults to data/nietzsche/\n\n    Examples\n    --------\n    >>> see tutorial_generate_text.py\n    >>> words = tl.files.load_nietzsche_dataset()\n    >>> words = basic_clean_str(words)\n    >>> words = words.split()\n    \"\"\"", "\n", "print", "(", "(", "\"Load or Download nietzsche dataset > {}\"", ".", "format", "(", "path", ")", ")", ")", "\n", "\n", "filename", "=", "\"nietzsche.txt\"", "\n", "url", "=", "'https://s3.amazonaws.com/text-datasets/'", "\n", "filepath", "=", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "url", ")", "\n", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "words", "=", "f", ".", "read", "(", ")", "\n", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_wmt_en_fr_dataset": [[444, 507], ["print", "files.load_wmt_en_fr_dataset.get_wmt_enfr_train_set"], "function", ["None"], ["", "", "def", "load_wmt_en_fr_dataset", "(", "path", "=", "'data/wmt_en_fr/'", ")", ":", "\n", "    ", "\"\"\"It will download English-to-French translation data from the WMT'15\n    Website (10^9-French-English corpus), and the 2013 news test from\n    the same site as development set.\n    Returns the directories of training data and test data.\n\n    Parameters\n    ----------\n    path : string\n        Path to download data to, defaults to data/wmt_en_fr/\n\n    References\n    ----------\n    - Code modified from /tensorflow/models/rnn/translation/data_utils.py\n\n    Notes\n    -----\n    Usually, it will take a long time to download this dataset.\n    \"\"\"", "\n", "# URLs for WMT data.", "\n", "_WMT_ENFR_TRAIN_URL", "=", "\"http://www.statmt.org/wmt10/\"", "\n", "_WMT_ENFR_DEV_URL", "=", "\"http://www.statmt.org/wmt15/\"", "\n", "\n", "def", "gunzip_file", "(", "gz_path", ",", "new_path", ")", ":", "\n", "        ", "\"\"\"Unzips from gz_path into new_path.\"\"\"", "\n", "print", "(", "(", "\"Unpacking %s to %s\"", "%", "(", "gz_path", ",", "new_path", ")", ")", ")", "\n", "with", "gzip", ".", "open", "(", "gz_path", ",", "\"rb\"", ")", "as", "gz_file", ":", "\n", "            ", "with", "open", "(", "new_path", ",", "\"wb\"", ")", "as", "new_file", ":", "\n", "                ", "for", "line", "in", "gz_file", ":", "\n", "                    ", "new_file", ".", "write", "(", "line", ")", "\n", "\n", "", "", "", "", "def", "get_wmt_enfr_train_set", "(", "path", ")", ":", "\n", "        ", "\"\"\"Download the WMT en-fr training corpus to directory unless it's there.\"\"\"", "\n", "filename", "=", "\"training-giga-fren.tar\"", "\n", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "_WMT_ENFR_TRAIN_URL", ",", "extract", "=", "True", ")", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"giga-fren.release2.fixed\"", ")", "\n", "gunzip_file", "(", "train_path", "+", "\".fr.gz\"", ",", "train_path", "+", "\".fr\"", ")", "\n", "gunzip_file", "(", "train_path", "+", "\".en.gz\"", ",", "train_path", "+", "\".en\"", ")", "\n", "return", "train_path", "\n", "\n", "", "def", "get_wmt_enfr_dev_set", "(", "path", ")", ":", "\n", "        ", "\"\"\"Download the WMT en-fr training corpus to directory unless it's there.\"\"\"", "\n", "filename", "=", "\"dev-v2.tgz\"", "\n", "dev_file", "=", "maybe_download_and_extract", "(", "filename", ",", "path", ",", "_WMT_ENFR_DEV_URL", ",", "extract", "=", "False", ")", "\n", "dev_name", "=", "\"newstest2013\"", "\n", "dev_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"newstest2013\"", ")", "\n", "if", "not", "(", "gfile", ".", "Exists", "(", "dev_path", "+", "\".fr\"", ")", "and", "gfile", ".", "Exists", "(", "dev_path", "+", "\".en\"", ")", ")", ":", "\n", "            ", "print", "(", "(", "\"Extracting tgz file %s\"", "%", "dev_file", ")", ")", "\n", "with", "tarfile", ".", "open", "(", "dev_file", ",", "\"r:gz\"", ")", "as", "dev_tar", ":", "\n", "              ", "fr_dev_file", "=", "dev_tar", ".", "getmember", "(", "\"dev/\"", "+", "dev_name", "+", "\".fr\"", ")", "\n", "en_dev_file", "=", "dev_tar", ".", "getmember", "(", "\"dev/\"", "+", "dev_name", "+", "\".en\"", ")", "\n", "fr_dev_file", ".", "name", "=", "dev_name", "+", "\".fr\"", "# Extract without \"dev/\" prefix.", "\n", "en_dev_file", ".", "name", "=", "dev_name", "+", "\".en\"", "\n", "dev_tar", ".", "extract", "(", "fr_dev_file", ",", "path", ")", "\n", "dev_tar", ".", "extract", "(", "en_dev_file", ",", "path", ")", "\n", "", "", "return", "dev_path", "\n", "\n", "", "print", "(", "(", "\"Load or Download WMT English-to-French translation > {}\"", ".", "format", "(", "path", ")", ")", ")", "\n", "\n", "train_path", "=", "get_wmt_enfr_train_set", "(", "path", ")", "\n", "dev_path", "=", "get_wmt_enfr_dev_set", "(", "path", ")", "\n", "\n", "return", "train_path", ",", "dev_path", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.save_npz": [[510, 556], ["numpy.savez", "print", "sess.run", "enumerate", "sess.run.append", "print", "value.eval"], "function", ["None"], ["", "def", "save_npz", "(", "save_list", "=", "[", "]", ",", "name", "=", "'model.npz'", ",", "sess", "=", "None", ")", ":", "\n", "    ", "\"\"\"Input parameters and the file name, save parameters into .npz file. Use tl.utils.load_npz() to restore.\n\n    Parameters\n    ----------\n    save_list : a list\n        Parameters want to be saved.\n    name : a string or None\n        The name of the .npz file.\n    sess : None or Session\n\n    Examples\n    --------\n    >>> tl.files.save_npz(network.all_params, name='model_test.npz', sess=sess)\n    ... File saved to: model_test.npz\n    >>> load_params = tl.files.load_npz(name='model_test.npz')\n    ... Loading param0, (784, 800)\n    ... Loading param1, (800,)\n    ... Loading param2, (800, 800)\n    ... Loading param3, (800,)\n    ... Loading param4, (800, 10)\n    ... Loading param5, (10,)\n    >>> put parameters into a TensorLayer network, please see assign_params()\n\n    Notes\n    -----\n    If you got session issues, you can change the value.eval() to value.eval(session=sess)\n\n    References\n    ----------\n    - `Saving dictionary using numpy <http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez>`_\n    \"\"\"", "\n", "## save params into a list", "\n", "save_list_var", "=", "[", "]", "\n", "if", "sess", ":", "\n", "        ", "save_list_var", "=", "sess", ".", "run", "(", "save_list", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "for", "k", ",", "value", "in", "enumerate", "(", "save_list", ")", ":", "\n", "                ", "save_list_var", ".", "append", "(", "value", ".", "eval", "(", ")", ")", "\n", "", "", "except", ":", "\n", "            ", "print", "(", "\" Fail to save model, Hint: pass the session into this function, save_npz(network.all_params, name='model.npz', sess=sess)\"", ")", "\n", "", "", "np", ".", "savez", "(", "name", ",", "params", "=", "save_list_var", ")", "\n", "save_list_var", "=", "None", "\n", "del", "save_list_var", "\n", "print", "(", "(", "\"[*] %s saved\"", "%", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_npz": [[564, 601], ["numpy.load"], "function", ["None"], ["", "def", "load_npz", "(", "path", "=", "''", ",", "name", "=", "'model.npz'", ")", ":", "\n", "    ", "\"\"\"Load the parameters of a Model saved by tl.files.save_npz().\n\n    Parameters\n    ----------\n    path : a string\n        Folder path to .npz file.\n    name : a string or None\n        The name of the .npz file.\n\n    Returns\n    --------\n    params : list\n        A list of parameters in order.\n\n    Examples\n    --------\n    - See save_npz and assign_params\n\n    References\n    ----------\n    - `Saving dictionary using numpy <http://stackoverflow.com/questions/22315595/saving-dictionary-of-header-information-using-numpy-savez>`_\n    \"\"\"", "\n", "## if save_npz save params into a dictionary", "\n", "# d = np.load( path+name )", "\n", "# params = []", "\n", "# print('Load Model')", "\n", "# for key, val in sorted( d.items() ):", "\n", "#     params.append(val)", "\n", "#     print('Loading %s, %s' % (key, str(val.shape)))", "\n", "# return params", "\n", "## if save_npz save params into a list", "\n", "d", "=", "np", ".", "load", "(", "path", "+", "name", ")", "\n", "# for val in sorted( d.items() ):", "\n", "#     params = val", "\n", "#     return params", "\n", "return", "d", "[", "'params'", "]", "\n", "# print(d.items()[0][1]['params'])", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.assign_params": [[605, 636], ["enumerate", "sess.run", "ops.append", "network.all_params[].assign"], "function", ["None"], ["", "def", "assign_params", "(", "sess", ",", "params", ",", "network", ")", ":", "\n", "    ", "\"\"\"Assign the given parameters to the TensorLayer network.\n\n    Parameters\n    ----------\n    sess : TensorFlow Session\n    params : a list\n        A list of parameters in order.\n    network : a :class:`Layer` class\n        The network to be assigned\n\n    Examples\n    --------\n    >>> Save your network as follow:\n    >>> tl.files.save_npz(network.all_params, name='model_test.npz')\n    >>> network.print_params()\n    ...\n    ... Next time, load and assign your network as follow:\n    >>> sess.run(tf.initialize_all_variables()) # re-initialize, then save and assign\n    >>> load_params = tl.files.load_npz(name='model_test.npz')\n    >>> tl.files.assign_params(sess, load_params, network)\n    >>> network.print_params()\n\n    References\n    ----------\n    - `Assign value to a TensorFlow variable <http://stackoverflow.com/questions/34220532/how-to-assign-value-to-a-tensorflow-variable>`_\n    \"\"\"", "\n", "ops", "=", "[", "]", "\n", "for", "idx", ",", "param", "in", "enumerate", "(", "params", ")", ":", "\n", "        ", "ops", ".", "append", "(", "network", ".", "all_params", "[", "idx", "]", ".", "assign", "(", "param", ")", ")", "\n", "", "sess", ".", "run", "(", "ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_and_assign_npz": [[637, 666], ["os.path.exists", "print", "files.load_npz", "files.assign_params", "print"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_npz", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.assign_params"], ["", "def", "load_and_assign_npz", "(", "sess", "=", "None", ",", "name", "=", "None", ",", "network", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load model from npz and assign to a network.\n\n    Parameters\n    -------------\n    sess : TensorFlow Session\n    name : string\n        Model path.\n    network : a :class:`Layer` class\n        The network to be assigned\n\n    Returns\n    --------\n    Returns False if faild to model is not exist.\n\n    Examples\n    ---------\n    >>> tl.files.load_and_assign_npz(sess=sess, name='net.npz', network=net)\n    \"\"\"", "\n", "assert", "network", "is", "not", "None", "\n", "assert", "sess", "is", "not", "None", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "name", ")", ":", "\n", "        ", "print", "(", "(", "\"[!] Load {} failed!\"", ".", "format", "(", "name", ")", ")", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "        ", "params", "=", "load_npz", "(", "name", "=", "name", ")", "\n", "assign_params", "(", "sess", ",", "params", ",", "network", ")", "\n", "print", "(", "(", "\"[*] Load {} SUCCESS!\"", ".", "format", "(", "name", ")", ")", ")", "\n", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.save_any_to_npy": [[668, 679], ["numpy.save"], "function", ["None"], ["", "", "def", "save_any_to_npy", "(", "save_dict", "=", "{", "}", ",", "name", "=", "'file.npy'", ")", ":", "\n", "    ", "\"\"\"Save variables to .npy file.\n\n    Examples\n    ---------\n    >>> tl.files.save_any_to_npy(save_dict={'data': ['a','b']}, name='test.npy')\n    >>> data = tl.files.load_npy_to_any(name='test.npy')\n    >>> print(data)\n    ... {'data': ['a','b']}\n    \"\"\"", "\n", "np", ".", "save", "(", "name", ",", "save_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_npy_to_any": [[680, 698], ["os.path.join", "numpy.load().item", "numpy.load", "numpy.load", "print", "exit"], "function", ["None"], ["", "def", "load_npy_to_any", "(", "path", "=", "''", ",", "name", "=", "'file.npy'", ")", ":", "\n", "    ", "\"\"\"Load .npy file.\n\n    Examples\n    ---------\n    - see save_any_to_npy()\n    \"\"\"", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "try", ":", "\n", "        ", "npy", "=", "np", ".", "load", "(", "file_path", ")", ".", "item", "(", ")", "\n", "", "except", ":", "\n", "        ", "npy", "=", "np", ".", "load", "(", "file_path", ")", "\n", "", "finally", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "npy", "\n", "", "except", ":", "\n", "            ", "print", "(", "(", "\"[!] Fail to load %s\"", "%", "file_path", ")", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.npz_to_W_pdf": [[701, 721], ["files.load_file_list", "print", "visualize.W", "files.load_npz", "f.split", "f.split"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_file_list", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.W", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_npz"], ["", "", "", "def", "npz_to_W_pdf", "(", "path", "=", "None", ",", "regx", "=", "'w1pre_[0-9]+\\.(npz)'", ")", ":", "\n", "    ", "\"\"\"Convert the first weight matrix of .npz file to .pdf by using tl.visualize.W().\n\n    Parameters\n    ----------\n    path : a string or None\n        A folder path to npz files.\n    regx : a string\n        Regx for the file name.\n\n    Examples\n    --------\n    >>> Convert the first weight matrix of w1_pre...npz file to w1_pre...pdf.\n    >>> tl.files.npz_to_W_pdf(path='/Users/.../npz_file/', regx='w1pre_[0-9]+\\.(npz)')\n    \"\"\"", "\n", "file_list", "=", "load_file_list", "(", "path", "=", "path", ",", "regx", "=", "regx", ")", "\n", "for", "f", "in", "file_list", ":", "\n", "        ", "W", "=", "load_npz", "(", "path", ",", "f", ")", "[", "0", "]", "\n", "print", "(", "(", "\"%s --> %s\"", "%", "(", "f", ",", "f", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'.pdf'", ")", ")", ")", "\n", "visualize", ".", "W", "(", "W", ",", "second", "=", "10", ",", "saveable", "=", "True", ",", "name", "=", "f", ".", "split", "(", "'.'", ")", "[", "0", "]", ",", "fig_idx", "=", "2012", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_file_list": [[724, 751], ["os.listdir", "enumerate", "os.getcwd", "re.search", "print", "print", "return_list.append", "len"], "function", ["None"], ["", "", "def", "load_file_list", "(", "path", "=", "None", ",", "regx", "=", "'\\.npz'", ",", "printable", "=", "True", ")", ":", "\n", "    ", "\"\"\"Return a file list in a folder by given a path and regular expression.\n\n    Parameters\n    ----------\n    path : a string or None\n        A folder path.\n    regx : a string\n        The regx of file name.\n    printable : boolean, whether to print the files infomation.\n\n    Examples\n    ----------\n    >>> file_list = tl.files.load_file_list(path=None, regx='w1pre_[0-9]+\\.(npz)')\n    \"\"\"", "\n", "if", "path", "==", "False", ":", "\n", "        ", "path", "=", "os", ".", "getcwd", "(", ")", "\n", "", "file_list", "=", "os", ".", "listdir", "(", "path", ")", "\n", "return_list", "=", "[", "]", "\n", "for", "idx", ",", "f", "in", "enumerate", "(", "file_list", ")", ":", "\n", "        ", "if", "re", ".", "search", "(", "regx", ",", "f", ")", ":", "\n", "            ", "return_list", ".", "append", "(", "f", ")", "\n", "# return_list.sort()", "\n", "", "", "if", "printable", ":", "\n", "        ", "print", "(", "(", "'Match file list = %s'", "%", "return_list", ")", ")", "\n", "print", "(", "(", "'Number of files = %d'", "%", "len", "(", "return_list", ")", ")", ")", "\n", "", "return", "return_list", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.load_folder_list": [[752, 761], ["os.path.join", "os.listdir", "os.path.isdir", "os.path.join"], "function", ["None"], ["", "def", "load_folder_list", "(", "path", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Return a folder list in a folder by given a folder path.\n\n    Parameters\n    ----------\n    path : a string or None\n        A folder path.\n    \"\"\"", "\n", "return", "[", "os", ".", "path", ".", "join", "(", "path", ",", "o", ")", "for", "o", "in", "os", ".", "listdir", "(", "path", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path", ",", "o", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.exists_or_mkdir": [[762, 790], ["os.path.exists", "os.makedirs", "print", "print"], "function", ["None"], ["", "def", "exists_or_mkdir", "(", "path", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Check a folder by given name, if not exist, create the folder and return False,\n    if directory exists, return True.\n\n    Parameters\n    ----------\n    path : a string\n        A folder path.\n    verbose : boolean\n        If True, prints results, deaults is True\n\n    Returns\n    --------\n    True if folder exist, otherwise, returns False and create the folder\n\n    Examples\n    --------\n    >>> tl.files.exists_or_mkdir(\"checkpoints/train\")\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "(", "\"[*] creates %s ...\"", "%", "path", ")", ")", "\n", "", "os", ".", "makedirs", "(", "path", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "(", "\"[!] %s exists ...\"", "%", "path", ")", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.maybe_download_and_extract": [[791, 859], ["files.exists_or_mkdir", "os.path.join", "os.path.join", "urlretrieve", "os.path.exists", "files.maybe_download_and_extract._download"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.exists_or_mkdir"], ["", "", "def", "maybe_download_and_extract", "(", "filename", ",", "working_directory", ",", "url_source", ",", "extract", "=", "False", ",", "expected_bytes", "=", "None", ")", ":", "\n", "    ", "\"\"\"Checks if file exists in working_directory otherwise tries to dowload the file,\n    and optionally also tries to extract the file if format is \".zip\" or \".tar\"\n\n    Parameters\n    ----------\n    filename : string\n        The name of the (to be) dowloaded file.\n    working_directory : string\n        A folder path to search for the file in and dowload the file to\n    url : string\n        The URL to download the file from\n    extract : bool, defaults to False\n        If True, tries to uncompress the dowloaded file is \".tar.gz/.tar.bz2\" or \".zip\" file\n    expected_bytes : int/None\n        If set tries to verify that the downloaded file is of the specified size, otherwise raises an Exception,\n        defaults to None which corresponds to no check being performed\n    Returns\n    ----------\n    filepath to dowloaded (uncompressed) file\n\n    Examples\n    --------\n    >>> down_file = tl.files.maybe_download_and_extract(filename = 'train-images-idx3-ubyte.gz',\n                                                        working_directory = 'data/',\n                                                        url_source = 'http://yann.lecun.com/exdb/mnist/')\n    >>> tl.files.maybe_download_and_extract(filename = 'ADEChallengeData2016.zip',\n                                            working_directory = 'data/',\n                                            url_source = 'http://sceneparsing.csail.mit.edu/data/',\n                                            extract=True)\n    \"\"\"", "\n", "# We first define a download function, supporting both Python 2 and 3.", "\n", "def", "_download", "(", "filename", ",", "working_directory", ",", "url_source", ")", ":", "\n", "        ", "def", "_dlProgress", "(", "count", ",", "blockSize", ",", "totalSize", ")", ":", "\n", "            ", "if", "(", "totalSize", "!=", "0", ")", ":", "\n", "                ", "percent", "=", "float", "(", "count", "*", "blockSize", ")", "/", "float", "(", "totalSize", ")", "*", "100.0", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\r\"", "\"Downloading \"", "+", "filename", "+", "\"...%d%%\"", "%", "percent", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "            ", "from", "urllib", ".", "request", "import", "urlretrieve", "\n", "", "else", ":", "\n", "            ", "from", "urllib", ".", "request", "import", "urlretrieve", "\n", "", "filepath", "=", "os", ".", "path", ".", "join", "(", "working_directory", ",", "filename", ")", "\n", "urlretrieve", "(", "url_source", "+", "filename", ",", "filepath", ",", "reporthook", "=", "_dlProgress", ")", "\n", "\n", "", "exists_or_mkdir", "(", "working_directory", ",", "verbose", "=", "False", ")", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "working_directory", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "        ", "_download", "(", "filename", ",", "working_directory", ",", "url_source", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "(", "'Succesfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", ")", "\n", "if", "(", "not", "(", "expected_bytes", "is", "None", ")", "and", "(", "expected_bytes", "!=", "statinfo", ".", "st_size", ")", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Failed to verify '", "+", "filename", "+", "'. Can you get to it with a browser?'", ")", "\n", "", "if", "(", "extract", ")", ":", "\n", "            ", "if", "tarfile", ".", "is_tarfile", "(", "filepath", ")", ":", "\n", "                ", "print", "(", "'Trying to extract tar file'", ")", "\n", "tarfile", ".", "open", "(", "filepath", ",", "'r'", ")", ".", "extractall", "(", "working_directory", ")", "\n", "print", "(", "'... Success!'", ")", "\n", "", "elif", "zipfile", ".", "is_zipfile", "(", "filepath", ")", ":", "\n", "                ", "print", "(", "'Trying to extract zip file'", ")", "\n", "with", "zipfile", ".", "ZipFile", "(", "filepath", ")", "as", "zf", ":", "\n", "                    ", "zf", ".", "extractall", "(", "working_directory", ")", "\n", "", "print", "(", "'... Success!'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Unknown compression_format only .tar.gz/.tar.bz2/.tar and .zip supported\"", ")", "\n", "", "", "", "return", "filepath", "\n", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.save_images": [[15, 44], ["visualize.save_images.imsave"], "function", ["None"], ["def", "save_images", "(", "images", ",", "size", ",", "image_path", ")", ":", "\n", "    ", "\"\"\"Save mutiple images into one single image.\n\n    Parameters\n    -----------\n    images : numpy array [batch, w, h, c]\n    size : list of two int, row and column number.\n        number of images should be equal or less than size[0] * size[1]\n    image_path : string.\n\n    Examples\n    ---------\n    >>> images = np.random.rand(64, 100, 100, 3)\n    >>> tl.visualize.save_images(images, [8, 8], 'temp.png')\n    \"\"\"", "\n", "def", "merge", "(", "images", ",", "size", ")", ":", "\n", "        ", "h", ",", "w", "=", "images", ".", "shape", "[", "1", "]", ",", "images", ".", "shape", "[", "2", "]", "\n", "img", "=", "np", ".", "zeros", "(", "(", "h", "*", "size", "[", "0", "]", ",", "w", "*", "size", "[", "1", "]", ",", "3", ")", ")", "\n", "for", "idx", ",", "image", "in", "enumerate", "(", "images", ")", ":", "\n", "            ", "i", "=", "idx", "%", "size", "[", "1", "]", "\n", "j", "=", "idx", "//", "size", "[", "1", "]", "\n", "img", "[", "j", "*", "h", ":", "j", "*", "h", "+", "h", ",", "i", "*", "w", ":", "i", "*", "w", "+", "w", ",", ":", "]", "=", "image", "\n", "", "return", "img", "\n", "\n", "", "def", "imsave", "(", "images", ",", "size", ",", "path", ")", ":", "\n", "        ", "return", "scipy", ".", "misc", ".", "imsave", "(", "path", ",", "merge", "(", "images", ",", "size", ")", ")", "\n", "\n", "", "assert", "len", "(", "images", ")", "<=", "size", "[", "0", "]", "*", "size", "[", "1", "]", ",", "\"number of images should be equal or less than size[0] * size[1] {}\"", ".", "format", "(", "len", "(", "images", ")", ")", "\n", "return", "imsave", "(", "images", ",", "size", ",", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.W": [[45, 105], ["matplotlib.figure", "int", "int", "int", "range", "matplotlib.ion", "numpy.sqrt", "numpy.ceil", "range", "matplotlib.savefig", "matplotlib.draw", "matplotlib.pause", "plt.figure.add_subplot", "matplotlib.imshow", "matplotlib.gca().xaxis.set_major_locator", "matplotlib.gca().yaxis.set_major_locator", "numpy.sqrt", "numpy.reshape", "matplotlib.NullLocator", "matplotlib.NullLocator", "matplotlib.gca", "matplotlib.gca"], "function", ["None"], ["", "def", "W", "(", "W", "=", "None", ",", "second", "=", "10", ",", "saveable", "=", "True", ",", "shape", "=", "[", "28", ",", "28", "]", ",", "name", "=", "'mnist'", ",", "fig_idx", "=", "2396512", ")", ":", "\n", "    ", "\"\"\"Visualize every columns of the weight matrix to a group of Greyscale img.\n\n    Parameters\n    ----------\n    W : numpy.array\n        The weight matrix\n    second : int\n        The display second(s) for the image(s), if saveable is False.\n    saveable : boolean\n        Save or plot the figure.\n    shape : a list with 2 int\n        The shape of feature image, MNIST is [28, 80].\n    name : a string\n        A name to save the image, if saveable is True.\n    fig_idx : int\n        matplotlib figure index.\n\n    Examples\n    --------\n    >>> tl.visualize.W(network.all_params[0].eval(), second=10, saveable=True, name='weight_of_1st_layer', fig_idx=2012)\n    \"\"\"", "\n", "if", "saveable", "is", "False", ":", "\n", "        ", "plt", ".", "ion", "(", ")", "\n", "", "fig", "=", "plt", ".", "figure", "(", "fig_idx", ")", "# show all feature images", "\n", "size", "=", "W", ".", "shape", "[", "0", "]", "\n", "n_units", "=", "W", ".", "shape", "[", "1", "]", "\n", "\n", "num_r", "=", "int", "(", "np", ".", "sqrt", "(", "n_units", ")", ")", "# \u6bcf\u884c\u663e\u793a\u7684\u4e2a\u6570   \u82e525\u4e2ahidden unit -> \u6bcf\u884c\u663e\u793a5\u4e2a", "\n", "num_c", "=", "int", "(", "np", ".", "ceil", "(", "n_units", "/", "num_r", ")", ")", "\n", "count", "=", "int", "(", "1", ")", "\n", "for", "row", "in", "range", "(", "1", ",", "num_r", "+", "1", ")", ":", "\n", "        ", "for", "col", "in", "range", "(", "1", ",", "num_c", "+", "1", ")", ":", "\n", "            ", "if", "count", ">", "n_units", ":", "\n", "                ", "break", "\n", "", "a", "=", "fig", ".", "add_subplot", "(", "num_r", ",", "num_c", ",", "count", ")", "\n", "# ------------------------------------------------------------", "\n", "# plt.imshow(np.reshape(W[:,count-1],(28,28)), cmap='gray')", "\n", "# ------------------------------------------------------------", "\n", "feature", "=", "W", "[", ":", ",", "count", "-", "1", "]", "/", "np", ".", "sqrt", "(", "(", "W", "[", ":", ",", "count", "-", "1", "]", "**", "2", ")", ".", "sum", "(", ")", ")", "\n", "# feature[feature<0.0001] = 0   # value threshold", "\n", "# if count == 1 or count == 2:", "\n", "#     print(np.mean(feature))", "\n", "# if np.std(feature) < 0.03:      # condition threshold", "\n", "#     feature = np.zeros_like(feature)", "\n", "# if np.mean(feature) < -0.015:      # condition threshold", "\n", "#     feature = np.zeros_like(feature)", "\n", "plt", ".", "imshow", "(", "np", ".", "reshape", "(", "feature", ",", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", ")", ",", "\n", "cmap", "=", "'gray'", ",", "interpolation", "=", "\"nearest\"", ")", "#, vmin=np.min(feature), vmax=np.max(feature))", "\n", "# plt.title(name)", "\n", "# ------------------------------------------------------------", "\n", "# plt.imshow(np.reshape(W[:,count-1] ,(np.sqrt(size),np.sqrt(size))), cmap='gray', interpolation=\"nearest\")", "\n", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "# distable tick", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "", "if", "saveable", ":", "\n", "        ", "plt", ".", "savefig", "(", "name", "+", "'.pdf'", ",", "format", "=", "'pdf'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "draw", "(", ")", "\n", "plt", ".", "pause", "(", "second", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.frame": [[106, 147], ["matplotlib.figure", "matplotlib.imshow", "matplotlib.title", "matplotlib.ion", "len", "matplotlib.savefig", "matplotlib.draw", "matplotlib.pause"], "function", ["None"], ["", "", "def", "frame", "(", "I", "=", "None", ",", "second", "=", "5", ",", "saveable", "=", "True", ",", "name", "=", "'frame'", ",", "cmap", "=", "None", ",", "fig_idx", "=", "12836", ")", ":", "\n", "    ", "\"\"\"Display a frame(image). Make sure OpenAI Gym render() is disable before using it.\n\n    Parameters\n    ----------\n    I : numpy.array\n        The image\n    second : int\n        The display second(s) for the image(s), if saveable is False.\n    saveable : boolean\n        Save or plot the figure.\n    name : a string\n        A name to save the image, if saveable is True.\n    cmap : None or string\n        'gray' for greyscale, None for default, etc.\n    fig_idx : int\n        matplotlib figure index.\n\n    Examples\n    --------\n    >>> env = gym.make(\"Pong-v0\")\n    >>> observation = env.reset()\n    >>> tl.visualize.frame(observation)\n    \"\"\"", "\n", "if", "saveable", "is", "False", ":", "\n", "        ", "plt", ".", "ion", "(", ")", "\n", "", "fig", "=", "plt", ".", "figure", "(", "fig_idx", ")", "# show all feature images", "\n", "\n", "if", "len", "(", "I", ".", "shape", ")", "and", "I", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "# (10,10,1) --> (10,10)", "\n", "        ", "I", "=", "I", "[", ":", ",", ":", ",", "0", "]", "\n", "\n", "", "plt", ".", "imshow", "(", "I", ",", "cmap", ")", "\n", "plt", ".", "title", "(", "name", ")", "\n", "# plt.gca().xaxis.set_major_locator(plt.NullLocator())    # distable tick", "\n", "# plt.gca().yaxis.set_major_locator(plt.NullLocator())", "\n", "\n", "if", "saveable", ":", "\n", "        ", "plt", ".", "savefig", "(", "name", "+", "'.pdf'", ",", "format", "=", "'pdf'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "draw", "(", ")", "\n", "plt", ".", "pause", "(", "second", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.CNN2d": [[148, 207], ["int", "int", "matplotlib.ion", "matplotlib.figure", "range", "numpy.sqrt", "numpy.ceil", "range", "matplotlib.savefig", "matplotlib.draw", "matplotlib.pause", "plt.figure.add_subplot", "matplotlib.gca().xaxis.set_major_locator", "matplotlib.gca().yaxis.set_major_locator", "matplotlib.imshow", "matplotlib.NullLocator", "matplotlib.NullLocator", "numpy.reshape", "matplotlib.imshow", "Exception", "numpy.reshape", "matplotlib.gca", "matplotlib.gca"], "function", ["None"], ["", "", "def", "CNN2d", "(", "CNN", "=", "None", ",", "second", "=", "10", ",", "saveable", "=", "True", ",", "name", "=", "'cnn'", ",", "fig_idx", "=", "3119362", ")", ":", "\n", "    ", "\"\"\"Display a group of RGB or Greyscale CNN masks.\n\n    Parameters\n    ----------\n    CNN : numpy.array\n        The image. e.g: 64 5x5 RGB images can be (5, 5, 3, 64).\n    second : int\n        The display second(s) for the image(s), if saveable is False.\n    saveable : boolean\n        Save or plot the figure.\n    name : a string\n        A name to save the image, if saveable is True.\n    fig_idx : int\n        matplotlib figure index.\n\n    Examples\n    --------\n    >>> tl.visualize.CNN2d(network.all_params[0].eval(), second=10, saveable=True, name='cnn1_mnist', fig_idx=2012)\n    \"\"\"", "\n", "# print(CNN.shape)    # (5, 5, 3, 64)", "\n", "# exit()", "\n", "n_mask", "=", "CNN", ".", "shape", "[", "3", "]", "\n", "n_row", "=", "CNN", ".", "shape", "[", "0", "]", "\n", "n_col", "=", "CNN", ".", "shape", "[", "1", "]", "\n", "n_color", "=", "CNN", ".", "shape", "[", "2", "]", "\n", "row", "=", "int", "(", "np", ".", "sqrt", "(", "n_mask", ")", ")", "\n", "col", "=", "int", "(", "np", ".", "ceil", "(", "n_mask", "/", "row", ")", ")", "\n", "plt", ".", "ion", "(", ")", "# active mode", "\n", "fig", "=", "plt", ".", "figure", "(", "fig_idx", ")", "\n", "count", "=", "1", "\n", "for", "ir", "in", "range", "(", "1", ",", "row", "+", "1", ")", ":", "\n", "        ", "for", "ic", "in", "range", "(", "1", ",", "col", "+", "1", ")", ":", "\n", "            ", "if", "count", ">", "n_mask", ":", "\n", "                ", "break", "\n", "", "a", "=", "fig", ".", "add_subplot", "(", "col", ",", "row", ",", "count", ")", "\n", "# print(CNN[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5", "\n", "# exit()", "\n", "# plt.imshow(", "\n", "#         np.reshape(CNN[count-1,:,:,:], (n_row, n_col)),", "\n", "#         cmap='gray', interpolation=\"nearest\")     # theano", "\n", "if", "n_color", "==", "1", ":", "\n", "                ", "plt", ".", "imshow", "(", "\n", "np", ".", "reshape", "(", "CNN", "[", ":", ",", ":", ",", ":", ",", "count", "-", "1", "]", ",", "(", "n_row", ",", "n_col", ")", ")", ",", "\n", "cmap", "=", "'gray'", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "", "elif", "n_color", "==", "3", ":", "\n", "                ", "plt", ".", "imshow", "(", "\n", "np", ".", "reshape", "(", "CNN", "[", ":", ",", ":", ",", ":", ",", "count", "-", "1", "]", ",", "(", "n_row", ",", "n_col", ",", "n_color", ")", ")", ",", "\n", "cmap", "=", "'gray'", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Unknown n_color\"", ")", "\n", "", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "# distable tick", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "", "if", "saveable", ":", "\n", "        ", "plt", ".", "savefig", "(", "name", "+", "'.pdf'", ",", "format", "=", "'pdf'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "draw", "(", ")", "\n", "plt", ".", "pause", "(", "second", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.images2d": [[209, 274], ["int", "int", "matplotlib.ion", "matplotlib.figure", "range", "numpy.asarray", "numpy.sqrt", "numpy.ceil", "range", "matplotlib.savefig", "matplotlib.draw", "matplotlib.pause", "plt.figure.add_subplot", "matplotlib.gca().xaxis.set_major_locator", "matplotlib.gca().yaxis.set_major_locator", "matplotlib.imshow", "matplotlib.NullLocator", "matplotlib.NullLocator", "numpy.reshape", "matplotlib.imshow", "Exception", "matplotlib.gca", "matplotlib.gca"], "function", ["None"], ["", "", "def", "images2d", "(", "images", "=", "None", ",", "second", "=", "10", ",", "saveable", "=", "True", ",", "name", "=", "'images'", ",", "dtype", "=", "None", ",", "\n", "fig_idx", "=", "3119362", ")", ":", "\n", "    ", "\"\"\"Display a group of RGB or Greyscale images.\n\n    Parameters\n    ----------\n    images : numpy.array\n        The images.\n    second : int\n        The display second(s) for the image(s), if saveable is False.\n    saveable : boolean\n        Save or plot the figure.\n    name : a string\n        A name to save the image, if saveable is True.\n    dtype : None or numpy data type\n        The data type for displaying the images.\n    fig_idx : int\n        matplotlib figure index.\n\n    Examples\n    --------\n    >>> X_train, y_train, X_test, y_test = tl.files.load_cifar10_dataset(shape=(-1, 32, 32, 3), plotable=False)\n    >>> tl.visualize.images2d(X_train[0:100,:,:,:], second=10, saveable=False, name='cifar10', dtype=np.uint8, fig_idx=20212)\n    \"\"\"", "\n", "# print(images.shape)    # (50000, 32, 32, 3)", "\n", "# exit()", "\n", "if", "dtype", ":", "\n", "        ", "images", "=", "np", ".", "asarray", "(", "images", ",", "dtype", "=", "dtype", ")", "\n", "", "n_mask", "=", "images", ".", "shape", "[", "0", "]", "\n", "n_row", "=", "images", ".", "shape", "[", "1", "]", "\n", "n_col", "=", "images", ".", "shape", "[", "2", "]", "\n", "n_color", "=", "images", ".", "shape", "[", "3", "]", "\n", "row", "=", "int", "(", "np", ".", "sqrt", "(", "n_mask", ")", ")", "\n", "col", "=", "int", "(", "np", ".", "ceil", "(", "n_mask", "/", "row", ")", ")", "\n", "plt", ".", "ion", "(", ")", "# active mode", "\n", "fig", "=", "plt", ".", "figure", "(", "fig_idx", ")", "\n", "count", "=", "1", "\n", "for", "ir", "in", "range", "(", "1", ",", "row", "+", "1", ")", ":", "\n", "        ", "for", "ic", "in", "range", "(", "1", ",", "col", "+", "1", ")", ":", "\n", "            ", "if", "count", ">", "n_mask", ":", "\n", "                ", "break", "\n", "", "a", "=", "fig", ".", "add_subplot", "(", "col", ",", "row", ",", "count", ")", "\n", "# print(images[:,:,:,count-1].shape, n_row, n_col)   # (5, 1, 32) 5 5", "\n", "# plt.imshow(", "\n", "#         np.reshape(images[count-1,:,:,:], (n_row, n_col)),", "\n", "#         cmap='gray', interpolation=\"nearest\")     # theano", "\n", "if", "n_color", "==", "1", ":", "\n", "                ", "plt", ".", "imshow", "(", "\n", "np", ".", "reshape", "(", "images", "[", "count", "-", "1", ",", ":", ",", ":", "]", ",", "(", "n_row", ",", "n_col", ")", ")", ",", "\n", "cmap", "=", "'gray'", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "# plt.title(name)", "\n", "", "elif", "n_color", "==", "3", ":", "\n", "                ", "plt", ".", "imshow", "(", "images", "[", "count", "-", "1", ",", ":", ",", ":", "]", ",", "\n", "cmap", "=", "'gray'", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "# plt.title(name)", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Unknown n_color\"", ")", "\n", "", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "# distable tick", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "", "if", "saveable", ":", "\n", "        ", "plt", ".", "savefig", "(", "name", "+", "'.pdf'", ",", "format", "=", "'pdf'", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "draw", "(", ")", "\n", "plt", ".", "pause", "(", "second", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.visualize.tsne_embedding": [[275, 338], ["matplotlib.figure", "enumerate", "TSNE", "TSNE.fit_transform", "visualize.tsne_embedding.plot_with_labels"], "function", ["None"], ["", "", "def", "tsne_embedding", "(", "embeddings", ",", "reverse_dictionary", ",", "plot_only", "=", "500", ",", "\n", "second", "=", "5", ",", "saveable", "=", "False", ",", "name", "=", "'tsne'", ",", "fig_idx", "=", "9862", ")", ":", "\n", "    ", "\"\"\"Visualize the embeddings by using t-SNE.\n\n    Parameters\n    ----------\n    embeddings : a matrix\n        The images.\n    reverse_dictionary : a dictionary\n        id_to_word, mapping id to unique word.\n    plot_only : int\n        The number of examples to plot, choice the most common words.\n    second : int\n        The display second(s) for the image(s), if saveable is False.\n    saveable : boolean\n        Save or plot the figure.\n    name : a string\n        A name to save the image, if saveable is True.\n    fig_idx : int\n        matplotlib figure index.\n\n    Examples\n    --------\n    >>> see 'tutorial_word2vec_basic.py'\n    >>> final_embeddings = normalized_embeddings.eval()\n    >>> tl.visualize.tsne_embedding(final_embeddings, labels, reverse_dictionary,\n    ...                   plot_only=500, second=5, saveable=False, name='tsne')\n    \"\"\"", "\n", "def", "plot_with_labels", "(", "low_dim_embs", ",", "labels", ",", "figsize", "=", "(", "18", ",", "18", ")", ",", "second", "=", "5", ",", "\n", "saveable", "=", "True", ",", "name", "=", "'tsne'", ",", "fig_idx", "=", "9862", ")", ":", "\n", "        ", "assert", "low_dim_embs", ".", "shape", "[", "0", "]", ">=", "len", "(", "labels", ")", ",", "\"More labels than embeddings\"", "\n", "if", "saveable", "is", "False", ":", "\n", "            ", "plt", ".", "ion", "(", ")", "\n", "plt", ".", "figure", "(", "fig_idx", ")", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "figsize", ")", "#in inches", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "x", ",", "y", "=", "low_dim_embs", "[", "i", ",", ":", "]", "\n", "plt", ".", "scatter", "(", "x", ",", "y", ")", "\n", "plt", ".", "annotate", "(", "label", ",", "\n", "xy", "=", "(", "x", ",", "y", ")", ",", "\n", "xytext", "=", "(", "5", ",", "2", ")", ",", "\n", "textcoords", "=", "'offset points'", ",", "\n", "ha", "=", "'right'", ",", "\n", "va", "=", "'bottom'", ")", "\n", "", "if", "saveable", ":", "\n", "            ", "plt", ".", "savefig", "(", "name", "+", "'.pdf'", ",", "format", "=", "'pdf'", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "draw", "(", ")", "\n", "plt", ".", "pause", "(", "second", ")", "\n", "\n", "", "", "try", ":", "\n", "        ", "from", "sklearn", ".", "manifold", "import", "TSNE", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "from", "six", ".", "moves", "import", "xrange", "\n", "\n", "tsne", "=", "TSNE", "(", "perplexity", "=", "30", ",", "n_components", "=", "2", ",", "init", "=", "'pca'", ",", "n_iter", "=", "5000", ")", "\n", "# plot_only = 500", "\n", "low_dim_embs", "=", "tsne", ".", "fit_transform", "(", "embeddings", "[", ":", "plot_only", ",", ":", "]", ")", "\n", "labels", "=", "[", "reverse_dictionary", "[", "i", "]", "for", "i", "in", "range", "(", "plot_only", ")", "]", "\n", "plot_with_labels", "(", "low_dim_embs", ",", "labels", ",", "second", "=", "second", ",", "saveable", "=", "saveable", ",", "name", "=", "name", ",", "fig_idx", "=", "fig_idx", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "print", "(", "\"Please install sklearn and matplotlib to visualize embeddings.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__init__": [[76, 108], ["pymongo.MongoClient", "gridfs.GridFS", "gridfs.GridFS", "gridfs.GridFS", "gridfs.GridFS", "print", "db.TensorDB.db.authenticate", "str", "uuid.uuid1"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "ip", "=", "'localhost'", ",", "\n", "port", "=", "27017", ",", "\n", "db_name", "=", "'db_name'", ",", "\n", "user_name", "=", "None", ",", "\n", "password", "=", "'password'", ",", "\n", "studyID", "=", "None", "\n", ")", ":", "\n", "## connect mongodb", "\n", "        ", "client", "=", "MongoClient", "(", "ip", ",", "port", ")", "\n", "self", ".", "db", "=", "client", "[", "db_name", "]", "\n", "if", "user_name", "!=", "None", ":", "\n", "            ", "self", ".", "db", ".", "authenticate", "(", "user_name", ",", "password", ")", "\n", "\n", "", "if", "studyID", "is", "None", ":", "\n", "            ", "self", ".", "studyID", "=", "str", "(", "uuid", ".", "uuid1", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "studyID", "=", "studyID", "\n", "\n", "## define file system (Buckets)", "\n", "", "self", ".", "datafs", "=", "gridfs", ".", "GridFS", "(", "self", ".", "db", ",", "collection", "=", "\"datafs\"", ")", "\n", "self", ".", "modelfs", "=", "gridfs", ".", "GridFS", "(", "self", ".", "db", ",", "collection", "=", "\"modelfs\"", ")", "\n", "self", ".", "paramsfs", "=", "gridfs", ".", "GridFS", "(", "self", ".", "db", ",", "collection", "=", "\"paramsfs\"", ")", "\n", "self", ".", "archfs", "=", "gridfs", ".", "GridFS", "(", "self", ".", "db", ",", "collection", "=", "\"ModelArchitecture\"", ")", "\n", "##", "\n", "print", "(", "(", "\"[TensorDB] Connect SUCCESS {}:{} {} {} {}\"", ".", "format", "(", "ip", ",", "port", ",", "db_name", ",", "user_name", ",", "studyID", ")", ")", ")", "\n", "\n", "self", ".", "ip", "=", "ip", "\n", "self", ".", "port", "=", "port", "\n", "self", ".", "db_name", "=", "db_name", "\n", "self", ".", "user_name", "=", "user_name", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__autofill": [[109, 111], ["args.update"], "methods", ["None"], ["", "def", "__autofill", "(", "self", ",", "args", ")", ":", "\n", "        ", "return", "args", ".", "update", "(", "{", "'studyID'", ":", "self", ".", "studyID", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__serialization": [[112, 114], ["pickle.dumps"], "methods", ["None"], ["", "def", "__serialization", "(", "self", ",", "ps", ")", ":", "\n", "        ", "return", "pickle", ".", "dumps", "(", "ps", ",", "protocol", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__deserialization": [[115, 117], ["pickle.loads"], "methods", ["None"], ["", "def", "__deserialization", "(", "self", ",", "ps", ")", ":", "\n", "        ", "return", "pickle", ".", "loads", "(", "ps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.save_params": [[118, 148], ["db.TensorDB.__autofill", "time.time", "db.TensorDB.__serialization", "db.TensorDB.paramsfs.put", "args.update", "db.TensorDB.db.Params.insert_one", "print", "lz4.frame.compress", "datetime.datetime.datetime.utcnow", "round", "time.time"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__autofill", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__serialization"], ["", "def", "save_params", "(", "self", ",", "params", "=", "[", "]", ",", "args", "=", "{", "}", ",", "lz4_comp", "=", "False", ")", ":", "#, file_name='parameters'):", "\n", "        ", "\"\"\" Save parameters into MongoDB Buckets, and save the file ID into Params Collections.\n\n        Parameters\n        ----------\n        params : a list of parameters\n        args : dictionary, item meta data.\n\n        Returns\n        ---------\n        f_id : the Buckets ID of the parameters.\n        \"\"\"", "\n", "self", ".", "__autofill", "(", "args", ")", "\n", "st", "=", "time", ".", "time", "(", ")", "\n", "d", "=", "self", ".", "__serialization", "(", "params", ")", "\n", "# print('seri time', time.time()-st)", "\n", "\n", "if", "lz4_comp", ":", "\n", "# s = time.time()", "\n", "            ", "d", "=", "compress", "(", "d", ",", "compression_level", "=", "3", ")", "\n", "# print('comp time', time.time()-s)", "\n", "\n", "# s = time.time()", "\n", "", "f_id", "=", "self", ".", "paramsfs", ".", "put", "(", "d", ")", "#, file_name=file_name)", "\n", "# print('save time', time.time()-s)", "\n", "args", ".", "update", "(", "{", "'f_id'", ":", "f_id", ",", "'time'", ":", "datetime", ".", "utcnow", "(", ")", "}", ")", "\n", "self", ".", "db", ".", "Params", ".", "insert_one", "(", "args", ")", "\n", "# print(\"[TensorDB] Save params: {} SUCCESS, took: {}s\".format(file_name, round(time.time()-s, 2)))", "\n", "print", "(", "(", "\"[TensorDB] Save params: SUCCESS, took: {}s\"", ".", "format", "(", "round", "(", "time", ".", "time", "(", ")", "-", "st", ",", "2", ")", ")", ")", ")", "\n", "return", "f_id", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.find_one_params": [[149, 185], ["db.TensorDB.db.Params.find_one", "time.time", "db.TensorDB.paramsfs.get().read", "db.TensorDB.__deserialization", "print", "print", "lz4.frame.decompress", "db.TensorDB.paramsfs.get", "round", "time.time"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__deserialization"], ["", "@", "AutoFill", "\n", "def", "find_one_params", "(", "self", ",", "args", "=", "{", "}", ",", "sort", "=", "None", ",", "lz4_decomp", "=", "False", ")", ":", "\n", "        ", "\"\"\" Find one parameter from MongoDB Buckets.\n\n        Parameters\n        ----------\n        args : dictionary, find items.\n\n        Returns\n        --------\n        params : the parameters, return False if nothing found.\n        f_id : the Buckets ID of the parameters, return False if nothing found.\n        \"\"\"", "\n", "d", "=", "self", ".", "db", ".", "Params", ".", "find_one", "(", "filter", "=", "args", ",", "sort", "=", "sort", ")", "\n", "\n", "if", "d", "is", "not", "None", ":", "\n", "            ", "f_id", "=", "d", "[", "'f_id'", "]", "\n", "", "else", ":", "\n", "            ", "print", "(", "(", "\"[TensorDB] Cannot find: {}\"", ".", "format", "(", "args", ")", ")", ")", "\n", "return", "False", ",", "False", "\n", "\n", "", "st", "=", "time", ".", "time", "(", ")", "\n", "d", "=", "self", ".", "paramsfs", ".", "get", "(", "f_id", ")", ".", "read", "(", ")", "\n", "# print('get time', time.time()-st)", "\n", "\n", "if", "lz4_decomp", ":", "\n", "# s = time.time()", "\n", "            ", "d", "=", "decompress", "(", "d", ")", "\n", "# print('decomp time', time.time()-s)", "\n", "\n", "# s = time.time()", "\n", "", "params", "=", "self", ".", "__deserialization", "(", "d", ")", "\n", "# print('deseri time', time.time()-s)", "\n", "\n", "print", "(", "(", "\"[TensorDB] Find one params SUCCESS, {} took: {}s\"", ".", "format", "(", "args", ",", "round", "(", "time", ".", "time", "(", ")", "-", "st", ",", "2", ")", ")", ")", ")", "\n", "return", "params", ",", "f_id", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.find_all_params": [[186, 216], ["time.time", "db.TensorDB.db.Params.find", "print", "db.TensorDB.distinct", "print", "db.TensorDB.paramsfs.get().read", "params.append", "round", "lz4.frame.decompress", "db.TensorDB.__deserialization", "db.TensorDB.paramsfs.get", "time.time"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__deserialization"], ["", "@", "AutoFill", "\n", "def", "find_all_params", "(", "self", ",", "args", "=", "{", "}", ",", "lz4_decomp", "=", "False", ")", ":", "\n", "        ", "\"\"\" Find all parameter from MongoDB Buckets\n\n        Parameters\n        ----------\n        args : dictionary, find items\n\n        Returns\n        --------\n        params : the parameters, return False if nothing found.\n\n        \"\"\"", "\n", "st", "=", "time", ".", "time", "(", ")", "\n", "pc", "=", "self", ".", "db", ".", "Params", ".", "find", "(", "args", ")", "\n", "\n", "if", "pc", "is", "not", "None", ":", "\n", "            ", "f_id_list", "=", "pc", ".", "distinct", "(", "'f_id'", ")", "\n", "params", "=", "[", "]", "\n", "for", "f_id", "in", "f_id_list", ":", "# you may have multiple Buckets files", "\n", "                ", "tmp", "=", "self", ".", "paramsfs", ".", "get", "(", "f_id", ")", ".", "read", "(", ")", "\n", "if", "lz4_decomp", ":", "\n", "                    ", "tmp", "=", "decompress", "(", "tmp", ")", "\n", "", "params", ".", "append", "(", "self", ".", "__deserialization", "(", "tmp", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "(", "\"[TensorDB] Cannot find: {}\"", ".", "format", "(", "args", ")", ")", ")", "\n", "return", "False", "\n", "\n", "", "print", "(", "(", "\"[TensorDB] Find all params SUCCESS, took: {}s\"", ".", "format", "(", "round", "(", "time", ".", "time", "(", ")", "-", "st", ",", "2", ")", ")", ")", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.del_params": [[217, 234], ["db.TensorDB.db.Params.find", "db.TensorDB.distinct", "db.TensorDB.db.Params.remove", "print", "db.TensorDB.paramsfs.delete"], "methods", ["None"], ["", "@", "AutoFill", "\n", "def", "del_params", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" Delete params in MongoDB uckets.\n\n        Parameters\n        -----------\n        args : dictionary, find items to delete, leave it empty to delete all parameters.\n        \"\"\"", "\n", "pc", "=", "self", ".", "db", ".", "Params", ".", "find", "(", "args", ")", "\n", "f_id_list", "=", "pc", ".", "distinct", "(", "'f_id'", ")", "\n", "# remove from Buckets", "\n", "for", "f", "in", "f_id_list", ":", "\n", "            ", "self", ".", "paramsfs", ".", "delete", "(", "f", ")", "\n", "# remove from Collections", "\n", "", "self", ".", "db", ".", "Params", ".", "remove", "(", "args", ")", "\n", "\n", "print", "(", "(", "\"[TensorDB] Delete params SUCCESS: {}\"", ".", "format", "(", "args", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB._print_dict": [[235, 243], ["list", "args.items", "str", "str"], "methods", ["None"], ["", "def", "_print_dict", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\" \"\"\"", "\n", "# return \" / \".join(str(key) + \": \"+ str(value) for key, value in args.items())", "\n", "string", "=", "''", "\n", "for", "key", ",", "value", "in", "list", "(", "args", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "key", "is", "not", "'_id'", ":", "\n", "                ", "string", "+=", "str", "(", "key", ")", "+", "\": \"", "+", "str", "(", "value", ")", "+", "\" / \"", "\n", "", "", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.train_log": [[245, 261], ["db.TensorDB.db.TrainLog.insert_one", "db.TensorDB._print_dict"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB._print_dict"], ["", "@", "AutoFill", "\n", "def", "train_log", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Save the training log.\n\n        Parameters\n        -----------\n        args : dictionary, items to save.\n\n        Examples\n        ---------\n        >>> db.train_log(time=time.time(), {'loss': loss, 'acc': acc})\n        \"\"\"", "\n", "_result", "=", "self", ".", "db", ".", "TrainLog", ".", "insert_one", "(", "args", ")", "\n", "_log", "=", "self", ".", "_print_dict", "(", "args", ")", "\n", "#print(\"[TensorDB] TrainLog: \" +_log)", "\n", "return", "_result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.del_train_log": [[262, 273], ["db.TensorDB.db.TrainLog.delete_many", "print"], "methods", ["None"], ["", "@", "AutoFill", "\n", "def", "del_train_log", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" Delete train log.\n\n        Parameters\n        -----------\n        args : dictionary, find items to delete, leave it empty to delete all log.\n        \"\"\"", "\n", "\n", "self", ".", "db", ".", "TrainLog", ".", "delete_many", "(", "args", ")", "\n", "print", "(", "\"[TensorDB] Delete TrainLog SUCCESS\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.valid_log": [[274, 292], ["db.TensorDB.db.ValidLog.insert_one", "db.TensorDB._print_dict", "print"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB._print_dict"], ["", "@", "AutoFill", "\n", "def", "valid_log", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Save the validating log.\n\n        Parameters\n        -----------\n        args : dictionary, items to save.\n\n        Examples\n        ---------\n        >>> db.valid_log(time=time.time(), {'loss': loss, 'acc': acc})\n        \"\"\"", "\n", "\n", "_result", "=", "self", ".", "db", ".", "ValidLog", ".", "insert_one", "(", "args", ")", "\n", "# _log = \"\".join(str(key) + \": \" + str(value) for key, value in args.items())", "\n", "_log", "=", "self", ".", "_print_dict", "(", "args", ")", "\n", "print", "(", "(", "\"[TensorDB] ValidLog: \"", "+", "_log", ")", ")", "\n", "return", "_result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.del_valid_log": [[293, 303], ["db.TensorDB.db.ValidLog.delete_many", "print"], "methods", ["None"], ["", "@", "AutoFill", "\n", "def", "del_valid_log", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" Delete validation log.\n\n        Parameters\n        -----------\n        args : dictionary, find items to delete, leave it empty to delete all log.\n        \"\"\"", "\n", "self", ".", "db", ".", "ValidLog", ".", "delete_many", "(", "args", ")", "\n", "print", "(", "\"[TensorDB] Delete ValidLog SUCCESS\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.test_log": [[304, 322], ["db.TensorDB.db.TestLog.insert_one", "db.TensorDB._print_dict", "print"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB._print_dict"], ["", "@", "AutoFill", "\n", "def", "test_log", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Save the testing log.\n\n        Parameters\n        -----------\n        args : dictionary, items to save.\n\n        Examples\n        ---------\n        >>> db.test_log(time=time.time(), {'loss': loss, 'acc': acc})\n        \"\"\"", "\n", "\n", "_result", "=", "self", ".", "db", ".", "TestLog", ".", "insert_one", "(", "args", ")", "\n", "# _log = \"\".join(str(key) + str(value) for key, value in args.items())", "\n", "_log", "=", "self", ".", "_print_dict", "(", "args", ")", "\n", "print", "(", "(", "\"[TensorDB] TestLog: \"", "+", "_log", ")", ")", "\n", "return", "_result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.del_test_log": [[323, 334], ["db.TensorDB.db.TestLog.delete_many", "print"], "methods", ["None"], ["", "@", "AutoFill", "\n", "def", "del_test_log", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Delete test log.\n\n        Parameters\n        -----------\n        args : dictionary, find items to delete, leave it empty to delete all log.\n        \"\"\"", "\n", "\n", "self", ".", "db", ".", "TestLog", ".", "delete_many", "(", "args", ")", "\n", "print", "(", "\"[TensorDB] Delete TestLog SUCCESS\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.save_model_architecture": [[336, 343], ["db.TensorDB.__autofill", "db.TensorDB.archfs.put", "args.update", "db.TensorDB.db.march.insert_one"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__autofill"], ["", "@", "AutoFill", "\n", "def", "save_model_architecture", "(", "self", ",", "s", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" \"\"\"", "\n", "self", ".", "__autofill", "(", "args", ")", "\n", "fid", "=", "self", ".", "archfs", ".", "put", "(", "s", ",", "filename", "=", "\"modelarchitecture\"", ")", "\n", "args", ".", "update", "(", "{", "\"fid\"", ":", "fid", "}", ")", "\n", "self", ".", "db", ".", "march", ".", "insert_one", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.load_model_architecture": [[344, 365], ["db.TensorDB.db.march.find_one", "print", "print", "print", "print", "db.TensorDB.archfs.get().read", "print", "print", "db.TensorDB.archfs.get"], "methods", ["None"], ["", "@", "AutoFill", "\n", "def", "load_model_architecture", "(", "self", ",", "args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" \"\"\"", "\n", "d", "=", "self", ".", "db", ".", "march", ".", "find_one", "(", "args", ")", "\n", "if", "d", "is", "not", "None", ":", "\n", "            ", "fid", "=", "d", "[", "'fid'", "]", "\n", "print", "(", "d", ")", "\n", "print", "(", "fid", ")", "\n", "# \"print find\"", "\n", "", "else", ":", "\n", "            ", "print", "(", "(", "\"[TensorDB] Cannot find: {}\"", ".", "format", "(", "args", ")", ")", ")", "\n", "print", "(", "\"no idtem\"", ")", "\n", "return", "False", ",", "False", "\n", "", "try", ":", "\n", "            ", "archs", "=", "self", ".", "archfs", ".", "get", "(", "fid", ")", ".", "read", "(", ")", "\n", "'''print(\"[TensorDB] Find one params SUCCESS, {} took: {}s\".format(args, round(time.time()-s, 2)))'''", "\n", "return", "archs", ",", "fid", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"exception\"", ")", "\n", "print", "(", "e", ")", "\n", "return", "False", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.submit_job": [[366, 394], ["db.TensorDB.__autofill", "args.update", "db.TensorDB._print_dict", "print", "db.TensorDB.db.Job.insert_one", "db.TensorDB.db.Job.replace_one", "datetime.datetime.datetime.utcnow"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__autofill", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB._print_dict"], ["", "", "@", "AutoFill", "\n", "def", "submit_job", "(", "self", ",", "args", "=", "{", "}", ",", "allow_duplicate", "=", "True", ")", ":", "\n", "        ", "\"\"\" Submit a job.\n\n        Parameters\n        -----------\n        args : dictionary, arguments of each job.\n        allow_duplicate : bool, allow to submit the same job with the same arguments.\n\n        Examples\n        ---------\n        >>> result = db.submit_job(args={\n        ...     \"file\": \"main.py\",\n        ...     \"args\": \"--data_dir=/data\",\n        ... }, allow_duplicate=True)\n        \"\"\"", "\n", "self", ".", "__autofill", "(", "args", ")", "\n", "args", ".", "update", "(", "{", "\n", "'status'", ":", "JobStatus", ".", "WAITING", ",", "\n", "\"datetime\"", ":", "datetime", ".", "utcnow", "(", ")", ",", "\n", "}", ")", "\n", "if", "allow_duplicate", ":", "\n", "            ", "_result", "=", "self", ".", "db", ".", "Job", ".", "insert_one", "(", "args", ")", "\n", "", "else", ":", "\n", "            ", "_result", "=", "self", ".", "db", ".", "Job", ".", "replace_one", "(", "args", ",", "args", ",", "upsert", "=", "True", ")", "\n", "", "_log", "=", "self", ".", "_print_dict", "(", "args", ")", "\n", "print", "(", "(", "\"[TensorDB] Submit Job: args={}\"", ".", "format", "(", "args", ")", ")", ")", "\n", "return", "_result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.get_job": [[395, 415], ["db.TensorDB.db.Job.find_one", "print"], "methods", ["None"], ["", "def", "get_job", "(", "self", ",", "job_id", ")", ":", "\n", "        ", "\"\"\" Get a job by ID.\n\n        Parameters\n        -----------\n        job_id : ObjectId, job id from MongoDB.\n\n        Examples\n        ---------\n        - Manually specify job id\n        >>> from bson.objectid import ObjectId\n        >>> job = db.get_job(job_id=ObjectId('5929da7f130fd737204369b3'))\n        \"\"\"", "\n", "job", "=", "self", ".", "db", ".", "Job", ".", "find_one", "(", "{", "\"_id\"", ":", "job_id", "}", ")", "\n", "\n", "if", "job", "is", "None", ":", "\n", "            ", "print", "(", "(", "\"[TensorDB] Cannot find any job with id: {}\"", ".", "format", "(", "job_id", ")", ")", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "            ", "return", "job", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.get_jobs": [[416, 444], ["print", "db.TensorDB.db.Job.find", "db.TensorDB.db.Job.find", "print", "jobs.append"], "methods", ["None"], ["", "", "def", "get_jobs", "(", "self", ",", "status", "=", "None", ")", ":", "\n", "        ", "\"\"\" Get jobs based on their status.\n\n        Parameters\n        -----------\n        status : string, status of jobs from tl.db.JobStatus\n\n        Examples\n        ---------\n        - Get all running jobs\n        >>> jobs = db.get_jobs(status=JobStatus.RUNNING)\n        \"\"\"", "\n", "jobs", "=", "[", "]", "\n", "\n", "if", "status", "is", "None", ":", "\n", "            ", "cursor", "=", "self", ".", "db", ".", "Job", ".", "find", "(", "{", "}", ")", "\n", "", "else", ":", "\n", "            ", "cursor", "=", "self", ".", "db", ".", "Job", ".", "find", "(", "{", "'status'", ":", "status", "}", ")", "\n", "\n", "", "if", "cursor", "is", "not", "None", ":", "\n", "            ", "for", "job", "in", "cursor", ":", "# you may have multiple Buckets files", "\n", "                ", "jobs", ".", "append", "(", "job", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"[TensorDB] There is no job\"", ")", "\n", "return", "False", "\n", "\n", "", "print", "(", "(", "\"[TensorDB] Get jobs with status:{} SUCCESS\"", ".", "format", "(", "status", ")", ")", ")", "\n", "return", "jobs", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.change_job_status": [[445, 477], ["db.TensorDB.db.Job.find_one", "print", "db.TensorDB.db.Job.update", "print", "datetime.datetime.datetime.utcnow"], "methods", ["None"], ["", "def", "change_job_status", "(", "self", ",", "job_id", ",", "status", ")", ":", "\n", "        ", "\"\"\" Change the status of a job.\n\n        Parameters\n        -----------\n        job_id : ObjectId, job id from MongoDB.\n        status : string, status of jobs from tl.db.JobStatus\n\n        Examples\n        ---------\n        - Terminate running jobs\n        >>> jobs = db.get_jobs(status=JobStatus.RUNNING)\n        >>> for j in jobs:\n        >>>     print db.change_job_status(job_id=j[\"_id\"], status=JobStatus.TERMINATED)\n        \"\"\"", "\n", "job", "=", "self", ".", "db", ".", "Job", ".", "find_one", "(", "{", "\"_id\"", ":", "job_id", "}", ")", "\n", "\n", "if", "job", "is", "None", ":", "\n", "            ", "print", "(", "(", "\"[TensorDB] Cannot find any job with id: {}\"", ".", "format", "(", "job_id", ")", ")", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "            ", "_result", "=", "self", ".", "db", ".", "Job", ".", "update", "(", "\n", "{", "'_id'", ":", "job_id", "}", ",", "\n", "{", "\n", "'$set'", ":", "{", "\n", "'status'", ":", "status", ",", "\n", "\"datetime\"", ":", "datetime", ".", "utcnow", "(", ")", "\n", "}", "\n", "}", ",", "upsert", "=", "False", ",", "multi", "=", "False", "\n", ")", "\n", "print", "(", "(", "\"[TensorDB] Change the status of job ({}) to: {}\"", ".", "format", "(", "job_id", ",", "status", ")", ")", ")", "\n", "return", "_result", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.__str__": [[478, 482], ["str"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "_s", "=", "\"[TensorDB] Info:\\n\"", "\n", "_t", "=", "_s", "+", "\"    \"", "+", "str", "(", "self", ".", "db", ")", "\n", "return", "_t", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.DBLogger.__init__": [[554, 557], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "db", ",", "model", ")", ":", "\n", "        ", "self", ".", "db", "=", "db", "\n", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.DBLogger.on_train_begin": [[558, 560], ["print"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "print", "(", "\"start\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.DBLogger.on_train_end": [[561, 563], ["print"], "methods", ["None"], ["", "def", "on_train_end", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "print", "(", "\"end\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.DBLogger.on_epoch_begin": [[564, 568], ["time.time"], "methods", ["None"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "et", "=", "time", ".", "time", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.DBLogger.on_epoch_end": [[569, 583], ["print", "print", "datetime.datetime.datetime.utcnow", "numpy.asscalar", "print", "db.DBLogger.db.save_params", "logs.update", "db.DBLogger.db.valid_log", "time.time"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.save_params", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.valid_log"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "et", "=", "time", ".", "time", "(", ")", "-", "self", ".", "et", "\n", "print", "(", "\"ending\"", ")", "\n", "print", "(", "epoch", ")", "\n", "logs", "[", "'epoch'", "]", "=", "epoch", "\n", "logs", "[", "'time'", "]", "=", "datetime", ".", "utcnow", "(", ")", "\n", "logs", "[", "'stepTime'", "]", "=", "self", ".", "et", "\n", "logs", "[", "'acc'", "]", "=", "np", ".", "asscalar", "(", "logs", "[", "'acc'", "]", ")", "\n", "print", "(", "logs", ")", "\n", "\n", "w", "=", "self", ".", "model", ".", "Params", "\n", "fid", "=", "self", ".", "db", ".", "save_params", "(", "w", ",", "logs", ")", "\n", "logs", ".", "update", "(", "{", "'params'", ":", "fid", "}", ")", "\n", "self", ".", "db", ".", "valid_log", "(", "logs", ")", "\n", "", "def", "on_batch_begin", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.DBLogger.on_batch_begin": [[583, 587], ["time.time"], "methods", ["None"], ["", "def", "on_batch_begin", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "t", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "losses", "=", "[", "]", "\n", "self", ".", "batch", "=", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.DBLogger.on_batch_end": [[588, 597], ["numpy.asscalar", "datetime.datetime.datetime.utcnow", "db.DBLogger.db.train_log", "time.time"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.TensorDB.train_log"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "t2", "=", "time", ".", "time", "(", ")", "-", "self", ".", "t", "\n", "logs", "[", "'acc'", "]", "=", "np", ".", "asscalar", "(", "logs", "[", "'acc'", "]", ")", "\n", "#logs['loss']=np.asscalar(logs['loss'])", "\n", "logs", "[", "'step_time'", "]", "=", "self", ".", "t2", "\n", "logs", "[", "'time'", "]", "=", "datetime", ".", "utcnow", "(", ")", "\n", "logs", "[", "'epoch'", "]", "=", "self", ".", "epoch", "\n", "logs", "[", "'batch'", "]", "=", "self", ".", "batch", "\n", "self", ".", "db", ".", "train_log", "(", "logs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.db.AutoFill": [[34, 40], ["inspect.getcallargs", "d[].update", "func"], "function", ["None"], ["", "def", "AutoFill", "(", "func", ")", ":", "\n", "    ", "def", "func_wrapper", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "d", "=", "inspect", ".", "getcallargs", "(", "func", ",", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "d", "[", "'args'", "]", ".", "update", "(", "{", "\"studyID\"", ":", "self", ".", "studyID", "}", ")", "\n", "return", "func", "(", "**", "d", ")", "\n", "", "return", "func_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.fit": [[12, 180], ["print", "time.time", "range", "print", "print", "tensorlayer.files.exists_or_mkdir", "tensorflow.summary.merge_all", "tensorlayer.layers.initialize_global_variables", "print", "time.time", "iterate.minibatches", "hasattr", "hasattr", "hasattr", "hasattr", "tensorflow.summary.scalar", "feed_dict.update", "sess.run", "hasattr", "tensorflow.compat.v1.summary.FileWriter", "tensorflow.compat.v1.summary.FileWriter", "tensorflow.compat.v1.summary.FileWriter", "tensorflow.compat.v1.summary.FileWriter", "iterate.minibatches", "iterate.minibatches", "print", "iterate.minibatches", "print", "print", "time.time", "hasattr", "hasattr", "print", "tensorflow.summary.histogram", "utils.dict_to_one", "feed_dict.update", "sess.run", "tf.compat.v1.summary.FileWriter.add_summary", "utils.dict_to_one", "feed_dict.update", "sess.run", "tf.compat.v1.summary.FileWriter.add_summary", "iterate.minibatches", "print", "utils.dict_to_one", "feed_dict.update", "print", "utils.dict_to_one", "feed_dict.update", "print", "sess.run", "sess.run", "sess.run", "sess.run", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.files.exists_or_mkdir", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.layers.initialize_global_variables", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one"], ["class_labels", "=", "np", ".", "unique", "(", "y", ")", "\n", "n_min_classes", "=", "-", "1", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "n_samples", "=", "len", "(", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", ")", "\n", "if", "n_min_classes", "==", "-", "1", ":", "\n", "            ", "n_min_classes", "=", "n_samples", "\n", "", "elif", "n_min_classes", ">", "n_samples", ":", "\n", "            ", "n_min_classes", "=", "n_samples", "\n", "\n", "", "", "balance_x", "=", "[", "]", "\n", "balance_y", "=", "[", "]", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "idx", "=", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", "\n", "idx", "=", "np", ".", "random", ".", "permutation", "(", "idx", ")", "[", ":", "n_min_classes", "]", "\n", "balance_x", ".", "append", "(", "x", "[", "idx", "]", ")", "\n", "balance_y", ".", "append", "(", "y", "[", "idx", "]", ")", "\n", "", "balance_x", "=", "np", ".", "vstack", "(", "balance_x", ")", "\n", "balance_y", "=", "np", ".", "hstack", "(", "balance_y", ")", "\n", "\n", "return", "balance_x", ",", "balance_y", "\n", "\n", "\n", "", "def", "get_balance_class_oversample", "(", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\"\n    Balance the number of samples of all classes by (oversampling):\n        1. Find the class that has the largest number of samples\n        2. Randomly select samples in each class equal to that largest number\n    \"\"\"", "\n", "class_labels", "=", "np", ".", "unique", "(", "y", ")", "\n", "n_max_classes", "=", "-", "1", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "n_samples", "=", "len", "(", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", ")", "\n", "if", "n_max_classes", "<", "n_samples", ":", "\n", "            ", "n_max_classes", "=", "n_samples", "\n", "\n", "", "", "balance_x", "=", "[", "]", "\n", "balance_y", "=", "[", "]", "\n", "for", "c", "in", "class_labels", ":", "\n", "        ", "idx", "=", "np", ".", "where", "(", "y", "==", "c", ")", "[", "0", "]", "\n", "n_samples", "=", "len", "(", "idx", ")", "\n", "n_repeats", "=", "int", "(", "n_max_classes", "/", "n_samples", ")", "\n", "tmp_x", "=", "np", ".", "repeat", "(", "x", "[", "idx", "]", ",", "n_repeats", ",", "axis", "=", "0", ")", "\n", "tmp_y", "=", "np", ".", "repeat", "(", "y", "[", "idx", "]", ",", "n_repeats", ",", "axis", "=", "0", ")", "\n", "n_remains", "=", "n_max_classes", "-", "len", "(", "tmp_x", ")", "\n", "if", "n_remains", ">", "0", ":", "\n", "            ", "sub_idx", "=", "np", ".", "random", ".", "permutation", "(", "idx", ")", "[", ":", "n_remains", "]", "\n", "tmp_x", "=", "np", ".", "vstack", "(", "[", "tmp_x", ",", "x", "[", "sub_idx", "]", "]", ")", "\n", "tmp_y", "=", "np", ".", "hstack", "(", "[", "tmp_y", ",", "y", "[", "sub_idx", "]", "]", ")", "\n", "", "balance_x", ".", "append", "(", "tmp_x", ")", "\n", "balance_y", ".", "append", "(", "tmp_y", ")", "\n", "", "balance_x", "=", "np", ".", "vstack", "(", "balance_x", ")", "\n", "balance_y", "=", "np", ".", "hstack", "(", "balance_y", ")", "\n", "\n", "return", "balance_x", ",", "balance_y", "\n", "\n", "\n", "", "def", "iterate_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Generate a generator that return a batch of inputs and targets.\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "if", "shuffle", ":", "\n", "        ", "indices", "=", "np", ".", "arange", "(", "len", "(", "inputs", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "inputs", ")", "-", "batch_size", "+", "1", ",", "batch_size", ")", ":", "\n", "        ", "if", "shuffle", ":", "\n", "            ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "            ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "inputs", "[", "excerpt", "]", ",", "targets", "[", "excerpt", "]", "\n", "\n", "\n", "", "", "def", "iterate_seq_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "seq_length", ",", "stride", ")", ":", "\n", "    ", "\"\"\"\n    Generate a generator that return a batch of sequence inputs and targets.\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "n_loads", "=", "(", "batch_size", "*", "stride", ")", "+", "(", "seq_length", "-", "stride", ")", "\n", "for", "start_idx", "in", "range", "(", "0", ",", "len", "(", "inputs", ")", "-", "n_loads", "+", "1", ",", "(", "batch_size", "*", "stride", ")", ")", ":", "\n", "        ", "seq_inputs", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "seq_length", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "seq_targets", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "seq_length", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "targets", ".", "dtype", ")", "\n", "for", "b_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "start_seq_idx", "=", "start_idx", "+", "(", "b_idx", "*", "stride", ")", "\n", "end_seq_idx", "=", "start_seq_idx", "+", "seq_length", "\n", "seq_inputs", "[", "b_idx", "]", "=", "inputs", "[", "start_seq_idx", ":", "end_seq_idx", "]", "\n", "seq_targets", "[", "b_idx", "]", "=", "targets", "[", "start_seq_idx", ":", "end_seq_idx", "]", "\n", "", "flatten_inputs", "=", "seq_inputs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ")", "\n", "flatten_targets", "=", "seq_targets", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ")", "\n", "yield", "flatten_inputs", ",", "flatten_targets", "\n", "\n", "\n", "", "", "def", "iterate_batch_seq_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "seq_length", ")", ":", "\n", "    ", "assert", "len", "(", "inputs", ")", "==", "len", "(", "targets", ")", "\n", "n_inputs", "=", "len", "(", "inputs", ")", "\n", "batch_len", "=", "n_inputs", "//", "batch_size", "\n", "\n", "epoch_size", "=", "batch_len", "//", "seq_length", "\n", "if", "epoch_size", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"epoch_size == 0, decrease batch_size or seq_length\"", ")", "\n", "\n", "", "seq_inputs", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "batch_len", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "seq_targets", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "batch_len", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "targets", ".", "dtype", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "seq_inputs", "[", "i", "]", "=", "inputs", "[", "i", "*", "batch_len", ":", "(", "i", "+", "1", ")", "*", "batch_len", "]", "\n", "seq_targets", "[", "i", "]", "=", "targets", "[", "i", "*", "batch_len", ":", "(", "i", "+", "1", ")", "*", "batch_len", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "epoch_size", ")", ":", "\n", "        ", "x", "=", "seq_inputs", "[", ":", ",", "i", "*", "seq_length", ":", "(", "i", "+", "1", ")", "*", "seq_length", "]", "\n", "y", "=", "seq_targets", "[", ":", ",", "i", "*", "seq_length", ":", "(", "i", "+", "1", ")", "*", "seq_length", "]", "\n", "flatten_x", "=", "x", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "inputs", ".", "shape", "[", "1", ":", "]", ")", "\n", "flatten_y", "=", "y", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "targets", ".", "shape", "[", "1", ":", "]", ")", "\n", "yield", "flatten_x", ",", "flatten_y", "\n", "\n", "\n", "", "", "def", "iterate_list_batch_seq_minibatches", "(", "inputs", ",", "targets", ",", "batch_size", ",", "seq_length", ")", ":", "\n", "    ", "for", "idx", ",", "each_data", "in", "enumerate", "(", "zip", "(", "inputs", ",", "targets", ")", ")", ":", "\n", "        ", "each_x", ",", "each_y", "=", "each_data", "\n", "seq_x", ",", "seq_y", "=", "[", "]", ",", "[", "]", "\n", "for", "x_batch", ",", "y_batch", "in", "iterate_seq_minibatches", "(", "inputs", "=", "each_x", ",", "\n", "targets", "=", "each_y", ",", "\n", "batch_size", "=", "1", ",", "\n", "seq_length", "=", "seq_length", ",", "\n", "stride", "=", "1", ")", ":", "\n", "            ", "seq_x", ".", "append", "(", "x_batch", ")", "\n", "seq_y", ".", "append", "(", "y_batch", ")", "\n", "", "seq_x", "=", "np", ".", "vstack", "(", "seq_x", ")", "\n", "seq_x", "=", "seq_x", ".", "reshape", "(", "(", "-", "1", ",", "seq_length", ")", "+", "seq_x", ".", "shape", "[", "1", ":", "]", ")", "\n", "seq_y", "=", "np", ".", "hstack", "(", "seq_y", ")", "\n", "seq_y", "=", "seq_y", ".", "reshape", "(", "(", "-", "1", ",", "seq_length", ")", "+", "seq_y", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "for", "x_batch", ",", "y_batch", "in", "iterate_batch_seq_minibatches", "(", "inputs", "=", "seq_x", ",", "\n", "targets", "=", "seq_y", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "seq_length", "=", "1", ")", ":", "\n", "            ", "x_batch", "=", "x_batch", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "x_batch", ".", "shape", "[", "2", ":", "]", ")", "\n", "y_batch", "=", "y_batch", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "y_batch", ".", "shape", "[", "2", ":", "]", ")", "\n", "yield", "x_batch", ",", "y_batch", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.test": [[182, 239], ["print", "utils.dict_to_one", "feed_dict.update", "print", "iterate.minibatches", "print", "print", "utils.dict_to_one", "feed_dict.update", "print", "sess.run", "sess.run", "sess.run", "sess.run"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.iterate.minibatches", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one"], []], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.predict": [[241, 269], ["utils.dict_to_one", "feed_dict.update", "sess.run"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one"], []], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.evaluation": [[271, 300], ["confusion_matrix", "f1_score", "f1_score", "accuracy_score", "print", "print", "print", "print", "range", "range"], "function", ["None"], []], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.dict_to_one": [[301, 318], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.flatten_list": [[319, 333], ["sum"], "function", ["None"], []], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.class_balancing_oversample": [[335, 414], ["Counter", "Counter.most_common", "list", "numpy.empty", "Counter", "print", "print", "print", "print", "print", "print", "number.items", "print", "print", "print", "print", "print", "print", "print", "numpy.vstack", "y_train.extend", "print", "Counter.most_common", "numpy.where", "numpy.vstack", "Counter.most_common", "len", "len", "len", "len", "len", "Counter.most_common", "Counter.most_common", "Counter.most_common", "numpy.array", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.tensorlayer.utils.get_random_int": [[416, 429], ["random.Random", "random.Random", "random.Random.randint", "range"], "function", ["None"], []], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__init__": [[30, 34], ["str", "int", "http.HTTPSConnection"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "interface_ip", ",", "interface_port", ")", ":", "\n", "        ", "self", ".", "interface_ip", "=", "str", "(", "interface_ip", ")", "\n", "self", ".", "interface_port", "=", "int", "(", "interface_port", ")", "\n", "self", ".", "connection", "=", "http", ".", "HTTPSConnection", "(", "self", ".", "interface_ip", ",", "self", ".", "interface_port", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.__str__": [[35, 38], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"\\rThe interface ip is set to: {0}\\r The interface port is set to: {1}\"", ".", "format", "(", "self", ".", "interface_ip", ",", "\n", "self", ".", "interface_port", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE._create_eae_zipfile": [[39, 64], ["to_zip.append", "zipfile.ZipFile", "zipfile.ZipFile.close", "os.chmod", "zipfile.ZipFile.write", "subprocess.call"], "methods", ["None"], ["", "def", "_create_eae_zipfile", "(", "self", ",", "zip_file_name", ",", "main_file_path", ",", "data_files", "=", "None", ")", ":", "\n", "\n", "        ", "to_zip", "=", "[", "]", "\n", "if", "data_files", "is", "None", ":", "\n", "            ", "data_files", "=", "[", "]", "\n", "\n", "# Handle main script", "\n", "", "to_zip", ".", "append", "(", "main_file_path", ")", "\n", "\n", "# Prepare the zip file", "\n", "zip_path", "=", "\"/tmp/\"", "+", "zip_file_name", "\n", "zipf", "=", "zipfile", ".", "ZipFile", "(", "zip_path", ",", "mode", "=", "'w'", ",", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ",", "allowZip64", "=", "True", ")", "\n", "for", "f", "in", "to_zip", ":", "\n", "            ", "zipf", ".", "write", "(", "f", ")", "\n", "", "zipf", ".", "close", "(", ")", "\n", "\n", "# Handle other files & dirs", "\n", "for", "f", "in", "data_files", ":", "\n", "            ", "zipCommand", "=", "\"zip -r -u -0 \"", "+", "zip_path", "+", "\" \"", "+", "f", "\n", "call", "(", "[", "zipCommand", "]", ",", "shell", "=", "True", ")", "\n", "\n", "# Chmod 666 the zip file so it can be accessed", "\n", "", "os", ".", "chmod", "(", "zip_path", ",", "stat", ".", "S_IRUSR", "|", "stat", ".", "S_IWUSR", "|", "stat", ".", "S_IRGRP", "|", "stat", ".", "S_IWGRP", "|", "stat", ".", "S_IROTH", "|", "stat", ".", "S_IWOTH", ")", "\n", "\n", "return", "zip_path", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.is_eae_alive": [[65, 70], ["eAE.eAE.connection.request", "eAE.eAE.connection.getresponse", "int", "eAE.eAE.read"], "methods", ["None"], ["", "def", "is_eae_alive", "(", "self", ")", ":", "\n", "        ", "\"\"\"Retrieve the status of the eAE\"\"\"", "\n", "self", ".", "connection", ".", "request", "(", "'GET'", ",", "'/interfaceEAE/utilities/isAlive'", ")", "\n", "res", "=", "self", ".", "connection", ".", "getresponse", "(", ")", "\n", "return", "int", "(", "res", ".", "read", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.retrieve_clusters": [[71, 78], ["eAE.eAE.connection.request", "eAE.eAE.connection.getresponse", "eAE.eAE.read().decode", "json.loads", "eAE.eAE.read"], "methods", ["None"], ["", "def", "retrieve_clusters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Retrieve the list of all available clusters\"\"\"", "\n", "self", ".", "connection", ".", "request", "(", "'GET'", ",", "'/interfaceEAE/EAEManagement/retrieveClusters'", ")", "\n", "res", "=", "self", ".", "connection", ".", "getresponse", "(", ")", "\n", "str_response", "=", "res", ".", "read", "(", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "clusters", "=", "json", ".", "loads", "(", "str_response", ")", "\n", "return", "clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.submit_jobs": [[79, 97], ["uuid.uuid4.uuid4", "eAE.eAE._create_eae_zipfile", "json.dumps", "eAE.eAE.connection.request", "eAE.eAE.connection.getresponse", "eAE.eAE.read", "str"], "methods", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE._create_eae_zipfile"], ["", "def", "submit_jobs", "(", "self", ",", "parameters_set", ",", "cluster", ",", "computation_type", ",", "main_file", ",", "data_files", ",", "host_ip", ",", "ssh_port", "=", "\"22\"", ")", ":", "\n", "        ", "\"\"\"Submit jobs to the eAE backend\n        \n        This method is called when a specific task needs to be deployed on a cluster.\n        \"\"\"", "\n", "\n", "uuid", "=", "uuid4", "(", ")", "\n", "zip_file_name", "=", "\"{0}.zip\"", ".", "format", "(", "uuid", ")", "\n", "configs", "=", "parameters_set", "\n", "zip_file", "=", "self", ".", "_create_eae_zipfile", "(", "zip_file_name", ",", "main_file", ",", "data_files", ")", "\n", "data", "=", "{", "'id'", ":", "str", "(", "uuid", ")", ",", "'host_ip'", ":", "host_ip", ",", "'ssh_port'", ":", "ssh_port", ",", "'zip'", ":", "zip_file", ",", "'configs'", ":", "configs", ",", "\n", "'cluster'", ":", "cluster", ",", "'clusterType'", ":", "computation_type", ",", "'mainScriptExport'", ":", "main_file", "}", "\n", "data_str", "=", "json", ".", "dumps", "(", "data", ")", "\n", "self", ".", "connection", ".", "request", "(", "'POST'", ",", "'/interfaceEAE/OpenLava/submitJob'", ",", "data_str", ")", "\n", "res", "=", "self", ".", "connection", ".", "getresponse", "(", ")", "\n", "submit_sucess", "=", "res", ".", "read", "(", ")", "\n", "\n", "return", "submit_sucess", "\n", "\n"]], "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.test_methods": [[99, 123], ["eAE.eAE", "eAE.is_eae_alive", "print", "eAE.retrieve_clusters", "print", "eAE.submit_jobs", "print"], "function", ["home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.is_eae_alive", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.retrieve_clusters", "home.repos.pwc.inspect_result.akaraspt_deepsleepnet.eAE.eAE.eAE.submit_jobs"], ["", "", "def", "test_methods", "(", ")", ":", "\n", "# Setting up the connection to interface", "\n", "    ", "ip", "=", "\"interfaceeae.doc.ic.ac.uk\"", "\n", "port", "=", "443", "\n", "eae", "=", "eAE", "(", "ip", ",", "port", ")", "\n", "\n", "# Testing if the interface is Alive", "\n", "is_alive", "=", "eae", ".", "is_eae_alive", "(", ")", "\n", "print", "(", "is_alive", ")", "\n", "\n", "# We retrieve the list of Clusters", "\n", "clusters", "=", "eae", ".", "retrieve_clusters", "(", ")", "\n", "print", "(", "clusters", ")", "\n", "\n", "# We submit a dummy job", "\n", "parameters_set", "=", "\"0\\n 1\\n 2\\n\"", "\n", "cluster", "=", "\"python_large\"", "\n", "computation_type", "=", "\"Python\"", "\n", "main_file", "=", "\"/PATH/TO/FILE/Demo.py\"", "\n", "data_files", "=", "[", "''", "]", "\n", "host_ip", "=", "\"X.X.X.X\"", "\n", "ssh_port", "=", "\"22\"", "\n", "job", "=", "eae", ".", "submit_jobs", "(", "parameters_set", ",", "cluster", ",", "computation_type", ",", "main_file", ",", "data_files", ",", "host_ip", ",", "ssh_port", ")", "\n", "print", "(", "job", ")", "\n", "\n"]]}